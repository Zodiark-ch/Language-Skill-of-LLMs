[2024-07-24 10:17:50,137][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isThen, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to
[2024-07-24 10:17:50,137][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Jamie
[2024-07-24 10:17:50,137][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:17:50,137][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:17:50,137][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:17:50,137][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,137][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:17:50,137][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,137][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:17:50,137][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22']
[2024-07-24 10:17:50,137][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:17:50,137][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:17:50,137][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:17:50,137][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,137][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:17:50,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,138][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:17:50,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,138][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:17:50,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,138][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:17:50,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,138][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:17:50,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,138][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:17:50,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,138][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:17:50,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,138][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:17:50,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,138][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:17:50,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,139][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:17:50,139][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit5', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,139][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:17:50,139][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,139][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:17:50,139][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,139][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:17:50,139][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,139][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:17:50,139][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,139][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:17:50,139][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,139][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:17:50,139][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,139][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:17:50,139][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,139][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:17:50,140][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit11', 'circuit13', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,140][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:17:50,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,144][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:17:50,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,144][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:17:50,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,144][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:17:50,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,144][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:17:50,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,144][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:17:50,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,144][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:17:50,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,144][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,145][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:17:50,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:17:50,145][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,145][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:17:50,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,145][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit15']
[2024-07-24 10:17:50,145][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:17:50,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:17:50,145][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:17:50,145][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:17:50,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:17:50,145][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,145][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:17:50,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,145][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit27']
[2024-07-24 10:17:50,145][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:17:50,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:17:50,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,146][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:17:50,146][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,146][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:17:50,146][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:17:50,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,146][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:17:50,146][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:17:50,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,146][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:17:50,146][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,146][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:17:50,146][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit6', 'circuit12', 'circuit13', 'circuit14']
[2024-07-24 10:17:50,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:17:50,146][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:17:50,147][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,147][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:17:50,147][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit5', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,147][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:17:50,147][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14']
[2024-07-24 10:17:50,147][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:17:50,147][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,147][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:17:50,147][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:17:50,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0']
[2024-07-24 10:17:50,147][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:17:50,147][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,147][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit10', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit26']
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23']
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:17:50,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit21']
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit26']
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit18', 'circuit19']
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20']
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit7', 'circuit13', 'circuit14', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:17:50,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22']
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit21']
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,150][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit16', 'circuit21', 'circuit25']
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit18', 'circuit22']
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22']
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit26']
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit26']
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit23', 'circuit25']
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit8', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,152][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,153][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit13']
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit17', 'circuit19']
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit20']
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:17:50,154][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit18', 'circuit21']
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit13']
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:17:50,155][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23', 'circuit27']
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit5', 'circuit6']
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14']
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit26']
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,156][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16']
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit28']
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7']
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21']
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit23']
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,157][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit20']
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20']
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:17:50,158][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit3', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21']
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14']
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit9', 'circuit15']
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit19', 'circuit20']
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23']
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,159][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit17']
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit18']
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,160][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23']
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22']
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19']
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:17:50,161][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21']
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,162][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:17:50,163][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,164][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,165][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1']
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit14', 'circuit17', 'circuit21']
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit14', 'circuit25']
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit26']
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit25']
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit18', 'circuit19', 'circuit22']
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit21']
[2024-07-24 10:17:50,166][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21', 'circuit24', 'circuit27']
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22']
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit4', 'circuit5', 'circuit14', 'circuit15']
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18']
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22']
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,167][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22']
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,168][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15']
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,169][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,170][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,171][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,172][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit6', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23']
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit14', 'circuit15', 'circuit27']
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit26']
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,173][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit5', 'circuit14', 'circuit15']
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit26']
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit23']
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit17', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit13', 'circuit15', 'circuit26']
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,174][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit27']
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19']
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18']
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit27']
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit15']
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19']
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit26']
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit16', 'circuit17', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17']
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,175][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22']
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit18', 'circuit19', 'circuit22']
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21']
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,176][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit27']
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit21', 'circuit26']
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit24']
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24']
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,177][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,178][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,179][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,180][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,181][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit8', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit27']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit18', 'circuit23', 'circuit26']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit8', 'circuit15', 'circuit23', 'circuit26']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14', 'circuit19', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,182][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit25', 'circuit27']
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit19', 'circuit23', 'circuit25']
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit17', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,183][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit23', 'circuit25']
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit19', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit17', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13']
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit20', 'circuit22', 'circuit27']
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit23']
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24']
[2024-07-24 10:17:50,184][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15', 'circuit25']
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14']
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,185][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit16', 'circuit18']
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15', 'circuit21', 'circuit25', 'circuit27']
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,186][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,187][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:17:50,188][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,189][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,190][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit9', 'circuit13', 'circuit14', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,191][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,192][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,193][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,194][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit20', 'circuit22']
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,195][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit15', 'circuit22']
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit1', 'circuit3', 'circuit4', 'circuit16']
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit21', 'circuit26']
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,196][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,197][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,198][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,199][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,200][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:17:50,201][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit9', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit13', 'circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit3', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit9', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,202][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:17:50,203][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,204][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,205][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,206][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,207][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,208][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,209][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,210][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,211][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,212][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit1', 'circuit4', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit15', 'circuit17', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit13', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,213][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,214][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,215][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,216][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,217][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,218][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,219][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,220][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,221][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,222][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23']
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,223][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,224][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:50,225][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:51,737][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:51,738][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:51,739][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:51,740][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:51,741][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:51,741][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:51,743][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:51,744][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:51,745][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:51,747][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:51,748][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:51,750][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:51,752][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:51,753][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:51,755][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:51,757][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:51,759][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:51,760][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:51,761][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:51,762][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:51,763][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:51,763][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:51,764][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:51,765][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:51,766][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:51,768][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Jamie] are: tensor([0.2713, 0.3216, 0.4071], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:51,769][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Jamie] are: tensor([3.1793e-05, 3.5104e-05, 9.9993e-01], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:51,770][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Jamie] are: tensor([0.5307, 0.2194, 0.2498], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:51,772][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Jamie] are: tensor([0.0069, 0.0011, 0.9920], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:51,774][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Jamie] are: tensor([0.0378, 0.0047, 0.9575], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:51,775][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Jamie] are: tensor([1.7690e-02, 2.4118e-06, 9.8231e-01], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:51,777][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Jamie] are: tensor([0.3911, 0.2796, 0.3293], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:51,779][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Jamie] are: tensor([0.4983, 0.3985, 0.1032], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:51,779][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Jamie] are: tensor([0.4405, 0.2743, 0.2852], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:51,780][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Jamie] are: tensor([0.6336, 0.3263, 0.0401], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:51,781][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Jamie] are: tensor([0.4429, 0.2461, 0.3110], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:51,781][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Jamie] are: tensor([0.3818, 0.3780, 0.2403], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:51,782][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6437, 0.0729, 0.2266, 0.0569], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:51,783][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0023, 0.0392, 0.0014, 0.9571], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:51,785][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2358, 0.1766, 0.0443, 0.5433], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:51,787][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1146, 0.3916, 0.0148, 0.4791], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:51,789][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3717, 0.1684, 0.1549, 0.3050], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:51,790][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1235, 0.1977, 0.0035, 0.6753], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:51,792][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5297, 0.0253, 0.4258, 0.0192], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:51,794][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2270, 0.1726, 0.3406, 0.2598], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:51,796][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0673, 0.4714, 0.0193, 0.4420], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:51,797][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4303, 0.2403, 0.1062, 0.2232], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:51,798][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4124, 0.3072, 0.0777, 0.2027], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:51,799][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4270, 0.1865, 0.1429, 0.2437], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:51,799][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.2093, 0.3278, 0.0828, 0.2633, 0.1168], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:51,800][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([3.8321e-05, 1.1486e-04, 2.3569e-04, 6.9513e-05, 9.9954e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:51,801][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.3532, 0.2296, 0.0770, 0.1384, 0.2018], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:51,802][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([4.4921e-03, 5.5093e-05, 9.2220e-03, 1.1051e-04, 9.8612e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:51,803][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0287, 0.0059, 0.1263, 0.0068, 0.8323], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:51,805][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([7.6686e-03, 3.7451e-07, 2.4998e-05, 9.4585e-08, 9.9231e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:51,806][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.2186, 0.2960, 0.2147, 0.1924, 0.0783], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:51,808][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.2325, 0.2814, 0.0704, 0.3682, 0.0475], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:51,810][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.2438, 0.1654, 0.1173, 0.1399, 0.3335], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:51,812][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.3833, 0.2168, 0.1900, 0.1798, 0.0302], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:51,814][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.3024, 0.2048, 0.0801, 0.1265, 0.2862], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:51,815][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.1816, 0.2345, 0.1451, 0.2582, 0.1806], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:51,816][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.3949, 0.0347, 0.1440, 0.0346, 0.0876, 0.3042], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:51,816][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ had] are: tensor([3.2204e-04, 1.6747e-03, 6.6930e-04, 2.8606e-03, 1.8513e-04, 9.9429e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:51,817][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.4917, 0.1254, 0.0353, 0.1483, 0.0524, 0.1469], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:51,818][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0049, 0.0054, 0.0013, 0.0115, 0.0019, 0.9749], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:51,819][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2251, 0.0640, 0.0427, 0.1159, 0.0742, 0.4781], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:51,820][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ had] are: tensor([3.9817e-02, 1.8581e-03, 2.0244e-04, 1.2918e-03, 2.8078e-04, 9.5655e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:51,821][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2132, 0.0159, 0.4196, 0.0149, 0.3150, 0.0214], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:51,823][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1249, 0.0973, 0.0984, 0.2258, 0.1727, 0.2808], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:51,825][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0960, 0.2695, 0.0346, 0.3541, 0.0268, 0.2191], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:51,826][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3038, 0.1832, 0.1020, 0.1888, 0.0946, 0.1276], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:51,828][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.2523, 0.1946, 0.0638, 0.1425, 0.0374, 0.3094], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:51,830][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.4105, 0.1371, 0.0988, 0.1710, 0.0963, 0.0864], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:51,832][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.3841, 0.0442, 0.1046, 0.0334, 0.3489, 0.0551, 0.0296],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:51,833][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.5377e-04, 4.2907e-03, 3.7406e-03, 4.2886e-03, 3.5781e-04, 4.6729e-04,
        9.8600e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:51,834][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2926, 0.1814, 0.0805, 0.2140, 0.0651, 0.1211, 0.0452],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:51,834][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0287, 0.0176, 0.0043, 0.0324, 0.0389, 0.1754, 0.7026],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:51,835][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1432, 0.0315, 0.0361, 0.0444, 0.0804, 0.4478, 0.2166],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:51,836][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0560, 0.1298, 0.0036, 0.0971, 0.0016, 0.0448, 0.6671],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:51,837][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2615, 0.0087, 0.3664, 0.0074, 0.3090, 0.0385, 0.0085],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:51,839][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0960, 0.0577, 0.0548, 0.1290, 0.1483, 0.2164, 0.2979],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:51,841][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0239, 0.1304, 0.0061, 0.1937, 0.0150, 0.1415, 0.4893],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:51,842][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2592, 0.1660, 0.0907, 0.1684, 0.0783, 0.1045, 0.1329],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:51,844][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2235, 0.1906, 0.0810, 0.1616, 0.0373, 0.0827, 0.2234],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:51,846][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3130, 0.1255, 0.1223, 0.1348, 0.1197, 0.0809, 0.1038],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:51,847][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.3346, 0.0740, 0.1229, 0.0782, 0.1474, 0.0698, 0.0827, 0.0904],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:51,849][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([2.6404e-04, 1.0258e-03, 1.9719e-03, 1.2059e-03, 2.3049e-03, 1.3640e-03,
        5.0203e-04, 9.9136e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:51,850][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.2921, 0.1129, 0.0502, 0.2019, 0.0778, 0.1500, 0.0779, 0.0373],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:51,851][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([1.0767e-03, 1.2856e-04, 2.0283e-05, 2.5209e-04, 7.9391e-04, 2.0034e-03,
        1.6734e-03, 9.9405e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:51,852][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0459, 0.0142, 0.0130, 0.0158, 0.0244, 0.0606, 0.0714, 0.7546],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:51,853][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([3.2516e-03, 1.1955e-04, 4.1709e-05, 1.7789e-05, 8.6875e-05, 9.6460e-06,
        5.2872e-06, 9.9647e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:51,853][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.2588, 0.0559, 0.1983, 0.0326, 0.1839, 0.0370, 0.0483, 0.1852],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:51,854][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0859, 0.0463, 0.0253, 0.0912, 0.1332, 0.1479, 0.2734, 0.1967],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:51,856][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.1173, 0.1425, 0.0238, 0.1317, 0.1063, 0.1074, 0.3191, 0.0520],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:51,858][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.2357, 0.1495, 0.1152, 0.1447, 0.0727, 0.0971, 0.1247, 0.0603],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:51,860][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.2072, 0.1489, 0.0486, 0.1230, 0.0502, 0.0830, 0.0828, 0.2563],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:51,862][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.4252, 0.0815, 0.1016, 0.0844, 0.1096, 0.0576, 0.0425, 0.0977],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:51,864][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.3142, 0.0494, 0.1293, 0.0355, 0.2135, 0.0648, 0.0432, 0.1226, 0.0275],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:51,865][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ of] are: tensor([8.9861e-04, 1.5859e-02, 1.4286e-04, 2.1562e-02, 7.5124e-05, 6.7594e-04,
        3.8732e-04, 9.5689e-05, 9.6030e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:51,867][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.3013, 0.1428, 0.0658, 0.1327, 0.0353, 0.0768, 0.0608, 0.0845, 0.0999],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:51,868][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ of] are: tensor([5.2298e-03, 3.0357e-03, 2.2093e-04, 7.0127e-03, 8.1627e-04, 4.5600e-02,
        6.1319e-02, 3.7489e-01, 5.0188e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:51,869][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1606, 0.0219, 0.0232, 0.0261, 0.0505, 0.1155, 0.0748, 0.3465, 0.1810],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:51,869][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ of] are: tensor([2.2662e-02, 9.1320e-02, 1.7151e-03, 1.0716e-01, 3.5500e-04, 6.5682e-02,
        2.3580e-01, 7.2130e-03, 4.6809e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:51,870][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.1801, 0.0153, 0.2831, 0.0135, 0.2694, 0.0351, 0.0142, 0.1796, 0.0096],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:51,871][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0526, 0.0255, 0.0309, 0.0532, 0.0753, 0.1053, 0.1782, 0.2645, 0.2146],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:51,872][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0229, 0.1175, 0.0078, 0.1836, 0.0134, 0.1237, 0.3533, 0.0215, 0.1564],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:51,873][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.2034, 0.1328, 0.0667, 0.1360, 0.0634, 0.0852, 0.1109, 0.0793, 0.1222],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:51,875][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.1695, 0.1571, 0.0429, 0.1486, 0.0313, 0.0767, 0.0912, 0.0593, 0.2234],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:51,877][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.2344, 0.1019, 0.1310, 0.1202, 0.1321, 0.0701, 0.0756, 0.0899, 0.0449],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:51,878][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.2559, 0.1032, 0.0899, 0.0947, 0.0769, 0.0361, 0.0905, 0.1004, 0.0557,
        0.0968], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:51,879][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([1.4083e-04, 4.5706e-05, 1.1641e-03, 3.7499e-05, 5.6543e-04, 2.0416e-05,
        1.1342e-03, 8.8447e-04, 1.7972e-05, 9.9599e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:51,881][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.2002, 0.0695, 0.0669, 0.1109, 0.0817, 0.1008, 0.0925, 0.0746, 0.1023,
        0.1004], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:51,883][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([4.4572e-04, 8.2957e-06, 1.8244e-05, 8.7099e-06, 1.8946e-04, 2.8326e-04,
        2.2890e-04, 1.8480e-03, 2.9444e-04, 9.9667e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:51,885][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0122, 0.0021, 0.0018, 0.0024, 0.0097, 0.0103, 0.0108, 0.0138, 0.0095,
        0.9274], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:51,886][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([4.2284e-03, 2.8178e-05, 2.2331e-05, 3.7845e-06, 5.5600e-05, 4.2784e-07,
        1.7979e-06, 1.4492e-04, 2.7548e-07, 9.9551e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:51,887][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.1240, 0.0263, 0.2245, 0.0205, 0.3717, 0.0172, 0.0187, 0.0818, 0.0223,
        0.0930], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:51,887][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0925, 0.0231, 0.0118, 0.0497, 0.0370, 0.0687, 0.1371, 0.1930, 0.2594,
        0.1277], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:51,888][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.1243, 0.1148, 0.0229, 0.1704, 0.0830, 0.1005, 0.1879, 0.0616, 0.0990,
        0.0357], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:51,889][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.1863, 0.1138, 0.0707, 0.1087, 0.1121, 0.0818, 0.0938, 0.0759, 0.1004,
        0.0566], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:51,890][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.1330, 0.1036, 0.0508, 0.1006, 0.0422, 0.0569, 0.0836, 0.0873, 0.0723,
        0.2696], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:51,892][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.2946, 0.1467, 0.0730, 0.1094, 0.0902, 0.0667, 0.0616, 0.0434, 0.0513,
        0.0631], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:51,894][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.2146, 0.0303, 0.1062, 0.0280, 0.2019, 0.0394, 0.0439, 0.1159, 0.0274,
        0.1717, 0.0207], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:51,895][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ at] are: tensor([7.4855e-04, 1.5244e-03, 6.5891e-04, 3.7636e-03, 4.1951e-04, 1.5068e-04,
        1.4837e-03, 3.0369e-05, 4.3012e-03, 3.3086e-05, 9.8689e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:51,897][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.2040, 0.1053, 0.0231, 0.1245, 0.0306, 0.0824, 0.0462, 0.0651, 0.1205,
        0.0821, 0.1166], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:51,898][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ at] are: tensor([1.0219e-03, 3.5258e-04, 2.2364e-04, 6.9208e-04, 5.1294e-04, 4.8590e-03,
        7.4731e-03, 3.9649e-03, 2.9989e-02, 1.3045e-01, 8.2046e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:51,900][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0612, 0.0063, 0.0069, 0.0094, 0.0228, 0.0575, 0.0338, 0.0463, 0.0699,
        0.3739, 0.3120], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:51,901][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ at] are: tensor([5.4709e-02, 2.3164e-02, 1.4911e-03, 9.6831e-03, 6.0424e-04, 3.6417e-02,
        1.6098e-02, 1.2104e-03, 3.8711e-03, 9.3882e-04, 8.5181e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:51,903][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1176, 0.0090, 0.3278, 0.0088, 0.2349, 0.0288, 0.0113, 0.1248, 0.0086,
        0.1145, 0.0140], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:51,904][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0367, 0.0125, 0.0077, 0.0282, 0.0180, 0.0469, 0.0823, 0.1102, 0.1269,
        0.1938, 0.3367], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:51,905][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0240, 0.1163, 0.0069, 0.2108, 0.0085, 0.1121, 0.1974, 0.0245, 0.1665,
        0.0261, 0.1068], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:51,906][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1505, 0.1050, 0.0575, 0.1137, 0.0480, 0.0787, 0.0909, 0.0699, 0.1095,
        0.0730, 0.1033], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:51,907][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1426, 0.1103, 0.0479, 0.1135, 0.0381, 0.0827, 0.0956, 0.0344, 0.0916,
        0.0301, 0.2131], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:51,908][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.2369, 0.0812, 0.0866, 0.0843, 0.1082, 0.0503, 0.0439, 0.0793, 0.0442,
        0.0769, 0.1082], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:51,909][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.3391, 0.0287, 0.1321, 0.0186, 0.1801, 0.0375, 0.0165, 0.0731, 0.0165,
        0.1201, 0.0177, 0.0201], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:51,910][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ the] are: tensor([2.9740e-03, 1.8203e-02, 6.4810e-04, 3.9227e-02, 2.7777e-04, 2.7141e-04,
        3.3086e-02, 8.6405e-05, 6.8727e-02, 7.4362e-05, 4.1100e-02, 7.9533e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:51,912][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1803, 0.0882, 0.0432, 0.0984, 0.0361, 0.0916, 0.0286, 0.0677, 0.1098,
        0.0610, 0.1661, 0.0291], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:51,914][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ the] are: tensor([1.0770e-02, 1.6530e-03, 6.0352e-04, 1.8825e-03, 1.3241e-03, 7.3225e-03,
        1.8892e-02, 1.2114e-02, 6.1538e-02, 5.5854e-02, 1.8256e-01, 6.4549e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:51,915][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1113, 0.0124, 0.0101, 0.0164, 0.0229, 0.0778, 0.0333, 0.0502, 0.0980,
        0.1411, 0.2313, 0.1951], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:51,917][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0659, 0.1033, 0.0159, 0.0845, 0.0057, 0.0632, 0.2072, 0.0503, 0.0543,
        0.0112, 0.0579, 0.2807], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:51,919][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1399, 0.0023, 0.2831, 0.0022, 0.2823, 0.0135, 0.0026, 0.1179, 0.0019,
        0.1477, 0.0050, 0.0015], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:51,921][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0380, 0.0089, 0.0074, 0.0176, 0.0239, 0.0229, 0.0365, 0.0573, 0.0943,
        0.0968, 0.2926, 0.3038], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:51,922][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0084, 0.0713, 0.0037, 0.1147, 0.0057, 0.0747, 0.2406, 0.0078, 0.0764,
        0.0135, 0.0511, 0.3321], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:51,923][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1656, 0.0935, 0.0598, 0.0970, 0.0549, 0.0680, 0.0775, 0.0634, 0.0901,
        0.0489, 0.0913, 0.0900], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:51,924][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1721, 0.1053, 0.0671, 0.1050, 0.0343, 0.0536, 0.1102, 0.0409, 0.0631,
        0.0296, 0.0725, 0.1462], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:51,925][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1792, 0.0721, 0.1049, 0.0756, 0.1177, 0.0468, 0.0782, 0.0689, 0.0286,
        0.0716, 0.0713, 0.0850], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:51,926][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.1943, 0.0863, 0.1377, 0.0781, 0.0528, 0.0552, 0.0815, 0.0488, 0.0672,
        0.0349, 0.0605, 0.0808, 0.0219], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:51,927][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ store] are: tensor([9.7041e-04, 2.2543e-03, 4.8561e-04, 1.7693e-03, 1.3675e-02, 1.1568e-03,
        3.9457e-04, 3.0706e-03, 5.0883e-04, 1.2820e-03, 5.8282e-04, 9.7572e-04,
        9.7287e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:51,929][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.1321, 0.0454, 0.1066, 0.0396, 0.2326, 0.0686, 0.0401, 0.0463, 0.0589,
        0.0792, 0.0610, 0.0451, 0.0444], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:51,930][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ store] are: tensor([2.6440e-04, 6.7578e-07, 2.0718e-06, 1.7832e-06, 3.3477e-05, 9.9483e-06,
        1.4848e-05, 9.9428e-04, 1.7501e-04, 3.6772e-03, 4.1684e-04, 3.5970e-04,
        9.9405e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:51,932][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0327, 0.0020, 0.0206, 0.0034, 0.0089, 0.0025, 0.0020, 0.0206, 0.0141,
        0.0283, 0.0304, 0.0249, 0.8094], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:51,933][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ store] are: tensor([1.1136e-02, 3.7554e-05, 5.1963e-05, 6.5100e-06, 1.4350e-03, 3.0149e-05,
        3.1729e-06, 1.7069e-04, 2.1932e-06, 2.0873e-05, 2.1581e-06, 1.7134e-06,
        9.8710e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:51,935][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.1562, 0.0321, 0.2871, 0.0201, 0.1577, 0.0125, 0.0140, 0.0368, 0.0139,
        0.1448, 0.0100, 0.0132, 0.1018], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:51,937][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0376, 0.0065, 0.0035, 0.0187, 0.0146, 0.0243, 0.0391, 0.0694, 0.0822,
        0.1350, 0.2068, 0.2687, 0.0936], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:51,939][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.1327, 0.0894, 0.0528, 0.1043, 0.0299, 0.0677, 0.0579, 0.0588, 0.0717,
        0.0929, 0.0996, 0.0925, 0.0499], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:51,940][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.1689, 0.0885, 0.0769, 0.0832, 0.0887, 0.0573, 0.0746, 0.0519, 0.0702,
        0.0729, 0.0696, 0.0812, 0.0161], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:51,941][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.1144, 0.0797, 0.0355, 0.0831, 0.0579, 0.0569, 0.0686, 0.0515, 0.0604,
        0.0299, 0.0564, 0.0642, 0.2415], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:51,942][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.2332, 0.0859, 0.0739, 0.0587, 0.0976, 0.0403, 0.0273, 0.0770, 0.0575,
        0.0716, 0.0904, 0.0246, 0.0621], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:51,943][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.3733, 0.0117, 0.0957, 0.0097, 0.1819, 0.0406, 0.0183, 0.0659, 0.0075,
        0.0908, 0.0142, 0.0311, 0.0508, 0.0084], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:51,943][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [.] are: tensor([2.9647e-03, 2.9750e-02, 1.1180e-03, 5.5077e-03, 3.1093e-04, 1.1785e-04,
        2.6002e-04, 2.2055e-04, 2.5112e-03, 7.6601e-05, 1.1364e-03, 2.5216e-04,
        4.5360e-05, 9.5573e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:51,945][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.3457, 0.0441, 0.0183, 0.0378, 0.0441, 0.1935, 0.0175, 0.0467, 0.0832,
        0.0369, 0.0514, 0.0215, 0.0146, 0.0448], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:51,946][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [.] are: tensor([1.3363e-02, 1.5887e-03, 5.0058e-04, 1.5393e-03, 2.5579e-03, 4.8000e-03,
        5.1745e-03, 2.1026e-02, 2.0132e-02, 2.1387e-02, 6.9185e-02, 1.8793e-01,
        1.3895e-01, 5.1187e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:51,948][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0273, 0.0092, 0.0079, 0.0176, 0.0070, 0.0191, 0.0163, 0.0403, 0.0538,
        0.0610, 0.1245, 0.1065, 0.2124, 0.2969], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:51,950][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1045, 0.1663, 0.0174, 0.1065, 0.0089, 0.0737, 0.0800, 0.0335, 0.0526,
        0.0111, 0.0555, 0.0644, 0.0117, 0.2140], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:51,952][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.1924, 0.0049, 0.2086, 0.0037, 0.2190, 0.0101, 0.0049, 0.0748, 0.0030,
        0.1579, 0.0064, 0.0032, 0.1087, 0.0024], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:51,954][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0177, 0.0043, 0.0063, 0.0079, 0.0129, 0.0119, 0.0181, 0.0296, 0.0308,
        0.0654, 0.0919, 0.1420, 0.1667, 0.3946], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:51,955][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0143, 0.1268, 0.0046, 0.1010, 0.0062, 0.0225, 0.0845, 0.0064, 0.0606,
        0.0048, 0.0400, 0.1367, 0.0071, 0.3845], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:51,957][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1434, 0.0801, 0.0573, 0.0833, 0.0507, 0.0636, 0.0641, 0.0605, 0.0671,
        0.0599, 0.0703, 0.0723, 0.0392, 0.0882], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:51,958][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1073, 0.0906, 0.0510, 0.0975, 0.0361, 0.0737, 0.0604, 0.0634, 0.0756,
        0.0531, 0.0747, 0.0607, 0.0285, 0.1275], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:51,959][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.2022, 0.0705, 0.0825, 0.0669, 0.0958, 0.0472, 0.0409, 0.0652, 0.0333,
        0.0595, 0.0704, 0.0317, 0.0463, 0.0876], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:51,960][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0965, 0.1166, 0.0374, 0.0995, 0.0623, 0.0147, 0.0667, 0.0074, 0.0715,
        0.0443, 0.0732, 0.0841, 0.0204, 0.1390, 0.0665], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:51,961][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([1.8225e-05, 2.6976e-05, 5.4758e-05, 1.8969e-05, 5.2330e-01, 4.5818e-06,
        1.7183e-05, 3.5984e-05, 9.3235e-06, 8.4012e-05, 4.7581e-05, 9.9723e-06,
        1.8365e-05, 2.4500e-06, 4.7635e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:51,962][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.1118, 0.0622, 0.0299, 0.0488, 0.0944, 0.0634, 0.0512, 0.0605, 0.0524,
        0.0579, 0.0405, 0.0651, 0.1264, 0.0429, 0.0927], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:51,963][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([1.2267e-04, 1.3867e-07, 1.6828e-05, 1.0593e-07, 2.1185e-03, 1.1778e-06,
        3.2443e-06, 3.8264e-06, 6.9712e-06, 4.8862e-05, 2.5009e-05, 3.8677e-05,
        2.9094e-03, 3.2940e-05, 9.9467e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:51,965][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([4.1715e-03, 5.1256e-04, 9.5182e-03, 4.7037e-04, 5.7458e-02, 3.9188e-04,
        5.1781e-04, 1.9184e-03, 2.2363e-03, 2.6111e-03, 4.9992e-03, 1.9813e-03,
        5.3285e-03, 1.3157e-02, 8.9473e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:51,966][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([1.7194e-03, 5.9628e-08, 1.0485e-05, 1.6551e-08, 6.2374e-01, 1.4751e-07,
        2.8126e-09, 9.3418e-07, 1.1093e-09, 1.6139e-06, 5.5931e-09, 8.6667e-10,
        1.8638e-05, 5.3544e-10, 3.7451e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:51,968][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.1081, 0.1310, 0.1481, 0.0987, 0.0531, 0.0198, 0.0591, 0.0241, 0.0585,
        0.0304, 0.0165, 0.0842, 0.0307, 0.0864, 0.0511], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:51,970][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0436, 0.0179, 0.0037, 0.0176, 0.0023, 0.0198, 0.0368, 0.0238, 0.0618,
        0.0828, 0.1536, 0.1356, 0.0157, 0.3524, 0.0324], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:51,972][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.0866, 0.0516, 0.0472, 0.0511, 0.1800, 0.0273, 0.0339, 0.0178, 0.0370,
        0.0149, 0.0293, 0.0370, 0.1177, 0.0535, 0.2151], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:51,973][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.1635, 0.0925, 0.1071, 0.0813, 0.0163, 0.0459, 0.0551, 0.0391, 0.0661,
        0.0506, 0.0544, 0.0695, 0.0627, 0.0794, 0.0166], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:51,975][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0904, 0.0615, 0.0425, 0.0555, 0.2420, 0.0357, 0.0405, 0.0306, 0.0405,
        0.0204, 0.0367, 0.0346, 0.0200, 0.0404, 0.2086], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:51,976][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0497, 0.0638, 0.0466, 0.0618, 0.0649, 0.0744, 0.0775, 0.0498, 0.0380,
        0.0730, 0.0962, 0.0733, 0.0469, 0.0856, 0.0987], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:51,977][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1917, 0.0189, 0.0444, 0.0227, 0.0906, 0.0941, 0.0180, 0.0457, 0.0221,
        0.0366, 0.0181, 0.0168, 0.0358, 0.0151, 0.1226, 0.2069],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:51,978][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([3.7454e-04, 5.8148e-04, 1.1424e-04, 1.2644e-03, 9.8878e-04, 6.5288e-03,
        1.4100e-04, 3.2796e-04, 7.6469e-04, 1.2313e-04, 3.5742e-04, 1.7551e-04,
        5.8502e-04, 5.0805e-05, 7.9566e-04, 9.8683e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:51,979][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1634, 0.0409, 0.0227, 0.0494, 0.0557, 0.0735, 0.0424, 0.0553, 0.0705,
        0.0620, 0.0696, 0.0522, 0.0411, 0.0693, 0.0589, 0.0732],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:51,980][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([8.5768e-04, 4.5951e-06, 9.5571e-07, 3.9920e-06, 3.0715e-06, 4.5515e-05,
        1.1785e-05, 3.8587e-05, 4.7093e-05, 2.9191e-04, 1.4097e-04, 2.0626e-04,
        2.0627e-03, 6.5130e-04, 7.5470e-04, 9.9488e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:51,982][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0840, 0.0065, 0.0016, 0.0065, 0.0076, 0.0108, 0.0076, 0.0102, 0.0191,
        0.0229, 0.0398, 0.0217, 0.0287, 0.0434, 0.0715, 0.6180],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:51,983][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([3.9521e-02, 2.1603e-05, 2.1566e-05, 2.1865e-05, 3.2734e-04, 1.8032e-03,
        1.2763e-05, 7.0386e-06, 5.9613e-06, 5.3239e-05, 1.5028e-05, 7.0771e-06,
        6.4618e-05, 1.0702e-06, 1.3195e-04, 9.5798e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:51,985][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0964, 0.0121, 0.1694, 0.0118, 0.1141, 0.0144, 0.0172, 0.0776, 0.0089,
        0.1488, 0.0104, 0.0133, 0.0948, 0.0124, 0.1689, 0.0296],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:51,987][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0180, 0.0040, 0.0028, 0.0059, 0.0070, 0.0059, 0.0114, 0.0133, 0.0147,
        0.0232, 0.0539, 0.0742, 0.0687, 0.2968, 0.1842, 0.2159],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:51,989][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0702, 0.0693, 0.0162, 0.0878, 0.0293, 0.0380, 0.0999, 0.0343, 0.0773,
        0.0622, 0.0720, 0.1211, 0.0524, 0.0940, 0.0417, 0.0342],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:51,991][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1077, 0.0591, 0.0482, 0.0627, 0.0582, 0.0584, 0.0524, 0.0523, 0.0578,
        0.0711, 0.0524, 0.0564, 0.0473, 0.0849, 0.0734, 0.0576],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:51,993][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0782, 0.0551, 0.0365, 0.0622, 0.0398, 0.1036, 0.0506, 0.0302, 0.0534,
        0.0334, 0.0551, 0.0487, 0.0311, 0.0655, 0.0408, 0.2159],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:51,994][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.2058, 0.0726, 0.0484, 0.0868, 0.0695, 0.0382, 0.0348, 0.0439, 0.0368,
        0.0426, 0.0645, 0.0313, 0.0262, 0.0782, 0.0690, 0.0513],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:51,995][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1677, 0.0132, 0.0411, 0.0102, 0.1581, 0.0214, 0.0092, 0.0408, 0.0087,
        0.0705, 0.0086, 0.0162, 0.0632, 0.0121, 0.2575, 0.0873, 0.0141],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:51,996][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([4.3903e-04, 1.1429e-03, 8.8262e-04, 1.2513e-03, 1.1082e-04, 1.3488e-04,
        4.3303e-01, 1.8435e-04, 1.1683e-03, 9.9667e-04, 3.4102e-03, 1.4667e-02,
        5.5832e-05, 2.8395e-04, 8.1985e-05, 1.1743e-04, 5.4204e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:51,997][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0993, 0.0507, 0.0314, 0.0774, 0.0292, 0.0465, 0.0158, 0.0588, 0.0780,
        0.0439, 0.1182, 0.0184, 0.0277, 0.1645, 0.0345, 0.0880, 0.0177],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:51,998][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([3.5066e-03, 2.6647e-04, 3.5842e-05, 1.7059e-04, 2.1950e-04, 3.6693e-04,
        1.2778e-03, 5.4098e-04, 1.7042e-03, 1.7124e-03, 4.6548e-03, 1.9026e-02,
        9.5376e-03, 2.8241e-02, 3.5695e-02, 1.2901e-01, 7.6403e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,000][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0230, 0.0027, 0.0023, 0.0029, 0.0037, 0.0191, 0.0076, 0.0071, 0.0115,
        0.0266, 0.0251, 0.0192, 0.0301, 0.0223, 0.0436, 0.5572, 0.1960],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,001][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([1.6608e-02, 5.2913e-02, 2.3188e-03, 4.6432e-02, 7.8828e-04, 2.4849e-02,
        4.1652e-01, 3.8508e-03, 2.4928e-02, 4.2875e-03, 3.1525e-02, 1.0142e-01,
        2.2497e-03, 1.3194e-02, 3.0220e-04, 3.8632e-03, 2.5395e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,003][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0871, 0.0020, 0.1510, 0.0020, 0.1323, 0.0128, 0.0022, 0.0831, 0.0021,
        0.1053, 0.0044, 0.0017, 0.1157, 0.0018, 0.2354, 0.0577, 0.0033],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,005][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0138, 0.0025, 0.0019, 0.0039, 0.0040, 0.0035, 0.0040, 0.0073, 0.0095,
        0.0119, 0.0299, 0.0350, 0.0319, 0.1990, 0.1108, 0.2733, 0.2577],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,007][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0069, 0.0337, 0.0017, 0.0591, 0.0057, 0.0459, 0.1360, 0.0064, 0.0435,
        0.0111, 0.0353, 0.1946, 0.0085, 0.0996, 0.0099, 0.0233, 0.2787],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,009][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1058, 0.0648, 0.0446, 0.0713, 0.0411, 0.0479, 0.0557, 0.0470, 0.0658,
        0.0414, 0.0651, 0.0670, 0.0326, 0.0703, 0.0487, 0.0602, 0.0709],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,011][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0744, 0.0578, 0.0398, 0.0682, 0.0257, 0.0453, 0.1265, 0.0340, 0.0542,
        0.0388, 0.0698, 0.0817, 0.0287, 0.0551, 0.0250, 0.0361, 0.1389],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,012][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1639, 0.0615, 0.0651, 0.0587, 0.0686, 0.0399, 0.0450, 0.0520, 0.0257,
        0.0505, 0.0513, 0.0332, 0.0417, 0.0663, 0.0700, 0.0623, 0.0442],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,013][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.1525, 0.0451, 0.0736, 0.0392, 0.0366, 0.0286, 0.0347, 0.0367, 0.0292,
        0.0680, 0.0310, 0.0338, 0.0455, 0.0353, 0.0375, 0.0389, 0.0382, 0.1955],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,013][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([2.5556e-04, 7.6196e-05, 1.6659e-03, 8.9839e-05, 6.0892e-03, 5.4908e-05,
        1.1922e-05, 4.7159e-05, 2.8230e-05, 7.9375e-04, 1.7900e-04, 7.5806e-06,
        3.5905e-05, 9.9076e-06, 5.0270e-03, 8.3949e-05, 7.2865e-06, 9.8554e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,014][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.1226, 0.0396, 0.1402, 0.0352, 0.0282, 0.0356, 0.0560, 0.0698, 0.0426,
        0.0632, 0.0472, 0.0514, 0.0466, 0.0535, 0.0261, 0.0220, 0.0561, 0.0641],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,016][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([1.2550e-03, 1.6904e-06, 3.1941e-06, 8.5620e-07, 3.2769e-05, 5.5107e-06,
        1.2625e-06, 5.9942e-05, 4.4519e-06, 2.8688e-04, 1.5951e-05, 1.4198e-05,
        1.8697e-03, 8.8756e-05, 3.6162e-03, 1.2320e-02, 3.9935e-04, 9.8002e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,018][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0434, 0.0019, 0.0116, 0.0015, 0.0167, 0.0014, 0.0015, 0.0038, 0.0029,
        0.0091, 0.0035, 0.0053, 0.0772, 0.0048, 0.0851, 0.0186, 0.0130, 0.6988],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,019][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([4.0914e-03, 7.5850e-06, 5.3853e-06, 1.4037e-06, 1.1961e-04, 1.5256e-06,
        1.4008e-06, 4.5544e-06, 4.7759e-07, 4.1680e-05, 1.0412e-06, 2.3702e-07,
        1.3615e-05, 1.7012e-07, 4.3439e-05, 4.8786e-06, 4.6020e-07, 9.9566e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,021][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0847, 0.0294, 0.2163, 0.0218, 0.0921, 0.0084, 0.0146, 0.0418, 0.0135,
        0.0950, 0.0113, 0.0139, 0.0710, 0.0164, 0.1014, 0.0123, 0.0164, 0.1398],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,022][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0274, 0.0037, 0.0039, 0.0042, 0.0087, 0.0060, 0.0086, 0.0060, 0.0121,
        0.0163, 0.0317, 0.0369, 0.0290, 0.1409, 0.1166, 0.2232, 0.2809, 0.0441],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,025][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.1598, 0.0584, 0.0520, 0.0573, 0.0273, 0.0334, 0.0491, 0.0556, 0.0474,
        0.1010, 0.0406, 0.0470, 0.0553, 0.0317, 0.0275, 0.0465, 0.0533, 0.0568],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,027][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.1170, 0.0614, 0.0548, 0.0580, 0.0778, 0.0472, 0.0450, 0.0416, 0.0477,
        0.0470, 0.0398, 0.0465, 0.0356, 0.0651, 0.0884, 0.0543, 0.0524, 0.0202],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,029][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0779, 0.0497, 0.0478, 0.0589, 0.0532, 0.0453, 0.0412, 0.0331, 0.0526,
        0.0427, 0.0391, 0.0427, 0.0183, 0.0520, 0.0476, 0.0311, 0.0365, 0.2304],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,029][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.1029, 0.0485, 0.0599, 0.0412, 0.1010, 0.0378, 0.0295, 0.0526, 0.0280,
        0.0588, 0.0522, 0.0267, 0.0322, 0.0684, 0.1106, 0.0608, 0.0293, 0.0596],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,030][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1906, 0.0167, 0.0537, 0.0140, 0.0721, 0.0465, 0.0148, 0.0478, 0.0154,
        0.0528, 0.0142, 0.0223, 0.0539, 0.0154, 0.1115, 0.1246, 0.0241, 0.0961,
        0.0134], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,031][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.0635e-03, 8.9834e-03, 1.6801e-04, 2.6119e-02, 8.8814e-05, 2.3092e-04,
        1.0625e-03, 3.7210e-05, 2.5756e-02, 1.8238e-04, 1.4918e-02, 1.4071e-03,
        6.7684e-05, 6.9809e-03, 7.0778e-05, 6.6501e-04, 9.9148e-04, 5.0112e-05,
        9.0816e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,032][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1026, 0.0418, 0.0271, 0.0609, 0.0239, 0.0375, 0.0155, 0.0447, 0.0657,
        0.0347, 0.0897, 0.0184, 0.0213, 0.1843, 0.0267, 0.0526, 0.0173, 0.0119,
        0.1233], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,033][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.1969e-03, 6.3118e-05, 3.2363e-06, 3.0265e-05, 1.2502e-05, 7.2222e-05,
        1.0069e-04, 3.0033e-05, 3.9230e-04, 2.6341e-04, 5.9594e-04, 2.4214e-03,
        6.6703e-04, 4.3858e-03, 1.6522e-03, 2.5056e-01, 7.1211e-02, 2.1025e-02,
        6.4531e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,035][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0207, 0.0011, 0.0009, 0.0016, 0.0004, 0.0110, 0.0030, 0.0046, 0.0040,
        0.0265, 0.0104, 0.0077, 0.0103, 0.0126, 0.0039, 0.3712, 0.0833, 0.1512,
        0.2755], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,037][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.9784e-02, 4.3618e-02, 2.7868e-03, 5.8735e-02, 5.8584e-04, 2.5041e-02,
        1.8580e-01, 7.4838e-03, 3.9503e-02, 9.6101e-03, 1.6766e-02, 1.3573e-01,
        1.5209e-03, 1.6480e-02, 2.4084e-04, 4.8831e-03, 1.1487e-01, 3.4469e-04,
        3.0622e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,039][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0824, 0.0036, 0.0379, 0.0032, 0.0706, 0.0111, 0.0030, 0.0354, 0.0044,
        0.1007, 0.0160, 0.0025, 0.0557, 0.0044, 0.1321, 0.0535, 0.0049, 0.0884,
        0.2903], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,040][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0146, 0.0021, 0.0024, 0.0029, 0.0036, 0.0026, 0.0031, 0.0043, 0.0038,
        0.0111, 0.0110, 0.0183, 0.0196, 0.0912, 0.0715, 0.1206, 0.1587, 0.1831,
        0.2756], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,043][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0053, 0.0387, 0.0018, 0.0694, 0.0034, 0.0314, 0.0850, 0.0057, 0.0494,
        0.0058, 0.0337, 0.1518, 0.0064, 0.1172, 0.0056, 0.0174, 0.1673, 0.0131,
        0.1915], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,045][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0918, 0.0547, 0.0350, 0.0618, 0.0303, 0.0420, 0.0524, 0.0417, 0.0559,
        0.0444, 0.0560, 0.0601, 0.0294, 0.0630, 0.0356, 0.0552, 0.0673, 0.0394,
        0.0841], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,046][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0710, 0.0543, 0.0353, 0.0699, 0.0230, 0.0547, 0.0630, 0.0345, 0.0623,
        0.0398, 0.0628, 0.0629, 0.0261, 0.0672, 0.0236, 0.0549, 0.0700, 0.0268,
        0.0979], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,047][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1479, 0.0570, 0.0627, 0.0576, 0.0625, 0.0424, 0.0373, 0.0453, 0.0268,
        0.0444, 0.0537, 0.0267, 0.0345, 0.0572, 0.0609, 0.0592, 0.0347, 0.0357,
        0.0537], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,060][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:52,060][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,061][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,062][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,063][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,063][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,064][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,065][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,066][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,067][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,067][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,068][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,069][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,070][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,070][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,072][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,073][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,075][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,077][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,078][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,080][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,081][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,082][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,083][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,083][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,084][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Jamie] are: tensor([0.2713, 0.3216, 0.4071], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,085][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Jamie] are: tensor([3.1793e-05, 3.5104e-05, 9.9993e-01], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,086][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Jamie] are: tensor([0.5307, 0.2194, 0.2498], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,088][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Jamie] are: tensor([0.0069, 0.0011, 0.9920], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,089][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Jamie] are: tensor([0.0378, 0.0047, 0.9575], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,091][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Jamie] are: tensor([1.7690e-02, 2.4118e-06, 9.8231e-01], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,092][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Jamie] are: tensor([0.3911, 0.2796, 0.3293], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,094][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Jamie] are: tensor([0.4983, 0.3985, 0.1032], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,096][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Jamie] are: tensor([0.4405, 0.2743, 0.2852], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,098][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Jamie] are: tensor([0.6336, 0.3263, 0.0401], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,099][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Jamie] are: tensor([0.4429, 0.2461, 0.3110], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,100][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Jamie] are: tensor([0.3818, 0.3780, 0.2403], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,100][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6437, 0.0729, 0.2266, 0.0569], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,101][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0023, 0.0392, 0.0014, 0.9571], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,102][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2358, 0.1766, 0.0443, 0.5433], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,102][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1146, 0.3916, 0.0148, 0.4791], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,104][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3717, 0.1684, 0.1549, 0.3050], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,106][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1235, 0.1977, 0.0035, 0.6753], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,108][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5297, 0.0253, 0.4258, 0.0192], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,109][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2270, 0.1726, 0.3406, 0.2598], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,111][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0673, 0.4714, 0.0193, 0.4420], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,113][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4303, 0.2403, 0.1062, 0.2232], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,115][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4124, 0.3072, 0.0777, 0.2027], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,116][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4270, 0.1865, 0.1429, 0.2437], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,117][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.2093, 0.3278, 0.0828, 0.2633, 0.1168], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,117][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([3.8321e-05, 1.1486e-04, 2.3569e-04, 6.9513e-05, 9.9954e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,118][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.3532, 0.2296, 0.0770, 0.1384, 0.2018], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,119][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([4.4921e-03, 5.5093e-05, 9.2220e-03, 1.1051e-04, 9.8612e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,120][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0287, 0.0059, 0.1263, 0.0068, 0.8323], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,121][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([7.6686e-03, 3.7451e-07, 2.4998e-05, 9.4585e-08, 9.9231e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,122][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.2186, 0.2960, 0.2147, 0.1924, 0.0783], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,124][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.2325, 0.2814, 0.0704, 0.3682, 0.0475], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,126][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.2438, 0.1654, 0.1173, 0.1399, 0.3335], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,127][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.3833, 0.2168, 0.1900, 0.1798, 0.0302], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,129][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.3024, 0.2048, 0.0801, 0.1265, 0.2862], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,130][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.1816, 0.2345, 0.1451, 0.2582, 0.1806], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,132][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.3949, 0.0347, 0.1440, 0.0346, 0.0876, 0.3042], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,133][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([3.2204e-04, 1.6747e-03, 6.6930e-04, 2.8606e-03, 1.8513e-04, 9.9429e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,134][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.4917, 0.1254, 0.0353, 0.1483, 0.0524, 0.1469], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,135][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0049, 0.0054, 0.0013, 0.0115, 0.0019, 0.9749], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,135][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2251, 0.0640, 0.0427, 0.1159, 0.0742, 0.4781], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,136][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([3.9817e-02, 1.8581e-03, 2.0244e-04, 1.2918e-03, 2.8078e-04, 9.5655e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,137][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.2132, 0.0159, 0.4196, 0.0149, 0.3150, 0.0214], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,139][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1249, 0.0973, 0.0984, 0.2258, 0.1727, 0.2808], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,141][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0960, 0.2695, 0.0346, 0.3541, 0.0268, 0.2191], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,142][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3038, 0.1832, 0.1020, 0.1888, 0.0946, 0.1276], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,144][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2523, 0.1946, 0.0638, 0.1425, 0.0374, 0.3094], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,146][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.4105, 0.1371, 0.0988, 0.1710, 0.0963, 0.0864], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,148][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.3841, 0.0442, 0.1046, 0.0334, 0.3489, 0.0551, 0.0296],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,149][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([8.5377e-04, 4.2907e-03, 3.7406e-03, 4.2886e-03, 3.5781e-04, 4.6729e-04,
        9.8600e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,151][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2926, 0.1814, 0.0805, 0.2140, 0.0651, 0.1211, 0.0452],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,151][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0287, 0.0176, 0.0043, 0.0324, 0.0389, 0.1754, 0.7026],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,152][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1432, 0.0315, 0.0361, 0.0444, 0.0804, 0.4478, 0.2166],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,153][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0560, 0.1298, 0.0036, 0.0971, 0.0016, 0.0448, 0.6671],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,154][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2615, 0.0087, 0.3664, 0.0074, 0.3090, 0.0385, 0.0085],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,155][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0960, 0.0577, 0.0548, 0.1290, 0.1483, 0.2164, 0.2979],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,156][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0239, 0.1304, 0.0061, 0.1937, 0.0150, 0.1415, 0.4893],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,159][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2592, 0.1660, 0.0907, 0.1684, 0.0783, 0.1045, 0.1329],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,160][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2235, 0.1906, 0.0810, 0.1616, 0.0373, 0.0827, 0.2234],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,161][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3130, 0.1255, 0.1223, 0.1348, 0.1197, 0.0809, 0.1038],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,163][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.3346, 0.0740, 0.1229, 0.0782, 0.1474, 0.0698, 0.0827, 0.0904],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,164][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([2.6404e-04, 1.0258e-03, 1.9719e-03, 1.2059e-03, 2.3049e-03, 1.3640e-03,
        5.0203e-04, 9.9136e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,166][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.2921, 0.1129, 0.0502, 0.2019, 0.0778, 0.1500, 0.0779, 0.0373],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,167][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([1.0767e-03, 1.2856e-04, 2.0283e-05, 2.5209e-04, 7.9391e-04, 2.0034e-03,
        1.6734e-03, 9.9405e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,168][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0459, 0.0142, 0.0130, 0.0158, 0.0244, 0.0606, 0.0714, 0.7546],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,169][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([3.2516e-03, 1.1955e-04, 4.1709e-05, 1.7789e-05, 8.6875e-05, 9.6460e-06,
        5.2872e-06, 9.9647e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,170][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.2588, 0.0559, 0.1983, 0.0326, 0.1839, 0.0370, 0.0483, 0.1852],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,170][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0859, 0.0463, 0.0253, 0.0912, 0.1332, 0.1479, 0.2734, 0.1967],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,171][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.1173, 0.1425, 0.0238, 0.1317, 0.1063, 0.1074, 0.3191, 0.0520],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,173][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.2357, 0.1495, 0.1152, 0.1447, 0.0727, 0.0971, 0.1247, 0.0603],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,174][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.2072, 0.1489, 0.0486, 0.1230, 0.0502, 0.0830, 0.0828, 0.2563],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,176][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.4252, 0.0815, 0.1016, 0.0844, 0.1096, 0.0576, 0.0425, 0.0977],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,178][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.3142, 0.0494, 0.1293, 0.0355, 0.2135, 0.0648, 0.0432, 0.1226, 0.0275],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,179][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([8.9861e-04, 1.5859e-02, 1.4286e-04, 2.1562e-02, 7.5124e-05, 6.7594e-04,
        3.8732e-04, 9.5689e-05, 9.6030e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,181][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.3013, 0.1428, 0.0658, 0.1327, 0.0353, 0.0768, 0.0608, 0.0845, 0.0999],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,182][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([5.2298e-03, 3.0357e-03, 2.2093e-04, 7.0127e-03, 8.1627e-04, 4.5600e-02,
        6.1319e-02, 3.7489e-01, 5.0188e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,184][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.1606, 0.0219, 0.0232, 0.0261, 0.0505, 0.1155, 0.0748, 0.3465, 0.1810],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,185][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([2.2662e-02, 9.1320e-02, 1.7151e-03, 1.0716e-01, 3.5500e-04, 6.5682e-02,
        2.3580e-01, 7.2130e-03, 4.6809e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,186][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.1801, 0.0153, 0.2831, 0.0135, 0.2694, 0.0351, 0.0142, 0.1796, 0.0096],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,186][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0526, 0.0255, 0.0309, 0.0532, 0.0753, 0.1053, 0.1782, 0.2645, 0.2146],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,187][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0229, 0.1175, 0.0078, 0.1836, 0.0134, 0.1237, 0.3533, 0.0215, 0.1564],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,188][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.2034, 0.1328, 0.0667, 0.1360, 0.0634, 0.0852, 0.1109, 0.0793, 0.1222],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,189][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.1695, 0.1571, 0.0429, 0.1486, 0.0313, 0.0767, 0.0912, 0.0593, 0.2234],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,191][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.2344, 0.1019, 0.1310, 0.1202, 0.1321, 0.0701, 0.0756, 0.0899, 0.0449],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,193][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.2559, 0.1032, 0.0899, 0.0947, 0.0769, 0.0361, 0.0905, 0.1004, 0.0557,
        0.0968], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,194][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([1.4083e-04, 4.5706e-05, 1.1641e-03, 3.7499e-05, 5.6543e-04, 2.0416e-05,
        1.1342e-03, 8.8447e-04, 1.7972e-05, 9.9599e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,196][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.2002, 0.0695, 0.0669, 0.1109, 0.0817, 0.1008, 0.0925, 0.0746, 0.1023,
        0.1004], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,197][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([4.4572e-04, 8.2957e-06, 1.8244e-05, 8.7099e-06, 1.8946e-04, 2.8326e-04,
        2.2890e-04, 1.8480e-03, 2.9444e-04, 9.9667e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,199][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0122, 0.0021, 0.0018, 0.0024, 0.0097, 0.0103, 0.0108, 0.0138, 0.0095,
        0.9274], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,200][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([4.2284e-03, 2.8178e-05, 2.2331e-05, 3.7845e-06, 5.5600e-05, 4.2784e-07,
        1.7979e-06, 1.4492e-04, 2.7548e-07, 9.9551e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,202][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.1240, 0.0263, 0.2245, 0.0205, 0.3717, 0.0172, 0.0187, 0.0818, 0.0223,
        0.0930], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,203][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0925, 0.0231, 0.0118, 0.0497, 0.0370, 0.0687, 0.1371, 0.1930, 0.2594,
        0.1277], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,204][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.1243, 0.1148, 0.0229, 0.1704, 0.0830, 0.1005, 0.1879, 0.0616, 0.0990,
        0.0357], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,204][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.1863, 0.1138, 0.0707, 0.1087, 0.1121, 0.0818, 0.0938, 0.0759, 0.1004,
        0.0566], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,205][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.1330, 0.1036, 0.0508, 0.1006, 0.0422, 0.0569, 0.0836, 0.0873, 0.0723,
        0.2696], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,206][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.2946, 0.1467, 0.0730, 0.1094, 0.0902, 0.0667, 0.0616, 0.0434, 0.0513,
        0.0631], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,208][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.2146, 0.0303, 0.1062, 0.0280, 0.2019, 0.0394, 0.0439, 0.1159, 0.0274,
        0.1717, 0.0207], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,209][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([7.4855e-04, 1.5244e-03, 6.5891e-04, 3.7636e-03, 4.1951e-04, 1.5068e-04,
        1.4837e-03, 3.0369e-05, 4.3012e-03, 3.3086e-05, 9.8689e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,211][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.2040, 0.1053, 0.0231, 0.1245, 0.0306, 0.0824, 0.0462, 0.0651, 0.1205,
        0.0821, 0.1166], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,212][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([1.0219e-03, 3.5258e-04, 2.2364e-04, 6.9208e-04, 5.1294e-04, 4.8590e-03,
        7.4731e-03, 3.9649e-03, 2.9989e-02, 1.3045e-01, 8.2046e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,214][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0612, 0.0063, 0.0069, 0.0094, 0.0228, 0.0575, 0.0338, 0.0463, 0.0699,
        0.3739, 0.3120], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,215][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([5.4709e-02, 2.3164e-02, 1.4911e-03, 9.6831e-03, 6.0424e-04, 3.6417e-02,
        1.6098e-02, 1.2104e-03, 3.8711e-03, 9.3882e-04, 8.5181e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,217][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.1176, 0.0090, 0.3278, 0.0088, 0.2349, 0.0288, 0.0113, 0.1248, 0.0086,
        0.1145, 0.0140], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,219][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0367, 0.0125, 0.0077, 0.0282, 0.0180, 0.0469, 0.0823, 0.1102, 0.1269,
        0.1938, 0.3367], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,220][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0240, 0.1163, 0.0069, 0.2108, 0.0085, 0.1121, 0.1974, 0.0245, 0.1665,
        0.0261, 0.1068], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,221][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.1505, 0.1050, 0.0575, 0.1137, 0.0480, 0.0787, 0.0909, 0.0699, 0.1095,
        0.0730, 0.1033], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,221][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.1426, 0.1103, 0.0479, 0.1135, 0.0381, 0.0827, 0.0956, 0.0344, 0.0916,
        0.0301, 0.2131], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,222][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.2369, 0.0812, 0.0866, 0.0843, 0.1082, 0.0503, 0.0439, 0.0793, 0.0442,
        0.0769, 0.1082], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,223][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.3391, 0.0287, 0.1321, 0.0186, 0.1801, 0.0375, 0.0165, 0.0731, 0.0165,
        0.1201, 0.0177, 0.0201], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,224][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([2.9740e-03, 1.8203e-02, 6.4810e-04, 3.9227e-02, 2.7777e-04, 2.7141e-04,
        3.3086e-02, 8.6405e-05, 6.8727e-02, 7.4362e-05, 4.1100e-02, 7.9533e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,226][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1803, 0.0882, 0.0432, 0.0984, 0.0361, 0.0916, 0.0286, 0.0677, 0.1098,
        0.0610, 0.1661, 0.0291], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,227][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([1.0770e-02, 1.6530e-03, 6.0352e-04, 1.8825e-03, 1.3241e-03, 7.3225e-03,
        1.8892e-02, 1.2114e-02, 6.1538e-02, 5.5854e-02, 1.8256e-01, 6.4549e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,229][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1113, 0.0124, 0.0101, 0.0164, 0.0229, 0.0778, 0.0333, 0.0502, 0.0980,
        0.1411, 0.2313, 0.1951], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,231][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0659, 0.1033, 0.0159, 0.0845, 0.0057, 0.0632, 0.2072, 0.0503, 0.0543,
        0.0112, 0.0579, 0.2807], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,233][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1399, 0.0023, 0.2831, 0.0022, 0.2823, 0.0135, 0.0026, 0.1179, 0.0019,
        0.1477, 0.0050, 0.0015], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,235][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0380, 0.0089, 0.0074, 0.0176, 0.0239, 0.0229, 0.0365, 0.0573, 0.0943,
        0.0968, 0.2926, 0.3038], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,236][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0084, 0.0713, 0.0037, 0.1147, 0.0057, 0.0747, 0.2406, 0.0078, 0.0764,
        0.0135, 0.0511, 0.3321], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,237][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1656, 0.0935, 0.0598, 0.0970, 0.0549, 0.0680, 0.0775, 0.0634, 0.0901,
        0.0489, 0.0913, 0.0900], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,238][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1721, 0.1053, 0.0671, 0.1050, 0.0343, 0.0536, 0.1102, 0.0409, 0.0631,
        0.0296, 0.0725, 0.1462], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,239][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1792, 0.0721, 0.1049, 0.0756, 0.1177, 0.0468, 0.0782, 0.0689, 0.0286,
        0.0716, 0.0713, 0.0850], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,240][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.1943, 0.0863, 0.1377, 0.0781, 0.0528, 0.0552, 0.0815, 0.0488, 0.0672,
        0.0349, 0.0605, 0.0808, 0.0219], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,241][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([9.7041e-04, 2.2543e-03, 4.8561e-04, 1.7693e-03, 1.3675e-02, 1.1568e-03,
        3.9457e-04, 3.0706e-03, 5.0883e-04, 1.2820e-03, 5.8282e-04, 9.7572e-04,
        9.7287e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,243][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.1321, 0.0454, 0.1066, 0.0396, 0.2326, 0.0686, 0.0401, 0.0463, 0.0589,
        0.0792, 0.0610, 0.0451, 0.0444], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,244][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([2.6440e-04, 6.7578e-07, 2.0718e-06, 1.7832e-06, 3.3477e-05, 9.9483e-06,
        1.4848e-05, 9.9428e-04, 1.7501e-04, 3.6772e-03, 4.1684e-04, 3.5970e-04,
        9.9405e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,246][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0327, 0.0020, 0.0206, 0.0034, 0.0089, 0.0025, 0.0020, 0.0206, 0.0141,
        0.0283, 0.0304, 0.0249, 0.8094], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,247][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([1.1136e-02, 3.7554e-05, 5.1963e-05, 6.5100e-06, 1.4350e-03, 3.0149e-05,
        3.1729e-06, 1.7069e-04, 2.1932e-06, 2.0873e-05, 2.1581e-06, 1.7134e-06,
        9.8710e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,249][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.1562, 0.0321, 0.2871, 0.0201, 0.1577, 0.0125, 0.0140, 0.0368, 0.0139,
        0.1448, 0.0100, 0.0132, 0.1018], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,251][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0376, 0.0065, 0.0035, 0.0187, 0.0146, 0.0243, 0.0391, 0.0694, 0.0822,
        0.1350, 0.2068, 0.2687, 0.0936], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,253][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.1327, 0.0894, 0.0528, 0.1043, 0.0299, 0.0677, 0.0579, 0.0588, 0.0717,
        0.0929, 0.0996, 0.0925, 0.0499], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,254][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.1689, 0.0885, 0.0769, 0.0832, 0.0887, 0.0573, 0.0746, 0.0519, 0.0702,
        0.0729, 0.0696, 0.0812, 0.0161], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,255][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.1144, 0.0797, 0.0355, 0.0831, 0.0579, 0.0569, 0.0686, 0.0515, 0.0604,
        0.0299, 0.0564, 0.0642, 0.2415], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,256][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.2332, 0.0859, 0.0739, 0.0587, 0.0976, 0.0403, 0.0273, 0.0770, 0.0575,
        0.0716, 0.0904, 0.0246, 0.0621], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,257][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.3733, 0.0117, 0.0957, 0.0097, 0.1819, 0.0406, 0.0183, 0.0659, 0.0075,
        0.0908, 0.0142, 0.0311, 0.0508, 0.0084], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,258][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([2.9647e-03, 2.9750e-02, 1.1180e-03, 5.5077e-03, 3.1093e-04, 1.1785e-04,
        2.6002e-04, 2.2055e-04, 2.5112e-03, 7.6601e-05, 1.1364e-03, 2.5216e-04,
        4.5360e-05, 9.5573e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,260][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.3457, 0.0441, 0.0183, 0.0378, 0.0441, 0.1935, 0.0175, 0.0467, 0.0832,
        0.0369, 0.0514, 0.0215, 0.0146, 0.0448], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,261][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([1.3363e-02, 1.5887e-03, 5.0058e-04, 1.5393e-03, 2.5579e-03, 4.8000e-03,
        5.1745e-03, 2.1026e-02, 2.0132e-02, 2.1387e-02, 6.9185e-02, 1.8793e-01,
        1.3895e-01, 5.1187e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,263][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0273, 0.0092, 0.0079, 0.0176, 0.0070, 0.0191, 0.0163, 0.0403, 0.0538,
        0.0610, 0.1245, 0.1065, 0.2124, 0.2969], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,265][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1045, 0.1663, 0.0174, 0.1065, 0.0089, 0.0737, 0.0800, 0.0335, 0.0526,
        0.0111, 0.0555, 0.0644, 0.0117, 0.2140], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,267][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.1924, 0.0049, 0.2086, 0.0037, 0.2190, 0.0101, 0.0049, 0.0748, 0.0030,
        0.1579, 0.0064, 0.0032, 0.1087, 0.0024], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,269][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0177, 0.0043, 0.0063, 0.0079, 0.0129, 0.0119, 0.0181, 0.0296, 0.0308,
        0.0654, 0.0919, 0.1420, 0.1667, 0.3946], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,270][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0143, 0.1268, 0.0046, 0.1010, 0.0062, 0.0225, 0.0845, 0.0064, 0.0606,
        0.0048, 0.0400, 0.1367, 0.0071, 0.3845], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,272][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.1434, 0.0801, 0.0573, 0.0833, 0.0507, 0.0636, 0.0641, 0.0605, 0.0671,
        0.0599, 0.0703, 0.0723, 0.0392, 0.0882], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,272][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1073, 0.0906, 0.0510, 0.0975, 0.0361, 0.0737, 0.0604, 0.0634, 0.0756,
        0.0531, 0.0747, 0.0607, 0.0285, 0.1275], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,273][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.2022, 0.0705, 0.0825, 0.0669, 0.0958, 0.0472, 0.0409, 0.0652, 0.0333,
        0.0595, 0.0704, 0.0317, 0.0463, 0.0876], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,274][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0965, 0.1166, 0.0374, 0.0995, 0.0623, 0.0147, 0.0667, 0.0074, 0.0715,
        0.0443, 0.0732, 0.0841, 0.0204, 0.1390, 0.0665], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,275][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([1.8225e-05, 2.6976e-05, 5.4758e-05, 1.8969e-05, 5.2330e-01, 4.5818e-06,
        1.7183e-05, 3.5984e-05, 9.3235e-06, 8.4012e-05, 4.7581e-05, 9.9723e-06,
        1.8365e-05, 2.4500e-06, 4.7635e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,277][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.1118, 0.0622, 0.0299, 0.0488, 0.0944, 0.0634, 0.0512, 0.0605, 0.0524,
        0.0579, 0.0405, 0.0651, 0.1264, 0.0429, 0.0927], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,279][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([1.2267e-04, 1.3867e-07, 1.6828e-05, 1.0593e-07, 2.1185e-03, 1.1778e-06,
        3.2443e-06, 3.8264e-06, 6.9712e-06, 4.8862e-05, 2.5009e-05, 3.8677e-05,
        2.9094e-03, 3.2940e-05, 9.9467e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,280][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([4.1715e-03, 5.1256e-04, 9.5182e-03, 4.7037e-04, 5.7458e-02, 3.9188e-04,
        5.1781e-04, 1.9184e-03, 2.2363e-03, 2.6111e-03, 4.9992e-03, 1.9813e-03,
        5.3285e-03, 1.3157e-02, 8.9473e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,281][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([1.7194e-03, 5.9628e-08, 1.0485e-05, 1.6551e-08, 6.2374e-01, 1.4751e-07,
        2.8126e-09, 9.3418e-07, 1.1093e-09, 1.6139e-06, 5.5931e-09, 8.6667e-10,
        1.8638e-05, 5.3544e-10, 3.7451e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,283][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.1081, 0.1310, 0.1481, 0.0987, 0.0531, 0.0198, 0.0591, 0.0241, 0.0585,
        0.0304, 0.0165, 0.0842, 0.0307, 0.0864, 0.0511], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,285][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0436, 0.0179, 0.0037, 0.0176, 0.0023, 0.0198, 0.0368, 0.0238, 0.0618,
        0.0828, 0.1536, 0.1356, 0.0157, 0.3524, 0.0324], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,287][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.0866, 0.0516, 0.0472, 0.0511, 0.1800, 0.0273, 0.0339, 0.0178, 0.0370,
        0.0149, 0.0293, 0.0370, 0.1177, 0.0535, 0.2151], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,289][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.1635, 0.0925, 0.1071, 0.0813, 0.0163, 0.0459, 0.0551, 0.0391, 0.0661,
        0.0506, 0.0544, 0.0695, 0.0627, 0.0794, 0.0166], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,291][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0904, 0.0615, 0.0425, 0.0555, 0.2420, 0.0357, 0.0405, 0.0306, 0.0405,
        0.0204, 0.0367, 0.0346, 0.0200, 0.0404, 0.2086], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,293][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0497, 0.0638, 0.0466, 0.0618, 0.0649, 0.0744, 0.0775, 0.0498, 0.0380,
        0.0730, 0.0962, 0.0733, 0.0469, 0.0856, 0.0987], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,294][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.1917, 0.0189, 0.0444, 0.0227, 0.0906, 0.0941, 0.0180, 0.0457, 0.0221,
        0.0366, 0.0181, 0.0168, 0.0358, 0.0151, 0.1226, 0.2069],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,295][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([3.7454e-04, 5.8148e-04, 1.1424e-04, 1.2644e-03, 9.8878e-04, 6.5288e-03,
        1.4100e-04, 3.2796e-04, 7.6469e-04, 1.2313e-04, 3.5742e-04, 1.7551e-04,
        5.8502e-04, 5.0805e-05, 7.9566e-04, 9.8683e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,296][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1634, 0.0409, 0.0227, 0.0494, 0.0557, 0.0735, 0.0424, 0.0553, 0.0705,
        0.0620, 0.0696, 0.0522, 0.0411, 0.0693, 0.0589, 0.0732],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,296][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([8.5768e-04, 4.5951e-06, 9.5571e-07, 3.9920e-06, 3.0715e-06, 4.5515e-05,
        1.1785e-05, 3.8587e-05, 4.7093e-05, 2.9191e-04, 1.4097e-04, 2.0626e-04,
        2.0627e-03, 6.5130e-04, 7.5470e-04, 9.9488e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,297][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0840, 0.0065, 0.0016, 0.0065, 0.0076, 0.0108, 0.0076, 0.0102, 0.0191,
        0.0229, 0.0398, 0.0217, 0.0287, 0.0434, 0.0715, 0.6180],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,299][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([3.9521e-02, 2.1603e-05, 2.1566e-05, 2.1865e-05, 3.2734e-04, 1.8032e-03,
        1.2763e-05, 7.0386e-06, 5.9613e-06, 5.3239e-05, 1.5028e-05, 7.0771e-06,
        6.4618e-05, 1.0702e-06, 1.3195e-04, 9.5798e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,301][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0964, 0.0121, 0.1694, 0.0118, 0.1141, 0.0144, 0.0172, 0.0776, 0.0089,
        0.1488, 0.0104, 0.0133, 0.0948, 0.0124, 0.1689, 0.0296],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,303][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0180, 0.0040, 0.0028, 0.0059, 0.0070, 0.0059, 0.0114, 0.0133, 0.0147,
        0.0232, 0.0539, 0.0742, 0.0687, 0.2968, 0.1842, 0.2159],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,304][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0702, 0.0693, 0.0162, 0.0878, 0.0293, 0.0380, 0.0999, 0.0343, 0.0773,
        0.0622, 0.0720, 0.1211, 0.0524, 0.0940, 0.0417, 0.0342],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,306][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1077, 0.0591, 0.0482, 0.0627, 0.0582, 0.0584, 0.0524, 0.0523, 0.0578,
        0.0711, 0.0524, 0.0564, 0.0473, 0.0849, 0.0734, 0.0576],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,308][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0782, 0.0551, 0.0365, 0.0622, 0.0398, 0.1036, 0.0506, 0.0302, 0.0534,
        0.0334, 0.0551, 0.0487, 0.0311, 0.0655, 0.0408, 0.2159],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,310][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.2058, 0.0726, 0.0484, 0.0868, 0.0695, 0.0382, 0.0348, 0.0439, 0.0368,
        0.0426, 0.0645, 0.0313, 0.0262, 0.0782, 0.0690, 0.0513],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,311][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1677, 0.0132, 0.0411, 0.0102, 0.1581, 0.0214, 0.0092, 0.0408, 0.0087,
        0.0705, 0.0086, 0.0162, 0.0632, 0.0121, 0.2575, 0.0873, 0.0141],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,312][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([4.3903e-04, 1.1429e-03, 8.8262e-04, 1.2513e-03, 1.1082e-04, 1.3488e-04,
        4.3303e-01, 1.8435e-04, 1.1683e-03, 9.9667e-04, 3.4102e-03, 1.4667e-02,
        5.5832e-05, 2.8395e-04, 8.1985e-05, 1.1743e-04, 5.4204e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,313][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0993, 0.0507, 0.0314, 0.0774, 0.0292, 0.0465, 0.0158, 0.0588, 0.0780,
        0.0439, 0.1182, 0.0184, 0.0277, 0.1645, 0.0345, 0.0880, 0.0177],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,314][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([3.5066e-03, 2.6647e-04, 3.5842e-05, 1.7059e-04, 2.1950e-04, 3.6693e-04,
        1.2778e-03, 5.4098e-04, 1.7042e-03, 1.7124e-03, 4.6548e-03, 1.9026e-02,
        9.5376e-03, 2.8241e-02, 3.5695e-02, 1.2901e-01, 7.6403e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,315][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0230, 0.0027, 0.0023, 0.0029, 0.0037, 0.0191, 0.0076, 0.0071, 0.0115,
        0.0266, 0.0251, 0.0192, 0.0301, 0.0223, 0.0436, 0.5572, 0.1960],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,316][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.6608e-02, 5.2913e-02, 2.3188e-03, 4.6432e-02, 7.8828e-04, 2.4849e-02,
        4.1652e-01, 3.8508e-03, 2.4928e-02, 4.2875e-03, 3.1525e-02, 1.0142e-01,
        2.2497e-03, 1.3194e-02, 3.0220e-04, 3.8632e-03, 2.5395e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,318][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0871, 0.0020, 0.1510, 0.0020, 0.1323, 0.0128, 0.0022, 0.0831, 0.0021,
        0.1053, 0.0044, 0.0017, 0.1157, 0.0018, 0.2354, 0.0577, 0.0033],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,320][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0138, 0.0025, 0.0019, 0.0039, 0.0040, 0.0035, 0.0040, 0.0073, 0.0095,
        0.0119, 0.0299, 0.0350, 0.0319, 0.1990, 0.1108, 0.2733, 0.2577],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,322][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0069, 0.0337, 0.0017, 0.0591, 0.0057, 0.0459, 0.1360, 0.0064, 0.0435,
        0.0111, 0.0353, 0.1946, 0.0085, 0.0996, 0.0099, 0.0233, 0.2787],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,323][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1058, 0.0648, 0.0446, 0.0713, 0.0411, 0.0479, 0.0557, 0.0470, 0.0658,
        0.0414, 0.0651, 0.0670, 0.0326, 0.0703, 0.0487, 0.0602, 0.0709],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,324][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0744, 0.0578, 0.0398, 0.0682, 0.0257, 0.0453, 0.1265, 0.0340, 0.0542,
        0.0388, 0.0698, 0.0817, 0.0287, 0.0551, 0.0250, 0.0361, 0.1389],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,325][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1639, 0.0615, 0.0651, 0.0587, 0.0686, 0.0399, 0.0450, 0.0520, 0.0257,
        0.0505, 0.0513, 0.0332, 0.0417, 0.0663, 0.0700, 0.0623, 0.0442],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,326][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.1525, 0.0451, 0.0736, 0.0392, 0.0366, 0.0286, 0.0347, 0.0367, 0.0292,
        0.0680, 0.0310, 0.0338, 0.0455, 0.0353, 0.0375, 0.0389, 0.0382, 0.1955],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,328][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([2.5556e-04, 7.6196e-05, 1.6659e-03, 8.9839e-05, 6.0892e-03, 5.4908e-05,
        1.1922e-05, 4.7159e-05, 2.8230e-05, 7.9375e-04, 1.7900e-04, 7.5806e-06,
        3.5905e-05, 9.9076e-06, 5.0270e-03, 8.3949e-05, 7.2865e-06, 9.8554e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,330][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.1226, 0.0396, 0.1402, 0.0352, 0.0282, 0.0356, 0.0560, 0.0698, 0.0426,
        0.0632, 0.0472, 0.0514, 0.0466, 0.0535, 0.0261, 0.0220, 0.0561, 0.0641],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,331][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([1.2550e-03, 1.6904e-06, 3.1941e-06, 8.5620e-07, 3.2769e-05, 5.5107e-06,
        1.2625e-06, 5.9942e-05, 4.4519e-06, 2.8688e-04, 1.5951e-05, 1.4198e-05,
        1.8697e-03, 8.8756e-05, 3.6162e-03, 1.2320e-02, 3.9935e-04, 9.8002e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,332][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.0434, 0.0019, 0.0116, 0.0015, 0.0167, 0.0014, 0.0015, 0.0038, 0.0029,
        0.0091, 0.0035, 0.0053, 0.0772, 0.0048, 0.0851, 0.0186, 0.0130, 0.6988],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,333][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([4.0914e-03, 7.5850e-06, 5.3853e-06, 1.4037e-06, 1.1961e-04, 1.5256e-06,
        1.4008e-06, 4.5544e-06, 4.7759e-07, 4.1680e-05, 1.0412e-06, 2.3702e-07,
        1.3615e-05, 1.7012e-07, 4.3439e-05, 4.8786e-06, 4.6020e-07, 9.9566e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,334][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.0847, 0.0294, 0.2163, 0.0218, 0.0921, 0.0084, 0.0146, 0.0418, 0.0135,
        0.0950, 0.0113, 0.0139, 0.0710, 0.0164, 0.1014, 0.0123, 0.0164, 0.1398],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,335][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0274, 0.0037, 0.0039, 0.0042, 0.0087, 0.0060, 0.0086, 0.0060, 0.0121,
        0.0163, 0.0317, 0.0369, 0.0290, 0.1409, 0.1166, 0.2232, 0.2809, 0.0441],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,337][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.1598, 0.0584, 0.0520, 0.0573, 0.0273, 0.0334, 0.0491, 0.0556, 0.0474,
        0.1010, 0.0406, 0.0470, 0.0553, 0.0317, 0.0275, 0.0465, 0.0533, 0.0568],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,339][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.1170, 0.0614, 0.0548, 0.0580, 0.0778, 0.0472, 0.0450, 0.0416, 0.0477,
        0.0470, 0.0398, 0.0465, 0.0356, 0.0651, 0.0884, 0.0543, 0.0524, 0.0202],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,341][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0779, 0.0497, 0.0478, 0.0589, 0.0532, 0.0453, 0.0412, 0.0331, 0.0526,
        0.0427, 0.0391, 0.0427, 0.0183, 0.0520, 0.0476, 0.0311, 0.0365, 0.2304],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,342][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.1029, 0.0485, 0.0599, 0.0412, 0.1010, 0.0378, 0.0295, 0.0526, 0.0280,
        0.0588, 0.0522, 0.0267, 0.0322, 0.0684, 0.1106, 0.0608, 0.0293, 0.0596],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,345][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1906, 0.0167, 0.0537, 0.0140, 0.0721, 0.0465, 0.0148, 0.0478, 0.0154,
        0.0528, 0.0142, 0.0223, 0.0539, 0.0154, 0.1115, 0.1246, 0.0241, 0.0961,
        0.0134], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,346][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.0635e-03, 8.9834e-03, 1.6801e-04, 2.6119e-02, 8.8814e-05, 2.3092e-04,
        1.0625e-03, 3.7210e-05, 2.5756e-02, 1.8238e-04, 1.4918e-02, 1.4071e-03,
        6.7684e-05, 6.9809e-03, 7.0778e-05, 6.6501e-04, 9.9148e-04, 5.0112e-05,
        9.0816e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,348][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1026, 0.0418, 0.0271, 0.0609, 0.0239, 0.0375, 0.0155, 0.0447, 0.0657,
        0.0347, 0.0897, 0.0184, 0.0213, 0.1843, 0.0267, 0.0526, 0.0173, 0.0119,
        0.1233], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,349][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.1969e-03, 6.3118e-05, 3.2363e-06, 3.0265e-05, 1.2502e-05, 7.2222e-05,
        1.0069e-04, 3.0033e-05, 3.9230e-04, 2.6341e-04, 5.9594e-04, 2.4214e-03,
        6.6703e-04, 4.3858e-03, 1.6522e-03, 2.5056e-01, 7.1211e-02, 2.1025e-02,
        6.4531e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,350][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0207, 0.0011, 0.0009, 0.0016, 0.0004, 0.0110, 0.0030, 0.0046, 0.0040,
        0.0265, 0.0104, 0.0077, 0.0103, 0.0126, 0.0039, 0.3712, 0.0833, 0.1512,
        0.2755], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,351][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.9784e-02, 4.3618e-02, 2.7868e-03, 5.8735e-02, 5.8584e-04, 2.5041e-02,
        1.8580e-01, 7.4838e-03, 3.9503e-02, 9.6101e-03, 1.6766e-02, 1.3573e-01,
        1.5209e-03, 1.6480e-02, 2.4084e-04, 4.8831e-03, 1.1487e-01, 3.4469e-04,
        3.0622e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,351][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0824, 0.0036, 0.0379, 0.0032, 0.0706, 0.0111, 0.0030, 0.0354, 0.0044,
        0.1007, 0.0160, 0.0025, 0.0557, 0.0044, 0.1321, 0.0535, 0.0049, 0.0884,
        0.2903], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,353][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0146, 0.0021, 0.0024, 0.0029, 0.0036, 0.0026, 0.0031, 0.0043, 0.0038,
        0.0111, 0.0110, 0.0183, 0.0196, 0.0912, 0.0715, 0.1206, 0.1587, 0.1831,
        0.2756], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,355][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0053, 0.0387, 0.0018, 0.0694, 0.0034, 0.0314, 0.0850, 0.0057, 0.0494,
        0.0058, 0.0337, 0.1518, 0.0064, 0.1172, 0.0056, 0.0174, 0.1673, 0.0131,
        0.1915], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,357][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0918, 0.0547, 0.0350, 0.0618, 0.0303, 0.0420, 0.0524, 0.0417, 0.0559,
        0.0444, 0.0560, 0.0601, 0.0294, 0.0630, 0.0356, 0.0552, 0.0673, 0.0394,
        0.0841], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,358][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0710, 0.0543, 0.0353, 0.0699, 0.0230, 0.0547, 0.0630, 0.0345, 0.0623,
        0.0398, 0.0628, 0.0629, 0.0261, 0.0672, 0.0236, 0.0549, 0.0700, 0.0268,
        0.0979], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,361][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1479, 0.0570, 0.0627, 0.0576, 0.0625, 0.0424, 0.0373, 0.0453, 0.0268,
        0.0444, 0.0537, 0.0267, 0.0345, 0.0572, 0.0609, 0.0592, 0.0347, 0.0357,
        0.0537], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,364][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:52,366][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[15777],
        [ 7139],
        [    1],
        [14060],
        [25616],
        [19372],
        [21065],
        [10466],
        [15445],
        [ 7927],
        [23329],
        [24986],
        [17939],
        [ 8584],
        [32009],
        [ 4400],
        [24012],
        [21374],
        [11234]], device='cuda:0')
[2024-07-24 10:17:52,368][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[27719],
        [16590],
        [    1],
        [15459],
        [ 1194],
        [25637],
        [12996],
        [29248],
        [23151],
        [30299],
        [17511],
        [10760],
        [30788],
        [22462],
        [ 1517],
        [27872],
        [12369],
        [14465],
        [22327]], device='cuda:0')
[2024-07-24 10:17:52,369][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 6370],
        [ 6126],
        [ 7330],
        [ 5755],
        [ 7904],
        [ 9510],
        [ 5443],
        [ 6933],
        [ 6859],
        [ 7992],
        [ 8361],
        [ 6819],
        [ 8325],
        [ 7216],
        [10119],
        [13602],
        [ 9692],
        [28391],
        [20832]], device='cuda:0')
[2024-07-24 10:17:52,372][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[45456],
        [ 6233],
        [14125],
        [22647],
        [25078],
        [40968],
        [39170],
        [21138],
        [17273],
        [24278],
        [28512],
        [42625],
        [11364],
        [ 6866],
        [23387],
        [16743],
        [38078],
        [10534],
        [24156]], device='cuda:0')
[2024-07-24 10:17:52,374][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 9506],
        [ 9955],
        [ 6424],
        [17477],
        [11532],
        [13995],
        [13772],
        [14242],
        [13999],
        [14201],
        [16958],
        [17129],
        [14683],
        [17423],
        [17491],
        [17255],
        [21526],
        [11302],
        [23235]], device='cuda:0')
[2024-07-24 10:17:52,376][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[25155],
        [29760],
        [30214],
        [37333],
        [25904],
        [ 2482],
        [26852],
        [10775],
        [33580],
        [  480],
        [43312],
        [39097],
        [17410],
        [43184],
        [25050],
        [ 4182],
        [31509],
        [ 5536],
        [31684]], device='cuda:0')
[2024-07-24 10:17:52,378][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 4040],
        [ 3889],
        [  925],
        [  613],
        [10448],
        [ 2905],
        [ 2690],
        [11855],
        [ 2629],
        [21644],
        [ 7422],
        [ 2194],
        [40737],
        [ 2199],
        [14894],
        [16997],
        [12763],
        [43164],
        [15173]], device='cuda:0')
[2024-07-24 10:17:52,380][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[36428],
        [32205],
        [26127],
        [27053],
        [16133],
        [34995],
        [22608],
        [24260],
        [27789],
        [27396],
        [26823],
        [26312],
        [14868],
        [28845],
        [16217],
        [30805],
        [21832],
        [14588],
        [24723]], device='cuda:0')
[2024-07-24 10:17:52,382][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[42801],
        [42567],
        [ 4346],
        [ 3439],
        [ 7643],
        [  697],
        [ 1075],
        [ 8978],
        [ 3910],
        [ 2531],
        [ 1754],
        [ 2957],
        [ 1986],
        [ 7230],
        [ 8461],
        [ 5282],
        [ 7635],
        [  711],
        [ 4334]], device='cuda:0')
[2024-07-24 10:17:52,384][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[19568],
        [19165],
        [12952],
        [13173],
        [29507],
        [26170],
        [37164],
        [33733],
        [33251],
        [33319],
        [30700],
        [40956],
        [39607],
        [24272],
        [30586],
        [17719],
        [34285],
        [34492],
        [32761]], device='cuda:0')
[2024-07-24 10:17:52,386][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[17387],
        [15137],
        [ 7184],
        [15290],
        [ 6548],
        [18122],
        [24011],
        [18460],
        [19793],
        [14624],
        [14551],
        [18065],
        [ 8849],
        [ 9691],
        [ 8374],
        [ 8778],
        [17763],
        [10180],
        [13679]], device='cuda:0')
[2024-07-24 10:17:52,387][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[28634],
        [37304],
        [37694],
        [40036],
        [37068],
        [39759],
        [38742],
        [37635],
        [40365],
        [37477],
        [40296],
        [39775],
        [36801],
        [39529],
        [38121],
        [38166],
        [39923],
        [36159],
        [40193]], device='cuda:0')
[2024-07-24 10:17:52,389][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 3964],
        [ 2891],
        [16463],
        [ 3203],
        [14297],
        [ 1619],
        [ 8396],
        [ 7900],
        [ 1966],
        [16192],
        [ 1675],
        [ 8243],
        [20539],
        [ 3870],
        [28467],
        [ 2043],
        [12213],
        [21691],
        [ 4414]], device='cuda:0')
[2024-07-24 10:17:52,391][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[26195],
        [16846],
        [ 7232],
        [10137],
        [ 5318],
        [ 7645],
        [ 6299],
        [ 8625],
        [ 5058],
        [ 5928],
        [ 5013],
        [ 5480],
        [ 5004],
        [ 5479],
        [ 4921],
        [ 5731],
        [ 5101],
        [ 4272],
        [ 4705]], device='cuda:0')
[2024-07-24 10:17:52,393][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[35124],
        [ 2771],
        [    7],
        [11477],
        [30268],
        [27206],
        [35233],
        [12993],
        [13351],
        [11049],
        [13634],
        [31709],
        [19413],
        [ 1012],
        [29752],
        [12240],
        [34200],
        [20644],
        [ 6297]], device='cuda:0')
[2024-07-24 10:17:52,395][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[13606],
        [13045],
        [ 5005],
        [ 8872],
        [10362],
        [ 6052],
        [13056],
        [10762],
        [11823],
        [11262],
        [11731],
        [11311],
        [11348],
        [11789],
        [12335],
        [10172],
        [14984],
        [ 6419],
        [ 8713]], device='cuda:0')
[2024-07-24 10:17:52,396][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 6810],
        [ 1093],
        [14223],
        [   66],
        [ 8506],
        [ 1711],
        [  190],
        [ 7529],
        [  323],
        [ 6372],
        [  348],
        [  180],
        [ 6548],
        [ 1862],
        [ 7577],
        [ 9443],
        [  189],
        [ 9144],
        [  129]], device='cuda:0')
[2024-07-24 10:17:52,399][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[21755],
        [21927],
        [15826],
        [30133],
        [18672],
        [29321],
        [28165],
        [29289],
        [24527],
        [23188],
        [22607],
        [21696],
        [15867],
        [26429],
        [15681],
        [21767],
        [20349],
        [16424],
        [15154]], device='cuda:0')
[2024-07-24 10:17:52,401][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 7795],
        [12796],
        [13352],
        [19419],
        [12951],
        [24504],
        [21265],
        [35455],
        [26670],
        [33115],
        [23561],
        [20289],
        [20092],
        [22026],
        [10210],
        [12837],
        [16607],
        [18478],
        [17906]], device='cuda:0')
[2024-07-24 10:17:52,403][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[17832],
        [18130],
        [16442],
        [20229],
        [10914],
        [22075],
        [17180],
        [26006],
        [16571],
        [24312],
        [21816],
        [16063],
        [17701],
        [16698],
        [12077],
        [24442],
        [22551],
        [12041],
        [18790]], device='cuda:0')
[2024-07-24 10:17:52,404][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[30054],
        [32514],
        [17707],
        [33821],
        [33261],
        [16692],
        [25342],
        [14221],
        [30468],
        [ 6851],
        [26659],
        [22561],
        [18934],
        [29069],
        [32739],
        [12176],
        [22881],
        [16488],
        [24593]], device='cuda:0')
[2024-07-24 10:17:52,406][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[24473],
        [24371],
        [ 5059],
        [ 4264],
        [14220],
        [ 4235],
        [ 4560],
        [ 5155],
        [ 2877],
        [ 6811],
        [ 2613],
        [ 3298],
        [ 1843],
        [ 3061],
        [23178],
        [ 5623],
        [ 7939],
        [ 2219],
        [30650]], device='cuda:0')
[2024-07-24 10:17:52,408][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 5737],
        [ 5738],
        [ 3946],
        [ 1512],
        [ 3293],
        [ 5425],
        [ 4589],
        [ 2797],
        [ 2637],
        [ 3373],
        [ 4605],
        [ 5345],
        [ 5473],
        [22054],
        [14210],
        [17653],
        [ 8249],
        [ 7440],
        [ 7327]], device='cuda:0')
[2024-07-24 10:17:52,410][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[20990],
        [ 5391],
        [18811],
        [ 2480],
        [18188],
        [ 2541],
        [ 1812],
        [ 2603],
        [ 1953],
        [ 2948],
        [ 2194],
        [ 2415],
        [ 5225],
        [ 2986],
        [20465],
        [ 3207],
        [ 2382],
        [ 9022],
        [ 2925]], device='cuda:0')
[2024-07-24 10:17:52,412][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[20038],
        [13942],
        [12488],
        [12017],
        [10907],
        [10728],
        [10598],
        [11173],
        [12895],
        [11646],
        [14667],
        [14177],
        [12651],
        [12520],
        [11649],
        [11068],
        [12311],
        [10096],
        [12760]], device='cuda:0')
[2024-07-24 10:17:52,414][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[23169],
        [28647],
        [22547],
        [31841],
        [24650],
        [31207],
        [30717],
        [26459],
        [35563],
        [22350],
        [34348],
        [30945],
        [24079],
        [32545],
        [22865],
        [30036],
        [30885],
        [22642],
        [32520]], device='cuda:0')
[2024-07-24 10:17:52,416][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[21705],
        [29270],
        [41530],
        [32050],
        [34479],
        [30609],
        [33201],
        [30397],
        [35203],
        [35797],
        [36471],
        [34907],
        [34349],
        [31902],
        [30298],
        [29448],
        [28729],
        [29453],
        [29471]], device='cuda:0')
[2024-07-24 10:17:52,418][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[25584],
        [26529],
        [30172],
        [32736],
        [27052],
        [34944],
        [33241],
        [31658],
        [32042],
        [31866],
        [31555],
        [32446],
        [32464],
        [26522],
        [26173],
        [30561],
        [30961],
        [33106],
        [29781]], device='cuda:0')
[2024-07-24 10:17:52,420][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 8647],
        [42417],
        [50229],
        [30579],
        [14656],
        [15931],
        [ 8965],
        [29772],
        [28275],
        [31679],
        [29806],
        [11014],
        [23546],
        [47442],
        [15164],
        [30181],
        [ 9844],
        [22672],
        [37901]], device='cuda:0')
[2024-07-24 10:17:52,422][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[9710],
        [9710],
        [9710],
        [9710],
        [9710],
        [9710],
        [9710],
        [9710],
        [9710],
        [9710],
        [9710],
        [9710],
        [9710],
        [9710],
        [9710],
        [9710],
        [9710],
        [9710],
        [9710]], device='cuda:0')
[2024-07-24 10:17:52,441][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:52,442][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,443][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,444][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,444][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,445][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,446][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,447][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,448][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,449][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,450][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,450][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,451][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,452][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4035, 0.5965], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,452][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.4326, 0.5674], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,453][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6589, 0.3411], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,454][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5261, 0.4739], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,454][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2865, 0.7135], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,456][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8464, 0.1536], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,457][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9614, 0.0386], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,459][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9589, 0.0411], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,460][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.8216, 0.1784], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,460][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1687, 0.8313], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,461][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([3.8656e-04, 9.9961e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,462][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.7758, 0.2242], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,462][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Jamie] are: tensor([0.0561, 0.5477, 0.3962], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,464][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Jamie] are: tensor([0.3803, 0.5307, 0.0890], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,465][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Jamie] are: tensor([0.4719, 0.2775, 0.2507], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,467][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Jamie] are: tensor([0.4663, 0.3132, 0.2206], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,469][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Jamie] are: tensor([0.0800, 0.4108, 0.5092], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,470][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Jamie] are: tensor([0.6261, 0.2529, 0.1210], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,472][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Jamie] are: tensor([0.2192, 0.3393, 0.4415], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,474][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Jamie] are: tensor([0.8181, 0.0892, 0.0928], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,475][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Jamie] are: tensor([0.8268, 0.1514, 0.0218], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,476][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Jamie] are: tensor([0.1231, 0.7779, 0.0990], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,477][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Jamie] are: tensor([0.0007, 0.6449, 0.3544], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,478][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Jamie] are: tensor([0.0244, 0.0150, 0.9606], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,479][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0344, 0.1612, 0.6388, 0.1655], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,479][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2988, 0.3711, 0.1502, 0.1799], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,480][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3646, 0.2010, 0.2042, 0.2302], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,482][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3587, 0.2222, 0.2149, 0.2042], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,484][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0645, 0.2021, 0.5463, 0.1870], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,486][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3791, 0.4049, 0.0532, 0.1627], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,487][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5051, 0.0418, 0.4266, 0.0266], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,489][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3119, 0.0380, 0.5681, 0.0820], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,491][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7697, 0.1682, 0.0327, 0.0295], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,493][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1037, 0.5805, 0.1381, 0.1778], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,494][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0027, 0.3304, 0.3061, 0.3607], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,495][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3277, 0.1466, 0.0234, 0.5023], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,495][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0134, 0.1128, 0.5483, 0.1410, 0.1844], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,496][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.2876, 0.4192, 0.0673, 0.1759, 0.0500], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,497][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.2899, 0.1835, 0.1660, 0.1961, 0.1646], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,498][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.3195, 0.2003, 0.1622, 0.1764, 0.1417], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,500][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0511, 0.2533, 0.3419, 0.1879, 0.1658], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,502][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.2785, 0.2533, 0.1679, 0.2199, 0.0805], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,503][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0537, 0.1302, 0.0154, 0.1725, 0.6283], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,505][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.5287, 0.1341, 0.1685, 0.1465, 0.0222], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,507][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.7561, 0.1631, 0.0265, 0.0281, 0.0262], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,508][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0958, 0.5696, 0.0727, 0.1843, 0.0777], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,510][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0018, 0.2370, 0.2051, 0.2755, 0.2806], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,511][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0165, 0.0098, 0.0017, 0.0100, 0.9620], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,512][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0391, 0.0713, 0.2781, 0.1221, 0.1482, 0.3412], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,513][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.2547, 0.3401, 0.0954, 0.1466, 0.0829, 0.0802], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,514][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2463, 0.1517, 0.1427, 0.1615, 0.1497, 0.1481], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,514][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.2383, 0.1668, 0.1491, 0.1378, 0.1382, 0.1697], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,515][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0426, 0.1749, 0.3243, 0.1168, 0.1863, 0.1550], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,517][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.3389, 0.3916, 0.1173, 0.0568, 0.0397, 0.0557], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,519][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.4955, 0.0078, 0.0209, 0.0340, 0.2765, 0.1652], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,521][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1672, 0.0417, 0.3656, 0.0788, 0.1844, 0.1624], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,522][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.7083, 0.1727, 0.0357, 0.0294, 0.0303, 0.0236], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,524][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0637, 0.3937, 0.0806, 0.0886, 0.1567, 0.2167], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,527][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0019, 0.1364, 0.1540, 0.1734, 0.2369, 0.2973], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,529][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0187, 0.0283, 0.0017, 0.0275, 0.0046, 0.9192], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,529][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0077, 0.0375, 0.0989, 0.0577, 0.1092, 0.4927, 0.1963],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,530][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.2069, 0.2555, 0.1011, 0.1201, 0.0921, 0.0786, 0.1458],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,531][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2229, 0.1279, 0.1218, 0.1427, 0.1271, 0.1228, 0.1348],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,532][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2264, 0.1353, 0.1317, 0.1171, 0.1142, 0.1404, 0.1348],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,533][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0465, 0.1476, 0.2743, 0.1188, 0.1676, 0.1344, 0.1108],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,535][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2663, 0.3096, 0.0683, 0.0739, 0.0673, 0.0447, 0.1699],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,536][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1502, 0.0060, 0.1093, 0.0104, 0.5914, 0.0876, 0.0451],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,538][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1433, 0.0283, 0.4216, 0.0503, 0.1878, 0.1281, 0.0406],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,539][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.6750, 0.1669, 0.0312, 0.0281, 0.0236, 0.0214, 0.0538],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,541][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0574, 0.3176, 0.0676, 0.0866, 0.1247, 0.1684, 0.1778],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,543][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0026, 0.1031, 0.1288, 0.1386, 0.1935, 0.2296, 0.2039],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,545][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0417, 0.0127, 0.0013, 0.0128, 0.0015, 0.0027, 0.9272],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,546][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0048, 0.0152, 0.0652, 0.0282, 0.0409, 0.1122, 0.5533, 0.1802],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,547][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.1934, 0.2573, 0.0730, 0.1155, 0.0620, 0.0646, 0.1470, 0.0872],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,547][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.2132, 0.1151, 0.1048, 0.1225, 0.1089, 0.1067, 0.1115, 0.1173],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,548][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.2082, 0.1286, 0.1129, 0.1085, 0.1015, 0.1198, 0.1026, 0.1179],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,549][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0348, 0.1378, 0.2623, 0.1034, 0.1423, 0.1097, 0.0714, 0.1383],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,550][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.2081, 0.3110, 0.0154, 0.0671, 0.0467, 0.0301, 0.1696, 0.1519],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,552][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0943, 0.0130, 0.0254, 0.0292, 0.7163, 0.0230, 0.0762, 0.0228],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,554][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.7043, 0.0530, 0.0526, 0.0427, 0.0397, 0.0528, 0.0446, 0.0103],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,555][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.6892, 0.1560, 0.0267, 0.0255, 0.0213, 0.0183, 0.0503, 0.0127],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,557][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0466, 0.2824, 0.0668, 0.0736, 0.1257, 0.1745, 0.2130, 0.0175],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,559][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0017, 0.0904, 0.1121, 0.1175, 0.1715, 0.1989, 0.1645, 0.1434],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,560][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([5.5413e-03, 1.7459e-02, 1.1747e-04, 8.7831e-03, 8.4309e-04, 1.1089e-03,
        6.6349e-04, 9.6548e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,562][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0023, 0.0117, 0.0350, 0.0217, 0.0399, 0.0708, 0.2637, 0.5446, 0.0103],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,563][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.1669, 0.2095, 0.0805, 0.0977, 0.0750, 0.0625, 0.1205, 0.0826, 0.1049],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,564][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.1756, 0.1001, 0.1003, 0.1102, 0.1059, 0.1009, 0.1035, 0.1065, 0.0971],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,565][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.1832, 0.1118, 0.1064, 0.0935, 0.1077, 0.1149, 0.0917, 0.1130, 0.0777],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,565][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0313, 0.1218, 0.2780, 0.0954, 0.1603, 0.1037, 0.0818, 0.0783, 0.0494],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,566][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0275, 0.0088, 0.0022, 0.0076, 0.0031, 0.0025, 0.0601, 0.0089, 0.8792],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,568][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.2839, 0.0046, 0.0052, 0.0391, 0.0052, 0.0246, 0.2772, 0.3325, 0.0275],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,569][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.3025, 0.0403, 0.1985, 0.0503, 0.1009, 0.1112, 0.0436, 0.1308, 0.0219],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,571][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.6768, 0.1521, 0.0274, 0.0254, 0.0223, 0.0192, 0.0484, 0.0135, 0.0149],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,573][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0494, 0.2832, 0.0673, 0.0778, 0.1242, 0.1325, 0.1425, 0.0162, 0.1068],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,574][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0046, 0.0625, 0.0981, 0.0962, 0.1504, 0.1759, 0.1301, 0.1221, 0.1602],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,576][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0613, 0.0292, 0.0024, 0.0505, 0.0009, 0.0039, 0.0188, 0.0056, 0.8274],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,578][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0011, 0.0101, 0.0396, 0.0232, 0.0266, 0.2117, 0.2416, 0.3535, 0.0204,
        0.0721], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,579][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.1601, 0.2192, 0.0601, 0.0973, 0.0517, 0.0531, 0.1253, 0.0730, 0.1027,
        0.0575], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,580][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.1668, 0.0969, 0.0863, 0.1028, 0.0905, 0.0881, 0.0920, 0.0921, 0.0884,
        0.0962], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,581][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.1698, 0.1066, 0.0977, 0.0955, 0.0801, 0.1072, 0.0897, 0.0989, 0.0706,
        0.0838], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,582][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0308, 0.1459, 0.1699, 0.1033, 0.1147, 0.1140, 0.0674, 0.1073, 0.0468,
        0.0999], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,583][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.1659, 0.1475, 0.0233, 0.0582, 0.0404, 0.0247, 0.1838, 0.1247, 0.0944,
        0.1370], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,584][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.1674, 0.0126, 0.0060, 0.0223, 0.3958, 0.0182, 0.2693, 0.0665, 0.0186,
        0.0230], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,585][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0663, 0.0118, 0.2641, 0.0212, 0.2077, 0.1102, 0.0230, 0.2267, 0.0292,
        0.0398], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,587][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.6793, 0.1417, 0.0266, 0.0259, 0.0235, 0.0189, 0.0497, 0.0132, 0.0148,
        0.0062], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,589][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0406, 0.2502, 0.0477, 0.0658, 0.0719, 0.1621, 0.2242, 0.0156, 0.1010,
        0.0211], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,590][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0023, 0.0590, 0.0791, 0.0819, 0.1198, 0.1388, 0.1129, 0.1023, 0.1171,
        0.1867], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,591][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([8.7827e-03, 9.6111e-03, 2.9362e-04, 1.3362e-02, 7.8313e-04, 1.3542e-03,
        3.3910e-03, 4.5476e-03, 4.3885e-02, 9.1399e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,593][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0058, 0.0270, 0.0642, 0.0381, 0.0545, 0.1475, 0.1480, 0.3674, 0.0365,
        0.0852, 0.0259], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,595][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.1405, 0.1808, 0.0695, 0.0843, 0.0655, 0.0531, 0.1048, 0.0709, 0.0903,
        0.0589, 0.0815], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,597][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1495, 0.0830, 0.0830, 0.0910, 0.0875, 0.0811, 0.0858, 0.0889, 0.0780,
        0.0912, 0.0810], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,598][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.1662, 0.0943, 0.0837, 0.0813, 0.0804, 0.0905, 0.0771, 0.0917, 0.0600,
        0.0850, 0.0897], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,599][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0283, 0.1012, 0.2024, 0.0795, 0.1108, 0.0857, 0.0653, 0.1013, 0.0371,
        0.1085, 0.0798], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,600][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0250, 0.0193, 0.0033, 0.0107, 0.0036, 0.0028, 0.0735, 0.0156, 0.0435,
        0.0107, 0.7920], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,600][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.2440, 0.0133, 0.2320, 0.0352, 0.0775, 0.2483, 0.1079, 0.0152, 0.0078,
        0.0138, 0.0050], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,601][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0395, 0.0055, 0.3689, 0.0193, 0.1462, 0.0891, 0.0113, 0.2439, 0.0190,
        0.0456, 0.0117], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,603][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.6581, 0.1488, 0.0274, 0.0259, 0.0228, 0.0194, 0.0489, 0.0136, 0.0154,
        0.0065, 0.0132], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,604][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0418, 0.2301, 0.0631, 0.0614, 0.1126, 0.1256, 0.1495, 0.0135, 0.0877,
        0.0241, 0.0905], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,606][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0040, 0.0398, 0.0656, 0.0636, 0.1057, 0.1112, 0.0863, 0.0838, 0.0982,
        0.1535, 0.1882], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,607][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ at] are: tensor([6.4969e-03, 9.4828e-03, 3.5045e-04, 9.5717e-03, 5.1440e-04, 2.7831e-03,
        1.1709e-03, 7.8029e-04, 1.7802e-02, 6.3844e-04, 9.5041e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,609][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0052, 0.0225, 0.0515, 0.0372, 0.0507, 0.1693, 0.1793, 0.2369, 0.0394,
        0.0732, 0.0652, 0.0696], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,611][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1204, 0.1459, 0.0714, 0.0725, 0.0712, 0.0516, 0.0855, 0.0666, 0.0779,
        0.0584, 0.0734, 0.1053], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,613][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1309, 0.0768, 0.0762, 0.0850, 0.0791, 0.0757, 0.0810, 0.0853, 0.0732,
        0.0872, 0.0732, 0.0764], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,615][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1510, 0.0786, 0.0811, 0.0741, 0.0736, 0.0830, 0.0783, 0.0920, 0.0524,
        0.0800, 0.0752, 0.0805], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,616][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0281, 0.0859, 0.1799, 0.0623, 0.1092, 0.0815, 0.0597, 0.1132, 0.0315,
        0.1289, 0.0626, 0.0571], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,616][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0777, 0.1652, 0.0537, 0.0245, 0.0138, 0.0147, 0.0947, 0.0657, 0.2165,
        0.0229, 0.1510, 0.0996], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,617][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.3521, 0.0055, 0.1663, 0.0145, 0.0338, 0.1462, 0.0357, 0.0572, 0.0206,
        0.0886, 0.0099, 0.0697], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,618][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0613, 0.0104, 0.3183, 0.0215, 0.1358, 0.0990, 0.0198, 0.2321, 0.0157,
        0.0497, 0.0151, 0.0211], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,619][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.6288, 0.1483, 0.0259, 0.0252, 0.0209, 0.0189, 0.0461, 0.0132, 0.0152,
        0.0062, 0.0130, 0.0383], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,621][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0432, 0.2026, 0.0540, 0.0610, 0.1029, 0.1219, 0.1239, 0.0171, 0.0845,
        0.0269, 0.0952, 0.0669], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,623][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0047, 0.0306, 0.0537, 0.0527, 0.0853, 0.0921, 0.0789, 0.0671, 0.0799,
        0.1370, 0.1538, 0.1642], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,625][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0393, 0.0093, 0.0047, 0.0166, 0.0016, 0.0023, 0.0096, 0.0023, 0.1157,
        0.0053, 0.0092, 0.7840], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,626][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0009, 0.0146, 0.0265, 0.0235, 0.0238, 0.1397, 0.2195, 0.2306, 0.0301,
        0.0736, 0.0534, 0.0889, 0.0748], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,628][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.1237, 0.1687, 0.0437, 0.0750, 0.0375, 0.0395, 0.0951, 0.0546, 0.0785,
        0.0432, 0.0689, 0.1298, 0.0418], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,630][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.1336, 0.0751, 0.0704, 0.0795, 0.0722, 0.0704, 0.0722, 0.0734, 0.0673,
        0.0774, 0.0668, 0.0667, 0.0748], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,632][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.1281, 0.0853, 0.0752, 0.0748, 0.0689, 0.0767, 0.0661, 0.0811, 0.0487,
        0.0774, 0.0746, 0.0641, 0.0792], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,633][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0192, 0.0981, 0.1529, 0.0689, 0.0857, 0.0754, 0.0456, 0.0804, 0.0307,
        0.0950, 0.0554, 0.0388, 0.1539], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,634][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0579, 0.0763, 0.0165, 0.0293, 0.0087, 0.0121, 0.1202, 0.0266, 0.1032,
        0.0157, 0.1785, 0.1926, 0.1626], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,634][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.2736, 0.0251, 0.0055, 0.1850, 0.0387, 0.0070, 0.3158, 0.0054, 0.0273,
        0.0019, 0.0012, 0.1088, 0.0047], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,635][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.3280, 0.0526, 0.0815, 0.0604, 0.0635, 0.1277, 0.0824, 0.0144, 0.0183,
        0.0707, 0.0326, 0.0496, 0.0183], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,636][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.6430, 0.1383, 0.0257, 0.0226, 0.0238, 0.0172, 0.0443, 0.0121, 0.0132,
        0.0057, 0.0114, 0.0359, 0.0069], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,638][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0290, 0.1778, 0.0336, 0.0467, 0.0551, 0.1371, 0.2068, 0.0118, 0.0794,
        0.0175, 0.0972, 0.0763, 0.0318], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,640][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0023, 0.0343, 0.0485, 0.0522, 0.0749, 0.0840, 0.0700, 0.0615, 0.0671,
        0.1147, 0.1313, 0.1190, 0.1403], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,641][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ store] are: tensor([2.7513e-03, 4.1171e-03, 1.3560e-04, 3.5611e-03, 5.3137e-04, 4.1335e-04,
        5.7987e-04, 2.7689e-04, 8.7158e-03, 3.1924e-04, 3.6869e-03, 2.0317e-04,
        9.7471e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,643][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0064, 0.0216, 0.1246, 0.0298, 0.0463, 0.0814, 0.1355, 0.1638, 0.0274,
        0.0857, 0.0419, 0.0623, 0.1159, 0.0575], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,645][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.1008, 0.1094, 0.0668, 0.0587, 0.0687, 0.0456, 0.0737, 0.0601, 0.0678,
        0.0534, 0.0638, 0.0890, 0.0530, 0.0891], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,647][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1124, 0.0644, 0.0667, 0.0720, 0.0707, 0.0654, 0.0693, 0.0721, 0.0630,
        0.0746, 0.0620, 0.0640, 0.0730, 0.0704], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,649][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.1337, 0.0710, 0.0725, 0.0706, 0.0689, 0.0720, 0.0663, 0.0748, 0.0502,
        0.0733, 0.0698, 0.0598, 0.0852, 0.0316], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,650][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0232, 0.0647, 0.1492, 0.0530, 0.1044, 0.0682, 0.0472, 0.0823, 0.0296,
        0.1070, 0.0522, 0.0437, 0.1405, 0.0347], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,651][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1284, 0.0447, 0.0473, 0.0259, 0.0131, 0.0191, 0.0885, 0.0410, 0.0754,
        0.0309, 0.0682, 0.1491, 0.0328, 0.2356], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,652][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0278, 0.0204, 0.4958, 0.0175, 0.1051, 0.1042, 0.0311, 0.0078, 0.0108,
        0.0096, 0.0114, 0.1326, 0.0010, 0.0250], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,652][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.2445, 0.0204, 0.1880, 0.0287, 0.1620, 0.0544, 0.0248, 0.0762, 0.0102,
        0.0473, 0.0172, 0.0204, 0.0904, 0.0153], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,653][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.6424, 0.1363, 0.0227, 0.0228, 0.0192, 0.0170, 0.0428, 0.0120, 0.0137,
        0.0058, 0.0119, 0.0361, 0.0066, 0.0108], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,655][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0415, 0.1718, 0.0515, 0.0544, 0.1036, 0.0779, 0.0850, 0.0146, 0.0677,
        0.0243, 0.0698, 0.0482, 0.0569, 0.1328], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,657][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0051, 0.0220, 0.0367, 0.0371, 0.0599, 0.0652, 0.0489, 0.0454, 0.0575,
        0.0907, 0.1048, 0.0982, 0.1285, 0.2000], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,659][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.1505, 0.0741, 0.0479, 0.0974, 0.0167, 0.0296, 0.0439, 0.0340, 0.1481,
        0.0515, 0.0378, 0.0649, 0.0257, 0.1779], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,661][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0017, 0.0149, 0.0730, 0.0188, 0.0232, 0.0967, 0.2488, 0.1076, 0.0281,
        0.0626, 0.0535, 0.0902, 0.0976, 0.0665, 0.0168], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,663][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.1193, 0.1517, 0.0300, 0.0661, 0.0199, 0.0305, 0.0751, 0.0405, 0.0630,
        0.0323, 0.0560, 0.1221, 0.0319, 0.1268, 0.0348], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,665][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.1051, 0.0680, 0.0620, 0.0726, 0.0611, 0.0624, 0.0625, 0.0655, 0.0597,
        0.0677, 0.0598, 0.0587, 0.0657, 0.0669, 0.0624], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,667][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.1288, 0.0728, 0.0627, 0.0686, 0.0540, 0.0820, 0.0632, 0.0694, 0.0502,
        0.0676, 0.0653, 0.0580, 0.0674, 0.0356, 0.0544], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,667][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0188, 0.1033, 0.1334, 0.0754, 0.0633, 0.0735, 0.0497, 0.0620, 0.0313,
        0.0828, 0.0559, 0.0403, 0.1149, 0.0364, 0.0592], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,668][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0161, 0.0274, 0.0702, 0.0457, 0.0218, 0.0085, 0.0612, 0.0080, 0.0376,
        0.0061, 0.0121, 0.2029, 0.0811, 0.2942, 0.1072], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,669][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0195, 0.0533, 0.0050, 0.0683, 0.2660, 0.0296, 0.0634, 0.0395, 0.0373,
        0.0175, 0.0088, 0.0369, 0.0071, 0.0717, 0.2761], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,670][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.1558, 0.0742, 0.1298, 0.0694, 0.0181, 0.0561, 0.0534, 0.0204, 0.0317,
        0.0356, 0.0430, 0.0923, 0.0439, 0.1544, 0.0221], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,671][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.6023, 0.1502, 0.0210, 0.0246, 0.0197, 0.0165, 0.0476, 0.0115, 0.0146,
        0.0053, 0.0130, 0.0451, 0.0067, 0.0136, 0.0085], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,673][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0212, 0.1262, 0.0154, 0.0405, 0.0163, 0.0970, 0.2389, 0.0092, 0.0770,
        0.0105, 0.1217, 0.0756, 0.0149, 0.1244, 0.0114], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,675][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0022, 0.0239, 0.0368, 0.0408, 0.0534, 0.0709, 0.0512, 0.0454, 0.0520,
        0.0825, 0.0952, 0.0920, 0.1067, 0.1483, 0.0986], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,676][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([1.4069e-04, 1.0256e-04, 2.4940e-04, 4.4392e-05, 2.6406e-01, 3.2897e-05,
        5.6643e-05, 1.7513e-05, 1.8837e-04, 1.7663e-05, 9.1786e-05, 3.6540e-05,
        1.1492e-04, 5.4581e-03, 7.2939e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,678][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0039, 0.0181, 0.0312, 0.0260, 0.0309, 0.1100, 0.1323, 0.1704, 0.0251,
        0.0674, 0.0505, 0.0654, 0.0926, 0.0714, 0.0235, 0.0812],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,680][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.1020, 0.1271, 0.0380, 0.0575, 0.0332, 0.0321, 0.0717, 0.0440, 0.0608,
        0.0358, 0.0543, 0.0975, 0.0348, 0.1126, 0.0597, 0.0386],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,682][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1023, 0.0610, 0.0576, 0.0650, 0.0573, 0.0569, 0.0578, 0.0607, 0.0556,
        0.0617, 0.0550, 0.0539, 0.0633, 0.0613, 0.0586, 0.0719],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,684][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.1181, 0.0649, 0.0552, 0.0620, 0.0551, 0.0706, 0.0568, 0.0622, 0.0485,
        0.0589, 0.0689, 0.0524, 0.0682, 0.0301, 0.0562, 0.0718],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,685][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0141, 0.0785, 0.1496, 0.0506, 0.0655, 0.0521, 0.0350, 0.0487, 0.0233,
        0.0671, 0.0521, 0.0342, 0.1475, 0.0302, 0.0628, 0.0888],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,686][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.1078, 0.0497, 0.0122, 0.0232, 0.0096, 0.0353, 0.1086, 0.0249, 0.0682,
        0.0185, 0.0572, 0.1102, 0.1161, 0.2045, 0.0136, 0.0402],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,686][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.3301, 0.0055, 0.0191, 0.1192, 0.0677, 0.1505, 0.0054, 0.0508, 0.0521,
        0.0211, 0.0169, 0.0083, 0.0028, 0.0152, 0.0735, 0.0618],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,687][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0375, 0.0401, 0.1182, 0.0532, 0.0619, 0.0428, 0.0291, 0.2020, 0.0562,
        0.0302, 0.0272, 0.0367, 0.0373, 0.1477, 0.0520, 0.0280],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,688][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.5746, 0.1491, 0.0287, 0.0256, 0.0237, 0.0192, 0.0503, 0.0133, 0.0149,
        0.0066, 0.0137, 0.0422, 0.0078, 0.0130, 0.0077, 0.0096],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,691][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0210, 0.1498, 0.0245, 0.0362, 0.0416, 0.1036, 0.1616, 0.0077, 0.0621,
        0.0123, 0.0904, 0.0710, 0.0308, 0.1155, 0.0312, 0.0408],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,692][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0022, 0.0174, 0.0316, 0.0304, 0.0485, 0.0537, 0.0391, 0.0339, 0.0443,
        0.0701, 0.0851, 0.0752, 0.0999, 0.1470, 0.0912, 0.1303],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,694][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([4.2091e-03, 6.3093e-03, 1.6521e-04, 4.6369e-03, 6.6957e-04, 3.3038e-03,
        3.9241e-04, 2.8202e-03, 1.2004e-02, 9.2873e-04, 1.3706e-03, 6.5025e-04,
        8.4301e-04, 4.3612e-02, 1.5610e-04, 9.1793e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,695][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0028, 0.0131, 0.0323, 0.0204, 0.0364, 0.1781, 0.0674, 0.2029, 0.0253,
        0.0473, 0.0322, 0.0612, 0.0537, 0.0470, 0.0290, 0.0938, 0.0571],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,697][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0844, 0.0979, 0.0504, 0.0499, 0.0491, 0.0367, 0.0580, 0.0464, 0.0538,
        0.0416, 0.0513, 0.0722, 0.0412, 0.0770, 0.0674, 0.0418, 0.0810],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,699][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0912, 0.0543, 0.0529, 0.0601, 0.0550, 0.0525, 0.0572, 0.0599, 0.0523,
        0.0613, 0.0512, 0.0528, 0.0598, 0.0579, 0.0569, 0.0658, 0.0588],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,701][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1079, 0.0576, 0.0590, 0.0530, 0.0500, 0.0626, 0.0610, 0.0681, 0.0407,
        0.0555, 0.0587, 0.0574, 0.0644, 0.0283, 0.0513, 0.0670, 0.0575],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,702][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0187, 0.0628, 0.1103, 0.0489, 0.0664, 0.0537, 0.0452, 0.0688, 0.0245,
        0.0842, 0.0457, 0.0405, 0.1216, 0.0291, 0.0646, 0.0758, 0.0390],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,703][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0349, 0.0525, 0.0204, 0.0137, 0.0183, 0.0176, 0.0521, 0.0287, 0.1150,
        0.0202, 0.0975, 0.1139, 0.0312, 0.1931, 0.0401, 0.0561, 0.0947],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,704][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0826, 0.0032, 0.0459, 0.0060, 0.2696, 0.0439, 0.0269, 0.0951, 0.0103,
        0.0290, 0.0027, 0.0571, 0.0015, 0.0068, 0.2841, 0.0083, 0.0270],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,705][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0356, 0.0236, 0.1681, 0.0259, 0.0728, 0.0347, 0.0174, 0.2669, 0.0309,
        0.0202, 0.0140, 0.0222, 0.0482, 0.1072, 0.0567, 0.0412, 0.0144],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,706][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.5603, 0.1593, 0.0273, 0.0253, 0.0199, 0.0186, 0.0464, 0.0129, 0.0152,
        0.0061, 0.0134, 0.0396, 0.0069, 0.0121, 0.0057, 0.0085, 0.0225],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,708][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0269, 0.1400, 0.0315, 0.0384, 0.0571, 0.0886, 0.0909, 0.0098, 0.0562,
        0.0167, 0.0734, 0.0482, 0.0389, 0.1112, 0.0459, 0.0383, 0.0882],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,710][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0042, 0.0125, 0.0248, 0.0236, 0.0397, 0.0436, 0.0381, 0.0306, 0.0360,
        0.0614, 0.0705, 0.0704, 0.0862, 0.1313, 0.0843, 0.1271, 0.1157],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,711][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([8.8027e-03, 3.1658e-03, 8.7777e-04, 2.3438e-03, 9.1269e-04, 6.5902e-04,
        2.0916e-01, 7.2617e-04, 1.7234e-02, 1.5220e-03, 3.6733e-03, 2.4982e-03,
        1.2068e-03, 3.8986e-02, 1.0596e-03, 1.3805e-03, 7.0579e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:52,713][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.0005, 0.0049, 0.0183, 0.0093, 0.0183, 0.1125, 0.1227, 0.1530, 0.0098,
        0.0560, 0.0125, 0.0375, 0.0485, 0.0342, 0.0146, 0.2074, 0.1149, 0.0252],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,715][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0848, 0.1195, 0.0256, 0.0516, 0.0203, 0.0256, 0.0658, 0.0354, 0.0535,
        0.0276, 0.0468, 0.0954, 0.0268, 0.1104, 0.0413, 0.0311, 0.1177, 0.0209],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,717][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0936, 0.0540, 0.0510, 0.0567, 0.0517, 0.0501, 0.0512, 0.0521, 0.0488,
        0.0554, 0.0480, 0.0478, 0.0544, 0.0544, 0.0531, 0.0625, 0.0521, 0.0631],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,718][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.1038, 0.0660, 0.0584, 0.0561, 0.0500, 0.0636, 0.0485, 0.0538, 0.0376,
        0.0540, 0.0576, 0.0448, 0.0594, 0.0292, 0.0504, 0.0650, 0.0453, 0.0568],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,719][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0173, 0.0738, 0.0988, 0.0492, 0.0657, 0.0561, 0.0304, 0.0477, 0.0224,
        0.0574, 0.0440, 0.0272, 0.1169, 0.0304, 0.0625, 0.0640, 0.0251, 0.1110],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,720][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.0437, 0.0501, 0.0048, 0.0094, 0.0090, 0.0065, 0.0739, 0.0256, 0.0320,
        0.0158, 0.0398, 0.1192, 0.1265, 0.1782, 0.0184, 0.0236, 0.1495, 0.0740],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,721][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([1.3993e-02, 6.9416e-03, 3.4612e-03, 1.0034e-02, 7.1648e-03, 5.9959e-03,
        3.4475e-01, 4.6200e-04, 1.0214e-02, 1.3281e-02, 3.1358e-04, 9.6522e-02,
        8.8314e-05, 1.2257e-02, 6.2491e-03, 1.9032e-05, 3.0552e-01, 1.6273e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,722][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.1427, 0.0511, 0.0851, 0.0601, 0.0643, 0.0423, 0.0460, 0.0374, 0.0287,
        0.0654, 0.0370, 0.0524, 0.0241, 0.1412, 0.0596, 0.0222, 0.0306, 0.0098],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,723][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.6391, 0.1266, 0.0181, 0.0199, 0.0184, 0.0138, 0.0393, 0.0096, 0.0115,
        0.0045, 0.0099, 0.0345, 0.0057, 0.0101, 0.0073, 0.0074, 0.0223, 0.0021],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,725][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.0177, 0.1202, 0.0200, 0.0279, 0.0329, 0.1023, 0.1525, 0.0066, 0.0546,
        0.0105, 0.0658, 0.0529, 0.0203, 0.0986, 0.0235, 0.0375, 0.1364, 0.0196],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,727][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0023, 0.0147, 0.0262, 0.0240, 0.0406, 0.0406, 0.0325, 0.0268, 0.0320,
        0.0561, 0.0627, 0.0583, 0.0705, 0.1119, 0.0753, 0.1068, 0.0832, 0.1356],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,728][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([1.7673e-03, 1.9697e-03, 4.5649e-04, 1.4558e-03, 6.1711e-04, 5.9479e-04,
        3.4881e-04, 4.7475e-04, 4.6659e-03, 1.5576e-03, 7.8047e-04, 6.7169e-04,
        6.0853e-03, 2.5481e-02, 6.9259e-04, 5.5261e-03, 1.0072e-03, 9.4585e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:52,730][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0023, 0.0093, 0.0260, 0.0123, 0.0175, 0.1459, 0.0763, 0.1505, 0.0218,
        0.0642, 0.0303, 0.0355, 0.0626, 0.0355, 0.0132, 0.1556, 0.0656, 0.0706,
        0.0052], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,732][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0704, 0.0846, 0.0461, 0.0445, 0.0467, 0.0333, 0.0520, 0.0421, 0.0481,
        0.0374, 0.0457, 0.0636, 0.0371, 0.0691, 0.0668, 0.0380, 0.0715, 0.0342,
        0.0689], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,734][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0799, 0.0478, 0.0487, 0.0517, 0.0496, 0.0479, 0.0499, 0.0522, 0.0461,
        0.0527, 0.0460, 0.0465, 0.0535, 0.0511, 0.0511, 0.0616, 0.0515, 0.0603,
        0.0518], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,736][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0988, 0.0499, 0.0508, 0.0460, 0.0477, 0.0588, 0.0475, 0.0556, 0.0377,
        0.0518, 0.0562, 0.0447, 0.0624, 0.0243, 0.0488, 0.0637, 0.0449, 0.0628,
        0.0479], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,737][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0174, 0.0466, 0.1058, 0.0361, 0.0643, 0.0454, 0.0374, 0.0526, 0.0209,
        0.0522, 0.0391, 0.0333, 0.1065, 0.0228, 0.0625, 0.0766, 0.0332, 0.1199,
        0.0275], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,738][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0257, 0.0047, 0.0050, 0.0068, 0.0059, 0.0049, 0.0385, 0.0022, 0.0292,
        0.0043, 0.0298, 0.0611, 0.0050, 0.0643, 0.0094, 0.0080, 0.0807, 0.0052,
        0.6091], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,738][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.4485, 0.0016, 0.0171, 0.0063, 0.0034, 0.0847, 0.0535, 0.0165, 0.0041,
        0.0046, 0.0018, 0.0332, 0.0025, 0.0020, 0.0039, 0.2520, 0.0536, 0.0080,
        0.0027], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,739][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0534, 0.0298, 0.1695, 0.0401, 0.0832, 0.0584, 0.0238, 0.1253, 0.0293,
        0.0263, 0.0166, 0.0244, 0.0407, 0.0768, 0.0543, 0.0553, 0.0190, 0.0527,
        0.0213], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,741][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.5778, 0.1451, 0.0253, 0.0239, 0.0204, 0.0177, 0.0444, 0.0124, 0.0142,
        0.0059, 0.0125, 0.0372, 0.0068, 0.0115, 0.0061, 0.0084, 0.0221, 0.0025,
        0.0060], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,743][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0245, 0.1235, 0.0278, 0.0357, 0.0526, 0.0727, 0.0917, 0.0093, 0.0511,
        0.0146, 0.0710, 0.0456, 0.0324, 0.0974, 0.0417, 0.0317, 0.0866, 0.0337,
        0.0564], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,745][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0050, 0.0090, 0.0188, 0.0172, 0.0290, 0.0333, 0.0250, 0.0202, 0.0271,
        0.0433, 0.0533, 0.0485, 0.0596, 0.0985, 0.0590, 0.0975, 0.0766, 0.1210,
        0.1580], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,746][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([5.2632e-02, 2.0580e-02, 5.8989e-04, 3.1462e-02, 7.2168e-04, 2.5567e-03,
        4.7361e-03, 1.1315e-03, 6.1265e-02, 1.9805e-03, 1.0964e-02, 1.9641e-03,
        1.5411e-03, 7.5443e-02, 1.6400e-04, 2.4018e-03, 5.1370e-03, 1.3297e-03,
        7.2340e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:52,764][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:52,765][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,765][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,766][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,767][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,767][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,768][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,769][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,770][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,771][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,771][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,772][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,773][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:52,773][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4560, 0.5440], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,774][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.8149, 0.1851], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,775][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6590, 0.3410], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,776][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3651, 0.6349], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,776][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3023, 0.6977], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,777][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0327, 0.9673], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,778][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9727, 0.0273], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,778][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.5929, 0.4071], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,780][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0536, 0.9464], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,781][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9451, 0.0549], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,783][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0010, 0.9990], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,785][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.8407, 0.1593], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:52,787][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Jamie] are: tensor([0.7430, 0.2075, 0.0495], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,788][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Jamie] are: tensor([0.9172, 0.0790, 0.0039], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,790][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Jamie] are: tensor([0.4716, 0.2696, 0.2588], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,790][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Jamie] are: tensor([0.4425, 0.3205, 0.2371], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,791][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Jamie] are: tensor([0.0824, 0.3954, 0.5222], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,792][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Jamie] are: tensor([5.6856e-01, 4.3130e-01, 1.3651e-04], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,792][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Jamie] are: tensor([0.1780, 0.2728, 0.5492], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,793][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Jamie] are: tensor([0.0475, 0.2463, 0.7062], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,794][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Jamie] are: tensor([0.0427, 0.8086, 0.1487], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,796][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Jamie] are: tensor([0.7772, 0.1585, 0.0643], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,798][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Jamie] are: tensor([0.0014, 0.6372, 0.3614], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,799][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Jamie] are: tensor([0.0021, 0.0033, 0.9946], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:52,801][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1558, 0.3873, 0.1581, 0.2987], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,803][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.8594, 0.1067, 0.0067, 0.0272], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,805][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3624, 0.1960, 0.2159, 0.2257], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,806][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.4384, 0.1886, 0.1907, 0.1823], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,807][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0667, 0.1945, 0.5540, 0.1847], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,808][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([4.1281e-01, 5.8690e-01, 1.0312e-04, 1.8348e-04], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,808][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4870, 0.0306, 0.4622, 0.0202], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,809][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0518, 0.0699, 0.8484, 0.0299], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,810][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0240, 0.6702, 0.0239, 0.2819], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,810][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.7251, 0.0478, 0.1124, 0.1147], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,812][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0049, 0.3327, 0.2909, 0.3715], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,814][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2421, 0.0933, 0.0342, 0.6305], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:52,816][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.2422, 0.3134, 0.0403, 0.2130, 0.1912], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,818][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.8819, 0.0876, 0.0047, 0.0214, 0.0044], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,819][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.2974, 0.1758, 0.1682, 0.1865, 0.1722], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,821][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.4240, 0.1348, 0.1461, 0.1625, 0.1326], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,823][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0524, 0.2428, 0.3478, 0.1844, 0.1727], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,824][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([4.5725e-01, 5.4234e-01, 3.1696e-04, 6.7860e-05, 2.7393e-05],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,825][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0400, 0.0929, 0.0153, 0.1351, 0.7167], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,826][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0265, 0.1134, 0.7011, 0.0867, 0.0722], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,826][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.0296, 0.4498, 0.1444, 0.3723, 0.0038], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,827][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.5283, 0.2243, 0.0497, 0.1615, 0.0362], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,828][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0031, 0.2381, 0.1954, 0.2828, 0.2807], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,829][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([3.0272e-03, 4.4306e-03, 3.3631e-04, 3.5922e-03, 9.8861e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:52,831][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0213, 0.0721, 0.0231, 0.0567, 0.1007, 0.7262], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,833][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.8287, 0.1103, 0.0072, 0.0275, 0.0064, 0.0199], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,834][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.2441, 0.1459, 0.1487, 0.1566, 0.1589, 0.1459], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,836][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.3789, 0.1272, 0.1299, 0.1237, 0.1184, 0.1220], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,838][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0434, 0.1663, 0.3272, 0.1143, 0.1924, 0.1563], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,839][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([5.6484e-02, 9.3849e-01, 3.5803e-04, 2.4160e-04, 2.5888e-05, 4.3966e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,841][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.4885, 0.0054, 0.0241, 0.0252, 0.3226, 0.1341], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,843][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0208, 0.0350, 0.5217, 0.0383, 0.1149, 0.2692], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,844][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([2.3829e-03, 3.0267e-01, 1.9527e-02, 7.4991e-02, 1.4004e-04, 6.0028e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,846][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.6176, 0.0737, 0.1010, 0.0911, 0.0744, 0.0421], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,847][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0031, 0.1488, 0.1481, 0.1877, 0.2367, 0.2757], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,848][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0061, 0.0277, 0.0016, 0.0172, 0.0053, 0.9422], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:52,848][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0046, 0.0433, 0.0166, 0.0444, 0.1794, 0.5957, 0.1160],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,849][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.7973, 0.1070, 0.0071, 0.0289, 0.0066, 0.0219, 0.0311],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,850][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2246, 0.1233, 0.1263, 0.1379, 0.1357, 0.1209, 0.1313],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,851][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.3695, 0.1081, 0.1115, 0.1101, 0.0966, 0.1020, 0.1021],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,853][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0471, 0.1404, 0.2770, 0.1161, 0.1727, 0.1351, 0.1115],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,854][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([3.2925e-01, 6.6997e-01, 7.2698e-05, 3.4766e-05, 7.6045e-06, 6.4461e-04,
        2.4931e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,856][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1180, 0.0033, 0.1141, 0.0067, 0.6606, 0.0640, 0.0333],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,857][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0313, 0.0128, 0.4304, 0.0127, 0.1866, 0.3032, 0.0229],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,859][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.5028e-03, 4.8502e-02, 1.5587e-03, 1.7048e-02, 7.3302e-06, 3.0677e-02,
        9.0070e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,861][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.5755, 0.0588, 0.1215, 0.1083, 0.0825, 0.0285, 0.0249],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,862][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0037, 0.1112, 0.1206, 0.1490, 0.1896, 0.2144, 0.2115],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,864][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.1638e-02, 5.4638e-03, 6.0164e-04, 5.1681e-03, 7.4065e-04, 4.6572e-04,
        9.7592e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:52,865][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0422, 0.0689, 0.0552, 0.0679, 0.1495, 0.3742, 0.2188, 0.0234],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,865][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.7794, 0.1093, 0.0075, 0.0293, 0.0065, 0.0215, 0.0328, 0.0137],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,866][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.2146, 0.1111, 0.1079, 0.1181, 0.1147, 0.1051, 0.1092, 0.1191],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,867][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.3460, 0.0910, 0.0937, 0.1039, 0.0953, 0.0967, 0.0916, 0.0818],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,868][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0351, 0.1302, 0.2658, 0.1005, 0.1471, 0.1105, 0.0718, 0.1391],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,869][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([2.0852e-01, 7.1908e-01, 7.9964e-04, 2.1900e-03, 3.4866e-04, 1.2164e-02,
        1.3288e-03, 5.5570e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,871][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0812, 0.0098, 0.0288, 0.0216, 0.7612, 0.0165, 0.0610, 0.0200],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,873][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0255, 0.0085, 0.1325, 0.0057, 0.0743, 0.2265, 0.0075, 0.5195],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,874][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([1.8405e-04, 3.0505e-02, 1.1836e-03, 1.1096e-02, 7.1349e-06, 2.2435e-02,
        9.3459e-01, 3.2204e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,876][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.4977, 0.1086, 0.0862, 0.1200, 0.0515, 0.0619, 0.0597, 0.0144],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,878][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0024, 0.0982, 0.1042, 0.1287, 0.1659, 0.1896, 0.1776, 0.1335],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,879][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([7.5767e-04, 6.5539e-03, 1.4293e-05, 1.4944e-03, 1.1689e-04, 7.0060e-05,
        3.1711e-05, 9.9096e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:52,881][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0050, 0.0401, 0.0123, 0.0274, 0.1660, 0.4738, 0.2089, 0.0436, 0.0229],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,882][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.7804, 0.1028, 0.0065, 0.0264, 0.0058, 0.0198, 0.0295, 0.0127, 0.0160],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,883][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.1785, 0.0962, 0.1038, 0.1064, 0.1122, 0.0987, 0.1011, 0.1080, 0.0951],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,884][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.3527, 0.0805, 0.0906, 0.0893, 0.0874, 0.0854, 0.0768, 0.0656, 0.0718],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,884][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0320, 0.1155, 0.2801, 0.0933, 0.1652, 0.1044, 0.0823, 0.0789, 0.0482],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,885][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([3.6724e-01, 6.3028e-01, 4.3140e-05, 5.7024e-05, 5.2714e-06, 6.2501e-04,
        2.9291e-05, 1.6662e-03, 5.1342e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,887][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.3038, 0.0033, 0.0058, 0.0296, 0.0056, 0.0186, 0.2531, 0.3606, 0.0196],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,889][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0295, 0.0451, 0.3724, 0.0348, 0.1140, 0.1043, 0.0304, 0.2191, 0.0504],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,890][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([3.6477e-04, 3.2970e-02, 1.2089e-03, 6.6711e-03, 5.0052e-06, 3.2495e-02,
        9.2626e-01, 1.3894e-06, 2.3467e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,892][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.4946, 0.0424, 0.1289, 0.0915, 0.0902, 0.0232, 0.0234, 0.0143, 0.0916],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,894][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0055, 0.0720, 0.0896, 0.1063, 0.1425, 0.1640, 0.1436, 0.1098, 0.1667],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,895][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([3.3719e-02, 2.0668e-02, 1.6401e-03, 4.1256e-02, 5.8772e-04, 1.4777e-03,
        1.1531e-02, 3.0365e-03, 8.8608e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:52,897][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0153, 0.0265, 0.0347, 0.0256, 0.0868, 0.2901, 0.0657, 0.0783, 0.0209,
        0.3560], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,899][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.8032, 0.0934, 0.0055, 0.0227, 0.0048, 0.0162, 0.0261, 0.0105, 0.0137,
        0.0039], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,899][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.1708, 0.0928, 0.0875, 0.0988, 0.0947, 0.0865, 0.0898, 0.0926, 0.0864,
        0.1001], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,900][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.3152, 0.0796, 0.0825, 0.0925, 0.0752, 0.0769, 0.0774, 0.0637, 0.0712,
        0.0658], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,901][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0308, 0.1377, 0.1729, 0.1003, 0.1187, 0.1149, 0.0679, 0.1081, 0.0453,
        0.1033], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,902][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([6.4450e-02, 9.2985e-01, 1.2843e-04, 1.6760e-04, 1.8336e-05, 1.4041e-03,
        1.2240e-04, 3.3592e-03, 8.2270e-05, 4.2222e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,903][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.1138, 0.0073, 0.0077, 0.0132, 0.5874, 0.0120, 0.1619, 0.0636, 0.0098,
        0.0234], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,905][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0090, 0.0091, 0.2607, 0.0090, 0.0498, 0.2590, 0.0074, 0.3540, 0.0167,
        0.0253], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,906][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([6.1555e-04, 4.6321e-02, 5.9839e-03, 2.6366e-02, 7.0680e-05, 5.4562e-02,
        8.6514e-01, 2.1976e-05, 9.1264e-04, 9.1135e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,908][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.4594, 0.0603, 0.1210, 0.1017, 0.0893, 0.0396, 0.0358, 0.0177, 0.0595,
        0.0155], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,909][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0035, 0.0654, 0.0742, 0.0911, 0.1171, 0.1319, 0.1225, 0.0945, 0.1290,
        0.1708], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,911][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([5.5843e-03, 1.2750e-02, 3.1779e-04, 1.3673e-02, 5.7409e-04, 3.8664e-04,
        9.2770e-04, 1.9009e-03, 2.0061e-02, 9.4382e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:52,913][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0067, 0.0187, 0.0104, 0.0168, 0.0800, 0.3471, 0.1010, 0.0380, 0.0238,
        0.2668, 0.0906], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,915][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.8217, 0.0818, 0.0047, 0.0196, 0.0042, 0.0151, 0.0226, 0.0095, 0.0119,
        0.0035, 0.0055], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,916][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1536, 0.0791, 0.0847, 0.0875, 0.0918, 0.0786, 0.0830, 0.0891, 0.0758,
        0.0953, 0.0816], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,917][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.3139, 0.0672, 0.0762, 0.0785, 0.0707, 0.0717, 0.0651, 0.0551, 0.0598,
        0.0629, 0.0790], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,917][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0284, 0.0960, 0.2047, 0.0776, 0.1140, 0.0860, 0.0655, 0.1013, 0.0360,
        0.1107, 0.0797], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,918][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([1.8377e-01, 8.0332e-01, 1.1475e-04, 1.6437e-04, 2.2127e-05, 3.7850e-03,
        1.9211e-04, 6.7859e-03, 1.6944e-04, 5.8348e-04, 1.0908e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,919][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.2235, 0.0089, 0.3010, 0.0271, 0.1110, 0.2072, 0.0822, 0.0176, 0.0056,
        0.0125, 0.0035], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,921][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0068, 0.0065, 0.1472, 0.0047, 0.1536, 0.1597, 0.0084, 0.3755, 0.0082,
        0.1174, 0.0119], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,922][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([1.1418e-03, 3.1783e-02, 2.5577e-03, 9.2958e-03, 2.0829e-05, 3.7375e-02,
        9.1771e-01, 7.3503e-06, 8.2838e-05, 3.0401e-06, 1.8896e-05],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,924][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.4795, 0.0372, 0.1211, 0.0764, 0.0850, 0.0309, 0.0325, 0.0175, 0.0670,
        0.0214, 0.0315], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,925][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0050, 0.0465, 0.0609, 0.0723, 0.1009, 0.1089, 0.0979, 0.0771, 0.1093,
        0.1368, 0.1845], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,926][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([8.1679e-04, 2.7471e-03, 7.2577e-05, 2.5780e-03, 1.8505e-04, 4.5832e-04,
        1.8736e-04, 1.2138e-04, 3.6167e-03, 9.8726e-05, 9.8912e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:52,929][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0023, 0.0236, 0.0061, 0.0242, 0.1015, 0.2092, 0.1078, 0.0288, 0.0451,
        0.1957, 0.2144, 0.0414], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,931][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.7813, 0.0908, 0.0055, 0.0238, 0.0052, 0.0186, 0.0266, 0.0115, 0.0149,
        0.0043, 0.0072, 0.0104], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,932][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1354, 0.0734, 0.0775, 0.0813, 0.0830, 0.0735, 0.0782, 0.0853, 0.0710,
        0.0908, 0.0737, 0.0768], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,933][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.3126, 0.0618, 0.0708, 0.0703, 0.0654, 0.0622, 0.0618, 0.0512, 0.0528,
        0.0551, 0.0663, 0.0696], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,934][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0282, 0.0811, 0.1815, 0.0608, 0.1122, 0.0819, 0.0600, 0.1132, 0.0307,
        0.1315, 0.0626, 0.0563], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,935][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([4.0480e-01, 5.9100e-01, 9.1403e-05, 4.5597e-05, 7.8426e-06, 9.4379e-04,
        3.5727e-05, 2.5764e-03, 4.2701e-05, 2.5144e-04, 1.7086e-04, 3.8417e-05],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,936][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.3370, 0.0038, 0.2197, 0.0111, 0.0400, 0.1288, 0.0311, 0.0612, 0.0147,
        0.0871, 0.0076, 0.0581], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,936][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0040, 0.0021, 0.1569, 0.0018, 0.0551, 0.1058, 0.0048, 0.4953, 0.0039,
        0.1555, 0.0105, 0.0044], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,938][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([3.7626e-04, 2.4571e-02, 4.9711e-04, 7.1052e-03, 3.8001e-06, 1.5398e-02,
        5.6171e-01, 8.9214e-07, 1.8390e-05, 4.3368e-07, 5.3670e-06, 3.9031e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,939][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.4623, 0.0263, 0.1055, 0.0942, 0.0943, 0.0239, 0.0228, 0.0303, 0.0573,
        0.0266, 0.0246, 0.0319], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,941][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0051, 0.0358, 0.0497, 0.0599, 0.0819, 0.0908, 0.0876, 0.0614, 0.0901,
        0.1191, 0.1530, 0.1655], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,942][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([7.1957e-03, 3.2777e-03, 1.4682e-03, 8.0289e-03, 5.1647e-04, 5.8065e-04,
        2.8291e-03, 3.7051e-04, 5.7968e-02, 1.2060e-03, 2.2006e-03, 9.1436e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:52,944][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.0084, 0.0242, 0.0232, 0.0280, 0.0538, 0.1442, 0.0498, 0.0244, 0.0144,
        0.2500, 0.2687, 0.0478, 0.0633], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,946][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.7739, 0.0954, 0.0056, 0.0238, 0.0050, 0.0173, 0.0273, 0.0113, 0.0143,
        0.0042, 0.0071, 0.0108, 0.0039], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,948][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.1400, 0.0715, 0.0702, 0.0756, 0.0744, 0.0679, 0.0697, 0.0728, 0.0651,
        0.0799, 0.0672, 0.0673, 0.0783], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,950][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.2694, 0.0574, 0.0668, 0.0702, 0.0606, 0.0618, 0.0587, 0.0521, 0.0528,
        0.0586, 0.0681, 0.0620, 0.0615], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,951][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0196, 0.0934, 0.1558, 0.0676, 0.0889, 0.0766, 0.0461, 0.0811, 0.0300,
        0.0973, 0.0558, 0.0385, 0.1495], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,951][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([2.4909e-01, 7.4653e-01, 1.7505e-04, 1.0324e-04, 1.7649e-05, 7.8196e-04,
        5.5709e-05, 2.1575e-03, 8.1723e-05, 2.5119e-04, 2.5717e-04, 5.0374e-05,
        4.4858e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,952][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.2814, 0.0233, 0.0114, 0.1674, 0.0773, 0.0057, 0.3027, 0.0067, 0.0219,
        0.0026, 0.0013, 0.0913, 0.0068], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,953][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0022, 0.0094, 0.1147, 0.0122, 0.0322, 0.5667, 0.0063, 0.0535, 0.0106,
        0.1631, 0.0213, 0.0035, 0.0044], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,954][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([1.9215e-04, 1.4149e-02, 8.2032e-04, 4.2535e-03, 1.1056e-05, 1.8678e-02,
        5.6827e-01, 3.9080e-06, 4.3254e-05, 1.5282e-06, 1.5490e-05, 3.9356e-01,
        2.7655e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,956][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.4431, 0.0339, 0.0607, 0.0489, 0.0641, 0.0613, 0.0401, 0.0348, 0.0506,
        0.0251, 0.0591, 0.0584, 0.0199], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,958][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.0030, 0.0359, 0.0433, 0.0563, 0.0697, 0.0800, 0.0767, 0.0563, 0.0773,
        0.1047, 0.1334, 0.1314, 0.1319], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,959][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([7.3123e-04, 2.2398e-03, 2.5084e-05, 1.3964e-03, 1.6758e-04, 4.9819e-05,
        7.1246e-05, 5.4805e-05, 1.4993e-03, 5.5373e-05, 9.5066e-04, 1.3339e-05,
        9.9275e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:52,961][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0134, 0.0312, 0.0110, 0.0217, 0.0986, 0.3059, 0.0785, 0.0182, 0.0255,
        0.2461, 0.0804, 0.0348, 0.0310, 0.0039], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,963][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.7884, 0.0842, 0.0048, 0.0212, 0.0045, 0.0164, 0.0233, 0.0104, 0.0130,
        0.0038, 0.0062, 0.0091, 0.0035, 0.0111], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,965][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1162, 0.0613, 0.0675, 0.0690, 0.0733, 0.0632, 0.0668, 0.0718, 0.0611,
        0.0770, 0.0621, 0.0641, 0.0763, 0.0703], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,966][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.2951, 0.0548, 0.0615, 0.0587, 0.0560, 0.0503, 0.0481, 0.0408, 0.0454,
        0.0463, 0.0570, 0.0507, 0.0527, 0.0826], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,968][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0234, 0.0615, 0.1507, 0.0520, 0.1076, 0.0688, 0.0477, 0.0826, 0.0292,
        0.1093, 0.0527, 0.0435, 0.1368, 0.0342], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,968][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([6.1446e-01, 3.8402e-01, 2.9346e-05, 1.5839e-05, 3.5401e-06, 3.3365e-04,
        7.9822e-06, 9.2296e-04, 1.3873e-05, 6.3254e-05, 6.1272e-05, 1.0270e-05,
        5.1816e-05, 2.8532e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,969][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([2.4386e-02, 1.4431e-02, 5.9084e-01, 1.2963e-02, 9.6910e-02, 7.9363e-02,
        2.4402e-02, 6.3039e-03, 7.4996e-03, 8.6519e-03, 8.6750e-03, 1.0681e-01,
        5.7060e-04, 1.8192e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,970][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0197, 0.0236, 0.1975, 0.0346, 0.1134, 0.1070, 0.0352, 0.1343, 0.0461,
        0.1088, 0.0887, 0.0240, 0.0405, 0.0266], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,971][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([1.8114e-04, 1.5588e-02, 8.2455e-04, 1.6058e-03, 7.3826e-06, 3.9317e-02,
        7.2115e-01, 1.3743e-06, 4.3048e-06, 1.4682e-06, 1.6982e-06, 2.2037e-01,
        5.5282e-07, 9.5057e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,972][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.4885, 0.0293, 0.0926, 0.0605, 0.0720, 0.0301, 0.0194, 0.0217, 0.0381,
        0.0212, 0.0259, 0.0233, 0.0239, 0.0536], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,974][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0054, 0.0270, 0.0360, 0.0435, 0.0601, 0.0653, 0.0578, 0.0435, 0.0652,
        0.0833, 0.1060, 0.1057, 0.1161, 0.1852], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,976][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.1534, 0.0852, 0.1504, 0.0913, 0.0327, 0.0191, 0.0269, 0.0337, 0.0777,
        0.0780, 0.0186, 0.0508, 0.0177, 0.1645], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:52,978][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0620, 0.0782, 0.0107, 0.0451, 0.0395, 0.1753, 0.0852, 0.0107, 0.0232,
        0.1580, 0.2047, 0.0555, 0.0219, 0.0062, 0.0238], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,980][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.7759, 0.0800, 0.0044, 0.0212, 0.0043, 0.0160, 0.0256, 0.0102, 0.0140,
        0.0040, 0.0075, 0.0114, 0.0042, 0.0145, 0.0067], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,982][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.1117, 0.0642, 0.0610, 0.0680, 0.0625, 0.0599, 0.0600, 0.0647, 0.0575,
        0.0694, 0.0595, 0.0590, 0.0685, 0.0674, 0.0667], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,984][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.2372, 0.0375, 0.0492, 0.0576, 0.0465, 0.0615, 0.0534, 0.0450, 0.0473,
        0.0512, 0.0592, 0.0587, 0.0558, 0.0958, 0.0441], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,985][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0190, 0.0980, 0.1355, 0.0733, 0.0657, 0.0743, 0.0502, 0.0628, 0.0304,
        0.0854, 0.0561, 0.0399, 0.1120, 0.0354, 0.0618], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,986][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([1.8876e-01, 8.0626e-01, 5.8158e-04, 2.0281e-04, 2.9965e-05, 7.9561e-04,
        4.9770e-05, 2.5039e-03, 7.4776e-05, 3.9397e-04, 1.3395e-04, 2.8182e-05,
        1.5176e-04, 1.4074e-05, 2.7922e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,987][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0146, 0.0391, 0.0053, 0.0546, 0.3073, 0.0245, 0.0477, 0.0400, 0.0317,
        0.0172, 0.0083, 0.0252, 0.0094, 0.0609, 0.3142], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,988][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0030, 0.0176, 0.1117, 0.0124, 0.0095, 0.3397, 0.0225, 0.2044, 0.0161,
        0.1388, 0.0254, 0.0180, 0.0348, 0.0396, 0.0065], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,989][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([8.9178e-04, 2.1004e-02, 4.2598e-03, 1.2238e-02, 1.2562e-04, 2.1995e-02,
        4.7523e-01, 9.3972e-05, 7.7923e-04, 3.5329e-05, 1.6893e-04, 4.4689e-01,
        5.1774e-05, 1.6120e-02, 1.1223e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,991][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.1129, 0.0633, 0.0170, 0.0264, 0.0099, 0.0425, 0.1381, 0.0104, 0.0618,
        0.0140, 0.1897, 0.1551, 0.0122, 0.1215, 0.0254], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,993][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0033, 0.0242, 0.0325, 0.0426, 0.0493, 0.0655, 0.0550, 0.0410, 0.0589,
        0.0746, 0.0979, 0.0999, 0.1006, 0.1535, 0.1013], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,994][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([1.5066e-05, 4.3022e-04, 6.5916e-05, 6.3577e-05, 4.3842e-01, 2.0970e-05,
        3.1339e-05, 7.2409e-06, 1.1518e-04, 3.6866e-06, 9.0704e-05, 1.0927e-05,
        2.6412e-05, 4.7727e-03, 5.5593e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:52,996][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0278, 0.0362, 0.0459, 0.0341, 0.0502, 0.1158, 0.0332, 0.0213, 0.0108,
        0.0922, 0.1170, 0.0204, 0.0250, 0.0081, 0.0353, 0.3266],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:52,998][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.7828, 0.0862, 0.0049, 0.0202, 0.0044, 0.0147, 0.0231, 0.0100, 0.0124,
        0.0037, 0.0061, 0.0093, 0.0034, 0.0114, 0.0054, 0.0020],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,000][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1074, 0.0576, 0.0573, 0.0614, 0.0590, 0.0544, 0.0553, 0.0595, 0.0531,
        0.0631, 0.0544, 0.0536, 0.0654, 0.0608, 0.0624, 0.0754],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,001][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.2590, 0.0432, 0.0502, 0.0509, 0.0466, 0.0501, 0.0431, 0.0365, 0.0425,
        0.0435, 0.0554, 0.0476, 0.0495, 0.0913, 0.0413, 0.0493],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,003][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0141, 0.0744, 0.1526, 0.0494, 0.0679, 0.0527, 0.0352, 0.0490, 0.0226,
        0.0691, 0.0521, 0.0336, 0.1423, 0.0293, 0.0654, 0.0904],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,003][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([1.7400e-01, 8.2365e-01, 4.0426e-05, 4.2536e-05, 4.5041e-06, 6.0030e-04,
        2.4326e-05, 1.2668e-03, 3.6199e-05, 9.2063e-05, 1.0069e-04, 2.2611e-05,
        7.6562e-05, 7.1847e-06, 1.1969e-05, 3.2042e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,004][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.3336, 0.0041, 0.0224, 0.1030, 0.0945, 0.1266, 0.0047, 0.0598, 0.0409,
        0.0193, 0.0125, 0.0061, 0.0028, 0.0118, 0.1036, 0.0544],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,005][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0018, 0.0032, 0.1828, 0.0027, 0.0173, 0.1277, 0.0006, 0.2312, 0.0091,
        0.2783, 0.0140, 0.0011, 0.0946, 0.0089, 0.0136, 0.0132],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,006][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([2.9194e-04, 2.0981e-02, 5.3752e-04, 7.4365e-03, 6.6907e-06, 2.2887e-02,
        4.0404e-01, 3.8777e-06, 8.9592e-05, 1.7622e-06, 2.7134e-05, 5.3745e-01,
        3.2080e-06, 6.1840e-03, 5.6848e-06, 5.4680e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,008][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.3005, 0.0465, 0.0603, 0.0443, 0.0415, 0.0558, 0.0535, 0.0178, 0.0476,
        0.0198, 0.0549, 0.0775, 0.0275, 0.0545, 0.0672, 0.0308],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,010][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0028, 0.0200, 0.0288, 0.0345, 0.0460, 0.0530, 0.0456, 0.0326, 0.0514,
        0.0646, 0.0869, 0.0833, 0.0921, 0.1428, 0.0908, 0.1250],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,011][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([1.7159e-03, 9.0862e-03, 1.1894e-04, 3.2145e-03, 6.1863e-04, 1.0713e-03,
        1.1969e-04, 2.0629e-03, 4.9944e-03, 5.8673e-04, 2.9562e-04, 1.6302e-04,
        3.0573e-04, 2.7194e-02, 7.3034e-05, 9.4838e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,013][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0018, 0.0148, 0.0070, 0.0150, 0.0552, 0.1475, 0.0426, 0.0216, 0.0191,
        0.1428, 0.0944, 0.0286, 0.0489, 0.0119, 0.0692, 0.2008, 0.0788],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,015][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.7449, 0.0935, 0.0056, 0.0239, 0.0051, 0.0181, 0.0252, 0.0116, 0.0146,
        0.0042, 0.0072, 0.0104, 0.0040, 0.0133, 0.0064, 0.0024, 0.0096],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,017][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0953, 0.0515, 0.0529, 0.0569, 0.0570, 0.0504, 0.0543, 0.0588, 0.0499,
        0.0626, 0.0506, 0.0522, 0.0618, 0.0573, 0.0610, 0.0691, 0.0585],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,019][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2696, 0.0431, 0.0466, 0.0484, 0.0403, 0.0445, 0.0464, 0.0359, 0.0396,
        0.0385, 0.0496, 0.0495, 0.0449, 0.0807, 0.0358, 0.0454, 0.0414],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,020][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0187, 0.0595, 0.1123, 0.0477, 0.0686, 0.0540, 0.0454, 0.0691, 0.0239,
        0.0863, 0.0457, 0.0399, 0.1177, 0.0284, 0.0669, 0.0767, 0.0393],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,021][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([2.5090e-01, 7.4522e-01, 7.6639e-05, 4.6680e-05, 7.3987e-06, 8.9994e-04,
        2.9125e-05, 2.1989e-03, 3.5574e-05, 1.9209e-04, 1.5319e-04, 2.9653e-05,
        1.0331e-04, 1.0759e-05, 2.5148e-05, 5.2852e-05, 1.4432e-05],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,022][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0639, 0.0019, 0.0483, 0.0041, 0.3093, 0.0293, 0.0209, 0.0951, 0.0066,
        0.0217, 0.0017, 0.0409, 0.0011, 0.0044, 0.3249, 0.0057, 0.0203],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,023][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0062, 0.0033, 0.0963, 0.0029, 0.0400, 0.0701, 0.0040, 0.5501, 0.0071,
        0.1051, 0.0099, 0.0040, 0.0233, 0.0128, 0.0337, 0.0276, 0.0035],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,024][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([4.4147e-04, 3.1509e-02, 7.2918e-04, 6.8239e-03, 3.7736e-06, 1.8167e-02,
        4.0955e-01, 1.3065e-06, 3.5336e-05, 6.0941e-07, 6.8699e-06, 4.3092e-01,
        7.0897e-07, 2.3633e-03, 2.3162e-06, 3.1644e-05, 9.9413e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,026][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.3414, 0.0239, 0.1091, 0.0523, 0.0658, 0.0275, 0.0287, 0.0239, 0.0377,
        0.0230, 0.0216, 0.0339, 0.0374, 0.0343, 0.0921, 0.0163, 0.0311],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,028][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0039, 0.0162, 0.0242, 0.0289, 0.0400, 0.0455, 0.0445, 0.0295, 0.0436,
        0.0559, 0.0741, 0.0758, 0.0779, 0.1257, 0.0822, 0.1167, 0.1155],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,029][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([8.3453e-04, 1.2397e-03, 2.0030e-04, 6.1655e-04, 2.2955e-04, 7.6317e-05,
        2.1833e-01, 9.2337e-05, 4.2316e-03, 2.3179e-04, 7.1562e-04, 5.1845e-04,
        1.1487e-04, 1.7815e-02, 2.5915e-04, 1.2810e-04, 7.5436e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,031][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.0053, 0.0122, 0.0150, 0.0129, 0.0346, 0.0996, 0.0191, 0.0104, 0.0057,
        0.1476, 0.0868, 0.0189, 0.0306, 0.0027, 0.0219, 0.3202, 0.0303, 0.1264],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,032][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([8.1773e-01, 7.0640e-02, 3.2612e-03, 1.5944e-02, 2.9184e-03, 1.1918e-02,
        1.9605e-02, 7.2663e-03, 9.8449e-03, 2.6253e-03, 4.8239e-03, 7.6602e-03,
        2.5729e-03, 9.7125e-03, 4.1778e-03, 1.5430e-03, 7.1538e-03, 5.9971e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,034][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.0988, 0.0506, 0.0499, 0.0533, 0.0525, 0.0478, 0.0488, 0.0509, 0.0465,
        0.0562, 0.0474, 0.0474, 0.0560, 0.0541, 0.0559, 0.0653, 0.0522, 0.0666],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,036][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.2601, 0.0374, 0.0455, 0.0452, 0.0416, 0.0434, 0.0385, 0.0321, 0.0354,
        0.0370, 0.0475, 0.0417, 0.0423, 0.0866, 0.0367, 0.0460, 0.0341, 0.0490],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,037][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.0175, 0.0701, 0.1010, 0.0482, 0.0682, 0.0566, 0.0306, 0.0481, 0.0220,
        0.0589, 0.0443, 0.0269, 0.1136, 0.0297, 0.0651, 0.0649, 0.0254, 0.1090],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,038][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([1.0809e-01, 8.6875e-01, 3.8293e-04, 1.0183e-03, 4.6862e-05, 4.4326e-03,
        3.6984e-04, 1.0956e-02, 6.6612e-04, 9.4821e-04, 1.1659e-03, 3.2230e-04,
        6.3100e-04, 1.4979e-04, 1.0865e-04, 5.6300e-04, 1.7875e-04, 1.2162e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,039][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([1.4889e-02, 6.1301e-03, 8.1733e-03, 8.5390e-03, 1.6123e-02, 5.1127e-03,
        3.2052e-01, 5.5236e-04, 7.9457e-03, 1.8060e-02, 2.8371e-04, 7.8892e-02,
        1.1363e-04, 9.4000e-03, 1.4439e-02, 1.5335e-05, 2.7607e-01, 2.1474e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,040][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0012, 0.0052, 0.0926, 0.0030, 0.0434, 0.0898, 0.0034, 0.1960, 0.0093,
        0.3753, 0.0104, 0.0017, 0.0303, 0.0124, 0.0316, 0.0870, 0.0026, 0.0050],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,041][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([2.3166e-04, 1.7583e-02, 9.1703e-04, 4.1103e-03, 1.7404e-05, 3.0290e-02,
        5.2145e-01, 3.2074e-06, 1.5591e-05, 1.2668e-06, 1.0115e-05, 2.7655e-01,
        2.5472e-06, 3.7541e-03, 1.4390e-05, 1.4345e-04, 1.4490e-01, 2.3717e-06],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,043][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.2497, 0.0372, 0.0468, 0.0369, 0.0407, 0.0616, 0.0431, 0.0273, 0.0344,
        0.0230, 0.0410, 0.0578, 0.0338, 0.0444, 0.0691, 0.0470, 0.0489, 0.0573],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,045][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0028, 0.0156, 0.0228, 0.0263, 0.0367, 0.0394, 0.0366, 0.0248, 0.0380,
        0.0510, 0.0653, 0.0656, 0.0659, 0.1126, 0.0739, 0.1037, 0.0933, 0.1260],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,046][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([9.1240e-04, 6.5529e-03, 5.4332e-04, 2.2719e-03, 5.1397e-04, 3.3753e-04,
        1.8514e-04, 2.9021e-04, 4.5948e-03, 8.3044e-04, 4.3895e-04, 5.0423e-04,
        2.6429e-03, 2.1050e-02, 2.1075e-04, 2.5324e-03, 2.6607e-04, 9.5532e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,048][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0015, 0.0056, 0.0051, 0.0063, 0.0223, 0.1525, 0.0190, 0.0091, 0.0065,
        0.1382, 0.0407, 0.0114, 0.0344, 0.0034, 0.0257, 0.2773, 0.0422, 0.1758,
        0.0231], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,050][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.7711, 0.0849, 0.0049, 0.0203, 0.0043, 0.0157, 0.0223, 0.0101, 0.0124,
        0.0036, 0.0060, 0.0089, 0.0034, 0.0109, 0.0052, 0.0020, 0.0081, 0.0009,
        0.0052], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,052][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0840, 0.0452, 0.0484, 0.0492, 0.0510, 0.0457, 0.0474, 0.0511, 0.0441,
        0.0538, 0.0453, 0.0459, 0.0548, 0.0505, 0.0543, 0.0640, 0.0512, 0.0635,
        0.0506], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,054][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2716, 0.0395, 0.0414, 0.0427, 0.0378, 0.0403, 0.0375, 0.0294, 0.0358,
        0.0335, 0.0450, 0.0406, 0.0389, 0.0722, 0.0330, 0.0398, 0.0331, 0.0468,
        0.0409], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,055][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0174, 0.0443, 0.1072, 0.0353, 0.0664, 0.0458, 0.0376, 0.0528, 0.0205,
        0.0535, 0.0392, 0.0330, 0.1034, 0.0224, 0.0648, 0.0775, 0.0336, 0.1178,
        0.0274], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,056][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.9058e-01, 8.0224e-01, 6.5439e-05, 1.0813e-04, 8.6149e-06, 1.9134e-03,
        7.4766e-05, 2.8834e-03, 9.5067e-05, 2.7911e-04, 3.5504e-04, 7.9367e-05,
        1.3324e-04, 2.2984e-05, 3.0788e-05, 1.1507e-04, 3.7621e-05, 8.1570e-04,
        1.6491e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,057][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.5308, 0.0014, 0.0195, 0.0059, 0.0035, 0.0684, 0.0517, 0.0178, 0.0034,
        0.0042, 0.0014, 0.0300, 0.0017, 0.0016, 0.0041, 0.1983, 0.0486, 0.0056,
        0.0020], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,058][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0071, 0.0149, 0.1013, 0.0079, 0.0667, 0.1368, 0.0037, 0.2167, 0.0202,
        0.1088, 0.0151, 0.0029, 0.0305, 0.0355, 0.0572, 0.0835, 0.0033, 0.0841,
        0.0037], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,059][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.7627e-04, 1.1181e-02, 6.5985e-04, 1.8320e-03, 3.9941e-06, 2.1353e-02,
        5.1624e-01, 8.5781e-07, 7.9300e-06, 5.8410e-07, 4.0175e-06, 3.1725e-01,
        6.0574e-07, 1.0362e-03, 2.6789e-06, 3.3882e-05, 1.3015e-01, 9.8643e-07,
        6.5485e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,061][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.3302, 0.0191, 0.0898, 0.0516, 0.0662, 0.0252, 0.0333, 0.0287, 0.0270,
        0.0244, 0.0211, 0.0410, 0.0313, 0.0271, 0.0679, 0.0177, 0.0319, 0.0408,
        0.0256], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,063][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0045, 0.0119, 0.0185, 0.0215, 0.0297, 0.0351, 0.0311, 0.0205, 0.0337,
        0.0412, 0.0571, 0.0556, 0.0569, 0.0972, 0.0599, 0.0923, 0.0833, 0.1090,
        0.1410], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,064][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.9534e-02, 1.1690e-02, 2.6929e-04, 2.0540e-02, 4.7190e-04, 4.9796e-04,
        1.7918e-03, 2.4359e-04, 2.5920e-02, 6.9456e-04, 3.4061e-03, 5.8496e-04,
        3.2862e-04, 5.6290e-02, 7.0221e-05, 2.7074e-04, 1.3702e-03, 8.3026e-05,
        8.5594e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,068][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:53,070][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[10265],
        [11375],
        [ 1421],
        [21695],
        [34114],
        [29161],
        [19634],
        [10546],
        [23760],
        [ 5465],
        [13070],
        [11423],
        [26237],
        [ 9012],
        [39007],
        [11563],
        [12207],
        [31075],
        [11205]], device='cuda:0')
[2024-07-24 10:17:53,072][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[15946],
        [18515],
        [   44],
        [29487],
        [38838],
        [35660],
        [28278],
        [15185],
        [30065],
        [12346],
        [32913],
        [28444],
        [20421],
        [17609],
        [42401],
        [ 8988],
        [25598],
        [29492],
        [13535]], device='cuda:0')
[2024-07-24 10:17:53,074][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[16018],
        [17189],
        [11624],
        [ 7826],
        [ 6312],
        [ 7936],
        [11107],
        [15427],
        [19405],
        [16819],
        [15702],
        [13470],
        [14155],
        [11126],
        [11220],
        [11630],
        [12077],
        [12577],
        [12126]], device='cuda:0')
[2024-07-24 10:17:53,075][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[13560],
        [12313],
        [12916],
        [12664],
        [12434],
        [13147],
        [13159],
        [13269],
        [13508],
        [13504],
        [13722],
        [13532],
        [13085],
        [13214],
        [12128],
        [12960],
        [13439],
        [12210],
        [13358]], device='cuda:0')
[2024-07-24 10:17:53,077][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[18439],
        [19497],
        [21550],
        [21564],
        [21813],
        [22100],
        [22914],
        [22976],
        [22760],
        [22848],
        [22874],
        [22820],
        [22323],
        [22083],
        [22171],
        [22392],
        [22753],
        [23014],
        [22995]], device='cuda:0')
[2024-07-24 10:17:53,079][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[18767],
        [19717],
        [17423],
        [18849],
        [19010],
        [16154],
        [14879],
        [15858],
        [15602],
        [15338],
        [15125],
        [14311],
        [14141],
        [14862],
        [15185],
        [14896],
        [14348],
        [14728],
        [14614]], device='cuda:0')
[2024-07-24 10:17:53,081][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 6173],
        [15802],
        [13928],
        [10253],
        [11472],
        [ 9312],
        [ 8660],
        [ 9553],
        [ 9278],
        [10079],
        [10586],
        [10322],
        [ 8767],
        [ 9179],
        [ 9578],
        [ 8615],
        [ 8692],
        [ 7906],
        [ 7418]], device='cuda:0')
[2024-07-24 10:17:53,083][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[14500],
        [12739],
        [10624],
        [13867],
        [13625],
        [11864],
        [24297],
        [26179],
        [27144],
        [31897],
        [26568],
        [31726],
        [38812],
        [41851],
        [42458],
        [41331],
        [40791],
        [41420],
        [34253]], device='cuda:0')
[2024-07-24 10:17:53,086][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 5688],
        [ 5603],
        [ 1016],
        [ 1542],
        [18476],
        [ 7969],
        [13077],
        [18439],
        [ 7451],
        [12474],
        [ 3909],
        [ 3720],
        [11628],
        [ 2271],
        [19066],
        [ 8808],
        [15438],
        [11860],
        [ 6117]], device='cuda:0')
[2024-07-24 10:17:53,088][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[8260],
        [8531],
        [2798],
        [   6],
        [2270],
        [  71],
        [  36],
        [6394],
        [ 906],
        [ 374],
        [ 143],
        [ 233],
        [7806],
        [ 305],
        [8678],
        [4966],
        [1666],
        [8517],
        [1406]], device='cuda:0')
[2024-07-24 10:17:53,090][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[43719],
        [44245],
        [44231],
        [44325],
        [44158],
        [44069],
        [44087],
        [44033],
        [43987],
        [43949],
        [43889],
        [43814],
        [43757],
        [43746],
        [43672],
        [43560],
        [43526],
        [43559],
        [43492]], device='cuda:0')
[2024-07-24 10:17:53,091][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[23957],
        [27105],
        [28598],
        [30193],
        [29810],
        [32412],
        [31327],
        [31439],
        [31053],
        [30874],
        [32022],
        [31686],
        [31105],
        [31942],
        [31069],
        [31588],
        [31457],
        [30683],
        [31335]], device='cuda:0')
[2024-07-24 10:17:53,093][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[16587],
        [42057],
        [41133],
        [40167],
        [39785],
        [38131],
        [36464],
        [34088],
        [35630],
        [33342],
        [31070],
        [31690],
        [29601],
        [28115],
        [30139],
        [30855],
        [31002],
        [29798],
        [32150]], device='cuda:0')
[2024-07-24 10:17:53,095][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[23870],
        [17883],
        [26821],
        [12448],
        [27242],
        [ 6562],
        [ 3434],
        [23682],
        [ 3286],
        [ 3788],
        [ 3829],
        [ 3127],
        [22043],
        [ 5385],
        [39657],
        [ 4974],
        [ 6448],
        [14340],
        [ 9630]], device='cuda:0')
[2024-07-24 10:17:53,097][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 9385],
        [ 9190],
        [11380],
        [ 5071],
        [21062],
        [42677],
        [26069],
        [17647],
        [15855],
        [21806],
        [34427],
        [27195],
        [40214],
        [17304],
        [36344],
        [20974],
        [26931],
        [35864],
        [16182]], device='cuda:0')
[2024-07-24 10:17:53,099][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[20914],
        [23659],
        [22347],
        [31199],
        [26020],
        [33703],
        [30960],
        [28981],
        [28966],
        [20707],
        [24235],
        [25707],
        [23611],
        [23042],
        [27369],
        [25157],
        [20715],
        [21297],
        [20370]], device='cuda:0')
[2024-07-24 10:17:53,101][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[1768],
        [1772],
        [1760],
        [1764],
        [1760],
        [1778],
        [1789],
        [1796],
        [1803],
        [1791],
        [1796],
        [1823],
        [1829],
        [1837],
        [1867],
        [1848],
        [1889],
        [1845],
        [1879]], device='cuda:0')
[2024-07-24 10:17:53,103][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[24830],
        [25757],
        [25594],
        [25377],
        [24285],
        [24248],
        [24330],
        [24010],
        [23955],
        [23912],
        [23716],
        [23781],
        [23612],
        [23774],
        [23438],
        [22936],
        [22933],
        [22762],
        [22783]], device='cuda:0')
[2024-07-24 10:17:53,105][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 4772],
        [14516],
        [14080],
        [14490],
        [14097],
        [15173],
        [15568],
        [15469],
        [15853],
        [15927],
        [15952],
        [16197],
        [16324],
        [16317],
        [16526],
        [16590],
        [16695],
        [16810],
        [16912]], device='cuda:0')
[2024-07-24 10:17:53,107][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[24610],
        [30653],
        [25081],
        [26051],
        [22595],
        [23247],
        [24374],
        [21112],
        [22094],
        [21842],
        [20333],
        [19367],
        [21510],
        [19683],
        [21298],
        [20540],
        [19995],
        [18977],
        [18315]], device='cuda:0')
[2024-07-24 10:17:53,109][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[24576],
        [17814],
        [20677],
        [19054],
        [19478],
        [17817],
        [18371],
        [18105],
        [18676],
        [17779],
        [17819],
        [18991],
        [17946],
        [21141],
        [17787],
        [17764],
        [17960],
        [17834],
        [17796]], device='cuda:0')
[2024-07-24 10:17:53,110][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[30920],
        [31090],
        [36981],
        [32621],
        [40952],
        [40551],
        [39000],
        [37750],
        [31975],
        [41184],
        [39244],
        [36075],
        [29528],
        [40269],
        [40551],
        [38218],
        [38372],
        [37889],
        [29814]], device='cuda:0')
[2024-07-24 10:17:53,112][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[17788],
        [12646],
        [48584],
        [48775],
        [47847],
        [46539],
        [44801],
        [16839],
        [36250],
        [30441],
        [21391],
        [19332],
        [38761],
        [27034],
        [23055],
        [31861],
        [13327],
        [27490],
        [20575]], device='cuda:0')
[2024-07-24 10:17:53,114][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[10215],
        [18387],
        [12784],
        [18257],
        [13082],
        [34245],
        [16941],
        [16460],
        [16693],
        [17759],
        [16859],
        [18671],
        [18615],
        [18244],
        [19567],
        [19862],
        [19271],
        [18578],
        [18336]], device='cuda:0')
[2024-07-24 10:17:53,116][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[6355],
        [6380],
        [5682],
        [5421],
        [4063],
        [5062],
        [4796],
        [4746],
        [4269],
        [4193],
        [4311],
        [4374],
        [4744],
        [4477],
        [3545],
        [3971],
        [4128],
        [4074],
        [4227]], device='cuda:0')
[2024-07-24 10:17:53,118][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[8341],
        [4955],
        [4262],
        [4096],
        [4428],
        [4040],
        [4188],
        [4295],
        [4509],
        [4601],
        [4591],
        [4755],
        [4629],
        [4943],
        [4939],
        [4776],
        [4870],
        [4782],
        [4767]], device='cuda:0')
[2024-07-24 10:17:53,120][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[22984],
        [22111],
        [11122],
        [11130],
        [10763],
        [11368],
        [29715],
        [13159],
        [16151],
        [10025],
        [19803],
        [28127],
        [24472],
        [ 7667],
        [ 4608],
        [11806],
        [23903],
        [24494],
        [12091]], device='cuda:0')
[2024-07-24 10:17:53,122][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[29792],
        [30776],
        [30861],
        [28784],
        [27868],
        [23336],
        [23969],
        [31989],
        [34713],
        [32173],
        [33313],
        [32811],
        [32809],
        [37291],
        [29766],
        [34358],
        [33590],
        [34454],
        [39589]], device='cuda:0')
[2024-07-24 10:17:53,124][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[21394],
        [39966],
        [25571],
        [29783],
        [12039],
        [ 1895],
        [15842],
        [31959],
        [26467],
        [16479],
        [ 8320],
        [14084],
        [ 5416],
        [24444],
        [23999],
        [15690],
        [18350],
        [ 9452],
        [27555]], device='cuda:0')
[2024-07-24 10:17:53,126][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[23314],
        [23314],
        [23314],
        [23314],
        [23314],
        [23314],
        [23314],
        [23314],
        [23314],
        [23314],
        [23314],
        [23314],
        [23314],
        [23314],
        [23314],
        [23314],
        [23314],
        [23314],
        [23314]], device='cuda:0')
[2024-07-24 10:17:53,160][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:53,162][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,164][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,166][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,167][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,168][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,168][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,169][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,170][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,170][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,171][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,172][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,173][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,174][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3105, 0.6895], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,174][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9282, 0.0718], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,176][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6963, 0.3037], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,178][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.8689, 0.1311], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,179][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0246, 0.9754], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,180][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1040, 0.8960], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,182][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2296, 0.7704], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,183][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5696, 0.4304], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,185][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9041, 0.0959], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,187][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.5455, 0.4545], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,188][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.5151, 0.4849], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,189][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0369, 0.9631], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,189][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Jamie] are: tensor([0.1374, 0.3405, 0.5221], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,190][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Jamie] are: tensor([0.0605, 0.7233, 0.2162], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,191][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Jamie] are: tensor([0.4090, 0.5440, 0.0470], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,191][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Jamie] are: tensor([0.8076, 0.1095, 0.0828], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,193][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Jamie] are: tensor([0.0071, 0.8213, 0.1715], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,195][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Jamie] are: tensor([0.0465, 0.7759, 0.1776], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,197][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Jamie] are: tensor([0.1748, 0.4862, 0.3390], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,198][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Jamie] are: tensor([0.3336, 0.2745, 0.3919], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,200][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Jamie] are: tensor([0.3794, 0.6018, 0.0189], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,202][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Jamie] are: tensor([0.4044, 0.4038, 0.1918], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,204][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Jamie] are: tensor([0.1273, 0.2359, 0.6368], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,205][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Jamie] are: tensor([0.0234, 0.4703, 0.5063], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,206][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0969, 0.2278, 0.3721, 0.3031], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,207][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.5952, 0.1622, 0.1885, 0.0541], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,207][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1546, 0.1279, 0.6731, 0.0444], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,208][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.8023, 0.0755, 0.0918, 0.0305], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,209][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0211, 0.3639, 0.2176, 0.3974], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,211][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0419, 0.4161, 0.3602, 0.1818], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,212][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([6.1461e-04, 2.2157e-02, 9.7065e-02, 8.8016e-01], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,214][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1740, 0.1144, 0.2776, 0.4340], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,215][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3937, 0.3245, 0.2310, 0.0509], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,217][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2885, 0.2439, 0.3641, 0.1035], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,219][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1556, 0.1676, 0.5208, 0.1560], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,220][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0193, 0.3925, 0.3222, 0.2660], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,222][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0557, 0.1476, 0.2326, 0.2049, 0.3592], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,223][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0360, 0.2103, 0.3822, 0.1905, 0.1810], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,224][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0725, 0.1059, 0.6152, 0.1864, 0.0199], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,224][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.8609, 0.0380, 0.0740, 0.0193, 0.0078], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,225][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0045, 0.6569, 0.1355, 0.1746, 0.0285], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,226][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0186, 0.3179, 0.2331, 0.3553, 0.0751], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,227][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0289, 0.1346, 0.0321, 0.5657, 0.2387], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,229][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.1113, 0.0965, 0.1335, 0.4084, 0.2502], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,231][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.2887, 0.2901, 0.1113, 0.2790, 0.0308], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,232][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.3297, 0.1619, 0.2790, 0.1443, 0.0852], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,234][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0715, 0.1477, 0.4326, 0.1238, 0.2244], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,236][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0190, 0.2833, 0.2462, 0.2766, 0.1749], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,237][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0486, 0.1153, 0.1916, 0.1633, 0.2884, 0.1928], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,239][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.4151, 0.0759, 0.1306, 0.2030, 0.0990, 0.0765], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,240][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0684, 0.1482, 0.4219, 0.2444, 0.0868, 0.0303], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,241][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.7432, 0.0435, 0.0735, 0.0421, 0.0764, 0.0213], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,241][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0048, 0.4766, 0.0619, 0.3669, 0.0395, 0.0504], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,242][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0276, 0.2564, 0.1791, 0.2288, 0.2136, 0.0945], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,243][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ had] are: tensor([4.6227e-04, 5.4069e-02, 1.9461e-02, 7.2361e-01, 9.9963e-02, 1.0244e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,244][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0859, 0.0934, 0.1284, 0.3118, 0.2494, 0.1311], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,246][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1388, 0.4516, 0.1251, 0.0717, 0.1882, 0.0246], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,248][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.1668, 0.1871, 0.1596, 0.1320, 0.3137, 0.0407], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,249][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0719, 0.1151, 0.3616, 0.0847, 0.2222, 0.1446], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,250][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0122, 0.2284, 0.1823, 0.1475, 0.1707, 0.2589], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,252][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0394, 0.0952, 0.1564, 0.1301, 0.2356, 0.1610, 0.1823],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,254][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1476, 0.0605, 0.3443, 0.2269, 0.1046, 0.0854, 0.0307],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,256][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1753, 0.1354, 0.1046, 0.2454, 0.0600, 0.2711, 0.0082],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,257][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.7789, 0.0346, 0.0749, 0.0315, 0.0455, 0.0225, 0.0120],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,258][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0170, 0.1840, 0.1178, 0.3065, 0.0958, 0.0877, 0.1912],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,258][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0224, 0.2264, 0.1366, 0.1928, 0.1276, 0.2720, 0.0221],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,259][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([2.4970e-04, 7.9286e-03, 3.7928e-03, 8.7096e-02, 3.4378e-02, 5.2238e-02,
        8.1432e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,260][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0800, 0.0679, 0.1200, 0.2504, 0.2266, 0.0951, 0.1601],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,261][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1041, 0.0943, 0.0384, 0.1474, 0.0508, 0.5595, 0.0056],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,263][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1598, 0.1317, 0.1591, 0.0786, 0.3424, 0.0807, 0.0478],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,265][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0920, 0.0940, 0.2864, 0.0928, 0.1719, 0.1418, 0.1211],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,266][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0117, 0.1638, 0.1286, 0.1248, 0.1127, 0.1928, 0.2656],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,268][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0306, 0.0733, 0.1175, 0.1042, 0.1736, 0.1319, 0.1510, 0.2180],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,270][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.1853, 0.0455, 0.1538, 0.0538, 0.0942, 0.0084, 0.0179, 0.4411],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,272][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0538, 0.0952, 0.3354, 0.1244, 0.0725, 0.1515, 0.1540, 0.0132],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,273][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.7031, 0.0500, 0.0749, 0.0330, 0.0286, 0.0560, 0.0242, 0.0301],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,274][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0030, 0.3810, 0.0811, 0.2419, 0.0922, 0.0668, 0.1195, 0.0145],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,275][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0139, 0.2193, 0.1392, 0.2221, 0.1121, 0.1992, 0.0418, 0.0523],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,276][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0005, 0.0611, 0.0215, 0.3303, 0.0615, 0.0427, 0.4638, 0.0186],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,277][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0765, 0.0705, 0.1006, 0.2534, 0.1714, 0.0883, 0.1499, 0.0894],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,277][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0322, 0.1870, 0.0328, 0.0803, 0.0160, 0.6379, 0.0115, 0.0023],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,279][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.1352, 0.1461, 0.1380, 0.1166, 0.1469, 0.1505, 0.1377, 0.0290],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,280][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0485, 0.0790, 0.2374, 0.0623, 0.1280, 0.1085, 0.0869, 0.2494],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,282][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0084, 0.1215, 0.0760, 0.0764, 0.0727, 0.1183, 0.1660, 0.3608],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,284][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0287, 0.0651, 0.1060, 0.0879, 0.1530, 0.1080, 0.1229, 0.1914, 0.1369],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,285][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.4964, 0.0168, 0.0071, 0.1066, 0.0102, 0.0023, 0.2062, 0.0902, 0.0643],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,287][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0442, 0.0230, 0.0596, 0.0573, 0.0643, 0.0662, 0.0550, 0.6272, 0.0032],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,289][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.7221, 0.0332, 0.0590, 0.0239, 0.0184, 0.0411, 0.0274, 0.0545, 0.0205],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,290][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0072, 0.0999, 0.0461, 0.1644, 0.0421, 0.0447, 0.1435, 0.1128, 0.3394],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,291][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0196, 0.1729, 0.1775, 0.1771, 0.1308, 0.1788, 0.0399, 0.0753, 0.0280],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,292][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ of] are: tensor([2.3073e-04, 2.3897e-03, 5.8165e-03, 7.2207e-02, 3.6548e-02, 4.1912e-02,
        5.9422e-01, 3.6150e-02, 2.1053e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,293][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0562, 0.0431, 0.0762, 0.1663, 0.1199, 0.0641, 0.1073, 0.0558, 0.3111],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,294][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0329, 0.0619, 0.0734, 0.1201, 0.1073, 0.5618, 0.0200, 0.0194, 0.0033],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,295][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.1395, 0.0887, 0.1402, 0.0703, 0.2469, 0.0896, 0.1101, 0.0733, 0.0415],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,296][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0539, 0.0754, 0.2351, 0.0681, 0.1228, 0.1024, 0.0934, 0.1776, 0.0714],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,298][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0090, 0.0953, 0.0634, 0.0683, 0.0592, 0.0987, 0.1438, 0.2661, 0.1962],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,299][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0228, 0.0528, 0.0805, 0.0758, 0.1187, 0.0987, 0.1118, 0.1530, 0.1163,
        0.1696], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,301][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.1958, 0.0457, 0.0939, 0.1887, 0.3264, 0.0024, 0.0640, 0.0702, 0.0058,
        0.0071], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,303][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0568, 0.0430, 0.0977, 0.0691, 0.0507, 0.2414, 0.0461, 0.1139, 0.2718,
        0.0095], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,305][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.7145, 0.0271, 0.0450, 0.0170, 0.0172, 0.0207, 0.0177, 0.0972, 0.0300,
        0.0136], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,306][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0090, 0.3053, 0.0930, 0.1458, 0.0672, 0.0769, 0.0849, 0.0657, 0.1271,
        0.0251], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,308][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0152, 0.1796, 0.1174, 0.1547, 0.1094, 0.1066, 0.0430, 0.1093, 0.0770,
        0.0878], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,309][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0006, 0.0180, 0.0025, 0.0523, 0.0171, 0.0061, 0.2467, 0.0162, 0.3674,
        0.2731], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,310][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0466, 0.0456, 0.0630, 0.1895, 0.1082, 0.0683, 0.0939, 0.0511, 0.2852,
        0.0486], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,311][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([3.0890e-02, 2.0007e-02, 1.6819e-02, 1.7914e-02, 1.9144e-03, 8.4841e-01,
        1.0210e-02, 2.1361e-02, 3.1797e-02, 6.7777e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,311][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.1473, 0.0958, 0.1659, 0.0522, 0.2213, 0.0584, 0.0655, 0.0740, 0.0990,
        0.0205], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,312][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0360, 0.0590, 0.2027, 0.0477, 0.1073, 0.0896, 0.0673, 0.2238, 0.0471,
        0.1195], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,314][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0073, 0.0830, 0.0518, 0.0516, 0.0469, 0.0702, 0.1005, 0.2311, 0.1338,
        0.2238], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,316][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0213, 0.0473, 0.0759, 0.0643, 0.1092, 0.0791, 0.0901, 0.1364, 0.1000,
        0.1649, 0.1114], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,318][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.1809, 0.0887, 0.0331, 0.2142, 0.0471, 0.0102, 0.1781, 0.2015, 0.0190,
        0.0108, 0.0164], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,319][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0639, 0.1083, 0.0809, 0.1071, 0.0533, 0.1360, 0.0993, 0.1214, 0.1705,
        0.0500, 0.0092], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,321][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.5872, 0.0245, 0.0612, 0.0218, 0.0355, 0.0345, 0.0279, 0.0736, 0.0711,
        0.0384, 0.0244], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,323][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0108, 0.1660, 0.0851, 0.1420, 0.0358, 0.0396, 0.1090, 0.0581, 0.2054,
        0.0946, 0.0536], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,325][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0156, 0.1426, 0.0974, 0.1408, 0.0752, 0.1549, 0.0492, 0.1255, 0.0604,
        0.1169, 0.0215], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,326][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ at] are: tensor([9.2719e-05, 1.2959e-02, 3.1866e-03, 3.9517e-02, 1.6213e-02, 8.1032e-03,
        1.4265e-01, 1.0493e-02, 2.1751e-01, 2.5177e-01, 2.9750e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,327][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0525, 0.0316, 0.0594, 0.1260, 0.1061, 0.0535, 0.0844, 0.0599, 0.1961,
        0.0522, 0.1783], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,328][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0239, 0.0165, 0.0525, 0.0225, 0.0037, 0.6555, 0.0527, 0.1228, 0.0388,
        0.0075, 0.0036], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,329][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1269, 0.0887, 0.0928, 0.0477, 0.1655, 0.0562, 0.0825, 0.0768, 0.0397,
        0.2079, 0.0152], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,329][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0495, 0.0495, 0.1683, 0.0478, 0.1010, 0.0838, 0.0710, 0.1935, 0.0495,
        0.1014, 0.0847], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,331][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0070, 0.0639, 0.0415, 0.0399, 0.0377, 0.0612, 0.0841, 0.1942, 0.1080,
        0.2073, 0.1552], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,333][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0169, 0.0396, 0.0652, 0.0550, 0.0965, 0.0681, 0.0780, 0.1234, 0.0884,
        0.1525, 0.0997, 0.1165], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,334][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1037, 0.0161, 0.2110, 0.0813, 0.0526, 0.0302, 0.0179, 0.3410, 0.0298,
        0.0316, 0.0167, 0.0681], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,336][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0625, 0.0617, 0.0567, 0.1219, 0.0332, 0.1504, 0.0285, 0.1155, 0.2477,
        0.0386, 0.0774, 0.0060], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,338][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.5846, 0.0219, 0.0438, 0.0213, 0.0289, 0.0223, 0.0214, 0.0717, 0.0407,
        0.0478, 0.0740, 0.0215], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,340][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0149, 0.1040, 0.0718, 0.0830, 0.0650, 0.0405, 0.0817, 0.0736, 0.1433,
        0.1298, 0.0954, 0.0970], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,341][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0138, 0.1317, 0.0841, 0.1487, 0.0948, 0.1590, 0.0308, 0.1083, 0.0402,
        0.1310, 0.0403, 0.0174], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,343][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ the] are: tensor([2.1543e-05, 7.8091e-04, 5.4002e-04, 6.2572e-03, 3.9626e-03, 3.8514e-03,
        5.0238e-02, 7.6926e-03, 4.3044e-02, 1.2268e-01, 1.7503e-01, 5.8590e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,344][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0349, 0.0250, 0.0461, 0.1125, 0.0731, 0.0403, 0.0676, 0.0415, 0.1900,
        0.0383, 0.1546, 0.1762], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,345][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0199, 0.0312, 0.0199, 0.0827, 0.0062, 0.2614, 0.0124, 0.0547, 0.1012,
        0.0516, 0.3578, 0.0009], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,345][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1664, 0.1216, 0.0983, 0.0550, 0.1465, 0.0551, 0.0284, 0.0653, 0.0498,
        0.1021, 0.0737, 0.0378], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,346][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0432, 0.0553, 0.1531, 0.0533, 0.0842, 0.0873, 0.0707, 0.1627, 0.0511,
        0.0925, 0.0789, 0.0675], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,347][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0063, 0.0515, 0.0360, 0.0322, 0.0314, 0.0517, 0.0666, 0.1544, 0.0867,
        0.1686, 0.1236, 0.1909], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,349][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0134, 0.0330, 0.0522, 0.0477, 0.0797, 0.0627, 0.0721, 0.1015, 0.0760,
        0.1170, 0.0861, 0.0989, 0.1596], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,351][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.1045, 0.0420, 0.1014, 0.2220, 0.0749, 0.0012, 0.0680, 0.0657, 0.0280,
        0.0228, 0.0593, 0.1776, 0.0324], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,353][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0408, 0.0561, 0.1753, 0.0666, 0.0260, 0.0263, 0.0914, 0.1153, 0.1318,
        0.1776, 0.0332, 0.0527, 0.0069], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,354][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.3411, 0.0351, 0.0606, 0.0341, 0.0310, 0.0531, 0.0293, 0.0847, 0.0721,
        0.0623, 0.0714, 0.0530, 0.0721], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,357][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0067, 0.4036, 0.0721, 0.1410, 0.0393, 0.0331, 0.0735, 0.0327, 0.0651,
        0.0343, 0.0472, 0.0427, 0.0088], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,358][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0081, 0.1311, 0.0848, 0.1232, 0.0840, 0.1214, 0.0458, 0.0678, 0.0685,
        0.1155, 0.0563, 0.0521, 0.0413], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,360][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ store] are: tensor([2.6484e-04, 5.1169e-03, 5.1059e-04, 8.9457e-03, 3.9232e-03, 1.0828e-03,
        5.0260e-02, 3.3470e-03, 7.7274e-02, 6.0150e-02, 9.2659e-02, 6.6992e-01,
        2.6550e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,362][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0388, 0.0267, 0.0411, 0.1161, 0.0692, 0.0415, 0.0543, 0.0357, 0.1876,
        0.0368, 0.1588, 0.1412, 0.0521], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,363][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ store] are: tensor([3.1563e-02, 4.8356e-02, 5.8586e-03, 4.4521e-02, 1.3528e-03, 2.4733e-02,
        4.7301e-02, 3.5542e-02, 1.2283e-01, 1.7836e-02, 5.8871e-01, 3.1192e-02,
        2.0528e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,365][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0793, 0.0638, 0.0900, 0.0578, 0.0668, 0.0387, 0.0735, 0.0635, 0.0620,
        0.1554, 0.1045, 0.1132, 0.0316], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,366][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0252, 0.0588, 0.1368, 0.0447, 0.0688, 0.0683, 0.0563, 0.1569, 0.0396,
        0.0984, 0.0658, 0.0567, 0.1238], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,367][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0058, 0.0479, 0.0299, 0.0307, 0.0234, 0.0408, 0.0564, 0.1260, 0.0707,
        0.1294, 0.1081, 0.1583, 0.1726], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,368][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0134, 0.0313, 0.0498, 0.0437, 0.0740, 0.0543, 0.0614, 0.0940, 0.0670,
        0.1146, 0.0760, 0.0877, 0.1545, 0.0784], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,369][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.2947, 0.0290, 0.0238, 0.0479, 0.0268, 0.0040, 0.1700, 0.1086, 0.0168,
        0.0022, 0.0218, 0.2277, 0.0020, 0.0245], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,370][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0375, 0.0177, 0.1245, 0.0339, 0.0420, 0.1106, 0.0873, 0.2828, 0.0472,
        0.0671, 0.0400, 0.0230, 0.0831, 0.0032], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,372][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.6009, 0.0226, 0.0419, 0.0172, 0.0234, 0.0295, 0.0087, 0.0436, 0.0258,
        0.0275, 0.0319, 0.0159, 0.0876, 0.0236], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,374][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0279, 0.0355, 0.0438, 0.0481, 0.0443, 0.0298, 0.0721, 0.0510, 0.0934,
        0.0846, 0.0652, 0.1093, 0.0352, 0.2598], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,376][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0105, 0.0970, 0.0731, 0.1030, 0.0634, 0.1339, 0.0377, 0.1049, 0.0558,
        0.0925, 0.0586, 0.0377, 0.0783, 0.0534], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,377][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [.] are: tensor([9.4916e-05, 2.6805e-04, 4.4380e-04, 4.3765e-03, 3.9158e-03, 1.6208e-03,
        4.4372e-02, 1.5118e-03, 2.2435e-02, 4.9714e-02, 8.5759e-02, 5.1074e-01,
        6.1153e-02, 2.1360e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,379][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0257, 0.0191, 0.0416, 0.0843, 0.0799, 0.0310, 0.0530, 0.0299, 0.1365,
        0.0339, 0.1121, 0.1257, 0.0485, 0.1789], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,381][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0647, 0.0223, 0.0637, 0.0374, 0.0418, 0.1504, 0.0624, 0.0818, 0.0706,
        0.0304, 0.3357, 0.0282, 0.0089, 0.0018], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,383][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1104, 0.0715, 0.0600, 0.0590, 0.0853, 0.0602, 0.0587, 0.0730, 0.0586,
        0.0677, 0.0773, 0.0891, 0.0740, 0.0553], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,384][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0310, 0.0416, 0.1510, 0.0408, 0.0884, 0.0644, 0.0629, 0.1368, 0.0445,
        0.0738, 0.0599, 0.0588, 0.1152, 0.0310], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,385][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0057, 0.0380, 0.0312, 0.0255, 0.0272, 0.0356, 0.0503, 0.1213, 0.0585,
        0.1247, 0.0784, 0.1260, 0.1781, 0.0994], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,385][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0091, 0.0245, 0.0396, 0.0361, 0.0602, 0.0488, 0.0563, 0.0854, 0.0611,
        0.1035, 0.0684, 0.0816, 0.1448, 0.0745, 0.1061], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,386][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0067, 0.0461, 0.1057, 0.0436, 0.0474, 0.0063, 0.0188, 0.0108, 0.0018,
        0.0165, 0.0208, 0.0623, 0.1107, 0.4486, 0.0539], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,387][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0228, 0.0282, 0.2124, 0.0591, 0.0079, 0.0882, 0.0964, 0.0690, 0.2094,
        0.0433, 0.0446, 0.0567, 0.0455, 0.0119, 0.0046], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,389][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.6119, 0.0097, 0.0364, 0.0065, 0.0041, 0.0123, 0.0083, 0.0467, 0.0173,
        0.0298, 0.0529, 0.0207, 0.0955, 0.0400, 0.0079], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,391][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0024, 0.3721, 0.1325, 0.1207, 0.0264, 0.0243, 0.0640, 0.0295, 0.0778,
        0.0323, 0.0325, 0.0241, 0.0137, 0.0319, 0.0159], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,393][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0055, 0.0988, 0.0693, 0.1117, 0.0220, 0.0814, 0.0431, 0.0894, 0.0742,
        0.1191, 0.0484, 0.0414, 0.0883, 0.0912, 0.0162], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,394][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([1.3160e-03, 2.0786e-03, 2.5147e-04, 3.6351e-03, 1.9698e-03, 5.4082e-04,
        2.4151e-02, 1.7393e-03, 4.4873e-02, 2.1027e-02, 3.9720e-02, 4.4887e-01,
        2.6549e-02, 3.3948e-01, 4.3797e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,396][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0233, 0.0197, 0.0277, 0.0867, 0.0495, 0.0367, 0.0457, 0.0233, 0.1277,
        0.0229, 0.1121, 0.1206, 0.0385, 0.1959, 0.0696], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,398][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.0611, 0.0486, 0.0217, 0.0522, 0.0053, 0.1190, 0.0393, 0.0835, 0.2478,
        0.0248, 0.1613, 0.0286, 0.0870, 0.0147, 0.0050], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,400][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.1435, 0.0472, 0.0704, 0.0325, 0.0167, 0.0454, 0.0663, 0.0308, 0.0348,
        0.1152, 0.0721, 0.1264, 0.0786, 0.0864, 0.0336], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,401][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0220, 0.0472, 0.1347, 0.0400, 0.0682, 0.0638, 0.0501, 0.1209, 0.0300,
        0.0850, 0.0503, 0.0534, 0.1393, 0.0315, 0.0635], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,402][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0050, 0.0368, 0.0282, 0.0284, 0.0173, 0.0400, 0.0483, 0.0811, 0.0579,
        0.0874, 0.0955, 0.1178, 0.1335, 0.1139, 0.1089], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,403][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0101, 0.0239, 0.0397, 0.0352, 0.0598, 0.0431, 0.0504, 0.0752, 0.0547,
        0.0915, 0.0625, 0.0727, 0.1261, 0.0660, 0.1056, 0.0834],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,404][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0035, 0.0235, 0.0956, 0.0177, 0.0178, 0.0518, 0.0008, 0.1931, 0.0068,
        0.0567, 0.0118, 0.0091, 0.1497, 0.3140, 0.0319, 0.0163],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,405][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0497, 0.0708, 0.1911, 0.0992, 0.0404, 0.0818, 0.0365, 0.0850, 0.0969,
        0.0394, 0.0296, 0.0435, 0.0748, 0.0262, 0.0258, 0.0090],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,407][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.3168, 0.0104, 0.0447, 0.0103, 0.0291, 0.0134, 0.0103, 0.0781, 0.0433,
        0.0707, 0.0466, 0.0323, 0.1167, 0.0693, 0.0885, 0.0194],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,409][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0068, 0.2650, 0.0718, 0.1316, 0.0435, 0.0300, 0.0743, 0.0425, 0.0756,
        0.0412, 0.0384, 0.0453, 0.0124, 0.0615, 0.0404, 0.0197],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,411][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0087, 0.1138, 0.0676, 0.1044, 0.0598, 0.0554, 0.0377, 0.0681, 0.0536,
        0.0954, 0.0487, 0.0541, 0.0814, 0.0911, 0.0435, 0.0166],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,412][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([3.7534e-05, 5.5975e-03, 4.5121e-04, 1.1796e-02, 2.8057e-03, 1.5290e-03,
        2.6279e-02, 2.1905e-03, 5.3720e-02, 5.3995e-02, 8.9917e-02, 4.7800e-01,
        1.1466e-02, 2.1659e-01, 1.3324e-02, 3.2306e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,414][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0228, 0.0227, 0.0282, 0.0806, 0.0472, 0.0304, 0.0471, 0.0209, 0.1183,
        0.0245, 0.1046, 0.1070, 0.0410, 0.1796, 0.0654, 0.0596],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,416][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0696, 0.1332, 0.0532, 0.0758, 0.0518, 0.0515, 0.0551, 0.1430, 0.1129,
        0.0322, 0.0602, 0.0595, 0.0126, 0.0316, 0.0531, 0.0048],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,418][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0553, 0.0361, 0.0366, 0.0204, 0.1051, 0.0171, 0.0443, 0.0217, 0.0311,
        0.0256, 0.0935, 0.0580, 0.0956, 0.0862, 0.2661, 0.0072],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,418][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0229, 0.0387, 0.1027, 0.0340, 0.0619, 0.0531, 0.0450, 0.1134, 0.0315,
        0.0838, 0.0512, 0.0446, 0.1456, 0.0263, 0.0588, 0.0866],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,419][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0053, 0.0403, 0.0202, 0.0223, 0.0137, 0.0281, 0.0403, 0.0721, 0.0510,
        0.0761, 0.0758, 0.0970, 0.0998, 0.0978, 0.0823, 0.1780],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,420][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0090, 0.0223, 0.0382, 0.0323, 0.0569, 0.0380, 0.0436, 0.0701, 0.0482,
        0.0892, 0.0549, 0.0649, 0.1241, 0.0609, 0.1032, 0.0764, 0.0677],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,421][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0407, 0.0205, 0.1143, 0.0580, 0.0330, 0.0222, 0.0070, 0.3967, 0.0135,
        0.0402, 0.0138, 0.0243, 0.0142, 0.1492, 0.0409, 0.0041, 0.0074],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,423][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0715, 0.0557, 0.0388, 0.1080, 0.0272, 0.1280, 0.0031, 0.1038, 0.2219,
        0.0249, 0.0553, 0.0227, 0.0445, 0.0128, 0.0167, 0.0634, 0.0018],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,425][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.4205, 0.0117, 0.0371, 0.0118, 0.0221, 0.0086, 0.0036, 0.0385, 0.0262,
        0.0463, 0.0389, 0.0284, 0.1197, 0.0467, 0.0534, 0.0732, 0.0134],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,426][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0130, 0.0764, 0.0643, 0.0792, 0.0569, 0.0327, 0.0499, 0.0496, 0.0896,
        0.0503, 0.0534, 0.0625, 0.0218, 0.1371, 0.0385, 0.0578, 0.0671],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,428][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0109, 0.1063, 0.0607, 0.0912, 0.0598, 0.1250, 0.0099, 0.0606, 0.0416,
        0.0890, 0.0354, 0.0310, 0.0861, 0.0931, 0.0449, 0.0483, 0.0061],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,429][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([1.8855e-05, 5.9523e-04, 1.4574e-04, 2.2421e-03, 1.3479e-03, 8.9606e-04,
        1.3776e-02, 2.2327e-03, 2.1696e-02, 4.4373e-02, 7.0149e-02, 3.2797e-01,
        1.7655e-02, 1.7986e-01, 1.9243e-02, 4.4974e-02, 2.5282e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,432][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0201, 0.0177, 0.0297, 0.0665, 0.0530, 0.0228, 0.0394, 0.0271, 0.1116,
        0.0263, 0.0887, 0.1036, 0.0412, 0.1589, 0.0735, 0.0514, 0.0685],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,433][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([1.0541e-02, 9.2163e-03, 3.5003e-03, 1.6475e-02, 4.8170e-03, 6.1210e-02,
        5.0844e-04, 6.2789e-03, 2.6713e-02, 1.8884e-02, 6.0380e-02, 2.7972e-03,
        3.2620e-02, 2.1294e-03, 4.8732e-03, 7.3872e-01, 3.3107e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,435][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0911, 0.0571, 0.0557, 0.0277, 0.0994, 0.0288, 0.0132, 0.0402, 0.0249,
        0.0513, 0.0403, 0.0263, 0.0741, 0.0780, 0.2078, 0.0576, 0.0266],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,436][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0312, 0.0351, 0.1037, 0.0348, 0.0601, 0.0511, 0.0445, 0.1306, 0.0354,
        0.0646, 0.0560, 0.0451, 0.1116, 0.0271, 0.0560, 0.0741, 0.0390],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,437][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0051, 0.0292, 0.0182, 0.0165, 0.0129, 0.0222, 0.0281, 0.0674, 0.0384,
        0.0611, 0.0528, 0.0731, 0.0848, 0.0649, 0.0727, 0.1467, 0.2060],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,437][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.0080, 0.0204, 0.0320, 0.0302, 0.0490, 0.0396, 0.0455, 0.0628, 0.0470,
        0.0723, 0.0522, 0.0608, 0.0997, 0.0542, 0.0779, 0.0685, 0.0702, 0.1096],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,438][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0490, 0.0142, 0.0786, 0.0419, 0.1276, 0.0032, 0.0150, 0.1235, 0.0051,
        0.1223, 0.0024, 0.0096, 0.0773, 0.0090, 0.1943, 0.0109, 0.0210, 0.0950],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,440][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0227, 0.0304, 0.1150, 0.0656, 0.0229, 0.2413, 0.0375, 0.1286, 0.0575,
        0.0496, 0.0131, 0.0292, 0.0416, 0.0120, 0.0124, 0.0941, 0.0238, 0.0029],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,442][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.2100, 0.0110, 0.0296, 0.0134, 0.0260, 0.0227, 0.0162, 0.0480, 0.0340,
        0.0417, 0.0310, 0.0318, 0.0674, 0.0602, 0.0858, 0.1491, 0.0676, 0.0546],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,444][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0060, 0.2228, 0.0602, 0.1065, 0.0465, 0.0456, 0.0675, 0.0542, 0.0637,
        0.0442, 0.0392, 0.0401, 0.0176, 0.0516, 0.0387, 0.0297, 0.0396, 0.0261],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,445][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.0071, 0.0914, 0.0687, 0.1014, 0.0741, 0.0721, 0.0400, 0.0654, 0.0459,
        0.0813, 0.0369, 0.0464, 0.0469, 0.0643, 0.0539, 0.0623, 0.0271, 0.0147],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,446][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([5.7165e-04, 4.0782e-03, 2.8518e-04, 5.1817e-03, 1.8346e-03, 5.5599e-04,
        1.7735e-02, 1.7450e-03, 4.9295e-02, 2.4055e-02, 4.1397e-02, 3.1856e-01,
        1.0383e-02, 2.2229e-01, 2.3249e-02, 2.5023e-02, 2.4077e-01, 1.2988e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,449][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0201, 0.0174, 0.0259, 0.0764, 0.0450, 0.0257, 0.0389, 0.0215, 0.0936,
        0.0206, 0.0882, 0.0915, 0.0344, 0.1889, 0.0624, 0.0522, 0.0692, 0.0282],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,451][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.0528, 0.0430, 0.0367, 0.0297, 0.0106, 0.1585, 0.0050, 0.0460, 0.1406,
        0.0235, 0.0987, 0.0352, 0.0677, 0.0127, 0.0096, 0.2181, 0.0037, 0.0080],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,453][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.0730, 0.0322, 0.0354, 0.0164, 0.0624, 0.0339, 0.0308, 0.0779, 0.0271,
        0.1251, 0.0314, 0.0452, 0.0704, 0.0325, 0.0861, 0.1298, 0.0641, 0.0265],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,454][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0198, 0.0376, 0.1066, 0.0284, 0.0614, 0.0528, 0.0367, 0.1038, 0.0241,
        0.0701, 0.0460, 0.0399, 0.1030, 0.0235, 0.0574, 0.0781, 0.0324, 0.0785],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,454][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.0058, 0.0261, 0.0156, 0.0169, 0.0124, 0.0204, 0.0267, 0.0505, 0.0345,
        0.0508, 0.0468, 0.0584, 0.0711, 0.0648, 0.0622, 0.1176, 0.1772, 0.1422],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,455][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0085, 0.0196, 0.0322, 0.0273, 0.0466, 0.0327, 0.0373, 0.0588, 0.0423,
        0.0710, 0.0472, 0.0554, 0.0985, 0.0513, 0.0827, 0.0645, 0.0589, 0.1045,
        0.0607], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,456][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.2443, 0.0394, 0.0125, 0.0911, 0.0268, 0.0046, 0.0517, 0.0287, 0.0360,
        0.0076, 0.0036, 0.2365, 0.0038, 0.0548, 0.0238, 0.0034, 0.0500, 0.0056,
        0.0758], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,459][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0425, 0.0361, 0.0329, 0.0645, 0.0132, 0.1393, 0.0621, 0.1537, 0.0933,
        0.0969, 0.0336, 0.0425, 0.0305, 0.0082, 0.0069, 0.0668, 0.0397, 0.0362,
        0.0012], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,461][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.3229, 0.0093, 0.0209, 0.0089, 0.0173, 0.0124, 0.0099, 0.0431, 0.0352,
        0.0233, 0.0278, 0.0198, 0.0889, 0.0415, 0.0387, 0.1117, 0.0395, 0.1095,
        0.0194], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,463][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0138, 0.0386, 0.0247, 0.0434, 0.0233, 0.0274, 0.0441, 0.0184, 0.0653,
        0.0569, 0.0395, 0.0572, 0.0128, 0.1636, 0.0189, 0.0577, 0.0877, 0.0441,
        0.1624], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,464][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0068, 0.0710, 0.0462, 0.0916, 0.0492, 0.1215, 0.0226, 0.0865, 0.0515,
        0.0672, 0.0399, 0.0320, 0.0654, 0.0590, 0.0406, 0.0784, 0.0177, 0.0348,
        0.0183], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,465][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([9.7552e-06, 3.5484e-04, 2.4400e-04, 2.3069e-03, 1.9376e-03, 8.5030e-04,
        1.5091e-02, 1.5990e-03, 1.1843e-02, 4.5265e-02, 5.9689e-02, 2.2608e-01,
        2.0441e-02, 1.0193e-01, 1.7410e-02, 3.5252e-02, 1.8860e-01, 1.3246e-02,
        2.5784e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,467][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0165, 0.0124, 0.0239, 0.0528, 0.0420, 0.0213, 0.0303, 0.0173, 0.0899,
        0.0177, 0.0837, 0.0869, 0.0326, 0.1348, 0.0597, 0.0489, 0.0568, 0.0307,
        0.1420], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,469][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([2.1839e-03, 4.5839e-03, 7.9502e-04, 3.5223e-03, 7.6051e-04, 4.0666e-02,
        1.5288e-03, 9.7701e-04, 3.5905e-03, 5.2554e-04, 4.4247e-03, 1.0909e-03,
        2.0863e-03, 6.3521e-04, 7.0543e-04, 8.9072e-01, 1.0262e-03, 4.0168e-02,
        1.4033e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,470][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0910, 0.0488, 0.0396, 0.0217, 0.0650, 0.0217, 0.0374, 0.0453, 0.0184,
        0.0633, 0.0139, 0.0517, 0.0746, 0.0493, 0.1090, 0.0657, 0.0846, 0.0849,
        0.0140], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,471][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0269, 0.0373, 0.0977, 0.0352, 0.0556, 0.0559, 0.0424, 0.0936, 0.0316,
        0.0540, 0.0490, 0.0435, 0.0910, 0.0241, 0.0505, 0.0739, 0.0369, 0.0726,
        0.0282], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,472][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0052, 0.0230, 0.0117, 0.0121, 0.0095, 0.0166, 0.0201, 0.0357, 0.0249,
        0.0385, 0.0333, 0.0498, 0.0553, 0.0493, 0.0485, 0.0968, 0.1349, 0.1205,
        0.2141], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,500][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:53,501][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,503][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,504][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,505][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,507][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,507][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,508][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,509][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,509][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,510][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,511][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,511][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,512][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5021, 0.4979], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,513][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0655, 0.9345], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,513][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0482, 0.9518], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,514][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0677, 0.9323], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,515][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9350, 0.0650], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,517][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0236, 0.9764], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,517][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3474, 0.6526], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,518][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3342, 0.6658], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,519][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.6053, 0.3947], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,520][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9945, 0.0055], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,522][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3379, 0.6621], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,523][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.5460, 0.4540], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,524][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Jamie] are: tensor([0.2802, 0.3081, 0.4116], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,524][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Jamie] are: tensor([0.3371, 0.6353, 0.0277], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,525][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Jamie] are: tensor([9.5279e-05, 1.0976e-03, 9.9881e-01], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,526][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Jamie] are: tensor([0.0018, 0.2608, 0.7374], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,527][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Jamie] are: tensor([0.2125, 0.7454, 0.0421], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,528][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Jamie] are: tensor([0.0009, 0.4661, 0.5330], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,530][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Jamie] are: tensor([0.0532, 0.0975, 0.8493], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,532][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Jamie] are: tensor([0.1050, 0.2078, 0.6872], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,533][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Jamie] are: tensor([0.3232, 0.4702, 0.2066], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,535][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Jamie] are: tensor([0.9819, 0.0090, 0.0091], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,537][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Jamie] are: tensor([0.0691, 0.2073, 0.7237], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,539][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Jamie] are: tensor([0.3336, 0.2715, 0.3949], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,540][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1896, 0.1861, 0.2876, 0.3368], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,541][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0799, 0.2993, 0.5003, 0.1206], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,542][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([3.5902e-08, 3.0433e-06, 1.0000e+00, 1.5129e-06], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,542][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([5.5282e-04, 4.4369e-02, 3.4543e-01, 6.0965e-01], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,543][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0400, 0.4265, 0.5266, 0.0068], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,544][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([3.0841e-04, 5.5968e-02, 2.1690e-01, 7.2682e-01], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,546][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0505, 0.1214, 0.6954, 0.1327], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,548][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0481, 0.0987, 0.3203, 0.5329], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,549][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2269, 0.2508, 0.2865, 0.2358], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,551][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9696, 0.0059, 0.0221, 0.0024], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,553][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0532, 0.1261, 0.4318, 0.3890], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,555][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2492, 0.2153, 0.3181, 0.2174], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,556][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.1221, 0.1403, 0.1952, 0.2320, 0.3103], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,558][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0792, 0.2582, 0.0670, 0.5483, 0.0474], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,558][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([1.3655e-05, 4.4740e-05, 1.3604e-01, 4.6417e-06, 8.6390e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,559][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([7.7538e-05, 7.2654e-03, 5.4514e-02, 2.2738e-01, 7.1077e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,560][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([2.0200e-03, 3.0621e-02, 9.5414e-01, 1.3012e-02, 2.0704e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,560][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([4.4675e-05, 9.9555e-03, 5.5213e-02, 4.9817e-01, 4.3662e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,561][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0071, 0.0151, 0.1463, 0.0141, 0.8173], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,563][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0260, 0.0536, 0.1552, 0.2446, 0.5206], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,565][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.1622, 0.2411, 0.1623, 0.2942, 0.1402], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,567][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.9672, 0.0053, 0.0159, 0.0046, 0.0069], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,568][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0041, 0.0166, 0.0829, 0.0812, 0.8153], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,570][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.1825, 0.1603, 0.2317, 0.1690, 0.2566], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,572][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1064, 0.0918, 0.1523, 0.1811, 0.2819, 0.1865], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,574][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.1697, 0.1113, 0.2221, 0.2709, 0.1316, 0.0944], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,575][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([2.1972e-11, 1.3421e-08, 7.3568e-04, 4.2705e-09, 9.9926e-01, 7.5243e-09],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,576][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([3.5484e-05, 3.8195e-03, 1.9643e-02, 9.4053e-02, 7.3939e-01, 1.4306e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,577][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.6924, 0.1507, 0.0044, 0.1255, 0.0139, 0.0131], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,577][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([1.1997e-05, 2.8248e-03, 1.2031e-02, 1.0950e-01, 6.3089e-01, 2.4475e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,578][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0114, 0.0260, 0.1643, 0.0290, 0.7065, 0.0628], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,579][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0197, 0.0394, 0.1251, 0.2054, 0.4795, 0.1309], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,581][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.1195, 0.1815, 0.1565, 0.1490, 0.2131, 0.1804], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,583][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.9104, 0.0143, 0.0274, 0.0108, 0.0302, 0.0070], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,584][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0136, 0.0361, 0.1230, 0.1023, 0.5727, 0.1522], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,586][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.1518, 0.1361, 0.2060, 0.1259, 0.2453, 0.1350], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,588][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0980, 0.0754, 0.1214, 0.1422, 0.2190, 0.1566, 0.1874],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,590][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0627, 0.0532, 0.5186, 0.1546, 0.1031, 0.0864, 0.0215],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,591][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([2.1576e-10, 4.4499e-08, 1.1437e-03, 8.0297e-09, 9.9886e-01, 2.2913e-08,
        1.0460e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,592][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([2.9414e-05, 1.4885e-03, 1.1016e-02, 4.4225e-02, 4.9988e-01, 1.2874e-01,
        3.1462e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,593][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.3871, 0.1571, 0.1454, 0.1710, 0.0425, 0.0871, 0.0099],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,593][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.2282e-05, 1.2913e-03, 5.3487e-03, 5.0876e-02, 2.3485e-01, 3.1523e-01,
        3.9239e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,594][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0088, 0.0228, 0.1460, 0.0291, 0.6909, 0.0659, 0.0366],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,595][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0156, 0.0313, 0.1019, 0.1704, 0.4065, 0.1079, 0.1663],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,596][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0751, 0.1112, 0.0992, 0.1665, 0.1267, 0.3374, 0.0839],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,597][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.9115, 0.0089, 0.0239, 0.0066, 0.0268, 0.0127, 0.0097],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,599][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0110, 0.0277, 0.0990, 0.0896, 0.4904, 0.1312, 0.1510],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,601][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1424, 0.1214, 0.1760, 0.1282, 0.1940, 0.1338, 0.1041],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,602][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0574, 0.0591, 0.0902, 0.1083, 0.1596, 0.1143, 0.1454, 0.2658],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,603][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.3065, 0.1339, 0.0641, 0.1719, 0.0614, 0.0051, 0.0946, 0.1627],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,605][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([3.0837e-10, 4.7167e-08, 6.2001e-04, 3.8444e-09, 9.9938e-01, 1.2612e-08,
        1.8253e-06, 1.6516e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,606][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([4.2695e-06, 3.5512e-04, 2.2539e-03, 1.7776e-02, 1.3481e-01, 1.0124e-01,
        6.6335e-01, 8.0208e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,608][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0818, 0.3667, 0.0190, 0.1812, 0.0256, 0.0968, 0.2066, 0.0223],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,609][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([5.0265e-06, 5.8111e-04, 2.9462e-03, 3.4089e-02, 1.2445e-01, 2.1206e-01,
        4.3742e-01, 1.8845e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,610][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0096, 0.0254, 0.1455, 0.0242, 0.5657, 0.0551, 0.0334, 0.1409],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,611][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0139, 0.0273, 0.0916, 0.1551, 0.3847, 0.0977, 0.1547, 0.0750],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,612][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0558, 0.1058, 0.0775, 0.1217, 0.0780, 0.3475, 0.0878, 0.1258],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,612][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.8498, 0.0161, 0.0281, 0.0132, 0.0220, 0.0291, 0.0318, 0.0099],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,613][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0057, 0.0180, 0.0698, 0.0659, 0.4464, 0.1052, 0.1177, 0.1713],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,615][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.1272, 0.0989, 0.1526, 0.0979, 0.1840, 0.1068, 0.0852, 0.1475],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:53,616][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0647, 0.0461, 0.0757, 0.0875, 0.1357, 0.0994, 0.1131, 0.2447, 0.1331],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,618][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0290, 0.0576, 0.2495, 0.0581, 0.0613, 0.1589, 0.0269, 0.2865, 0.0722],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,619][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([5.5313e-11, 3.2168e-09, 2.9669e-04, 6.9888e-10, 9.9970e-01, 4.1451e-09,
        2.0626e-07, 1.8910e-06, 9.1353e-07], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,620][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([1.1525e-05, 2.2022e-04, 2.3123e-03, 6.5910e-03, 6.2076e-02, 5.4663e-02,
        2.8229e-01, 1.1713e-01, 4.7470e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,622][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([2.5493e-04, 6.5160e-04, 2.7545e-03, 8.1842e-04, 4.0236e-04, 1.5371e-04,
        6.5831e-04, 9.9422e-01, 8.1509e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,623][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([4.5280e-06, 1.3374e-04, 1.0492e-03, 6.0701e-03, 3.2406e-02, 4.8070e-02,
        1.3119e-01, 7.0091e-02, 7.1099e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,625][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0083, 0.0206, 0.1255, 0.0238, 0.5481, 0.0533, 0.0323, 0.1301, 0.0579],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,627][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0146, 0.0294, 0.0891, 0.1441, 0.3260, 0.0929, 0.1413, 0.0749, 0.0878],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,627][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0606, 0.0671, 0.0877, 0.1021, 0.1217, 0.2377, 0.0832, 0.1537, 0.0862],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,628][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.9138, 0.0056, 0.0202, 0.0039, 0.0175, 0.0117, 0.0140, 0.0106, 0.0026],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,629][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0068, 0.0184, 0.0706, 0.0600, 0.3578, 0.0910, 0.1053, 0.1358, 0.1543],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,630][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.1075, 0.0915, 0.1371, 0.0966, 0.1601, 0.1018, 0.0814, 0.1261, 0.0979],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:53,631][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0329, 0.0378, 0.0609, 0.0748, 0.1026, 0.0761, 0.0970, 0.1725, 0.0961,
        0.2492], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,633][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.3367, 0.1212, 0.0209, 0.2954, 0.0621, 0.0015, 0.0985, 0.0208, 0.0402,
        0.0026], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,634][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([4.4030e-08, 6.5853e-07, 7.7911e-04, 4.0623e-08, 9.9834e-01, 5.9019e-08,
        5.3241e-06, 2.1063e-06, 1.5555e-05, 8.5824e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,635][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([1.0728e-06, 3.9013e-05, 3.0280e-04, 1.0470e-03, 1.3265e-02, 3.8197e-03,
        5.6826e-02, 4.9388e-02, 3.5068e-01, 5.2463e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,636][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([6.9197e-03, 3.5479e-02, 2.2258e-02, 5.8822e-03, 3.0691e-02, 6.0121e-01,
        3.1679e-02, 2.6010e-01, 5.6617e-03, 1.1807e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,638][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([3.7819e-07, 2.5933e-05, 1.0626e-04, 7.8118e-04, 7.2213e-03, 4.1100e-03,
        2.7594e-02, 4.3005e-02, 4.1068e-01, 5.0648e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,640][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0070, 0.0165, 0.1121, 0.0166, 0.4761, 0.0380, 0.0248, 0.1055, 0.0469,
        0.1566], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,642][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0122, 0.0242, 0.0773, 0.1260, 0.2992, 0.0811, 0.1247, 0.0645, 0.0764,
        0.1144], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,643][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0436, 0.0567, 0.0535, 0.0683, 0.0352, 0.3088, 0.0653, 0.1670, 0.1243,
        0.0774], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,644][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.8708, 0.0087, 0.0333, 0.0064, 0.0232, 0.0116, 0.0174, 0.0161, 0.0086,
        0.0039], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,645][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0028, 0.0093, 0.0410, 0.0361, 0.3063, 0.0641, 0.0688, 0.1125, 0.1062,
        0.2529], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,646][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0941, 0.0809, 0.1152, 0.0808, 0.1418, 0.0876, 0.0690, 0.1180, 0.0855,
        0.1273], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:53,647][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0361, 0.0294, 0.0514, 0.0595, 0.0947, 0.0670, 0.0749, 0.1584, 0.0886,
        0.2572, 0.0827], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,648][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.5607, 0.0516, 0.0028, 0.1209, 0.0050, 0.0023, 0.1635, 0.0388, 0.0494,
        0.0029, 0.0021], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,649][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([2.6535e-10, 7.5925e-09, 1.1659e-04, 9.9643e-10, 9.9476e-01, 3.4623e-09,
        1.5369e-07, 1.2342e-06, 8.8101e-07, 5.0057e-03, 1.1585e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,650][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([1.3743e-06, 1.7112e-05, 2.3912e-04, 4.7909e-04, 8.6745e-03, 3.0883e-03,
        2.2727e-02, 1.7504e-02, 1.1470e-01, 3.9938e-01, 4.3319e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,652][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0714, 0.2164, 0.3965, 0.0906, 0.0098, 0.0106, 0.0332, 0.1167, 0.0458,
        0.0036, 0.0053], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,654][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([3.0049e-07, 6.2866e-06, 2.5974e-05, 2.1354e-04, 1.1209e-03, 1.6206e-03,
        6.7029e-03, 8.6341e-03, 6.4870e-02, 3.9978e-01, 5.1703e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,655][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0078, 0.0165, 0.1004, 0.0196, 0.4520, 0.0439, 0.0265, 0.1015, 0.0443,
        0.1513, 0.0363], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,657][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0109, 0.0216, 0.0680, 0.1126, 0.2657, 0.0723, 0.1103, 0.0567, 0.0678,
        0.1007, 0.1135], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,659][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0411, 0.0472, 0.0584, 0.0622, 0.0354, 0.2029, 0.0910, 0.1665, 0.1104,
        0.0872, 0.0977], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,661][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.8412, 0.0097, 0.0267, 0.0057, 0.0297, 0.0154, 0.0251, 0.0199, 0.0065,
        0.0151, 0.0051], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,662][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0043, 0.0110, 0.0448, 0.0388, 0.2591, 0.0626, 0.0714, 0.1022, 0.1029,
        0.2100, 0.0930], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,663][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0882, 0.0719, 0.1112, 0.0776, 0.1271, 0.0794, 0.0659, 0.1079, 0.0792,
        0.1197, 0.0719], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:53,664][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0338, 0.0254, 0.0434, 0.0519, 0.0790, 0.0580, 0.0664, 0.1474, 0.0796,
        0.2444, 0.0749, 0.0958], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,664][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1138, 0.0344, 0.2591, 0.1059, 0.0538, 0.0481, 0.0187, 0.1653, 0.0532,
        0.0842, 0.0156, 0.0480], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,665][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([4.9141e-10, 2.7252e-08, 1.3343e-04, 1.9317e-09, 9.9572e-01, 4.7163e-09,
        2.0258e-07, 1.0873e-06, 3.6997e-06, 3.2120e-03, 8.7326e-04, 5.7683e-05],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,666][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([4.4142e-07, 4.9429e-06, 5.2893e-05, 1.6462e-04, 2.5302e-03, 5.1276e-04,
        6.1270e-03, 4.2168e-03, 2.3369e-02, 2.3369e-01, 3.6917e-01, 3.6016e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,668][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.2787, 0.2081, 0.1138, 0.1854, 0.0021, 0.0399, 0.0435, 0.0284, 0.0229,
        0.0079, 0.0625, 0.0069], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,669][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([1.4846e-07, 2.2622e-06, 1.0135e-05, 8.8859e-05, 5.3990e-04, 5.3383e-04,
        1.5836e-03, 2.8216e-03, 1.6594e-02, 1.4190e-01, 4.1720e-01, 4.1873e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,671][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0066, 0.0163, 0.0969, 0.0207, 0.4291, 0.0441, 0.0249, 0.1028, 0.0440,
        0.1547, 0.0367, 0.0233], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,673][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0104, 0.0208, 0.0627, 0.1034, 0.2344, 0.0668, 0.0998, 0.0527, 0.0617,
        0.0906, 0.1022, 0.0944], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,675][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0270, 0.0437, 0.0420, 0.0703, 0.0405, 0.1291, 0.0518, 0.1171, 0.1010,
        0.1244, 0.2138, 0.0395], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,677][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.8764, 0.0079, 0.0228, 0.0043, 0.0255, 0.0112, 0.0075, 0.0139, 0.0049,
        0.0087, 0.0139, 0.0031], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,679][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0046, 0.0121, 0.0431, 0.0400, 0.2211, 0.0613, 0.0688, 0.0935, 0.0985,
        0.1889, 0.0869, 0.0812], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,679][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0808, 0.0708, 0.1014, 0.0764, 0.1117, 0.0805, 0.0621, 0.0974, 0.0766,
        0.1096, 0.0695, 0.0632], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:53,680][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.0205, 0.0232, 0.0378, 0.0474, 0.0668, 0.0506, 0.0627, 0.1150, 0.0639,
        0.1773, 0.0623, 0.0813, 0.1911], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,681][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.2716, 0.0631, 0.0115, 0.3070, 0.0101, 0.0007, 0.0744, 0.0211, 0.0757,
        0.0068, 0.0118, 0.1339, 0.0122], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,682][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([1.5582e-09, 1.6170e-08, 1.1263e-04, 9.2067e-10, 8.2522e-01, 9.1501e-10,
        1.5294e-07, 3.2472e-07, 1.2544e-06, 7.2677e-03, 3.6015e-04, 1.0636e-04,
        1.6693e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,683][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([7.4734e-08, 1.3580e-06, 7.7899e-06, 3.2068e-05, 5.1352e-04, 2.6851e-04,
        1.2837e-03, 1.6319e-03, 1.3245e-02, 5.6184e-02, 1.5844e-01, 5.8056e-01,
        1.8784e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,684][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([8.2910e-03, 3.9724e-01, 4.4277e-03, 1.7884e-01, 1.2053e-02, 2.0803e-02,
        7.1042e-02, 4.1235e-02, 8.1937e-02, 1.7642e-02, 3.2497e-02, 1.3375e-01,
        2.4209e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,685][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([1.8865e-08, 4.6019e-07, 3.0963e-06, 1.7566e-05, 9.2934e-05, 1.4726e-04,
        5.7414e-04, 5.7092e-04, 7.4734e-03, 5.1902e-02, 1.4557e-01, 5.4177e-01,
        2.5188e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,687][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.0058, 0.0127, 0.0951, 0.0115, 0.3971, 0.0281, 0.0169, 0.0828, 0.0333,
        0.1255, 0.0267, 0.0172, 0.1473], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,689][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0087, 0.0176, 0.0573, 0.0959, 0.2379, 0.0607, 0.0950, 0.0476, 0.0576,
        0.0867, 0.0968, 0.0892, 0.0489], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,691][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.0262, 0.0447, 0.0255, 0.0565, 0.0215, 0.0880, 0.0594, 0.1234, 0.1080,
        0.1017, 0.2269, 0.0648, 0.0535], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,693][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.8914, 0.0047, 0.0206, 0.0036, 0.0111, 0.0073, 0.0136, 0.0111, 0.0047,
        0.0082, 0.0114, 0.0064, 0.0058], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,695][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.0025, 0.0085, 0.0316, 0.0323, 0.2201, 0.0519, 0.0577, 0.0849, 0.0905,
        0.1978, 0.0795, 0.0710, 0.0717], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,696][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.0723, 0.0602, 0.0956, 0.0599, 0.1084, 0.0647, 0.0506, 0.0913, 0.0621,
        0.1050, 0.0559, 0.0538, 0.1201], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:53,697][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0236, 0.0179, 0.0321, 0.0377, 0.0603, 0.0424, 0.0473, 0.1060, 0.0544,
        0.1782, 0.0528, 0.0680, 0.1896, 0.0897], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,698][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0720, 0.0711, 0.1121, 0.0468, 0.0442, 0.0468, 0.0283, 0.1187, 0.0407,
        0.0327, 0.0648, 0.0462, 0.0855, 0.1900], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,699][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([6.0916e-10, 4.1675e-09, 2.8239e-04, 9.8734e-10, 9.8689e-01, 1.4906e-09,
        8.4558e-08, 4.5085e-07, 1.2424e-07, 9.7557e-04, 1.0660e-05, 1.0553e-06,
        1.1842e-02, 2.3419e-07], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,700][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([2.4064e-07, 2.9287e-06, 2.0130e-05, 8.3815e-05, 5.5549e-04, 1.8890e-04,
        1.2579e-03, 7.6199e-04, 6.2292e-03, 3.7709e-02, 8.4405e-02, 1.5545e-01,
        3.3745e-01, 3.7589e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,702][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0074, 0.0140, 0.5462, 0.0134, 0.0770, 0.0149, 0.1033, 0.0838, 0.0174,
        0.0031, 0.0154, 0.0607, 0.0425, 0.0008], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,703][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([2.2320e-08, 4.9210e-07, 1.6878e-06, 1.2334e-05, 5.8557e-05, 9.6268e-05,
        3.5650e-04, 5.7315e-04, 4.1571e-03, 1.1181e-02, 7.8746e-02, 1.3809e-01,
        3.1685e-01, 4.4987e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,705][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0065, 0.0127, 0.0809, 0.0201, 0.3310, 0.0415, 0.0248, 0.0866, 0.0401,
        0.1384, 0.0333, 0.0221, 0.1497, 0.0122], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,707][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0078, 0.0160, 0.0536, 0.0885, 0.2185, 0.0562, 0.0873, 0.0441, 0.0529,
        0.0800, 0.0905, 0.0827, 0.0459, 0.0759], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,709][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0378, 0.0336, 0.0402, 0.0448, 0.0504, 0.0932, 0.0552, 0.1045, 0.0784,
        0.0982, 0.1780, 0.0623, 0.0855, 0.0378], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,711][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.9116, 0.0040, 0.0113, 0.0035, 0.0093, 0.0064, 0.0091, 0.0074, 0.0044,
        0.0040, 0.0116, 0.0053, 0.0096, 0.0024], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,713][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0048, 0.0117, 0.0418, 0.0356, 0.1945, 0.0532, 0.0629, 0.0814, 0.0876,
        0.1558, 0.0750, 0.0735, 0.0744, 0.0478], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,714][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0663, 0.0561, 0.0874, 0.0603, 0.1008, 0.0632, 0.0537, 0.0786, 0.0644,
        0.0930, 0.0575, 0.0555, 0.1082, 0.0550], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:53,715][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0180, 0.0193, 0.0290, 0.0359, 0.0461, 0.0405, 0.0499, 0.1070, 0.0517,
        0.1632, 0.0480, 0.0655, 0.1749, 0.0855, 0.0655], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,716][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0096, 0.0565, 0.0394, 0.1121, 0.0215, 0.0083, 0.0210, 0.0065, 0.0067,
        0.0115, 0.0107, 0.0567, 0.1381, 0.4682, 0.0332], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,716][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([1.5867e-07, 3.8007e-08, 1.6366e-05, 1.7316e-09, 3.1596e-04, 1.1666e-09,
        2.1552e-08, 1.1200e-08, 3.5283e-08, 1.9369e-06, 4.9228e-07, 4.9802e-07,
        2.4410e-05, 1.7603e-06, 9.9964e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,717][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([4.2505e-08, 4.6138e-07, 3.2806e-06, 1.0681e-05, 3.6554e-05, 4.8258e-05,
        4.0653e-04, 1.8094e-04, 1.3031e-03, 7.7001e-03, 2.3938e-02, 6.1794e-02,
        1.3156e-01, 2.0205e-01, 5.7096e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,718][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([2.2028e-03, 3.2102e-02, 8.1723e-01, 1.4484e-02, 1.9193e-04, 2.3803e-02,
        2.0624e-02, 5.8937e-04, 3.2469e-02, 1.7791e-04, 6.7995e-03, 4.1905e-02,
        1.4768e-03, 5.7776e-03, 1.6771e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,720][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([5.8539e-09, 9.2423e-08, 4.8979e-07, 3.5413e-06, 3.4081e-06, 2.1290e-05,
        1.0105e-04, 8.9825e-05, 1.0368e-03, 7.8993e-03, 1.9510e-02, 6.4739e-02,
        8.6667e-02, 4.5285e-01, 3.6708e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,722][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0023, 0.0049, 0.0489, 0.0050, 0.2408, 0.0140, 0.0070, 0.0424, 0.0145,
        0.0751, 0.0127, 0.0074, 0.0947, 0.0033, 0.4271], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,723][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0068, 0.0148, 0.0401, 0.0629, 0.1287, 0.0427, 0.0601, 0.0357, 0.0368,
        0.0534, 0.0608, 0.0571, 0.0329, 0.0507, 0.3167], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,725][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.0238, 0.0342, 0.0207, 0.0432, 0.0181, 0.1002, 0.0461, 0.1238, 0.1187,
        0.0760, 0.1646, 0.0548, 0.1075, 0.0432, 0.0251], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,727][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.9172, 0.0032, 0.0116, 0.0025, 0.0044, 0.0072, 0.0125, 0.0058, 0.0037,
        0.0049, 0.0095, 0.0065, 0.0070, 0.0020, 0.0021], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,729][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0005, 0.0022, 0.0129, 0.0128, 0.1599, 0.0237, 0.0264, 0.0431, 0.0433,
        0.1309, 0.0372, 0.0343, 0.0362, 0.0195, 0.4170], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,731][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0613, 0.0538, 0.0774, 0.0573, 0.0860, 0.0625, 0.0454, 0.0739, 0.0556,
        0.0858, 0.0508, 0.0486, 0.1067, 0.0526, 0.0822], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:53,732][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0166, 0.0158, 0.0281, 0.0330, 0.0513, 0.0337, 0.0412, 0.0854, 0.0445,
        0.1447, 0.0443, 0.0585, 0.1564, 0.0758, 0.0854, 0.0852],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,733][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0248, 0.0272, 0.1190, 0.0657, 0.0301, 0.0400, 0.0077, 0.1592, 0.0198,
        0.0889, 0.0099, 0.0329, 0.1385, 0.1451, 0.0443, 0.0469],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,734][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([4.0660e-14, 8.5687e-13, 2.8109e-09, 5.0477e-14, 2.3442e-05, 1.7024e-14,
        1.3729e-12, 8.2446e-13, 3.1385e-12, 1.0563e-09, 2.1342e-10, 3.1308e-11,
        9.5920e-09, 1.9608e-11, 9.9998e-01, 1.3283e-07], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,734][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([2.7039e-08, 1.4672e-07, 7.2885e-07, 3.8543e-06, 2.5051e-05, 4.6466e-06,
        6.6876e-05, 6.9358e-05, 4.2981e-04, 2.0193e-03, 4.1301e-03, 1.1535e-02,
        1.7136e-02, 7.9392e-02, 4.6251e-01, 4.2268e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,736][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1192, 0.2028, 0.1242, 0.1135, 0.0154, 0.0237, 0.0355, 0.0050, 0.1010,
        0.0036, 0.0404, 0.0630, 0.0035, 0.1356, 0.0134, 0.0003],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,738][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([1.7613e-09, 1.8302e-08, 6.3567e-08, 5.4601e-07, 2.9351e-06, 1.2239e-06,
        1.4600e-05, 8.7803e-06, 9.2437e-05, 4.4738e-04, 1.1838e-03, 6.4372e-03,
        1.1879e-02, 8.2235e-02, 3.9408e-01, 5.0362e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,740][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0031, 0.0069, 0.0531, 0.0078, 0.2223, 0.0171, 0.0104, 0.0476, 0.0205,
        0.0747, 0.0165, 0.0102, 0.0859, 0.0059, 0.3531, 0.0648],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,742][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0047, 0.0095, 0.0310, 0.0507, 0.1241, 0.0327, 0.0503, 0.0258, 0.0307,
        0.0461, 0.0518, 0.0473, 0.0264, 0.0432, 0.3896, 0.0360],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,744][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0383, 0.0430, 0.0324, 0.0470, 0.0414, 0.0738, 0.0494, 0.1254, 0.0852,
        0.0713, 0.1056, 0.0596, 0.0641, 0.0481, 0.0575, 0.0580],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,745][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.8454, 0.0058, 0.0170, 0.0035, 0.0211, 0.0070, 0.0159, 0.0087, 0.0058,
        0.0047, 0.0190, 0.0072, 0.0212, 0.0060, 0.0102, 0.0014],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,747][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0017, 0.0052, 0.0210, 0.0193, 0.1401, 0.0312, 0.0352, 0.0521, 0.0530,
        0.1241, 0.0468, 0.0423, 0.0496, 0.0265, 0.2857, 0.0663],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,748][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0562, 0.0491, 0.0707, 0.0478, 0.0871, 0.0502, 0.0428, 0.0720, 0.0504,
        0.0824, 0.0469, 0.0467, 0.1029, 0.0457, 0.0839, 0.0654],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:53,749][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0183, 0.0145, 0.0268, 0.0300, 0.0477, 0.0316, 0.0361, 0.0815, 0.0416,
        0.1428, 0.0403, 0.0514, 0.1515, 0.0690, 0.0781, 0.0811, 0.0576],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,750][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0470, 0.0234, 0.2199, 0.0612, 0.0485, 0.0275, 0.0100, 0.2308, 0.0146,
        0.1037, 0.0103, 0.0192, 0.0426, 0.0629, 0.0497, 0.0170, 0.0118],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,751][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.7126e-12, 2.0774e-11, 2.4816e-08, 1.5447e-12, 1.1371e-04, 1.0938e-12,
        2.4950e-11, 4.9445e-11, 1.8166e-10, 3.6585e-08, 7.3020e-09, 5.9918e-10,
        2.7016e-07, 6.9437e-11, 9.9986e-01, 3.3758e-06, 1.8762e-05],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,752][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.1670e-08, 5.0561e-08, 3.5767e-07, 8.9881e-07, 1.1135e-05, 1.6906e-06,
        4.1151e-06, 1.1430e-05, 8.2619e-05, 7.7845e-04, 1.0262e-03, 3.1253e-03,
        6.6411e-03, 1.5386e-02, 1.8523e-01, 3.4744e-01, 4.4026e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,754][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.3019, 0.1307, 0.0929, 0.1675, 0.0315, 0.0684, 0.0084, 0.0539, 0.0195,
        0.0010, 0.0247, 0.0268, 0.0010, 0.0305, 0.0283, 0.0074, 0.0055],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,755][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.2974e-09, 7.1128e-09, 2.4338e-08, 1.6525e-07, 8.2338e-07, 6.5087e-07,
        6.8260e-07, 1.8990e-06, 2.1353e-05, 1.5481e-04, 3.1358e-04, 1.4521e-03,
        4.4471e-03, 1.7384e-02, 8.0226e-02, 3.6566e-01, 5.3034e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,757][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0027, 0.0061, 0.0462, 0.0091, 0.2117, 0.0193, 0.0111, 0.0459, 0.0201,
        0.0745, 0.0165, 0.0102, 0.0825, 0.0057, 0.3634, 0.0625, 0.0125],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,759][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0048, 0.0099, 0.0307, 0.0505, 0.1157, 0.0327, 0.0484, 0.0257, 0.0296,
        0.0438, 0.0500, 0.0459, 0.0256, 0.0419, 0.3446, 0.0341, 0.0660],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,761][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0185, 0.0260, 0.0214, 0.0410, 0.0292, 0.0794, 0.0193, 0.0574, 0.0677,
        0.0783, 0.1321, 0.0368, 0.0891, 0.0344, 0.0463, 0.2012, 0.0218],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,763][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.8177, 0.0086, 0.0244, 0.0052, 0.0253, 0.0093, 0.0068, 0.0159, 0.0063,
        0.0075, 0.0137, 0.0049, 0.0217, 0.0067, 0.0126, 0.0066, 0.0069],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,765][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0022, 0.0060, 0.0229, 0.0207, 0.1288, 0.0317, 0.0361, 0.0532, 0.0538,
        0.1077, 0.0478, 0.0435, 0.0475, 0.0284, 0.2567, 0.0635, 0.0494],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,766][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0561, 0.0485, 0.0692, 0.0508, 0.0772, 0.0522, 0.0406, 0.0710, 0.0524,
        0.0749, 0.0471, 0.0436, 0.0923, 0.0451, 0.0743, 0.0671, 0.0378],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:53,767][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.0111, 0.0152, 0.0248, 0.0309, 0.0445, 0.0329, 0.0407, 0.0746, 0.0397,
        0.1171, 0.0385, 0.0518, 0.1258, 0.0652, 0.0610, 0.0710, 0.0623, 0.0927],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,768][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([6.1236e-01, 1.9572e-02, 2.8176e-03, 7.7229e-02, 9.7956e-03, 5.6685e-04,
        5.8703e-02, 1.8670e-02, 3.6997e-02, 9.3037e-03, 3.0560e-04, 2.9438e-02,
        4.8033e-03, 6.1741e-03, 1.8261e-02, 3.7968e-03, 8.5074e-02, 6.1363e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,769][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([2.8719e-11, 7.4597e-10, 8.0874e-08, 5.4490e-11, 8.4116e-05, 1.5032e-11,
        1.3096e-09, 7.5008e-10, 2.0786e-09, 2.5676e-07, 5.8671e-08, 2.8222e-08,
        7.9187e-07, 1.4547e-08, 9.9840e-01, 5.2445e-05, 1.4551e-03, 4.2949e-06],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,770][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([1.9012e-09, 1.1444e-08, 6.5875e-08, 2.1648e-07, 2.3500e-06, 9.0189e-07,
        5.5461e-06, 5.1181e-06, 4.1786e-05, 2.3983e-04, 3.7718e-04, 1.1180e-03,
        1.2408e-03, 5.2938e-03, 3.2091e-02, 1.2536e-01, 5.9346e-01, 2.4077e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,772][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.0157, 0.0236, 0.0158, 0.0182, 0.2646, 0.1057, 0.0078, 0.0531, 0.0211,
        0.0046, 0.0035, 0.0814, 0.0009, 0.0320, 0.2798, 0.0659, 0.0056, 0.0008],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,773][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([2.9538e-10, 1.4397e-09, 9.2514e-09, 4.5152e-08, 3.6689e-07, 1.3728e-07,
        7.5749e-07, 5.3659e-07, 6.4839e-06, 3.4334e-05, 1.1952e-04, 4.4248e-04,
        7.5726e-04, 4.7493e-03, 3.4560e-02, 1.0675e-01, 6.2320e-01, 2.2938e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,775][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.0023, 0.0045, 0.0461, 0.0045, 0.2147, 0.0120, 0.0072, 0.0371, 0.0150,
        0.0617, 0.0116, 0.0074, 0.0738, 0.0042, 0.3565, 0.0541, 0.0102, 0.0772],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,776][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0045, 0.0095, 0.0286, 0.0465, 0.1100, 0.0308, 0.0460, 0.0246, 0.0280,
        0.0414, 0.0464, 0.0427, 0.0240, 0.0382, 0.3223, 0.0317, 0.0614, 0.0635],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,778][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.0224, 0.0273, 0.0217, 0.0355, 0.0211, 0.0808, 0.0264, 0.0776, 0.0785,
        0.0623, 0.1126, 0.0440, 0.0745, 0.0337, 0.0312, 0.1391, 0.0322, 0.0788],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,780][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.8336, 0.0046, 0.0138, 0.0031, 0.0159, 0.0092, 0.0133, 0.0152, 0.0059,
        0.0089, 0.0103, 0.0076, 0.0178, 0.0034, 0.0079, 0.0085, 0.0136, 0.0075],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,782][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0008, 0.0029, 0.0138, 0.0129, 0.1271, 0.0237, 0.0248, 0.0401, 0.0398,
        0.1053, 0.0359, 0.0315, 0.0345, 0.0192, 0.2929, 0.0536, 0.0362, 0.1052],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,783][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0492, 0.0426, 0.0645, 0.0428, 0.0767, 0.0474, 0.0355, 0.0654, 0.0437,
        0.0727, 0.0404, 0.0385, 0.0899, 0.0405, 0.0735, 0.0601, 0.0331, 0.0835],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:53,784][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0156, 0.0119, 0.0223, 0.0257, 0.0399, 0.0292, 0.0315, 0.0726, 0.0382,
        0.1161, 0.0353, 0.0446, 0.1215, 0.0595, 0.0636, 0.0757, 0.0517, 0.0884,
        0.0566], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,785][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0213, 0.0407, 0.0692, 0.0355, 0.0423, 0.0299, 0.0092, 0.0408, 0.0230,
        0.0778, 0.0087, 0.0359, 0.0851, 0.1151, 0.0517, 0.0369, 0.0103, 0.2594,
        0.0074], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,786][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([5.2227e-13, 2.6352e-12, 5.0598e-09, 2.8373e-13, 5.7798e-05, 5.8736e-13,
        1.1861e-11, 2.9130e-11, 3.1728e-11, 3.3308e-08, 1.3056e-09, 2.1497e-10,
        3.0755e-07, 2.5755e-11, 9.9992e-01, 2.2992e-06, 1.7541e-05, 3.4636e-06,
        1.6869e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,787][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.7617e-09, 6.0796e-09, 3.1277e-08, 8.2802e-08, 1.3753e-06, 1.9117e-07,
        1.6875e-06, 1.7782e-06, 9.5578e-06, 6.9424e-05, 1.4311e-04, 3.2346e-04,
        6.7782e-04, 1.6182e-03, 1.7355e-02, 4.2566e-02, 1.9392e-01, 3.5410e-01,
        3.8920e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,789][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0730, 0.0266, 0.0701, 0.0211, 0.0231, 0.1900, 0.0140, 0.0019, 0.0916,
        0.0034, 0.0329, 0.0126, 0.0033, 0.0176, 0.0259, 0.3287, 0.0113, 0.0504,
        0.0024], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,791][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.3076e-10, 4.7723e-10, 1.3667e-09, 1.0356e-08, 4.7581e-08, 5.8414e-08,
        1.3693e-07, 1.7022e-07, 1.3071e-06, 8.2314e-06, 2.4947e-05, 7.9918e-05,
        2.1886e-04, 1.2106e-03, 3.9971e-03, 2.5266e-02, 1.1368e-01, 1.9228e-01,
        6.6324e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,793][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0026, 0.0057, 0.0416, 0.0082, 0.2061, 0.0190, 0.0095, 0.0378, 0.0157,
        0.0628, 0.0141, 0.0088, 0.0689, 0.0047, 0.3519, 0.0526, 0.0097, 0.0724,
        0.0079], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,795][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0044, 0.0091, 0.0278, 0.0451, 0.1048, 0.0295, 0.0438, 0.0235, 0.0267,
        0.0397, 0.0447, 0.0413, 0.0231, 0.0376, 0.3025, 0.0311, 0.0593, 0.0619,
        0.0443], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,797][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0143, 0.0224, 0.0165, 0.0285, 0.0238, 0.0679, 0.0275, 0.0491, 0.0449,
        0.0477, 0.0760, 0.0312, 0.0633, 0.0298, 0.0381, 0.1965, 0.0370, 0.1642,
        0.0212], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,798][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.1333e-01, 2.3738e-03, 9.4551e-03, 1.1070e-03, 1.0508e-02, 2.5294e-03,
        6.7521e-03, 7.0762e-03, 1.6775e-03, 3.5104e-03, 3.0992e-03, 3.2365e-03,
        8.6268e-03, 1.6708e-03, 4.8848e-03, 2.2037e-03, 9.7226e-03, 7.9486e-03,
        2.9217e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,800][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0019, 0.0052, 0.0195, 0.0181, 0.1107, 0.0286, 0.0316, 0.0427, 0.0467,
        0.0924, 0.0404, 0.0382, 0.0400, 0.0246, 0.2195, 0.0561, 0.0434, 0.1011,
        0.0393], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,801][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0473, 0.0438, 0.0607, 0.0455, 0.0685, 0.0470, 0.0375, 0.0590, 0.0475,
        0.0661, 0.0430, 0.0405, 0.0786, 0.0411, 0.0660, 0.0578, 0.0351, 0.0771,
        0.0380], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:53,804][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:53,806][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 9409],
        [23148],
        [ 9000],
        [25381],
        [18722],
        [33146],
        [20774],
        [16017],
        [32682],
        [ 9143],
        [23118],
        [17158],
        [26531],
        [16473],
        [29301],
        [19866],
        [21142],
        [28117],
        [25137]], device='cuda:0')
[2024-07-24 10:17:53,808][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[10728],
        [11082],
        [12812],
        [22483],
        [38661],
        [33461],
        [21441],
        [11139],
        [24165],
        [ 8313],
        [13467],
        [11588],
        [27922],
        [ 9265],
        [43674],
        [14495],
        [12498],
        [35135],
        [11191]], device='cuda:0')
[2024-07-24 10:17:53,810][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[22229],
        [30187],
        [35247],
        [36333],
        [37857],
        [37157],
        [37031],
        [36528],
        [35976],
        [36627],
        [36669],
        [36625],
        [37308],
        [37606],
        [38071],
        [37823],
        [37783],
        [37786],
        [37693]], device='cuda:0')
[2024-07-24 10:17:53,812][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[25681],
        [28197],
        [25476],
        [10911],
        [ 1321],
        [18539],
        [ 1995],
        [ 8715],
        [34861],
        [11535],
        [35187],
        [ 6048],
        [28633],
        [36846],
        [37382],
        [30659],
        [18732],
        [ 5626],
        [41877]], device='cuda:0')
[2024-07-24 10:17:53,814][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 7637],
        [ 5436],
        [ 3773],
        [ 4090],
        [ 5017],
        [ 5554],
        [ 7714],
        [ 6848],
        [19262],
        [11216],
        [12494],
        [13728],
        [17489],
        [17484],
        [12246],
        [10711],
        [11834],
        [11165],
        [16137]], device='cuda:0')
[2024-07-24 10:17:53,816][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 785],
        [ 700],
        [ 606],
        [ 605],
        [ 663],
        [ 779],
        [ 744],
        [ 739],
        [ 700],
        [ 697],
        [ 649],
        [ 636],
        [ 715],
        [ 731],
        [ 669],
        [ 894],
        [1006],
        [1375],
        [1076]], device='cuda:0')
[2024-07-24 10:17:53,818][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[37538],
        [38411],
        [39790],
        [36957],
        [38747],
        [36810],
        [36835],
        [38247],
        [33900],
        [38627],
        [35486],
        [36762],
        [37546],
        [32154],
        [37795],
        [36797],
        [33544],
        [36862],
        [28856]], device='cuda:0')
[2024-07-24 10:17:53,820][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[31092],
        [42997],
        [43474],
        [42585],
        [42796],
        [43646],
        [44989],
        [45051],
        [44921],
        [45056],
        [45489],
        [45630],
        [45695],
        [45679],
        [45411],
        [45355],
        [45421],
        [45659],
        [45760]], device='cuda:0')
[2024-07-24 10:17:53,821][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[22366],
        [25887],
        [28861],
        [32932],
        [30502],
        [32424],
        [30445],
        [31332],
        [30750],
        [29300],
        [28179],
        [27733],
        [28725],
        [29230],
        [29210],
        [28821],
        [26140],
        [26479],
        [29365]], device='cuda:0')
[2024-07-24 10:17:53,823][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[21018],
        [18528],
        [13774],
        [20144],
        [22636],
        [21808],
        [20592],
        [20114],
        [17485],
        [17885],
        [19114],
        [19406],
        [19661],
        [19115],
        [19468],
        [19265],
        [18953],
        [19064],
        [19854]], device='cuda:0')
[2024-07-24 10:17:53,825][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[12676],
        [12828],
        [14703],
        [12487],
        [10984],
        [12588],
        [16568],
        [19356],
        [16732],
        [21010],
        [18145],
        [ 7622],
        [ 8191],
        [ 8015],
        [ 7861],
        [ 9345],
        [25437],
        [13058],
        [27905]], device='cuda:0')
[2024-07-24 10:17:53,827][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[49389],
        [49129],
        [48740],
        [48378],
        [48582],
        [48305],
        [48226],
        [49124],
        [48818],
        [48693],
        [48956],
        [48986],
        [49017],
        [49142],
        [48986],
        [48128],
        [48544],
        [49224],
        [49070]], device='cuda:0')
[2024-07-24 10:17:53,829][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[37870],
        [42376],
        [36770],
        [37529],
        [36883],
        [35754],
        [36050],
        [33451],
        [34794],
        [33259],
        [34037],
        [34811],
        [34500],
        [34869],
        [34875],
        [34340],
        [34547],
        [33917],
        [34510]], device='cuda:0')
[2024-07-24 10:17:53,831][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 4181],
        [ 4993],
        [ 5358],
        [ 5208],
        [ 5695],
        [ 7834],
        [ 8214],
        [17710],
        [13999],
        [17636],
        [16957],
        [15292],
        [17329],
        [17784],
        [15718],
        [17185],
        [16988],
        [18939],
        [16595]], device='cuda:0')
[2024-07-24 10:17:53,833][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 8217],
        [29289],
        [13970],
        [31761],
        [ 8027],
        [31243],
        [15560],
        [26028],
        [16365],
        [11780],
        [24617],
        [21185],
        [18438],
        [19139],
        [ 9324],
        [19670],
        [19535],
        [12735],
        [21826]], device='cuda:0')
[2024-07-24 10:17:53,835][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[33027],
        [37556],
        [39995],
        [40295],
        [40688],
        [40925],
        [41087],
        [40774],
        [40381],
        [40475],
        [40331],
        [39994],
        [39638],
        [39304],
        [39234],
        [39325],
        [39403],
        [39575],
        [39321]], device='cuda:0')
[2024-07-24 10:17:53,837][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 7391],
        [ 6671],
        [ 6022],
        [ 6557],
        [ 2882],
        [  655],
        [15770],
        [ 1032],
        [ 9300],
        [ 1998],
        [ 3680],
        [ 4699],
        [ 1700],
        [  514],
        [  210],
        [  801],
        [ 6738],
        [ 3180],
        [ 3463]], device='cuda:0')
[2024-07-24 10:17:53,839][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[40623],
        [32596],
        [35832],
        [35829],
        [20539],
        [17109],
        [17115],
        [17105],
        [17098],
        [17111],
        [17120],
        [17115],
        [14882],
        [16943],
        [18547],
        [18549],
        [18548],
        [18548],
        [18548]], device='cuda:0')
[2024-07-24 10:17:53,840][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[40879],
        [36127],
        [38152],
        [39206],
        [34680],
        [32992],
        [38242],
        [28770],
        [35309],
        [39689],
        [37739],
        [41002],
        [39169],
        [32798],
        [31980],
        [33100],
        [35856],
        [30919],
        [36217]], device='cuda:0')
[2024-07-24 10:17:53,842][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[15803],
        [16543],
        [15712],
        [24238],
        [26546],
        [18275],
        [19214],
        [21448],
        [16735],
        [30382],
        [39242],
        [21035],
        [24937],
        [42518],
        [30056],
        [22715],
        [28926],
        [45006],
        [23166]], device='cuda:0')
[2024-07-24 10:17:53,844][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[36838],
        [46847],
        [35428],
        [37856],
        [22779],
        [13820],
        [19951],
        [20689],
        [20815],
        [15565],
        [11877],
        [21833],
        [24021],
        [35499],
        [26484],
        [19341],
        [23311],
        [21768],
        [21363]], device='cuda:0')
[2024-07-24 10:17:53,846][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[26409],
        [27243],
        [26882],
        [25620],
        [27197],
        [26452],
        [25832],
        [25416],
        [25036],
        [25483],
        [25124],
        [24833],
        [25489],
        [24727],
        [24276],
        [24408],
        [24181],
        [24542],
        [24338]], device='cuda:0')
[2024-07-24 10:17:53,848][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[12547],
        [12701],
        [ 9716],
        [ 9575],
        [ 9284],
        [ 9317],
        [ 9309],
        [ 9303],
        [ 9342],
        [ 9356],
        [ 9367],
        [ 9362],
        [ 9368],
        [ 9390],
        [ 9425],
        [ 9432],
        [ 9440],
        [ 9420],
        [ 9426]], device='cuda:0')
[2024-07-24 10:17:53,850][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[32582],
        [33679],
        [33971],
        [35116],
        [36322],
        [35710],
        [34556],
        [34036],
        [35021],
        [34012],
        [34669],
        [35089],
        [35095],
        [35567],
        [35560],
        [36323],
        [36810],
        [36710],
        [37360]], device='cuda:0')
[2024-07-24 10:17:53,852][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[25508],
        [25782],
        [25947],
        [25899],
        [26152],
        [27821],
        [27600],
        [30169],
        [27539],
        [28868],
        [30151],
        [28985],
        [28664],
        [28185],
        [27933],
        [30433],
        [31019],
        [30837],
        [27766]], device='cuda:0')
[2024-07-24 10:17:53,854][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[22656],
        [20767],
        [21861],
        [19817],
        [19750],
        [19723],
        [18630],
        [18623],
        [19620],
        [18867],
        [19127],
        [18948],
        [19293],
        [19485],
        [19441],
        [19759],
        [19495],
        [19237],
        [19299]], device='cuda:0')
[2024-07-24 10:17:53,856][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[24102],
        [24938],
        [17086],
        [18090],
        [15758],
        [16302],
        [17220],
        [18426],
        [18944],
        [18458],
        [18457],
        [18983],
        [19781],
        [20299],
        [19562],
        [19159],
        [19363],
        [18825],
        [18974]], device='cuda:0')
[2024-07-24 10:17:53,858][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[4332],
        [2340],
        [4006],
        [2339],
        [5134],
        [8270],
        [4651],
        [8863],
        [4655],
        [8371],
        [7924],
        [5288],
        [6878],
        [3270],
        [4710],
        [5227],
        [4042],
        [6866],
        [4133]], device='cuda:0')
[2024-07-24 10:17:53,859][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[12509],
        [ 6060],
        [ 5379],
        [ 2519],
        [ 7633],
        [ 2496],
        [ 2461],
        [ 6962],
        [13503],
        [ 7951],
        [ 8257],
        [ 6742],
        [12854],
        [11564],
        [16981],
        [13082],
        [ 6311],
        [10455],
        [12064]], device='cuda:0')
[2024-07-24 10:17:53,861][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[26371],
        [26371],
        [26371],
        [26371],
        [26371],
        [26371],
        [26371],
        [26371],
        [26371],
        [26371],
        [26371],
        [26371],
        [26371],
        [26371],
        [26371],
        [26371],
        [26371],
        [26371],
        [26371]], device='cuda:0')
[2024-07-24 10:17:53,897][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:53,898][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,899][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,899][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,900][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,901][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,901][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,902][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,903][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,905][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,906][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,907][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,907][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:53,909][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4657, 0.5343], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,911][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.6567, 0.3433], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,912][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2884, 0.7116], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,913][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0913, 0.9087], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,914][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4904, 0.5096], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,915][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4498, 0.5502], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,915][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0058, 0.9942], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,916][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5585, 0.4415], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,917][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5531, 0.4469], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,918][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1164, 0.8836], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,920][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.3828, 0.6172], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,921][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.1400e-04, 9.9989e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:53,923][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Jamie] are: tensor([0.1886, 0.2273, 0.5841], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,924][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Jamie] are: tensor([0.4787, 0.2629, 0.2585], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,926][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Jamie] are: tensor([0.1446, 0.4162, 0.4392], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,928][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Jamie] are: tensor([0.0091, 0.7203, 0.2706], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,929][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Jamie] are: tensor([0.3537, 0.3576, 0.2887], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,931][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Jamie] are: tensor([0.2800, 0.3576, 0.3623], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,931][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Jamie] are: tensor([0.0023, 0.7922, 0.2055], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,932][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Jamie] are: tensor([0.3364, 0.3431, 0.3205], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,933][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Jamie] are: tensor([0.3895, 0.3103, 0.3002], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,933][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Jamie] are: tensor([0.0298, 0.6287, 0.3415], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,934][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Jamie] are: tensor([0.1908, 0.5362, 0.2730], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,935][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Jamie] are: tensor([3.6398e-06, 4.4953e-01, 5.5047e-01], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:53,937][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1061, 0.1351, 0.4055, 0.3533], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,939][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.3908, 0.2211, 0.2073, 0.1808], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,940][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0798, 0.2954, 0.3218, 0.3029], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,942][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0136, 0.4522, 0.4270, 0.1072], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,944][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2779, 0.2787, 0.2211, 0.2223], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,945][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1948, 0.2378, 0.2721, 0.2953], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,947][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0016, 0.3640, 0.1122, 0.5221], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,948][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2974, 0.2353, 0.2605, 0.2067], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,949][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2940, 0.2329, 0.2387, 0.2344], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,949][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0291, 0.2733, 0.1076, 0.5900], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,950][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1625, 0.3696, 0.0352, 0.4327], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,951][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([1.3809e-06, 4.6444e-01, 4.0042e-01, 1.3514e-01], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:53,952][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0926, 0.1203, 0.2224, 0.2246, 0.3401], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,954][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.3106, 0.1828, 0.1775, 0.1599, 0.1693], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,956][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0318, 0.2034, 0.2333, 0.2385, 0.2930], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,957][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.0071, 0.3794, 0.3829, 0.1911, 0.0397], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,959][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.2368, 0.2326, 0.1841, 0.1814, 0.1650], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,961][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.1536, 0.1907, 0.2043, 0.2247, 0.2269], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,962][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0008, 0.3047, 0.0813, 0.4982, 0.1151], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,964][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.2022, 0.1980, 0.2239, 0.1887, 0.1871], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,965][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.2346, 0.1907, 0.1946, 0.1897, 0.1905], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,966][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0086, 0.1180, 0.0742, 0.6845, 0.1147], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,967][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0769, 0.1686, 0.1513, 0.5178, 0.0854], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,967][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([1.8396e-07, 2.2605e-01, 3.5617e-01, 2.5180e-01, 1.6598e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:53,968][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0624, 0.0874, 0.1874, 0.1843, 0.3291, 0.1495], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,969][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.2658, 0.1568, 0.1560, 0.1377, 0.1538, 0.1299], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,971][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0558, 0.1693, 0.1869, 0.1770, 0.2020, 0.2091], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,973][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0109, 0.4211, 0.1739, 0.2166, 0.1094, 0.0681], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,975][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1933, 0.1941, 0.1592, 0.1578, 0.1433, 0.1523], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,976][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1190, 0.1453, 0.1663, 0.1802, 0.1892, 0.2001], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,977][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ had] are: tensor([3.3446e-04, 1.8320e-01, 6.1485e-02, 3.3754e-01, 9.3531e-02, 3.2391e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,979][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1906, 0.1650, 0.1793, 0.1470, 0.1707, 0.1474], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,981][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1974, 0.1566, 0.1602, 0.1585, 0.1591, 0.1682], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,982][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0146, 0.1953, 0.0645, 0.3610, 0.0947, 0.2699], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,983][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0919, 0.3139, 0.0496, 0.3545, 0.0833, 0.1068], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,984][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ had] are: tensor([1.5543e-05, 6.8978e-02, 5.9629e-02, 2.3290e-02, 2.2882e-02, 8.2521e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:53,985][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0409, 0.0603, 0.1580, 0.1294, 0.3337, 0.1255, 0.1522],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,985][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.2446, 0.1403, 0.1386, 0.1229, 0.1407, 0.1151, 0.0978],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,987][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0422, 0.1441, 0.1581, 0.1550, 0.1862, 0.1758, 0.1386],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,988][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0082, 0.4758, 0.1980, 0.0885, 0.0461, 0.1253, 0.0580],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,991][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1674, 0.1704, 0.1387, 0.1373, 0.1253, 0.1339, 0.1271],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,992][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1004, 0.1211, 0.1410, 0.1487, 0.1600, 0.1689, 0.1598],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,993][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([5.0159e-05, 1.0184e-01, 3.4700e-02, 2.4555e-01, 6.4487e-02, 2.4621e-01,
        3.0717e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,995][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1647, 0.1428, 0.1517, 0.1294, 0.1472, 0.1390, 0.1252],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,997][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1750, 0.1361, 0.1361, 0.1372, 0.1394, 0.1443, 0.1319],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:53,999][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0005, 0.0469, 0.0186, 0.2452, 0.0376, 0.3601, 0.2911],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,000][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0655, 0.1291, 0.0766, 0.1487, 0.0777, 0.2136, 0.2888],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,001][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([5.6733e-07, 6.3130e-02, 1.0762e-01, 7.4193e-02, 8.6448e-02, 6.5469e-01,
        1.3909e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,001][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0429, 0.0555, 0.1427, 0.1156, 0.2970, 0.1095, 0.1437, 0.0931],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,002][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.2193, 0.1279, 0.1264, 0.1127, 0.1277, 0.1055, 0.0878, 0.0928],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,003][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0427, 0.1265, 0.1380, 0.1344, 0.1500, 0.1501, 0.1209, 0.1375],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,004][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0043, 0.2966, 0.1707, 0.1042, 0.0460, 0.0605, 0.2665, 0.0511],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,006][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.1492, 0.1512, 0.1231, 0.1223, 0.1119, 0.1181, 0.1146, 0.1096],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,008][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0844, 0.1031, 0.1194, 0.1339, 0.1411, 0.1517, 0.1463, 0.1201],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,009][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0004, 0.1144, 0.0343, 0.1880, 0.0523, 0.2095, 0.2833, 0.1178],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,010][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.1394, 0.1313, 0.1353, 0.1246, 0.1235, 0.1265, 0.1162, 0.1032],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,012][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.1565, 0.1256, 0.1187, 0.1217, 0.1171, 0.1245, 0.1181, 0.1178],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,014][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0007, 0.0361, 0.0190, 0.1730, 0.0358, 0.2863, 0.3638, 0.0852],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,016][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0638, 0.0893, 0.0367, 0.1059, 0.0656, 0.3338, 0.0491, 0.2559],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,017][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([1.4983e-06, 6.1799e-02, 1.1302e-01, 9.7443e-02, 1.1231e-01, 5.8496e-01,
        2.1301e-02, 9.1735e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,018][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0315, 0.0487, 0.1428, 0.1119, 0.2869, 0.1013, 0.1373, 0.0797, 0.0599],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,019][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.2106, 0.1177, 0.1147, 0.1014, 0.1139, 0.0961, 0.0800, 0.0851, 0.0806],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,019][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0309, 0.1061, 0.1213, 0.1170, 0.1432, 0.1338, 0.1061, 0.1229, 0.1186],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,020][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0026, 0.2283, 0.1518, 0.0614, 0.0535, 0.0674, 0.0880, 0.3093, 0.0377],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,022][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1360, 0.1389, 0.1110, 0.1102, 0.1017, 0.1075, 0.1016, 0.0972, 0.0959],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,023][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0764, 0.0920, 0.1127, 0.1162, 0.1285, 0.1322, 0.1255, 0.1058, 0.1107],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,025][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ of] are: tensor([1.0251e-04, 7.1362e-02, 2.4106e-02, 1.5676e-01, 3.9357e-02, 1.4681e-01,
        1.6092e-01, 9.4334e-02, 3.0625e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,026][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.1282, 0.1145, 0.1257, 0.1043, 0.1209, 0.1079, 0.1034, 0.0954, 0.0996],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,028][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.1362, 0.1059, 0.1088, 0.1083, 0.1121, 0.1148, 0.1042, 0.1044, 0.1053],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,030][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0009, 0.0472, 0.0146, 0.1813, 0.0292, 0.1655, 0.1415, 0.0536, 0.3662],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,032][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0192, 0.0874, 0.0557, 0.1376, 0.0207, 0.1151, 0.0882, 0.1245, 0.3516],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,033][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ of] are: tensor([1.3062e-06, 5.9525e-02, 1.0646e-01, 7.0367e-02, 7.8513e-02, 6.2923e-01,
        1.8721e-02, 9.4420e-03, 2.7740e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,034][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0430, 0.0564, 0.1363, 0.1037, 0.2489, 0.0982, 0.1270, 0.0817, 0.0630,
        0.0418], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,035][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.1820, 0.1089, 0.1085, 0.0971, 0.1092, 0.0902, 0.0747, 0.0797, 0.0751,
        0.0744], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,036][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0260, 0.0944, 0.1054, 0.1045, 0.1241, 0.1196, 0.0928, 0.1074, 0.1065,
        0.1193], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,037][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0040, 0.2555, 0.1129, 0.1047, 0.0246, 0.1081, 0.1073, 0.1060, 0.1458,
        0.0311], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,038][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.1275, 0.1286, 0.1028, 0.1008, 0.0933, 0.0987, 0.0935, 0.0894, 0.0884,
        0.0771], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,039][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0675, 0.0854, 0.0974, 0.1061, 0.1141, 0.1226, 0.1155, 0.0983, 0.1042,
        0.0888], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,041][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0005, 0.0861, 0.0242, 0.1243, 0.0311, 0.1393, 0.1814, 0.0744, 0.2781,
        0.0606], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,043][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.1043, 0.1046, 0.1107, 0.0955, 0.1010, 0.0987, 0.0958, 0.0942, 0.1026,
        0.0926], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,044][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.1254, 0.0986, 0.0984, 0.0980, 0.0983, 0.1031, 0.0944, 0.0946, 0.0967,
        0.0924], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,045][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([3.1531e-04, 1.4578e-02, 6.2010e-03, 7.6657e-02, 1.1066e-02, 1.5529e-01,
        2.1865e-01, 5.0674e-02, 4.2930e-01, 3.7271e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,048][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0261, 0.0765, 0.0523, 0.1835, 0.0247, 0.1927, 0.0707, 0.1075, 0.0767,
        0.1893], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,049][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([9.5060e-06, 7.6437e-02, 9.9744e-02, 7.7582e-02, 8.4751e-02, 5.1660e-01,
        2.4758e-02, 1.4527e-02, 4.7151e-02, 5.8443e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,051][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0341, 0.0470, 0.1270, 0.1017, 0.2453, 0.0916, 0.1220, 0.0753, 0.0560,
        0.0356, 0.0643], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,052][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.1734, 0.0997, 0.1015, 0.0895, 0.1029, 0.0848, 0.0695, 0.0737, 0.0689,
        0.0712, 0.0649], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,053][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0298, 0.0874, 0.0947, 0.0924, 0.1087, 0.1074, 0.0851, 0.0965, 0.0974,
        0.1070, 0.0936], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,054][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0023, 0.2753, 0.0867, 0.0673, 0.0470, 0.0869, 0.0828, 0.0666, 0.1636,
        0.0679, 0.0538], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,054][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1181, 0.1198, 0.0954, 0.0944, 0.0863, 0.0911, 0.0862, 0.0828, 0.0821,
        0.0710, 0.0729], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,055][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0636, 0.0760, 0.0946, 0.0957, 0.1067, 0.1107, 0.1061, 0.0886, 0.0936,
        0.0864, 0.0782], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,056][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ at] are: tensor([1.0065e-04, 5.2790e-02, 1.8389e-02, 1.0881e-01, 2.7573e-02, 1.0343e-01,
        1.1764e-01, 7.0063e-02, 2.3300e-01, 6.8319e-02, 1.9990e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,058][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.1057, 0.0895, 0.1044, 0.0836, 0.1028, 0.0914, 0.0905, 0.0888, 0.0868,
        0.0954, 0.0610], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,060][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.1166, 0.0900, 0.0885, 0.0902, 0.0906, 0.0950, 0.0867, 0.0854, 0.0889,
        0.0847, 0.0833], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,062][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0012, 0.0352, 0.0148, 0.1015, 0.0188, 0.1008, 0.0894, 0.0346, 0.1975,
        0.0864, 0.3199], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,063][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0508, 0.1427, 0.0568, 0.1347, 0.0360, 0.0658, 0.0621, 0.0645, 0.1179,
        0.0677, 0.2010], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,064][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ at] are: tensor([3.5192e-06, 8.1540e-02, 8.4301e-02, 5.7842e-02, 5.1476e-02, 5.6213e-01,
        1.5863e-02, 9.5038e-03, 3.2591e-02, 4.7068e-02, 5.7679e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,066][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0290, 0.0425, 0.1129, 0.0905, 0.2298, 0.0899, 0.1065, 0.0688, 0.0462,
        0.0362, 0.0602, 0.0875], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,068][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1707, 0.0946, 0.0938, 0.0831, 0.0923, 0.0777, 0.0640, 0.0680, 0.0646,
        0.0656, 0.0609, 0.0648], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,069][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0255, 0.0800, 0.0884, 0.0856, 0.1007, 0.0981, 0.0782, 0.0895, 0.0889,
        0.0983, 0.0880, 0.0787], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,070][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0035, 0.2537, 0.0855, 0.0502, 0.0242, 0.0700, 0.0403, 0.1052, 0.0935,
        0.0728, 0.1175, 0.0835], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,071][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1078, 0.1103, 0.0884, 0.0876, 0.0799, 0.0843, 0.0811, 0.0779, 0.0763,
        0.0662, 0.0678, 0.0725], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,072][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0587, 0.0713, 0.0837, 0.0885, 0.0962, 0.1013, 0.0962, 0.0820, 0.0872,
        0.0779, 0.0735, 0.0836], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,073][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ the] are: tensor([3.3573e-05, 3.7133e-02, 1.3366e-02, 9.0842e-02, 2.1887e-02, 8.1704e-02,
        9.8418e-02, 5.7365e-02, 2.1018e-01, 5.5017e-02, 1.8155e-01, 1.5251e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,074][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1010, 0.0852, 0.0918, 0.0801, 0.0921, 0.0833, 0.0813, 0.0780, 0.0800,
        0.0846, 0.0615, 0.0812], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,076][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1059, 0.0827, 0.0828, 0.0830, 0.0843, 0.0880, 0.0793, 0.0792, 0.0814,
        0.0782, 0.0762, 0.0791], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,077][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0005, 0.0172, 0.0065, 0.0602, 0.0107, 0.0653, 0.0612, 0.0225, 0.1623,
        0.0387, 0.3210, 0.2339], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,079][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0412, 0.0617, 0.0220, 0.0657, 0.0246, 0.1323, 0.1117, 0.1803, 0.0304,
        0.0830, 0.0308, 0.2163], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,080][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.9890e-06, 7.5231e-02, 7.8323e-02, 4.8104e-02, 4.6779e-02, 5.2666e-01,
        8.7866e-03, 5.3949e-03, 1.9191e-02, 4.0970e-02, 5.4413e-02, 9.6147e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,082][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0288, 0.0398, 0.1080, 0.0887, 0.2149, 0.0830, 0.1045, 0.0654, 0.0430,
        0.0333, 0.0521, 0.0792, 0.0592], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,084][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.1537, 0.0863, 0.0860, 0.0770, 0.0862, 0.0733, 0.0608, 0.0649, 0.0621,
        0.0617, 0.0587, 0.0624, 0.0669], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,086][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0322, 0.0721, 0.0785, 0.0778, 0.0910, 0.0871, 0.0729, 0.0832, 0.0825,
        0.0903, 0.0815, 0.0743, 0.0766], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,087][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0012, 0.1261, 0.0608, 0.0620, 0.0171, 0.0490, 0.1372, 0.0427, 0.1599,
        0.0267, 0.1329, 0.1467, 0.0379], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,088][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0981, 0.0994, 0.0814, 0.0815, 0.0741, 0.0782, 0.0754, 0.0726, 0.0711,
        0.0629, 0.0641, 0.0680, 0.0733], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,089][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0517, 0.0679, 0.0757, 0.0855, 0.0892, 0.0997, 0.0933, 0.0753, 0.0824,
        0.0703, 0.0687, 0.0801, 0.0602], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,089][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0002, 0.0467, 0.0128, 0.0715, 0.0177, 0.0806, 0.1151, 0.0464, 0.1921,
        0.0366, 0.1786, 0.1622, 0.0393], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,090][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0825, 0.0788, 0.0847, 0.0785, 0.0768, 0.0779, 0.0762, 0.0737, 0.0772,
        0.0769, 0.0626, 0.0804, 0.0739], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,092][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.0984, 0.0775, 0.0750, 0.0766, 0.0755, 0.0792, 0.0747, 0.0735, 0.0760,
        0.0726, 0.0728, 0.0746, 0.0735], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,094][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ store] are: tensor([1.5808e-04, 6.2546e-03, 2.5871e-03, 2.9081e-02, 3.9796e-03, 6.3702e-02,
        8.1572e-02, 2.1781e-02, 1.6320e-01, 1.6721e-02, 3.7181e-01, 2.2614e-01,
        1.3007e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,096][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0228, 0.0525, 0.0206, 0.0632, 0.0212, 0.1182, 0.0548, 0.1484, 0.0439,
        0.1132, 0.0975, 0.0857, 0.1581], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,097][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ store] are: tensor([5.3566e-06, 6.0410e-02, 7.7677e-02, 5.0570e-02, 3.8201e-02, 5.2429e-01,
        1.1139e-02, 6.7765e-03, 2.7327e-02, 3.0525e-02, 5.5974e-02, 8.0424e-02,
        3.6680e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,099][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0261, 0.0341, 0.0971, 0.0710, 0.2463, 0.0746, 0.0963, 0.0573, 0.0418,
        0.0279, 0.0464, 0.0770, 0.0520, 0.0522], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,101][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.1354, 0.0837, 0.0828, 0.0733, 0.0835, 0.0697, 0.0588, 0.0630, 0.0602,
        0.0609, 0.0571, 0.0602, 0.0633, 0.0480], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,102][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0258, 0.0699, 0.0746, 0.0711, 0.0821, 0.0828, 0.0678, 0.0769, 0.0778,
        0.0829, 0.0754, 0.0695, 0.0732, 0.0700], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,104][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0018, 0.1051, 0.1112, 0.0274, 0.0271, 0.0587, 0.0724, 0.0848, 0.0562,
        0.0937, 0.0362, 0.1077, 0.1910, 0.0268], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,105][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0962, 0.0977, 0.0771, 0.0773, 0.0701, 0.0753, 0.0699, 0.0661, 0.0662,
        0.0576, 0.0594, 0.0620, 0.0665, 0.0584], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,105][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0512, 0.0618, 0.0715, 0.0770, 0.0835, 0.0881, 0.0844, 0.0692, 0.0748,
        0.0666, 0.0625, 0.0732, 0.0578, 0.0784], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,106][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [.] are: tensor([5.6210e-05, 3.9406e-02, 1.4715e-02, 8.1829e-02, 2.4155e-02, 7.2014e-02,
        8.6444e-02, 5.3137e-02, 1.6793e-01, 5.1051e-02, 1.4810e-01, 1.2922e-01,
        4.9687e-02, 8.2258e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,107][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0849, 0.0744, 0.0829, 0.0684, 0.0787, 0.0721, 0.0675, 0.0663, 0.0661,
        0.0733, 0.0511, 0.0729, 0.0752, 0.0662], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,109][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0907, 0.0721, 0.0726, 0.0722, 0.0733, 0.0769, 0.0678, 0.0683, 0.0696,
        0.0673, 0.0651, 0.0682, 0.0676, 0.0684], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,111][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0004, 0.0146, 0.0065, 0.0531, 0.0105, 0.0639, 0.0560, 0.0217, 0.1351,
        0.0425, 0.2430, 0.1989, 0.0261, 0.1278], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,113][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0709, 0.1335, 0.0358, 0.0992, 0.0329, 0.0530, 0.0382, 0.1116, 0.0396,
        0.0481, 0.0464, 0.0650, 0.0703, 0.1556], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,114][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [.] are: tensor([1.0950e-06, 7.3485e-02, 9.2476e-02, 5.0135e-02, 5.2775e-02, 4.4034e-01,
        7.9395e-03, 4.7511e-03, 1.7718e-02, 3.9348e-02, 4.8319e-02, 1.0840e-01,
        4.4189e-02, 2.0118e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,116][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0320, 0.0438, 0.0866, 0.0729, 0.1378, 0.0639, 0.0696, 0.0534, 0.0397,
        0.0309, 0.0500, 0.0627, 0.0479, 0.0520, 0.1569], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,118][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.1290, 0.0789, 0.0782, 0.0706, 0.0771, 0.0659, 0.0538, 0.0562, 0.0550,
        0.0543, 0.0515, 0.0562, 0.0593, 0.0441, 0.0698], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,120][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0090, 0.0567, 0.0666, 0.0723, 0.1087, 0.0768, 0.0595, 0.0694, 0.0722,
        0.0862, 0.0664, 0.0612, 0.0553, 0.0563, 0.0833], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,121][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.0011, 0.0785, 0.0729, 0.0402, 0.0072, 0.0297, 0.0637, 0.0735, 0.1529,
        0.0460, 0.1424, 0.0947, 0.1246, 0.0652, 0.0073], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,122][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0926, 0.0931, 0.0736, 0.0720, 0.0668, 0.0702, 0.0658, 0.0636, 0.0615,
        0.0543, 0.0553, 0.0583, 0.0627, 0.0545, 0.0557], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,123][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0470, 0.0586, 0.0639, 0.0695, 0.0709, 0.0849, 0.0783, 0.0656, 0.0717,
        0.0630, 0.0612, 0.0692, 0.0572, 0.0739, 0.0652], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,124][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([3.8988e-05, 3.0306e-02, 8.4952e-03, 5.9627e-02, 1.1674e-02, 6.6252e-02,
        1.0586e-01, 3.5298e-02, 1.8440e-01, 3.1911e-02, 1.6626e-01, 1.7550e-01,
        3.3346e-02, 8.0127e-02, 1.0898e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,125][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0645, 0.0662, 0.0757, 0.0640, 0.0630, 0.0675, 0.0632, 0.0688, 0.0685,
        0.0703, 0.0581, 0.0703, 0.0764, 0.0640, 0.0594], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,127][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.0869, 0.0669, 0.0667, 0.0673, 0.0693, 0.0707, 0.0630, 0.0637, 0.0657,
        0.0623, 0.0610, 0.0644, 0.0626, 0.0654, 0.0641], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,128][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([6.7714e-05, 2.7623e-03, 1.6132e-03, 3.0157e-02, 3.3851e-03, 5.6216e-02,
        8.0641e-02, 1.0974e-02, 1.7606e-01, 9.9480e-03, 2.7913e-01, 2.1058e-01,
        1.0353e-02, 1.2422e-01, 3.8912e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,130][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0150, 0.0331, 0.0277, 0.1031, 0.0146, 0.1066, 0.1170, 0.0832, 0.0586,
        0.0733, 0.0532, 0.1909, 0.0567, 0.0475, 0.0194], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,131][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([3.8000e-07, 3.7580e-02, 7.3306e-02, 7.6336e-02, 5.2155e-02, 4.4438e-01,
        8.7311e-03, 4.8026e-03, 1.8814e-02, 2.4869e-02, 4.9694e-02, 8.2059e-02,
        3.9527e-02, 2.6976e-02, 6.0773e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,133][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0220, 0.0313, 0.0748, 0.0638, 0.1389, 0.0586, 0.0710, 0.0454, 0.0353,
        0.0254, 0.0410, 0.0586, 0.0425, 0.0482, 0.1819, 0.0613],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,135][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.1229, 0.0736, 0.0741, 0.0661, 0.0728, 0.0608, 0.0499, 0.0528, 0.0520,
        0.0506, 0.0485, 0.0522, 0.0559, 0.0416, 0.0668, 0.0595],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,137][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0220, 0.0562, 0.0630, 0.0617, 0.0776, 0.0684, 0.0590, 0.0672, 0.0651,
        0.0736, 0.0634, 0.0580, 0.0597, 0.0593, 0.0792, 0.0667],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,138][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0020, 0.1196, 0.0566, 0.0670, 0.0066, 0.0264, 0.0492, 0.0460, 0.1699,
        0.0494, 0.1379, 0.0845, 0.0787, 0.0896, 0.0071, 0.0093],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,139][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0839, 0.0847, 0.0688, 0.0684, 0.0625, 0.0656, 0.0624, 0.0599, 0.0590,
        0.0517, 0.0532, 0.0559, 0.0604, 0.0515, 0.0517, 0.0603],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,140][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0429, 0.0546, 0.0607, 0.0667, 0.0700, 0.0758, 0.0719, 0.0598, 0.0669,
        0.0567, 0.0566, 0.0635, 0.0527, 0.0693, 0.0647, 0.0672],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,141][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([1.0582e-04, 3.7563e-02, 1.2088e-02, 6.6111e-02, 1.7488e-02, 5.9515e-02,
        9.1367e-02, 4.2182e-02, 1.4982e-01, 3.8114e-02, 1.3795e-01, 1.4664e-01,
        4.0987e-02, 8.4476e-02, 1.6461e-02, 5.9135e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,142][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0734, 0.0635, 0.0707, 0.0570, 0.0654, 0.0590, 0.0618, 0.0589, 0.0615,
        0.0643, 0.0486, 0.0663, 0.0666, 0.0591, 0.0624, 0.0615],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,144][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0821, 0.0628, 0.0610, 0.0627, 0.0626, 0.0654, 0.0608, 0.0597, 0.0621,
        0.0590, 0.0586, 0.0605, 0.0592, 0.0624, 0.0608, 0.0604],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,146][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0006, 0.0120, 0.0037, 0.0433, 0.0066, 0.0379, 0.0547, 0.0182, 0.1085,
        0.0219, 0.2117, 0.1985, 0.0167, 0.1284, 0.0053, 0.1319],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,148][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0138, 0.0841, 0.0072, 0.0741, 0.0115, 0.1163, 0.0817, 0.1046, 0.0889,
        0.0835, 0.0714, 0.0727, 0.0450, 0.0811, 0.0171, 0.0468],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,149][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([6.7879e-06, 7.5542e-02, 7.9499e-02, 6.2322e-02, 3.8151e-02, 3.8672e-01,
        9.2136e-03, 5.5643e-03, 2.1441e-02, 2.6237e-02, 4.6462e-02, 7.1745e-02,
        4.1707e-02, 2.7639e-02, 4.5986e-02, 6.1768e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,151][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0185, 0.0286, 0.0687, 0.0541, 0.1400, 0.0582, 0.0653, 0.0447, 0.0304,
        0.0284, 0.0424, 0.0522, 0.0397, 0.0396, 0.1546, 0.0570, 0.0776],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,153][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1241, 0.0700, 0.0689, 0.0622, 0.0678, 0.0563, 0.0471, 0.0503, 0.0486,
        0.0478, 0.0451, 0.0485, 0.0521, 0.0402, 0.0637, 0.0566, 0.0507],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,155][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0148, 0.0541, 0.0611, 0.0597, 0.0768, 0.0700, 0.0539, 0.0615, 0.0621,
        0.0707, 0.0601, 0.0542, 0.0559, 0.0555, 0.0736, 0.0641, 0.0518],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,156][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0024, 0.1616, 0.0502, 0.0311, 0.0126, 0.0417, 0.0213, 0.0989, 0.0533,
        0.0370, 0.0763, 0.0633, 0.2242, 0.0627, 0.0130, 0.0318, 0.0185],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,157][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0785, 0.0808, 0.0647, 0.0644, 0.0587, 0.0618, 0.0594, 0.0568, 0.0560,
        0.0481, 0.0496, 0.0528, 0.0573, 0.0477, 0.0485, 0.0568, 0.0576],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,157][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0410, 0.0499, 0.0582, 0.0610, 0.0664, 0.0707, 0.0664, 0.0577, 0.0607,
        0.0550, 0.0522, 0.0587, 0.0494, 0.0643, 0.0619, 0.0639, 0.0627],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,158][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([1.4269e-05, 2.3745e-02, 9.5498e-03, 6.5149e-02, 1.6197e-02, 5.5042e-02,
        7.9268e-02, 4.2047e-02, 1.6419e-01, 3.8453e-02, 1.3837e-01, 1.2371e-01,
        3.8937e-02, 8.2078e-02, 1.4641e-02, 6.1600e-02, 4.7014e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,160][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0693, 0.0600, 0.0642, 0.0556, 0.0619, 0.0584, 0.0542, 0.0542, 0.0576,
        0.0607, 0.0454, 0.0598, 0.0630, 0.0585, 0.0596, 0.0639, 0.0536],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,162][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0757, 0.0596, 0.0593, 0.0605, 0.0611, 0.0641, 0.0567, 0.0563, 0.0585,
        0.0559, 0.0545, 0.0568, 0.0557, 0.0577, 0.0564, 0.0566, 0.0543],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,163][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([3.8906e-04, 7.4402e-03, 2.3319e-03, 2.5962e-02, 4.1071e-03, 2.4605e-02,
        1.8283e-02, 7.7405e-03, 5.2250e-02, 1.3955e-02, 1.0957e-01, 8.1732e-02,
        1.0824e-02, 5.8912e-02, 2.4194e-03, 1.4846e-01, 4.3102e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,165][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0243, 0.0471, 0.0212, 0.0547, 0.0202, 0.0721, 0.1028, 0.1640, 0.0235,
        0.0630, 0.0290, 0.0919, 0.0473, 0.0497, 0.0289, 0.0280, 0.1323],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,167][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.4581e-06, 7.4064e-02, 7.2057e-02, 4.1414e-02, 2.9444e-02, 4.6433e-01,
        3.4744e-03, 3.1487e-03, 1.0591e-02, 2.4613e-02, 3.1279e-02, 5.2939e-02,
        3.5424e-02, 1.4862e-02, 2.8757e-02, 6.0096e-02, 5.3503e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,169][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.0229, 0.0314, 0.0689, 0.0594, 0.1079, 0.0489, 0.0643, 0.0425, 0.0339,
        0.0218, 0.0374, 0.0558, 0.0410, 0.0457, 0.1365, 0.0547, 0.0753, 0.0517],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,171][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.1222, 0.0667, 0.0653, 0.0593, 0.0646, 0.0535, 0.0449, 0.0483, 0.0461,
        0.0449, 0.0423, 0.0460, 0.0496, 0.0373, 0.0599, 0.0534, 0.0488, 0.0472],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,172][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0125, 0.0467, 0.0548, 0.0556, 0.0781, 0.0645, 0.0517, 0.0583, 0.0599,
        0.0682, 0.0563, 0.0509, 0.0501, 0.0508, 0.0786, 0.0604, 0.0482, 0.0542],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,173][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.0008, 0.0651, 0.0643, 0.0316, 0.0120, 0.0245, 0.1147, 0.0307, 0.1272,
        0.0343, 0.0762, 0.1220, 0.0753, 0.0631, 0.0133, 0.0384, 0.0934, 0.0129],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,174][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0755, 0.0768, 0.0610, 0.0601, 0.0554, 0.0586, 0.0559, 0.0539, 0.0531,
        0.0465, 0.0479, 0.0505, 0.0542, 0.0462, 0.0472, 0.0541, 0.0550, 0.0480],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,175][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.0366, 0.0465, 0.0540, 0.0580, 0.0630, 0.0700, 0.0638, 0.0541, 0.0587,
        0.0514, 0.0490, 0.0568, 0.0459, 0.0605, 0.0586, 0.0636, 0.0600, 0.0497],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,176][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([1.3386e-04, 3.1142e-02, 8.2856e-03, 5.0338e-02, 1.1381e-02, 5.9353e-02,
        1.0638e-01, 3.1528e-02, 1.5352e-01, 2.0857e-02, 1.4621e-01, 1.4585e-01,
        2.4223e-02, 7.1345e-02, 1.0701e-02, 4.8517e-02, 6.7285e-02, 1.2960e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,178][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0579, 0.0552, 0.0619, 0.0526, 0.0561, 0.0511, 0.0548, 0.0563, 0.0570,
        0.0574, 0.0468, 0.0608, 0.0609, 0.0525, 0.0531, 0.0595, 0.0545, 0.0514],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,180][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.0745, 0.0552, 0.0540, 0.0559, 0.0573, 0.0588, 0.0542, 0.0530, 0.0561,
        0.0525, 0.0521, 0.0543, 0.0526, 0.0555, 0.0557, 0.0544, 0.0524, 0.0515],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,182][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([1.0733e-04, 2.3522e-03, 9.1925e-04, 1.2670e-02, 1.6801e-03, 2.4462e-02,
        3.4375e-02, 6.7177e-03, 6.9207e-02, 5.0649e-03, 1.2534e-01, 1.0312e-01,
        4.6808e-03, 5.6531e-02, 1.8573e-03, 8.0604e-02, 4.6135e-01, 8.9678e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,183][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0112, 0.0533, 0.0167, 0.0698, 0.0111, 0.1279, 0.0632, 0.0533, 0.0582,
        0.0730, 0.0325, 0.0985, 0.0564, 0.0574, 0.0172, 0.0603, 0.0901, 0.0500],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,185][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([6.5972e-06, 5.9074e-02, 6.3777e-02, 5.0692e-02, 3.5843e-02, 4.0317e-01,
        8.2078e-03, 5.1548e-03, 1.8506e-02, 2.2158e-02, 3.7867e-02, 5.0480e-02,
        3.2487e-02, 2.0721e-02, 4.5482e-02, 4.8904e-02, 4.8385e-02, 4.9082e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,186][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0164, 0.0234, 0.0627, 0.0509, 0.1300, 0.0477, 0.0631, 0.0366, 0.0271,
        0.0164, 0.0294, 0.0502, 0.0328, 0.0349, 0.1775, 0.0490, 0.0762, 0.0448,
        0.0309], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,188][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1131, 0.0637, 0.0627, 0.0566, 0.0618, 0.0525, 0.0434, 0.0454, 0.0438,
        0.0437, 0.0405, 0.0439, 0.0464, 0.0363, 0.0573, 0.0522, 0.0469, 0.0452,
        0.0445], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,189][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0140, 0.0476, 0.0543, 0.0527, 0.0706, 0.0622, 0.0487, 0.0550, 0.0566,
        0.0629, 0.0533, 0.0481, 0.0496, 0.0482, 0.0708, 0.0582, 0.0465, 0.0557,
        0.0451], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,190][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0017, 0.1035, 0.0496, 0.0219, 0.0155, 0.0503, 0.0536, 0.0529, 0.0535,
        0.0750, 0.0250, 0.0936, 0.1896, 0.0733, 0.0160, 0.0416, 0.0454, 0.0303,
        0.0078], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,191][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0721, 0.0732, 0.0582, 0.0577, 0.0527, 0.0558, 0.0532, 0.0517, 0.0506,
        0.0444, 0.0456, 0.0481, 0.0517, 0.0440, 0.0447, 0.0513, 0.0522, 0.0455,
        0.0474], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,192][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0375, 0.0452, 0.0524, 0.0556, 0.0597, 0.0641, 0.0606, 0.0515, 0.0547,
        0.0492, 0.0458, 0.0533, 0.0430, 0.0579, 0.0553, 0.0580, 0.0568, 0.0481,
        0.0515], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,193][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([4.0060e-05, 2.5907e-02, 7.9181e-03, 6.0111e-02, 1.1090e-02, 4.9677e-02,
        6.3512e-02, 3.5249e-02, 1.2842e-01, 2.9425e-02, 1.1281e-01, 1.0216e-01,
        3.1281e-02, 6.9707e-02, 9.3037e-03, 5.1118e-02, 3.5149e-02, 1.3692e-02,
        1.6343e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,196][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0613, 0.0537, 0.0604, 0.0506, 0.0576, 0.0518, 0.0516, 0.0489, 0.0512,
        0.0548, 0.0393, 0.0540, 0.0558, 0.0506, 0.0543, 0.0575, 0.0506, 0.0523,
        0.0434], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,197][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0681, 0.0528, 0.0535, 0.0543, 0.0559, 0.0579, 0.0515, 0.0506, 0.0526,
        0.0503, 0.0490, 0.0513, 0.0498, 0.0520, 0.0515, 0.0510, 0.0495, 0.0480,
        0.0504], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,199][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([3.6406e-04, 7.1924e-03, 2.4519e-03, 1.9595e-02, 3.2796e-03, 1.8654e-02,
        1.7723e-02, 7.6581e-03, 3.5287e-02, 1.3271e-02, 6.4853e-02, 7.2542e-02,
        9.0124e-03, 4.6757e-02, 2.1701e-03, 1.0411e-01, 3.6659e-01, 2.7643e-02,
        1.8085e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,200][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0084, 0.0446, 0.0160, 0.0474, 0.0102, 0.0821, 0.0258, 0.0384, 0.0466,
        0.0225, 0.1527, 0.0360, 0.0843, 0.0603, 0.0173, 0.0306, 0.0349, 0.0835,
        0.1587], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,202][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.9923e-06, 6.8687e-02, 4.5623e-02, 3.2399e-02, 1.9771e-02, 4.4924e-01,
        4.3037e-03, 2.9344e-03, 8.8008e-03, 2.1700e-02, 2.5751e-02, 4.7878e-02,
        2.7242e-02, 1.2084e-02, 1.9764e-02, 4.5494e-02, 4.6217e-02, 6.7606e-02,
        5.4505e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,247][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:54,248][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,248][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,249][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,250][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,251][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,251][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,253][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,253][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,254][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,255][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,255][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,256][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,257][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.9926e-01, 7.3722e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,257][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.4208, 0.5792], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,258][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0547, 0.9453], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,259][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4734, 0.5266], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,260][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5498, 0.4502], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,262][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3036, 0.6964], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,263][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.5506, 0.4494], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,265][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0418, 0.9582], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,267][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2143, 0.7857], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,268][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.6538, 0.3462], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,270][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.6285, 0.3715], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,271][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.4453, 0.5547], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,272][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Jamie] are: tensor([0.7843, 0.0553, 0.1604], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,273][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Jamie] are: tensor([0.1050, 0.3471, 0.5479], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,273][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Jamie] are: tensor([0.1288, 0.8621, 0.0091], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,274][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Jamie] are: tensor([0.3287, 0.3722, 0.2991], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,275][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Jamie] are: tensor([0.3548, 0.2983, 0.3469], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,276][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Jamie] are: tensor([0.1844, 0.4494, 0.3661], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,278][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Jamie] are: tensor([0.0376, 0.7434, 0.2190], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,279][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Jamie] are: tensor([0.0010, 0.9798, 0.0192], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,281][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Jamie] are: tensor([0.0116, 0.9637, 0.0247], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,282][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Jamie] are: tensor([0.0572, 0.8583, 0.0845], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,284][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Jamie] are: tensor([0.4305, 0.2470, 0.3225], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,286][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Jamie] are: tensor([0.3024, 0.4256, 0.2719], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,288][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9616, 0.0066, 0.0218, 0.0100], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,289][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0906, 0.1807, 0.6113, 0.1174], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,290][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0831, 0.6804, 0.2156, 0.0209], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,290][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2579, 0.2940, 0.2382, 0.2099], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,291][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2551, 0.2154, 0.2668, 0.2627], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,292][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1274, 0.2793, 0.2429, 0.3504], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,292][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3415, 0.1424, 0.0967, 0.4194], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,294][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0538, 0.2004, 0.0238, 0.7220], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,296][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0987, 0.2653, 0.0171, 0.6189], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,298][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2423, 0.3183, 0.0239, 0.4156], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,299][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.3541, 0.2082, 0.2098, 0.2279], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,301][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1700, 0.4068, 0.2314, 0.1918], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,303][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.7143, 0.0386, 0.0893, 0.0508, 0.1070], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,305][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0428, 0.2329, 0.3384, 0.1683, 0.2177], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,306][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.0934, 0.8014, 0.0161, 0.0807, 0.0083], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,307][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.1938, 0.2364, 0.2200, 0.2075, 0.1423], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,308][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.2024, 0.1708, 0.1998, 0.1942, 0.2329], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,308][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.0947, 0.2309, 0.1861, 0.2888, 0.1995], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,309][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0138, 0.2058, 0.0557, 0.5644, 0.1603], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,310][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0010, 0.2087, 0.0127, 0.7405, 0.0372], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,312][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.0047, 0.1250, 0.0052, 0.8455, 0.0195], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,314][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.0381, 0.1561, 0.0583, 0.5810, 0.1665], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,315][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.2640, 0.1484, 0.1985, 0.1864, 0.2026], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,317][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.1146, 0.3165, 0.2437, 0.2946, 0.0307], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,319][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.7596, 0.0279, 0.0560, 0.0326, 0.0744, 0.0495], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,321][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0569, 0.1264, 0.3033, 0.1354, 0.3333, 0.0446], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,322][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.1959, 0.1332, 0.1083, 0.1436, 0.4137, 0.0052], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,323][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1546, 0.1852, 0.1517, 0.1530, 0.1313, 0.2242], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,324][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1587, 0.1327, 0.1630, 0.1605, 0.1992, 0.1858], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,325][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0819, 0.1784, 0.1504, 0.2188, 0.1571, 0.2135], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,326][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0166, 0.0644, 0.0652, 0.3676, 0.4046, 0.0816], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,326][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0017, 0.0628, 0.0110, 0.5792, 0.2861, 0.0593], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,328][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0094, 0.1509, 0.0128, 0.6326, 0.1386, 0.0557], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,330][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0537, 0.3431, 0.0079, 0.4226, 0.0742, 0.0985], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,331][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2146, 0.1398, 0.1540, 0.1643, 0.1748, 0.1525], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,333][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.2354, 0.2296, 0.1459, 0.1867, 0.1070, 0.0955], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,335][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.8690, 0.0091, 0.0281, 0.0139, 0.0363, 0.0247, 0.0188],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,337][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0329, 0.1228, 0.2631, 0.1074, 0.3516, 0.0501, 0.0722],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,338][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0635, 0.6094, 0.0253, 0.1818, 0.1021, 0.0136, 0.0043],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,340][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1070, 0.1402, 0.1164, 0.1060, 0.0929, 0.1948, 0.2426],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,341][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1310, 0.1120, 0.1381, 0.1347, 0.1699, 0.1581, 0.1562],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,342][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0701, 0.1449, 0.1258, 0.1765, 0.1318, 0.1730, 0.1779],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,342][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([9.6416e-06, 3.9289e-02, 2.3652e-02, 4.9249e-01, 3.9272e-01, 5.1530e-02,
        3.0555e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,343][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([3.6747e-08, 3.6779e-02, 3.2998e-03, 7.2017e-01, 2.1618e-01, 2.3560e-02,
        8.3830e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,344][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.0589e-06, 7.5596e-02, 4.6695e-03, 7.8444e-01, 1.1413e-01, 2.1151e-02,
        2.0633e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,345][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([8.4631e-05, 1.0961e-01, 1.6977e-02, 6.0109e-01, 1.6285e-01, 1.0856e-01,
        8.3195e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,347][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1918, 0.1159, 0.1326, 0.1368, 0.1465, 0.1425, 0.1340],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,348][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0846, 0.2621, 0.1899, 0.1486, 0.1340, 0.1187, 0.0620],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,350][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.8323, 0.0150, 0.0327, 0.0153, 0.0383, 0.0257, 0.0213, 0.0193],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,351][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0189, 0.1436, 0.2039, 0.1096, 0.3056, 0.0540, 0.0816, 0.0827],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,353][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.3883, 0.3583, 0.0176, 0.0864, 0.0069, 0.0039, 0.1345, 0.0041],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,355][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0820, 0.1033, 0.0906, 0.0904, 0.0804, 0.1433, 0.2345, 0.1754],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,357][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.1223, 0.1032, 0.1180, 0.1154, 0.1406, 0.1324, 0.1304, 0.1377],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,358][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0556, 0.1301, 0.1068, 0.1627, 0.1150, 0.1562, 0.1646, 0.1090],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,359][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([2.7511e-06, 5.1486e-02, 1.7216e-02, 6.1581e-01, 2.7970e-01, 3.5303e-02,
        3.5500e-04, 1.2096e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,359][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([4.0035e-09, 2.9405e-02, 2.0805e-03, 7.9412e-01, 1.5539e-01, 1.8993e-02,
        5.9528e-06, 3.4176e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,360][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([2.5066e-07, 5.3931e-02, 4.3918e-03, 7.7119e-01, 1.4556e-01, 2.4900e-02,
        2.2605e-05, 7.7951e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,361][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([2.7919e-05, 6.3421e-02, 1.6516e-02, 4.8461e-01, 3.7005e-01, 6.4629e-02,
        5.2530e-04, 2.1470e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,362][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.1770, 0.1097, 0.1129, 0.1231, 0.1332, 0.1292, 0.1052, 0.1098],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,364][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0491, 0.0888, 0.0513, 0.0616, 0.0191, 0.0493, 0.1794, 0.5014],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,366][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.8756, 0.0063, 0.0219, 0.0091, 0.0310, 0.0170, 0.0123, 0.0115, 0.0154],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,367][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0220, 0.0967, 0.2623, 0.0930, 0.2901, 0.0462, 0.0820, 0.0822, 0.0254],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,368][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([2.6117e-02, 2.1820e-01, 1.1492e-02, 1.7320e-01, 1.5742e-02, 2.7490e-03,
        5.2175e-01, 3.0305e-02, 4.5216e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,370][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0673, 0.0865, 0.0773, 0.0661, 0.0747, 0.1289, 0.1790, 0.2234, 0.0968],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,372][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0982, 0.0831, 0.1043, 0.1031, 0.1322, 0.1226, 0.1207, 0.1210, 0.1147],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,374][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0539, 0.1080, 0.0957, 0.1329, 0.1014, 0.1304, 0.1345, 0.0956, 0.1475],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,375][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([9.7448e-05, 4.3814e-02, 2.3494e-02, 5.9983e-01, 2.8396e-01, 4.7016e-02,
        6.3774e-04, 3.3594e-04, 8.1257e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,376][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([7.3563e-07, 2.9183e-02, 2.2389e-03, 6.9598e-01, 2.4461e-01, 2.7882e-02,
        1.7116e-05, 1.0529e-05, 7.1009e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,377][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([1.1818e-05, 5.2445e-02, 9.3806e-03, 7.7072e-01, 1.4260e-01, 2.4596e-02,
        3.5122e-05, 1.1935e-05, 2.0379e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,377][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([3.9396e-04, 9.0025e-02, 1.0447e-02, 6.3859e-01, 1.8913e-01, 6.6931e-02,
        8.6560e-04, 5.3507e-04, 3.0810e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,378][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.1574, 0.0992, 0.1093, 0.1123, 0.1109, 0.1122, 0.1014, 0.0841, 0.1131],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,379][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0201, 0.0804, 0.1018, 0.0520, 0.0699, 0.0434, 0.0729, 0.5437, 0.0158],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,381][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.7648, 0.0154, 0.0354, 0.0167, 0.0423, 0.0292, 0.0233, 0.0219, 0.0268,
        0.0241], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,383][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0230, 0.1228, 0.1694, 0.1080, 0.2334, 0.0480, 0.0749, 0.1272, 0.0375,
        0.0559], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,385][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0894, 0.1668, 0.0190, 0.1001, 0.0136, 0.0039, 0.1396, 0.0476, 0.4185,
        0.0016], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,386][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0658, 0.0912, 0.0762, 0.0761, 0.0564, 0.1327, 0.1518, 0.1582, 0.1041,
        0.0874], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,388][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0977, 0.0817, 0.0914, 0.0908, 0.1096, 0.1034, 0.1001, 0.1056, 0.0987,
        0.1211], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,390][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0407, 0.0984, 0.0808, 0.1257, 0.0870, 0.1203, 0.1286, 0.0854, 0.1456,
        0.0876], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,391][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([4.1923e-05, 4.8156e-02, 1.6808e-02, 6.2800e-01, 2.5269e-01, 5.0745e-02,
        2.9946e-04, 1.7202e-04, 9.0516e-04, 2.1820e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,392][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([2.3445e-07, 2.8101e-02, 1.8331e-03, 7.3541e-01, 2.1300e-01, 2.1420e-02,
        7.1704e-06, 3.8493e-06, 6.3014e-05, 1.5682e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,393][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([3.6292e-06, 4.2512e-02, 3.8475e-03, 7.6246e-01, 1.7074e-01, 2.0125e-02,
        1.0341e-05, 7.0289e-06, 1.7257e-04, 1.2800e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,394][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([1.6156e-04, 9.5486e-02, 1.8985e-02, 5.5764e-01, 1.3427e-01, 1.8516e-01,
        7.4972e-04, 5.1083e-04, 3.6440e-03, 3.3957e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,395][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.1492, 0.0855, 0.0999, 0.1030, 0.1025, 0.1012, 0.0885, 0.0746, 0.0886,
        0.1071], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,396][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0374, 0.0424, 0.0723, 0.0472, 0.0517, 0.0242, 0.1028, 0.5203, 0.0521,
        0.0496], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,397][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.8269, 0.0078, 0.0244, 0.0106, 0.0314, 0.0209, 0.0153, 0.0142, 0.0177,
        0.0158, 0.0151], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,399][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0251, 0.0983, 0.2019, 0.0743, 0.2832, 0.0449, 0.0693, 0.0882, 0.0277,
        0.0584, 0.0287], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,400][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0372, 0.3282, 0.0259, 0.1226, 0.0336, 0.0088, 0.2751, 0.0467, 0.0503,
        0.0700, 0.0017], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,402][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0640, 0.0863, 0.0575, 0.0617, 0.0559, 0.1090, 0.1337, 0.1343, 0.1013,
        0.1112, 0.0850], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,403][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0882, 0.0707, 0.0813, 0.0786, 0.0960, 0.0903, 0.0875, 0.0934, 0.0857,
        0.1088, 0.1195], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,406][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0377, 0.0923, 0.0750, 0.1190, 0.0808, 0.1115, 0.1177, 0.0773, 0.1344,
        0.0808, 0.0735], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,407][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([8.3910e-05, 4.0550e-02, 1.9456e-02, 5.3238e-01, 3.5823e-01, 4.2636e-02,
        5.4308e-04, 2.3181e-04, 1.0621e-03, 3.6296e-03, 1.1983e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,408][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([5.9560e-07, 2.5673e-02, 2.4309e-03, 6.8931e-01, 2.6123e-01, 2.0292e-02,
        1.6251e-05, 1.2785e-05, 1.0713e-04, 7.9444e-04, 1.3987e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,409][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([9.2244e-06, 5.9283e-02, 3.9628e-03, 8.1954e-01, 9.3251e-02, 2.2817e-02,
        3.1023e-05, 1.7803e-05, 3.0144e-04, 4.8133e-04, 3.0753e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,410][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([5.1071e-04, 9.1371e-02, 2.5700e-02, 6.6870e-01, 1.3270e-01, 6.3882e-02,
        1.2232e-03, 4.9522e-04, 3.5798e-03, 8.5852e-03, 3.2516e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,411][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.1291, 0.0776, 0.0919, 0.0908, 0.0970, 0.0851, 0.0839, 0.0637, 0.0832,
        0.0817, 0.1160], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,412][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0248, 0.0748, 0.0278, 0.0460, 0.0189, 0.0477, 0.0432, 0.5020, 0.0403,
        0.1347, 0.0399], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,413][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.7945, 0.0078, 0.0263, 0.0123, 0.0346, 0.0228, 0.0167, 0.0155, 0.0200,
        0.0172, 0.0163, 0.0159], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,414][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0219, 0.0818, 0.2205, 0.0716, 0.2676, 0.0345, 0.0461, 0.0923, 0.0199,
        0.0484, 0.0317, 0.0639], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,416][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0797, 0.3801, 0.0102, 0.0634, 0.0434, 0.0047, 0.0085, 0.0724, 0.1948,
        0.0841, 0.0557, 0.0030], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,418][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0527, 0.0784, 0.0556, 0.0528, 0.0485, 0.1014, 0.1161, 0.1348, 0.0820,
        0.1021, 0.0795, 0.0960], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,419][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0719, 0.0597, 0.0740, 0.0723, 0.0919, 0.0856, 0.0839, 0.0866, 0.0798,
        0.0990, 0.1072, 0.0881], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,422][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0390, 0.0835, 0.0715, 0.1029, 0.0762, 0.0997, 0.1032, 0.0722, 0.1156,
        0.0754, 0.0708, 0.0900], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,423][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([8.3828e-04, 4.0198e-02, 2.2789e-02, 5.6343e-01, 3.1296e-01, 4.0294e-02,
        4.8681e-04, 2.0893e-04, 1.1685e-03, 3.3273e-03, 1.5296e-03, 1.2772e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,424][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([2.4777e-05, 3.3732e-02, 1.8398e-03, 6.7053e-01, 2.6995e-01, 1.9950e-02,
        1.3529e-05, 1.0048e-05, 1.0926e-04, 5.9899e-04, 1.9757e-04, 3.0410e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,425][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([1.7449e-04, 5.2349e-02, 3.2627e-03, 7.9832e-01, 1.1666e-01, 2.3201e-02,
        2.5498e-05, 1.4168e-05, 3.4543e-04, 4.8985e-04, 5.9430e-04, 4.5651e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,427][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0025, 0.1135, 0.0164, 0.6197, 0.1358, 0.0749, 0.0009, 0.0007, 0.0041,
        0.0063, 0.0065, 0.0188], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,429][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1204, 0.0669, 0.0771, 0.0760, 0.0852, 0.0845, 0.0759, 0.0704, 0.0695,
        0.0835, 0.0875, 0.1031], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,431][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0219, 0.0801, 0.0502, 0.0570, 0.0466, 0.0394, 0.0564, 0.2816, 0.0461,
        0.1636, 0.1300, 0.0271], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,432][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.6970, 0.0081, 0.0343, 0.0165, 0.0457, 0.0317, 0.0238, 0.0226, 0.0262,
        0.0236, 0.0227, 0.0226, 0.0252], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,433][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0107, 0.0777, 0.1287, 0.1018, 0.2094, 0.0391, 0.0600, 0.0743, 0.0325,
        0.0611, 0.0442, 0.1086, 0.0520], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,434][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.0216, 0.1196, 0.0061, 0.0408, 0.0107, 0.0008, 0.0955, 0.0074, 0.1578,
        0.0067, 0.2028, 0.3286, 0.0016], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,435][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.0448, 0.0589, 0.0503, 0.0509, 0.0447, 0.0905, 0.1231, 0.1130, 0.0857,
        0.0858, 0.0870, 0.0929, 0.0723], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,436][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0729, 0.0590, 0.0682, 0.0669, 0.0817, 0.0760, 0.0747, 0.0780, 0.0731,
        0.0906, 0.0998, 0.0804, 0.0788], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,438][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.0319, 0.0781, 0.0632, 0.0999, 0.0690, 0.0948, 0.1003, 0.0662, 0.1141,
        0.0695, 0.0633, 0.0864, 0.0633], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,439][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([6.3308e-05, 2.5665e-02, 1.4102e-02, 6.4855e-01, 2.3280e-01, 4.1808e-02,
        2.4877e-04, 1.4383e-04, 1.1927e-03, 3.8077e-03, 1.8464e-03, 1.6591e-02,
        1.3185e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,440][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([9.4813e-07, 3.3602e-02, 1.8182e-03, 7.7715e-01, 1.6291e-01, 1.7193e-02,
        5.8083e-06, 4.8885e-06, 8.2978e-05, 3.7494e-04, 1.7986e-04, 5.4941e-03,
        1.1809e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,442][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([2.0485e-05, 2.9169e-02, 2.9411e-03, 7.8123e-01, 1.5687e-01, 2.1467e-02,
        1.5422e-05, 7.5723e-06, 2.7499e-04, 4.0021e-04, 6.6448e-04, 6.0333e-03,
        9.0612e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,443][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([5.7679e-04, 6.1289e-02, 1.5640e-02, 6.6704e-01, 8.0887e-02, 1.0904e-01,
        8.1427e-04, 9.2062e-04, 5.5012e-03, 6.5482e-03, 1.6365e-02, 2.8112e-02,
        7.2706e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,445][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.1046, 0.0627, 0.0710, 0.0703, 0.0777, 0.0731, 0.0700, 0.0649, 0.0668,
        0.0810, 0.0990, 0.0925, 0.0665], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,447][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.0296, 0.0496, 0.0585, 0.0402, 0.0211, 0.0472, 0.0628, 0.3650, 0.0386,
        0.0997, 0.1208, 0.0407, 0.0263], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,448][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.7835, 0.0066, 0.0226, 0.0107, 0.0337, 0.0199, 0.0145, 0.0135, 0.0178,
        0.0153, 0.0144, 0.0138, 0.0168, 0.0169], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,450][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0205, 0.0623, 0.2099, 0.0563, 0.2363, 0.0384, 0.0512, 0.0617, 0.0181,
        0.0419, 0.0228, 0.0802, 0.0512, 0.0493], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,450][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0452, 0.2255, 0.0110, 0.0187, 0.0144, 0.0007, 0.1350, 0.0274, 0.0084,
        0.0447, 0.0409, 0.3404, 0.0873, 0.0004], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,451][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0421, 0.0575, 0.0433, 0.0409, 0.0390, 0.0771, 0.1144, 0.1089, 0.0741,
        0.0985, 0.0655, 0.0901, 0.0902, 0.0586], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,452][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0593, 0.0492, 0.0628, 0.0625, 0.0800, 0.0741, 0.0741, 0.0734, 0.0695,
        0.0838, 0.0902, 0.0762, 0.0715, 0.0736], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,453][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0334, 0.0696, 0.0606, 0.0850, 0.0639, 0.0824, 0.0852, 0.0613, 0.0952,
        0.0637, 0.0599, 0.0750, 0.0586, 0.1063], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,454][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([2.3393e-05, 2.4043e-02, 2.0224e-02, 5.5545e-01, 3.4020e-01, 3.3817e-02,
        3.6862e-04, 1.4111e-04, 6.4289e-04, 2.2513e-03, 9.5155e-04, 1.1218e-02,
        9.7925e-03, 8.7760e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,456][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([2.3632e-07, 1.6908e-02, 1.9892e-03, 7.2892e-01, 2.2563e-01, 1.9364e-02,
        1.2682e-05, 7.6370e-06, 7.5819e-05, 4.0843e-04, 1.5665e-04, 3.2401e-03,
        3.1461e-03, 1.4444e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,457][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([6.2679e-06, 4.8082e-02, 2.9098e-03, 8.2250e-01, 9.6824e-02, 1.9433e-02,
        3.9907e-05, 1.8871e-05, 3.0921e-04, 3.8837e-04, 4.8825e-04, 6.5442e-03,
        1.9191e-03, 5.3274e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,458][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([1.7616e-04, 1.0452e-01, 1.4967e-02, 6.0598e-01, 1.8777e-01, 5.4159e-02,
        6.7356e-04, 5.4381e-04, 2.3824e-03, 4.4476e-03, 3.1561e-03, 1.3594e-02,
        5.4140e-03, 2.2199e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,460][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1069, 0.0638, 0.0684, 0.0699, 0.0735, 0.0703, 0.0623, 0.0556, 0.0626,
        0.0660, 0.0781, 0.0833, 0.0588, 0.0806], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,462][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0211, 0.0438, 0.0594, 0.0195, 0.0326, 0.0284, 0.0542, 0.4102, 0.0169,
        0.0673, 0.0905, 0.0396, 0.0979, 0.0185], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,464][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.4659, 0.0175, 0.0482, 0.0259, 0.0627, 0.0385, 0.0324, 0.0289, 0.0362,
        0.0318, 0.0331, 0.0313, 0.0363, 0.0342, 0.0771], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,466][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0124, 0.0921, 0.1568, 0.0769, 0.1057, 0.0406, 0.0541, 0.0515, 0.0279,
        0.0500, 0.0567, 0.0780, 0.0629, 0.0838, 0.0506], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,467][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.0126, 0.0538, 0.0039, 0.0121, 0.0022, 0.0035, 0.2676, 0.0222, 0.1533,
        0.0099, 0.0476, 0.3855, 0.0191, 0.0054, 0.0013], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,468][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.0439, 0.0581, 0.0511, 0.0502, 0.0344, 0.0724, 0.1047, 0.0954, 0.0739,
        0.0770, 0.0788, 0.0818, 0.0686, 0.0647, 0.0448], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,469][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0604, 0.0503, 0.0612, 0.0590, 0.0719, 0.0674, 0.0669, 0.0669, 0.0645,
        0.0732, 0.0804, 0.0690, 0.0661, 0.0679, 0.0749], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,469][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.0296, 0.0651, 0.0545, 0.0791, 0.0580, 0.0764, 0.0801, 0.0567, 0.0898,
        0.0583, 0.0543, 0.0700, 0.0531, 0.1011, 0.0740], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,470][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([1.7871e-04, 5.6066e-02, 2.3606e-02, 5.8602e-01, 2.2589e-01, 2.1502e-02,
        4.0624e-04, 1.8382e-04, 1.9827e-03, 3.5016e-03, 2.9520e-03, 2.2240e-02,
        1.9104e-02, 7.5658e-03, 2.8797e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,472][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([4.5197e-06, 4.9357e-02, 3.5110e-03, 8.3323e-01, 5.7787e-02, 2.6389e-02,
        1.3182e-05, 2.2959e-05, 1.9157e-04, 1.4411e-03, 3.8309e-04, 1.4742e-02,
        1.0755e-02, 9.2659e-04, 1.2488e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,474][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([2.4452e-05, 3.8184e-02, 2.3316e-03, 8.8835e-01, 2.5060e-02, 2.1018e-02,
        3.0498e-05, 2.5925e-05, 4.7913e-04, 9.4207e-04, 7.5761e-04, 1.3998e-02,
        6.5164e-03, 1.0216e-03, 1.2587e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,475][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([7.1849e-04, 6.3414e-02, 2.5398e-02, 6.3982e-01, 1.6352e-01, 3.7034e-02,
        8.6955e-04, 2.5525e-04, 3.4734e-03, 3.3070e-03, 4.2369e-03, 2.6788e-02,
        8.3361e-03, 5.3192e-03, 1.7509e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,477][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0923, 0.0512, 0.0661, 0.0637, 0.0688, 0.0710, 0.0610, 0.0545, 0.0598,
        0.0671, 0.0770, 0.0831, 0.0546, 0.0661, 0.0638], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,479][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0116, 0.0350, 0.0333, 0.0341, 0.0038, 0.0484, 0.0390, 0.3162, 0.0400,
        0.0701, 0.2397, 0.0337, 0.0774, 0.0146, 0.0033], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,481][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.6551, 0.0147, 0.0284, 0.0143, 0.0356, 0.0228, 0.0193, 0.0172, 0.0241,
        0.0193, 0.0188, 0.0181, 0.0224, 0.0223, 0.0457, 0.0221],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,483][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0109, 0.0579, 0.1532, 0.0617, 0.1332, 0.0322, 0.0545, 0.0744, 0.0241,
        0.0582, 0.0343, 0.0866, 0.0507, 0.0831, 0.0626, 0.0225],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,484][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([6.4517e-03, 3.0678e-02, 8.0995e-03, 1.0012e-02, 1.1449e-02, 4.4836e-04,
        8.8037e-02, 1.4684e-02, 8.0049e-02, 6.9851e-03, 2.6464e-02, 6.9509e-01,
        7.7158e-04, 1.2068e-02, 8.4117e-03, 3.0080e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,485][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0412, 0.0581, 0.0429, 0.0473, 0.0294, 0.0658, 0.0958, 0.0920, 0.0721,
        0.0721, 0.0726, 0.0799, 0.0650, 0.0614, 0.0414, 0.0631],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,486][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0550, 0.0463, 0.0562, 0.0542, 0.0668, 0.0632, 0.0617, 0.0640, 0.0587,
        0.0711, 0.0763, 0.0644, 0.0621, 0.0619, 0.0687, 0.0694],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,487][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0278, 0.0605, 0.0508, 0.0735, 0.0535, 0.0716, 0.0741, 0.0515, 0.0825,
        0.0535, 0.0499, 0.0649, 0.0486, 0.0948, 0.0699, 0.0727],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,488][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([2.2606e-03, 2.8126e-02, 1.1770e-02, 5.7399e-01, 2.2367e-01, 2.3298e-02,
        3.5495e-04, 6.6722e-05, 6.8930e-04, 1.5866e-03, 1.1085e-03, 1.4422e-02,
        7.5566e-03, 2.3943e-03, 9.6347e-03, 9.9073e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,489][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([1.3416e-04, 2.5220e-02, 9.2755e-04, 7.3425e-01, 1.7626e-01, 4.1649e-03,
        9.5961e-06, 4.6552e-06, 5.7393e-05, 2.3324e-04, 8.4814e-05, 2.5125e-03,
        1.0759e-03, 2.5507e-04, 1.1347e-03, 5.3669e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,491][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([8.0867e-04, 6.0800e-02, 2.1270e-03, 8.0659e-01, 7.8816e-02, 1.0828e-02,
        1.6845e-05, 3.1364e-06, 2.0675e-04, 2.8471e-04, 2.1522e-04, 4.5752e-03,
        8.2134e-04, 7.0108e-04, 1.1278e-03, 3.2076e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,492][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([7.9892e-03, 1.2951e-01, 4.6187e-03, 6.0888e-01, 6.4098e-02, 6.7082e-02,
        5.7215e-04, 3.2148e-04, 3.1127e-03, 3.4298e-03, 5.9910e-03, 1.8479e-02,
        2.1336e-03, 5.6036e-03, 3.8343e-03, 7.4345e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,494][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0831, 0.0529, 0.0547, 0.0604, 0.0633, 0.0672, 0.0572, 0.0563, 0.0546,
        0.0676, 0.0745, 0.0729, 0.0515, 0.0672, 0.0597, 0.0569],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,496][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0355, 0.0496, 0.0530, 0.0376, 0.0245, 0.0291, 0.0418, 0.3059, 0.0427,
        0.0738, 0.1410, 0.0474, 0.0538, 0.0319, 0.0227, 0.0097],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,498][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.6486, 0.0095, 0.0270, 0.0135, 0.0361, 0.0228, 0.0183, 0.0164, 0.0227,
        0.0182, 0.0176, 0.0173, 0.0206, 0.0208, 0.0462, 0.0217, 0.0227],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,500][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0134, 0.0624, 0.1404, 0.0528, 0.1771, 0.0289, 0.0369, 0.0629, 0.0149,
        0.0477, 0.0207, 0.0546, 0.0710, 0.0681, 0.0857, 0.0351, 0.0275],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,501][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0373, 0.1797, 0.0087, 0.0678, 0.0401, 0.0032, 0.0012, 0.0084, 0.1503,
        0.0499, 0.0881, 0.0579, 0.2059, 0.0408, 0.0337, 0.0258, 0.0015],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,502][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0327, 0.0490, 0.0366, 0.0354, 0.0302, 0.0639, 0.0774, 0.0956, 0.0562,
        0.0632, 0.0560, 0.0676, 0.0708, 0.0538, 0.0430, 0.0739, 0.0946],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,503][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0494, 0.0417, 0.0516, 0.0500, 0.0626, 0.0590, 0.0578, 0.0597, 0.0551,
        0.0670, 0.0718, 0.0605, 0.0581, 0.0582, 0.0652, 0.0652, 0.0671],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,504][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0269, 0.0567, 0.0487, 0.0683, 0.0511, 0.0668, 0.0689, 0.0486, 0.0761,
        0.0504, 0.0475, 0.0599, 0.0457, 0.0861, 0.0647, 0.0669, 0.0670],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,505][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([3.4931e-03, 1.9295e-02, 9.7272e-03, 4.2809e-01, 2.0734e-01, 1.7425e-02,
        1.4821e-04, 7.7169e-05, 7.3344e-04, 1.4342e-03, 6.0686e-04, 6.9768e-03,
        3.9013e-03, 1.7671e-03, 7.2401e-03, 1.1889e-01, 1.7286e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,507][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([3.1147e-04, 1.1694e-02, 7.2771e-04, 5.3227e-01, 8.3020e-02, 7.0565e-03,
        3.5685e-06, 2.5708e-06, 6.4679e-05, 1.9354e-04, 9.1498e-05, 2.4034e-03,
        1.0517e-03, 2.4287e-04, 7.1838e-04, 1.9436e-01, 1.6579e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,508][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.7878e-03, 3.4528e-02, 1.2464e-03, 7.1019e-01, 5.4058e-02, 8.7062e-03,
        9.4942e-06, 5.5674e-06, 2.0583e-04, 1.9965e-04, 2.6457e-04, 2.2465e-03,
        5.8170e-04, 5.4653e-04, 8.6908e-04, 1.0117e-01, 8.3381e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,510][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([6.5015e-03, 5.3900e-02, 6.0605e-03, 4.3187e-01, 5.9588e-02, 4.7008e-02,
        3.5611e-04, 2.3996e-04, 1.8666e-03, 2.7458e-03, 3.3375e-03, 1.1405e-02,
        2.9102e-03, 2.9963e-03, 3.0054e-03, 2.6636e-01, 9.9852e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,512][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0830, 0.0479, 0.0537, 0.0566, 0.0590, 0.0611, 0.0551, 0.0531, 0.0505,
        0.0597, 0.0630, 0.0703, 0.0490, 0.0606, 0.0563, 0.0518, 0.0692],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,514][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0215, 0.0573, 0.0412, 0.0358, 0.0295, 0.0309, 0.0148, 0.3450, 0.0311,
        0.0888, 0.0934, 0.0302, 0.0851, 0.0386, 0.0282, 0.0183, 0.0103],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,516][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.4647, 0.0155, 0.0402, 0.0189, 0.0492, 0.0311, 0.0259, 0.0248, 0.0293,
        0.0265, 0.0263, 0.0248, 0.0305, 0.0281, 0.0594, 0.0305, 0.0311, 0.0431],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,517][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.0083, 0.0670, 0.1111, 0.0576, 0.1548, 0.0287, 0.0434, 0.0573, 0.0186,
        0.0398, 0.0293, 0.0730, 0.0548, 0.0770, 0.0782, 0.0403, 0.0308, 0.0300],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,518][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.0557, 0.2024, 0.0102, 0.0519, 0.0133, 0.0032, 0.0664, 0.0304, 0.1375,
        0.0080, 0.1337, 0.1938, 0.0124, 0.0085, 0.0065, 0.0070, 0.0570, 0.0020],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,519][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.0297, 0.0399, 0.0342, 0.0345, 0.0281, 0.0573, 0.0873, 0.0751, 0.0563,
        0.0626, 0.0533, 0.0672, 0.0558, 0.0491, 0.0379, 0.0710, 0.1032, 0.0575],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,520][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.0562, 0.0452, 0.0488, 0.0461, 0.0549, 0.0520, 0.0504, 0.0548, 0.0508,
        0.0624, 0.0695, 0.0554, 0.0564, 0.0512, 0.0545, 0.0563, 0.0582, 0.0769],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,521][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.0211, 0.0533, 0.0426, 0.0672, 0.0461, 0.0642, 0.0682, 0.0448, 0.0774,
        0.0463, 0.0421, 0.0585, 0.0419, 0.0904, 0.0633, 0.0659, 0.0668, 0.0399],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,522][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([6.1604e-04, 8.1297e-03, 2.5503e-03, 2.2670e-01, 7.6019e-02, 9.2775e-03,
        9.4960e-05, 3.3597e-05, 3.5425e-04, 6.7254e-04, 5.8945e-04, 6.4952e-03,
        3.4158e-03, 1.4404e-03, 3.8580e-03, 1.7214e-01, 2.9055e-01, 1.9706e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,524][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([4.5581e-05, 7.3191e-03, 2.6118e-04, 2.6551e-01, 5.2467e-02, 1.9958e-03,
        2.0851e-06, 1.2286e-06, 4.3342e-05, 8.9072e-05, 6.4923e-05, 2.7803e-03,
        5.8385e-04, 2.0700e-04, 6.0450e-04, 2.1250e-01, 3.2548e-01, 1.3004e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,526][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([3.9475e-04, 1.4896e-02, 6.7289e-04, 5.4275e-01, 5.2503e-02, 5.5235e-03,
        6.9649e-06, 2.4754e-06, 1.3327e-04, 1.1122e-04, 2.1679e-04, 2.7898e-03,
        2.8219e-04, 4.4000e-04, 9.3460e-04, 1.9650e-01, 1.5356e-01, 2.8291e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,527][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([1.7611e-03, 2.9932e-02, 3.4288e-03, 3.2968e-01, 4.1692e-02, 4.8909e-02,
        3.4222e-04, 1.0843e-04, 2.4014e-03, 1.5986e-03, 2.7062e-03, 1.7000e-02,
        2.1679e-03, 3.6218e-03, 3.0381e-03, 2.4352e-01, 1.7341e-01, 9.4681e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,529][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0699, 0.0444, 0.0510, 0.0516, 0.0553, 0.0574, 0.0522, 0.0453, 0.0490,
        0.0581, 0.0658, 0.0660, 0.0465, 0.0572, 0.0537, 0.0514, 0.0669, 0.0582],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,531][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0125, 0.0350, 0.0481, 0.0275, 0.0347, 0.0296, 0.0265, 0.3247, 0.0245,
        0.1351, 0.0569, 0.0334, 0.0753, 0.0247, 0.0354, 0.0364, 0.0187, 0.0210],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,533][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.6980, 0.0061, 0.0203, 0.0093, 0.0300, 0.0167, 0.0126, 0.0115, 0.0160,
        0.0129, 0.0124, 0.0119, 0.0148, 0.0149, 0.0389, 0.0165, 0.0168, 0.0247,
        0.0156], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,535][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0103, 0.0478, 0.1408, 0.0495, 0.1860, 0.0339, 0.0410, 0.0614, 0.0163,
        0.0347, 0.0242, 0.0539, 0.0502, 0.0554, 0.0872, 0.0347, 0.0297, 0.0301,
        0.0129], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,536][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.8404e-02, 6.6635e-02, 1.7193e-02, 1.8034e-02, 5.0712e-02, 8.6860e-04,
        3.8440e-02, 9.9165e-03, 1.3203e-02, 1.8856e-02, 1.3714e-02, 5.2718e-01,
        2.1164e-02, 3.6625e-03, 3.0095e-02, 2.3964e-02, 4.8326e-02, 7.9501e-02,
        1.3192e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,537][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0279, 0.0408, 0.0287, 0.0300, 0.0267, 0.0596, 0.0746, 0.0768, 0.0473,
        0.0694, 0.0436, 0.0642, 0.0617, 0.0465, 0.0362, 0.0675, 0.0849, 0.0624,
        0.0510], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,538][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0423, 0.0354, 0.0446, 0.0436, 0.0551, 0.0514, 0.0509, 0.0521, 0.0483,
        0.0583, 0.0630, 0.0532, 0.0506, 0.0511, 0.0581, 0.0573, 0.0591, 0.0717,
        0.0539], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,539][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0247, 0.0501, 0.0435, 0.0602, 0.0459, 0.0591, 0.0607, 0.0439, 0.0679,
        0.0455, 0.0433, 0.0535, 0.0420, 0.0751, 0.0572, 0.0592, 0.0589, 0.0404,
        0.0690], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,540][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.8528e-03, 7.4493e-03, 4.8566e-03, 2.4900e-01, 1.3588e-01, 1.0615e-02,
        2.0204e-04, 5.4368e-05, 3.9602e-04, 9.1823e-04, 5.7099e-04, 7.8575e-03,
        3.7048e-03, 1.3082e-03, 5.2840e-03, 6.3574e-02, 2.3466e-01, 1.9720e-01,
        7.4611e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,542][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.3914e-04, 5.1049e-03, 2.7874e-04, 2.6527e-01, 6.0412e-02, 2.5458e-03,
        5.0056e-06, 2.4492e-06, 3.5272e-05, 1.2049e-04, 5.7785e-05, 1.8570e-03,
        7.7960e-04, 1.6172e-04, 4.8294e-04, 1.2785e-01, 2.0005e-01, 2.5258e-01,
        8.2278e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,543][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.1564e-03, 2.0701e-02, 6.6716e-04, 4.7934e-01, 5.7128e-02, 8.3482e-03,
        1.8492e-05, 6.2214e-06, 2.1255e-04, 1.6001e-04, 2.2608e-04, 5.6061e-03,
        6.1043e-04, 7.2810e-04, 1.0223e-03, 8.7660e-02, 1.7374e-01, 8.0805e-02,
        8.1865e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,544][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([4.1524e-03, 6.0160e-02, 6.3148e-03, 3.5667e-01, 3.6118e-02, 3.9669e-02,
        5.2261e-04, 2.3847e-04, 1.8561e-03, 1.9646e-03, 1.8680e-03, 1.4206e-02,
        2.0735e-03, 3.8612e-03, 2.3777e-03, 2.0923e-01, 1.3672e-01, 7.7799e-02,
        4.4195e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,546][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0727, 0.0435, 0.0497, 0.0485, 0.0527, 0.0557, 0.0451, 0.0415, 0.0456,
        0.0490, 0.0672, 0.0602, 0.0457, 0.0536, 0.0501, 0.0488, 0.0562, 0.0563,
        0.0581], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,548][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0182, 0.0424, 0.0196, 0.0347, 0.0294, 0.0171, 0.0331, 0.2871, 0.0193,
        0.1184, 0.0872, 0.0298, 0.0923, 0.0339, 0.0323, 0.0186, 0.0257, 0.0507,
        0.0104], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,552][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:54,554][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 9963],
        [18768],
        [ 9666],
        [20446],
        [16292],
        [24472],
        [14761],
        [13383],
        [27876],
        [ 5754],
        [17867],
        [11257],
        [23350],
        [13221],
        [25872],
        [14327],
        [12700],
        [16698],
        [13691]], device='cuda:0')
[2024-07-24 10:17:54,555][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 9606],
        [23095],
        [ 8116],
        [23895],
        [17659],
        [29751],
        [17615],
        [13463],
        [30913],
        [ 6974],
        [20137],
        [13674],
        [26808],
        [17347],
        [28903],
        [18702],
        [16806],
        [27131],
        [20762]], device='cuda:0')
[2024-07-24 10:17:54,557][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[42902],
        [39305],
        [30716],
        [26291],
        [27712],
        [26557],
        [24060],
        [23850],
        [23748],
        [24297],
        [24315],
        [24246],
        [23865],
        [24136],
        [22968],
        [22620],
        [22851],
        [23171],
        [22694]], device='cuda:0')
[2024-07-24 10:17:54,559][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[32516],
        [34464],
        [34006],
        [34327],
        [34419],
        [33805],
        [33753],
        [34084],
        [34079],
        [34268],
        [34288],
        [34320],
        [34237],
        [34204],
        [34322],
        [34328],
        [34532],
        [34445],
        [34576]], device='cuda:0')
[2024-07-24 10:17:54,561][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[512],
        [394],
        [466],
        [383],
        [420],
        [365],
        [325],
        [282],
        [280],
        [257],
        [240],
        [241],
        [238],
        [245],
        [261],
        [262],
        [263],
        [275],
        [279]], device='cuda:0')
[2024-07-24 10:17:54,563][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[5492],
        [4557],
        [2351],
        [1980],
        [2347],
        [3102],
        [2152],
        [2341],
        [2215],
        [2571],
        [2770],
        [2718],
        [2692],
        [2723],
        [3023],
        [3414],
        [3169],
        [2724],
        [3266]], device='cuda:0')
[2024-07-24 10:17:54,565][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[31738],
        [30793],
        [31122],
        [30697],
        [30560],
        [30306],
        [29988],
        [29928],
        [29234],
        [28903],
        [28448],
        [28267],
        [28211],
        [27943],
        [27982],
        [27768],
        [27566],
        [27276],
        [27108]], device='cuda:0')
[2024-07-24 10:17:54,567][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[25705],
        [27147],
        [23675],
        [24180],
        [24436],
        [24041],
        [23912],
        [23823],
        [23951],
        [23551],
        [23866],
        [24355],
        [24660],
        [24921],
        [25099],
        [24550],
        [24408],
        [24477],
        [24662]], device='cuda:0')
[2024-07-24 10:17:54,570][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[41862],
        [43715],
        [45537],
        [44134],
        [44545],
        [43959],
        [42929],
        [43397],
        [42220],
        [42612],
        [42123],
        [42125],
        [42286],
        [42707],
        [42096],
        [42842],
        [42649],
        [42272],
        [41952]], device='cuda:0')
[2024-07-24 10:17:54,572][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[48115],
        [47776],
        [47373],
        [47172],
        [46977],
        [46812],
        [46992],
        [46950],
        [46807],
        [46550],
        [46455],
        [46640],
        [46610],
        [46635],
        [46561],
        [46643],
        [46729],
        [46624],
        [46648]], device='cuda:0')
[2024-07-24 10:17:54,573][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[24953],
        [23987],
        [24934],
        [24967],
        [24751],
        [24689],
        [24700],
        [24587],
        [24592],
        [24569],
        [24665],
        [24671],
        [24609],
        [24662],
        [24600],
        [24536],
        [24593],
        [24704],
        [24721]], device='cuda:0')
[2024-07-24 10:17:54,575][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 4870],
        [11777],
        [14405],
        [13540],
        [13755],
        [11360],
        [ 9435],
        [ 9386],
        [ 9255],
        [ 8658],
        [ 9050],
        [ 9043],
        [ 8767],
        [ 8892],
        [ 8548],
        [ 7805],
        [ 6932],
        [ 7317],
        [ 7875]], device='cuda:0')
[2024-07-24 10:17:54,577][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[20487],
        [15956],
        [29393],
        [21515],
        [28972],
        [21330],
        [24010],
        [11196],
        [12151],
        [13453],
        [15642],
        [14049],
        [13362],
        [16133],
        [18050],
        [13139],
        [15243],
        [16116],
        [11158]], device='cuda:0')
[2024-07-24 10:17:54,579][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[30800],
        [ 5342],
        [ 9526],
        [ 7520],
        [ 8262],
        [ 3029],
        [ 3650],
        [ 3846],
        [ 3620],
        [ 3700],
        [ 3535],
        [ 3313],
        [ 3339],
        [ 3532],
        [ 4016],
        [ 3951],
        [ 3587],
        [ 3823],
        [ 3314]], device='cuda:0')
[2024-07-24 10:17:54,581][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[13579],
        [ 3160],
        [ 1324],
        [ 1872],
        [ 1257],
        [ 2050],
        [ 2183],
        [ 8715],
        [ 3957],
        [ 9737],
        [ 5690],
        [ 3209],
        [18387],
        [ 2283],
        [ 5768],
        [  996],
        [ 2793],
        [ 6162],
        [ 1810]], device='cuda:0')
[2024-07-24 10:17:54,583][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[34545],
        [34529],
        [35149],
        [34516],
        [33449],
        [33610],
        [34091],
        [34061],
        [34141],
        [33541],
        [34026],
        [33616],
        [33657],
        [33608],
        [31062],
        [31994],
        [31765],
        [31200],
        [32355]], device='cuda:0')
[2024-07-24 10:17:54,585][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 8080],
        [11901],
        [11799],
        [11059],
        [ 8007],
        [ 6286],
        [ 6716],
        [ 7310],
        [ 7106],
        [ 8564],
        [ 7712],
        [ 7700],
        [ 9834],
        [ 8377],
        [10160],
        [ 8568],
        [ 7134],
        [ 7847],
        [ 6906]], device='cuda:0')
[2024-07-24 10:17:54,587][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[45119],
        [46729],
        [47160],
        [48671],
        [46870],
        [49923],
        [47592],
        [48061],
        [39108],
        [41214],
        [39163],
        [45430],
        [27514],
        [36833],
        [27824],
        [28836],
        [47946],
        [36390],
        [32565]], device='cuda:0')
[2024-07-24 10:17:54,589][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[37389],
        [26824],
        [15266],
        [11782],
        [10010],
        [10399],
        [12044],
        [15091],
        [13098],
        [12221],
        [11211],
        [11141],
        [11350],
        [11520],
        [ 9852],
        [10142],
        [11829],
        [13001],
        [12272]], device='cuda:0')
[2024-07-24 10:17:54,591][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[25914],
        [23495],
        [21560],
        [18761],
        [17504],
        [16792],
        [16158],
        [16530],
        [16002],
        [16280],
        [16457],
        [16087],
        [16256],
        [15829],
        [15743],
        [15752],
        [15735],
        [16307],
        [16067]], device='cuda:0')
[2024-07-24 10:17:54,592][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[13864],
        [19523],
        [19946],
        [20161],
        [20106],
        [19975],
        [19488],
        [18981],
        [18660],
        [18560],
        [18693],
        [18781],
        [18766],
        [18332],
        [18114],
        [18174],
        [18105],
        [17867],
        [17843]], device='cuda:0')
[2024-07-24 10:17:54,594][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[16692],
        [ 9748],
        [ 7793],
        [ 9930],
        [ 8625],
        [ 9839],
        [ 9479],
        [ 9371],
        [ 9453],
        [ 9479],
        [ 9387],
        [ 9283],
        [ 9386],
        [ 9256],
        [ 8352],
        [ 8999],
        [ 8177],
        [ 6142],
        [ 5217]], device='cuda:0')
[2024-07-24 10:17:54,596][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[23087],
        [25668],
        [25682],
        [17364],
        [16860],
        [14443],
        [14287],
        [14557],
        [14006],
        [14185],
        [13798],
        [13874],
        [14615],
        [13997],
        [15314],
        [14479],
        [18225],
        [22275],
        [18972]], device='cuda:0')
[2024-07-24 10:17:54,598][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[36489],
        [30612],
        [26960],
        [28790],
        [28624],
        [21736],
        [23419],
        [22017],
        [21953],
        [20928],
        [24684],
        [23498],
        [21658],
        [24652],
        [28875],
        [25361],
        [26161],
        [25722],
        [24530]], device='cuda:0')
[2024-07-24 10:17:54,600][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[14487],
        [10656],
        [ 8259],
        [ 7436],
        [ 6058],
        [ 7734],
        [ 8038],
        [ 7017],
        [ 7191],
        [ 9630],
        [ 7349],
        [ 7728],
        [ 8792],
        [ 7074],
        [ 6986],
        [10071],
        [15832],
        [16480],
        [16192]], device='cuda:0')
[2024-07-24 10:17:54,603][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[43929],
        [40398],
        [46381],
        [44164],
        [46658],
        [46661],
        [47108],
        [46490],
        [45990],
        [45255],
        [44333],
        [44554],
        [43433],
        [43454],
        [44191],
        [43695],
        [44051],
        [43147],
        [42616]], device='cuda:0')
[2024-07-24 10:17:54,605][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[34321],
        [19020],
        [19215],
        [20423],
        [21468],
        [21843],
        [21043],
        [38024],
        [32116],
        [35580],
        [33971],
        [33058],
        [35502],
        [33807],
        [35711],
        [32903],
        [30474],
        [30349],
        [31608]], device='cuda:0')
[2024-07-24 10:17:54,607][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 7237],
        [13315],
        [15968],
        [17167],
        [19253],
        [17340],
        [19384],
        [17344],
        [22000],
        [20525],
        [21970],
        [20189],
        [22477],
        [22357],
        [22185],
        [21486],
        [16191],
        [17702],
        [18956]], device='cuda:0')
[2024-07-24 10:17:54,608][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 3241],
        [ 4336],
        [ 7631],
        [11446],
        [ 5960],
        [10772],
        [ 8943],
        [ 3920],
        [ 9603],
        [ 2111],
        [ 4979],
        [ 7884],
        [ 2462],
        [16151],
        [ 4784],
        [16678],
        [11776],
        [ 1874],
        [15257]], device='cuda:0')
[2024-07-24 10:17:54,610][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[21278],
        [21278],
        [21278],
        [21278],
        [21278],
        [21278],
        [21278],
        [21278],
        [21278],
        [21278],
        [21278],
        [21278],
        [21278],
        [21278],
        [21278],
        [21278],
        [21278],
        [21278],
        [21278]], device='cuda:0')
[2024-07-24 10:17:54,667][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:54,667][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,669][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,670][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,671][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,671][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,672][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,672][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,673][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,674][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,674][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,675][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,676][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:54,676][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2322, 0.7678], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,677][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2424, 0.7576], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,678][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2343, 0.7657], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,678][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1082, 0.8918], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,679][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.8630, 0.1370], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,680][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0152, 0.9848], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,681][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2263, 0.7737], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,681][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0763, 0.9237], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,683][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9596, 0.0404], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,684][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7104, 0.2896], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,686][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9136, 0.0864], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,687][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9504, 0.0496], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:54,689][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Jamie] are: tensor([0.0662, 0.6920, 0.2418], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,691][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Jamie] are: tensor([0.0238, 0.7510, 0.2251], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,693][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Jamie] are: tensor([0.1099, 0.4039, 0.4863], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,694][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Jamie] are: tensor([0.0851, 0.7305, 0.1844], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,694][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Jamie] are: tensor([0.8472, 0.0862, 0.0666], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,695][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Jamie] are: tensor([0.0165, 0.8337, 0.1498], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,696][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Jamie] are: tensor([0.1127, 0.4588, 0.4285], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,697][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Jamie] are: tensor([0.0496, 0.4047, 0.5456], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,697][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Jamie] are: tensor([0.9203, 0.0500, 0.0297], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,699][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Jamie] are: tensor([0.4643, 0.3130, 0.2226], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,700][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Jamie] are: tensor([0.2945, 0.3307, 0.3748], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,701][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Jamie] are: tensor([2.0064e-03, 9.9799e-01, 2.1695e-06], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:54,703][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1435, 0.2833, 0.0256, 0.5475], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,705][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1075, 0.2900, 0.1000, 0.5025], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,706][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0713, 0.2377, 0.3356, 0.3554], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,708][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1006, 0.3065, 0.1056, 0.4873], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,710][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.6355, 0.1161, 0.0987, 0.1497], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,711][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0012, 0.6969, 0.2631, 0.0388], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,712][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0936, 0.2934, 0.2729, 0.3401], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,713][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0324, 0.2080, 0.1085, 0.6511], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,713][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.9340, 0.0249, 0.0070, 0.0342], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,714][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.7020, 0.1074, 0.0584, 0.1322], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,715][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.5294, 0.1148, 0.2369, 0.1189], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,717][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.7921, 0.0514, 0.0205, 0.1361], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:54,718][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0252, 0.1128, 0.0230, 0.7291, 0.1098], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,720][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0153, 0.1642, 0.0385, 0.6677, 0.1143], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,722][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0491, 0.1760, 0.2283, 0.2714, 0.2752], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,724][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.0418, 0.1778, 0.0389, 0.5877, 0.1538], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,726][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.5899, 0.0905, 0.0714, 0.1381, 0.1100], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,727][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0534, 0.3335, 0.1576, 0.0251, 0.4305], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,728][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0640, 0.2210, 0.2078, 0.2734, 0.2337], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,729][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0067, 0.1143, 0.0989, 0.3987, 0.3815], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,730][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.6887, 0.0499, 0.0668, 0.0994, 0.0952], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,731][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.3976, 0.1091, 0.0841, 0.2462, 0.1629], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,731][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.1351, 0.0424, 0.0295, 0.0740, 0.7189], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,732][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([3.6138e-05, 5.3245e-02, 3.1172e-05, 9.4657e-01, 1.1958e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:54,734][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0620, 0.1400, 0.0122, 0.3969, 0.1301, 0.2588], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,736][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0410, 0.1196, 0.0604, 0.4712, 0.1770, 0.1308], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,737][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0411, 0.1395, 0.1930, 0.2072, 0.2198, 0.1994], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,739][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0183, 0.1125, 0.0506, 0.2895, 0.1830, 0.3462], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,741][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.5085, 0.0896, 0.0760, 0.1085, 0.0922, 0.1252], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,742][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ had] are: tensor([5.9681e-04, 6.3428e-01, 7.7036e-02, 1.7825e-02, 2.4623e-01, 2.4031e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,744][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0522, 0.1789, 0.1641, 0.2107, 0.1863, 0.2077], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,746][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0090, 0.0759, 0.0409, 0.2191, 0.2159, 0.4392], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,746][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.7865, 0.0429, 0.0139, 0.0644, 0.0314, 0.0609], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,747][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3161, 0.1333, 0.0571, 0.1377, 0.1303, 0.2256], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,748][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.1978, 0.2667, 0.1203, 0.0282, 0.0128, 0.3741], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,748][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0077, 0.0017, 0.0020, 0.3102, 0.5817, 0.0967], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:54,749][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([3.6165e-05, 4.3744e-02, 4.9319e-03, 6.4863e-01, 1.1282e-01, 1.8916e-01,
        6.7926e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,750][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.0917e-04, 4.7628e-02, 1.8615e-02, 6.9109e-01, 1.5352e-01, 8.6569e-02,
        2.4618e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,752][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0303, 0.1122, 0.1676, 0.1780, 0.2006, 0.1736, 0.1378],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,753][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.9518e-04, 6.6700e-02, 2.2747e-02, 5.2845e-01, 2.0547e-01, 1.7289e-01,
        3.5406e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,755][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.4609, 0.0874, 0.0736, 0.0925, 0.0881, 0.1026, 0.0948],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,756][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([2.6177e-06, 2.9856e-02, 6.4004e-02, 7.4488e-02, 8.1873e-01, 1.1525e-02,
        1.3922e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,758][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0366, 0.1472, 0.1372, 0.1817, 0.1602, 0.1807, 0.1564],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,760][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0010, 0.0955, 0.0321, 0.3469, 0.2254, 0.2734, 0.0256],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,762][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.5595, 0.0608, 0.0196, 0.0965, 0.0564, 0.1096, 0.0975],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,763][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0101, 0.0917, 0.0480, 0.3409, 0.2160, 0.2749, 0.0183],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,763][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1344, 0.2362, 0.1883, 0.0485, 0.1427, 0.2016, 0.0481],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,764][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([6.9536e-10, 8.9690e-05, 1.9792e-06, 9.7759e-01, 1.0235e-02, 1.2080e-02,
        4.6390e-12], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:54,765][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([1.8237e-05, 2.3474e-02, 4.6205e-03, 5.5775e-01, 1.9798e-01, 2.1492e-01,
        1.0381e-03, 1.9400e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,766][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([6.9846e-05, 5.0549e-02, 1.7212e-02, 7.0791e-01, 1.4421e-01, 7.4417e-02,
        4.0253e-03, 1.6048e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,766][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0268, 0.0977, 0.1420, 0.1526, 0.1745, 0.1553, 0.1287, 0.1225],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,767][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([8.7436e-05, 7.8761e-02, 1.5766e-02, 5.4900e-01, 2.0404e-01, 1.4785e-01,
        3.5568e-03, 9.3273e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,769][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.4626, 0.0716, 0.0539, 0.0847, 0.0728, 0.0965, 0.0890, 0.0689],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,770][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([4.3361e-05, 7.0632e-02, 4.5858e-02, 1.2888e-01, 7.0302e-01, 2.3590e-02,
        8.7062e-03, 1.9274e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,772][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0288, 0.1223, 0.1174, 0.1531, 0.1377, 0.1546, 0.1403, 0.1457],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,774][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0006, 0.0922, 0.0348, 0.3639, 0.2267, 0.2421, 0.0256, 0.0140],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,776][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.6448, 0.0401, 0.0196, 0.0661, 0.0600, 0.0781, 0.0658, 0.0255],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,777][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0044, 0.0770, 0.0356, 0.3174, 0.2737, 0.2531, 0.0268, 0.0121],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,779][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.3328, 0.0287, 0.0348, 0.0217, 0.1431, 0.0553, 0.0956, 0.2879],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,780][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([9.8358e-11, 9.9505e-05, 4.1940e-07, 9.8120e-01, 1.2218e-02, 6.4862e-03,
        3.7011e-09, 6.7878e-12], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:54,781][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ of] are: tensor([9.9697e-05, 3.4901e-02, 5.5082e-03, 6.5375e-01, 1.7418e-01, 1.2948e-01,
        5.9839e-04, 1.2301e-04, 1.3578e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,782][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ of] are: tensor([2.4850e-04, 3.8118e-02, 1.6851e-02, 6.7359e-01, 1.6148e-01, 1.0085e-01,
        3.4934e-03, 2.0246e-03, 3.3526e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,782][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0258, 0.0878, 0.1363, 0.1344, 0.1601, 0.1337, 0.1053, 0.1084, 0.1081],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,783][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ of] are: tensor([4.8838e-04, 5.5855e-02, 2.2670e-02, 5.1885e-01, 1.9727e-01, 1.9247e-01,
        4.4942e-03, 1.9274e-03, 5.9721e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,784][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.4203, 0.0698, 0.0576, 0.0834, 0.0684, 0.0898, 0.0874, 0.0581, 0.0652],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,786][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ of] are: tensor([7.0510e-06, 4.1203e-02, 8.2629e-02, 9.1060e-02, 7.6536e-01, 1.1481e-02,
        1.6052e-03, 4.9282e-03, 1.7303e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,788][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0300, 0.1117, 0.1043, 0.1358, 0.1199, 0.1332, 0.1144, 0.1245, 0.1262],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,789][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0018, 0.0834, 0.0319, 0.2864, 0.2440, 0.2776, 0.0233, 0.0137, 0.0379],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,791][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.5550, 0.0475, 0.0206, 0.0821, 0.0612, 0.0889, 0.0752, 0.0281, 0.0413],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,793][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0201, 0.0644, 0.0451, 0.2830, 0.3084, 0.2286, 0.0198, 0.0111, 0.0195],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,795][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.4473, 0.0680, 0.0904, 0.0391, 0.0333, 0.0725, 0.0203, 0.0684, 0.1607],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,796][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ of] are: tensor([3.7418e-07, 1.1847e-04, 5.6792e-06, 7.3731e-01, 2.4105e-01, 2.1518e-02,
        1.1774e-10, 1.1835e-10, 5.8521e-10], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:54,797][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([7.9707e-05, 2.4791e-02, 2.9967e-03, 6.6886e-01, 8.8999e-02, 2.0722e-01,
        7.5592e-04, 1.2681e-04, 2.6441e-03, 3.5284e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,798][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([2.5797e-04, 4.2332e-02, 1.2229e-02, 7.0541e-01, 1.2824e-01, 7.6359e-02,
        3.9409e-03, 1.9872e-03, 8.6230e-03, 2.0624e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,798][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0197, 0.0759, 0.1039, 0.1160, 0.1250, 0.1211, 0.0986, 0.0922, 0.1057,
        0.1420], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,799][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([4.0874e-04, 9.2375e-02, 1.8179e-02, 5.3721e-01, 1.6268e-01, 1.6984e-01,
        3.1654e-03, 1.0597e-03, 5.9693e-03, 9.1100e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,800][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.4153, 0.0549, 0.0414, 0.0742, 0.0570, 0.0860, 0.0786, 0.0566, 0.0564,
        0.0795], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,801][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([1.1389e-04, 4.9224e-02, 3.0534e-02, 5.6383e-02, 6.7689e-01, 9.6316e-03,
        3.2162e-03, 8.4259e-03, 5.7964e-03, 1.5979e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,802][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0216, 0.0916, 0.0863, 0.1170, 0.1021, 0.1183, 0.1112, 0.1121, 0.1246,
        0.1152], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,804][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0009, 0.0773, 0.0240, 0.3468, 0.1954, 0.2454, 0.0175, 0.0085, 0.0265,
        0.0577], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,805][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.4220, 0.0703, 0.0156, 0.0890, 0.0449, 0.1209, 0.0830, 0.0305, 0.0328,
        0.0909], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,807][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0126, 0.0794, 0.0285, 0.3215, 0.1821, 0.2915, 0.0175, 0.0090, 0.0248,
        0.0331], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,809][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.1666, 0.0576, 0.0320, 0.0790, 0.0475, 0.0449, 0.0563, 0.1019, 0.3079,
        0.1062], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,810][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([3.8346e-08, 6.0432e-05, 1.4539e-07, 9.7635e-01, 4.6579e-03, 1.8931e-02,
        3.9109e-10, 1.9465e-11, 7.8890e-08, 6.5352e-08], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:54,811][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ at] are: tensor([2.1403e-04, 4.2963e-02, 3.8326e-03, 6.7263e-01, 1.0288e-01, 1.5940e-01,
        1.2050e-03, 2.7400e-04, 4.1909e-03, 9.5011e-03, 2.9098e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,812][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ at] are: tensor([4.5600e-04, 5.1873e-02, 2.1259e-02, 6.6506e-01, 1.2272e-01, 9.1360e-02,
        4.2704e-03, 1.9698e-03, 7.9519e-03, 2.5063e-02, 8.0157e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,814][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0186, 0.0671, 0.1031, 0.1059, 0.1201, 0.1071, 0.0826, 0.0843, 0.0863,
        0.1420, 0.0830], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,815][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0005, 0.0694, 0.0218, 0.4857, 0.2128, 0.1656, 0.0053, 0.0016, 0.0086,
        0.0178, 0.0109], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,816][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.4172, 0.0505, 0.0351, 0.0719, 0.0475, 0.0816, 0.0748, 0.0530, 0.0553,
        0.0689, 0.0442], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,817][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ at] are: tensor([3.6929e-05, 5.2308e-02, 4.2290e-02, 5.7934e-02, 6.4687e-01, 9.3388e-03,
        2.3997e-03, 5.3945e-03, 4.0583e-03, 1.6443e-01, 1.4945e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,817][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0226, 0.0876, 0.0817, 0.1075, 0.0936, 0.1059, 0.0913, 0.0990, 0.1020,
        0.1031, 0.1057], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,818][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0013, 0.0715, 0.0246, 0.2855, 0.1998, 0.2463, 0.0229, 0.0097, 0.0314,
        0.0562, 0.0509], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,820][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.5608, 0.0417, 0.0105, 0.0560, 0.0367, 0.0750, 0.0647, 0.0215, 0.0342,
        0.0696, 0.0294], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,822][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0162, 0.0691, 0.0329, 0.3275, 0.1829, 0.2379, 0.0205, 0.0088, 0.0250,
        0.0483, 0.0308], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,824][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1125, 0.1242, 0.1982, 0.0200, 0.1621, 0.0125, 0.0194, 0.0575, 0.1379,
        0.0489, 0.1068], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,825][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ at] are: tensor([2.5326e-06, 8.7605e-05, 6.6964e-07, 9.4505e-01, 4.0324e-02, 1.4536e-02,
        8.2189e-11, 3.1126e-11, 4.7388e-09, 3.1818e-07, 1.0523e-07],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:54,827][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ the] are: tensor([1.0055e-03, 4.6256e-02, 4.0073e-03, 6.3592e-01, 1.1445e-01, 1.5353e-01,
        6.5492e-04, 1.8571e-04, 3.3164e-03, 4.2739e-03, 5.4569e-03, 3.0948e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,829][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0015, 0.0559, 0.0198, 0.5894, 0.1577, 0.0855, 0.0031, 0.0013, 0.0058,
        0.0160, 0.0080, 0.0560], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,830][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0176, 0.0610, 0.0951, 0.0981, 0.1125, 0.0989, 0.0763, 0.0769, 0.0804,
        0.1310, 0.0775, 0.0746], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,832][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0025, 0.0776, 0.0206, 0.4849, 0.1890, 0.1484, 0.0038, 0.0014, 0.0069,
        0.0136, 0.0114, 0.0398], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,833][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.3471, 0.0647, 0.0539, 0.0663, 0.0583, 0.0738, 0.0623, 0.0512, 0.0506,
        0.0648, 0.0520, 0.0551], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,834][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ the] are: tensor([8.8111e-05, 3.3158e-02, 5.0767e-02, 4.9886e-02, 7.0164e-01, 6.3635e-03,
        9.7545e-04, 2.8639e-03, 1.9604e-03, 8.9071e-02, 9.8550e-03, 5.3368e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,834][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0210, 0.0797, 0.0742, 0.0969, 0.0849, 0.0953, 0.0825, 0.0892, 0.0920,
        0.0935, 0.0960, 0.0948], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,835][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0032, 0.0723, 0.0280, 0.2016, 0.2172, 0.2214, 0.0198, 0.0086, 0.0229,
        0.0459, 0.0445, 0.1145], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,837][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.6464, 0.0294, 0.0091, 0.0434, 0.0271, 0.0557, 0.0478, 0.0132, 0.0247,
        0.0441, 0.0200, 0.0390], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,838][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0442, 0.0644, 0.0346, 0.2642, 0.1596, 0.2000, 0.0162, 0.0073, 0.0217,
        0.0286, 0.0326, 0.1266], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,840][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.2215, 0.0649, 0.0709, 0.0223, 0.0231, 0.2009, 0.0238, 0.0881, 0.1145,
        0.0335, 0.0800, 0.0564], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,841][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ the] are: tensor([7.7970e-04, 7.3083e-05, 3.8076e-07, 9.7710e-01, 1.0400e-02, 1.1349e-02,
        3.2297e-11, 1.4014e-11, 8.1539e-09, 5.8705e-08, 5.6347e-07, 2.9412e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:54,843][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ store] are: tensor([7.4899e-04, 1.6680e-02, 4.3579e-03, 6.8730e-01, 1.3070e-01, 8.2119e-02,
        6.6576e-04, 1.5816e-04, 4.9148e-03, 4.6975e-03, 8.6865e-03, 4.3287e-02,
        1.5677e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,845][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0009, 0.0248, 0.0249, 0.5496, 0.1815, 0.0719, 0.0026, 0.0012, 0.0065,
        0.0167, 0.0106, 0.0835, 0.0253], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,846][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0156, 0.0567, 0.0780, 0.0865, 0.0953, 0.0887, 0.0727, 0.0691, 0.0782,
        0.1098, 0.0710, 0.0694, 0.1089], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,848][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0032, 0.0426, 0.0187, 0.3975, 0.2015, 0.1968, 0.0039, 0.0011, 0.0078,
        0.0197, 0.0167, 0.0692, 0.0212], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,849][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.3290, 0.0420, 0.0301, 0.0751, 0.0453, 0.0809, 0.0831, 0.0474, 0.0564,
        0.0626, 0.0372, 0.0602, 0.0508], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,850][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0008, 0.0358, 0.0235, 0.0530, 0.4759, 0.0068, 0.0017, 0.0050, 0.0050,
        0.0849, 0.0206, 0.1162, 0.1708], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,851][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0179, 0.0686, 0.0663, 0.0861, 0.0760, 0.0862, 0.0793, 0.0810, 0.0876,
        0.0852, 0.0925, 0.0907, 0.0826], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,852][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0018, 0.0709, 0.0327, 0.1974, 0.2177, 0.1470, 0.0146, 0.0078, 0.0246,
        0.0475, 0.0380, 0.1037, 0.0963], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,853][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.5956, 0.0287, 0.0119, 0.0552, 0.0301, 0.0713, 0.0549, 0.0111, 0.0253,
        0.0434, 0.0245, 0.0371, 0.0110], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,855][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0420, 0.0354, 0.0406, 0.2830, 0.1895, 0.1701, 0.0151, 0.0075, 0.0192,
        0.0254, 0.0381, 0.1095, 0.0243], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,857][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0667, 0.0336, 0.0825, 0.0108, 0.0377, 0.0088, 0.0434, 0.0825, 0.0359,
        0.2350, 0.0154, 0.0410, 0.3067], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,858][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ store] are: tensor([3.5329e-06, 1.9728e-04, 2.4829e-07, 9.4289e-01, 5.8837e-03, 2.8309e-03,
        5.1115e-10, 1.8265e-11, 3.3436e-08, 2.0688e-07, 1.9683e-06, 4.8166e-02,
        2.7732e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:54,859][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [.] are: tensor([3.1263e-04, 4.1681e-02, 3.1263e-03, 6.9438e-01, 7.4936e-02, 1.2962e-01,
        6.7994e-04, 1.6556e-04, 2.6058e-03, 4.0933e-03, 3.4360e-03, 2.9193e-02,
        9.7218e-03, 6.0513e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,860][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [.] are: tensor([3.9392e-04, 8.2573e-02, 2.0188e-02, 5.4190e-01, 1.4596e-01, 5.5381e-02,
        3.5263e-03, 1.5545e-03, 4.8226e-03, 1.7651e-02, 1.0345e-02, 6.6636e-02,
        2.8571e-02, 2.0489e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,863][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0150, 0.0538, 0.0773, 0.0792, 0.0899, 0.0778, 0.0618, 0.0664, 0.0662,
        0.1138, 0.0640, 0.0613, 0.1002, 0.0733], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,864][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0007, 0.0600, 0.0227, 0.4594, 0.1875, 0.1663, 0.0039, 0.0012, 0.0064,
        0.0114, 0.0089, 0.0434, 0.0166, 0.0116], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,866][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.3504, 0.0572, 0.0448, 0.0624, 0.0504, 0.0684, 0.0558, 0.0434, 0.0437,
        0.0541, 0.0390, 0.0470, 0.0415, 0.0419], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,867][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [.] are: tensor([6.2709e-06, 1.8902e-02, 5.5684e-02, 6.0549e-02, 5.7578e-01, 1.0235e-02,
        8.9166e-04, 2.2044e-03, 1.7995e-03, 7.0115e-02, 1.0093e-02, 6.0335e-02,
        1.2236e-01, 1.1036e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,868][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0175, 0.0674, 0.0629, 0.0819, 0.0720, 0.0806, 0.0698, 0.0744, 0.0773,
        0.0782, 0.0811, 0.0804, 0.0767, 0.0798], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,869][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0007, 0.0659, 0.0214, 0.2661, 0.1493, 0.1935, 0.0149, 0.0051, 0.0231,
        0.0337, 0.0318, 0.0867, 0.0488, 0.0591], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,869][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.3228, 0.0630, 0.0175, 0.0737, 0.0537, 0.0937, 0.0620, 0.0219, 0.0309,
        0.0836, 0.0302, 0.0628, 0.0198, 0.0644], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,870][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0126, 0.0668, 0.0305, 0.2661, 0.1776, 0.1983, 0.0143, 0.0070, 0.0148,
        0.0341, 0.0263, 0.1114, 0.0178, 0.0222], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,872][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.3134, 0.0421, 0.0943, 0.0168, 0.0421, 0.0319, 0.0168, 0.0271, 0.1429,
        0.0457, 0.0715, 0.0346, 0.0281, 0.0927], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,874][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [.] are: tensor([1.1170e-07, 3.4000e-05, 2.4115e-07, 9.7281e-01, 1.5143e-02, 1.0307e-02,
        1.4535e-10, 8.5383e-12, 4.8229e-09, 9.2252e-08, 2.8231e-07, 1.6696e-03,
        3.5144e-05, 1.5107e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:54,876][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0018, 0.0239, 0.0052, 0.4603, 0.0799, 0.1400, 0.0028, 0.0005, 0.0109,
        0.0133, 0.0155, 0.1338, 0.0574, 0.0331, 0.0216], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,877][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0011, 0.0543, 0.0141, 0.4229, 0.0948, 0.0690, 0.0054, 0.0029, 0.0099,
        0.0268, 0.0147, 0.1064, 0.0870, 0.0531, 0.0376], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,880][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0128, 0.0479, 0.0645, 0.0724, 0.0777, 0.0728, 0.0637, 0.0619, 0.0700,
        0.0963, 0.0622, 0.0624, 0.0947, 0.0712, 0.0696], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,881][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.0052, 0.0513, 0.0186, 0.3661, 0.1339, 0.1147, 0.0061, 0.0029, 0.0151,
        0.0217, 0.0289, 0.0899, 0.0485, 0.0506, 0.0465], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,883][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.2873, 0.0572, 0.0415, 0.0654, 0.0562, 0.0676, 0.0601, 0.0411, 0.0410,
        0.0503, 0.0326, 0.0446, 0.0436, 0.0400, 0.0714], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,884][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0015, 0.0321, 0.0526, 0.0300, 0.3842, 0.0073, 0.0026, 0.0082, 0.0038,
        0.0685, 0.0196, 0.0729, 0.2038, 0.0383, 0.0746], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,885][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0146, 0.0575, 0.0539, 0.0736, 0.0624, 0.0742, 0.0677, 0.0729, 0.0766,
        0.0764, 0.0791, 0.0782, 0.0733, 0.0796, 0.0599], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,886][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0015, 0.0480, 0.0423, 0.1386, 0.2211, 0.1062, 0.0148, 0.0061, 0.0180,
        0.0321, 0.0301, 0.0893, 0.0662, 0.0710, 0.1146], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,886][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.2025, 0.0417, 0.0358, 0.0809, 0.0459, 0.1403, 0.0657, 0.0211, 0.0352,
        0.0770, 0.0437, 0.0703, 0.0322, 0.0711, 0.0367], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,888][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0425, 0.0442, 0.0393, 0.1874, 0.1049, 0.1733, 0.0172, 0.0152, 0.0220,
        0.0445, 0.0413, 0.1327, 0.0418, 0.0497, 0.0443], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,890][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0557, 0.0149, 0.0093, 0.0277, 0.2013, 0.1131, 0.0387, 0.0577, 0.0242,
        0.0905, 0.0404, 0.0259, 0.0788, 0.0272, 0.1946], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,891][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([2.4365e-05, 8.2615e-04, 1.0485e-06, 7.7054e-01, 1.0278e-03, 1.3239e-02,
        3.2536e-09, 4.5393e-10, 3.6061e-07, 1.7864e-06, 3.2475e-05, 2.1019e-01,
        1.3183e-03, 2.7142e-03, 8.3025e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:54,892][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([1.7223e-02, 3.3467e-02, 1.5001e-03, 4.8302e-01, 4.3736e-02, 7.5479e-02,
        4.8611e-04, 1.0477e-04, 2.1824e-03, 1.4927e-03, 2.9627e-03, 2.7364e-02,
        5.6092e-03, 5.6192e-03, 3.5117e-03, 2.9625e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,894][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0119, 0.0383, 0.0138, 0.4121, 0.0976, 0.0403, 0.0020, 0.0007, 0.0031,
        0.0078, 0.0047, 0.0452, 0.0146, 0.0191, 0.0162, 0.2726],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,896][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0133, 0.0474, 0.0651, 0.0688, 0.0748, 0.0682, 0.0562, 0.0580, 0.0608,
        0.0906, 0.0554, 0.0552, 0.0847, 0.0658, 0.0681, 0.0677],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,898][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0081, 0.0592, 0.0141, 0.3827, 0.1365, 0.0836, 0.0020, 0.0009, 0.0036,
        0.0065, 0.0073, 0.0243, 0.0081, 0.0117, 0.0155, 0.2358],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,900][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.2655, 0.0505, 0.0415, 0.0564, 0.0466, 0.0617, 0.0533, 0.0386, 0.0427,
        0.0520, 0.0369, 0.0461, 0.0427, 0.0408, 0.0556, 0.0691],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,901][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0010, 0.0380, 0.0198, 0.0219, 0.3833, 0.0031, 0.0007, 0.0021, 0.0015,
        0.0384, 0.0058, 0.0338, 0.0432, 0.0113, 0.0423, 0.3538],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,902][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0162, 0.0584, 0.0542, 0.0708, 0.0615, 0.0690, 0.0606, 0.0638, 0.0677,
        0.0666, 0.0706, 0.0701, 0.0655, 0.0703, 0.0567, 0.0780],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,903][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0025, 0.0485, 0.0158, 0.1851, 0.1196, 0.1685, 0.0125, 0.0038, 0.0146,
        0.0193, 0.0218, 0.0590, 0.0305, 0.0436, 0.0437, 0.2112],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,903][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.5169, 0.0298, 0.0068, 0.0429, 0.0258, 0.0539, 0.0476, 0.0150, 0.0214,
        0.0637, 0.0245, 0.0455, 0.0116, 0.0429, 0.0182, 0.0337],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,904][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1393, 0.0548, 0.0205, 0.1592, 0.0837, 0.1072, 0.0099, 0.0048, 0.0142,
        0.0135, 0.0192, 0.0778, 0.0113, 0.0213, 0.0218, 0.2414],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,906][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.1859, 0.0353, 0.0279, 0.0146, 0.0145, 0.1976, 0.0169, 0.1206, 0.0420,
        0.0125, 0.0339, 0.0424, 0.0207, 0.0761, 0.0192, 0.1399],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,908][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([2.2291e-01, 7.2859e-06, 9.9586e-08, 4.7309e-01, 1.8487e-03, 8.7359e-04,
        7.8405e-12, 9.3689e-13, 5.1315e-10, 1.4405e-09, 2.8797e-08, 1.8380e-04,
        8.7701e-07, 1.5514e-06, 3.6988e-06, 3.0108e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:54,909][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([3.8896e-03, 1.5090e-02, 7.5852e-04, 1.9925e-01, 2.7054e-02, 4.8560e-02,
        1.5240e-04, 3.9219e-05, 8.2438e-04, 9.3291e-04, 1.3068e-03, 9.3493e-03,
        2.1039e-03, 3.3373e-03, 1.8437e-03, 3.8778e-01, 2.9773e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,911][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0057, 0.0215, 0.0056, 0.2479, 0.0537, 0.0262, 0.0008, 0.0004, 0.0020,
        0.0045, 0.0029, 0.0218, 0.0078, 0.0110, 0.0085, 0.2029, 0.3767],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,913][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0125, 0.0430, 0.0641, 0.0659, 0.0762, 0.0659, 0.0522, 0.0531, 0.0552,
        0.0877, 0.0519, 0.0500, 0.0809, 0.0614, 0.0668, 0.0649, 0.0482],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,915][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0059, 0.0291, 0.0088, 0.2641, 0.0876, 0.0549, 0.0011, 0.0004, 0.0027,
        0.0038, 0.0049, 0.0169, 0.0053, 0.0072, 0.0088, 0.2213, 0.2772],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,917][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2616, 0.0523, 0.0437, 0.0486, 0.0477, 0.0550, 0.0468, 0.0387, 0.0367,
        0.0525, 0.0410, 0.0392, 0.0421, 0.0327, 0.0501, 0.0546, 0.0569],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,918][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([7.7005e-04, 9.6229e-03, 1.2635e-02, 1.1446e-02, 3.0065e-01, 1.3411e-03,
        1.3706e-04, 4.7598e-04, 3.8668e-04, 9.3709e-03, 1.3051e-03, 9.3657e-03,
        1.5366e-02, 1.8375e-03, 1.5017e-02, 1.5281e-01, 4.5747e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,919][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0147, 0.0554, 0.0501, 0.0668, 0.0576, 0.0652, 0.0555, 0.0603, 0.0628,
        0.0621, 0.0648, 0.0647, 0.0612, 0.0652, 0.0521, 0.0725, 0.0691],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,919][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0021, 0.0453, 0.0102, 0.1146, 0.0857, 0.0942, 0.0081, 0.0036, 0.0111,
        0.0205, 0.0189, 0.0470, 0.0234, 0.0364, 0.0314, 0.1714, 0.2761],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,920][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.4538, 0.0267, 0.0093, 0.0428, 0.0270, 0.0534, 0.0440, 0.0144, 0.0219,
        0.0537, 0.0206, 0.0425, 0.0103, 0.0504, 0.0186, 0.0364, 0.0742],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,921][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0650, 0.0269, 0.0103, 0.1208, 0.0572, 0.0839, 0.0049, 0.0025, 0.0080,
        0.0077, 0.0105, 0.0476, 0.0050, 0.0117, 0.0124, 0.2030, 0.3226],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,923][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0666, 0.0864, 0.0724, 0.0174, 0.0506, 0.0823, 0.0177, 0.0582, 0.0951,
        0.0291, 0.0925, 0.0436, 0.0626, 0.0863, 0.0577, 0.0507, 0.0308],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,925][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([5.4938e-02, 2.0761e-07, 4.0837e-09, 5.4400e-03, 7.2899e-05, 4.1384e-05,
        4.9286e-14, 2.2261e-14, 1.5640e-11, 6.8956e-11, 1.2056e-09, 1.2123e-06,
        2.0338e-08, 3.1582e-08, 5.9134e-08, 2.6119e-01, 6.7831e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:54,926][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([2.3133e-03, 3.3869e-03, 1.8504e-04, 8.8991e-02, 6.8131e-03, 1.7751e-02,
        1.0772e-04, 2.7387e-05, 5.5387e-04, 4.8678e-04, 9.2083e-04, 8.6957e-03,
        1.7585e-03, 2.6140e-03, 7.5330e-04, 2.8219e-01, 4.4265e-01, 1.3980e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,927][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([2.0706e-03, 4.4726e-03, 2.1935e-03, 1.0297e-01, 2.6172e-02, 9.6014e-03,
        5.1160e-04, 2.2312e-04, 1.0392e-03, 2.3717e-03, 1.9470e-03, 1.8267e-02,
        4.0255e-03, 7.2481e-03, 5.4918e-03, 1.5144e-01, 4.5988e-01, 2.0007e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,930][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0106, 0.0387, 0.0523, 0.0601, 0.0650, 0.0626, 0.0523, 0.0486, 0.0569,
        0.0742, 0.0500, 0.0499, 0.0760, 0.0603, 0.0569, 0.0642, 0.0506, 0.0706],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,931][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([4.2209e-03, 1.3069e-02, 4.7676e-03, 1.4942e-01, 5.6551e-02, 2.5445e-02,
        7.4293e-04, 2.1382e-04, 1.7729e-03, 2.2166e-03, 2.8005e-03, 1.4315e-02,
        4.6193e-03, 7.8593e-03, 7.9022e-03, 2.1705e-01, 2.9831e-01, 1.8873e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,933][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.2886, 0.0344, 0.0225, 0.0499, 0.0300, 0.0555, 0.0514, 0.0331, 0.0354,
        0.0451, 0.0284, 0.0389, 0.0360, 0.0362, 0.0402, 0.0625, 0.0691, 0.0429],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,934][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([5.4529e-04, 2.3797e-03, 1.1799e-03, 3.1164e-03, 4.9991e-02, 3.1561e-04,
        9.6988e-05, 3.5234e-04, 2.9074e-04, 5.4020e-03, 1.0272e-03, 6.5479e-03,
        7.9481e-03, 2.4673e-03, 5.1642e-03, 8.7203e-02, 3.9639e-01, 4.2958e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,935][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0115, 0.0463, 0.0429, 0.0595, 0.0510, 0.0601, 0.0556, 0.0541, 0.0620,
        0.0555, 0.0649, 0.0639, 0.0555, 0.0643, 0.0492, 0.0711, 0.0715, 0.0611],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,936][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0015, 0.0186, 0.0095, 0.1048, 0.0778, 0.0650, 0.0066, 0.0026, 0.0107,
        0.0138, 0.0137, 0.0416, 0.0233, 0.0251, 0.0289, 0.1814, 0.2065, 0.1685],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,937][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.4994, 0.0212, 0.0100, 0.0442, 0.0389, 0.0478, 0.0418, 0.0147, 0.0209,
        0.0384, 0.0240, 0.0324, 0.0149, 0.0349, 0.0251, 0.0225, 0.0550, 0.0137],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,938][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.0331, 0.0137, 0.0043, 0.0988, 0.0309, 0.0459, 0.0048, 0.0018, 0.0061,
        0.0050, 0.0081, 0.0456, 0.0075, 0.0094, 0.0090, 0.1620, 0.4022, 0.1117],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,940][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0533, 0.0132, 0.0439, 0.0124, 0.1102, 0.0172, 0.0333, 0.0148, 0.0514,
        0.0915, 0.0209, 0.0246, 0.0295, 0.0280, 0.1169, 0.0207, 0.0403, 0.2779],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,942][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([2.8250e-05, 7.8991e-10, 9.1725e-13, 2.3254e-05, 1.6042e-07, 5.4840e-08,
        8.3153e-15, 4.9471e-16, 1.1346e-12, 1.2972e-12, 6.3027e-11, 7.2498e-07,
        1.1702e-09, 4.3857e-09, 3.2437e-09, 1.7575e-02, 9.7266e-01, 9.7132e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:54,943][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([2.7621e-03, 7.3727e-03, 3.4369e-04, 1.5291e-01, 1.2059e-02, 2.2064e-02,
        1.4276e-04, 2.9990e-05, 5.9779e-04, 7.3597e-04, 5.7750e-04, 8.2597e-03,
        1.0031e-03, 2.0874e-03, 6.8966e-04, 2.3035e-01, 3.2794e-01, 1.8292e-01,
        4.7163e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,945][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0029, 0.0092, 0.0032, 0.1023, 0.0251, 0.0121, 0.0008, 0.0004, 0.0011,
        0.0038, 0.0023, 0.0195, 0.0069, 0.0070, 0.0043, 0.1240, 0.3752, 0.1713,
        0.1287], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,947][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0115, 0.0379, 0.0584, 0.0573, 0.0677, 0.0574, 0.0445, 0.0465, 0.0464,
        0.0798, 0.0447, 0.0432, 0.0728, 0.0540, 0.0613, 0.0582, 0.0414, 0.0685,
        0.0486], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,949][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0028, 0.0179, 0.0044, 0.1414, 0.0511, 0.0350, 0.0010, 0.0004, 0.0021,
        0.0038, 0.0035, 0.0133, 0.0039, 0.0054, 0.0052, 0.1677, 0.2890, 0.1620,
        0.0901], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,950][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2378, 0.0435, 0.0318, 0.0506, 0.0388, 0.0526, 0.0467, 0.0331, 0.0350,
        0.0398, 0.0265, 0.0386, 0.0325, 0.0349, 0.0526, 0.0600, 0.0600, 0.0332,
        0.0518], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,952][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.1206e-04, 1.6030e-03, 1.8096e-03, 3.2689e-03, 5.7119e-02, 3.3614e-04,
        5.3483e-05, 1.8584e-04, 1.0786e-04, 4.0555e-03, 4.5152e-04, 2.8577e-03,
        4.6117e-03, 7.0429e-04, 2.4648e-03, 7.7097e-02, 2.5741e-01, 5.2875e-01,
        5.6996e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,954][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0126, 0.0488, 0.0441, 0.0587, 0.0505, 0.0576, 0.0492, 0.0517, 0.0553,
        0.0527, 0.0575, 0.0574, 0.0527, 0.0573, 0.0457, 0.0640, 0.0625, 0.0592,
        0.0623], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,955][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0015, 0.0300, 0.0079, 0.0754, 0.0662, 0.0602, 0.0058, 0.0026, 0.0088,
        0.0151, 0.0134, 0.0357, 0.0196, 0.0228, 0.0229, 0.1181, 0.2036, 0.1636,
        0.1270], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,957][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.4253, 0.0305, 0.0090, 0.0412, 0.0279, 0.0545, 0.0358, 0.0115, 0.0169,
        0.0401, 0.0178, 0.0333, 0.0103, 0.0367, 0.0162, 0.0331, 0.0688, 0.0236,
        0.0677], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,957][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0367, 0.0193, 0.0080, 0.0750, 0.0380, 0.0443, 0.0040, 0.0018, 0.0051,
        0.0066, 0.0082, 0.0371, 0.0038, 0.0087, 0.0090, 0.1543, 0.3270, 0.1066,
        0.1067], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,958][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1882, 0.0487, 0.0505, 0.0352, 0.0081, 0.0695, 0.0253, 0.0402, 0.1008,
        0.0313, 0.0891, 0.0464, 0.0124, 0.0693, 0.0098, 0.0274, 0.0377, 0.0119,
        0.0981], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:54,959][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([8.6359e-04, 1.9256e-09, 9.6551e-11, 5.3578e-05, 1.5310e-05, 1.0411e-06,
        6.0304e-14, 1.2092e-14, 5.5430e-13, 2.2733e-11, 3.9034e-11, 5.3388e-07,
        1.1997e-08, 2.8854e-09, 1.9975e-08, 4.3884e-02, 7.3804e-01, 2.1133e-01,
        5.8165e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,006][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:55,007][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,009][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,009][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,010][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,011][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,012][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,012][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,013][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,014][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,014][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,015][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,016][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,016][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1702, 0.8298], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,017][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0571, 0.9429], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,018][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9095, 0.0905], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,018][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1381, 0.8619], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,021][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9924, 0.0076], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,024][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1263, 0.8737], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,025][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.4490, 0.5510], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,026][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2811, 0.7189], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,026][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9596, 0.0404], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,027][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7104, 0.2896], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,028][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3969, 0.6031], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,031][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9504, 0.0496], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,035][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Jamie] are: tensor([0.0925, 0.4834, 0.4241], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,036][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Jamie] are: tensor([0.0193, 0.9330, 0.0477], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,036][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Jamie] are: tensor([0.8151, 0.1476, 0.0373], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,037][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Jamie] are: tensor([0.1007, 0.4487, 0.4505], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,038][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Jamie] are: tensor([0.9865, 0.0068, 0.0067], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,039][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Jamie] are: tensor([0.0987, 0.7594, 0.1419], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,042][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Jamie] are: tensor([0.2173, 0.4759, 0.3068], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,046][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Jamie] are: tensor([0.1807, 0.4069, 0.4124], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,047][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Jamie] are: tensor([0.9203, 0.0500, 0.0297], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,047][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Jamie] are: tensor([0.4643, 0.3130, 0.2226], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,048][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Jamie] are: tensor([0.0889, 0.3751, 0.5360], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,049][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Jamie] are: tensor([2.0064e-03, 9.9799e-01, 2.1695e-06], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,050][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0746, 0.3300, 0.2894, 0.3060], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,053][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0228, 0.5980, 0.1595, 0.2197], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,057][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.8611, 0.0833, 0.0107, 0.0449], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,058][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0496, 0.3189, 0.3050, 0.3265], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,058][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9792, 0.0054, 0.0040, 0.0115], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,059][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1477, 0.4518, 0.0566, 0.3440], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,060][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2502, 0.1751, 0.1312, 0.4435], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,061][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0843, 0.3061, 0.3063, 0.3032], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,064][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9340, 0.0249, 0.0070, 0.0342], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,068][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.7020, 0.1074, 0.0584, 0.1322], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,069][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1373, 0.1632, 0.6194, 0.0801], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,069][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.7921, 0.0514, 0.0205, 0.1361], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,070][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0496, 0.2418, 0.2165, 0.2342, 0.2579], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,071][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0236, 0.7323, 0.0245, 0.1979, 0.0217], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,072][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.6507, 0.1336, 0.0401, 0.1008, 0.0748], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,075][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.0530, 0.2265, 0.2250, 0.2415, 0.2541], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,079][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.9549, 0.0063, 0.0095, 0.0126, 0.0167], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,079][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.0529, 0.2239, 0.0409, 0.4992, 0.1831], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,080][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0838, 0.1328, 0.0930, 0.5094, 0.1810], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,081][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0388, 0.2300, 0.2452, 0.2392, 0.2468], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,082][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.6887, 0.0499, 0.0668, 0.0994, 0.0952], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,083][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.3976, 0.1091, 0.0841, 0.2462, 0.1629], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,088][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0544, 0.0839, 0.1303, 0.0448, 0.6865], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,090][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([3.6138e-05, 5.3245e-02, 3.1172e-05, 9.4657e-01, 1.1958e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,090][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0439, 0.1935, 0.1716, 0.1847, 0.2094, 0.1970], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,091][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0810, 0.3698, 0.0793, 0.3142, 0.1015, 0.0542], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,092][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.5320, 0.1449, 0.0234, 0.0893, 0.0796, 0.1307], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,093][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0374, 0.1775, 0.1772, 0.1879, 0.1989, 0.2211], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,095][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.9363, 0.0076, 0.0071, 0.0181, 0.0106, 0.0203], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,099][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0612, 0.2248, 0.0307, 0.3535, 0.1524, 0.1774], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,101][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0805, 0.1079, 0.0641, 0.3065, 0.1563, 0.2847], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,101][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0534, 0.1911, 0.1917, 0.1915, 0.1911, 0.1812], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,102][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.7865, 0.0429, 0.0139, 0.0644, 0.0314, 0.0609], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,103][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3161, 0.1333, 0.0571, 0.1377, 0.1303, 0.2256], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,104][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0866, 0.1689, 0.4131, 0.0336, 0.1828, 0.1150], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,106][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0077, 0.0017, 0.0020, 0.3102, 0.5817, 0.0967], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,110][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0181, 0.1663, 0.1573, 0.1700, 0.2070, 0.1758, 0.1054],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,112][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0438, 0.4350, 0.1336, 0.1289, 0.1463, 0.0863, 0.0262],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,112][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1428, 0.2338, 0.0431, 0.1764, 0.1584, 0.1753, 0.0701],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,113][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0195, 0.1546, 0.1527, 0.1655, 0.1722, 0.1814, 0.1541],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,114][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.8983, 0.0134, 0.0102, 0.0240, 0.0137, 0.0274, 0.0130],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,115][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([3.2645e-04, 8.4931e-02, 1.8528e-02, 6.1080e-01, 1.8687e-01, 9.4283e-02,
        4.2670e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,117][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0250, 0.0638, 0.0426, 0.2894, 0.1257, 0.3106, 0.1429],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,121][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0340, 0.1622, 0.1646, 0.1650, 0.1677, 0.1522, 0.1543],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,123][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.5595, 0.0608, 0.0196, 0.0965, 0.0564, 0.1096, 0.0975],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,123][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0101, 0.0917, 0.0480, 0.3409, 0.2160, 0.2749, 0.0183],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,124][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0341, 0.1092, 0.3825, 0.0349, 0.3390, 0.0594, 0.0409],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,125][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([6.9536e-10, 8.9690e-05, 1.9792e-06, 9.7759e-01, 1.0235e-02, 1.2080e-02,
        4.6390e-12], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,126][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0144, 0.1478, 0.1493, 0.1544, 0.1981, 0.1560, 0.0941, 0.0859],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,128][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0065, 0.6010, 0.0367, 0.1874, 0.0593, 0.0585, 0.0488, 0.0020],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,133][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0917, 0.1677, 0.0491, 0.1898, 0.1723, 0.1955, 0.0733, 0.0605],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,134][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0185, 0.1333, 0.1343, 0.1449, 0.1509, 0.1586, 0.1346, 0.1249],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,135][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.8944, 0.0169, 0.0075, 0.0252, 0.0167, 0.0249, 0.0102, 0.0043],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,135][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([1.7234e-04, 5.1390e-02, 1.0352e-02, 6.8796e-01, 1.2237e-01, 1.1598e-01,
        8.3424e-03, 3.4320e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,136][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0220, 0.0536, 0.0407, 0.2183, 0.1231, 0.2629, 0.2004, 0.0790],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,137][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0361, 0.1410, 0.1417, 0.1418, 0.1420, 0.1306, 0.1320, 0.1346],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,141][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.6448, 0.0401, 0.0196, 0.0661, 0.0600, 0.0781, 0.0658, 0.0255],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,144][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0044, 0.0770, 0.0356, 0.3174, 0.2737, 0.2531, 0.0268, 0.0121],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,145][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0839, 0.1012, 0.2260, 0.0374, 0.2282, 0.0504, 0.0672, 0.2058],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,146][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([9.8358e-11, 9.9505e-05, 4.1940e-07, 9.8120e-01, 1.2218e-02, 6.4862e-03,
        3.7011e-09, 6.7878e-12], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,147][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0150, 0.1394, 0.1348, 0.1415, 0.1787, 0.1454, 0.0894, 0.0807, 0.0751],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,148][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0178, 0.3313, 0.1330, 0.1374, 0.1872, 0.0821, 0.0690, 0.0156, 0.0266],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,150][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.1475, 0.1715, 0.0306, 0.1610, 0.1274, 0.1547, 0.0607, 0.0695, 0.0771],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,155][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0143, 0.1207, 0.1201, 0.1291, 0.1332, 0.1421, 0.1205, 0.1125, 0.1074],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,156][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.9089, 0.0127, 0.0068, 0.0229, 0.0101, 0.0175, 0.0096, 0.0033, 0.0082],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,157][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([6.2476e-04, 7.9426e-02, 1.5787e-02, 6.8866e-01, 1.1684e-01, 8.4085e-02,
        4.9467e-03, 3.0514e-03, 6.5730e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,157][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0286, 0.0540, 0.0345, 0.2345, 0.1109, 0.2088, 0.0952, 0.0527, 0.1807],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,158][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0203, 0.1218, 0.1252, 0.1262, 0.1289, 0.1163, 0.1177, 0.1198, 0.1238],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,159][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.5550, 0.0475, 0.0206, 0.0821, 0.0612, 0.0889, 0.0752, 0.0281, 0.0413],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,163][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0201, 0.0644, 0.0451, 0.2830, 0.3084, 0.2286, 0.0198, 0.0111, 0.0195],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,166][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0617, 0.1361, 0.3390, 0.0293, 0.2595, 0.0254, 0.0240, 0.0757, 0.0495],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,167][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([3.7418e-07, 1.1847e-04, 5.6792e-06, 7.3731e-01, 2.4105e-01, 2.1518e-02,
        1.1774e-10, 1.1835e-10, 5.8521e-10], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,168][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0133, 0.1304, 0.1205, 0.1339, 0.1632, 0.1388, 0.0810, 0.0727, 0.0693,
        0.0769], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,169][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0066, 0.4992, 0.0337, 0.1768, 0.0559, 0.0548, 0.0488, 0.0067, 0.1141,
        0.0033], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,169][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.1090, 0.1950, 0.0336, 0.1769, 0.1240, 0.1598, 0.0486, 0.0475, 0.0505,
        0.0550], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,172][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0154, 0.1059, 0.1069, 0.1151, 0.1199, 0.1296, 0.1079, 0.1018, 0.0958,
        0.1017], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,177][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.8859, 0.0147, 0.0057, 0.0228, 0.0089, 0.0254, 0.0096, 0.0046, 0.0084,
        0.0139], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,177][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([5.4398e-04, 6.0423e-02, 7.9024e-03, 6.6551e-01, 1.1300e-01, 1.1024e-01,
        5.7071e-03, 2.6735e-03, 1.5190e-02, 1.8803e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,178][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0154, 0.0331, 0.0212, 0.1386, 0.0625, 0.1646, 0.1553, 0.0538, 0.3028,
        0.0527], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,179][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0183, 0.1089, 0.1124, 0.1133, 0.1152, 0.1038, 0.1047, 0.1065, 0.1099,
        0.1071], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,180][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.4220, 0.0703, 0.0156, 0.0890, 0.0449, 0.1209, 0.0830, 0.0305, 0.0328,
        0.0909], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,181][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0126, 0.0794, 0.0285, 0.3215, 0.1821, 0.2915, 0.0175, 0.0090, 0.0248,
        0.0331], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,185][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0493, 0.0917, 0.1603, 0.0820, 0.1392, 0.0497, 0.0591, 0.0969, 0.1391,
        0.1326], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,188][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([3.8346e-08, 6.0432e-05, 1.4539e-07, 9.7635e-01, 4.6579e-03, 1.8931e-02,
        3.9109e-10, 1.9465e-11, 7.8890e-08, 6.5352e-08], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,189][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0122, 0.1203, 0.1123, 0.1217, 0.1509, 0.1243, 0.0782, 0.0725, 0.0684,
        0.0755, 0.0638], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,190][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0431, 0.2599, 0.1573, 0.1423, 0.0708, 0.1187, 0.1014, 0.0170, 0.0626,
        0.0166, 0.0104], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,190][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1237, 0.1787, 0.0253, 0.1320, 0.0909, 0.1406, 0.0541, 0.0493, 0.0521,
        0.0566, 0.0966], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,191][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0146, 0.0958, 0.0965, 0.1051, 0.1103, 0.1169, 0.0971, 0.0908, 0.0847,
        0.0917, 0.0966], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,194][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.9006, 0.0123, 0.0057, 0.0199, 0.0081, 0.0197, 0.0086, 0.0032, 0.0053,
        0.0076, 0.0091], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,198][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0009, 0.0889, 0.0082, 0.6505, 0.0891, 0.0967, 0.0067, 0.0030, 0.0132,
        0.0315, 0.0112], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,199][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0222, 0.0373, 0.0241, 0.1722, 0.0687, 0.1639, 0.0746, 0.0386, 0.1541,
        0.0440, 0.2002], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,200][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0199, 0.0993, 0.1010, 0.1017, 0.1027, 0.0933, 0.0945, 0.0955, 0.0986,
        0.0959, 0.0974], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,201][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.5608, 0.0417, 0.0105, 0.0560, 0.0367, 0.0750, 0.0647, 0.0215, 0.0342,
        0.0696, 0.0294], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,202][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0162, 0.0691, 0.0329, 0.3275, 0.1829, 0.2379, 0.0205, 0.0088, 0.0250,
        0.0483, 0.0308], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,204][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0287, 0.1050, 0.3428, 0.0208, 0.2872, 0.0125, 0.0201, 0.0424, 0.0524,
        0.0441, 0.0439], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,206][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([2.5326e-06, 8.7605e-05, 6.6964e-07, 9.4505e-01, 4.0324e-02, 1.4536e-02,
        8.2189e-11, 3.1126e-11, 4.7388e-09, 3.1818e-07, 1.0523e-07],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,210][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0125, 0.1168, 0.1067, 0.1184, 0.1427, 0.1190, 0.0684, 0.0629, 0.0617,
        0.0671, 0.0599, 0.0639], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,211][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0164, 0.4185, 0.0590, 0.1215, 0.0904, 0.1323, 0.0277, 0.0093, 0.0680,
        0.0167, 0.0200, 0.0203], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,212][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1832, 0.1400, 0.0197, 0.1111, 0.0772, 0.1237, 0.0404, 0.0371, 0.0411,
        0.0431, 0.0726, 0.1108], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,213][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0109, 0.0924, 0.0902, 0.0983, 0.1007, 0.1048, 0.0881, 0.0842, 0.0787,
        0.0831, 0.0874, 0.0812], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,213][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.9159, 0.0097, 0.0062, 0.0146, 0.0069, 0.0135, 0.0056, 0.0029, 0.0048,
        0.0044, 0.0054, 0.0101], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,217][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0033, 0.0677, 0.0108, 0.6484, 0.0897, 0.0732, 0.0048, 0.0020, 0.0084,
        0.0204, 0.0115, 0.0598], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,221][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0234, 0.0329, 0.0206, 0.1387, 0.0617, 0.1306, 0.0634, 0.0341, 0.1297,
        0.0413, 0.1822, 0.1415], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,221][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0192, 0.0911, 0.0922, 0.0926, 0.0936, 0.0849, 0.0863, 0.0869, 0.0897,
        0.0873, 0.0889, 0.0874], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,222][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.6464, 0.0294, 0.0091, 0.0434, 0.0271, 0.0557, 0.0478, 0.0132, 0.0247,
        0.0441, 0.0200, 0.0390], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,223][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0442, 0.0644, 0.0346, 0.2642, 0.1596, 0.2000, 0.0162, 0.0073, 0.0217,
        0.0286, 0.0326, 0.1266], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,224][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0461, 0.0636, 0.2840, 0.0293, 0.1342, 0.0879, 0.0449, 0.1111, 0.0530,
        0.0643, 0.0449, 0.0368], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,226][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([7.7970e-04, 7.3083e-05, 3.8076e-07, 9.7710e-01, 1.0400e-02, 1.1349e-02,
        3.2297e-11, 1.4014e-11, 8.1539e-09, 5.8705e-08, 5.6347e-07, 2.9412e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,230][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.0126, 0.1071, 0.0995, 0.1113, 0.1310, 0.1071, 0.0627, 0.0587, 0.0590,
        0.0633, 0.0573, 0.0609, 0.0695], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,232][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0030, 0.2956, 0.0439, 0.1959, 0.0807, 0.0785, 0.0955, 0.0048, 0.0850,
        0.0066, 0.0269, 0.0741, 0.0096], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,233][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.1254, 0.0892, 0.0244, 0.1267, 0.1004, 0.1095, 0.0379, 0.0468, 0.0503,
        0.0369, 0.0718, 0.1111, 0.0695], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,233][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.0118, 0.0860, 0.0841, 0.0911, 0.0926, 0.0968, 0.0810, 0.0774, 0.0728,
        0.0766, 0.0819, 0.0759, 0.0721], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,234][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.9277, 0.0070, 0.0027, 0.0138, 0.0037, 0.0068, 0.0055, 0.0020, 0.0058,
        0.0029, 0.0061, 0.0103, 0.0059], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,235][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.0033, 0.0360, 0.0074, 0.5907, 0.0879, 0.0932, 0.0043, 0.0018, 0.0139,
        0.0140, 0.0159, 0.1016, 0.0299], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,239][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.0105, 0.0197, 0.0158, 0.0865, 0.0440, 0.0963, 0.0832, 0.0330, 0.1527,
        0.0371, 0.2117, 0.1650, 0.0445], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,242][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0257, 0.0851, 0.0850, 0.0841, 0.0845, 0.0775, 0.0785, 0.0793, 0.0811,
        0.0794, 0.0805, 0.0792, 0.0802], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,243][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.5956, 0.0287, 0.0119, 0.0552, 0.0301, 0.0713, 0.0549, 0.0111, 0.0253,
        0.0434, 0.0245, 0.0371, 0.0110], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,244][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.0420, 0.0354, 0.0406, 0.2830, 0.1895, 0.1701, 0.0151, 0.0075, 0.0192,
        0.0254, 0.0381, 0.1095, 0.0243], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,245][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.0127, 0.0488, 0.1455, 0.0146, 0.0672, 0.0092, 0.0261, 0.0464, 0.0396,
        0.1112, 0.0115, 0.0142, 0.4530], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,246][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([3.5329e-06, 1.9728e-04, 2.4829e-07, 9.4289e-01, 5.8837e-03, 2.8309e-03,
        5.1115e-10, 1.8265e-11, 3.3436e-08, 2.0688e-07, 1.9683e-06, 4.8166e-02,
        2.7732e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,249][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0103, 0.0971, 0.0911, 0.1002, 0.1202, 0.1015, 0.0638, 0.0597, 0.0572,
        0.0623, 0.0545, 0.0595, 0.0664, 0.0563], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,253][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0092, 0.2196, 0.1016, 0.0951, 0.1080, 0.1432, 0.1159, 0.0073, 0.0494,
        0.0088, 0.0224, 0.0749, 0.0237, 0.0209], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,254][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0845, 0.1283, 0.0185, 0.1127, 0.0648, 0.1112, 0.0357, 0.0388, 0.0386,
        0.0404, 0.0727, 0.1010, 0.0592, 0.0934], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,255][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0101, 0.0777, 0.0761, 0.0814, 0.0825, 0.0876, 0.0759, 0.0744, 0.0690,
        0.0715, 0.0765, 0.0714, 0.0682, 0.0777], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,256][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.8254, 0.0157, 0.0112, 0.0248, 0.0104, 0.0210, 0.0087, 0.0030, 0.0079,
        0.0074, 0.0086, 0.0146, 0.0051, 0.0362], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,257][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0009, 0.0616, 0.0089, 0.6547, 0.0609, 0.0900, 0.0041, 0.0014, 0.0068,
        0.0102, 0.0090, 0.0553, 0.0147, 0.0216], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,260][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0195, 0.0280, 0.0184, 0.1120, 0.0532, 0.1110, 0.0544, 0.0280, 0.1034,
        0.0342, 0.1504, 0.1241, 0.0467, 0.1165], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,264][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0170, 0.0789, 0.0792, 0.0796, 0.0784, 0.0725, 0.0735, 0.0737, 0.0763,
        0.0737, 0.0754, 0.0743, 0.0741, 0.0734], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,265][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.3228, 0.0630, 0.0175, 0.0737, 0.0537, 0.0937, 0.0620, 0.0219, 0.0309,
        0.0836, 0.0302, 0.0628, 0.0198, 0.0644], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,266][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0126, 0.0668, 0.0305, 0.2661, 0.1776, 0.1983, 0.0143, 0.0070, 0.0148,
        0.0341, 0.0263, 0.1114, 0.0178, 0.0222], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,267][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0434, 0.0572, 0.2520, 0.0175, 0.1906, 0.0132, 0.0221, 0.0383, 0.0443,
        0.0450, 0.0359, 0.0183, 0.1310, 0.0912], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,268][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([1.1170e-07, 3.4000e-05, 2.4115e-07, 9.7281e-01, 1.5143e-02, 1.0307e-02,
        1.4535e-10, 8.5383e-12, 4.8229e-09, 9.2252e-08, 2.8231e-07, 1.6696e-03,
        3.5144e-05, 1.5107e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,271][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0141, 0.0931, 0.0836, 0.0939, 0.1068, 0.0899, 0.0552, 0.0518, 0.0524,
        0.0547, 0.0499, 0.0554, 0.0627, 0.0536, 0.0830], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,275][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0058, 0.3500, 0.0084, 0.0880, 0.0073, 0.2240, 0.0470, 0.0051, 0.0839,
        0.0042, 0.0574, 0.0549, 0.0219, 0.0388, 0.0034], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,276][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.0715, 0.0995, 0.0253, 0.0927, 0.0633, 0.0908, 0.0383, 0.0474, 0.0350,
        0.0404, 0.0762, 0.1128, 0.0600, 0.0950, 0.0518], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,277][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.0147, 0.0682, 0.0678, 0.0724, 0.0752, 0.0814, 0.0691, 0.0680, 0.0638,
        0.0670, 0.0735, 0.0679, 0.0639, 0.0708, 0.0763], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,277][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.6912, 0.0138, 0.0168, 0.0279, 0.0281, 0.0166, 0.0080, 0.0028, 0.0103,
        0.0061, 0.0098, 0.0166, 0.0068, 0.0535, 0.0917], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,278][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.0045, 0.0458, 0.0102, 0.3459, 0.0811, 0.0623, 0.0094, 0.0038, 0.0175,
        0.0247, 0.0282, 0.1404, 0.0747, 0.1071, 0.0444], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,282][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0043, 0.0113, 0.0068, 0.0644, 0.0185, 0.0879, 0.0653, 0.0240, 0.1571,
        0.0260, 0.1831, 0.1457, 0.0308, 0.1574, 0.0175], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,286][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0072, 0.0680, 0.0750, 0.0728, 0.0792, 0.0675, 0.0689, 0.0700, 0.0731,
        0.0709, 0.0710, 0.0698, 0.0681, 0.0685, 0.0700], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,287][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.2025, 0.0417, 0.0358, 0.0809, 0.0459, 0.1403, 0.0657, 0.0211, 0.0352,
        0.0770, 0.0437, 0.0703, 0.0322, 0.0711, 0.0367], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,288][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.0425, 0.0442, 0.0393, 0.1874, 0.1049, 0.1733, 0.0172, 0.0152, 0.0220,
        0.0445, 0.0413, 0.1327, 0.0418, 0.0497, 0.0443], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,288][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0178, 0.0337, 0.0416, 0.0203, 0.2725, 0.0367, 0.0226, 0.0265, 0.0138,
        0.0541, 0.0218, 0.0119, 0.1189, 0.0315, 0.2763], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,289][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([2.4365e-05, 8.2615e-04, 1.0485e-06, 7.7054e-01, 1.0278e-03, 1.3239e-02,
        3.2536e-09, 4.5393e-10, 3.6061e-07, 1.7864e-06, 3.2475e-05, 2.1019e-01,
        1.3183e-03, 2.7142e-03, 8.3025e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,293][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0157, 0.0888, 0.0761, 0.0906, 0.0984, 0.0865, 0.0520, 0.0472, 0.0477,
        0.0486, 0.0459, 0.0498, 0.0539, 0.0493, 0.0731, 0.0764],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,297][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0115, 0.3120, 0.0451, 0.1561, 0.0341, 0.0498, 0.0377, 0.0087, 0.0647,
        0.0114, 0.0391, 0.0491, 0.0206, 0.1103, 0.0175, 0.0323],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,297][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.2061, 0.0936, 0.0177, 0.0868, 0.0805, 0.0878, 0.0262, 0.0273, 0.0250,
        0.0330, 0.0440, 0.0752, 0.0299, 0.0603, 0.0500, 0.0566],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,298][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0149, 0.0637, 0.0621, 0.0672, 0.0688, 0.0746, 0.0632, 0.0615, 0.0582,
        0.0602, 0.0655, 0.0614, 0.0571, 0.0641, 0.0686, 0.0891],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,299][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.8244, 0.0108, 0.0058, 0.0172, 0.0066, 0.0196, 0.0067, 0.0022, 0.0040,
        0.0050, 0.0046, 0.0117, 0.0047, 0.0339, 0.0236, 0.0193],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,300][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0181, 0.0658, 0.0062, 0.3779, 0.0798, 0.0583, 0.0036, 0.0014, 0.0073,
        0.0111, 0.0074, 0.0535, 0.0133, 0.0306, 0.0221, 0.2436],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,304][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0219, 0.0229, 0.0139, 0.0911, 0.0384, 0.0711, 0.0418, 0.0202, 0.0855,
        0.0247, 0.1212, 0.1003, 0.0341, 0.1078, 0.0241, 0.1811],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,310][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0164, 0.0697, 0.0692, 0.0690, 0.0684, 0.0634, 0.0639, 0.0638, 0.0656,
        0.0637, 0.0648, 0.0638, 0.0645, 0.0631, 0.0629, 0.0677],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,311][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.5169, 0.0298, 0.0068, 0.0429, 0.0258, 0.0539, 0.0476, 0.0150, 0.0214,
        0.0637, 0.0245, 0.0455, 0.0116, 0.0429, 0.0182, 0.0337],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,311][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1393, 0.0548, 0.0205, 0.1592, 0.0837, 0.1072, 0.0099, 0.0048, 0.0142,
        0.0135, 0.0192, 0.0778, 0.0113, 0.0213, 0.0218, 0.2414],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,312][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0325, 0.0460, 0.1509, 0.0175, 0.1014, 0.0506, 0.0230, 0.1048, 0.0305,
        0.0232, 0.0195, 0.0212, 0.1206, 0.0696, 0.1183, 0.0704],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,313][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([2.2291e-01, 7.2859e-06, 9.9586e-08, 4.7309e-01, 1.8487e-03, 8.7359e-04,
        7.8405e-12, 9.3689e-13, 5.1315e-10, 1.4405e-09, 2.8797e-08, 1.8380e-04,
        8.7701e-07, 1.5514e-06, 3.6988e-06, 3.0108e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,316][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0125, 0.0833, 0.0742, 0.0850, 0.0979, 0.0824, 0.0468, 0.0426, 0.0433,
        0.0452, 0.0404, 0.0445, 0.0485, 0.0453, 0.0705, 0.0757, 0.0620],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,321][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0240, 0.2976, 0.0852, 0.0945, 0.0788, 0.0615, 0.0157, 0.0084, 0.0586,
        0.0142, 0.0221, 0.0215, 0.0385, 0.0410, 0.0376, 0.0836, 0.0172],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,322][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2237, 0.0897, 0.0132, 0.0678, 0.0531, 0.0645, 0.0188, 0.0171, 0.0192,
        0.0190, 0.0356, 0.0604, 0.0241, 0.0521, 0.0387, 0.0614, 0.1416],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,323][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0098, 0.0623, 0.0597, 0.0649, 0.0654, 0.0685, 0.0586, 0.0565, 0.0541,
        0.0553, 0.0587, 0.0553, 0.0527, 0.0615, 0.0659, 0.0797, 0.0712],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,324][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.7996, 0.0101, 0.0068, 0.0167, 0.0082, 0.0220, 0.0083, 0.0025, 0.0043,
        0.0058, 0.0054, 0.0104, 0.0030, 0.0341, 0.0239, 0.0176, 0.0213],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,324][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0108, 0.0291, 0.0041, 0.2525, 0.0458, 0.0272, 0.0012, 0.0006, 0.0031,
        0.0040, 0.0031, 0.0325, 0.0066, 0.0154, 0.0098, 0.1814, 0.3728],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,328][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0229, 0.0207, 0.0117, 0.0832, 0.0337, 0.0622, 0.0274, 0.0180, 0.0610,
        0.0216, 0.0833, 0.0712, 0.0289, 0.0788, 0.0173, 0.1563, 0.2018],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,332][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0127, 0.0632, 0.0635, 0.0643, 0.0656, 0.0587, 0.0602, 0.0606, 0.0630,
        0.0612, 0.0620, 0.0608, 0.0602, 0.0601, 0.0604, 0.0642, 0.0593],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,333][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.4538, 0.0267, 0.0093, 0.0428, 0.0270, 0.0534, 0.0440, 0.0144, 0.0219,
        0.0537, 0.0206, 0.0425, 0.0103, 0.0504, 0.0186, 0.0364, 0.0742],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,334][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0650, 0.0269, 0.0103, 0.1208, 0.0572, 0.0839, 0.0049, 0.0025, 0.0080,
        0.0077, 0.0105, 0.0476, 0.0050, 0.0117, 0.0124, 0.2030, 0.3226],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,334][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0109, 0.0354, 0.1231, 0.0109, 0.1345, 0.0191, 0.0161, 0.0426, 0.0205,
        0.0253, 0.0235, 0.0141, 0.2527, 0.0536, 0.1741, 0.0278, 0.0156],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,335][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([5.4938e-02, 2.0761e-07, 4.0837e-09, 5.4400e-03, 7.2899e-05, 4.1384e-05,
        4.9286e-14, 2.2261e-14, 1.5640e-11, 6.8956e-11, 1.2056e-09, 1.2123e-06,
        2.0338e-08, 3.1582e-08, 5.9134e-08, 2.6119e-01, 6.7831e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,339][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.0128, 0.0797, 0.0689, 0.0814, 0.0898, 0.0776, 0.0433, 0.0389, 0.0398,
        0.0419, 0.0372, 0.0420, 0.0461, 0.0427, 0.0637, 0.0721, 0.0592, 0.0628],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,343][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.0012, 0.4347, 0.0426, 0.1357, 0.0651, 0.0524, 0.0488, 0.0013, 0.0285,
        0.0030, 0.0117, 0.0539, 0.0179, 0.0277, 0.0163, 0.0197, 0.0354, 0.0040],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,344][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.1568, 0.0636, 0.0114, 0.0779, 0.0535, 0.0686, 0.0236, 0.0232, 0.0221,
        0.0237, 0.0353, 0.0636, 0.0298, 0.0459, 0.0362, 0.0660, 0.1640, 0.0348],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,344][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.0091, 0.0576, 0.0564, 0.0612, 0.0619, 0.0648, 0.0547, 0.0523, 0.0504,
        0.0516, 0.0549, 0.0515, 0.0491, 0.0587, 0.0625, 0.0766, 0.0671, 0.0597],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,345][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.8837, 0.0046, 0.0037, 0.0093, 0.0065, 0.0095, 0.0042, 0.0016, 0.0031,
        0.0029, 0.0027, 0.0070, 0.0031, 0.0159, 0.0197, 0.0105, 0.0089, 0.0029],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,346][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([6.1420e-03, 6.5642e-03, 7.3875e-04, 9.5249e-02, 1.2934e-02, 1.3633e-02,
        8.2639e-04, 2.9782e-04, 2.6544e-03, 2.2274e-03, 2.7149e-03, 2.2463e-02,
        3.2798e-03, 1.4419e-02, 4.1845e-03, 1.2883e-01, 4.9538e-01, 1.8747e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,350][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.0067, 0.0080, 0.0052, 0.0391, 0.0165, 0.0416, 0.0408, 0.0128, 0.0744,
        0.0137, 0.0974, 0.0815, 0.0183, 0.0846, 0.0152, 0.1316, 0.2864, 0.0262],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,353][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0110, 0.0584, 0.0604, 0.0604, 0.0628, 0.0553, 0.0571, 0.0573, 0.0599,
        0.0581, 0.0584, 0.0573, 0.0569, 0.0563, 0.0581, 0.0607, 0.0558, 0.0559],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,354][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.4994, 0.0212, 0.0100, 0.0442, 0.0389, 0.0478, 0.0418, 0.0147, 0.0209,
        0.0384, 0.0240, 0.0324, 0.0149, 0.0349, 0.0251, 0.0225, 0.0550, 0.0137],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,355][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.0331, 0.0137, 0.0043, 0.0988, 0.0309, 0.0459, 0.0048, 0.0018, 0.0061,
        0.0050, 0.0081, 0.0456, 0.0075, 0.0094, 0.0090, 0.1620, 0.4022, 0.1117],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,356][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0136, 0.0366, 0.1107, 0.0153, 0.1195, 0.0111, 0.0217, 0.0154, 0.0326,
        0.0542, 0.0155, 0.0134, 0.1161, 0.0462, 0.1444, 0.0171, 0.0223, 0.1943],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,357][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([2.8250e-05, 7.8991e-10, 9.1725e-13, 2.3254e-05, 1.6042e-07, 5.4840e-08,
        8.3153e-15, 4.9471e-16, 1.1346e-12, 1.2972e-12, 6.3027e-11, 7.2498e-07,
        1.1702e-09, 4.3857e-09, 3.2437e-09, 1.7575e-02, 9.7266e-01, 9.7132e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,361][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0100, 0.0734, 0.0640, 0.0740, 0.0854, 0.0728, 0.0436, 0.0389, 0.0387,
        0.0410, 0.0356, 0.0405, 0.0427, 0.0399, 0.0612, 0.0667, 0.0566, 0.0604,
        0.0547], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,364][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0170, 0.2246, 0.1152, 0.0874, 0.0579, 0.0463, 0.0703, 0.0098, 0.0441,
        0.0181, 0.0175, 0.0459, 0.0372, 0.0474, 0.0233, 0.0385, 0.0700, 0.0094,
        0.0202], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,365][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1491, 0.0685, 0.0097, 0.0557, 0.0418, 0.0638, 0.0197, 0.0203, 0.0190,
        0.0251, 0.0378, 0.0663, 0.0229, 0.0511, 0.0320, 0.0589, 0.1385, 0.0303,
        0.0895], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,366][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0072, 0.0537, 0.0529, 0.0567, 0.0585, 0.0617, 0.0524, 0.0498, 0.0474,
        0.0490, 0.0510, 0.0483, 0.0470, 0.0541, 0.0589, 0.0716, 0.0629, 0.0566,
        0.0603], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,367][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.8425, 0.0092, 0.0054, 0.0144, 0.0047, 0.0131, 0.0054, 0.0018, 0.0034,
        0.0036, 0.0045, 0.0083, 0.0034, 0.0260, 0.0141, 0.0147, 0.0132, 0.0025,
        0.0101], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,369][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0041, 0.0140, 0.0013, 0.1351, 0.0140, 0.0158, 0.0010, 0.0004, 0.0017,
        0.0034, 0.0019, 0.0175, 0.0033, 0.0096, 0.0028, 0.1272, 0.3509, 0.2151,
        0.0809], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,373][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0225, 0.0144, 0.0080, 0.0613, 0.0253, 0.0463, 0.0225, 0.0121, 0.0471,
        0.0138, 0.0671, 0.0591, 0.0203, 0.0624, 0.0131, 0.1181, 0.1968, 0.0382,
        0.1517], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,375][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0113, 0.0561, 0.0567, 0.0571, 0.0587, 0.0522, 0.0541, 0.0542, 0.0565,
        0.0549, 0.0555, 0.0544, 0.0540, 0.0535, 0.0544, 0.0574, 0.0532, 0.0533,
        0.0524], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,376][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.4253, 0.0305, 0.0090, 0.0412, 0.0279, 0.0545, 0.0358, 0.0115, 0.0169,
        0.0401, 0.0178, 0.0333, 0.0103, 0.0367, 0.0162, 0.0331, 0.0688, 0.0236,
        0.0677], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,377][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0367, 0.0193, 0.0080, 0.0750, 0.0380, 0.0443, 0.0040, 0.0018, 0.0051,
        0.0066, 0.0082, 0.0371, 0.0038, 0.0087, 0.0090, 0.1543, 0.3270, 0.1066,
        0.1067], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,378][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0325, 0.0508, 0.1564, 0.0208, 0.0944, 0.0147, 0.0321, 0.0437, 0.0281,
        0.0267, 0.0283, 0.0272, 0.1093, 0.0706, 0.1381, 0.0189, 0.0287, 0.0576,
        0.0210], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,379][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([8.6359e-04, 1.9256e-09, 9.6551e-11, 5.3578e-05, 1.5310e-05, 1.0411e-06,
        6.0304e-14, 1.2092e-14, 5.5430e-13, 2.2733e-11, 3.9034e-11, 5.3388e-07,
        1.1997e-08, 2.8854e-09, 1.9975e-08, 4.3884e-02, 7.3804e-01, 2.1133e-01,
        5.8165e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,382][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:55,385][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 9437],
        [ 7869],
        [ 7234],
        [10688],
        [10526],
        [15472],
        [ 8620],
        [14752],
        [12224],
        [ 4411],
        [10440],
        [ 8441],
        [15592],
        [ 4929],
        [10558],
        [10065],
        [ 5148],
        [11706],
        [ 5946]], device='cuda:0')
[2024-07-24 10:17:55,388][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 9568],
        [11235],
        [ 3243],
        [18497],
        [15983],
        [23019],
        [16468],
        [13245],
        [24706],
        [ 3280],
        [13282],
        [ 9742],
        [17705],
        [ 5681],
        [16005],
        [ 8500],
        [ 8445],
        [16332],
        [ 7646]], device='cuda:0')
[2024-07-24 10:17:55,389][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[  873],
        [32933],
        [31697],
        [33834],
        [34779],
        [23078],
        [28427],
        [25971],
        [29864],
        [27721],
        [29279],
        [28768],
        [30231],
        [29809],
        [22661],
        [30158],
        [22577],
        [16588],
        [17422]], device='cuda:0')
[2024-07-24 10:17:55,391][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[47210],
        [42852],
        [42570],
        [44475],
        [44963],
        [44552],
        [44465],
        [44477],
        [44405],
        [44545],
        [44537],
        [45247],
        [45847],
        [45693],
        [46215],
        [42739],
        [44582],
        [47127],
        [47656]], device='cuda:0')
[2024-07-24 10:17:55,393][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[16554],
        [18002],
        [19617],
        [20643],
        [20865],
        [20674],
        [20716],
        [21005],
        [21598],
        [22765],
        [23354],
        [23612],
        [24124],
        [24138],
        [24075],
        [23962],
        [23960],
        [24238],
        [24394]], device='cuda:0')
[2024-07-24 10:17:55,396][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 670],
        [5208],
        [5262],
        [6056],
        [7162],
        [4941],
        [6648],
        [6788],
        [6455],
        [6363],
        [6319],
        [6049],
        [5403],
        [5789],
        [4800],
        [4395],
        [3493],
        [3001],
        [3231]], device='cuda:0')
[2024-07-24 10:17:55,399][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[23951],
        [23456],
        [22698],
        [22593],
        [22988],
        [23038],
        [23373],
        [23571],
        [23512],
        [23007],
        [23152],
        [22871],
        [22959],
        [22927],
        [23014],
        [23055],
        [23122],
        [23201],
        [23467]], device='cuda:0')
[2024-07-24 10:17:55,401][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[14227],
        [21131],
        [24961],
        [27905],
        [33920],
        [26924],
        [35395],
        [32341],
        [35016],
        [31104],
        [30975],
        [32286],
        [26753],
        [30709],
        [28129],
        [22526],
        [14180],
        [ 9501],
        [ 9669]], device='cuda:0')
[2024-07-24 10:17:55,402][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[26664],
        [21606],
        [19279],
        [21239],
        [20981],
        [22614],
        [23728],
        [24773],
        [25595],
        [26264],
        [26802],
        [27220],
        [27500],
        [27819],
        [27872],
        [27844],
        [27933],
        [27882],
        [27628]], device='cuda:0')
[2024-07-24 10:17:55,405][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[7068],
        [8554],
        [8017],
        [5993],
        [5467],
        [5653],
        [5563],
        [5581],
        [5644],
        [5583],
        [5621],
        [5553],
        [5580],
        [5655],
        [5553],
        [5477],
        [5322],
        [5516],
        [5474]], device='cuda:0')
[2024-07-24 10:17:55,408][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 3111],
        [ 2579],
        [ 3632],
        [ 3136],
        [13422],
        [ 5892],
        [13628],
        [12486],
        [15703],
        [17480],
        [15929],
        [12951],
        [14701],
        [20086],
        [23232],
        [17583],
        [21107],
        [21043],
        [22852]], device='cuda:0')
[2024-07-24 10:17:55,411][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[38447],
        [34804],
        [42849],
        [39856],
        [37184],
        [40375],
        [38320],
        [37156],
        [37044],
        [39001],
        [38955],
        [39964],
        [39488],
        [39615],
        [41216],
        [42162],
        [41580],
        [40182],
        [41332]], device='cuda:0')
[2024-07-24 10:17:55,413][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[32911],
        [22309],
        [ 3301],
        [ 4600],
        [17485],
        [ 5974],
        [ 5268],
        [37581],
        [ 6663],
        [ 6790],
        [ 4206],
        [ 9820],
        [10498],
        [ 2978],
        [16987],
        [20803],
        [ 4947],
        [ 5007],
        [ 3353]], device='cuda:0')
[2024-07-24 10:17:55,414][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[35336],
        [34593],
        [14454],
        [34786],
        [30481],
        [43734],
        [31700],
        [31667],
        [37973],
        [31637],
        [32567],
        [31698],
        [31365],
        [31789],
        [30873],
        [35382],
        [33490],
        [31615],
        [32969]], device='cuda:0')
[2024-07-24 10:17:55,416][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 4775],
        [11925],
        [27450],
        [15731],
        [15020],
        [20590],
        [12525],
        [17738],
        [12175],
        [12640],
        [13402],
        [12390],
        [16405],
        [ 8768],
        [10769],
        [15126],
        [ 9905],
        [11854],
        [10081]], device='cuda:0')
[2024-07-24 10:17:55,420][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[1643],
        [2445],
        [3146],
        [2806],
        [2758],
        [2621],
        [2589],
        [2464],
        [2340],
        [2272],
        [2119],
        [2093],
        [2055],
        [2052],
        [2052],
        [2040],
        [2010],
        [1973],
        [1910]], device='cuda:0')
[2024-07-24 10:17:55,423][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 5162],
        [11796],
        [12618],
        [16477],
        [14515],
        [18370],
        [18049],
        [16890],
        [19113],
        [17811],
        [21605],
        [19332],
        [20883],
        [21897],
        [22101],
        [19789],
        [18812],
        [18455],
        [20659]], device='cuda:0')
[2024-07-24 10:17:55,424][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 4117],
        [ 4574],
        [ 4947],
        [ 4269],
        [ 5088],
        [ 6299],
        [ 6540],
        [ 7647],
        [ 8699],
        [ 8084],
        [ 8573],
        [ 8992],
        [ 8929],
        [ 9047],
        [ 9604],
        [ 8841],
        [10437],
        [10791],
        [11126]], device='cuda:0')
[2024-07-24 10:17:55,426][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[13139],
        [ 5449],
        [ 4912],
        [ 4791],
        [ 5071],
        [ 5227],
        [ 5145],
        [ 5039],
        [ 5010],
        [ 4849],
        [ 4764],
        [ 4734],
        [ 4687],
        [ 4609],
        [ 4657],
        [ 4639],
        [ 4671],
        [ 4696],
        [ 4725]], device='cuda:0')
[2024-07-24 10:17:55,428][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[12164],
        [13041],
        [13893],
        [14716],
        [19996],
        [19772],
        [24413],
        [24398],
        [22756],
        [23263],
        [22487],
        [21613],
        [20792],
        [33235],
        [46819],
        [36366],
        [36430],
        [30576],
        [31856]], device='cuda:0')
[2024-07-24 10:17:55,431][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[13389],
        [ 5698],
        [ 6258],
        [ 5874],
        [ 8163],
        [ 7361],
        [ 9178],
        [ 9190],
        [ 9118],
        [ 8515],
        [ 7820],
        [ 7301],
        [ 6389],
        [ 6960],
        [ 3459],
        [ 4930],
        [ 3997],
        [ 4269],
        [ 4060]], device='cuda:0')
[2024-07-24 10:17:55,435][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[13927],
        [12851],
        [12299],
        [11058],
        [11350],
        [ 9255],
        [ 8160],
        [ 7995],
        [ 7798],
        [ 6948],
        [ 7395],
        [ 6999],
        [ 6602],
        [ 6830],
        [ 6294],
        [ 6882],
        [ 6720],
        [ 6373],
        [ 6991]], device='cuda:0')
[2024-07-24 10:17:55,436][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[48083],
        [ 3924],
        [ 3025],
        [ 2625],
        [ 2565],
        [ 2591],
        [ 2544],
        [ 2540],
        [ 2504],
        [ 2513],
        [ 2521],
        [ 2534],
        [ 2536],
        [ 2518],
        [ 2524],
        [ 2532],
        [ 2521],
        [ 2520],
        [ 2510]], device='cuda:0')
[2024-07-24 10:17:55,437][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 5917],
        [ 7021],
        [ 7592],
        [ 7538],
        [ 9441],
        [11537],
        [15722],
        [12606],
        [14291],
        [11870],
        [10731],
        [11122],
        [11856],
        [12605],
        [13911],
        [10814],
        [12277],
        [11602],
        [13554]], device='cuda:0')
[2024-07-24 10:17:55,440][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 8717],
        [23926],
        [24687],
        [20360],
        [24183],
        [20774],
        [20865],
        [21027],
        [21132],
        [19118],
        [18794],
        [19432],
        [19385],
        [19622],
        [17683],
        [13616],
        [12631],
        [11204],
        [10926]], device='cuda:0')
[2024-07-24 10:17:55,443][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[4195],
        [1737],
        [3187],
        [3025],
        [5282],
        [3032],
        [4116],
        [3331],
        [3052],
        [1998],
        [3309],
        [2581],
        [3615],
        [2675],
        [4378],
        [2671],
        [3044],
        [4436],
        [2829]], device='cuda:0')
[2024-07-24 10:17:55,446][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[33977],
        [34211],
        [27149],
        [33331],
        [20819],
        [31102],
        [21002],
        [20938],
        [24802],
        [21060],
        [21606],
        [21012],
        [21646],
        [21091],
        [24676],
        [32140],
        [35100],
        [36049],
        [33933]], device='cuda:0')
[2024-07-24 10:17:55,448][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[43656],
        [44901],
        [44146],
        [45126],
        [44084],
        [43076],
        [43204],
        [43565],
        [43104],
        [44169],
        [43880],
        [44034],
        [44139],
        [43791],
        [43565],
        [44398],
        [43940],
        [43727],
        [43843]], device='cuda:0')
[2024-07-24 10:17:55,449][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[41395],
        [43203],
        [39156],
        [40037],
        [30700],
        [34079],
        [30055],
        [35057],
        [31063],
        [32848],
        [35606],
        [36629],
        [37012],
        [35364],
        [33101],
        [35392],
        [34187],
        [38617],
        [36189]], device='cuda:0')
[2024-07-24 10:17:55,451][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[6988],
        [6988],
        [6988],
        [6988],
        [6988],
        [6988],
        [6988],
        [6988],
        [6988],
        [6988],
        [6988],
        [6988],
        [6988],
        [6988],
        [6988],
        [6988],
        [6988],
        [6988],
        [6988]], device='cuda:0')
[2024-07-24 10:17:55,508][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:55,508][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,509][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,510][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,510][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,511][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,512][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,512][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,513][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,514][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,514][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,515][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,516][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,516][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5280, 0.4720], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,517][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2179, 0.7821], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,518][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1371, 0.8629], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,518][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3110, 0.6890], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,521][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3644, 0.6356], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,521][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2091, 0.7909], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,522][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4768, 0.5232], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,523][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3778, 0.6222], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,523][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.6487, 0.3513], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,524][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2413, 0.7587], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,528][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4656, 0.5344], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,532][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2521, 0.7479], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,532][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Jamie] are: tensor([0.3492, 0.1248, 0.5259], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,533][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Jamie] are: tensor([0.1690, 0.3817, 0.4493], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,534][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Jamie] are: tensor([0.0694, 0.6524, 0.2782], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,534][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Jamie] are: tensor([0.1657, 0.4510, 0.3833], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,535][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Jamie] are: tensor([0.1878, 0.6108, 0.2014], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,539][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Jamie] are: tensor([0.2259, 0.6354, 0.1387], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,542][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Jamie] are: tensor([0.4445, 0.4838, 0.0717], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,543][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Jamie] are: tensor([0.2451, 0.4805, 0.2744], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,544][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Jamie] are: tensor([0.7139, 0.1756, 0.1104], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,544][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Jamie] are: tensor([0.1153, 0.5063, 0.3784], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,545][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Jamie] are: tensor([0.2840, 0.3067, 0.4093], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,546][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Jamie] are: tensor([0.1580, 0.4222, 0.4198], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,549][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1899, 0.1135, 0.4713, 0.2252], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,553][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0905, 0.2348, 0.2728, 0.4018], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,554][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1375, 0.4012, 0.2536, 0.2077], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,555][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3786, 0.3087, 0.1908, 0.1219], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,555][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.6089, 0.1748, 0.0562, 0.1600], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,556][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1668, 0.3604, 0.0769, 0.3959], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,557][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6555, 0.1042, 0.0640, 0.1763], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,560][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.6544, 0.2303, 0.0761, 0.0392], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,562][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.6285, 0.1113, 0.1103, 0.1499], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,562][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0992, 0.2865, 0.2906, 0.3238], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,566][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2174, 0.1597, 0.2003, 0.4225], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,566][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1051, 0.3040, 0.3195, 0.2714], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,567][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.1175, 0.0623, 0.1475, 0.4794, 0.1933], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,568][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0811, 0.1661, 0.1959, 0.2784, 0.2784], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,569][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0273, 0.2196, 0.0707, 0.3944, 0.2880], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,569][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.0716, 0.1640, 0.1659, 0.2621, 0.3364], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,573][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0884, 0.1657, 0.0562, 0.5760, 0.1136], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,577][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.2710, 0.1414, 0.0600, 0.3541, 0.1734], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,578][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.1643, 0.2087, 0.0675, 0.4218, 0.1378], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,578][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.1245, 0.4163, 0.1454, 0.1948, 0.1190], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,579][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.3854, 0.0969, 0.0550, 0.3311, 0.1316], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,580][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0633, 0.2451, 0.2857, 0.2587, 0.1472], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,582][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0434, 0.0520, 0.0642, 0.5924, 0.2480], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,586][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0749, 0.2355, 0.2357, 0.2026, 0.2512], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,588][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0566, 0.1966, 0.1478, 0.3669, 0.1208, 0.1113], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,588][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0408, 0.1316, 0.1585, 0.2161, 0.2253, 0.2277], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,589][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0600, 0.1753, 0.1105, 0.1396, 0.3338, 0.1808], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,590][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1461, 0.1509, 0.1035, 0.1337, 0.2461, 0.2197], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,591][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.3393, 0.0875, 0.0319, 0.1580, 0.0922, 0.2911], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,593][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0818, 0.2802, 0.0511, 0.3603, 0.1544, 0.0721], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,597][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.3544, 0.0641, 0.0347, 0.1412, 0.1244, 0.2811], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,599][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.6266, 0.0795, 0.0169, 0.0286, 0.0444, 0.2040], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,599][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.5480, 0.0412, 0.0433, 0.1043, 0.1335, 0.1297], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,600][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0627, 0.1827, 0.1786, 0.1824, 0.1253, 0.2683], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,601][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0636, 0.1049, 0.1358, 0.3381, 0.1115, 0.2460], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,602][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0626, 0.1765, 0.1822, 0.1656, 0.1875, 0.2255], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:55,604][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0356, 0.0969, 0.0953, 0.2995, 0.1195, 0.2180, 0.1353],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,608][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0380, 0.1021, 0.1203, 0.1778, 0.1700, 0.1776, 0.2142],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,610][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0010, 0.0529, 0.0280, 0.4110, 0.2858, 0.1999, 0.0214],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,610][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0053, 0.0766, 0.0570, 0.2817, 0.2679, 0.2650, 0.0465],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,611][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0042, 0.0384, 0.0129, 0.3991, 0.0960, 0.4398, 0.0095],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,612][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1285, 0.2216, 0.0450, 0.3722, 0.1811, 0.0404, 0.0113],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,613][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0151, 0.0512, 0.0177, 0.3323, 0.1445, 0.4211, 0.0181],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,615][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0151, 0.1000, 0.0162, 0.1255, 0.1362, 0.5244, 0.0825],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,620][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0372, 0.0368, 0.0423, 0.3597, 0.1860, 0.3040, 0.0340],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,621][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0488, 0.1360, 0.1430, 0.1488, 0.0991, 0.2132, 0.2111],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,622][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1663, 0.1399, 0.1635, 0.1739, 0.1199, 0.1492, 0.0872],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,622][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0495, 0.1455, 0.1579, 0.1404, 0.1664, 0.1810, 0.1593],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:55,623][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0141, 0.0426, 0.0897, 0.2857, 0.1390, 0.2191, 0.1642, 0.0456],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,624][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0280, 0.0741, 0.0977, 0.1482, 0.1417, 0.1548, 0.1847, 0.1707],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,628][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0007, 0.0412, 0.0361, 0.3515, 0.3199, 0.1961, 0.0434, 0.0110],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,631][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0029, 0.0534, 0.0617, 0.2638, 0.2482, 0.2531, 0.0613, 0.0557],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,632][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0018, 0.0300, 0.0087, 0.4180, 0.0752, 0.4414, 0.0166, 0.0084],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,633][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0797, 0.2479, 0.0424, 0.3427, 0.2074, 0.0406, 0.0131, 0.0263],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,634][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0145, 0.0450, 0.0168, 0.3391, 0.1182, 0.4008, 0.0444, 0.0212],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,634][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0028, 0.0962, 0.0305, 0.1170, 0.3055, 0.3623, 0.0733, 0.0123],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,637][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0264, 0.0235, 0.0374, 0.3769, 0.1689, 0.2973, 0.0541, 0.0155],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,641][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0282, 0.1071, 0.1159, 0.1209, 0.0780, 0.1919, 0.1983, 0.1597],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,642][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0175, 0.0514, 0.0703, 0.3359, 0.0832, 0.2030, 0.1531, 0.0857],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,643][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0493, 0.1277, 0.1374, 0.1150, 0.1418, 0.1578, 0.1378, 0.1331],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:55,644][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0148, 0.0780, 0.1087, 0.2439, 0.1005, 0.2083, 0.1576, 0.0546, 0.0337],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,645][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0286, 0.0668, 0.0815, 0.1217, 0.1140, 0.1168, 0.1490, 0.1442, 0.1775],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,646][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0022, 0.0407, 0.0271, 0.4022, 0.3084, 0.1566, 0.0261, 0.0091, 0.0275],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,648][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0054, 0.0553, 0.0465, 0.2596, 0.2745, 0.2020, 0.0414, 0.0485, 0.0667],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,654][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0084, 0.0220, 0.0103, 0.4467, 0.0966, 0.3810, 0.0113, 0.0060, 0.0178],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,656][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.3228, 0.1419, 0.0354, 0.2614, 0.1446, 0.0399, 0.0124, 0.0200, 0.0216],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,657][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0322, 0.0610, 0.0145, 0.3114, 0.1648, 0.3265, 0.0255, 0.0356, 0.0285],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,658][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0162, 0.1018, 0.0253, 0.1522, 0.1906, 0.3295, 0.0710, 0.0191, 0.0942],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,658][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0294, 0.0184, 0.0366, 0.3491, 0.2070, 0.2922, 0.0381, 0.0104, 0.0186],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,659][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0283, 0.0857, 0.0949, 0.1059, 0.0697, 0.1575, 0.1564, 0.1534, 0.1484],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,662][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0614, 0.0797, 0.0961, 0.1823, 0.0838, 0.1511, 0.1043, 0.1225, 0.1187],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,667][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0404, 0.1124, 0.1233, 0.1080, 0.1244, 0.1374, 0.1208, 0.1158, 0.1174],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:55,667][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0133, 0.0385, 0.0627, 0.1499, 0.1050, 0.0713, 0.0918, 0.0195, 0.0455,
        0.4024], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,668][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0219, 0.0596, 0.0734, 0.1088, 0.1112, 0.1154, 0.1310, 0.1193, 0.1536,
        0.1059], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,669][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0014, 0.0462, 0.0205, 0.2890, 0.2565, 0.1926, 0.0328, 0.0116, 0.0584,
        0.0909], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,670][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0037, 0.0429, 0.0378, 0.1906, 0.1588, 0.1684, 0.0467, 0.0439, 0.1036,
        0.2035], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,672][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0078, 0.0315, 0.0116, 0.3241, 0.1039, 0.4160, 0.0169, 0.0089, 0.0274,
        0.0519], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,676][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.1250, 0.2551, 0.0316, 0.3089, 0.1680, 0.0313, 0.0125, 0.0215, 0.0271,
        0.0191], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,678][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0139, 0.0327, 0.0072, 0.2706, 0.1032, 0.4299, 0.0233, 0.0202, 0.0656,
        0.0335], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,679][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0120, 0.0595, 0.0106, 0.1156, 0.1113, 0.2779, 0.0887, 0.0206, 0.1237,
        0.1802], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,680][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0348, 0.0253, 0.0393, 0.2746, 0.2462, 0.2239, 0.0443, 0.0102, 0.0406,
        0.0608], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,680][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0287, 0.0977, 0.0894, 0.0878, 0.0611, 0.1454, 0.1385, 0.1531, 0.1352,
        0.0631], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,681][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0119, 0.0332, 0.0283, 0.3254, 0.0370, 0.1728, 0.1495, 0.0167, 0.2138,
        0.0113], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,684][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0344, 0.1073, 0.1051, 0.0967, 0.1190, 0.1274, 0.1034, 0.0952, 0.0945,
        0.1170], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:55,688][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0099, 0.0589, 0.0409, 0.1023, 0.0708, 0.0754, 0.0663, 0.0259, 0.0267,
        0.3408, 0.1822], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,689][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0189, 0.0579, 0.0666, 0.1006, 0.0965, 0.0957, 0.1156, 0.1083, 0.1360,
        0.0947, 0.1091], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,690][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0029, 0.0539, 0.0271, 0.3006, 0.2510, 0.1466, 0.0272, 0.0086, 0.0493,
        0.0803, 0.0525], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,691][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0058, 0.0527, 0.0364, 0.1632, 0.1633, 0.1398, 0.0425, 0.0461, 0.0745,
        0.2012, 0.0746], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,692][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0120, 0.0317, 0.0104, 0.3255, 0.0983, 0.3639, 0.0127, 0.0063, 0.0241,
        0.0606, 0.0546], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,693][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.2069, 0.1682, 0.0283, 0.3528, 0.1400, 0.0323, 0.0101, 0.0143, 0.0154,
        0.0151, 0.0166], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,696][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0813, 0.0298, 0.0084, 0.1946, 0.0982, 0.3883, 0.0230, 0.0176, 0.0535,
        0.0555, 0.0499], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,700][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0223, 0.0442, 0.0118, 0.0596, 0.1805, 0.2608, 0.0722, 0.0103, 0.0851,
        0.1221, 0.1311], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,700][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0340, 0.0281, 0.0366, 0.3303, 0.2083, 0.2046, 0.0321, 0.0110, 0.0266,
        0.0505, 0.0379], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,701][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0245, 0.0806, 0.0864, 0.0881, 0.0523, 0.1277, 0.1437, 0.1182, 0.1302,
        0.0758, 0.0725], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,702][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0114, 0.0247, 0.0220, 0.3570, 0.0218, 0.1791, 0.1542, 0.0129, 0.2066,
        0.0080, 0.0023], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,703][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0300, 0.0956, 0.1011, 0.0878, 0.1005, 0.1177, 0.0962, 0.0846, 0.0871,
        0.1016, 0.0978], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:55,705][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0102, 0.0374, 0.0228, 0.0863, 0.0353, 0.0787, 0.0389, 0.0142, 0.0280,
        0.2214, 0.1812, 0.2455], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,710][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0168, 0.0519, 0.0611, 0.0910, 0.0863, 0.0864, 0.1070, 0.1017, 0.1236,
        0.0815, 0.0920, 0.1008], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,711][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0114, 0.0503, 0.0235, 0.2373, 0.2323, 0.0996, 0.0213, 0.0078, 0.0336,
        0.0491, 0.0427, 0.1912], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,712][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0197, 0.0499, 0.0304, 0.1208, 0.1384, 0.1156, 0.0274, 0.0326, 0.0486,
        0.1194, 0.0543, 0.2429], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,713][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0619, 0.0364, 0.0086, 0.3146, 0.0827, 0.2842, 0.0092, 0.0045, 0.0166,
        0.0368, 0.0428, 0.1017], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,713][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1941, 0.1795, 0.0317, 0.3289, 0.1375, 0.0330, 0.0088, 0.0164, 0.0205,
        0.0158, 0.0164, 0.0174], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,715][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1568, 0.0343, 0.0138, 0.1955, 0.0912, 0.2679, 0.0133, 0.0124, 0.0334,
        0.0310, 0.0485, 0.1017], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,720][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0611, 0.0592, 0.0099, 0.0537, 0.0511, 0.1955, 0.0432, 0.0079, 0.0673,
        0.0507, 0.1176, 0.2827], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,721][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0877, 0.0428, 0.0389, 0.2786, 0.1661, 0.1802, 0.0247, 0.0082, 0.0229,
        0.0359, 0.0323, 0.0816], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,722][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0204, 0.0685, 0.0678, 0.0814, 0.0497, 0.1191, 0.1236, 0.1079, 0.1132,
        0.0659, 0.0731, 0.1096], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,723][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0433, 0.0733, 0.0821, 0.0907, 0.0452, 0.0854, 0.0440, 0.1021, 0.0549,
        0.1178, 0.1769, 0.0843], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,724][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0326, 0.0831, 0.0917, 0.0790, 0.0908, 0.1019, 0.0887, 0.0820, 0.0823,
        0.0912, 0.0827, 0.0940], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:55,725][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0050, 0.0129, 0.0459, 0.0849, 0.0712, 0.0559, 0.0559, 0.0065, 0.0266,
        0.1451, 0.1640, 0.2405, 0.0856], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,728][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0154, 0.0405, 0.0536, 0.0766, 0.0774, 0.0816, 0.0992, 0.0914, 0.1151,
        0.0755, 0.0950, 0.1008, 0.0778], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,732][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0139, 0.0314, 0.0149, 0.1581, 0.1466, 0.1116, 0.0166, 0.0077, 0.0268,
        0.0530, 0.0493, 0.2881, 0.0820], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,733][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0056, 0.0245, 0.0254, 0.1256, 0.1198, 0.0938, 0.0206, 0.0192, 0.0501,
        0.1044, 0.0450, 0.2233, 0.1427], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,734][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0247, 0.0148, 0.0073, 0.2412, 0.0656, 0.2151, 0.0106, 0.0044, 0.0243,
        0.0484, 0.0702, 0.1871, 0.0862], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,735][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.1318, 0.1757, 0.0475, 0.2295, 0.1444, 0.0354, 0.0145, 0.0307, 0.0428,
        0.0262, 0.0315, 0.0422, 0.0478], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,735][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0273, 0.0284, 0.0135, 0.1833, 0.0684, 0.2247, 0.0160, 0.0125, 0.0420,
        0.0434, 0.0578, 0.1927, 0.0899], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,739][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0134, 0.0694, 0.0236, 0.0765, 0.0711, 0.1311, 0.0289, 0.0079, 0.0374,
        0.0632, 0.0957, 0.3168, 0.0651], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,743][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.0925, 0.0189, 0.0371, 0.1621, 0.1297, 0.1515, 0.0240, 0.0071, 0.0277,
        0.0464, 0.0502, 0.1867, 0.0660], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,744][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0208, 0.0628, 0.0730, 0.0699, 0.0378, 0.1150, 0.1240, 0.0959, 0.1093,
        0.0663, 0.0631, 0.1033, 0.0588], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,744][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0159, 0.0216, 0.0322, 0.2469, 0.0499, 0.1363, 0.1385, 0.0195, 0.1515,
        0.0112, 0.0031, 0.1244, 0.0490], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,745][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0302, 0.0780, 0.0821, 0.0707, 0.0812, 0.0920, 0.0814, 0.0777, 0.0784,
        0.0832, 0.0755, 0.0849, 0.0846], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:55,746][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0043, 0.0443, 0.0514, 0.0682, 0.0698, 0.0489, 0.0474, 0.0121, 0.0211,
        0.1581, 0.1268, 0.2074, 0.1184, 0.0218], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,750][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0126, 0.0443, 0.0567, 0.0791, 0.0774, 0.0733, 0.0849, 0.0806, 0.1022,
        0.0725, 0.0821, 0.0856, 0.0700, 0.0786], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,754][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0029, 0.0444, 0.0173, 0.2539, 0.1787, 0.1035, 0.0131, 0.0035, 0.0206,
        0.0386, 0.0313, 0.1888, 0.0822, 0.0212], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,754][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0047, 0.0413, 0.0219, 0.1170, 0.1229, 0.1010, 0.0172, 0.0211, 0.0340,
        0.0965, 0.0369, 0.1874, 0.1622, 0.0359], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,755][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0138, 0.0404, 0.0068, 0.3250, 0.0787, 0.2698, 0.0076, 0.0030, 0.0114,
        0.0315, 0.0308, 0.0971, 0.0531, 0.0309], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,756][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1698, 0.1230, 0.0255, 0.4352, 0.1354, 0.0232, 0.0067, 0.0117, 0.0183,
        0.0089, 0.0126, 0.0152, 0.0130, 0.0016], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,757][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0348, 0.0226, 0.0064, 0.2477, 0.0560, 0.2661, 0.0194, 0.0081, 0.0312,
        0.0205, 0.0322, 0.1376, 0.0475, 0.0700], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,761][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0171, 0.0744, 0.0103, 0.0783, 0.0572, 0.1763, 0.0317, 0.0064, 0.0509,
        0.0357, 0.0982, 0.2406, 0.0426, 0.0803], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,764][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0308, 0.0388, 0.0321, 0.2694, 0.1576, 0.1721, 0.0204, 0.0051, 0.0117,
        0.0318, 0.0243, 0.0965, 0.0704, 0.0390], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,765][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0184, 0.0602, 0.0582, 0.0699, 0.0475, 0.0979, 0.0963, 0.0868, 0.0944,
        0.0553, 0.0599, 0.0945, 0.0654, 0.0953], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,766][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0218, 0.0615, 0.0604, 0.1179, 0.0361, 0.1103, 0.0712, 0.0769, 0.0805,
        0.0694, 0.0532, 0.1135, 0.0603, 0.0671], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,767][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0238, 0.0784, 0.0806, 0.0663, 0.0796, 0.0878, 0.0738, 0.0670, 0.0695,
        0.0776, 0.0732, 0.0765, 0.0753, 0.0706], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:55,768][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0025, 0.0250, 0.0288, 0.1419, 0.0489, 0.1047, 0.0385, 0.0065, 0.0204,
        0.1413, 0.1230, 0.1217, 0.0946, 0.0199, 0.0820], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,772][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0140, 0.0379, 0.0465, 0.0642, 0.0630, 0.0666, 0.0778, 0.0760, 0.1014,
        0.0708, 0.0854, 0.0811, 0.0692, 0.0763, 0.0698], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,775][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0025, 0.0190, 0.0076, 0.1017, 0.0691, 0.0649, 0.0186, 0.0082, 0.0349,
        0.0684, 0.0692, 0.2273, 0.1398, 0.0498, 0.1190], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,776][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.0033, 0.0177, 0.0170, 0.0470, 0.0562, 0.0515, 0.0227, 0.0241, 0.0435,
        0.0953, 0.0574, 0.2167, 0.1674, 0.0641, 0.1160], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,777][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0062, 0.0127, 0.0042, 0.1185, 0.0241, 0.1273, 0.0138, 0.0083, 0.0305,
        0.0666, 0.0827, 0.2175, 0.1496, 0.0953, 0.0426], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,778][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.5197, 0.0307, 0.0118, 0.1762, 0.0560, 0.0483, 0.0128, 0.0119, 0.0274,
        0.0204, 0.0174, 0.0242, 0.0346, 0.0034, 0.0053], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,779][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0192, 0.0274, 0.0085, 0.0980, 0.0377, 0.0855, 0.0197, 0.0158, 0.0363,
        0.0539, 0.0456, 0.2085, 0.1124, 0.1764, 0.0552], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,782][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0054, 0.0263, 0.0089, 0.0396, 0.0160, 0.1004, 0.0310, 0.0099, 0.0511,
        0.1146, 0.1189, 0.1909, 0.1353, 0.1000, 0.0516], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,786][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.0231, 0.0206, 0.0119, 0.1159, 0.0398, 0.1518, 0.0329, 0.0104, 0.0444,
        0.0699, 0.0622, 0.1552, 0.1287, 0.0801, 0.0531], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,787][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0139, 0.0529, 0.0615, 0.0570, 0.0329, 0.0969, 0.0933, 0.0957, 0.0907,
        0.0570, 0.0667, 0.0951, 0.0579, 0.0965, 0.0318], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,788][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0166, 0.0595, 0.0652, 0.1046, 0.0777, 0.0800, 0.0503, 0.0711, 0.0616,
        0.0650, 0.0567, 0.0688, 0.1150, 0.0407, 0.0673], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,788][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0192, 0.0721, 0.0721, 0.0601, 0.0756, 0.0803, 0.0689, 0.0621, 0.0629,
        0.0714, 0.0663, 0.0727, 0.0758, 0.0629, 0.0774], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:55,789][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0015, 0.0075, 0.0101, 0.0295, 0.0114, 0.0191, 0.0391, 0.0084, 0.0167,
        0.2147, 0.1637, 0.2496, 0.0675, 0.0248, 0.0562, 0.0803],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,793][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0107, 0.0367, 0.0467, 0.0622, 0.0648, 0.0685, 0.0774, 0.0725, 0.0886,
        0.0617, 0.0713, 0.0738, 0.0637, 0.0669, 0.0648, 0.0697],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,796][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0245, 0.0282, 0.0131, 0.1057, 0.0996, 0.0401, 0.0106, 0.0038, 0.0183,
        0.0228, 0.0241, 0.1147, 0.0525, 0.0228, 0.0838, 0.3353],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,797][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0223, 0.0281, 0.0118, 0.0564, 0.0568, 0.0534, 0.0134, 0.0131, 0.0193,
        0.0430, 0.0223, 0.1463, 0.0695, 0.0249, 0.0675, 0.3521],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,798][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1410, 0.0178, 0.0041, 0.1038, 0.0283, 0.0667, 0.0026, 0.0013, 0.0055,
        0.0073, 0.0132, 0.0418, 0.0197, 0.0173, 0.0179, 0.5118],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,799][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.1328, 0.1506, 0.0270, 0.3649, 0.1166, 0.0291, 0.0125, 0.0235, 0.0273,
        0.0209, 0.0211, 0.0279, 0.0218, 0.0034, 0.0071, 0.0135],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,800][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1059, 0.0148, 0.0052, 0.1015, 0.0286, 0.1205, 0.0067, 0.0042, 0.0139,
        0.0092, 0.0189, 0.0695, 0.0235, 0.0381, 0.0235, 0.4161],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,804][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0431, 0.0139, 0.0014, 0.0116, 0.0075, 0.0354, 0.0057, 0.0018, 0.0125,
        0.0149, 0.0198, 0.0521, 0.0122, 0.0202, 0.0064, 0.7415],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,807][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1946, 0.0219, 0.0208, 0.1036, 0.0820, 0.0602, 0.0173, 0.0054, 0.0146,
        0.0279, 0.0285, 0.0760, 0.0466, 0.0470, 0.0678, 0.1856],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,808][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0203, 0.0541, 0.0555, 0.0515, 0.0418, 0.0790, 0.0822, 0.0815, 0.0894,
        0.0530, 0.0626, 0.0818, 0.0641, 0.0798, 0.0437, 0.0597],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,809][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0124, 0.0642, 0.0734, 0.0291, 0.0376, 0.0350, 0.0148, 0.0714, 0.0182,
        0.1318, 0.2820, 0.0308, 0.1424, 0.0185, 0.0144, 0.0239],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,810][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0223, 0.0669, 0.0669, 0.0559, 0.0668, 0.0779, 0.0630, 0.0571, 0.0576,
        0.0668, 0.0597, 0.0646, 0.0664, 0.0585, 0.0676, 0.0819],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:55,811][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0037, 0.0113, 0.0083, 0.0320, 0.0156, 0.0319, 0.0197, 0.0137, 0.0152,
        0.1363, 0.1178, 0.1643, 0.0862, 0.0243, 0.0405, 0.1190, 0.1601],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,814][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0110, 0.0339, 0.0401, 0.0600, 0.0577, 0.0606, 0.0729, 0.0720, 0.0837,
        0.0576, 0.0646, 0.0700, 0.0579, 0.0603, 0.0559, 0.0652, 0.0764],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,818][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0105, 0.0142, 0.0057, 0.0774, 0.0600, 0.0270, 0.0032, 0.0011, 0.0075,
        0.0080, 0.0086, 0.0530, 0.0256, 0.0083, 0.0341, 0.1950, 0.4606],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,819][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0200, 0.0155, 0.0086, 0.0392, 0.0365, 0.0357, 0.0053, 0.0075, 0.0126,
        0.0249, 0.0126, 0.0651, 0.0567, 0.0144, 0.0414, 0.3459, 0.2583],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,820][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0785, 0.0089, 0.0014, 0.0484, 0.0132, 0.0518, 0.0009, 0.0006, 0.0021,
        0.0039, 0.0053, 0.0174, 0.0084, 0.0065, 0.0066, 0.4921, 0.2539],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,821][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2347, 0.0959, 0.0217, 0.3574, 0.1295, 0.0285, 0.0070, 0.0134, 0.0182,
        0.0126, 0.0145, 0.0172, 0.0164, 0.0033, 0.0075, 0.0119, 0.0103],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,822][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1244, 0.0098, 0.0024, 0.0462, 0.0244, 0.0674, 0.0025, 0.0026, 0.0073,
        0.0053, 0.0094, 0.0289, 0.0124, 0.0185, 0.0174, 0.4146, 0.2068],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,825][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0464, 0.0060, 0.0009, 0.0071, 0.0036, 0.0257, 0.0038, 0.0011, 0.0084,
        0.0049, 0.0136, 0.0356, 0.0083, 0.0150, 0.0037, 0.6702, 0.1458],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,829][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1217, 0.0131, 0.0115, 0.0985, 0.0503, 0.0618, 0.0061, 0.0039, 0.0069,
        0.0130, 0.0125, 0.0496, 0.0303, 0.0284, 0.0334, 0.2439, 0.2151],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,830][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0160, 0.0493, 0.0532, 0.0540, 0.0353, 0.0784, 0.0758, 0.0776, 0.0745,
        0.0477, 0.0582, 0.0732, 0.0588, 0.0741, 0.0355, 0.0681, 0.0703],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,830][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0254, 0.0615, 0.0616, 0.0421, 0.0337, 0.0486, 0.0217, 0.0814, 0.0261,
        0.1125, 0.2106, 0.0434, 0.1070, 0.0254, 0.0134, 0.0346, 0.0512],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,831][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0221, 0.0575, 0.0625, 0.0531, 0.0650, 0.0684, 0.0607, 0.0568, 0.0563,
        0.0622, 0.0557, 0.0623, 0.0610, 0.0558, 0.0638, 0.0681, 0.0688],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:55,833][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.0033, 0.0032, 0.0205, 0.0456, 0.0366, 0.0222, 0.0253, 0.0086, 0.0121,
        0.0799, 0.1558, 0.1803, 0.0424, 0.0151, 0.0935, 0.0818, 0.1443, 0.0296],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,837][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0132, 0.0311, 0.0370, 0.0553, 0.0533, 0.0565, 0.0700, 0.0636, 0.0792,
        0.0519, 0.0625, 0.0676, 0.0538, 0.0569, 0.0531, 0.0605, 0.0763, 0.0582],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,839][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0043, 0.0035, 0.0013, 0.0133, 0.0135, 0.0075, 0.0015, 0.0006, 0.0028,
        0.0039, 0.0043, 0.0282, 0.0095, 0.0044, 0.0151, 0.1338, 0.4587, 0.2936],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,840][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.0042, 0.0038, 0.0024, 0.0138, 0.0123, 0.0117, 0.0032, 0.0024, 0.0067,
        0.0115, 0.0069, 0.0442, 0.0248, 0.0089, 0.0191, 0.1639, 0.2315, 0.4286],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,841][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([2.5437e-02, 2.0061e-03, 6.2720e-04, 1.9800e-02, 5.0171e-03, 1.5411e-02,
        6.5884e-04, 2.9237e-04, 1.4399e-03, 2.1438e-03, 4.1079e-03, 1.6102e-02,
        5.4465e-03, 6.8606e-03, 4.4202e-03, 3.6343e-01, 3.5459e-01, 1.7221e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,842][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.1549, 0.1579, 0.0306, 0.2426, 0.1639, 0.0220, 0.0101, 0.0349, 0.0293,
        0.0172, 0.0195, 0.0313, 0.0206, 0.0034, 0.0129, 0.0135, 0.0246, 0.0108],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,845][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0430, 0.0056, 0.0016, 0.0330, 0.0157, 0.0433, 0.0025, 0.0021, 0.0070,
        0.0043, 0.0098, 0.0399, 0.0131, 0.0206, 0.0120, 0.3451, 0.2824, 0.1192],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,847][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([3.1258e-02, 2.4573e-03, 6.0164e-04, 3.9889e-03, 3.2176e-03, 1.2122e-02,
        3.2142e-03, 9.3923e-04, 5.3069e-03, 6.8617e-03, 1.0981e-02, 3.0621e-02,
        1.0472e-02, 1.2690e-02, 5.4940e-03, 6.3000e-01, 1.2490e-01, 1.0487e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,850][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.1442, 0.0044, 0.0050, 0.0334, 0.0261, 0.0244, 0.0052, 0.0015, 0.0045,
        0.0065, 0.0097, 0.0355, 0.0119, 0.0164, 0.0306, 0.1393, 0.2989, 0.2023],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,851][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.0140, 0.0476, 0.0439, 0.0536, 0.0340, 0.0787, 0.0844, 0.0649, 0.0768,
        0.0444, 0.0447, 0.0773, 0.0460, 0.0781, 0.0362, 0.0742, 0.0806, 0.0207],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,852][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0092, 0.0123, 0.0136, 0.1728, 0.0137, 0.0807, 0.0786, 0.0096, 0.1142,
        0.0052, 0.0018, 0.0850, 0.0245, 0.0350, 0.0397, 0.1456, 0.1405, 0.0181],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,853][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.0200, 0.0526, 0.0556, 0.0472, 0.0584, 0.0606, 0.0550, 0.0558, 0.0521,
        0.0591, 0.0541, 0.0599, 0.0591, 0.0510, 0.0574, 0.0653, 0.0650, 0.0719],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:55,855][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0033, 0.0080, 0.0100, 0.0137, 0.0163, 0.0220, 0.0266, 0.0101, 0.0054,
        0.0985, 0.0546, 0.1687, 0.0751, 0.0223, 0.0588, 0.0914, 0.2373, 0.0440,
        0.0339], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,859][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0113, 0.0309, 0.0369, 0.0539, 0.0523, 0.0536, 0.0634, 0.0612, 0.0715,
        0.0490, 0.0565, 0.0609, 0.0493, 0.0546, 0.0505, 0.0580, 0.0672, 0.0554,
        0.0636], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,861][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0041, 0.0039, 0.0015, 0.0170, 0.0155, 0.0079, 0.0018, 0.0005, 0.0021,
        0.0041, 0.0039, 0.0282, 0.0105, 0.0034, 0.0103, 0.0990, 0.4083, 0.2876,
        0.0903], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,862][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0038, 0.0047, 0.0023, 0.0115, 0.0134, 0.0114, 0.0026, 0.0026, 0.0043,
        0.0099, 0.0047, 0.0298, 0.0192, 0.0071, 0.0157, 0.1562, 0.1619, 0.4404,
        0.0985], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,863][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([2.4306e-02, 3.0765e-03, 5.3823e-04, 1.9691e-02, 6.3024e-03, 2.0232e-02,
        6.3417e-04, 2.9506e-04, 9.9185e-04, 2.5519e-03, 2.5944e-03, 1.1423e-02,
        5.6954e-03, 4.0216e-03, 3.5396e-03, 3.7937e-01, 2.4676e-01, 1.5661e-01,
        1.1136e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,864][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1542, 0.1527, 0.0228, 0.3429, 0.1254, 0.0347, 0.0118, 0.0164, 0.0166,
        0.0172, 0.0149, 0.0239, 0.0189, 0.0030, 0.0056, 0.0113, 0.0155, 0.0073,
        0.0051], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,866][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0573, 0.0044, 0.0016, 0.0269, 0.0116, 0.0454, 0.0028, 0.0021, 0.0036,
        0.0040, 0.0050, 0.0267, 0.0086, 0.0140, 0.0088, 0.3135, 0.2250, 0.1204,
        0.1183], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,870][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0191, 0.0033, 0.0008, 0.0061, 0.0028, 0.0155, 0.0031, 0.0008, 0.0057,
        0.0037, 0.0073, 0.0253, 0.0059, 0.0116, 0.0028, 0.5760, 0.1241, 0.1385,
        0.0475], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,872][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0484, 0.0063, 0.0060, 0.0415, 0.0330, 0.0318, 0.0045, 0.0014, 0.0023,
        0.0060, 0.0061, 0.0280, 0.0124, 0.0144, 0.0185, 0.1617, 0.2396, 0.2723,
        0.0658], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,873][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0129, 0.0437, 0.0446, 0.0490, 0.0323, 0.0693, 0.0730, 0.0673, 0.0716,
        0.0402, 0.0504, 0.0693, 0.0496, 0.0701, 0.0337, 0.0620, 0.0681, 0.0337,
        0.0591], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,874][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0170, 0.0534, 0.0419, 0.0470, 0.0287, 0.0527, 0.0276, 0.0558, 0.0284,
        0.0750, 0.0970, 0.0489, 0.0604, 0.0286, 0.0141, 0.0454, 0.0662, 0.1501,
        0.0618], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,875][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0186, 0.0509, 0.0537, 0.0461, 0.0537, 0.0601, 0.0522, 0.0481, 0.0502,
        0.0539, 0.0513, 0.0557, 0.0559, 0.0491, 0.0537, 0.0616, 0.0595, 0.0643,
        0.0612], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:55,932][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:55,933][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,934][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,935][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,935][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,936][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,937][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,937][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,938][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,939][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,939][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,940][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,941][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:55,941][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9503, 0.0497], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,942][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.7724, 0.2276], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,945][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1371, 0.8629], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,946][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3110, 0.6890], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,947][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3644, 0.6356], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,947][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.8144, 0.1856], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,948][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.4768, 0.5232], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,949][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3357, 0.6643], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,951][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.6487, 0.3513], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,956][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9793, 0.0207], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,957][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9852, 0.0148], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,957][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9582, 0.0418], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:55,958][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Jamie] are: tensor([0.9310, 0.0353, 0.0337], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,959][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Jamie] are: tensor([0.9373, 0.0244, 0.0383], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,959][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Jamie] are: tensor([0.0694, 0.6524, 0.2782], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,962][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Jamie] are: tensor([0.1657, 0.4510, 0.3833], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,965][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Jamie] are: tensor([0.1878, 0.6108, 0.2014], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,967][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Jamie] are: tensor([0.8595, 0.0790, 0.0615], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,968][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Jamie] are: tensor([0.4445, 0.4838, 0.0717], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,969][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Jamie] are: tensor([0.3734, 0.4984, 0.1282], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,970][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Jamie] are: tensor([0.7139, 0.1756, 0.1104], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,970][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Jamie] are: tensor([0.9395, 0.0272, 0.0333], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,971][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Jamie] are: tensor([0.9306, 0.0404, 0.0290], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,975][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Jamie] are: tensor([0.9459, 0.0412, 0.0130], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:55,978][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9625, 0.0091, 0.0225, 0.0059], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,979][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.7838, 0.0398, 0.1454, 0.0309], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,979][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1375, 0.4012, 0.2536, 0.2077], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,980][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3786, 0.3087, 0.1908, 0.1219], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,981][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.6089, 0.1748, 0.0562, 0.1600], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,982][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.6670, 0.1418, 0.1061, 0.0851], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,985][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6555, 0.1042, 0.0640, 0.1763], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,991][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.6663, 0.2285, 0.0325, 0.0726], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,992][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.6285, 0.1113, 0.1103, 0.1499], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,993][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9596, 0.0162, 0.0154, 0.0088], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,994][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9589, 0.0199, 0.0073, 0.0139], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,994][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.9385, 0.0222, 0.0067, 0.0326], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:55,995][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.9138, 0.0250, 0.0230, 0.0167, 0.0215], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:55,998][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.8891, 0.0095, 0.0251, 0.0201, 0.0563], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,002][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.0273, 0.2196, 0.0707, 0.3944, 0.2880], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,003][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.0716, 0.1640, 0.1659, 0.2621, 0.3364], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,004][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0884, 0.1657, 0.0562, 0.5760, 0.1136], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,004][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.7773, 0.0540, 0.0596, 0.0612, 0.0479], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,005][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.1643, 0.2087, 0.0675, 0.4218, 0.1378], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,006][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.2675, 0.2606, 0.0516, 0.3111, 0.1092], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,009][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.3854, 0.0969, 0.0550, 0.3311, 0.1316], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,013][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.8939, 0.0349, 0.0484, 0.0152, 0.0077], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,014][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.8601, 0.0386, 0.0127, 0.0316, 0.0570], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,015][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.8072, 0.0633, 0.0203, 0.0472, 0.0620], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,015][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.8548, 0.0303, 0.0432, 0.0290, 0.0273, 0.0154], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,016][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.5553, 0.0307, 0.1061, 0.0374, 0.2056, 0.0647], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,017][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0600, 0.1753, 0.1105, 0.1396, 0.3338, 0.1808], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,019][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1461, 0.1509, 0.1035, 0.1337, 0.2461, 0.2197], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,024][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.3393, 0.0875, 0.0319, 0.1580, 0.0922, 0.2911], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,025][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.5009, 0.1200, 0.0702, 0.1375, 0.0991, 0.0724], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,026][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.3544, 0.0641, 0.0347, 0.1412, 0.1244, 0.2811], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,026][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.5896, 0.1475, 0.0184, 0.0828, 0.0518, 0.1100], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,027][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.5480, 0.0412, 0.0433, 0.1043, 0.1335, 0.1297], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,028][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.8754, 0.0321, 0.0220, 0.0154, 0.0347, 0.0203], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,030][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.8291, 0.0464, 0.0223, 0.0320, 0.0218, 0.0485], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,035][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.7731, 0.0475, 0.0097, 0.0554, 0.0221, 0.0922], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,036][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.8356, 0.0214, 0.0375, 0.0276, 0.0344, 0.0284, 0.0151],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,037][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.5336, 0.0201, 0.0982, 0.0326, 0.1736, 0.0741, 0.0678],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,038][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0010, 0.0529, 0.0280, 0.4110, 0.2858, 0.1999, 0.0214],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,038][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0053, 0.0766, 0.0570, 0.2817, 0.2679, 0.2650, 0.0465],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,039][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0042, 0.0384, 0.0129, 0.3991, 0.0960, 0.4398, 0.0095],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,043][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.4626, 0.0845, 0.0932, 0.1078, 0.1013, 0.1118, 0.0389],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,047][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0151, 0.0512, 0.0177, 0.3323, 0.1445, 0.4211, 0.0181],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,047][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0293, 0.1708, 0.0228, 0.3221, 0.1069, 0.3055, 0.0426],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,048][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0372, 0.0368, 0.0423, 0.3597, 0.1860, 0.3040, 0.0340],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,049][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.8069, 0.0523, 0.0287, 0.0236, 0.0424, 0.0330, 0.0131],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,050][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.8218, 0.0557, 0.0156, 0.0314, 0.0208, 0.0461, 0.0086],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,052][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.5085, 0.0779, 0.0257, 0.1312, 0.0647, 0.1035, 0.0885],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,056][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.8771, 0.0091, 0.0267, 0.0146, 0.0342, 0.0203, 0.0120, 0.0059],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,058][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.3853, 0.0098, 0.0925, 0.0399, 0.1560, 0.0873, 0.0985, 0.1307],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,058][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0007, 0.0412, 0.0361, 0.3515, 0.3199, 0.1961, 0.0434, 0.0110],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,059][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0029, 0.0534, 0.0617, 0.2638, 0.2482, 0.2531, 0.0613, 0.0557],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,060][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0018, 0.0300, 0.0087, 0.4180, 0.0752, 0.4414, 0.0166, 0.0084],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,061][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.5119, 0.0516, 0.0912, 0.0719, 0.1076, 0.0834, 0.0533, 0.0291],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,063][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0145, 0.0450, 0.0168, 0.3391, 0.1182, 0.4008, 0.0444, 0.0212],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,068][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0116, 0.1367, 0.0341, 0.3013, 0.1961, 0.2504, 0.0534, 0.0164],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,069][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0264, 0.0235, 0.0374, 0.3769, 0.1689, 0.2973, 0.0541, 0.0155],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,070][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.8283, 0.0337, 0.0311, 0.0202, 0.0362, 0.0303, 0.0119, 0.0084],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,070][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.7881, 0.0556, 0.0192, 0.0348, 0.0330, 0.0481, 0.0120, 0.0092],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,071][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.5545, 0.0604, 0.0266, 0.0888, 0.0664, 0.0822, 0.0750, 0.0462],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,072][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.6250, 0.0543, 0.0902, 0.0558, 0.0564, 0.0591, 0.0334, 0.0154, 0.0103],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,076][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.2030, 0.0078, 0.1730, 0.0287, 0.2227, 0.0677, 0.1028, 0.1258, 0.0685],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,080][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0022, 0.0407, 0.0271, 0.4022, 0.3084, 0.1566, 0.0261, 0.0091, 0.0275],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,080][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0054, 0.0553, 0.0465, 0.2596, 0.2745, 0.2020, 0.0414, 0.0485, 0.0667],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,081][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0084, 0.0220, 0.0103, 0.4467, 0.0966, 0.3810, 0.0113, 0.0060, 0.0178],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,082][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.2356, 0.0772, 0.1195, 0.1408, 0.1163, 0.1682, 0.0642, 0.0405, 0.0378],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,083][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0322, 0.0610, 0.0145, 0.3114, 0.1648, 0.3265, 0.0255, 0.0356, 0.0285],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,085][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0352, 0.1242, 0.0250, 0.3594, 0.1364, 0.2056, 0.0406, 0.0185, 0.0550],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,090][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0294, 0.0184, 0.0366, 0.3491, 0.2070, 0.2922, 0.0381, 0.0104, 0.0186],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,091][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.7414, 0.0405, 0.0425, 0.0309, 0.0559, 0.0422, 0.0171, 0.0182, 0.0113],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,092][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.7973, 0.0481, 0.0204, 0.0386, 0.0223, 0.0474, 0.0096, 0.0079, 0.0083],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,093][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.5726, 0.0663, 0.0201, 0.0877, 0.0407, 0.0839, 0.0576, 0.0183, 0.0529],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,093][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.8569, 0.0121, 0.0318, 0.0156, 0.0436, 0.0111, 0.0094, 0.0045, 0.0045,
        0.0106], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,094][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.4143, 0.0081, 0.0659, 0.0205, 0.1894, 0.0479, 0.0569, 0.0463, 0.0426,
        0.1082], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,098][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0014, 0.0462, 0.0205, 0.2890, 0.2565, 0.1926, 0.0328, 0.0116, 0.0584,
        0.0909], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,101][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0037, 0.0429, 0.0378, 0.1906, 0.1588, 0.1684, 0.0467, 0.0439, 0.1036,
        0.2035], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,102][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0078, 0.0315, 0.0116, 0.3241, 0.1039, 0.4160, 0.0169, 0.0089, 0.0274,
        0.0519], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,103][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.3514, 0.0577, 0.0973, 0.0916, 0.1256, 0.1107, 0.0422, 0.0217, 0.0315,
        0.0702], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,104][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0139, 0.0327, 0.0072, 0.2706, 0.1032, 0.4299, 0.0233, 0.0202, 0.0656,
        0.0335], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,104][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0184, 0.1224, 0.0159, 0.3245, 0.0997, 0.1972, 0.0426, 0.0162, 0.0599,
        0.1032], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,107][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0348, 0.0253, 0.0393, 0.2746, 0.2462, 0.2239, 0.0443, 0.0102, 0.0406,
        0.0608], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,112][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.7774, 0.0531, 0.0259, 0.0210, 0.0429, 0.0293, 0.0137, 0.0158, 0.0108,
        0.0101], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,113][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.6168, 0.1536, 0.0163, 0.0485, 0.0242, 0.0820, 0.0125, 0.0067, 0.0096,
        0.0296], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,113][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.5519, 0.0947, 0.0185, 0.0724, 0.0701, 0.0586, 0.0455, 0.0196, 0.0222,
        0.0464], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,114][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.7921, 0.0240, 0.0363, 0.0214, 0.0515, 0.0199, 0.0138, 0.0081, 0.0051,
        0.0160, 0.0118], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,115][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.2343, 0.0076, 0.1008, 0.0195, 0.2138, 0.0383, 0.0522, 0.0573, 0.0371,
        0.1896, 0.0494], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,116][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0029, 0.0539, 0.0271, 0.3006, 0.2510, 0.1466, 0.0272, 0.0086, 0.0493,
        0.0803, 0.0525], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,119][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0058, 0.0527, 0.0364, 0.1632, 0.1633, 0.1398, 0.0425, 0.0461, 0.0745,
        0.2012, 0.0746], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,123][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0120, 0.0317, 0.0104, 0.3255, 0.0983, 0.3639, 0.0127, 0.0063, 0.0241,
        0.0606, 0.0546], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,124][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.2741, 0.0679, 0.0893, 0.1314, 0.1188, 0.0943, 0.0389, 0.0318, 0.0317,
        0.0861, 0.0356], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,125][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0813, 0.0298, 0.0084, 0.1946, 0.0982, 0.3883, 0.0230, 0.0176, 0.0535,
        0.0555, 0.0499], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,125][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0434, 0.1051, 0.0182, 0.2039, 0.1435, 0.2100, 0.0451, 0.0107, 0.0544,
        0.0843, 0.0815], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,126][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0340, 0.0281, 0.0366, 0.3303, 0.2083, 0.2046, 0.0321, 0.0110, 0.0266,
        0.0505, 0.0379], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,129][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.7639, 0.0500, 0.0303, 0.0202, 0.0456, 0.0289, 0.0117, 0.0128, 0.0069,
        0.0180, 0.0116], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,133][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.7847, 0.0696, 0.0095, 0.0249, 0.0119, 0.0486, 0.0069, 0.0043, 0.0055,
        0.0198, 0.0144], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,134][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.5256, 0.0633, 0.0213, 0.0819, 0.0420, 0.0811, 0.0428, 0.0111, 0.0279,
        0.0336, 0.0694], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,135][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.8066, 0.0216, 0.0290, 0.0202, 0.0398, 0.0234, 0.0109, 0.0056, 0.0063,
        0.0136, 0.0125, 0.0105], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,136][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.3339, 0.0177, 0.1280, 0.0166, 0.1598, 0.0334, 0.0391, 0.0676, 0.0362,
        0.1065, 0.0336, 0.0278], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,137][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0114, 0.0503, 0.0235, 0.2373, 0.2323, 0.0996, 0.0213, 0.0078, 0.0336,
        0.0491, 0.0427, 0.1912], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,139][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0197, 0.0499, 0.0304, 0.1208, 0.1384, 0.1156, 0.0274, 0.0326, 0.0486,
        0.1194, 0.0543, 0.2429], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,143][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0619, 0.0364, 0.0086, 0.3146, 0.0827, 0.2842, 0.0092, 0.0045, 0.0166,
        0.0368, 0.0428, 0.1017], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,145][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.4225, 0.0796, 0.0704, 0.0815, 0.0665, 0.0714, 0.0273, 0.0278, 0.0371,
        0.0556, 0.0314, 0.0290], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,146][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1568, 0.0343, 0.0138, 0.1955, 0.0912, 0.2679, 0.0133, 0.0124, 0.0334,
        0.0310, 0.0485, 0.1017], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,147][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0977, 0.1368, 0.0147, 0.1894, 0.0589, 0.1590, 0.0296, 0.0095, 0.0427,
        0.0403, 0.0725, 0.1488], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,147][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0877, 0.0428, 0.0389, 0.2786, 0.1661, 0.1802, 0.0247, 0.0082, 0.0229,
        0.0359, 0.0323, 0.0816], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,148][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.8480, 0.0276, 0.0165, 0.0123, 0.0302, 0.0174, 0.0067, 0.0076, 0.0045,
        0.0114, 0.0075, 0.0103], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,152][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.8807, 0.0281, 0.0050, 0.0141, 0.0077, 0.0237, 0.0047, 0.0035, 0.0035,
        0.0109, 0.0077, 0.0103], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,156][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.6004, 0.0449, 0.0169, 0.0708, 0.0311, 0.0606, 0.0364, 0.0102, 0.0187,
        0.0225, 0.0291, 0.0585], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,157][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.8261, 0.0130, 0.0418, 0.0118, 0.0424, 0.0096, 0.0100, 0.0039, 0.0050,
        0.0090, 0.0095, 0.0100, 0.0079], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,157][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.4100, 0.0030, 0.0568, 0.0066, 0.0638, 0.0231, 0.0400, 0.0407, 0.0470,
        0.0631, 0.0626, 0.0488, 0.1346], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,158][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.0139, 0.0314, 0.0149, 0.1581, 0.1466, 0.1116, 0.0166, 0.0077, 0.0268,
        0.0530, 0.0493, 0.2881, 0.0820], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,159][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.0056, 0.0245, 0.0254, 0.1256, 0.1198, 0.0938, 0.0206, 0.0192, 0.0501,
        0.1044, 0.0450, 0.2233, 0.1427], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,163][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0247, 0.0148, 0.0073, 0.2412, 0.0656, 0.2151, 0.0106, 0.0044, 0.0243,
        0.0484, 0.0702, 0.1871, 0.0862], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,166][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.5880, 0.0214, 0.0782, 0.0232, 0.0288, 0.0387, 0.0181, 0.0136, 0.0230,
        0.0451, 0.0372, 0.0393, 0.0454], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,167][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.0273, 0.0284, 0.0135, 0.1833, 0.0684, 0.2247, 0.0160, 0.0125, 0.0420,
        0.0434, 0.0578, 0.1927, 0.0899], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,168][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0629, 0.0955, 0.0250, 0.2138, 0.0849, 0.0969, 0.0220, 0.0094, 0.0294,
        0.0474, 0.0720, 0.1775, 0.0634], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,169][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.0925, 0.0189, 0.0371, 0.1621, 0.1297, 0.1515, 0.0240, 0.0071, 0.0277,
        0.0464, 0.0502, 0.1867, 0.0660], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,170][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.8136, 0.0325, 0.0263, 0.0129, 0.0201, 0.0224, 0.0087, 0.0102, 0.0065,
        0.0139, 0.0096, 0.0157, 0.0077], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,173][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.8120, 0.0333, 0.0089, 0.0182, 0.0189, 0.0328, 0.0073, 0.0072, 0.0049,
        0.0153, 0.0150, 0.0193, 0.0069], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,177][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.6431, 0.0609, 0.0109, 0.0552, 0.0297, 0.0375, 0.0288, 0.0112, 0.0185,
        0.0184, 0.0243, 0.0385, 0.0231], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,178][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.7323, 0.0303, 0.0617, 0.0209, 0.0532, 0.0177, 0.0139, 0.0064, 0.0054,
        0.0123, 0.0120, 0.0117, 0.0140, 0.0083], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,179][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.1339, 0.0106, 0.1094, 0.0145, 0.2100, 0.0300, 0.0349, 0.0403, 0.0194,
        0.0829, 0.0298, 0.0358, 0.1797, 0.0688], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,180][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0029, 0.0444, 0.0173, 0.2539, 0.1787, 0.1035, 0.0131, 0.0035, 0.0206,
        0.0386, 0.0313, 0.1888, 0.0822, 0.0212], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,181][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0047, 0.0413, 0.0219, 0.1170, 0.1229, 0.1010, 0.0172, 0.0211, 0.0340,
        0.0965, 0.0369, 0.1874, 0.1622, 0.0359], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,184][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0138, 0.0404, 0.0068, 0.3250, 0.0787, 0.2698, 0.0076, 0.0030, 0.0114,
        0.0315, 0.0308, 0.0971, 0.0531, 0.0309], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,188][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.2189, 0.0670, 0.0689, 0.1098, 0.0861, 0.0899, 0.0268, 0.0185, 0.0257,
        0.0479, 0.0286, 0.0426, 0.1199, 0.0495], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,189][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0348, 0.0226, 0.0064, 0.2477, 0.0560, 0.2661, 0.0194, 0.0081, 0.0312,
        0.0205, 0.0322, 0.1376, 0.0475, 0.0700], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,190][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0428, 0.1557, 0.0137, 0.2575, 0.0529, 0.1290, 0.0194, 0.0069, 0.0299,
        0.0257, 0.0567, 0.1205, 0.0344, 0.0549], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,191][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0308, 0.0388, 0.0321, 0.2694, 0.1576, 0.1721, 0.0204, 0.0051, 0.0117,
        0.0318, 0.0243, 0.0965, 0.0704, 0.0390], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,192][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.6956, 0.0466, 0.0318, 0.0222, 0.0530, 0.0341, 0.0113, 0.0123, 0.0077,
        0.0201, 0.0115, 0.0204, 0.0201, 0.0134], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,195][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.7190, 0.0620, 0.0162, 0.0291, 0.0117, 0.0664, 0.0082, 0.0067, 0.0052,
        0.0253, 0.0159, 0.0194, 0.0057, 0.0093], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,199][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.4481, 0.0772, 0.0223, 0.0722, 0.0420, 0.0681, 0.0378, 0.0104, 0.0245,
        0.0230, 0.0443, 0.0526, 0.0245, 0.0530], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,200][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.6608, 0.0449, 0.0352, 0.0301, 0.0423, 0.0278, 0.0166, 0.0084, 0.0118,
        0.0194, 0.0187, 0.0137, 0.0191, 0.0113, 0.0398], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,201][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.1458, 0.0082, 0.0288, 0.0196, 0.0469, 0.0400, 0.0397, 0.0370, 0.0560,
        0.0778, 0.0729, 0.0472, 0.1831, 0.0928, 0.1042], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,202][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.0025, 0.0190, 0.0076, 0.1017, 0.0691, 0.0649, 0.0186, 0.0082, 0.0349,
        0.0684, 0.0692, 0.2273, 0.1398, 0.0498, 0.1190], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,203][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.0033, 0.0177, 0.0170, 0.0470, 0.0562, 0.0515, 0.0227, 0.0241, 0.0435,
        0.0953, 0.0574, 0.2167, 0.1674, 0.0641, 0.1160], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,206][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0062, 0.0127, 0.0042, 0.1185, 0.0241, 0.1273, 0.0138, 0.0083, 0.0305,
        0.0666, 0.0827, 0.2175, 0.1496, 0.0953, 0.0426], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,210][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.1927, 0.0472, 0.0398, 0.0581, 0.0254, 0.1040, 0.0396, 0.0159, 0.0418,
        0.0891, 0.0536, 0.0525, 0.1364, 0.0620, 0.0420], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,211][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0192, 0.0274, 0.0085, 0.0980, 0.0377, 0.0855, 0.0197, 0.0158, 0.0363,
        0.0539, 0.0456, 0.2085, 0.1124, 0.1764, 0.0552], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,212][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0199, 0.0498, 0.0107, 0.1277, 0.0275, 0.0821, 0.0291, 0.0180, 0.0485,
        0.0911, 0.0943, 0.1280, 0.1228, 0.1004, 0.0500], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,213][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.0231, 0.0206, 0.0119, 0.1159, 0.0398, 0.1518, 0.0329, 0.0104, 0.0444,
        0.0699, 0.0622, 0.1552, 0.1287, 0.0801, 0.0531], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,213][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.5862, 0.0623, 0.0614, 0.0231, 0.0158, 0.0475, 0.0165, 0.0189, 0.0161,
        0.0250, 0.0234, 0.0378, 0.0209, 0.0217, 0.0234], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,217][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.5299, 0.0672, 0.0162, 0.0424, 0.0489, 0.0757, 0.0141, 0.0156, 0.0126,
        0.0344, 0.0213, 0.0246, 0.0207, 0.0133, 0.0630], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,221][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.3440, 0.0739, 0.0210, 0.0544, 0.0664, 0.0446, 0.0397, 0.0107, 0.0186,
        0.0270, 0.0323, 0.0528, 0.0513, 0.0434, 0.1198], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,222][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.5761, 0.0244, 0.0475, 0.0286, 0.0450, 0.0219, 0.0294, 0.0108, 0.0125,
        0.0383, 0.0282, 0.0258, 0.0242, 0.0216, 0.0356, 0.0302],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,223][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.1280, 0.0057, 0.0460, 0.0110, 0.0734, 0.0229, 0.0479, 0.0482, 0.0374,
        0.0980, 0.0481, 0.0390, 0.1331, 0.0910, 0.1216, 0.0487],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,224][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0245, 0.0282, 0.0131, 0.1057, 0.0996, 0.0401, 0.0106, 0.0038, 0.0183,
        0.0228, 0.0241, 0.1147, 0.0525, 0.0228, 0.0838, 0.3353],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,224][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0223, 0.0281, 0.0118, 0.0564, 0.0568, 0.0534, 0.0134, 0.0131, 0.0193,
        0.0430, 0.0223, 0.1463, 0.0695, 0.0249, 0.0675, 0.3521],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,228][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1410, 0.0178, 0.0041, 0.1038, 0.0283, 0.0667, 0.0026, 0.0013, 0.0055,
        0.0073, 0.0132, 0.0418, 0.0197, 0.0173, 0.0179, 0.5118],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,232][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.3921, 0.0410, 0.0378, 0.0418, 0.0432, 0.0457, 0.0262, 0.0165, 0.0253,
        0.0432, 0.0378, 0.0333, 0.0713, 0.0458, 0.0570, 0.0421],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,233][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.1059, 0.0148, 0.0052, 0.1015, 0.0286, 0.1205, 0.0067, 0.0042, 0.0139,
        0.0092, 0.0189, 0.0695, 0.0235, 0.0381, 0.0235, 0.4161],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,233][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.1470, 0.0747, 0.0059, 0.0914, 0.0275, 0.0693, 0.0101, 0.0054, 0.0181,
        0.0244, 0.0292, 0.0640, 0.0252, 0.0331, 0.0168, 0.3577],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,234][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1946, 0.0219, 0.0208, 0.1036, 0.0820, 0.0602, 0.0173, 0.0054, 0.0146,
        0.0279, 0.0285, 0.0760, 0.0466, 0.0470, 0.0678, 0.1856],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,235][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.7388, 0.0356, 0.0206, 0.0152, 0.0338, 0.0161, 0.0079, 0.0085, 0.0059,
        0.0110, 0.0111, 0.0163, 0.0157, 0.0108, 0.0343, 0.0183],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,239][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.7377, 0.0478, 0.0071, 0.0240, 0.0109, 0.0397, 0.0079, 0.0051, 0.0064,
        0.0161, 0.0147, 0.0170, 0.0053, 0.0086, 0.0194, 0.0321],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,243][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.4510, 0.0569, 0.0169, 0.0499, 0.0324, 0.0471, 0.0274, 0.0089, 0.0129,
        0.0191, 0.0240, 0.0341, 0.0304, 0.0344, 0.0621, 0.0925],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,243][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.7743, 0.0130, 0.0201, 0.0144, 0.0297, 0.0161, 0.0100, 0.0063, 0.0057,
        0.0129, 0.0122, 0.0103, 0.0108, 0.0097, 0.0217, 0.0194, 0.0134],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,244][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1367, 0.0058, 0.0547, 0.0126, 0.0934, 0.0235, 0.0226, 0.0789, 0.0240,
        0.0937, 0.0241, 0.0218, 0.1305, 0.0621, 0.1289, 0.0661, 0.0204],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,245][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0105, 0.0142, 0.0057, 0.0774, 0.0600, 0.0270, 0.0032, 0.0011, 0.0075,
        0.0080, 0.0086, 0.0530, 0.0256, 0.0083, 0.0341, 0.1950, 0.4606],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,246][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0200, 0.0155, 0.0086, 0.0392, 0.0365, 0.0357, 0.0053, 0.0075, 0.0126,
        0.0249, 0.0126, 0.0651, 0.0567, 0.0144, 0.0414, 0.3459, 0.2583],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,250][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0785, 0.0089, 0.0014, 0.0484, 0.0132, 0.0518, 0.0009, 0.0006, 0.0021,
        0.0039, 0.0053, 0.0174, 0.0084, 0.0065, 0.0066, 0.4921, 0.2539],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,253][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2583, 0.0363, 0.0402, 0.0656, 0.0430, 0.0502, 0.0173, 0.0227, 0.0201,
        0.0546, 0.0257, 0.0324, 0.0769, 0.0637, 0.0581, 0.1078, 0.0270],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,254][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1244, 0.0098, 0.0024, 0.0462, 0.0244, 0.0674, 0.0025, 0.0026, 0.0073,
        0.0053, 0.0094, 0.0289, 0.0124, 0.0185, 0.0174, 0.4146, 0.2068],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,255][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0902, 0.0346, 0.0033, 0.0511, 0.0134, 0.0479, 0.0057, 0.0020, 0.0093,
        0.0081, 0.0193, 0.0433, 0.0154, 0.0223, 0.0091, 0.3526, 0.2723],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,256][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1217, 0.0131, 0.0115, 0.0985, 0.0503, 0.0618, 0.0061, 0.0039, 0.0069,
        0.0130, 0.0125, 0.0496, 0.0303, 0.0284, 0.0334, 0.2439, 0.2151],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,257][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.7566, 0.0321, 0.0144, 0.0129, 0.0280, 0.0174, 0.0067, 0.0069, 0.0047,
        0.0130, 0.0087, 0.0120, 0.0114, 0.0085, 0.0284, 0.0216, 0.0166],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,261][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.8488, 0.0270, 0.0032, 0.0109, 0.0055, 0.0213, 0.0042, 0.0030, 0.0032,
        0.0092, 0.0071, 0.0091, 0.0022, 0.0040, 0.0068, 0.0167, 0.0178],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,264][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.5309, 0.0300, 0.0132, 0.0423, 0.0290, 0.0426, 0.0270, 0.0067, 0.0111,
        0.0153, 0.0188, 0.0293, 0.0131, 0.0251, 0.0496, 0.0443, 0.0718],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,265][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.8173, 0.0073, 0.0238, 0.0076, 0.0396, 0.0056, 0.0064, 0.0031, 0.0030,
        0.0063, 0.0079, 0.0065, 0.0060, 0.0048, 0.0326, 0.0090, 0.0084, 0.0047],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,266][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.4575, 0.0023, 0.0244, 0.0056, 0.0465, 0.0129, 0.0235, 0.0229, 0.0196,
        0.0397, 0.0272, 0.0202, 0.0505, 0.0365, 0.1084, 0.0382, 0.0303, 0.0338],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,267][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.0043, 0.0035, 0.0013, 0.0133, 0.0135, 0.0075, 0.0015, 0.0006, 0.0028,
        0.0039, 0.0043, 0.0282, 0.0095, 0.0044, 0.0151, 0.1338, 0.4587, 0.2936],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,269][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.0042, 0.0038, 0.0024, 0.0138, 0.0123, 0.0117, 0.0032, 0.0024, 0.0067,
        0.0115, 0.0069, 0.0442, 0.0248, 0.0089, 0.0191, 0.1639, 0.2315, 0.4286],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,272][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([2.5437e-02, 2.0061e-03, 6.2720e-04, 1.9800e-02, 5.0171e-03, 1.5411e-02,
        6.5884e-04, 2.9237e-04, 1.4399e-03, 2.1438e-03, 4.1079e-03, 1.6102e-02,
        5.4465e-03, 6.8606e-03, 4.4202e-03, 3.6343e-01, 3.5459e-01, 1.7221e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,275][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.5207, 0.0131, 0.0193, 0.0188, 0.0243, 0.0289, 0.0161, 0.0121, 0.0203,
        0.0356, 0.0255, 0.0239, 0.0332, 0.0236, 0.0549, 0.0536, 0.0232, 0.0530],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,276][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.0430, 0.0056, 0.0016, 0.0330, 0.0157, 0.0433, 0.0025, 0.0021, 0.0070,
        0.0043, 0.0098, 0.0399, 0.0131, 0.0206, 0.0120, 0.3451, 0.2824, 0.1192],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,277][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0728, 0.0122, 0.0016, 0.0237, 0.0110, 0.0192, 0.0041, 0.0014, 0.0055,
        0.0097, 0.0148, 0.0347, 0.0164, 0.0181, 0.0115, 0.3256, 0.2271, 0.1907],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,278][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.1442, 0.0044, 0.0050, 0.0334, 0.0261, 0.0244, 0.0052, 0.0015, 0.0045,
        0.0065, 0.0097, 0.0355, 0.0119, 0.0164, 0.0306, 0.1393, 0.2989, 0.2023],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,280][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.7369, 0.0262, 0.0211, 0.0123, 0.0254, 0.0199, 0.0083, 0.0070, 0.0064,
        0.0101, 0.0073, 0.0151, 0.0104, 0.0085, 0.0327, 0.0265, 0.0172, 0.0089],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,284][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.7729, 0.0258, 0.0057, 0.0169, 0.0127, 0.0230, 0.0045, 0.0054, 0.0036,
        0.0141, 0.0109, 0.0124, 0.0049, 0.0068, 0.0230, 0.0210, 0.0168, 0.0197],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,286][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.6473, 0.0228, 0.0092, 0.0271, 0.0244, 0.0191, 0.0139, 0.0083, 0.0073,
        0.0124, 0.0161, 0.0230, 0.0129, 0.0162, 0.0379, 0.0455, 0.0414, 0.0153],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,287][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.7171, 0.0152, 0.0275, 0.0111, 0.0332, 0.0142, 0.0125, 0.0075, 0.0036,
        0.0128, 0.0097, 0.0148, 0.0123, 0.0117, 0.0259, 0.0229, 0.0240, 0.0119,
        0.0121], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,288][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1218, 0.0056, 0.0851, 0.0082, 0.1270, 0.0264, 0.0236, 0.0361, 0.0100,
        0.0511, 0.0192, 0.0208, 0.0680, 0.0514, 0.1245, 0.0785, 0.0272, 0.1011,
        0.0145], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,289][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0041, 0.0039, 0.0015, 0.0170, 0.0155, 0.0079, 0.0018, 0.0005, 0.0021,
        0.0041, 0.0039, 0.0282, 0.0105, 0.0034, 0.0103, 0.0990, 0.4083, 0.2876,
        0.0903], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,291][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0038, 0.0047, 0.0023, 0.0115, 0.0134, 0.0114, 0.0026, 0.0026, 0.0043,
        0.0099, 0.0047, 0.0298, 0.0192, 0.0071, 0.0157, 0.1562, 0.1619, 0.4404,
        0.0985], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,293][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([2.4306e-02, 3.0765e-03, 5.3823e-04, 1.9691e-02, 6.3024e-03, 2.0232e-02,
        6.3417e-04, 2.9506e-04, 9.9185e-04, 2.5519e-03, 2.5944e-03, 1.1423e-02,
        5.6954e-03, 4.0216e-03, 3.5396e-03, 3.7937e-01, 2.4676e-01, 1.5661e-01,
        1.1136e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,297][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2189, 0.0440, 0.0443, 0.0526, 0.0436, 0.0626, 0.0196, 0.0158, 0.0097,
        0.0327, 0.0197, 0.0320, 0.0618, 0.0454, 0.0378, 0.0744, 0.0372, 0.1234,
        0.0244], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,298][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0573, 0.0044, 0.0016, 0.0269, 0.0116, 0.0454, 0.0028, 0.0021, 0.0036,
        0.0040, 0.0050, 0.0267, 0.0086, 0.0140, 0.0088, 0.3135, 0.2250, 0.1204,
        0.1183], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,299][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0467, 0.0196, 0.0025, 0.0386, 0.0087, 0.0240, 0.0036, 0.0013, 0.0053,
        0.0050, 0.0088, 0.0252, 0.0088, 0.0144, 0.0056, 0.2425, 0.1971, 0.2476,
        0.0947], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,299][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0484, 0.0063, 0.0060, 0.0415, 0.0330, 0.0318, 0.0045, 0.0014, 0.0023,
        0.0060, 0.0061, 0.0280, 0.0124, 0.0144, 0.0185, 0.1617, 0.2396, 0.2723,
        0.0658], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,302][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.7396, 0.0280, 0.0161, 0.0111, 0.0286, 0.0172, 0.0061, 0.0063, 0.0040,
        0.0102, 0.0074, 0.0118, 0.0100, 0.0071, 0.0263, 0.0230, 0.0166, 0.0179,
        0.0129], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,307][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.8184, 0.0346, 0.0037, 0.0123, 0.0039, 0.0225, 0.0042, 0.0026, 0.0032,
        0.0078, 0.0074, 0.0089, 0.0020, 0.0043, 0.0053, 0.0206, 0.0178, 0.0051,
        0.0153], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,310][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.4969, 0.0413, 0.0117, 0.0374, 0.0192, 0.0362, 0.0194, 0.0057, 0.0117,
        0.0105, 0.0188, 0.0239, 0.0180, 0.0230, 0.0359, 0.0536, 0.0480, 0.0133,
        0.0755], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,314][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:56,316][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 9610],
        [13721],
        [22082],
        [25093],
        [21999],
        [30913],
        [21758],
        [23472],
        [22231],
        [11830],
        [19837],
        [18819],
        [27474],
        [10207],
        [13824],
        [18990],
        [11573],
        [25626],
        [13300]], device='cuda:0')
[2024-07-24 10:17:56,319][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 9512],
        [ 7870],
        [ 9041],
        [13427],
        [11911],
        [18481],
        [11658],
        [12707],
        [10942],
        [ 4929],
        [10066],
        [ 9117],
        [14343],
        [ 3819],
        [ 7026],
        [ 8629],
        [ 4649],
        [14330],
        [ 4941]], device='cuda:0')
[2024-07-24 10:17:56,322][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[40634],
        [46049],
        [50214],
        [50165],
        [49753],
        [49460],
        [49072],
        [49021],
        [48897],
        [46971],
        [45675],
        [44947],
        [46726],
        [47114],
        [47706],
        [45141],
        [45355],
        [46440],
        [45586]], device='cuda:0')
[2024-07-24 10:17:56,324][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[20012],
        [23832],
        [34865],
        [29182],
        [26793],
        [26819],
        [25803],
        [26155],
        [27052],
        [27027],
        [26863],
        [26644],
        [26040],
        [26688],
        [26658],
        [26620],
        [26569],
        [26359],
        [26449]], device='cuda:0')
[2024-07-24 10:17:56,325][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[23210],
        [ 3970],
        [ 3015],
        [ 5014],
        [ 6758],
        [ 6703],
        [11547],
        [10883],
        [11000],
        [12624],
        [12500],
        [13837],
        [17466],
        [15259],
        [18892],
        [17299],
        [21936],
        [20711],
        [19979]], device='cuda:0')
[2024-07-24 10:17:56,327][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[27724],
        [37414],
        [46045],
        [42755],
        [41775],
        [42325],
        [39633],
        [39315],
        [39137],
        [41936],
        [42575],
        [42654],
        [42549],
        [42525],
        [43621],
        [43492],
        [42587],
        [39549],
        [39523]], device='cuda:0')
[2024-07-24 10:17:56,331][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 9975],
        [44002],
        [46741],
        [39827],
        [46243],
        [43959],
        [45677],
        [45523],
        [45636],
        [45488],
        [45593],
        [45398],
        [44808],
        [45600],
        [44395],
        [45723],
        [45016],
        [44118],
        [44607]], device='cuda:0')
[2024-07-24 10:17:56,334][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 7297],
        [44332],
        [44035],
        [41148],
        [37088],
        [40288],
        [39175],
        [39547],
        [35522],
        [39136],
        [37143],
        [37324],
        [37174],
        [36612],
        [26933],
        [36787],
        [35048],
        [36484],
        [36660]], device='cuda:0')
[2024-07-24 10:17:56,336][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[35779],
        [30846],
        [30991],
        [31902],
        [27977],
        [27723],
        [23517],
        [22498],
        [24141],
        [22868],
        [22803],
        [21897],
        [18166],
        [19332],
        [17886],
        [26221],
        [24721],
        [21173],
        [22142]], device='cuda:0')
[2024-07-24 10:17:56,337][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[12982],
        [27182],
        [30542],
        [24836],
        [26298],
        [13548],
        [14176],
        [13332],
        [15608],
        [16402],
        [14121],
        [17474],
        [18278],
        [18258],
        [17049],
        [13267],
        [14923],
        [17918],
        [19666]], device='cuda:0')
[2024-07-24 10:17:56,339][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[38120],
        [25307],
        [29185],
        [24571],
        [19099],
        [23854],
        [11856],
        [11709],
        [12313],
        [13843],
        [13176],
        [13619],
        [15270],
        [14017],
        [14841],
        [18174],
        [16414],
        [17180],
        [16158]], device='cuda:0')
[2024-07-24 10:17:56,343][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[15398],
        [35755],
        [42278],
        [43985],
        [44407],
        [43138],
        [44324],
        [44710],
        [44420],
        [44456],
        [44417],
        [44497],
        [44534],
        [44516],
        [44607],
        [44655],
        [44750],
        [44763],
        [44768]], device='cuda:0')
[2024-07-24 10:17:56,346][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[22085],
        [33685],
        [33979],
        [28519],
        [26619],
        [23297],
        [25882],
        [20407],
        [22539],
        [17668],
        [16902],
        [27742],
        [18667],
        [23226],
        [23441],
        [28795],
        [26736],
        [11972],
        [22799]], device='cuda:0')
[2024-07-24 10:17:56,347][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[6206],
        [ 516],
        [ 450],
        [ 462],
        [ 577],
        [ 694],
        [ 838],
        [ 961],
        [1118],
        [1443],
        [1486],
        [1622],
        [1897],
        [1703],
        [1738],
        [1792],
        [1871],
        [2266],
        [2299]], device='cuda:0')
[2024-07-24 10:17:56,349][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[23209],
        [13184],
        [16947],
        [17444],
        [19265],
        [20192],
        [18653],
        [23631],
        [20706],
        [21215],
        [22605],
        [18968],
        [24817],
        [18477],
        [20328],
        [18261],
        [18069],
        [21304],
        [18823]], device='cuda:0')
[2024-07-24 10:17:56,351][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[38189],
        [38477],
        [37817],
        [37759],
        [38232],
        [38169],
        [38345],
        [38345],
        [36964],
        [38654],
        [38810],
        [38623],
        [38272],
        [37725],
        [36565],
        [35026],
        [37253],
        [37543],
        [36355]], device='cuda:0')
[2024-07-24 10:17:56,354][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 8305],
        [ 8427],
        [ 8967],
        [12630],
        [ 9907],
        [17932],
        [18912],
        [19930],
        [22477],
        [18270],
        [19887],
        [18601],
        [20792],
        [25848],
        [22998],
        [22049],
        [22509],
        [17474],
        [23667]], device='cuda:0')
[2024-07-24 10:17:56,357][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[29230],
        [41650],
        [41007],
        [42472],
        [43034],
        [39090],
        [39957],
        [39736],
        [40811],
        [40898],
        [41683],
        [41766],
        [40415],
        [41477],
        [40451],
        [37704],
        [38099],
        [37388],
        [39015]], device='cuda:0')
[2024-07-24 10:17:56,359][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[15292],
        [38281],
        [39035],
        [38676],
        [37680],
        [36200],
        [37195],
        [36831],
        [37255],
        [34706],
        [34124],
        [37945],
        [37430],
        [37078],
        [35295],
        [36380],
        [37498],
        [27457],
        [28018]], device='cuda:0')
[2024-07-24 10:17:56,360][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[28780],
        [25756],
        [18823],
        [11550],
        [19876],
        [10047],
        [12839],
        [13133],
        [13561],
        [12403],
        [13636],
        [13173],
        [13994],
        [13581],
        [15497],
        [ 5754],
        [ 7156],
        [ 9786],
        [ 8736]], device='cuda:0')
[2024-07-24 10:17:56,363][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[16280],
        [24375],
        [23322],
        [29744],
        [27403],
        [34436],
        [34570],
        [34114],
        [36577],
        [35715],
        [35719],
        [33469],
        [29227],
        [35546],
        [33494],
        [32790],
        [33502],
        [29177],
        [33377]], device='cuda:0')
[2024-07-24 10:17:56,366][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[38374],
        [35235],
        [33327],
        [34291],
        [31578],
        [38290],
        [37055],
        [36996],
        [36147],
        [37749],
        [38814],
        [39092],
        [40231],
        [38976],
        [40166],
        [40999],
        [41586],
        [41590],
        [42822]], device='cuda:0')
[2024-07-24 10:17:56,369][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[16102],
        [15474],
        [18243],
        [16733],
        [16862],
        [17048],
        [16615],
        [16213],
        [16303],
        [15646],
        [16748],
        [16532],
        [16490],
        [16619],
        [16126],
        [11173],
        [10369],
        [ 9160],
        [10902]], device='cuda:0')
[2024-07-24 10:17:56,371][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[43777],
        [42588],
        [41702],
        [40580],
        [36418],
        [37831],
        [34166],
        [34614],
        [34272],
        [35059],
        [34911],
        [35189],
        [37853],
        [36565],
        [40116],
        [39291],
        [42067],
        [41611],
        [41207]], device='cuda:0')
[2024-07-24 10:17:56,372][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[31339],
        [30841],
        [30074],
        [30537],
        [29256],
        [28740],
        [27196],
        [27793],
        [25855],
        [26564],
        [26257],
        [28219],
        [27481],
        [24190],
        [20908],
        [25914],
        [26274],
        [25688],
        [25623]], device='cuda:0')
[2024-07-24 10:17:56,374][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[35636],
        [35620],
        [34766],
        [34996],
        [34705],
        [35724],
        [35698],
        [36012],
        [36146],
        [34142],
        [36294],
        [36808],
        [37357],
        [37039],
        [36319],
        [37558],
        [37670],
        [38180],
        [37800]], device='cuda:0')
[2024-07-24 10:17:56,378][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[34002],
        [35716],
        [36476],
        [34765],
        [33912],
        [28654],
        [12811],
        [14483],
        [13975],
        [11542],
        [10964],
        [15330],
        [18094],
        [10885],
        [ 7267],
        [ 9145],
        [12501],
        [18111],
        [12449]], device='cuda:0')
[2024-07-24 10:17:56,381][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[8175],
        [5621],
        [7344],
        [6036],
        [7975],
        [6065],
        [7327],
        [7039],
        [6253],
        [7625],
        [6305],
        [5869],
        [6384],
        [5915],
        [6751],
        [8296],
        [6829],
        [9254],
        [7448]], device='cuda:0')
[2024-07-24 10:17:56,382][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[4606],
        [2846],
        [2069],
        [2275],
        [2307],
        [1917],
        [2066],
        [1646],
        [2717],
        [2330],
        [2561],
        [2152],
        [1410],
        [2503],
        [2885],
        [3520],
        [2572],
        [2333],
        [2837]], device='cuda:0')
[2024-07-24 10:17:56,384][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[16550],
        [16550],
        [16550],
        [16550],
        [16550],
        [16550],
        [16550],
        [16550],
        [16550],
        [16550],
        [16550],
        [16550],
        [16550],
        [16550],
        [16550],
        [16550],
        [16550],
        [16550],
        [16550]], device='cuda:0')
[2024-07-24 10:17:56,444][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:56,445][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,445][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,446][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,447][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,447][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,449][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,450][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,450][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,451][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,452][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,452][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,453][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,454][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9981, 0.0019], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,454][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0362, 0.9638], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,455][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2189, 0.7811], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,456][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.8060, 0.1940], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,456][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1574, 0.8426], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,457][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.6140, 0.3860], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,458][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0952, 0.9048], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,458][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9877, 0.0123], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,464][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9021, 0.0979], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,464][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0243, 0.9757], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,465][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1633, 0.8367], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,466][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2485, 0.7515], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,466][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Jamie] are: tensor([9.9927e-01, 4.0537e-04, 3.2622e-04], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,467][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Jamie] are: tensor([0.0183, 0.4569, 0.5248], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,472][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Jamie] are: tensor([0.1073, 0.4927, 0.4000], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,474][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Jamie] are: tensor([0.6966, 0.1954, 0.1080], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,475][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Jamie] are: tensor([0.0762, 0.4267, 0.4971], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,475][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Jamie] are: tensor([0.3721, 0.0413, 0.5865], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,476][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Jamie] are: tensor([0.0496, 0.2121, 0.7383], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,477][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Jamie] are: tensor([0.1317, 0.6367, 0.2316], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,481][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Jamie] are: tensor([0.9201, 0.0501, 0.0298], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,484][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Jamie] are: tensor([0.0704, 0.4974, 0.4322], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,485][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Jamie] are: tensor([0.0545, 0.7363, 0.2092], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,485][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Jamie] are: tensor([0.1802, 0.3234, 0.4964], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,486][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.9697e-01, 1.1613e-03, 9.8051e-04, 8.9154e-04], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,487][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0156, 0.2355, 0.2261, 0.5228], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,489][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0949, 0.3178, 0.2725, 0.3147], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,494][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.6245, 0.2024, 0.0958, 0.0773], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,495][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0983, 0.2832, 0.3133, 0.3051], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,495][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1305, 0.0158, 0.8131, 0.0406], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,496][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0396, 0.2379, 0.3094, 0.4131], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,497][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.8536, 0.0193, 0.1205, 0.0066], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,499][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.8916, 0.0451, 0.0335, 0.0297], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,504][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0112, 0.2852, 0.3678, 0.3358], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,505][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0285, 0.6932, 0.1279, 0.1504], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,505][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2115, 0.3348, 0.3502, 0.1035], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,506][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([9.9867e-01, 4.9493e-04, 3.0408e-04, 3.1580e-04, 2.1330e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,507][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0207, 0.2275, 0.1707, 0.3888, 0.1923], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,510][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0619, 0.2514, 0.2069, 0.2493, 0.2305], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,514][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.6028, 0.1386, 0.1051, 0.0618, 0.0917], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,515][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0396, 0.2083, 0.2358, 0.2370, 0.2793], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,516][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.1896, 0.0236, 0.2202, 0.3548, 0.2119], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,516][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0416, 0.1767, 0.2576, 0.2046, 0.3196], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,517][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.1158, 0.6073, 0.1575, 0.0595, 0.0599], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,520][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.8631, 0.0437, 0.0268, 0.0419, 0.0246], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,524][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0169, 0.2188, 0.2263, 0.4160, 0.1220], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,525][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0680, 0.4854, 0.0761, 0.2838, 0.0867], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,526][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.1557, 0.2238, 0.2466, 0.2103, 0.1637], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,526][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ had] are: tensor([9.9771e-01, 7.1649e-04, 5.1069e-04, 5.0971e-04, 4.0807e-04, 1.3998e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,527][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0082, 0.1389, 0.1276, 0.3028, 0.1951, 0.2273], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,530][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0574, 0.1924, 0.1622, 0.1908, 0.1848, 0.2125], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,534][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.4357, 0.1537, 0.1294, 0.0754, 0.1678, 0.0379], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,535][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0448, 0.1620, 0.1809, 0.1825, 0.2085, 0.2212], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,536][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0516, 0.0058, 0.5675, 0.1289, 0.1772, 0.0690], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,537][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0287, 0.1314, 0.2165, 0.1996, 0.2170, 0.2067], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,537][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.4764, 0.1947, 0.1324, 0.0438, 0.0836, 0.0690], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,542][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.8608, 0.0342, 0.0208, 0.0249, 0.0227, 0.0366], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,545][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0061, 0.2375, 0.2284, 0.2291, 0.1299, 0.1690], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,545][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0124, 0.2534, 0.0642, 0.6302, 0.0329, 0.0069], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,546][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.2477, 0.2151, 0.1799, 0.1184, 0.1476, 0.0913], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,547][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([9.9936e-01, 2.4785e-04, 1.1623e-04, 1.3479e-04, 8.0995e-05, 3.1521e-05,
        3.3336e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,548][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0044, 0.1028, 0.1034, 0.2918, 0.1893, 0.1982, 0.1102],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,552][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0453, 0.1542, 0.1311, 0.1515, 0.1468, 0.1730, 0.1980],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,555][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.4247, 0.1577, 0.0690, 0.0820, 0.1650, 0.0613, 0.0403],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,556][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0452, 0.1388, 0.1534, 0.1457, 0.1726, 0.1907, 0.1535],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,556][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0193, 0.0069, 0.4485, 0.1406, 0.2764, 0.0776, 0.0306],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,557][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0260, 0.1319, 0.1633, 0.1368, 0.1586, 0.1381, 0.2453],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,558][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.7661, 0.0465, 0.0590, 0.0104, 0.0273, 0.0648, 0.0260],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,562][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.6225, 0.0428, 0.0229, 0.1046, 0.0499, 0.1395, 0.0180],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,565][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0078, 0.1807, 0.1969, 0.1923, 0.1029, 0.1443, 0.1751],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,566][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0172, 0.2372, 0.0585, 0.2648, 0.0566, 0.0261, 0.3395],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,567][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0286, 0.1410, 0.1056, 0.2927, 0.2074, 0.1810, 0.0437],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:56,567][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([9.9971e-01, 1.1822e-04, 3.8204e-05, 6.7782e-05, 2.8409e-05, 1.2121e-05,
        1.1098e-05, 1.1696e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,568][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0016, 0.0674, 0.0838, 0.2706, 0.2030, 0.1893, 0.1292, 0.0552],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,573][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0343, 0.1348, 0.1120, 0.1348, 0.1282, 0.1536, 0.1760, 0.1263],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,575][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.3781, 0.1510, 0.0712, 0.0713, 0.1041, 0.0583, 0.0705, 0.0956],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,576][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0245, 0.1123, 0.1237, 0.1320, 0.1524, 0.1630, 0.1425, 0.1496],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,577][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0335, 0.0109, 0.3589, 0.1635, 0.3112, 0.0682, 0.0398, 0.0139],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,578][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0106, 0.0775, 0.0908, 0.1442, 0.1320, 0.1018, 0.1200, 0.3230],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,578][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.2951, 0.1410, 0.0403, 0.0336, 0.0261, 0.1079, 0.1689, 0.1872],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,583][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.4165, 0.0478, 0.0359, 0.1369, 0.0746, 0.1871, 0.0554, 0.0458],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,585][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0056, 0.0898, 0.1435, 0.1844, 0.0809, 0.1510, 0.2224, 0.1225],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,586][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0086, 0.1462, 0.0170, 0.1649, 0.0139, 0.0496, 0.1495, 0.4502],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,587][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0150, 0.0928, 0.0884, 0.2351, 0.1872, 0.2246, 0.0847, 0.0722],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:56,588][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ of] are: tensor([9.9942e-01, 2.0212e-04, 6.5403e-05, 1.3046e-04, 5.7766e-05, 2.4564e-05,
        2.1727e-05, 1.8843e-05, 6.1957e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,589][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0052, 0.1009, 0.0941, 0.2559, 0.1588, 0.1715, 0.0886, 0.0501, 0.0750],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,593][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0350, 0.1197, 0.0996, 0.1189, 0.1112, 0.1331, 0.1536, 0.1116, 0.1173],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,596][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.3641, 0.2190, 0.0499, 0.0701, 0.1013, 0.0496, 0.0413, 0.0667, 0.0381],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,596][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0267, 0.1040, 0.1095, 0.1142, 0.1277, 0.1413, 0.1221, 0.1262, 0.1284],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,597][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0363, 0.0030, 0.4071, 0.1243, 0.2418, 0.0943, 0.0251, 0.0107, 0.0575],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,598][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0088, 0.0973, 0.1068, 0.1289, 0.1139, 0.0822, 0.1293, 0.0789, 0.2538],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,599][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.7236, 0.0112, 0.0473, 0.0032, 0.0231, 0.0511, 0.0419, 0.0809, 0.0177],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,604][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.6726, 0.0300, 0.0159, 0.0786, 0.0440, 0.1054, 0.0141, 0.0201, 0.0193],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,606][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0030, 0.0736, 0.1621, 0.1104, 0.0812, 0.1122, 0.1449, 0.1186, 0.1941],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,607][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0254, 0.0429, 0.0232, 0.1007, 0.0300, 0.0058, 0.1408, 0.5711, 0.0602],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,607][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0268, 0.0993, 0.0911, 0.2485, 0.2264, 0.1262, 0.0447, 0.0519, 0.0851],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:56,608][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([9.9968e-01, 9.5361e-05, 3.6055e-05, 6.0224e-05, 2.9619e-05, 1.1285e-05,
        1.0307e-05, 1.2060e-05, 4.7591e-05, 1.8316e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,609][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0031, 0.0864, 0.0788, 0.2363, 0.1438, 0.1631, 0.0834, 0.0439, 0.0784,
        0.0828], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,614][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0279, 0.1063, 0.0879, 0.1054, 0.1012, 0.1233, 0.1384, 0.0993, 0.1085,
        0.1019], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,616][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.3489, 0.1246, 0.0458, 0.0528, 0.0826, 0.0329, 0.0446, 0.1029, 0.0688,
        0.0961], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,617][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0227, 0.0925, 0.1014, 0.1037, 0.1164, 0.1235, 0.1085, 0.1134, 0.1104,
        0.1077], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,618][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0236, 0.0049, 0.2884, 0.1609, 0.2387, 0.0291, 0.0329, 0.0140, 0.1436,
        0.0640], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,618][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0161, 0.0743, 0.0946, 0.1065, 0.1025, 0.0932, 0.0913, 0.1478, 0.1384,
        0.1353], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,619][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0904, 0.1444, 0.0636, 0.0171, 0.0262, 0.1163, 0.0511, 0.2859, 0.1023,
        0.1026], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,624][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.6215, 0.0258, 0.0143, 0.0748, 0.0381, 0.1149, 0.0182, 0.0197, 0.0333,
        0.0395], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,626][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0072, 0.0813, 0.0997, 0.1183, 0.0722, 0.1176, 0.1266, 0.0837, 0.1763,
        0.1170], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,627][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0964, 0.2285, 0.0264, 0.1468, 0.0091, 0.0149, 0.0616, 0.2230, 0.1167,
        0.0765], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,628][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0234, 0.0631, 0.0364, 0.1604, 0.0995, 0.1235, 0.0448, 0.0432, 0.1154,
        0.2902], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:56,629][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ at] are: tensor([9.9959e-01, 1.3056e-04, 4.2878e-05, 8.0002e-05, 3.8695e-05, 1.4003e-05,
        1.3418e-05, 1.2802e-05, 4.3755e-05, 1.9358e-05, 1.8001e-05],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,629][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0026, 0.0747, 0.0737, 0.2125, 0.1394, 0.1473, 0.0835, 0.0413, 0.0765,
        0.0820, 0.0665], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,634][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0247, 0.0986, 0.0831, 0.0965, 0.0920, 0.1100, 0.1262, 0.0888, 0.0963,
        0.0913, 0.0923], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,639][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.2716, 0.1376, 0.0368, 0.0540, 0.0761, 0.0354, 0.0587, 0.0748, 0.0559,
        0.1455, 0.0536], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,640][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0154, 0.0825, 0.0889, 0.0965, 0.1068, 0.1117, 0.1000, 0.1015, 0.1022,
        0.0983, 0.0962], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,641][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0479, 0.0052, 0.3596, 0.1226, 0.1581, 0.0987, 0.0114, 0.0185, 0.0299,
        0.0750, 0.0732], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,641][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0056, 0.0584, 0.0773, 0.1119, 0.1264, 0.0733, 0.0811, 0.0934, 0.1593,
        0.0649, 0.1484], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,642][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.1914, 0.0414, 0.0416, 0.0145, 0.0824, 0.0575, 0.0466, 0.0814, 0.0562,
        0.3394, 0.0477], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,647][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.6410, 0.0283, 0.0133, 0.0777, 0.0343, 0.0849, 0.0146, 0.0175, 0.0256,
        0.0308, 0.0321], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,649][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0023, 0.0755, 0.1011, 0.0892, 0.0619, 0.0872, 0.0978, 0.0721, 0.1791,
        0.1252, 0.1087], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,650][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0237, 0.1110, 0.0380, 0.1618, 0.0138, 0.0122, 0.1679, 0.2672, 0.0640,
        0.1034, 0.0370], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,651][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0191, 0.0547, 0.0466, 0.1383, 0.0981, 0.1048, 0.0381, 0.0336, 0.0877,
        0.2497, 0.1293], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:56,652][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ the] are: tensor([9.9956e-01, 1.1756e-04, 4.2202e-05, 7.3930e-05, 3.8652e-05, 1.4103e-05,
        1.3943e-05, 1.4840e-05, 6.1547e-05, 2.2806e-05, 2.3136e-05, 1.4820e-05],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,653][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0038, 0.0772, 0.0722, 0.2021, 0.1273, 0.1399, 0.0691, 0.0360, 0.0629,
        0.0658, 0.0533, 0.0904], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,658][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0259, 0.0878, 0.0738, 0.0866, 0.0814, 0.0979, 0.1124, 0.0822, 0.0856,
        0.0832, 0.0803, 0.1029], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,659][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.3182, 0.1342, 0.0376, 0.0466, 0.0755, 0.0416, 0.0345, 0.0681, 0.0357,
        0.1139, 0.0503, 0.0438], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,660][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0190, 0.0743, 0.0822, 0.0818, 0.0964, 0.1060, 0.0877, 0.0949, 0.0938,
        0.0910, 0.0950, 0.0781], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,661][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0286, 0.0040, 0.2482, 0.0772, 0.1502, 0.0713, 0.0138, 0.0104, 0.0257,
        0.0668, 0.1410, 0.1628], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,662][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0094, 0.0688, 0.0706, 0.0859, 0.0878, 0.0832, 0.1077, 0.0870, 0.1144,
        0.0639, 0.0700, 0.1515], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,663][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.3168, 0.0250, 0.0361, 0.0073, 0.0150, 0.0440, 0.0351, 0.1173, 0.0413,
        0.2467, 0.0721, 0.0433], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,669][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.8274, 0.0154, 0.0066, 0.0335, 0.0150, 0.0310, 0.0039, 0.0052, 0.0064,
        0.0074, 0.0091, 0.0390], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,670][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0016, 0.0728, 0.0879, 0.0907, 0.0415, 0.0717, 0.0826, 0.0662, 0.1868,
        0.0924, 0.1189, 0.0870], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,671][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0157, 0.0455, 0.0222, 0.0691, 0.0158, 0.0105, 0.1013, 0.4087, 0.0947,
        0.1030, 0.0390, 0.0744], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,672][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0549, 0.0581, 0.0461, 0.1422, 0.0924, 0.0817, 0.0173, 0.0220, 0.0419,
        0.0991, 0.0777, 0.2666], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:56,673][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ store] are: tensor([9.9974e-01, 8.7955e-05, 2.4044e-05, 4.7771e-05, 2.2592e-05, 8.6125e-06,
        7.6331e-06, 6.9493e-06, 2.2942e-05, 1.1505e-05, 9.4019e-06, 6.2911e-06,
        2.4417e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,678][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0018, 0.0571, 0.0587, 0.1831, 0.1181, 0.1223, 0.0670, 0.0300, 0.0603,
        0.0651, 0.0534, 0.0918, 0.0914], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,680][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0218, 0.0812, 0.0671, 0.0801, 0.0737, 0.0923, 0.1040, 0.0737, 0.0798,
        0.0753, 0.0762, 0.0952, 0.0797], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,681][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.2845, 0.1403, 0.0455, 0.0571, 0.0717, 0.0418, 0.0313, 0.0610, 0.0334,
        0.0847, 0.0477, 0.0350, 0.0661], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,681][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0111, 0.0687, 0.0757, 0.0816, 0.0916, 0.0956, 0.0852, 0.0865, 0.0870,
        0.0806, 0.0811, 0.0741, 0.0812], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,682][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0125, 0.0014, 0.0976, 0.0746, 0.1689, 0.0519, 0.0184, 0.0189, 0.0596,
        0.1244, 0.1503, 0.1894, 0.0320], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,684][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0121, 0.0481, 0.0609, 0.1002, 0.0635, 0.0691, 0.0808, 0.1114, 0.1193,
        0.0581, 0.0664, 0.0824, 0.1278], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,690][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0587, 0.0550, 0.0187, 0.0122, 0.0198, 0.0357, 0.0532, 0.1368, 0.0646,
        0.1394, 0.0724, 0.0929, 0.2405], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,691][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.7359, 0.0118, 0.0055, 0.0353, 0.0130, 0.0344, 0.0046, 0.0066, 0.0085,
        0.0114, 0.0135, 0.0619, 0.0575], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,691][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0032, 0.0392, 0.0744, 0.0740, 0.0245, 0.0742, 0.0888, 0.0547, 0.1555,
        0.0663, 0.1490, 0.1350, 0.0613], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,692][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0071, 0.0752, 0.0110, 0.0974, 0.0120, 0.0108, 0.0819, 0.4376, 0.0586,
        0.0355, 0.0357, 0.1094, 0.0277], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,693][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0273, 0.0188, 0.0172, 0.0547, 0.0367, 0.0298, 0.0079, 0.0098, 0.0209,
        0.0581, 0.0488, 0.1933, 0.4766], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:56,695][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [.] are: tensor([9.9970e-01, 1.0353e-04, 2.8590e-05, 5.8312e-05, 2.5917e-05, 9.7755e-06,
        8.1641e-06, 6.3284e-06, 2.2295e-05, 1.0801e-05, 9.0350e-06, 6.4584e-06,
        2.6791e-06, 3.7943e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,700][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0023, 0.0599, 0.0584, 0.1678, 0.1032, 0.1173, 0.0556, 0.0279, 0.0502,
        0.0509, 0.0435, 0.0758, 0.0823, 0.1048], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,701][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0209, 0.0744, 0.0619, 0.0744, 0.0685, 0.0840, 0.0959, 0.0687, 0.0730,
        0.0705, 0.0694, 0.0871, 0.0749, 0.0765], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,702][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.3147, 0.1296, 0.0290, 0.0392, 0.0647, 0.0442, 0.0242, 0.0655, 0.0251,
        0.0692, 0.0421, 0.0300, 0.0877, 0.0348], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,703][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0157, 0.0633, 0.0697, 0.0720, 0.0824, 0.0866, 0.0771, 0.0760, 0.0821,
        0.0737, 0.0786, 0.0679, 0.0749, 0.0802], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,703][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0154, 0.0015, 0.1960, 0.0429, 0.1968, 0.0345, 0.0240, 0.0054, 0.0263,
        0.0602, 0.1448, 0.1843, 0.0423, 0.0255], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,708][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0060, 0.0508, 0.0734, 0.0794, 0.0848, 0.0623, 0.0701, 0.0652, 0.1066,
        0.0541, 0.0877, 0.0620, 0.0878, 0.1096], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,710][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.3539, 0.0082, 0.0249, 0.0025, 0.0143, 0.0306, 0.0488, 0.0809, 0.0197,
        0.0749, 0.0313, 0.0510, 0.2304, 0.0285], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,711][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.6678, 0.0243, 0.0091, 0.0545, 0.0210, 0.0525, 0.0048, 0.0062, 0.0077,
        0.0093, 0.0108, 0.0568, 0.0576, 0.0176], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,712][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0010, 0.0596, 0.0814, 0.0677, 0.0413, 0.0559, 0.0702, 0.0445, 0.1284,
        0.0753, 0.0879, 0.0790, 0.0641, 0.1437], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,713][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0095, 0.0286, 0.0245, 0.0602, 0.0162, 0.0024, 0.0802, 0.4786, 0.0561,
        0.0884, 0.0295, 0.0914, 0.0202, 0.0143], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,716][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0207, 0.0417, 0.0265, 0.1007, 0.0452, 0.0437, 0.0084, 0.0103, 0.0167,
        0.0455, 0.0374, 0.1457, 0.3520, 0.1054], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:56,720][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([9.9968e-01, 1.2123e-04, 2.8768e-05, 6.0927e-05, 2.3826e-05, 9.7578e-06,
        8.0885e-06, 6.4186e-06, 2.2352e-05, 1.0785e-05, 8.8421e-06, 6.0747e-06,
        2.3122e-06, 3.8295e-06, 1.8489e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,721][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0087, 0.0967, 0.0652, 0.1727, 0.0821, 0.1110, 0.0430, 0.0302, 0.0383,
        0.0372, 0.0341, 0.0605, 0.0708, 0.0860, 0.0635], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,722][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0173, 0.0693, 0.0553, 0.0699, 0.0622, 0.0803, 0.0899, 0.0651, 0.0704,
        0.0654, 0.0659, 0.0829, 0.0700, 0.0724, 0.0638], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,723][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.2154, 0.0775, 0.0394, 0.0328, 0.0443, 0.0354, 0.0372, 0.0630, 0.0349,
        0.1333, 0.0499, 0.0315, 0.1051, 0.0472, 0.0533], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,724][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0121, 0.0577, 0.0648, 0.0661, 0.0766, 0.0821, 0.0688, 0.0755, 0.0721,
        0.0716, 0.0724, 0.0599, 0.0743, 0.0736, 0.0725], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,729][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0140, 0.0021, 0.0260, 0.0565, 0.0317, 0.0637, 0.0187, 0.0363, 0.1044,
        0.1418, 0.1666, 0.1173, 0.0933, 0.0958, 0.0320], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,731][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0079, 0.0506, 0.0509, 0.0585, 0.0614, 0.0521, 0.0461, 0.0893, 0.0851,
        0.0661, 0.0608, 0.0725, 0.1078, 0.0940, 0.0968], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,732][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0216, 0.1018, 0.0208, 0.0082, 0.0079, 0.0324, 0.0176, 0.1054, 0.0407,
        0.0683, 0.0685, 0.0759, 0.2294, 0.1662, 0.0355], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,733][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.3638, 0.0156, 0.0082, 0.0337, 0.0167, 0.0390, 0.0134, 0.0156, 0.0199,
        0.0320, 0.0375, 0.1130, 0.1692, 0.0543, 0.0680], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,733][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0012, 0.0418, 0.0389, 0.0818, 0.0231, 0.0573, 0.0681, 0.0317, 0.1380,
        0.0658, 0.1127, 0.0871, 0.0938, 0.1379, 0.0209], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,736][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0200, 0.1013, 0.0164, 0.0633, 0.0231, 0.0063, 0.0463, 0.2621, 0.0949,
        0.0914, 0.0640, 0.0650, 0.0674, 0.0555, 0.0229], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,741][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0079, 0.0070, 0.0072, 0.0194, 0.0111, 0.0165, 0.0091, 0.0128, 0.0282,
        0.0602, 0.0556, 0.1485, 0.3940, 0.1539, 0.0686], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:56,742][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([9.9969e-01, 1.3526e-04, 2.7033e-05, 6.1502e-05, 2.3961e-05, 8.4621e-06,
        7.3182e-06, 5.2041e-06, 1.6421e-05, 8.4509e-06, 6.2957e-06, 4.5319e-06,
        1.5554e-06, 2.7252e-06, 1.2009e-06, 4.9482e-07], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,742][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0019, 0.0464, 0.0446, 0.1332, 0.0868, 0.0887, 0.0498, 0.0243, 0.0455,
        0.0480, 0.0389, 0.0664, 0.0690, 0.0903, 0.1000, 0.0661],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,743][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0198, 0.0656, 0.0546, 0.0648, 0.0617, 0.0724, 0.0820, 0.0597, 0.0632,
        0.0611, 0.0600, 0.0750, 0.0653, 0.0662, 0.0612, 0.0675],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,745][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.2026, 0.0913, 0.0357, 0.0365, 0.0543, 0.0298, 0.0265, 0.0454, 0.0392,
        0.1017, 0.0392, 0.0302, 0.0934, 0.0436, 0.0737, 0.0569],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,751][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0145, 0.0523, 0.0606, 0.0577, 0.0725, 0.0756, 0.0645, 0.0696, 0.0679,
        0.0650, 0.0675, 0.0563, 0.0703, 0.0681, 0.0682, 0.0696],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,752][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0253, 0.0041, 0.1691, 0.1358, 0.0974, 0.0278, 0.0118, 0.0146, 0.0322,
        0.0608, 0.1114, 0.0955, 0.0523, 0.0593, 0.0679, 0.0345],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,753][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0059, 0.0440, 0.0463, 0.0676, 0.0493, 0.0548, 0.0772, 0.0652, 0.1102,
        0.0442, 0.0607, 0.0824, 0.0490, 0.0773, 0.0571, 0.1086],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,753][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0613, 0.0255, 0.0266, 0.0107, 0.0159, 0.0209, 0.0224, 0.1008, 0.0269,
        0.1080, 0.0530, 0.0585, 0.3287, 0.0613, 0.0566, 0.0229],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,756][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.7392, 0.0108, 0.0043, 0.0264, 0.0096, 0.0231, 0.0029, 0.0036, 0.0042,
        0.0040, 0.0060, 0.0309, 0.0213, 0.0107, 0.0183, 0.0847],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,761][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0015, 0.0425, 0.0525, 0.0650, 0.0319, 0.0587, 0.0828, 0.0423, 0.1096,
        0.0723, 0.1033, 0.0823, 0.0627, 0.1452, 0.0229, 0.0244],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,762][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0154, 0.0284, 0.0120, 0.1040, 0.0102, 0.0059, 0.1128, 0.2102, 0.1111,
        0.1188, 0.0414, 0.1174, 0.0543, 0.0307, 0.0088, 0.0186],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,763][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0507, 0.0240, 0.0144, 0.0615, 0.0293, 0.0222, 0.0060, 0.0079, 0.0124,
        0.0203, 0.0210, 0.0986, 0.1598, 0.0641, 0.0603, 0.3477],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:56,763][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([9.9980e-01, 5.4361e-05, 1.7868e-05, 3.2991e-05, 1.6315e-05, 5.4981e-06,
        5.3420e-06, 5.6220e-06, 2.5030e-05, 8.6463e-06, 9.1149e-06, 5.5610e-06,
        2.5700e-06, 3.8583e-06, 2.0908e-06, 9.7001e-07, 2.3931e-06],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,766][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0033, 0.0555, 0.0458, 0.1339, 0.0718, 0.0873, 0.0373, 0.0222, 0.0340,
        0.0353, 0.0295, 0.0519, 0.0590, 0.0724, 0.0656, 0.0547, 0.1406],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,771][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0185, 0.0600, 0.0506, 0.0590, 0.0567, 0.0669, 0.0760, 0.0555, 0.0577,
        0.0565, 0.0546, 0.0699, 0.0612, 0.0613, 0.0572, 0.0636, 0.0748],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,772][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2275, 0.0926, 0.0266, 0.0387, 0.0678, 0.0288, 0.0144, 0.0391, 0.0215,
        0.0755, 0.0327, 0.0275, 0.0844, 0.0356, 0.0855, 0.0744, 0.0273],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,773][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0154, 0.0519, 0.0578, 0.0556, 0.0664, 0.0718, 0.0582, 0.0653, 0.0635,
        0.0626, 0.0655, 0.0522, 0.0656, 0.0638, 0.0624, 0.0653, 0.0566],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,774][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0208, 0.0026, 0.2188, 0.0560, 0.1249, 0.0297, 0.0075, 0.0066, 0.0192,
        0.0490, 0.1303, 0.1027, 0.0255, 0.0314, 0.0733, 0.0453, 0.0564],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,776][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0079, 0.0475, 0.0551, 0.0501, 0.0533, 0.0496, 0.0930, 0.0515, 0.0757,
        0.0377, 0.0589, 0.0854, 0.0695, 0.0707, 0.0458, 0.0469, 0.1016],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,781][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1789, 0.0233, 0.0245, 0.0049, 0.0109, 0.0257, 0.0108, 0.0430, 0.0255,
        0.1248, 0.0388, 0.0231, 0.3010, 0.0564, 0.0490, 0.0416, 0.0178],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,782][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.8079, 0.0059, 0.0022, 0.0152, 0.0053, 0.0120, 0.0008, 0.0014, 0.0016,
        0.0014, 0.0021, 0.0122, 0.0105, 0.0042, 0.0083, 0.0576, 0.0515],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,783][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0014, 0.0420, 0.0470, 0.0573, 0.0281, 0.0459, 0.0515, 0.0546, 0.0944,
        0.0773, 0.0851, 0.0726, 0.0566, 0.1618, 0.0309, 0.0387, 0.0549],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,784][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0052, 0.0341, 0.0070, 0.0474, 0.0086, 0.0060, 0.0804, 0.3253, 0.0747,
        0.1111, 0.0367, 0.0959, 0.0370, 0.0343, 0.0093, 0.0157, 0.0713],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,786][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0480, 0.0135, 0.0064, 0.0341, 0.0146, 0.0144, 0.0021, 0.0031, 0.0053,
        0.0086, 0.0097, 0.0396, 0.0838, 0.0282, 0.0256, 0.2982, 0.3647],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:56,791][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([9.9981e-01, 5.4878e-05, 1.7904e-05, 3.3077e-05, 1.6482e-05, 5.6641e-06,
        5.3332e-06, 5.6953e-06, 2.1463e-05, 8.8927e-06, 8.4261e-06, 5.1278e-06,
        2.1104e-06, 3.2624e-06, 1.6680e-06, 6.9987e-07, 2.2805e-06, 7.7752e-07],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,792][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0024, 0.0486, 0.0384, 0.1203, 0.0628, 0.0733, 0.0317, 0.0172, 0.0285,
        0.0285, 0.0242, 0.0436, 0.0488, 0.0614, 0.0586, 0.0460, 0.1257, 0.1400],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,793][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0147, 0.0563, 0.0468, 0.0558, 0.0531, 0.0642, 0.0733, 0.0514, 0.0556,
        0.0517, 0.0540, 0.0668, 0.0562, 0.0575, 0.0538, 0.0613, 0.0718, 0.0556],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,794][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.3210, 0.1480, 0.0221, 0.0383, 0.0367, 0.0312, 0.0180, 0.0322, 0.0143,
        0.0541, 0.0304, 0.0166, 0.0504, 0.0350, 0.0369, 0.0528, 0.0274, 0.0347],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,796][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0098, 0.0481, 0.0537, 0.0576, 0.0617, 0.0674, 0.0601, 0.0600, 0.0615,
        0.0568, 0.0580, 0.0520, 0.0579, 0.0625, 0.0609, 0.0615, 0.0575, 0.0531],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,801][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.0165, 0.0011, 0.0828, 0.0410, 0.1043, 0.0263, 0.0125, 0.0162, 0.0261,
        0.0351, 0.0959, 0.1105, 0.0324, 0.0673, 0.0815, 0.0716, 0.1198, 0.0592],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,802][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0085, 0.0290, 0.0425, 0.0589, 0.0599, 0.0486, 0.0370, 0.0649, 0.0772,
        0.0556, 0.0440, 0.0485, 0.0714, 0.0749, 0.0943, 0.0853, 0.0448, 0.0545],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,803][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0162, 0.0964, 0.0078, 0.0094, 0.0069, 0.0276, 0.0091, 0.0282, 0.0300,
        0.0910, 0.0452, 0.0292, 0.1345, 0.1630, 0.0334, 0.0181, 0.0121, 0.2420],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,804][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.7445, 0.0028, 0.0009, 0.0092, 0.0027, 0.0072, 0.0008, 0.0010, 0.0016,
        0.0012, 0.0019, 0.0113, 0.0093, 0.0046, 0.0070, 0.0685, 0.0760, 0.0495],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,806][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.0049, 0.0361, 0.0373, 0.0590, 0.0299, 0.0535, 0.0640, 0.0397, 0.1003,
        0.0645, 0.0916, 0.0868, 0.0502, 0.1026, 0.0288, 0.0370, 0.0636, 0.0501],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,811][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0491, 0.0572, 0.0138, 0.0837, 0.0096, 0.0094, 0.0910, 0.1481, 0.0397,
        0.0727, 0.0352, 0.0952, 0.0276, 0.0525, 0.0146, 0.0253, 0.1366, 0.0386],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,812][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([1.4743e-02, 1.0903e-03, 8.8344e-04, 4.2050e-03, 2.2512e-03, 1.7579e-03,
        5.5718e-04, 9.1138e-04, 1.2360e-03, 2.4813e-03, 2.9456e-03, 1.5627e-02,
        2.3299e-02, 1.1258e-02, 7.3380e-03, 8.8068e-02, 1.7894e-01, 6.4241e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:56,813][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.9969e-01, 1.1481e-04, 2.9138e-05, 5.8850e-05, 2.6820e-05, 8.6226e-06,
        8.0857e-06, 6.4755e-06, 2.0754e-05, 1.0426e-05, 8.3864e-06, 5.8482e-06,
        2.2655e-06, 3.2720e-06, 1.6842e-06, 7.0000e-07, 2.4776e-06, 9.7516e-07,
        1.2104e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,814][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0022, 0.0409, 0.0345, 0.1012, 0.0584, 0.0680, 0.0302, 0.0159, 0.0258,
        0.0271, 0.0226, 0.0408, 0.0429, 0.0558, 0.0546, 0.0433, 0.1159, 0.1253,
        0.0946], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,816][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0153, 0.0536, 0.0441, 0.0537, 0.0495, 0.0603, 0.0689, 0.0494, 0.0530,
        0.0498, 0.0500, 0.0626, 0.0532, 0.0547, 0.0495, 0.0570, 0.0673, 0.0528,
        0.0552], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,821][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1946, 0.1090, 0.0199, 0.0320, 0.0451, 0.0247, 0.0217, 0.0314, 0.0185,
        0.0778, 0.0397, 0.0284, 0.0688, 0.0347, 0.0546, 0.0556, 0.0381, 0.0641,
        0.0413], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,822][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0111, 0.0455, 0.0495, 0.0516, 0.0582, 0.0633, 0.0546, 0.0565, 0.0576,
        0.0550, 0.0566, 0.0487, 0.0559, 0.0577, 0.0563, 0.0582, 0.0528, 0.0535,
        0.0573], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,823][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0205, 0.0008, 0.1803, 0.0335, 0.1373, 0.0166, 0.0080, 0.0052, 0.0089,
        0.0450, 0.0592, 0.0831, 0.0246, 0.0188, 0.0893, 0.0625, 0.0950, 0.0652,
        0.0460], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,824][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0055, 0.0422, 0.0432, 0.0620, 0.0536, 0.0322, 0.0531, 0.0327, 0.0887,
        0.0307, 0.0615, 0.0551, 0.0516, 0.0770, 0.0644, 0.0452, 0.0601, 0.0387,
        0.1025], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,829][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0755, 0.0070, 0.0141, 0.0030, 0.0118, 0.0209, 0.0218, 0.0537, 0.0231,
        0.0725, 0.0182, 0.0394, 0.2751, 0.0399, 0.0519, 0.0402, 0.0345, 0.1916,
        0.0061], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,831][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.6531, 0.0042, 0.0014, 0.0119, 0.0040, 0.0120, 0.0011, 0.0014, 0.0017,
        0.0017, 0.0025, 0.0154, 0.0127, 0.0051, 0.0073, 0.0739, 0.0891, 0.0595,
        0.0421], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,832][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0016, 0.0426, 0.0635, 0.0419, 0.0269, 0.0554, 0.0460, 0.0435, 0.0620,
        0.0537, 0.0676, 0.0611, 0.0446, 0.1228, 0.0253, 0.0377, 0.0547, 0.0862,
        0.0630], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,833][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0198, 0.0315, 0.0143, 0.0536, 0.0091, 0.0077, 0.0745, 0.3631, 0.0319,
        0.0925, 0.0335, 0.0812, 0.0209, 0.0157, 0.0099, 0.0161, 0.0708, 0.0219,
        0.0320], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,834][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([7.7995e-03, 1.5747e-03, 9.2182e-04, 4.9667e-03, 2.3742e-03, 2.3302e-03,
        5.8884e-04, 7.2268e-04, 1.0724e-03, 2.3081e-03, 2.0999e-03, 1.1742e-02,
        2.2227e-02, 8.5581e-03, 5.2391e-03, 8.1359e-02, 1.5646e-01, 6.0752e-01,
        8.0140e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:56,901][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:56,902][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,903][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,903][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,904][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,905][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,905][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,906][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,906][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,907][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,908][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,910][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,911][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:56,911][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9091, 0.0909], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,912][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.6115, 0.3885], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,913][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7027, 0.2973], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,913][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.8818, 0.1182], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,918][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9939, 0.0061], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,920][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6761, 0.3239], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,921][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9932, 0.0068], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,922][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.6446, 0.3554], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,922][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9021, 0.0979], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,923][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0243, 0.9757], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,928][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.6654, 0.3346], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,930][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.5855, 0.4145], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:56,931][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Jamie] are: tensor([0.8308, 0.0799, 0.0892], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,932][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Jamie] are: tensor([0.5183, 0.2544, 0.2272], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,932][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Jamie] are: tensor([0.6400, 0.1233, 0.2367], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,933][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Jamie] are: tensor([0.8939, 0.0615, 0.0446], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,936][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Jamie] are: tensor([0.9802, 0.0112, 0.0086], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,940][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Jamie] are: tensor([0.6020, 0.1727, 0.2254], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,941][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Jamie] are: tensor([0.9838, 0.0050, 0.0112], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,942][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Jamie] are: tensor([0.5727, 0.1997, 0.2276], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,942][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Jamie] are: tensor([0.9201, 0.0501, 0.0298], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,943][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Jamie] are: tensor([0.0704, 0.4974, 0.4322], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,944][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Jamie] are: tensor([0.5302, 0.2071, 0.2627], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,950][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Jamie] are: tensor([0.4092, 0.1941, 0.3967], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:56,953][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.8463, 0.0688, 0.0663, 0.0187], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,954][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.3681, 0.1986, 0.1757, 0.2577], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,955][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5654, 0.0932, 0.2110, 0.1304], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,955][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.8878, 0.0450, 0.0346, 0.0327], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,956][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9906, 0.0040, 0.0030, 0.0025], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,959][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.6178, 0.1405, 0.1178, 0.1238], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,963][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9877, 0.0041, 0.0056, 0.0026], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,964][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.5257, 0.1735, 0.1521, 0.1487], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,965][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.8916, 0.0451, 0.0335, 0.0297], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,965][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0112, 0.2852, 0.3678, 0.3358], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,966][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.5589, 0.1178, 0.2417, 0.0816], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,969][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4589, 0.1775, 0.2807, 0.0829], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:56,973][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.7451, 0.0844, 0.0803, 0.0396, 0.0507], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,974][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.4025, 0.1146, 0.1035, 0.2167, 0.1627], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,975][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.3431, 0.0959, 0.1921, 0.1765, 0.1924], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,976][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.8182, 0.0529, 0.0487, 0.0414, 0.0388], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,976][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.9485, 0.0134, 0.0111, 0.0092, 0.0178], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,979][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.4133, 0.1245, 0.1248, 0.1795, 0.1579], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,984][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.9750, 0.0052, 0.0099, 0.0036, 0.0063], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,984][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.3426, 0.1842, 0.1554, 0.1727, 0.1451], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,985][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.8631, 0.0437, 0.0268, 0.0419, 0.0246], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,986][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.0169, 0.2188, 0.2263, 0.4160, 0.1220], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,987][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.4156, 0.1348, 0.2174, 0.0906, 0.1416], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,989][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.3385, 0.1342, 0.2213, 0.1415, 0.1644], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:56,994][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.6785, 0.0768, 0.0798, 0.0316, 0.0438, 0.0895], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,995][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.4162, 0.0733, 0.0535, 0.1129, 0.0936, 0.2505], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,995][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.3539, 0.0901, 0.1552, 0.1299, 0.1417, 0.1292], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,996][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.7339, 0.0470, 0.0468, 0.0423, 0.0481, 0.0819], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:56,997][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.9687, 0.0070, 0.0062, 0.0051, 0.0062, 0.0068], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,001][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.4692, 0.0839, 0.0798, 0.1071, 0.0905, 0.1696], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,004][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.9822, 0.0036, 0.0053, 0.0024, 0.0030, 0.0035], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,005][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.3665, 0.0938, 0.1186, 0.1153, 0.1171, 0.1888], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,006][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.8608, 0.0342, 0.0208, 0.0249, 0.0227, 0.0366], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,006][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0061, 0.2375, 0.2284, 0.2291, 0.1299, 0.1690], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,007][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.3125, 0.1318, 0.2107, 0.1340, 0.1078, 0.1033], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,012][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.4475, 0.1145, 0.1541, 0.0790, 0.1321, 0.0729], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,014][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.3869, 0.0802, 0.0872, 0.0920, 0.0853, 0.2332, 0.0352],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,015][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1474, 0.0609, 0.0468, 0.2171, 0.1286, 0.3391, 0.0603],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,016][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2465, 0.0683, 0.1192, 0.1180, 0.1234, 0.1365, 0.1882],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,017][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.5267, 0.0587, 0.0574, 0.0786, 0.0722, 0.1610, 0.0453],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,017][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.9734, 0.0062, 0.0038, 0.0048, 0.0048, 0.0058, 0.0013],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,022][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2136, 0.0899, 0.0732, 0.1903, 0.1322, 0.2402, 0.0607],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,025][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.9788, 0.0041, 0.0057, 0.0028, 0.0029, 0.0034, 0.0022],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,025][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1718, 0.0785, 0.0964, 0.1724, 0.1265, 0.2353, 0.1190],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,026][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.6225, 0.0428, 0.0229, 0.1046, 0.0499, 0.1395, 0.0180],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,027][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0078, 0.1807, 0.1969, 0.1923, 0.1029, 0.1443, 0.1751],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,028][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.3160, 0.1260, 0.1812, 0.0909, 0.0981, 0.0877, 0.1001],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,032][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1267, 0.1049, 0.1369, 0.1966, 0.2285, 0.1617, 0.0447],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,035][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.1887, 0.0765, 0.1017, 0.1221, 0.1117, 0.2458, 0.0644, 0.0892],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,036][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0708, 0.0426, 0.0410, 0.2313, 0.1299, 0.3536, 0.0699, 0.0609],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,036][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.1483, 0.0602, 0.1113, 0.1253, 0.1386, 0.1365, 0.1871, 0.0927],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,037][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.2923, 0.0601, 0.0762, 0.1007, 0.1117, 0.2200, 0.0797, 0.0594],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,038][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.9489, 0.0093, 0.0078, 0.0072, 0.0113, 0.0078, 0.0031, 0.0046],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,042][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.1366, 0.0808, 0.0770, 0.1874, 0.1490, 0.2308, 0.0849, 0.0536],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,045][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.9407, 0.0106, 0.0114, 0.0068, 0.0078, 0.0080, 0.0056, 0.0092],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,046][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0803, 0.0700, 0.0766, 0.1739, 0.1272, 0.2248, 0.1499, 0.0973],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,047][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.4165, 0.0478, 0.0359, 0.1369, 0.0746, 0.1871, 0.0554, 0.0458],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,047][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0056, 0.0898, 0.1435, 0.1844, 0.0809, 0.1510, 0.2224, 0.1225],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,048][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.1694, 0.1314, 0.1446, 0.0872, 0.0940, 0.1027, 0.1172, 0.1536],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,053][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0700, 0.0776, 0.1174, 0.1734, 0.2088, 0.1951, 0.0762, 0.0817],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,055][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.3949, 0.0637, 0.0581, 0.0906, 0.0737, 0.1756, 0.0334, 0.0621, 0.0478],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,056][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.1020, 0.0504, 0.0309, 0.1966, 0.0979, 0.3502, 0.0562, 0.0482, 0.0676],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,057][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.2181, 0.0551, 0.1034, 0.1022, 0.1175, 0.1146, 0.1557, 0.0691, 0.0644],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,058][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.5271, 0.0452, 0.0478, 0.0645, 0.0648, 0.1356, 0.0404, 0.0399, 0.0347],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,058][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.9647, 0.0068, 0.0049, 0.0052, 0.0057, 0.0068, 0.0016, 0.0031, 0.0012],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,063][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.2222, 0.0709, 0.0617, 0.1681, 0.1206, 0.2115, 0.0556, 0.0348, 0.0545],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,065][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.9673, 0.0049, 0.0074, 0.0035, 0.0038, 0.0039, 0.0025, 0.0037, 0.0030],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,066][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.1253, 0.0586, 0.0807, 0.1309, 0.1030, 0.2007, 0.0956, 0.0892, 0.1159],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,067][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.6726, 0.0300, 0.0159, 0.0786, 0.0440, 0.1054, 0.0141, 0.0201, 0.0193],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,068][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0030, 0.0736, 0.1621, 0.1104, 0.0812, 0.1122, 0.1449, 0.1186, 0.1941],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,069][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.1989, 0.1057, 0.1558, 0.0802, 0.0903, 0.0686, 0.0886, 0.1180, 0.0940],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,074][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.1214, 0.0734, 0.1162, 0.1653, 0.2295, 0.1177, 0.0426, 0.0592, 0.0746],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,076][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.3261, 0.0549, 0.0468, 0.0683, 0.0588, 0.1580, 0.0327, 0.0583, 0.0645,
        0.1317], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,076][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.1093, 0.0427, 0.0262, 0.1598, 0.0685, 0.3020, 0.0573, 0.0461, 0.0777,
        0.1106], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,077][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.2007, 0.0532, 0.0832, 0.1147, 0.0978, 0.1141, 0.1358, 0.0600, 0.0683,
        0.0722], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,078][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.4077, 0.0555, 0.0499, 0.0762, 0.0730, 0.1315, 0.0444, 0.0411, 0.0431,
        0.0776], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,079][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.9526, 0.0105, 0.0043, 0.0069, 0.0074, 0.0084, 0.0024, 0.0032, 0.0018,
        0.0026], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,084][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.1643, 0.0649, 0.0552, 0.1626, 0.1054, 0.1934, 0.0562, 0.0390, 0.0579,
        0.1011], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,086][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.9666, 0.0054, 0.0065, 0.0031, 0.0038, 0.0038, 0.0024, 0.0036, 0.0022,
        0.0026], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,087][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0877, 0.0545, 0.0468, 0.1069, 0.0681, 0.1603, 0.1052, 0.0759, 0.1243,
        0.1704], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,087][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.6215, 0.0258, 0.0143, 0.0748, 0.0381, 0.1149, 0.0182, 0.0197, 0.0333,
        0.0395], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,088][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0072, 0.0813, 0.0997, 0.1183, 0.0722, 0.1176, 0.1266, 0.0837, 0.1763,
        0.1170], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,089][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.1551, 0.0886, 0.1199, 0.0639, 0.0674, 0.0741, 0.0858, 0.1096, 0.0908,
        0.1447], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,094][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0964, 0.0573, 0.0603, 0.1247, 0.1270, 0.1209, 0.0446, 0.0513, 0.0948,
        0.2227], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,096][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.3332, 0.0620, 0.0461, 0.0618, 0.0530, 0.1243, 0.0238, 0.0481, 0.0435,
        0.1188, 0.0855], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,097][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0867, 0.0435, 0.0274, 0.1516, 0.0750, 0.2489, 0.0559, 0.0405, 0.0818,
        0.0954, 0.0934], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,098][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1725, 0.0516, 0.0772, 0.0994, 0.0849, 0.1043, 0.1277, 0.0496, 0.0579,
        0.0682, 0.1067], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,098][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.3596, 0.0516, 0.0514, 0.0678, 0.0770, 0.1328, 0.0434, 0.0351, 0.0368,
        0.0741, 0.0705], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,099][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([9.6915e-01, 7.0627e-03, 2.4742e-03, 3.4591e-03, 4.1863e-03, 4.1000e-03,
        1.0801e-03, 1.7228e-03, 8.8961e-04, 1.6808e-03, 4.1983e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,104][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.1678, 0.0625, 0.0474, 0.1570, 0.0890, 0.1723, 0.0477, 0.0335, 0.0461,
        0.0822, 0.0947], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,106][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.9519, 0.0068, 0.0091, 0.0043, 0.0050, 0.0051, 0.0032, 0.0041, 0.0025,
        0.0025, 0.0055], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,107][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0997, 0.0457, 0.0478, 0.1109, 0.0666, 0.1296, 0.0803, 0.0609, 0.0967,
        0.1429, 0.1190], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,108][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.6410, 0.0283, 0.0133, 0.0777, 0.0343, 0.0849, 0.0146, 0.0175, 0.0256,
        0.0308, 0.0321], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,109][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0023, 0.0755, 0.1011, 0.0892, 0.0619, 0.0872, 0.0978, 0.0721, 0.1791,
        0.1252, 0.1087], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,110][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.1480, 0.0912, 0.0943, 0.0702, 0.0575, 0.0641, 0.0887, 0.1002, 0.0851,
        0.1255, 0.0752], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,116][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0811, 0.0518, 0.0687, 0.1055, 0.1223, 0.1030, 0.0384, 0.0422, 0.0754,
        0.1935, 0.1182], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,117][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.4610, 0.0436, 0.0403, 0.0492, 0.0409, 0.0834, 0.0139, 0.0290, 0.0251,
        0.0537, 0.0496, 0.1103], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,118][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1523, 0.0406, 0.0286, 0.1549, 0.0704, 0.2389, 0.0327, 0.0234, 0.0490,
        0.0523, 0.0533, 0.1036], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,118][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1870, 0.0434, 0.0695, 0.0794, 0.0777, 0.0786, 0.0994, 0.0434, 0.0459,
        0.0528, 0.0863, 0.1365], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,119][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.4542, 0.0411, 0.0374, 0.0516, 0.0528, 0.0997, 0.0277, 0.0250, 0.0243,
        0.0471, 0.0503, 0.0888], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,122][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([9.7275e-01, 5.1528e-03, 1.9975e-03, 2.8461e-03, 2.9551e-03, 3.4878e-03,
        7.5932e-04, 1.2905e-03, 6.4410e-04, 1.1222e-03, 2.9605e-03, 4.0305e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,126][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.2333, 0.0597, 0.0417, 0.1201, 0.0789, 0.1376, 0.0318, 0.0210, 0.0276,
        0.0470, 0.0583, 0.1431], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,127][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.9476, 0.0072, 0.0080, 0.0042, 0.0040, 0.0050, 0.0030, 0.0041, 0.0025,
        0.0025, 0.0044, 0.0076], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,128][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1497, 0.0442, 0.0429, 0.0904, 0.0590, 0.1068, 0.0530, 0.0466, 0.0646,
        0.0978, 0.0891, 0.1558], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,129][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.8274, 0.0154, 0.0066, 0.0335, 0.0150, 0.0310, 0.0039, 0.0052, 0.0064,
        0.0074, 0.0091, 0.0390], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,129][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0016, 0.0728, 0.0879, 0.0907, 0.0415, 0.0717, 0.0826, 0.0662, 0.1868,
        0.0924, 0.1189, 0.0870], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,135][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.2076, 0.0753, 0.0929, 0.0544, 0.0612, 0.0570, 0.0696, 0.0891, 0.0683,
        0.0982, 0.0584, 0.0680], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,136][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1630, 0.0536, 0.0641, 0.1010, 0.1082, 0.0794, 0.0197, 0.0285, 0.0405,
        0.0917, 0.0748, 0.1757], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,137][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.3730, 0.0348, 0.0214, 0.0416, 0.0280, 0.0667, 0.0128, 0.0259, 0.0208,
        0.0492, 0.0468, 0.1167, 0.1623], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,138][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.1220, 0.0219, 0.0161, 0.1048, 0.0468, 0.1710, 0.0248, 0.0186, 0.0388,
        0.0624, 0.0668, 0.1445, 0.1616], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,139][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.1562, 0.0380, 0.0617, 0.0778, 0.0803, 0.0754, 0.0881, 0.0483, 0.0449,
        0.0534, 0.0771, 0.1292, 0.0696], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,142][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.4586, 0.0397, 0.0308, 0.0464, 0.0441, 0.0964, 0.0202, 0.0203, 0.0212,
        0.0342, 0.0405, 0.0743, 0.0735], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,146][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.9475, 0.0069, 0.0037, 0.0045, 0.0064, 0.0058, 0.0016, 0.0030, 0.0012,
        0.0021, 0.0058, 0.0074, 0.0040], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,147][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.1578, 0.0353, 0.0319, 0.1089, 0.0638, 0.1160, 0.0311, 0.0216, 0.0297,
        0.0501, 0.0620, 0.1586, 0.1332], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,148][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.9525, 0.0059, 0.0085, 0.0032, 0.0039, 0.0041, 0.0021, 0.0033, 0.0020,
        0.0021, 0.0033, 0.0050, 0.0042], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,149][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0987, 0.0403, 0.0361, 0.0574, 0.0461, 0.0791, 0.0448, 0.0398, 0.0581,
        0.0840, 0.0710, 0.1357, 0.2089], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,150][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.7359, 0.0118, 0.0055, 0.0353, 0.0130, 0.0344, 0.0046, 0.0066, 0.0085,
        0.0114, 0.0135, 0.0619, 0.0575], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,155][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.0032, 0.0392, 0.0744, 0.0740, 0.0245, 0.0742, 0.0888, 0.0547, 0.1555,
        0.0663, 0.1490, 0.1350, 0.0613], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,157][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.1140, 0.0780, 0.0961, 0.0476, 0.0654, 0.0483, 0.0686, 0.0927, 0.0680,
        0.0998, 0.0599, 0.0710, 0.0906], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,157][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.1092, 0.0249, 0.0346, 0.0572, 0.0605, 0.0428, 0.0120, 0.0169, 0.0265,
        0.0684, 0.0574, 0.1517, 0.3377], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,158][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.3439, 0.0473, 0.0307, 0.0461, 0.0315, 0.0726, 0.0094, 0.0190, 0.0161,
        0.0409, 0.0359, 0.1022, 0.1681, 0.0363], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,159][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0879, 0.0404, 0.0215, 0.1302, 0.0497, 0.2134, 0.0238, 0.0157, 0.0274,
        0.0353, 0.0381, 0.0868, 0.1273, 0.1026], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,162][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1707, 0.0367, 0.0519, 0.0629, 0.0622, 0.0696, 0.0817, 0.0358, 0.0351,
        0.0474, 0.0695, 0.1175, 0.0630, 0.0959], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,166][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.3068, 0.0420, 0.0357, 0.0580, 0.0457, 0.1154, 0.0260, 0.0235, 0.0220,
        0.0460, 0.0472, 0.0967, 0.0939, 0.0410], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,167][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.9482, 0.0091, 0.0034, 0.0053, 0.0047, 0.0069, 0.0012, 0.0020, 0.0010,
        0.0021, 0.0050, 0.0057, 0.0029, 0.0025], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,168][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1687, 0.0565, 0.0380, 0.1049, 0.0726, 0.1123, 0.0229, 0.0168, 0.0209,
        0.0361, 0.0466, 0.1158, 0.1133, 0.0745], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,169][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.9563, 0.0053, 0.0069, 0.0029, 0.0033, 0.0033, 0.0018, 0.0025, 0.0015,
        0.0017, 0.0028, 0.0043, 0.0028, 0.0046], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,170][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0635, 0.0356, 0.0368, 0.0777, 0.0465, 0.1011, 0.0402, 0.0338, 0.0499,
        0.0674, 0.0628, 0.1212, 0.1863, 0.0771], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,176][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.6678, 0.0243, 0.0091, 0.0545, 0.0210, 0.0525, 0.0048, 0.0062, 0.0077,
        0.0093, 0.0108, 0.0568, 0.0576, 0.0176], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,177][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0010, 0.0596, 0.0814, 0.0677, 0.0413, 0.0559, 0.0702, 0.0445, 0.1284,
        0.0753, 0.0879, 0.0790, 0.0641, 0.1437], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,178][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1104, 0.0841, 0.1048, 0.0599, 0.0504, 0.0498, 0.0569, 0.0771, 0.0612,
        0.0906, 0.0583, 0.0648, 0.0688, 0.0630], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,179][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0910, 0.0440, 0.0475, 0.0829, 0.0703, 0.0535, 0.0121, 0.0172, 0.0216,
        0.0557, 0.0459, 0.1177, 0.2654, 0.0752], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,180][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.1617, 0.0244, 0.0204, 0.0227, 0.0211, 0.0483, 0.0145, 0.0293, 0.0308,
        0.0694, 0.0631, 0.1264, 0.2204, 0.0717, 0.0758], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,185][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0408, 0.0179, 0.0131, 0.0556, 0.0318, 0.1052, 0.0293, 0.0255, 0.0487,
        0.0493, 0.0725, 0.1340, 0.1820, 0.1280, 0.0663], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,187][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.0869, 0.0314, 0.0505, 0.0630, 0.0570, 0.0641, 0.0821, 0.0366, 0.0422,
        0.0499, 0.0708, 0.1117, 0.0719, 0.1024, 0.0798], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,188][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.1930, 0.0341, 0.0309, 0.0397, 0.0350, 0.0919, 0.0311, 0.0331, 0.0316,
        0.0561, 0.0641, 0.1011, 0.1136, 0.0566, 0.0880], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,189][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.7702, 0.0230, 0.0125, 0.0153, 0.0215, 0.0215, 0.0060, 0.0083, 0.0050,
        0.0098, 0.0191, 0.0186, 0.0140, 0.0085, 0.0466], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,189][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.0725, 0.0252, 0.0235, 0.0553, 0.0431, 0.0764, 0.0327, 0.0259, 0.0356,
        0.0609, 0.0700, 0.1328, 0.1489, 0.1168, 0.0804], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,194][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.8182, 0.0125, 0.0210, 0.0082, 0.0119, 0.0104, 0.0066, 0.0082, 0.0054,
        0.0062, 0.0090, 0.0132, 0.0094, 0.0135, 0.0463], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,197][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0318, 0.0262, 0.0200, 0.0356, 0.0236, 0.0607, 0.0510, 0.0405, 0.0615,
        0.0821, 0.0787, 0.1409, 0.1899, 0.0963, 0.0611], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,198][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.3638, 0.0156, 0.0082, 0.0337, 0.0167, 0.0390, 0.0134, 0.0156, 0.0199,
        0.0320, 0.0375, 0.1130, 0.1692, 0.0543, 0.0680], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,198][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.0012, 0.0418, 0.0389, 0.0818, 0.0231, 0.0573, 0.0681, 0.0317, 0.1380,
        0.0658, 0.1127, 0.0871, 0.0938, 0.1379, 0.0209], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,199][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0750, 0.0630, 0.0737, 0.0489, 0.0573, 0.0476, 0.0606, 0.0732, 0.0704,
        0.0949, 0.0615, 0.0620, 0.0873, 0.0537, 0.0710], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,202][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0372, 0.0127, 0.0182, 0.0274, 0.0253, 0.0290, 0.0145, 0.0215, 0.0351,
        0.0738, 0.0665, 0.1319, 0.3027, 0.1134, 0.0909], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,207][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.3128, 0.0318, 0.0237, 0.0312, 0.0221, 0.0478, 0.0073, 0.0141, 0.0145,
        0.0227, 0.0258, 0.0652, 0.1077, 0.0282, 0.0402, 0.2050],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,208][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.1123, 0.0253, 0.0102, 0.0810, 0.0325, 0.0949, 0.0183, 0.0152, 0.0226,
        0.0300, 0.0322, 0.0808, 0.0781, 0.0928, 0.0373, 0.2366],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,208][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1158, 0.0341, 0.0510, 0.0637, 0.0543, 0.0614, 0.0680, 0.0308, 0.0339,
        0.0390, 0.0619, 0.0902, 0.0578, 0.0859, 0.0682, 0.0841],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,209][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.3508, 0.0295, 0.0233, 0.0362, 0.0326, 0.0604, 0.0200, 0.0183, 0.0173,
        0.0308, 0.0357, 0.0676, 0.0618, 0.0302, 0.0597, 0.1258],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,212][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.9064, 0.0087, 0.0049, 0.0059, 0.0069, 0.0071, 0.0018, 0.0030, 0.0016,
        0.0028, 0.0068, 0.0075, 0.0047, 0.0033, 0.0179, 0.0107],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,217][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.1651, 0.0337, 0.0250, 0.0733, 0.0475, 0.0713, 0.0173, 0.0131, 0.0159,
        0.0243, 0.0317, 0.0793, 0.0680, 0.0559, 0.0465, 0.2320],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,218][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.8859, 0.0098, 0.0097, 0.0051, 0.0055, 0.0059, 0.0037, 0.0050, 0.0029,
        0.0039, 0.0054, 0.0084, 0.0053, 0.0079, 0.0206, 0.0150],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,218][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0872, 0.0294, 0.0230, 0.0538, 0.0273, 0.0561, 0.0331, 0.0264, 0.0385,
        0.0479, 0.0576, 0.1012, 0.1283, 0.0702, 0.0497, 0.1702],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,219][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.7392, 0.0108, 0.0043, 0.0264, 0.0096, 0.0231, 0.0029, 0.0036, 0.0042,
        0.0040, 0.0060, 0.0309, 0.0213, 0.0107, 0.0183, 0.0847],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,222][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0015, 0.0425, 0.0525, 0.0650, 0.0319, 0.0587, 0.0828, 0.0423, 0.1096,
        0.0723, 0.1033, 0.0823, 0.0627, 0.1452, 0.0229, 0.0244],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,227][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.1093, 0.0566, 0.0730, 0.0456, 0.0477, 0.0435, 0.0612, 0.0684, 0.0581,
        0.0845, 0.0515, 0.0626, 0.0625, 0.0566, 0.0612, 0.0578],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,228][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.1492, 0.0274, 0.0272, 0.0553, 0.0455, 0.0311, 0.0090, 0.0130, 0.0164,
        0.0287, 0.0278, 0.0841, 0.1373, 0.0507, 0.0738, 0.2236],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,229][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4058, 0.0210, 0.0155, 0.0236, 0.0151, 0.0351, 0.0039, 0.0085, 0.0078,
        0.0148, 0.0149, 0.0419, 0.0684, 0.0153, 0.0268, 0.1504, 0.1311],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,229][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1788, 0.0136, 0.0068, 0.0576, 0.0231, 0.0585, 0.0080, 0.0101, 0.0124,
        0.0158, 0.0171, 0.0430, 0.0561, 0.0480, 0.0246, 0.1660, 0.2605],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,232][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1476, 0.0294, 0.0454, 0.0503, 0.0478, 0.0504, 0.0557, 0.0250, 0.0250,
        0.0304, 0.0498, 0.0781, 0.0494, 0.0664, 0.0617, 0.0772, 0.1103],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,237][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.4107, 0.0230, 0.0177, 0.0306, 0.0246, 0.0523, 0.0118, 0.0107, 0.0102,
        0.0202, 0.0220, 0.0452, 0.0424, 0.0195, 0.0410, 0.1194, 0.0987],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,238][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([9.5586e-01, 4.0823e-03, 1.6594e-03, 2.5731e-03, 2.8200e-03, 3.1156e-03,
        6.7710e-04, 1.1767e-03, 5.4422e-04, 1.0273e-03, 2.7451e-03, 3.5957e-03,
        1.4462e-03, 1.2424e-03, 7.5940e-03, 5.7646e-03, 4.0713e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,239][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2244, 0.0309, 0.0184, 0.0592, 0.0338, 0.0541, 0.0098, 0.0070, 0.0087,
        0.0138, 0.0192, 0.0511, 0.0449, 0.0336, 0.0310, 0.1795, 0.1806],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,239][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.9304, 0.0050, 0.0053, 0.0030, 0.0027, 0.0038, 0.0024, 0.0031, 0.0018,
        0.0018, 0.0034, 0.0048, 0.0029, 0.0044, 0.0115, 0.0078, 0.0058],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,241][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1130, 0.0219, 0.0185, 0.0524, 0.0259, 0.0499, 0.0191, 0.0170, 0.0231,
        0.0301, 0.0312, 0.0656, 0.0879, 0.0411, 0.0381, 0.1640, 0.2013],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,248][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.8079, 0.0059, 0.0022, 0.0152, 0.0053, 0.0120, 0.0008, 0.0014, 0.0016,
        0.0014, 0.0021, 0.0122, 0.0105, 0.0042, 0.0083, 0.0576, 0.0515],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,250][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0014, 0.0420, 0.0470, 0.0573, 0.0281, 0.0459, 0.0515, 0.0546, 0.0944,
        0.0773, 0.0851, 0.0726, 0.0566, 0.1618, 0.0309, 0.0387, 0.0549],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,251][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1483, 0.0457, 0.0637, 0.0378, 0.0406, 0.0398, 0.0496, 0.0683, 0.0519,
        0.0734, 0.0472, 0.0524, 0.0561, 0.0478, 0.0583, 0.0553, 0.0638],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,252][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1569, 0.0200, 0.0170, 0.0406, 0.0306, 0.0245, 0.0044, 0.0069, 0.0094,
        0.0163, 0.0169, 0.0462, 0.0934, 0.0295, 0.0431, 0.2154, 0.2291],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,253][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.3236, 0.0109, 0.0058, 0.0114, 0.0077, 0.0183, 0.0029, 0.0063, 0.0053,
        0.0099, 0.0116, 0.0343, 0.0508, 0.0151, 0.0196, 0.1362, 0.1412, 0.1891],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,257][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.0912, 0.0073, 0.0042, 0.0338, 0.0136, 0.0302, 0.0057, 0.0060, 0.0093,
        0.0098, 0.0157, 0.0352, 0.0515, 0.0402, 0.0199, 0.1450, 0.2638, 0.2178],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,260][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.1413, 0.0289, 0.0344, 0.0613, 0.0397, 0.0531, 0.0490, 0.0222, 0.0290,
        0.0260, 0.0480, 0.0731, 0.0452, 0.0639, 0.0536, 0.0708, 0.1028, 0.0577],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,261][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.4107, 0.0171, 0.0120, 0.0204, 0.0162, 0.0350, 0.0080, 0.0093, 0.0078,
        0.0135, 0.0160, 0.0368, 0.0327, 0.0154, 0.0332, 0.1062, 0.0902, 0.1197],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,262][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.8910, 0.0078, 0.0047, 0.0060, 0.0081, 0.0067, 0.0017, 0.0033, 0.0013,
        0.0021, 0.0064, 0.0075, 0.0041, 0.0026, 0.0196, 0.0129, 0.0088, 0.0054],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,262][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.1350, 0.0130, 0.0091, 0.0360, 0.0210, 0.0340, 0.0080, 0.0062, 0.0081,
        0.0117, 0.0182, 0.0450, 0.0420, 0.0332, 0.0258, 0.1766, 0.2020, 0.1753],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,267][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.9159, 0.0053, 0.0063, 0.0029, 0.0039, 0.0036, 0.0021, 0.0034, 0.0017,
        0.0021, 0.0034, 0.0053, 0.0034, 0.0044, 0.0162, 0.0093, 0.0058, 0.0050],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,270][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0623, 0.0167, 0.0134, 0.0323, 0.0150, 0.0318, 0.0176, 0.0132, 0.0220,
        0.0245, 0.0296, 0.0594, 0.0792, 0.0377, 0.0278, 0.1273, 0.2007, 0.1895],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,271][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.7445, 0.0028, 0.0009, 0.0092, 0.0027, 0.0072, 0.0008, 0.0010, 0.0016,
        0.0012, 0.0019, 0.0113, 0.0093, 0.0046, 0.0070, 0.0685, 0.0760, 0.0495],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,272][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.0049, 0.0361, 0.0373, 0.0590, 0.0299, 0.0535, 0.0640, 0.0397, 0.1003,
        0.0645, 0.0916, 0.0868, 0.0502, 0.1026, 0.0288, 0.0370, 0.0636, 0.0501],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,273][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.1177, 0.0478, 0.0672, 0.0406, 0.0428, 0.0407, 0.0481, 0.0603, 0.0441,
        0.0623, 0.0421, 0.0512, 0.0581, 0.0467, 0.0703, 0.0573, 0.0567, 0.0461],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,277][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0770, 0.0038, 0.0045, 0.0099, 0.0086, 0.0059, 0.0018, 0.0032, 0.0036,
        0.0075, 0.0079, 0.0265, 0.0416, 0.0171, 0.0194, 0.1016, 0.1572, 0.5029],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,280][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2403, 0.0137, 0.0067, 0.0136, 0.0088, 0.0191, 0.0032, 0.0063, 0.0049,
        0.0118, 0.0113, 0.0327, 0.0511, 0.0130, 0.0179, 0.1374, 0.1401, 0.1964,
        0.0717], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,281][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0492, 0.0096, 0.0033, 0.0305, 0.0099, 0.0448, 0.0068, 0.0049, 0.0086,
        0.0098, 0.0114, 0.0322, 0.0326, 0.0376, 0.0108, 0.1408, 0.3032, 0.1501,
        0.1038], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,282][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1526, 0.0247, 0.0328, 0.0439, 0.0365, 0.0435, 0.0439, 0.0231, 0.0194,
        0.0237, 0.0383, 0.0667, 0.0357, 0.0553, 0.0465, 0.0684, 0.0960, 0.0659,
        0.0828], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,283][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2725, 0.0163, 0.0118, 0.0200, 0.0183, 0.0366, 0.0102, 0.0090, 0.0083,
        0.0165, 0.0189, 0.0395, 0.0381, 0.0174, 0.0340, 0.1012, 0.1052, 0.1522,
        0.0741], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,284][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.4283e-01, 4.8909e-03, 1.8606e-03, 3.0120e-03, 2.9564e-03, 4.2699e-03,
        8.1727e-04, 1.4217e-03, 6.6814e-04, 1.1316e-03, 3.1193e-03, 3.8497e-03,
        1.5519e-03, 1.6812e-03, 7.9446e-03, 6.5923e-03, 4.9849e-03, 3.2328e-03,
        3.1853e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,290][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1289, 0.0164, 0.0094, 0.0354, 0.0192, 0.0340, 0.0076, 0.0055, 0.0065,
        0.0115, 0.0154, 0.0447, 0.0358, 0.0293, 0.0208, 0.1535, 0.1758, 0.1610,
        0.0892], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,291][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.9400, 0.0040, 0.0049, 0.0023, 0.0022, 0.0026, 0.0014, 0.0020, 0.0013,
        0.0012, 0.0024, 0.0034, 0.0027, 0.0033, 0.0099, 0.0060, 0.0038, 0.0028,
        0.0038], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,292][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0650, 0.0126, 0.0096, 0.0269, 0.0137, 0.0295, 0.0132, 0.0121, 0.0167,
        0.0210, 0.0227, 0.0474, 0.0625, 0.0300, 0.0238, 0.1312, 0.1600, 0.1924,
        0.1098], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,293][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.6531, 0.0042, 0.0014, 0.0119, 0.0040, 0.0120, 0.0011, 0.0014, 0.0017,
        0.0017, 0.0025, 0.0154, 0.0127, 0.0051, 0.0073, 0.0739, 0.0891, 0.0595,
        0.0421], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,297][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0016, 0.0426, 0.0635, 0.0419, 0.0269, 0.0554, 0.0460, 0.0435, 0.0620,
        0.0537, 0.0676, 0.0611, 0.0446, 0.1228, 0.0253, 0.0377, 0.0547, 0.0862,
        0.0630], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,300][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1321, 0.0544, 0.0620, 0.0425, 0.0387, 0.0355, 0.0443, 0.0590, 0.0445,
        0.0630, 0.0414, 0.0493, 0.0475, 0.0454, 0.0525, 0.0458, 0.0572, 0.0371,
        0.0477], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,301][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0523, 0.0047, 0.0048, 0.0112, 0.0093, 0.0073, 0.0019, 0.0027, 0.0033,
        0.0071, 0.0062, 0.0213, 0.0402, 0.0138, 0.0157, 0.0942, 0.1387, 0.4681,
        0.0971], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,304][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:57,308][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 8153],
        [ 6126],
        [20771],
        [11823],
        [ 9488],
        [10492],
        [ 7618],
        [ 7431],
        [ 3855],
        [ 5035],
        [ 7475],
        [ 5323],
        [ 7027],
        [  851],
        [ 3007],
        [ 7928],
        [ 1608],
        [ 6018],
        [ 1078]], device='cuda:0')
[2024-07-24 10:17:57,311][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 8895],
        [11452],
        [27455],
        [25198],
        [19292],
        [29689],
        [20465],
        [17802],
        [19006],
        [10200],
        [18705],
        [16617],
        [21190],
        [ 8428],
        [ 9837],
        [14581],
        [ 8179],
        [20470],
        [ 9904]], device='cuda:0')
[2024-07-24 10:17:57,313][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[19101],
        [18934],
        [19043],
        [18824],
        [18996],
        [18920],
        [19051],
        [19081],
        [19057],
        [19082],
        [19072],
        [19072],
        [19085],
        [19083],
        [19082],
        [19081],
        [19090],
        [19089],
        [19082]], device='cuda:0')
[2024-07-24 10:17:57,314][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[6804],
        [4571],
        [1704],
        [3179],
        [2147],
        [2269],
        [2135],
        [2032],
        [2125],
        [2264],
        [2162],
        [2108],
        [2027],
        [2137],
        [2104],
        [2064],
        [2225],
        [1992],
        [2082]], device='cuda:0')
[2024-07-24 10:17:57,317][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[6961],
        [8552],
        [8253],
        [7961],
        [6816],
        [7041],
        [7112],
        [7357],
        [7370],
        [6945],
        [6890],
        [7014],
        [6683],
        [6455],
        [6181],
        [5913],
        [5889],
        [5722],
        [5629]], device='cuda:0')
[2024-07-24 10:17:57,320][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 8017],
        [ 9701],
        [14942],
        [12243],
        [14204],
        [15888],
        [13678],
        [14607],
        [13644],
        [14772],
        [14388],
        [14472],
        [15645],
        [16212],
        [17782],
        [17136],
        [16963],
        [15472],
        [17343]], device='cuda:0')
[2024-07-24 10:17:57,323][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 7471],
        [10962],
        [ 1720],
        [ 2829],
        [ 1916],
        [ 2144],
        [ 2269],
        [ 2464],
        [ 2861],
        [ 2607],
        [ 2641],
        [ 2711],
        [ 2696],
        [ 2883],
        [ 2517],
        [ 2551],
        [ 2569],
        [ 2361],
        [ 2503]], device='cuda:0')
[2024-07-24 10:17:57,325][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[4385],
        [2471],
        [4138],
        [4982],
        [3929],
        [4510],
        [4641],
        [4570],
        [4358],
        [4820],
        [4846],
        [5231],
        [6557],
        [5840],
        [7290],
        [5484],
        [5281],
        [4928],
        [4560]], device='cuda:0')
[2024-07-24 10:17:57,326][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[15403],
        [ 5185],
        [24003],
        [10114],
        [15319],
        [12080],
        [ 7842],
        [ 5939],
        [ 5483],
        [ 6581],
        [ 7007],
        [ 5742],
        [ 4742],
        [ 5504],
        [ 6172],
        [ 5595],
        [ 5088],
        [ 6446],
        [ 6451]], device='cuda:0')
[2024-07-24 10:17:57,328][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 3823],
        [ 3846],
        [ 8947],
        [  855],
        [11281],
        [ 5251],
        [ 3291],
        [16947],
        [ 7340],
        [20916],
        [18095],
        [20521],
        [24302],
        [20336],
        [23459],
        [21154],
        [19013],
        [23158],
        [21075]], device='cuda:0')
[2024-07-24 10:17:57,332][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 8661],
        [10769],
        [ 9281],
        [ 9185],
        [ 8939],
        [ 8693],
        [10232],
        [12760],
        [ 9862],
        [11395],
        [11981],
        [10071],
        [13365],
        [14177],
        [23966],
        [13744],
        [13208],
        [15468],
        [18446]], device='cuda:0')
[2024-07-24 10:17:57,335][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[17312],
        [23395],
        [49976],
        [50044],
        [49577],
        [49140],
        [48198],
        [46030],
        [46949],
        [43102],
        [41268],
        [39336],
        [34385],
        [37870],
        [33091],
        [35177],
        [34894],
        [32194],
        [33950]], device='cuda:0')
[2024-07-24 10:17:57,336][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[4608],
        [1416],
        [4014],
        [1920],
        [1384],
        [ 519],
        [ 729],
        [ 611],
        [ 743],
        [ 584],
        [ 713],
        [ 815],
        [ 628],
        [ 911],
        [ 790],
        [ 662],
        [ 780],
        [ 777],
        [ 936]], device='cuda:0')
[2024-07-24 10:17:57,338][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[21450],
        [38947],
        [37820],
        [37213],
        [36919],
        [37029],
        [34769],
        [33667],
        [33817],
        [35655],
        [34473],
        [32239],
        [29283],
        [29875],
        [28896],
        [28486],
        [25469],
        [27770],
        [27646]], device='cuda:0')
[2024-07-24 10:17:57,340][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[18556],
        [43492],
        [31883],
        [22228],
        [27853],
        [14768],
        [27465],
        [12581],
        [27607],
        [23952],
        [20560],
        [24779],
        [30614],
        [22856],
        [23482],
        [22559],
        [21381],
        [24773],
        [18256]], device='cuda:0')
[2024-07-24 10:17:57,343][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[22041],
        [14131],
        [10119],
        [11223],
        [ 6265],
        [ 4165],
        [ 5857],
        [12277],
        [ 8791],
        [11747],
        [14678],
        [12647],
        [18263],
        [17634],
        [28376],
        [14738],
        [13898],
        [16113],
        [19070]], device='cuda:0')
[2024-07-24 10:17:57,346][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[39239],
        [29703],
        [14501],
        [13257],
        [17982],
        [27039],
        [23583],
        [23118],
        [24844],
        [26540],
        [28450],
        [28166],
        [33298],
        [29581],
        [33975],
        [34590],
        [34740],
        [39741],
        [36188]], device='cuda:0')
[2024-07-24 10:17:57,348][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[9511],
        [5753],
        [3145],
        [3460],
        [3117],
        [2922],
        [2827],
        [2556],
        [2472],
        [2294],
        [2267],
        [2287],
        [2216],
        [2398],
        [2073],
        [2053],
        [1700],
        [1937],
        [1846]], device='cuda:0')
[2024-07-24 10:17:57,349][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[13287],
        [21243],
        [20730],
        [23044],
        [31387],
        [34585],
        [35893],
        [35732],
        [36555],
        [38128],
        [38416],
        [38636],
        [40182],
        [39879],
        [41161],
        [41598],
        [40895],
        [41843],
        [41427]], device='cuda:0')
[2024-07-24 10:17:57,351][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[20374],
        [20420],
        [19944],
        [20210],
        [18843],
        [19683],
        [19878],
        [19000],
        [19586],
        [19220],
        [19711],
        [19948],
        [19197],
        [19289],
        [15699],
        [17854],
        [19679],
        [17536],
        [19235]], device='cuda:0')
[2024-07-24 10:17:57,355][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[8385],
        [3992],
        [1667],
        [1999],
        [2403],
        [2317],
        [5157],
        [5600],
        [4639],
        [4323],
        [4069],
        [2731],
        [2372],
        [2398],
        [2364],
        [2849],
        [3383],
        [2838],
        [3194]], device='cuda:0')
[2024-07-24 10:17:57,358][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[48185],
        [48244],
        [48308],
        [48252],
        [48334],
        [48281],
        [48300],
        [48383],
        [48416],
        [48435],
        [48455],
        [48443],
        [48488],
        [48505],
        [45024],
        [47749],
        [48464],
        [48385],
        [48544]], device='cuda:0')
[2024-07-24 10:17:57,359][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[46506],
        [19979],
        [16253],
        [21360],
        [17892],
        [19906],
        [20133],
        [20502],
        [21915],
        [23370],
        [25618],
        [26204],
        [25572],
        [25192],
        [27111],
        [26181],
        [26283],
        [25445],
        [26394]], device='cuda:0')
[2024-07-24 10:17:57,361][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[17817],
        [11901],
        [14460],
        [13952],
        [14661],
        [15490],
        [30096],
        [40081],
        [27726],
        [32734],
        [30172],
        [18311],
        [24205],
        [27186],
        [38480],
        [23893],
        [19254],
        [24607],
        [29020]], device='cuda:0')
[2024-07-24 10:17:57,363][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[35068],
        [20474],
        [26463],
        [26728],
        [27351],
        [26927],
        [26208],
        [23695],
        [21034],
        [20504],
        [21054],
        [21299],
        [22210],
        [22693],
        [22612],
        [22595],
        [22356],
        [23393],
        [25063]], device='cuda:0')
[2024-07-24 10:17:57,366][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[27166],
        [27316],
        [23044],
        [20957],
        [26191],
        [25695],
        [26605],
        [33989],
        [35002],
        [36126],
        [36130],
        [36202],
        [36879],
        [35588],
        [37107],
        [37264],
        [37865],
        [38602],
        [38756]], device='cuda:0')
[2024-07-24 10:17:57,369][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[24924],
        [10638],
        [17592],
        [20847],
        [18907],
        [19645],
        [16383],
        [16402],
        [16765],
        [16384],
        [13824],
        [16663],
        [18322],
        [18663],
        [17893],
        [15763],
        [13214],
        [10684],
        [11586]], device='cuda:0')
[2024-07-24 10:17:57,371][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 9212],
        [25374],
        [29428],
        [28355],
        [25476],
        [22606],
        [18129],
        [14731],
        [17428],
        [15404],
        [15500],
        [16880],
        [13120],
        [13958],
        [11687],
        [14354],
        [15223],
        [13354],
        [12075]], device='cuda:0')
[2024-07-24 10:17:57,372][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[25214],
        [35093],
        [40106],
        [33642],
        [29794],
        [27230],
        [22700],
        [ 8665],
        [20341],
        [23301],
        [20153],
        [24888],
        [22158],
        [22283],
        [22802],
        [22245],
        [23083],
        [23532],
        [22804]], device='cuda:0')
[2024-07-24 10:17:57,375][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[765],
        [765],
        [765],
        [765],
        [765],
        [765],
        [765],
        [765],
        [765],
        [765],
        [765],
        [765],
        [765],
        [765],
        [765],
        [765],
        [765],
        [765],
        [765]], device='cuda:0')
[2024-07-24 10:17:57,450][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:57,451][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,451][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,452][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,453][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,453][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,454][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,455][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,455][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,456][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,457][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,457][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,458][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,459][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.7790, 0.2210], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,459][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.6055, 0.3945], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,460][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0315, 0.9685], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,461][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2851, 0.7149], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,463][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1018, 0.8982], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,464][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.7949, 0.2051], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,464][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.8774, 0.1226], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,465][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0383, 0.9617], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,466][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.7934, 0.2066], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,467][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1575, 0.8425], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,470][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2112, 0.7888], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,474][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1549, 0.8451], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,474][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Jamie] are: tensor([0.5581, 0.2107, 0.2312], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,475][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Jamie] are: tensor([0.9083, 0.0558, 0.0359], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,476][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Jamie] are: tensor([0.0163, 0.5866, 0.3972], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,476][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Jamie] are: tensor([0.1531, 0.4610, 0.3859], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,478][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Jamie] are: tensor([0.0530, 0.5170, 0.4300], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,482][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Jamie] are: tensor([0.1041, 0.4394, 0.4565], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,484][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Jamie] are: tensor([0.5506, 0.1800, 0.2693], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,485][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Jamie] are: tensor([0.0273, 0.6050, 0.3676], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,486][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Jamie] are: tensor([0.6439, 0.0564, 0.2996], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,486][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Jamie] are: tensor([0.0788, 0.4007, 0.5206], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,487][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Jamie] are: tensor([0.0154, 0.0940, 0.8907], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,489][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Jamie] are: tensor([0.2785, 0.6093, 0.1123], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,493][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4598, 0.1668, 0.1774, 0.1960], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,495][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.9370, 0.0274, 0.0211, 0.0145], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,496][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0106, 0.4056, 0.2711, 0.3127], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,496][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0929, 0.3313, 0.2779, 0.2978], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,497][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0456, 0.3425, 0.2242, 0.3876], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,498][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.6517, 0.1052, 0.1594, 0.0837], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,500][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.8593, 0.0519, 0.0622, 0.0266], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,504][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0312, 0.3507, 0.1791, 0.4390], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,505][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.6359, 0.0555, 0.1767, 0.1319], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,506][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0643, 0.2089, 0.2830, 0.4438], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,507][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0045, 0.0264, 0.9477, 0.0213], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,508][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3017, 0.3221, 0.1833, 0.1929], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,508][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.3300, 0.1476, 0.1555, 0.1819, 0.1850], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,511][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.9445, 0.0145, 0.0184, 0.0074, 0.0153], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,516][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0078, 0.3310, 0.2164, 0.2592, 0.1855], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,516][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.0415, 0.2718, 0.2292, 0.2643, 0.1932], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,517][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0572, 0.3698, 0.1854, 0.2899, 0.0977], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,518][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.1385, 0.1336, 0.1856, 0.3091, 0.2332], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,519][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.5439, 0.1144, 0.2182, 0.0817, 0.0419], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,519][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0166, 0.2782, 0.1525, 0.4221, 0.1307], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,522][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.6242, 0.0250, 0.0772, 0.1074, 0.1662], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,526][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0312, 0.1381, 0.1776, 0.3113, 0.3418], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,527][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0014, 0.0449, 0.5871, 0.0302, 0.3364], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,528][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.3314, 0.2781, 0.0947, 0.2099, 0.0858], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,529][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.2882, 0.1227, 0.1288, 0.1462, 0.1518, 0.1622], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,529][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.7043, 0.0419, 0.0730, 0.0319, 0.0567, 0.0922], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,530][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0068, 0.2646, 0.1730, 0.2105, 0.1500, 0.1950], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,532][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0534, 0.2223, 0.1847, 0.2004, 0.1377, 0.2015], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,537][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0253, 0.1992, 0.1454, 0.2759, 0.1395, 0.2148], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,538][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.4339, 0.0554, 0.1248, 0.0657, 0.1211, 0.1991], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,538][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.8275, 0.0475, 0.0601, 0.0290, 0.0155, 0.0205], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,539][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0148, 0.2031, 0.1126, 0.2677, 0.0821, 0.3197], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,540][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.5078, 0.0200, 0.0659, 0.0910, 0.1500, 0.1652], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,541][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0401, 0.0991, 0.1178, 0.2025, 0.2231, 0.3175], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,543][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0070, 0.0316, 0.6787, 0.0279, 0.2167, 0.0381], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,548][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1794, 0.3194, 0.1116, 0.1770, 0.0863, 0.1263], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,549][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2712, 0.1034, 0.1045, 0.1274, 0.1292, 0.1414, 0.1228],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,550][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.6404, 0.0423, 0.0588, 0.0343, 0.0473, 0.0914, 0.0856],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,550][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0053, 0.2202, 0.1439, 0.1723, 0.1226, 0.1582, 0.1776],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,551][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0366, 0.1854, 0.1517, 0.1785, 0.1183, 0.1819, 0.1476],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,552][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0151, 0.1716, 0.1142, 0.2751, 0.1150, 0.1866, 0.1223],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,556][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1701, 0.0560, 0.0885, 0.0736, 0.1055, 0.2734, 0.2330],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,559][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.8136, 0.0418, 0.0469, 0.0333, 0.0103, 0.0235, 0.0306],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,560][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0077, 0.1374, 0.0908, 0.2619, 0.0756, 0.3572, 0.0695],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,561][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.4870, 0.0118, 0.0249, 0.1032, 0.1010, 0.1451, 0.1271],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,562][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0268, 0.0718, 0.0834, 0.1446, 0.1546, 0.2520, 0.2668],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,562][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0021, 0.0210, 0.4494, 0.0402, 0.2782, 0.0558, 0.1533],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,565][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3824, 0.2444, 0.0802, 0.0975, 0.0536, 0.0978, 0.0440],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:57,570][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.2342, 0.0905, 0.0907, 0.1145, 0.1133, 0.1285, 0.1144, 0.1139],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,571][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.5615, 0.0376, 0.0276, 0.0186, 0.0307, 0.0510, 0.0479, 0.2250],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,572][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0044, 0.1953, 0.1255, 0.1512, 0.1055, 0.1382, 0.1572, 0.1227],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,572][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0318, 0.1552, 0.1293, 0.1580, 0.1076, 0.1622, 0.1358, 0.1201],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,573][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0062, 0.0969, 0.0878, 0.2659, 0.1392, 0.1748, 0.1596, 0.0695],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,575][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0667, 0.0292, 0.0822, 0.0533, 0.1238, 0.2482, 0.2585, 0.1381],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,581][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.4437, 0.0813, 0.1093, 0.0689, 0.0319, 0.0700, 0.0869, 0.1079],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,583][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0031, 0.1387, 0.0949, 0.2902, 0.0681, 0.3083, 0.0608, 0.0359],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,584][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.1817, 0.0107, 0.0168, 0.0964, 0.0900, 0.1352, 0.1535, 0.3158],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,585][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0211, 0.0509, 0.0565, 0.1141, 0.1184, 0.2093, 0.2388, 0.1909],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,586][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0017, 0.0160, 0.3922, 0.0423, 0.1368, 0.1259, 0.2277, 0.0575],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,587][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.2538, 0.2341, 0.0642, 0.1303, 0.0502, 0.0981, 0.0657, 0.1036],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:57,589][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.2264, 0.0812, 0.0817, 0.1007, 0.1025, 0.1113, 0.0979, 0.0979, 0.1005],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,594][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.3361, 0.0309, 0.0396, 0.0268, 0.0405, 0.0793, 0.0637, 0.2957, 0.0874],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,595][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0036, 0.1661, 0.1084, 0.1313, 0.0918, 0.1198, 0.1351, 0.1028, 0.1409],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,596][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0220, 0.1443, 0.1195, 0.1413, 0.0925, 0.1441, 0.1169, 0.1038, 0.1157],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,597][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0149, 0.1696, 0.0950, 0.2266, 0.0872, 0.1559, 0.0976, 0.0693, 0.0840],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,597][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0561, 0.0486, 0.0710, 0.0556, 0.0859, 0.2108, 0.2027, 0.1107, 0.1586],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,600][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.6737, 0.0464, 0.0492, 0.0437, 0.0134, 0.0316, 0.0434, 0.0511, 0.0474],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,605][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0047, 0.1101, 0.0893, 0.2225, 0.0749, 0.3251, 0.0695, 0.0418, 0.0620],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,605][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.3130, 0.0055, 0.0106, 0.0553, 0.0484, 0.0707, 0.0738, 0.2230, 0.1996],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,606][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0174, 0.0454, 0.0532, 0.0948, 0.0978, 0.1653, 0.1787, 0.1513, 0.1960],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,607][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0004, 0.0106, 0.2563, 0.0152, 0.1219, 0.0313, 0.1431, 0.0754, 0.3456],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,608][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.2624, 0.2072, 0.0698, 0.0758, 0.0418, 0.1053, 0.0611, 0.1178, 0.0588],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:57,609][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.2000, 0.0712, 0.0722, 0.0918, 0.0907, 0.1019, 0.0899, 0.0895, 0.0932,
        0.0996], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,612][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.6607, 0.0130, 0.0159, 0.0097, 0.0202, 0.0291, 0.0277, 0.1275, 0.0422,
        0.0540], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,616][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0035, 0.1488, 0.0962, 0.1168, 0.0812, 0.1057, 0.1192, 0.0921, 0.1250,
        0.1116], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,617][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0218, 0.1159, 0.0981, 0.1243, 0.0881, 0.1295, 0.1099, 0.0983, 0.1154,
        0.0987], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,617][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0110, 0.1325, 0.0820, 0.2182, 0.0833, 0.1393, 0.0956, 0.0565, 0.0866,
        0.0952], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,618][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0456, 0.0296, 0.0490, 0.0437, 0.0839, 0.1783, 0.1847, 0.1013, 0.1687,
        0.1151], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,619][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.4361, 0.0560, 0.0851, 0.0474, 0.0241, 0.0512, 0.0666, 0.0941, 0.0886,
        0.0508], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,622][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0026, 0.1307, 0.0781, 0.2271, 0.0624, 0.2881, 0.0687, 0.0427, 0.0575,
        0.0421], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,627][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.1535, 0.0025, 0.0039, 0.0310, 0.0258, 0.0471, 0.0621, 0.1578, 0.1827,
        0.3336], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,627][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0155, 0.0358, 0.0409, 0.0754, 0.0788, 0.1389, 0.1522, 0.1201, 0.1668,
        0.1755], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,628][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0010, 0.0086, 0.1911, 0.0156, 0.1180, 0.0299, 0.0963, 0.0576, 0.1940,
        0.2879], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,629][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.2703, 0.2178, 0.0500, 0.0945, 0.0383, 0.0729, 0.0489, 0.0697, 0.0533,
        0.0842], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:57,630][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.2000, 0.0631, 0.0640, 0.0816, 0.0811, 0.0903, 0.0790, 0.0792, 0.0812,
        0.0871, 0.0934], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,632][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.3155, 0.0292, 0.0375, 0.0196, 0.0433, 0.0547, 0.0474, 0.2124, 0.0649,
        0.1035, 0.0720], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,637][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0032, 0.1286, 0.0846, 0.1024, 0.0717, 0.0939, 0.1063, 0.0813, 0.1108,
        0.0986, 0.1187], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,638][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0220, 0.1198, 0.0967, 0.1159, 0.0747, 0.1171, 0.0961, 0.0836, 0.0954,
        0.0826, 0.0962], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,639][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0083, 0.1087, 0.0690, 0.1976, 0.0806, 0.1287, 0.0890, 0.0485, 0.0791,
        0.0887, 0.1019], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,640][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0664, 0.0293, 0.0487, 0.0382, 0.0633, 0.1677, 0.1864, 0.0784, 0.1248,
        0.0973, 0.0995], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,640][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.5989, 0.0535, 0.0472, 0.0374, 0.0128, 0.0289, 0.0300, 0.0378, 0.0352,
        0.0169, 0.1014], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,642][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0045, 0.1192, 0.0826, 0.2121, 0.0704, 0.2756, 0.0513, 0.0326, 0.0539,
        0.0358, 0.0620], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,646][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.1493, 0.0034, 0.0042, 0.0314, 0.0250, 0.0443, 0.0543, 0.1116, 0.1246,
        0.2377, 0.2141], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,646][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0132, 0.0306, 0.0360, 0.0639, 0.0690, 0.1199, 0.1276, 0.1034, 0.1454,
        0.1472, 0.1437], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,650][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0008, 0.0088, 0.2249, 0.0127, 0.1093, 0.0139, 0.0484, 0.0295, 0.1413,
        0.1934, 0.2169], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,651][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.2563, 0.2465, 0.0520, 0.0775, 0.0427, 0.0725, 0.0372, 0.0620, 0.0395,
        0.0804, 0.0332], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:57,652][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1817, 0.0600, 0.0611, 0.0750, 0.0758, 0.0830, 0.0709, 0.0711, 0.0722,
        0.0777, 0.0833, 0.0881], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,652][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1762, 0.0322, 0.0319, 0.0191, 0.0272, 0.0479, 0.0500, 0.2665, 0.0803,
        0.0998, 0.0805, 0.0883], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,653][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0028, 0.1172, 0.0766, 0.0920, 0.0642, 0.0834, 0.0942, 0.0725, 0.0978,
        0.0871, 0.1047, 0.1075], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,657][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0212, 0.1085, 0.0880, 0.1053, 0.0680, 0.1063, 0.0863, 0.0757, 0.0862,
        0.0746, 0.0873, 0.0927], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,660][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0104, 0.1161, 0.0696, 0.1794, 0.0749, 0.1151, 0.0673, 0.0401, 0.0570,
        0.0649, 0.0743, 0.1309], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,661][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1144, 0.0406, 0.0556, 0.0377, 0.0689, 0.1375, 0.1181, 0.0652, 0.1050,
        0.0716, 0.0797, 0.1057], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,662][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.5709, 0.0466, 0.0427, 0.0344, 0.0121, 0.0228, 0.0292, 0.0381, 0.0311,
        0.0164, 0.0862, 0.0695], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,663][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0037, 0.1128, 0.0710, 0.1783, 0.0556, 0.2388, 0.0519, 0.0326, 0.0538,
        0.0350, 0.0629, 0.1036], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,664][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.3050, 0.0042, 0.0053, 0.0331, 0.0241, 0.0324, 0.0204, 0.0623, 0.0552,
        0.0909, 0.1050, 0.2622], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,667][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0119, 0.0308, 0.0339, 0.0593, 0.0621, 0.1066, 0.1127, 0.0916, 0.1251,
        0.1296, 0.1257, 0.1108], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,671][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0008, 0.0170, 0.3139, 0.0119, 0.0991, 0.0104, 0.0246, 0.0331, 0.1163,
        0.1261, 0.1603, 0.0865], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,672][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1187, 0.2280, 0.0618, 0.0912, 0.0366, 0.0894, 0.0415, 0.0925, 0.0625,
        0.0817, 0.0433, 0.0528], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:57,673][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.1622, 0.0530, 0.0545, 0.0695, 0.0684, 0.0758, 0.0660, 0.0657, 0.0669,
        0.0721, 0.0774, 0.0833, 0.0853], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,674][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.3734, 0.0145, 0.0157, 0.0122, 0.0195, 0.0345, 0.0341, 0.1604, 0.0497,
        0.0593, 0.0718, 0.0605, 0.0944], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,674][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0028, 0.1037, 0.0691, 0.0827, 0.0580, 0.0760, 0.0862, 0.0663, 0.0894,
        0.0799, 0.0973, 0.0988, 0.0897], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,678][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0219, 0.0867, 0.0736, 0.0916, 0.0669, 0.0947, 0.0801, 0.0718, 0.0845,
        0.0691, 0.0841, 0.0888, 0.0863], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,682][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0061, 0.0786, 0.0502, 0.1561, 0.0630, 0.0929, 0.0638, 0.0333, 0.0566,
        0.0597, 0.0709, 0.1250, 0.1439], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,683][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0581, 0.0191, 0.0267, 0.0337, 0.0434, 0.1069, 0.1798, 0.0649, 0.1231,
        0.0769, 0.0626, 0.1258, 0.0791], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,684][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.2369, 0.0471, 0.0517, 0.0360, 0.0158, 0.0384, 0.0493, 0.0686, 0.0608,
        0.0378, 0.1560, 0.1403, 0.0613], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,684][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0021, 0.0845, 0.0493, 0.1444, 0.0489, 0.2121, 0.0631, 0.0433, 0.0606,
        0.0376, 0.0684, 0.0983, 0.0871], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,685][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.1678, 0.0014, 0.0016, 0.0147, 0.0091, 0.0151, 0.0131, 0.0287, 0.0399,
        0.0550, 0.0955, 0.2345, 0.3234], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,689][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0113, 0.0255, 0.0292, 0.0531, 0.0546, 0.0957, 0.0992, 0.0815, 0.1117,
        0.1162, 0.1114, 0.0993, 0.1113], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,693][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0062, 0.0047, 0.0783, 0.0082, 0.0277, 0.0191, 0.0460, 0.0330, 0.1508,
        0.0964, 0.2379, 0.1198, 0.1719], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,693][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0666, 0.1966, 0.0358, 0.1122, 0.0237, 0.0769, 0.0599, 0.0665, 0.0851,
        0.0866, 0.0558, 0.0868, 0.0475], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:57,694][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.1481, 0.0542, 0.0527, 0.0658, 0.0647, 0.0714, 0.0606, 0.0606, 0.0615,
        0.0658, 0.0700, 0.0758, 0.0775, 0.0711], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,695][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.1414, 0.0251, 0.0258, 0.0198, 0.0252, 0.0482, 0.0468, 0.2015, 0.0524,
        0.0817, 0.0689, 0.0707, 0.1249, 0.0676], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,696][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0023, 0.0982, 0.0642, 0.0763, 0.0542, 0.0708, 0.0791, 0.0612, 0.0818,
        0.0739, 0.0887, 0.0909, 0.0819, 0.0765], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,700][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0219, 0.0947, 0.0764, 0.0906, 0.0573, 0.0913, 0.0716, 0.0611, 0.0707,
        0.0590, 0.0709, 0.0757, 0.0774, 0.0815], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,703][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0053, 0.0792, 0.0520, 0.1480, 0.0592, 0.0927, 0.0477, 0.0273, 0.0402,
        0.0484, 0.0553, 0.1026, 0.1351, 0.1068], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,704][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1135, 0.0290, 0.0350, 0.0318, 0.0447, 0.1368, 0.1156, 0.0443, 0.0792,
        0.0643, 0.0611, 0.0941, 0.0734, 0.0771], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,705][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.5394, 0.0498, 0.0350, 0.0328, 0.0097, 0.0217, 0.0251, 0.0297, 0.0265,
        0.0164, 0.0762, 0.0628, 0.0266, 0.0484], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,706][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0022, 0.0725, 0.0524, 0.1304, 0.0430, 0.2230, 0.0495, 0.0295, 0.0506,
        0.0271, 0.0544, 0.0924, 0.0796, 0.0934], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,707][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.1710, 0.0031, 0.0028, 0.0301, 0.0146, 0.0268, 0.0133, 0.0376, 0.0329,
        0.0534, 0.0608, 0.2030, 0.1992, 0.1513], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,710][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0108, 0.0255, 0.0287, 0.0485, 0.0513, 0.0867, 0.0906, 0.0723, 0.0988,
        0.1039, 0.0993, 0.0895, 0.0984, 0.0956], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,714][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0003, 0.0051, 0.1541, 0.0048, 0.0601, 0.0096, 0.0237, 0.0178, 0.0753,
        0.1275, 0.1189, 0.0666, 0.2538, 0.0824], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,715][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.3585, 0.2396, 0.0402, 0.0465, 0.0233, 0.0503, 0.0221, 0.0452, 0.0219,
        0.0411, 0.0205, 0.0341, 0.0324, 0.0243], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:57,716][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.1036, 0.0481, 0.0483, 0.0598, 0.0589, 0.0660, 0.0597, 0.0594, 0.0617,
        0.0673, 0.0712, 0.0762, 0.0791, 0.0727, 0.0679], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,716][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.4075, 0.0177, 0.0211, 0.0128, 0.0170, 0.0343, 0.0277, 0.0901, 0.0397,
        0.0416, 0.0585, 0.0542, 0.0633, 0.0379, 0.0769], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,717][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0021, 0.0942, 0.0603, 0.0733, 0.0517, 0.0680, 0.0754, 0.0582, 0.0796,
        0.0711, 0.0854, 0.0877, 0.0783, 0.0737, 0.0409], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,721][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.0069, 0.0720, 0.0605, 0.0777, 0.0535, 0.0852, 0.0722, 0.0650, 0.0745,
        0.0655, 0.0767, 0.0819, 0.0836, 0.0888, 0.0358], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,725][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0196, 0.1291, 0.0562, 0.1159, 0.0356, 0.0760, 0.0452, 0.0397, 0.0368,
        0.0410, 0.0521, 0.0850, 0.1335, 0.0901, 0.0440], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,725][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0273, 0.0082, 0.0130, 0.0241, 0.0205, 0.1197, 0.1816, 0.0815, 0.1337,
        0.0732, 0.0603, 0.0867, 0.0871, 0.0589, 0.0241], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,726][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.1616, 0.0530, 0.0625, 0.0380, 0.0131, 0.0458, 0.0473, 0.0513, 0.0564,
        0.0317, 0.1464, 0.1311, 0.0514, 0.0844, 0.0259], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,727][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0008, 0.0943, 0.0583, 0.1627, 0.0459, 0.1692, 0.0472, 0.0316, 0.0447,
        0.0360, 0.0444, 0.0792, 0.0860, 0.0799, 0.0197], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,728][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.0173, 0.0005, 0.0007, 0.0052, 0.0040, 0.0083, 0.0185, 0.0350, 0.0473,
        0.0753, 0.0839, 0.2219, 0.2705, 0.1798, 0.0319], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,732][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0058, 0.0195, 0.0217, 0.0415, 0.0419, 0.0787, 0.0823, 0.0716, 0.0927,
        0.1057, 0.0985, 0.0851, 0.0950, 0.0940, 0.0661], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,735][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([1.2197e-04, 2.6824e-03, 4.1793e-02, 7.9261e-03, 2.6731e-02, 1.2019e-02,
        3.0026e-02, 9.4560e-03, 1.5341e-01, 1.1838e-01, 1.5278e-01, 9.1527e-02,
        1.7455e-01, 8.5930e-02, 9.2668e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,736][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0465, 0.1140, 0.0291, 0.0704, 0.0194, 0.0793, 0.0696, 0.0485, 0.0787,
        0.0868, 0.0749, 0.1052, 0.0582, 0.0973, 0.0222], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:57,737][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1114, 0.0468, 0.0461, 0.0583, 0.0564, 0.0626, 0.0535, 0.0527, 0.0543,
        0.0574, 0.0616, 0.0671, 0.0679, 0.0631, 0.0596, 0.0813],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,738][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.2396, 0.0142, 0.0221, 0.0110, 0.0208, 0.0292, 0.0349, 0.1591, 0.0459,
        0.0628, 0.0566, 0.0549, 0.0901, 0.0387, 0.0719, 0.0483],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,739][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0021, 0.0891, 0.0572, 0.0697, 0.0489, 0.0637, 0.0723, 0.0553, 0.0750,
        0.0671, 0.0803, 0.0834, 0.0744, 0.0702, 0.0385, 0.0528],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,742][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0185, 0.0828, 0.0670, 0.0801, 0.0530, 0.0810, 0.0631, 0.0546, 0.0638,
        0.0541, 0.0644, 0.0684, 0.0685, 0.0729, 0.0305, 0.0772],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,746][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0057, 0.0639, 0.0385, 0.1099, 0.0465, 0.0703, 0.0460, 0.0251, 0.0410,
        0.0422, 0.0492, 0.0876, 0.1038, 0.0929, 0.0697, 0.1077],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,747][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0869, 0.0187, 0.0359, 0.0242, 0.0370, 0.0986, 0.0999, 0.0434, 0.0836,
        0.0446, 0.0531, 0.0815, 0.0929, 0.0663, 0.0385, 0.0950],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,748][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.3190, 0.0469, 0.0435, 0.0328, 0.0119, 0.0280, 0.0342, 0.0415, 0.0423,
        0.0243, 0.1133, 0.0883, 0.0373, 0.0574, 0.0257, 0.0537],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,749][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0024, 0.0828, 0.0525, 0.1217, 0.0398, 0.1675, 0.0459, 0.0283, 0.0442,
        0.0304, 0.0491, 0.0784, 0.0734, 0.0820, 0.0234, 0.0782],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,750][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1300, 0.0019, 0.0020, 0.0165, 0.0082, 0.0131, 0.0110, 0.0224, 0.0273,
        0.0314, 0.0496, 0.1360, 0.1421, 0.1204, 0.0253, 0.2629],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,753][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0092, 0.0204, 0.0223, 0.0415, 0.0416, 0.0736, 0.0775, 0.0609, 0.0851,
        0.0908, 0.0852, 0.0779, 0.0853, 0.0844, 0.0585, 0.0858],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,757][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0016, 0.0024, 0.0336, 0.0048, 0.0150, 0.0098, 0.0371, 0.0147, 0.0800,
        0.0979, 0.1677, 0.0891, 0.1811, 0.1050, 0.0910, 0.0693],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,758][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.1229, 0.1180, 0.0334, 0.0727, 0.0250, 0.0587, 0.0467, 0.0613, 0.0653,
        0.0719, 0.0491, 0.0717, 0.0534, 0.0776, 0.0240, 0.0482],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:57,759][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1150, 0.0430, 0.0424, 0.0532, 0.0519, 0.0575, 0.0487, 0.0482, 0.0494,
        0.0523, 0.0561, 0.0609, 0.0621, 0.0574, 0.0546, 0.0750, 0.0721],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,759][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0850, 0.0174, 0.0186, 0.0128, 0.0188, 0.0325, 0.0368, 0.1572, 0.0504,
        0.0647, 0.0493, 0.0553, 0.1021, 0.0528, 0.0516, 0.0480, 0.1468],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,761][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0019, 0.0839, 0.0540, 0.0654, 0.0458, 0.0594, 0.0670, 0.0524, 0.0704,
        0.0627, 0.0748, 0.0774, 0.0694, 0.0658, 0.0365, 0.0498, 0.0634],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,766][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0161, 0.0773, 0.0620, 0.0745, 0.0469, 0.0753, 0.0602, 0.0518, 0.0598,
        0.0514, 0.0603, 0.0641, 0.0666, 0.0699, 0.0260, 0.0723, 0.0654],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,768][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0086, 0.0880, 0.0442, 0.1159, 0.0391, 0.0700, 0.0295, 0.0197, 0.0250,
        0.0274, 0.0325, 0.0600, 0.0805, 0.0605, 0.0412, 0.0803, 0.1775],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,768][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.4245, 0.0121, 0.0151, 0.0116, 0.0163, 0.0477, 0.0456, 0.0199, 0.0380,
        0.0239, 0.0274, 0.0399, 0.0306, 0.0350, 0.0186, 0.0633, 0.1305],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,769][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.4876, 0.0437, 0.0323, 0.0294, 0.0092, 0.0172, 0.0223, 0.0279, 0.0212,
        0.0135, 0.0630, 0.0531, 0.0212, 0.0429, 0.0204, 0.0311, 0.0640],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,770][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0018, 0.0863, 0.0506, 0.1378, 0.0365, 0.1859, 0.0293, 0.0192, 0.0375,
        0.0182, 0.0324, 0.0581, 0.0573, 0.0576, 0.0160, 0.0663, 0.1091],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,773][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1889, 0.0015, 0.0011, 0.0127, 0.0057, 0.0087, 0.0042, 0.0124, 0.0112,
        0.0143, 0.0218, 0.0768, 0.0721, 0.0736, 0.0146, 0.2112, 0.2693],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,778][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0105, 0.0208, 0.0215, 0.0390, 0.0379, 0.0694, 0.0688, 0.0542, 0.0778,
        0.0793, 0.0761, 0.0707, 0.0776, 0.0749, 0.0488, 0.0773, 0.0952],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,779][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0006, 0.0026, 0.0499, 0.0030, 0.0224, 0.0044, 0.0101, 0.0217, 0.0332,
        0.0723, 0.0784, 0.0526, 0.1894, 0.0701, 0.2021, 0.1028, 0.0845],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,780][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1529, 0.1679, 0.0475, 0.0635, 0.0267, 0.0639, 0.0294, 0.0734, 0.0382,
        0.0614, 0.0282, 0.0476, 0.0589, 0.0462, 0.0159, 0.0529, 0.0255],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:57,781][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.1109, 0.0357, 0.0362, 0.0472, 0.0453, 0.0513, 0.0447, 0.0440, 0.0458,
        0.0477, 0.0525, 0.0572, 0.0580, 0.0543, 0.0503, 0.0710, 0.0694, 0.0784],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,781][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.7060, 0.0050, 0.0045, 0.0030, 0.0045, 0.0099, 0.0104, 0.0483, 0.0195,
        0.0171, 0.0277, 0.0200, 0.0254, 0.0112, 0.0244, 0.0217, 0.0296, 0.0118],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,785][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0019, 0.0790, 0.0509, 0.0622, 0.0433, 0.0565, 0.0637, 0.0488, 0.0666,
        0.0594, 0.0712, 0.0734, 0.0650, 0.0616, 0.0346, 0.0470, 0.0600, 0.0549],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,789][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.0117, 0.0596, 0.0504, 0.0645, 0.0457, 0.0675, 0.0571, 0.0507, 0.0603,
        0.0504, 0.0609, 0.0644, 0.0627, 0.0688, 0.0296, 0.0752, 0.0665, 0.0540],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,790][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0062, 0.0631, 0.0280, 0.0858, 0.0265, 0.0487, 0.0256, 0.0159, 0.0210,
        0.0219, 0.0266, 0.0517, 0.0641, 0.0518, 0.0351, 0.0709, 0.1667, 0.1903],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,791][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.1093, 0.0098, 0.0121, 0.0158, 0.0201, 0.0468, 0.0763, 0.0424, 0.0658,
        0.0352, 0.0268, 0.0638, 0.0495, 0.0492, 0.0203, 0.0937, 0.1642, 0.0987],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,792][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.1944, 0.0335, 0.0472, 0.0281, 0.0138, 0.0282, 0.0335, 0.0462, 0.0442,
        0.0265, 0.1091, 0.0860, 0.0462, 0.0539, 0.0262, 0.0568, 0.0815, 0.0447],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,794][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0015, 0.0723, 0.0392, 0.1060, 0.0314, 0.1467, 0.0387, 0.0294, 0.0388,
        0.0228, 0.0419, 0.0609, 0.0477, 0.0549, 0.0183, 0.0589, 0.1195, 0.0710],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,797][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([7.8368e-02, 3.7242e-04, 2.5385e-04, 4.1317e-03, 1.6814e-03, 2.8092e-03,
        3.1403e-03, 7.2308e-03, 8.3994e-03, 8.6812e-03, 1.6510e-02, 7.0004e-02,
        6.1582e-02, 5.0042e-02, 8.4945e-03, 1.3347e-01, 2.8966e-01, 2.5517e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,800][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.0097, 0.0169, 0.0175, 0.0351, 0.0314, 0.0640, 0.0628, 0.0474, 0.0703,
        0.0705, 0.0678, 0.0647, 0.0704, 0.0697, 0.0443, 0.0714, 0.0904, 0.0956],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,801][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0033, 0.0029, 0.0140, 0.0026, 0.0118, 0.0077, 0.0202, 0.0121, 0.0721,
        0.0501, 0.1180, 0.0453, 0.0706, 0.0368, 0.1097, 0.0582, 0.0726, 0.2920],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,802][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.2114, 0.1381, 0.0374, 0.0787, 0.0281, 0.0475, 0.0322, 0.0512, 0.0399,
        0.0466, 0.0292, 0.0470, 0.0436, 0.0403, 0.0225, 0.0472, 0.0261, 0.0332],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:57,802][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1003, 0.0370, 0.0360, 0.0447, 0.0444, 0.0490, 0.0420, 0.0416, 0.0430,
        0.0453, 0.0488, 0.0532, 0.0544, 0.0500, 0.0473, 0.0657, 0.0630, 0.0729,
        0.0612], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,805][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.2605, 0.0120, 0.0106, 0.0064, 0.0098, 0.0178, 0.0212, 0.1202, 0.0314,
        0.0423, 0.0433, 0.0388, 0.0754, 0.0354, 0.0399, 0.0392, 0.0940, 0.0447,
        0.0573], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,810][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0017, 0.0740, 0.0482, 0.0578, 0.0405, 0.0536, 0.0602, 0.0463, 0.0625,
        0.0557, 0.0671, 0.0693, 0.0613, 0.0582, 0.0322, 0.0447, 0.0572, 0.0524,
        0.0571], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,811][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0122, 0.0654, 0.0540, 0.0650, 0.0416, 0.0664, 0.0544, 0.0471, 0.0542,
        0.0461, 0.0548, 0.0588, 0.0605, 0.0640, 0.0240, 0.0666, 0.0601, 0.0486,
        0.0561], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,812][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0052, 0.0564, 0.0261, 0.0743, 0.0257, 0.0467, 0.0219, 0.0142, 0.0176,
        0.0199, 0.0233, 0.0451, 0.0553, 0.0463, 0.0301, 0.0605, 0.1468, 0.1550,
        0.1298], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,813][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1751, 0.0112, 0.0087, 0.0126, 0.0114, 0.0570, 0.0614, 0.0227, 0.0379,
        0.0253, 0.0224, 0.0493, 0.0333, 0.0367, 0.0118, 0.0774, 0.1680, 0.1033,
        0.0745], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,814][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.4408, 0.0403, 0.0272, 0.0279, 0.0087, 0.0191, 0.0226, 0.0258, 0.0219,
        0.0132, 0.0606, 0.0525, 0.0209, 0.0387, 0.0188, 0.0335, 0.0663, 0.0223,
        0.0387], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,817][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0007, 0.0502, 0.0305, 0.0735, 0.0240, 0.1240, 0.0255, 0.0182, 0.0287,
        0.0158, 0.0304, 0.0484, 0.0452, 0.0549, 0.0142, 0.0561, 0.1091, 0.0741,
        0.1764], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,821][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([5.0797e-02, 4.2602e-04, 2.5991e-04, 4.3524e-03, 1.8369e-03, 3.4978e-03,
        2.5557e-03, 6.0280e-03, 6.5007e-03, 9.5343e-03, 1.4146e-02, 4.8656e-02,
        5.2626e-02, 4.6668e-02, 6.5555e-03, 1.4960e-01, 2.0129e-01, 2.7416e-01,
        1.2050e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,822][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0077, 0.0166, 0.0172, 0.0323, 0.0308, 0.0581, 0.0591, 0.0461, 0.0645,
        0.0669, 0.0638, 0.0587, 0.0642, 0.0625, 0.0411, 0.0635, 0.0809, 0.0882,
        0.0777], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,823][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.7883e-04, 1.6355e-03, 2.8686e-02, 8.0711e-04, 8.9005e-03, 2.7413e-03,
        7.1428e-03, 1.1755e-02, 1.6022e-02, 3.0298e-02, 2.6258e-02, 1.6374e-02,
        6.0897e-02, 2.2095e-02, 6.6332e-02, 5.4009e-02, 3.8620e-02, 5.4745e-01,
        5.9802e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,824][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.2718, 0.1375, 0.0400, 0.0557, 0.0246, 0.0652, 0.0256, 0.0604, 0.0222,
        0.0475, 0.0269, 0.0392, 0.0316, 0.0294, 0.0165, 0.0401, 0.0253, 0.0310,
        0.0096], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:57,902][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:57,908][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,909][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,909][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,910][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,911][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,911][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,913][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,913][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,914][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,915][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,915][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,916][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:57,917][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9506, 0.0494], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,917][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.7047, 0.2953], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,918][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0018, 0.9982], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,919][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9034, 0.0966], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,923][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.8091, 0.1909], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,925][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9808, 0.0192], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,926][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.8600, 0.1400], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,927][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2288, 0.7712], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,927][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.7504, 0.2496], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,928][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7933, 0.2067], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,929][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0170, 0.9830], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,932][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.8109, 0.1891], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:57,936][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Jamie] are: tensor([0.8850, 0.0574, 0.0576], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,936][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Jamie] are: tensor([0.3933, 0.1869, 0.4197], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,937][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Jamie] are: tensor([0.0021, 0.4447, 0.5531], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,938][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Jamie] are: tensor([0.8911, 0.0549, 0.0540], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,939][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Jamie] are: tensor([0.8150, 0.1028, 0.0822], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,940][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Jamie] are: tensor([0.8568, 0.0545, 0.0886], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,943][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Jamie] are: tensor([0.5707, 0.1603, 0.2690], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,946][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Jamie] are: tensor([0.1232, 0.3164, 0.5604], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,947][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Jamie] are: tensor([0.6679, 0.0948, 0.2373], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,948][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Jamie] are: tensor([0.8116, 0.0896, 0.0988], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,949][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Jamie] are: tensor([0.0063, 0.1533, 0.8404], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,949][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Jamie] are: tensor([0.6826, 0.2125, 0.1049], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:57,951][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9413, 0.0276, 0.0197, 0.0115], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,955][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.5159, 0.1380, 0.2537, 0.0924], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,957][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0021, 0.2594, 0.4572, 0.2813], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,958][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.7886, 0.0717, 0.0522, 0.0876], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,959][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.7531, 0.1040, 0.0640, 0.0790], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,960][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9637, 0.0135, 0.0185, 0.0044], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,960][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.7999, 0.0676, 0.0946, 0.0378], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,962][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2551, 0.2246, 0.4017, 0.1186], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,966][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.5659, 0.1132, 0.2085, 0.1124], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,968][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.6310, 0.1207, 0.1245, 0.1239], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,969][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0033, 0.0815, 0.8035, 0.1116], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,970][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.6872, 0.1230, 0.1077, 0.0821], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:57,971][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.8458, 0.0364, 0.0354, 0.0479, 0.0346], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,971][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.3921, 0.1068, 0.3103, 0.0789, 0.1119], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,973][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.0008, 0.1988, 0.3825, 0.2653, 0.1526], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,977][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.7385, 0.0640, 0.0506, 0.0962, 0.0507], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,979][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.7364, 0.0845, 0.0462, 0.0941, 0.0387], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,980][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.8683, 0.0304, 0.0477, 0.0158, 0.0378], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,981][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.6332, 0.0981, 0.1632, 0.0648, 0.0407], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,982][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.1069, 0.1870, 0.3961, 0.1082, 0.2017], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,982][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.5941, 0.0660, 0.1199, 0.1004, 0.1195], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,984][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.5814, 0.0801, 0.0853, 0.1549, 0.0984], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,988][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0014, 0.0758, 0.6297, 0.0964, 0.1967], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,990][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.5688, 0.1393, 0.0991, 0.1050, 0.0878], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:57,991][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.8975, 0.0217, 0.0165, 0.0185, 0.0188, 0.0270], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,992][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.3018, 0.1223, 0.2647, 0.0929, 0.1046, 0.1137], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,993][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0015, 0.1668, 0.2429, 0.2165, 0.1494, 0.2230], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,993][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.6699, 0.0583, 0.0421, 0.0700, 0.0347, 0.1249], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:57,996][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.6430, 0.0779, 0.0530, 0.0798, 0.0370, 0.1094], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,001][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.9119, 0.0199, 0.0290, 0.0072, 0.0206, 0.0114], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,001][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.7094, 0.0738, 0.1014, 0.0446, 0.0376, 0.0331], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,002][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.2619, 0.1621, 0.3001, 0.0761, 0.1290, 0.0707], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,003][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.4878, 0.0626, 0.1164, 0.0891, 0.1105, 0.1336], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,004][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3394, 0.0794, 0.0957, 0.1273, 0.1090, 0.2492], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,004][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0031, 0.0639, 0.5293, 0.0917, 0.1676, 0.1444], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,007][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.5341, 0.1498, 0.0776, 0.0800, 0.0778, 0.0807], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,012][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.8871, 0.0144, 0.0050, 0.0336, 0.0129, 0.0401, 0.0069],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,013][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.3270, 0.1170, 0.2231, 0.0911, 0.0855, 0.1094, 0.0469],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,013][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0012, 0.1346, 0.1999, 0.1490, 0.1130, 0.1668, 0.2354],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,014][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.6033, 0.0424, 0.0250, 0.1017, 0.0309, 0.1647, 0.0319],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,015][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.6441, 0.0395, 0.0229, 0.0776, 0.0292, 0.1174, 0.0694],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,016][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.8791, 0.0227, 0.0310, 0.0097, 0.0259, 0.0185, 0.0130],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,019][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.7367, 0.0597, 0.0792, 0.0396, 0.0233, 0.0295, 0.0320],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,023][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2378, 0.1501, 0.2643, 0.0790, 0.1184, 0.1144, 0.0361],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,024][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.4151, 0.0439, 0.0617, 0.1195, 0.1035, 0.1756, 0.0808],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,024][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2760, 0.0485, 0.0409, 0.1368, 0.0721, 0.3020, 0.1237],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,025][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0019, 0.0426, 0.3516, 0.0697, 0.1534, 0.1170, 0.2639],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,026][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.6175, 0.1147, 0.0642, 0.0527, 0.0569, 0.0597, 0.0343],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,029][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.5505, 0.0333, 0.0143, 0.0940, 0.0370, 0.1433, 0.0493, 0.0783],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,034][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.2287, 0.1444, 0.1989, 0.0802, 0.0982, 0.1065, 0.0578, 0.0853],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,034][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0004, 0.1073, 0.1375, 0.1306, 0.0918, 0.1894, 0.2806, 0.0625],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,035][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.4410, 0.0474, 0.0328, 0.1142, 0.0426, 0.2030, 0.0529, 0.0660],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,036][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.2891, 0.0578, 0.0304, 0.1226, 0.0436, 0.1731, 0.1400, 0.1434],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,037][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.6658, 0.0357, 0.0647, 0.0231, 0.0664, 0.0443, 0.0403, 0.0596],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,039][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.5104, 0.0766, 0.1146, 0.0609, 0.0391, 0.0528, 0.0578, 0.0878],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,043][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.1024, 0.1337, 0.2506, 0.1022, 0.1229, 0.1242, 0.0551, 0.1090],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,045][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.1621, 0.0436, 0.0490, 0.1289, 0.1087, 0.1887, 0.1169, 0.2020],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,046][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.1442, 0.0373, 0.0271, 0.1290, 0.0631, 0.2849, 0.1715, 0.1429],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,046][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0014, 0.0361, 0.2762, 0.0580, 0.0945, 0.1372, 0.3045, 0.0922],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,047][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.3355, 0.1497, 0.0856, 0.0894, 0.0688, 0.0973, 0.0712, 0.1026],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,048][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.8919, 0.0102, 0.0033, 0.0259, 0.0102, 0.0241, 0.0063, 0.0169, 0.0112],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,051][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.3405, 0.1110, 0.1539, 0.0731, 0.0748, 0.0972, 0.0403, 0.0700, 0.0391],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,055][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0004, 0.0745, 0.1316, 0.0993, 0.0769, 0.1201, 0.1941, 0.0422, 0.2609],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,056][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.5840, 0.0316, 0.0202, 0.0826, 0.0300, 0.1321, 0.0310, 0.0470, 0.0415],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,057][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.5842, 0.0318, 0.0123, 0.0613, 0.0162, 0.0841, 0.0519, 0.0808, 0.0775],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,058][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.7994, 0.0263, 0.0368, 0.0111, 0.0318, 0.0224, 0.0183, 0.0350, 0.0188],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,059][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.6378, 0.0548, 0.0719, 0.0399, 0.0235, 0.0296, 0.0364, 0.0639, 0.0421],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,061][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.2156, 0.1013, 0.2078, 0.0741, 0.1115, 0.1217, 0.0399, 0.0950, 0.0331],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,066][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.3119, 0.0277, 0.0388, 0.0856, 0.0691, 0.1234, 0.0639, 0.1559, 0.1237],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,067][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.2164, 0.0278, 0.0235, 0.1030, 0.0487, 0.2018, 0.1034, 0.1164, 0.1588],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,068][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0010, 0.0226, 0.2101, 0.0368, 0.0884, 0.0843, 0.2284, 0.0752, 0.2531],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,068][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.5371, 0.0872, 0.0628, 0.0485, 0.0515, 0.0676, 0.0448, 0.0688, 0.0317],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,069][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.7486, 0.0132, 0.0050, 0.0446, 0.0125, 0.0524, 0.0123, 0.0272, 0.0302,
        0.0541], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,070][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.1867, 0.0856, 0.2204, 0.0637, 0.1169, 0.0919, 0.0528, 0.0857, 0.0433,
        0.0531], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,074][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0004, 0.0782, 0.1155, 0.0893, 0.0565, 0.1117, 0.1528, 0.0369, 0.2211,
        0.1375], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,077][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.4589, 0.0356, 0.0206, 0.0853, 0.0297, 0.1496, 0.0359, 0.0446, 0.0450,
        0.0947], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,078][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.3855, 0.0331, 0.0125, 0.0801, 0.0185, 0.0956, 0.0656, 0.0804, 0.1044,
        0.1243], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,079][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.6727, 0.0249, 0.0372, 0.0133, 0.0403, 0.0279, 0.0249, 0.0435, 0.0282,
        0.0872], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,080][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.5093, 0.0611, 0.0931, 0.0505, 0.0275, 0.0381, 0.0416, 0.0765, 0.0592,
        0.0432], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,080][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0899, 0.1132, 0.2162, 0.0849, 0.1112, 0.1193, 0.0437, 0.0850, 0.0399,
        0.0967], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,083][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.1975, 0.0184, 0.0197, 0.0596, 0.0454, 0.0973, 0.0603, 0.1252, 0.1221,
        0.2543], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,088][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.1736, 0.0182, 0.0153, 0.0765, 0.0366, 0.2015, 0.0971, 0.0817, 0.1489,
        0.1507], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,089][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0012, 0.0215, 0.1984, 0.0361, 0.0839, 0.0793, 0.1830, 0.0647, 0.1885,
        0.1434], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,089][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.4108, 0.1190, 0.0656, 0.0667, 0.0542, 0.0747, 0.0490, 0.0652, 0.0330,
        0.0618], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,090][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.8038, 0.0106, 0.0030, 0.0307, 0.0094, 0.0328, 0.0076, 0.0174, 0.0141,
        0.0313, 0.0392], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,091][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.1951, 0.1306, 0.1685, 0.0831, 0.0959, 0.0951, 0.0452, 0.0607, 0.0386,
        0.0344, 0.0528], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,093][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0004, 0.0596, 0.0851, 0.0783, 0.0488, 0.0851, 0.1477, 0.0351, 0.2297,
        0.1124, 0.1178], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,097][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.4027, 0.0335, 0.0197, 0.0838, 0.0309, 0.1285, 0.0350, 0.0410, 0.0411,
        0.0834, 0.1003], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,099][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.2904, 0.0291, 0.0118, 0.0713, 0.0194, 0.0947, 0.0621, 0.0692, 0.0911,
        0.1082, 0.1528], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,100][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.6408, 0.0274, 0.0362, 0.0133, 0.0328, 0.0256, 0.0238, 0.0348, 0.0213,
        0.0695, 0.0747], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,101][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.5223, 0.0631, 0.0804, 0.0420, 0.0263, 0.0315, 0.0332, 0.0618, 0.0407,
        0.0343, 0.0646], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,102][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.1457, 0.1111, 0.1765, 0.0694, 0.1178, 0.0989, 0.0348, 0.0877, 0.0329,
        0.0777, 0.0476], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,102][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.1722, 0.0199, 0.0191, 0.0560, 0.0425, 0.0903, 0.0547, 0.0942, 0.0910,
        0.1979, 0.1623], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,106][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.1308, 0.0169, 0.0186, 0.0751, 0.0428, 0.1589, 0.0779, 0.0750, 0.1209,
        0.1094, 0.1737], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,110][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0008, 0.0194, 0.1788, 0.0297, 0.0766, 0.0484, 0.1379, 0.0499, 0.1703,
        0.1259, 0.1623], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,110][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.4016, 0.1222, 0.0610, 0.0610, 0.0616, 0.0689, 0.0417, 0.0593, 0.0290,
        0.0554, 0.0383], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,111][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.8786, 0.0085, 0.0022, 0.0176, 0.0051, 0.0159, 0.0021, 0.0061, 0.0045,
        0.0083, 0.0130, 0.0382], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,112][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1892, 0.1242, 0.1732, 0.0725, 0.0717, 0.0773, 0.0410, 0.0705, 0.0402,
        0.0363, 0.0541, 0.0496], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,113][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0004, 0.0661, 0.1035, 0.0796, 0.0473, 0.0754, 0.1148, 0.0362, 0.1910,
        0.0972, 0.1129, 0.0756], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,117][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.5285, 0.0317, 0.0160, 0.0647, 0.0196, 0.0855, 0.0154, 0.0220, 0.0186,
        0.0335, 0.0462, 0.1183], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,120][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.4469, 0.0271, 0.0107, 0.0488, 0.0150, 0.0533, 0.0293, 0.0352, 0.0391,
        0.0415, 0.0726, 0.1806], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,121][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.7529, 0.0217, 0.0262, 0.0088, 0.0227, 0.0145, 0.0107, 0.0210, 0.0119,
        0.0367, 0.0432, 0.0296], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,122][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.5222, 0.0551, 0.0699, 0.0359, 0.0234, 0.0260, 0.0290, 0.0583, 0.0340,
        0.0340, 0.0539, 0.0584], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,123][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1660, 0.1046, 0.1746, 0.0609, 0.0831, 0.0787, 0.0327, 0.0868, 0.0306,
        0.0770, 0.0523, 0.0527], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,124][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.3392, 0.0215, 0.0211, 0.0540, 0.0380, 0.0632, 0.0211, 0.0522, 0.0406,
        0.0778, 0.0797, 0.1916], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,127][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1973, 0.0240, 0.0153, 0.0602, 0.0274, 0.1171, 0.0385, 0.0431, 0.0592,
        0.0558, 0.0935, 0.2686], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,131][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0006, 0.0215, 0.1715, 0.0295, 0.0707, 0.0443, 0.1064, 0.0525, 0.1588,
        0.0994, 0.1388, 0.1058], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,132][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.3369, 0.1209, 0.0675, 0.0636, 0.0585, 0.0636, 0.0408, 0.0748, 0.0342,
        0.0482, 0.0397, 0.0512], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,133][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.6147, 0.0084, 0.0023, 0.0315, 0.0066, 0.0222, 0.0036, 0.0080, 0.0068,
        0.0122, 0.0197, 0.0755, 0.1884], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,133][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.1525, 0.0710, 0.1530, 0.0597, 0.0838, 0.0800, 0.0511, 0.0819, 0.0334,
        0.0431, 0.0653, 0.0589, 0.0663], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,134][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.0003, 0.0317, 0.0634, 0.0439, 0.0281, 0.0734, 0.1175, 0.0257, 0.1756,
        0.0880, 0.1272, 0.0872, 0.1380], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,138][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.3975, 0.0221, 0.0143, 0.0529, 0.0173, 0.0824, 0.0139, 0.0183, 0.0159,
        0.0242, 0.0406, 0.1221, 0.1785], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,142][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.3501, 0.0181, 0.0050, 0.0408, 0.0076, 0.0374, 0.0183, 0.0248, 0.0306,
        0.0298, 0.0596, 0.1794, 0.1987], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,142][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.4718, 0.0260, 0.0316, 0.0145, 0.0348, 0.0268, 0.0304, 0.0349, 0.0237,
        0.0691, 0.0707, 0.0644, 0.1013], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,143][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.3344, 0.0613, 0.0734, 0.0456, 0.0247, 0.0375, 0.0408, 0.0706, 0.0519,
        0.0444, 0.0709, 0.0847, 0.0598], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,144][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0782, 0.1079, 0.1669, 0.0688, 0.1039, 0.0841, 0.0324, 0.0647, 0.0308,
        0.0578, 0.0451, 0.0503, 0.1091], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,145][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.2378, 0.0110, 0.0097, 0.0318, 0.0187, 0.0374, 0.0158, 0.0285, 0.0325,
        0.0534, 0.0777, 0.1843, 0.2613], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,148][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.1372, 0.0113, 0.0075, 0.0432, 0.0152, 0.0821, 0.0236, 0.0257, 0.0401,
        0.0362, 0.0619, 0.2154, 0.3007], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,152][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.0009, 0.0130, 0.1081, 0.0229, 0.0360, 0.0577, 0.1223, 0.0414, 0.1493,
        0.0716, 0.1400, 0.1135, 0.1232], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,153][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.2597, 0.1177, 0.0586, 0.0733, 0.0487, 0.0718, 0.0513, 0.0720, 0.0388,
        0.0563, 0.0504, 0.0639, 0.0376], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,154][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.8372, 0.0098, 0.0018, 0.0167, 0.0042, 0.0126, 0.0010, 0.0030, 0.0018,
        0.0040, 0.0059, 0.0231, 0.0672, 0.0117], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,155][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.2119, 0.0975, 0.1456, 0.0705, 0.0674, 0.0877, 0.0358, 0.0547, 0.0270,
        0.0308, 0.0503, 0.0435, 0.0475, 0.0298], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,156][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0003, 0.0596, 0.0865, 0.0657, 0.0425, 0.0759, 0.1034, 0.0253, 0.1452,
        0.0803, 0.0853, 0.0637, 0.0998, 0.0664], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,159][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.4299, 0.0257, 0.0145, 0.0561, 0.0174, 0.0813, 0.0115, 0.0174, 0.0122,
        0.0229, 0.0322, 0.0905, 0.1280, 0.0603], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,163][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.3026, 0.0247, 0.0082, 0.0463, 0.0089, 0.0478, 0.0169, 0.0230, 0.0229,
        0.0243, 0.0452, 0.1422, 0.1873, 0.0997], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,164][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.6553, 0.0228, 0.0229, 0.0096, 0.0215, 0.0170, 0.0119, 0.0194, 0.0106,
        0.0400, 0.0427, 0.0344, 0.0631, 0.0287], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,165][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.4969, 0.0530, 0.0551, 0.0322, 0.0188, 0.0238, 0.0254, 0.0437, 0.0287,
        0.0281, 0.0501, 0.0543, 0.0418, 0.0480], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,166][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.1287, 0.0770, 0.1554, 0.0555, 0.0789, 0.0811, 0.0291, 0.0694, 0.0234,
        0.0603, 0.0433, 0.0519, 0.1048, 0.0413], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,167][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.1889, 0.0208, 0.0151, 0.0609, 0.0293, 0.0672, 0.0153, 0.0343, 0.0268,
        0.0517, 0.0512, 0.1610, 0.1711, 0.1063], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,170][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.1719, 0.0194, 0.0129, 0.0462, 0.0195, 0.0851, 0.0209, 0.0236, 0.0266,
        0.0284, 0.0482, 0.1605, 0.2143, 0.1223], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,174][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0004, 0.0138, 0.1376, 0.0185, 0.0549, 0.0379, 0.0899, 0.0342, 0.1100,
        0.0825, 0.1029, 0.0828, 0.1678, 0.0668], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,175][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.4344, 0.0951, 0.0548, 0.0408, 0.0428, 0.0460, 0.0299, 0.0545, 0.0204,
        0.0395, 0.0313, 0.0428, 0.0324, 0.0352], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,176][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.1667, 0.0043, 0.0026, 0.0123, 0.0050, 0.0150, 0.0075, 0.0154, 0.0139,
        0.0350, 0.0444, 0.1266, 0.4190, 0.0863, 0.0461], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,176][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0862, 0.0720, 0.1360, 0.0679, 0.0707, 0.0960, 0.0495, 0.0628, 0.0357,
        0.0399, 0.0498, 0.0537, 0.0465, 0.0353, 0.0981], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,177][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([1.0563e-04, 3.5598e-02, 6.2011e-02, 5.7366e-02, 3.0787e-02, 7.1888e-02,
        1.0130e-01, 1.9223e-02, 2.0175e-01, 7.2410e-02, 9.5709e-02, 7.6314e-02,
        8.8140e-02, 7.3968e-02, 1.3426e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,181][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.1724, 0.0164, 0.0113, 0.0340, 0.0142, 0.0581, 0.0212, 0.0256, 0.0264,
        0.0444, 0.0556, 0.1284, 0.2142, 0.0990, 0.0787], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,185][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.1014, 0.0098, 0.0047, 0.0201, 0.0063, 0.0257, 0.0258, 0.0287, 0.0373,
        0.0453, 0.0858, 0.1716, 0.2606, 0.1371, 0.0398], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,185][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.1929, 0.0249, 0.0321, 0.0182, 0.0287, 0.0337, 0.0382, 0.0492, 0.0378,
        0.0914, 0.0914, 0.0665, 0.1268, 0.0609, 0.1075], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,186][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.1666, 0.0533, 0.0691, 0.0397, 0.0212, 0.0412, 0.0437, 0.0658, 0.0550,
        0.0580, 0.0804, 0.0911, 0.0701, 0.0809, 0.0638], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,187][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0237, 0.0735, 0.1393, 0.0626, 0.0849, 0.0751, 0.0403, 0.0688, 0.0381,
        0.0753, 0.0457, 0.0503, 0.1054, 0.0427, 0.0743], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,188][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.0408, 0.0046, 0.0050, 0.0156, 0.0104, 0.0247, 0.0236, 0.0395, 0.0431,
        0.0769, 0.0780, 0.2012, 0.2478, 0.1360, 0.0532], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,192][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.0470, 0.0056, 0.0052, 0.0172, 0.0084, 0.0402, 0.0249, 0.0257, 0.0432,
        0.0504, 0.0721, 0.1669, 0.2690, 0.1608, 0.0633], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,195][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0002, 0.0142, 0.0949, 0.0245, 0.0407, 0.0393, 0.0898, 0.0258, 0.1559,
        0.0792, 0.1111, 0.0891, 0.1370, 0.0644, 0.0339], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,196][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.1146, 0.0994, 0.0571, 0.0716, 0.0478, 0.0739, 0.0634, 0.0579, 0.0508,
        0.0660, 0.0577, 0.0698, 0.0466, 0.0683, 0.0549], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,197][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.7370, 0.0057, 0.0014, 0.0141, 0.0033, 0.0087, 0.0012, 0.0034, 0.0019,
        0.0031, 0.0058, 0.0207, 0.0446, 0.0128, 0.0097, 0.1265],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,198][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.1528, 0.0727, 0.1084, 0.0496, 0.0561, 0.0599, 0.0405, 0.0681, 0.0342,
        0.0379, 0.0516, 0.0470, 0.0522, 0.0299, 0.0762, 0.0628],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,199][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0002, 0.0402, 0.0561, 0.0602, 0.0343, 0.0636, 0.1137, 0.0188, 0.1634,
        0.0766, 0.0881, 0.0736, 0.0942, 0.0809, 0.0130, 0.0231],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,203][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.3376, 0.0264, 0.0122, 0.0449, 0.0134, 0.0517, 0.0101, 0.0122, 0.0108,
        0.0180, 0.0264, 0.0722, 0.0838, 0.0523, 0.0391, 0.1888],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,206][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.2551, 0.0188, 0.0059, 0.0309, 0.0080, 0.0318, 0.0140, 0.0171, 0.0198,
        0.0178, 0.0351, 0.1048, 0.1101, 0.0745, 0.0237, 0.2326],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,207][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.4447, 0.0235, 0.0315, 0.0118, 0.0257, 0.0184, 0.0155, 0.0231, 0.0158,
        0.0401, 0.0494, 0.0396, 0.0791, 0.0328, 0.0854, 0.0637],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,208][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.3193, 0.0509, 0.0591, 0.0365, 0.0209, 0.0278, 0.0315, 0.0527, 0.0386,
        0.0344, 0.0568, 0.0594, 0.0465, 0.0548, 0.0575, 0.0533],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,209][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.1039, 0.0846, 0.1133, 0.0543, 0.0650, 0.0643, 0.0305, 0.0592, 0.0241,
        0.0597, 0.0383, 0.0450, 0.0894, 0.0418, 0.0730, 0.0536],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,211][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1831, 0.0128, 0.0104, 0.0344, 0.0164, 0.0321, 0.0121, 0.0210, 0.0212,
        0.0293, 0.0394, 0.1048, 0.1152, 0.0798, 0.0361, 0.2519],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,215][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1031, 0.0120, 0.0080, 0.0349, 0.0132, 0.0468, 0.0152, 0.0150, 0.0204,
        0.0203, 0.0319, 0.1076, 0.1326, 0.0899, 0.0458, 0.3034],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,217][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0008, 0.0102, 0.0707, 0.0215, 0.0289, 0.0422, 0.1116, 0.0298, 0.1076,
        0.0723, 0.1233, 0.1029, 0.1357, 0.0833, 0.0303, 0.0290],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,218][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.2593, 0.0849, 0.0429, 0.0592, 0.0362, 0.0625, 0.0448, 0.0550, 0.0347,
        0.0485, 0.0453, 0.0558, 0.0328, 0.0556, 0.0416, 0.0410],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,219][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([8.1075e-01, 3.9974e-03, 7.5323e-04, 8.1284e-03, 1.6243e-03, 5.2622e-03,
        3.6176e-04, 1.1052e-03, 6.8200e-04, 1.0923e-03, 2.1568e-03, 8.5578e-03,
        2.2074e-02, 4.6697e-03, 4.3676e-03, 8.5021e-02, 3.9393e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,220][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1909, 0.0905, 0.0997, 0.0536, 0.0511, 0.0559, 0.0290, 0.0476, 0.0280,
        0.0283, 0.0424, 0.0390, 0.0412, 0.0250, 0.0665, 0.0543, 0.0569],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,222][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0002, 0.0405, 0.0562, 0.0489, 0.0334, 0.0559, 0.0806, 0.0286, 0.1542,
        0.0778, 0.0821, 0.0585, 0.0948, 0.0693, 0.0182, 0.0304, 0.0705],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,227][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.4362, 0.0179, 0.0069, 0.0338, 0.0076, 0.0384, 0.0048, 0.0072, 0.0057,
        0.0092, 0.0154, 0.0433, 0.0570, 0.0319, 0.0222, 0.1486, 0.1138],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,230][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.3790, 0.0125, 0.0040, 0.0209, 0.0047, 0.0192, 0.0056, 0.0087, 0.0092,
        0.0082, 0.0170, 0.0516, 0.0624, 0.0359, 0.0140, 0.1601, 0.1869],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,231][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.6893, 0.0162, 0.0155, 0.0062, 0.0138, 0.0090, 0.0056, 0.0104, 0.0056,
        0.0178, 0.0235, 0.0177, 0.0303, 0.0142, 0.0520, 0.0411, 0.0320],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,232][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.4903, 0.0392, 0.0436, 0.0254, 0.0142, 0.0171, 0.0191, 0.0366, 0.0213,
        0.0215, 0.0360, 0.0396, 0.0320, 0.0366, 0.0454, 0.0384, 0.0438],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,233][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1244, 0.0710, 0.1125, 0.0457, 0.0589, 0.0643, 0.0213, 0.0621, 0.0218,
        0.0489, 0.0341, 0.0388, 0.0850, 0.0317, 0.0641, 0.0560, 0.0596],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,235][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2668, 0.0113, 0.0064, 0.0268, 0.0118, 0.0224, 0.0048, 0.0116, 0.0087,
        0.0135, 0.0174, 0.0576, 0.0580, 0.0465, 0.0215, 0.1955, 0.2192],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,239][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1417, 0.0102, 0.0051, 0.0225, 0.0076, 0.0335, 0.0062, 0.0085, 0.0102,
        0.0090, 0.0165, 0.0620, 0.0759, 0.0477, 0.0253, 0.2330, 0.2850],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,241][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0006, 0.0082, 0.0649, 0.0170, 0.0346, 0.0288, 0.0603, 0.0364, 0.0739,
        0.0674, 0.0894, 0.0870, 0.1476, 0.0748, 0.0434, 0.0408, 0.1249],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,242][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.4081, 0.0804, 0.0419, 0.0404, 0.0361, 0.0428, 0.0254, 0.0526, 0.0189,
        0.0354, 0.0248, 0.0352, 0.0296, 0.0297, 0.0365, 0.0353, 0.0270],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,243][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([5.2339e-01, 1.8172e-03, 3.9277e-04, 6.1250e-03, 1.0114e-03, 3.6752e-03,
        4.9058e-04, 1.2719e-03, 8.5356e-04, 1.2777e-03, 3.0348e-03, 1.3762e-02,
        3.0785e-02, 9.0145e-03, 4.4955e-03, 1.1571e-01, 9.2608e-02, 1.9029e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,244][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.1884, 0.0608, 0.0893, 0.0394, 0.0427, 0.0448, 0.0279, 0.0642, 0.0277,
        0.0344, 0.0518, 0.0408, 0.0384, 0.0189, 0.0704, 0.0548, 0.0430, 0.0623],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,246][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.0003, 0.0420, 0.0606, 0.0497, 0.0326, 0.0534, 0.0856, 0.0206, 0.1285,
        0.0687, 0.0816, 0.0675, 0.0799, 0.0554, 0.0163, 0.0278, 0.0762, 0.0535],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,250][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.3203, 0.0100, 0.0043, 0.0210, 0.0051, 0.0243, 0.0039, 0.0055, 0.0045,
        0.0073, 0.0135, 0.0408, 0.0501, 0.0277, 0.0199, 0.1452, 0.1244, 0.1722],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,252][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.2423, 0.0072, 0.0016, 0.0144, 0.0022, 0.0118, 0.0048, 0.0068, 0.0072,
        0.0063, 0.0135, 0.0528, 0.0455, 0.0351, 0.0090, 0.1491, 0.2217, 0.1687],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,253][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.3637, 0.0222, 0.0244, 0.0110, 0.0239, 0.0151, 0.0129, 0.0200, 0.0132,
        0.0335, 0.0361, 0.0370, 0.0600, 0.0310, 0.0773, 0.0768, 0.0696, 0.0724],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,254][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.3075, 0.0398, 0.0596, 0.0324, 0.0182, 0.0224, 0.0252, 0.0435, 0.0358,
        0.0265, 0.0482, 0.0519, 0.0415, 0.0467, 0.0593, 0.0490, 0.0493, 0.0433],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,255][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0772, 0.0725, 0.1116, 0.0455, 0.0597, 0.0533, 0.0219, 0.0494, 0.0214,
        0.0448, 0.0329, 0.0355, 0.0606, 0.0290, 0.0733, 0.0460, 0.0583, 0.1071],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,258][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.1500, 0.0043, 0.0022, 0.0116, 0.0044, 0.0091, 0.0040, 0.0075, 0.0069,
        0.0087, 0.0137, 0.0536, 0.0502, 0.0328, 0.0137, 0.1318, 0.2315, 0.2639],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,262][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.0879, 0.0031, 0.0019, 0.0120, 0.0036, 0.0178, 0.0042, 0.0051, 0.0069,
        0.0058, 0.0113, 0.0485, 0.0586, 0.0387, 0.0172, 0.1853, 0.2399, 0.2520],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,263][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0017, 0.0111, 0.0481, 0.0167, 0.0275, 0.0394, 0.0771, 0.0233, 0.0978,
        0.0511, 0.1069, 0.0781, 0.0848, 0.0496, 0.0350, 0.0275, 0.0970, 0.1273],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,264][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.3391, 0.0790, 0.0495, 0.0518, 0.0368, 0.0493, 0.0328, 0.0481, 0.0226,
        0.0328, 0.0293, 0.0358, 0.0264, 0.0338, 0.0370, 0.0360, 0.0287, 0.0311],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,265][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([5.7013e-01, 2.2468e-03, 3.4023e-04, 4.5016e-03, 8.9595e-04, 3.0893e-03,
        3.2918e-04, 9.5307e-04, 6.9870e-04, 1.0460e-03, 2.0030e-03, 1.0124e-02,
        2.6222e-02, 5.6922e-03, 3.6370e-03, 1.0891e-01, 5.6756e-02, 1.6677e-01,
        3.5660e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,266][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.2912, 0.0591, 0.0739, 0.0322, 0.0367, 0.0369, 0.0208, 0.0442, 0.0174,
        0.0208, 0.0364, 0.0301, 0.0361, 0.0189, 0.0638, 0.0509, 0.0461, 0.0547,
        0.0298], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,270][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0002, 0.0388, 0.0535, 0.0364, 0.0262, 0.0524, 0.0764, 0.0225, 0.1075,
        0.0530, 0.0595, 0.0465, 0.0683, 0.0535, 0.0138, 0.0282, 0.0721, 0.0605,
        0.1306], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,274][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2935, 0.0081, 0.0036, 0.0193, 0.0045, 0.0239, 0.0040, 0.0059, 0.0043,
        0.0063, 0.0121, 0.0408, 0.0477, 0.0274, 0.0168, 0.1445, 0.1207, 0.1456,
        0.0709], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,274][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2103, 0.0067, 0.0013, 0.0109, 0.0022, 0.0124, 0.0045, 0.0062, 0.0067,
        0.0064, 0.0135, 0.0454, 0.0453, 0.0321, 0.0079, 0.1338, 0.1937, 0.1425,
        0.1182], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,275][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.5616, 0.0154, 0.0122, 0.0061, 0.0115, 0.0109, 0.0076, 0.0117, 0.0062,
        0.0208, 0.0243, 0.0234, 0.0395, 0.0179, 0.0457, 0.0511, 0.0468, 0.0530,
        0.0344], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,276][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.4794, 0.0370, 0.0377, 0.0233, 0.0133, 0.0162, 0.0175, 0.0312, 0.0193,
        0.0168, 0.0310, 0.0359, 0.0264, 0.0307, 0.0415, 0.0365, 0.0423, 0.0358,
        0.0282], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,279][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1279, 0.0578, 0.0918, 0.0353, 0.0487, 0.0476, 0.0177, 0.0496, 0.0164,
        0.0368, 0.0313, 0.0351, 0.0530, 0.0290, 0.0639, 0.0467, 0.0639, 0.1057,
        0.0420], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,283][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0881, 0.0040, 0.0020, 0.0110, 0.0045, 0.0108, 0.0032, 0.0062, 0.0054,
        0.0094, 0.0118, 0.0386, 0.0441, 0.0311, 0.0111, 0.1493, 0.1729, 0.2950,
        0.1011], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,285][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0567, 0.0036, 0.0018, 0.0099, 0.0031, 0.0148, 0.0040, 0.0051, 0.0060,
        0.0062, 0.0110, 0.0416, 0.0522, 0.0358, 0.0140, 0.1542, 0.2196, 0.2452,
        0.1153], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,285][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0006, 0.0089, 0.0622, 0.0096, 0.0254, 0.0237, 0.0486, 0.0262, 0.0500,
        0.0452, 0.0516, 0.0499, 0.0875, 0.0417, 0.0314, 0.0324, 0.0876, 0.2382,
        0.0794], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,286][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.3955, 0.0766, 0.0413, 0.0370, 0.0322, 0.0440, 0.0238, 0.0477, 0.0150,
        0.0292, 0.0245, 0.0338, 0.0244, 0.0286, 0.0352, 0.0337, 0.0279, 0.0320,
        0.0176], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,290][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:58,293][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[4747],
        [ 495],
        [9635],
        [6396],
        [5536],
        [4581],
        [3812],
        [4427],
        [ 591],
        [1159],
        [1793],
        [1396],
        [ 668],
        [  74],
        [ 257],
        [ 909],
        [  45],
        [ 950],
        [  55]], device='cuda:0')
[2024-07-24 10:17:58,296][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[5158],
        [1034],
        [6506],
        [3713],
        [4304],
        [3415],
        [3467],
        [4299],
        [ 949],
        [1406],
        [2662],
        [2026],
        [1252],
        [ 202],
        [ 625],
        [1652],
        [ 144],
        [1595],
        [ 156]], device='cuda:0')
[2024-07-24 10:17:58,298][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[21876],
        [20961],
        [18462],
        [17279],
        [15490],
        [15167],
        [15339],
        [14950],
        [14926],
        [15079],
        [14391],
        [14173],
        [13671],
        [13743],
        [13584],
        [13882],
        [13911],
        [13813],
        [13842]], device='cuda:0')
[2024-07-24 10:17:58,299][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[21374],
        [10563],
        [13492],
        [14536],
        [14251],
        [ 2908],
        [ 1845],
        [ 2322],
        [ 1705],
        [ 2179],
        [ 1477],
        [ 1424],
        [ 1303],
        [ 1228],
        [ 1299],
        [ 1231],
        [ 1094],
        [ 1798],
        [ 1087]], device='cuda:0')
[2024-07-24 10:17:58,302][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[26273],
        [19305],
        [41764],
        [40155],
        [39150],
        [37972],
        [37700],
        [36372],
        [35635],
        [35394],
        [34723],
        [34002],
        [32203],
        [32399],
        [32430],
        [31988],
        [32270],
        [32019],
        [31741]], device='cuda:0')
[2024-07-24 10:17:58,305][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 7476],
        [12508],
        [ 9038],
        [ 9899],
        [ 9685],
        [11500],
        [12284],
        [12917],
        [13129],
        [13226],
        [13440],
        [13604],
        [13442],
        [13195],
        [13041],
        [13035],
        [13230],
        [13252],
        [13272]], device='cuda:0')
[2024-07-24 10:17:58,308][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 6756],
        [15050],
        [14303],
        [15077],
        [15206],
        [14186],
        [12992],
        [12269],
        [11419],
        [11012],
        [10832],
        [10510],
        [ 9377],
        [ 8775],
        [ 9110],
        [ 9629],
        [10481],
        [10414],
        [ 9984]], device='cuda:0')
[2024-07-24 10:17:58,310][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[40668],
        [31474],
        [23155],
        [28285],
        [17873],
        [19224],
        [14845],
        [14139],
        [13764],
        [13751],
        [13732],
        [14193],
        [12664],
        [13549],
        [12349],
        [11978],
        [14987],
        [11705],
        [11783]], device='cuda:0')
[2024-07-24 10:17:58,311][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[   80],
        [ 1515],
        [31285],
        [ 2245],
        [32633],
        [ 4508],
        [ 6081],
        [38741],
        [23317],
        [38102],
        [30591],
        [33974],
        [43375],
        [35332],
        [43663],
        [41878],
        [37954],
        [43435],
        [38961]], device='cuda:0')
[2024-07-24 10:17:58,313][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[25242],
        [10638],
        [12685],
        [13551],
        [13979],
        [15050],
        [14860],
        [14753],
        [14147],
        [13565],
        [13269],
        [12151],
        [10707],
        [10874],
        [10825],
        [10489],
        [10991],
        [10327],
        [ 9250]], device='cuda:0')
[2024-07-24 10:17:58,317][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 5611],
        [ 6634],
        [10966],
        [ 9849],
        [ 8031],
        [ 9684],
        [ 8209],
        [ 4871],
        [ 4014],
        [ 6538],
        [ 6605],
        [ 6501],
        [ 3386],
        [ 4925],
        [ 4828],
        [ 4354],
        [ 6395],
        [ 6325],
        [ 6086]], device='cuda:0')
[2024-07-24 10:17:58,320][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[35238],
        [22939],
        [18456],
        [18437],
        [20883],
        [23049],
        [23093],
        [22596],
        [22715],
        [22837],
        [22229],
        [21864],
        [22259],
        [22226],
        [22338],
        [22870],
        [22882],
        [22441],
        [22508]], device='cuda:0')
[2024-07-24 10:17:58,321][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 8312],
        [ 3408],
        [50050],
        [50118],
        [47189],
        [48974],
        [42638],
        [40235],
        [25827],
        [16217],
        [25053],
        [33543],
        [ 8077],
        [14986],
        [ 6030],
        [ 6422],
        [ 7969],
        [ 8411],
        [12985]], device='cuda:0')
[2024-07-24 10:17:58,323][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[28383],
        [ 5467],
        [ 9777],
        [12958],
        [12230],
        [11490],
        [11192],
        [ 6143],
        [ 5034],
        [ 3834],
        [ 4132],
        [ 3226],
        [ 2225],
        [ 4232],
        [ 1913],
        [ 2168],
        [ 2844],
        [ 2886],
        [ 3230]], device='cuda:0')
[2024-07-24 10:17:58,325][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[12454],
        [20529],
        [20438],
        [19714],
        [17966],
        [21791],
        [24160],
        [17735],
        [25117],
        [20898],
        [21683],
        [25854],
        [24031],
        [29801],
        [19837],
        [23582],
        [25426],
        [18767],
        [26376]], device='cuda:0')
[2024-07-24 10:17:58,328][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[42872],
        [43274],
        [44808],
        [43982],
        [45991],
        [44943],
        [45123],
        [43859],
        [45203],
        [47136],
        [46698],
        [45605],
        [47433],
        [46155],
        [44471],
        [47350],
        [46616],
        [47249],
        [47319]], device='cuda:0')
[2024-07-24 10:17:58,331][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[44828],
        [40301],
        [33945],
        [34530],
        [31614],
        [30684],
        [30545],
        [29737],
        [31457],
        [28785],
        [28505],
        [28420],
        [26965],
        [28187],
        [26815],
        [27426],
        [27808],
        [27585],
        [28905]], device='cuda:0')
[2024-07-24 10:17:58,333][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[30965],
        [31841],
        [33616],
        [38749],
        [38672],
        [39820],
        [36495],
        [32770],
        [32873],
        [31123],
        [27771],
        [26473],
        [22659],
        [25490],
        [24339],
        [24458],
        [24787],
        [23681],
        [21688]], device='cuda:0')
[2024-07-24 10:17:58,334][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[11787],
        [ 7154],
        [ 6122],
        [ 4477],
        [ 3721],
        [ 2050],
        [ 1815],
        [ 2107],
        [ 1816],
        [ 2058],
        [ 2181],
        [ 2307],
        [ 2048],
        [ 2274],
        [ 2635],
        [ 1811],
        [ 2029],
        [ 2262],
        [ 2022]], device='cuda:0')
[2024-07-24 10:17:58,337][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[29814],
        [17914],
        [18289],
        [13104],
        [14095],
        [ 8554],
        [ 7561],
        [ 5501],
        [ 6787],
        [ 5894],
        [ 6189],
        [ 7283],
        [ 9984],
        [ 9582],
        [10188],
        [ 9183],
        [ 7688],
        [ 6568],
        [ 6534]], device='cuda:0')
[2024-07-24 10:17:58,340][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[33165],
        [30777],
        [19211],
        [29614],
        [19615],
        [24357],
        [22571],
        [21014],
        [20722],
        [22943],
        [22244],
        [22648],
        [10314],
        [21795],
        [ 8849],
        [ 9116],
        [21171],
        [ 6272],
        [13307]], device='cuda:0')
[2024-07-24 10:17:58,343][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[43533],
        [43973],
        [48151],
        [44353],
        [47410],
        [45606],
        [44840],
        [46567],
        [44312],
        [44460],
        [44260],
        [42910],
        [41194],
        [41387],
        [41927],
        [40606],
        [40706],
        [40598],
        [40885]], device='cuda:0')
[2024-07-24 10:17:58,345][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[46733],
        [17794],
        [ 9986],
        [ 9144],
        [10573],
        [10076],
        [10050],
        [ 9796],
        [ 9460],
        [ 9808],
        [10103],
        [10119],
        [ 9935],
        [ 9449],
        [ 9871],
        [10118],
        [ 9873],
        [10266],
        [10290]], device='cuda:0')
[2024-07-24 10:17:58,346][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[49233],
        [45772],
        [42495],
        [37832],
        [37591],
        [29014],
        [25017],
        [14266],
        [26720],
        [23714],
        [24764],
        [34455],
        [32200],
        [26446],
        [22720],
        [29060],
        [36055],
        [18343],
        [14257]], device='cuda:0')
[2024-07-24 10:17:58,348][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[33537],
        [27508],
        [20828],
        [18460],
        [23238],
        [19789],
        [18154],
        [20002],
        [20595],
        [22523],
        [23227],
        [25760],
        [35421],
        [33395],
        [35464],
        [33418],
        [32070],
        [29770],
        [31508]], device='cuda:0')
[2024-07-24 10:17:58,352][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[47920],
        [19127],
        [17525],
        [17196],
        [15569],
        [14000],
        [12451],
        [13388],
        [17096],
        [16164],
        [14473],
        [15921],
        [20255],
        [21899],
        [21647],
        [21856],
        [23065],
        [21310],
        [23554]], device='cuda:0')
[2024-07-24 10:17:58,355][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[33559],
        [12625],
        [ 8295],
        [11143],
        [12145],
        [12776],
        [11671],
        [15177],
        [13874],
        [14841],
        [14759],
        [15601],
        [16634],
        [14595],
        [17775],
        [16279],
        [14485],
        [15795],
        [15127]], device='cuda:0')
[2024-07-24 10:17:58,356][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[   54],
        [ 4758],
        [ 8633],
        [11033],
        [ 9292],
        [13889],
        [16265],
        [14296],
        [14667],
        [12229],
        [12233],
        [12271],
        [12120],
        [11726],
        [13985],
        [13269],
        [11075],
        [16084],
        [14004]], device='cuda:0')
[2024-07-24 10:17:58,358][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[26439],
        [22038],
        [22064],
        [27513],
        [27470],
        [28812],
        [30344],
        [36734],
        [31531],
        [35660],
        [35922],
        [31943],
        [32548],
        [29801],
        [35089],
        [33417],
        [32378],
        [37264],
        [35049]], device='cuda:0')
[2024-07-24 10:17:58,360][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[5455],
        [5455],
        [5455],
        [5455],
        [5455],
        [5455],
        [5455],
        [5455],
        [5455],
        [5455],
        [5455],
        [5455],
        [5455],
        [5455],
        [5455],
        [5455],
        [5455],
        [5455],
        [5455]], device='cuda:0')
[2024-07-24 10:17:58,435][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:58,438][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,439][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,439][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,440][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,441][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,441][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,443][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,443][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,444][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,445][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,445][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,446][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,447][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4855, 0.5145], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,447][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.0000e+00, 6.5035e-07], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,448][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.7066, 0.2934], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,449][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([4.5048e-04, 9.9955e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,449][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.7048, 0.2952], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,450][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2965, 0.7035], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,451][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0346, 0.9654], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,454][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0062, 0.9938], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,457][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2887, 0.7113], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,458][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1928, 0.8072], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,458][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7643, 0.2357], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,459][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.7725, 0.2275], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,460][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Jamie] are: tensor([0.0590, 0.4343, 0.5067], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,461][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Jamie] are: tensor([1.0000e+00, 7.7405e-07, 1.7323e-06], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,464][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Jamie] are: tensor([0.5095, 0.2659, 0.2246], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,468][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Jamie] are: tensor([0.0012, 0.5541, 0.4447], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,468][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Jamie] are: tensor([0.4781, 0.1164, 0.4055], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,469][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Jamie] are: tensor([0.1391, 0.4335, 0.4274], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,470][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Jamie] are: tensor([0.0043, 0.6234, 0.3723], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,470][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Jamie] are: tensor([0.0035, 0.4336, 0.5629], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,472][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Jamie] are: tensor([0.0690, 0.4545, 0.4765], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,476][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Jamie] are: tensor([0.1228, 0.4092, 0.4679], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,478][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Jamie] are: tensor([0.8500, 0.0873, 0.0627], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,479][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Jamie] are: tensor([0.5711, 0.1182, 0.3107], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,480][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1444, 0.2543, 0.2928, 0.3085], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,480][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([9.9990e-01, 1.8328e-05, 3.7380e-05, 4.5740e-05], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,481][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.5949, 0.1759, 0.1650, 0.0642], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,482][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([3.5797e-04, 3.5799e-01, 2.4181e-01, 3.9984e-01], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,485][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4330, 0.1502, 0.1916, 0.2252], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,489][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1105, 0.3020, 0.3000, 0.2874], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,490][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0020, 0.4882, 0.2879, 0.2220], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,490][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0043, 0.2618, 0.3021, 0.4319], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,491][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0639, 0.2988, 0.3296, 0.3078], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,492][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0582, 0.2332, 0.2636, 0.4449], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,494][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.7202, 0.1062, 0.0581, 0.1156], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,498][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4139, 0.1421, 0.2062, 0.2378], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,500][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0393, 0.2488, 0.2498, 0.1608, 0.3012], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,500][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([9.9212e-01, 1.7923e-04, 3.5302e-04, 5.2195e-04, 6.8295e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,501][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.2465, 0.2443, 0.2159, 0.1127, 0.1806], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,502][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.0011, 0.2882, 0.2622, 0.3842, 0.0643], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,502][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.4141, 0.0754, 0.1185, 0.2640, 0.1281], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,505][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0674, 0.2343, 0.2352, 0.2244, 0.2387], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,507][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([4.0197e-04, 5.4182e-01, 2.4799e-01, 1.6972e-01, 4.0062e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,510][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0020, 0.1809, 0.2129, 0.3192, 0.2849], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,511][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.0235, 0.2543, 0.2554, 0.2493, 0.2175], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,512][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0436, 0.2212, 0.1971, 0.2930, 0.2452], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,512][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.7209, 0.0783, 0.0493, 0.0965, 0.0550], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,513][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.2106, 0.1059, 0.1698, 0.2614, 0.2523], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,516][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0508, 0.3826, 0.1237, 0.1719, 0.2123, 0.0588], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,518][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ had] are: tensor([9.9972e-01, 5.0641e-06, 1.0250e-05, 1.4675e-05, 2.2718e-04, 1.8010e-05],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,521][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.4577, 0.1376, 0.1454, 0.0588, 0.1246, 0.0760], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,522][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0004, 0.2515, 0.2023, 0.3112, 0.0480, 0.1866], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,522][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.5381, 0.0631, 0.0527, 0.1580, 0.0819, 0.1062], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,523][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0485, 0.1835, 0.1815, 0.1751, 0.1845, 0.2269], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,524][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0016, 0.3630, 0.2240, 0.1693, 0.0573, 0.1848], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,526][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0028, 0.1490, 0.1590, 0.2268, 0.1952, 0.2673], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,531][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0310, 0.1927, 0.1972, 0.1880, 0.1687, 0.2224], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,532][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0876, 0.1605, 0.1374, 0.1804, 0.1295, 0.3046], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,532][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.8202, 0.0506, 0.0235, 0.0522, 0.0217, 0.0318], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,533][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.2485, 0.0861, 0.1035, 0.1583, 0.1381, 0.2655], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,534][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0683, 0.1692, 0.0679, 0.1141, 0.2858, 0.0919, 0.2028],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,535][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([9.9976e-01, 2.7663e-06, 6.0845e-06, 1.0870e-05, 1.9756e-04, 1.3414e-05,
        1.2482e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,538][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.3651, 0.1549, 0.1505, 0.0618, 0.1239, 0.0757, 0.0680],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,540][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([2.9887e-04, 1.9313e-01, 1.8978e-01, 3.0505e-01, 4.8243e-02, 1.5504e-01,
        1.0845e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,542][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.4888, 0.0293, 0.0144, 0.1852, 0.0332, 0.1176, 0.1315],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,543][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0388, 0.1540, 0.1506, 0.1455, 0.1487, 0.1881, 0.1744],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,544][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0008, 0.3748, 0.1929, 0.1476, 0.0441, 0.1682, 0.0716],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,545][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0012, 0.1034, 0.1154, 0.1746, 0.1477, 0.2203, 0.2373],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,545][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0213, 0.1584, 0.1617, 0.1566, 0.1405, 0.1904, 0.1711],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,548][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0686, 0.1172, 0.0878, 0.1320, 0.0996, 0.2864, 0.2085],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,553][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.7205, 0.0586, 0.0263, 0.0842, 0.0318, 0.0478, 0.0309],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,553][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1039, 0.0630, 0.0571, 0.1211, 0.0885, 0.2462, 0.3202],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:58,554][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0041, 0.5867, 0.0658, 0.1019, 0.0250, 0.0062, 0.0367, 0.1737],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,555][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([9.9989e-01, 1.3908e-06, 2.9564e-06, 4.8313e-06, 8.2312e-05, 6.7847e-06,
        6.1760e-06, 4.7017e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,556][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.1900, 0.1434, 0.1392, 0.0558, 0.1110, 0.0737, 0.0637, 0.2232],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,557][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([1.5735e-04, 1.1374e-01, 1.1182e-01, 2.9724e-01, 2.6939e-02, 2.1344e-01,
        1.3340e-01, 1.0325e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,560][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.6111, 0.0339, 0.0204, 0.1348, 0.0422, 0.0756, 0.0741, 0.0079],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,566][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0282, 0.1256, 0.1243, 0.1167, 0.1213, 0.1473, 0.1432, 0.1934],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,567][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0087, 0.1620, 0.1405, 0.1314, 0.0727, 0.1459, 0.0771, 0.2617],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,568][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0030, 0.1096, 0.0995, 0.1427, 0.1167, 0.1624, 0.1967, 0.1694],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,569][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0529, 0.1265, 0.1353, 0.1287, 0.1243, 0.1544, 0.1527, 0.1252],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,570][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.1482, 0.2016, 0.1509, 0.1785, 0.0674, 0.1126, 0.1235, 0.0173],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,571][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.8944, 0.0306, 0.0104, 0.0274, 0.0103, 0.0124, 0.0119, 0.0026],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,576][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0924, 0.0377, 0.0364, 0.0956, 0.0754, 0.1988, 0.3589, 0.1048],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:58,578][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0119, 0.0396, 0.0159, 0.0325, 0.1287, 0.0416, 0.0934, 0.5739, 0.0624],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,578][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ of] are: tensor([9.9732e-01, 3.5305e-05, 6.6031e-05, 1.3129e-04, 1.5190e-03, 2.1800e-04,
        1.4012e-04, 1.6112e-04, 4.0492e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,579][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.2235, 0.1446, 0.1130, 0.0529, 0.0966, 0.0662, 0.0578, 0.1745, 0.0709],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,580][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0003, 0.1343, 0.1546, 0.2178, 0.0549, 0.0809, 0.0596, 0.1204, 0.1773],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,581][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.3810, 0.0197, 0.0084, 0.1386, 0.0231, 0.0785, 0.1164, 0.0370, 0.1975],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,583][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0256, 0.1084, 0.1056, 0.1032, 0.1052, 0.1352, 0.1273, 0.2086, 0.0807],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,586][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ of] are: tensor([3.2977e-04, 2.1334e-01, 1.0337e-01, 8.0700e-02, 2.1635e-02, 8.8637e-02,
        3.9542e-02, 4.2099e-01, 3.1456e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,588][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0007, 0.0625, 0.0735, 0.1066, 0.0924, 0.1407, 0.1555, 0.2207, 0.1474],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,589][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0133, 0.1137, 0.1148, 0.1086, 0.0991, 0.1363, 0.1252, 0.1695, 0.1194],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,590][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0081, 0.0186, 0.0124, 0.0232, 0.0167, 0.0537, 0.0368, 0.8071, 0.0233],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,591][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.5891, 0.0624, 0.0255, 0.0912, 0.0389, 0.0635, 0.0330, 0.0101, 0.0862],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,592][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0765, 0.0342, 0.0368, 0.0752, 0.0806, 0.2076, 0.2417, 0.1047, 0.1427],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:58,594][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0108, 0.1518, 0.0309, 0.0545, 0.0561, 0.0160, 0.0546, 0.4053, 0.0332,
        0.1867], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,597][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([9.9872e-01, 1.3247e-05, 2.6872e-05, 4.4637e-05, 6.1082e-04, 6.7311e-05,
        6.4518e-05, 5.0544e-05, 1.6390e-04, 2.3680e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,599][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.1894, 0.1238, 0.1001, 0.0509, 0.0791, 0.0560, 0.0465, 0.1487, 0.0611,
        0.1443], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,600][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([1.3619e-04, 6.8786e-02, 9.0983e-02, 1.5672e-01, 2.6338e-02, 9.5697e-02,
        6.6308e-02, 8.5218e-02, 2.4819e-01, 1.6162e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,601][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.4115, 0.0142, 0.0058, 0.1056, 0.0130, 0.0670, 0.1018, 0.0124, 0.1634,
        0.1053], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,602][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0219, 0.1019, 0.0992, 0.0946, 0.0966, 0.1231, 0.1157, 0.1777, 0.0743,
        0.0952], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,603][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([3.5981e-04, 2.0628e-01, 9.7859e-02, 7.6330e-02, 1.9788e-02, 8.9240e-02,
        3.6185e-02, 4.0623e-01, 2.7417e-02, 4.0309e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,605][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0005, 0.0586, 0.0620, 0.0966, 0.0787, 0.1249, 0.1399, 0.1853, 0.1365,
        0.1170], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,610][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0167, 0.0895, 0.0975, 0.0923, 0.0872, 0.1243, 0.1201, 0.1443, 0.1145,
        0.1137], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,611][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0222, 0.0479, 0.0320, 0.0470, 0.0348, 0.0992, 0.0676, 0.5031, 0.0530,
        0.0933], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,612][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.7764, 0.0339, 0.0137, 0.0468, 0.0149, 0.0277, 0.0178, 0.0047, 0.0420,
        0.0221], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,613][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0899, 0.0293, 0.0232, 0.0718, 0.0486, 0.1527, 0.2219, 0.0734, 0.1216,
        0.1678], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:58,613][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0093, 0.1113, 0.0286, 0.0413, 0.0560, 0.0138, 0.0438, 0.4057, 0.0196,
        0.1705, 0.1002], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,615][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ at] are: tensor([9.9857e-01, 1.0896e-05, 2.3662e-05, 3.9527e-05, 6.4944e-04, 6.1893e-05,
        5.2988e-05, 5.3921e-05, 1.5658e-04, 2.8876e-04, 9.1967e-05],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,619][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1945, 0.1086, 0.0940, 0.0378, 0.0762, 0.0495, 0.0413, 0.1505, 0.0534,
        0.1379, 0.0563], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,621][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ at] are: tensor([7.5971e-05, 5.3788e-02, 5.7641e-02, 1.1381e-01, 1.4918e-02, 7.3242e-02,
        5.5108e-02, 6.1114e-02, 2.3206e-01, 1.5881e-01, 1.7944e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,622][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.3529, 0.0188, 0.0076, 0.1156, 0.0174, 0.0758, 0.0697, 0.0135, 0.1266,
        0.0912, 0.1109], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,623][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0186, 0.0903, 0.0880, 0.0864, 0.0876, 0.1133, 0.1069, 0.1682, 0.0675,
        0.0880, 0.0852], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,624][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ at] are: tensor([3.8463e-04, 1.9505e-01, 9.4598e-02, 7.4459e-02, 2.0103e-02, 8.3400e-02,
        3.5795e-02, 3.9055e-01, 2.7229e-02, 3.8572e-02, 3.9851e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,624][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0005, 0.0530, 0.0547, 0.0883, 0.0707, 0.1133, 0.1273, 0.1591, 0.1216,
        0.1026, 0.1089], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,628][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0103, 0.0872, 0.0922, 0.0881, 0.0790, 0.1101, 0.1038, 0.1404, 0.0978,
        0.1054, 0.0856], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,632][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0228, 0.0432, 0.0274, 0.0476, 0.0298, 0.0926, 0.0603, 0.4565, 0.0442,
        0.0773, 0.0982], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,632][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.7388, 0.0409, 0.0135, 0.0519, 0.0160, 0.0262, 0.0178, 0.0042, 0.0400,
        0.0195, 0.0312], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,633][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0909, 0.0288, 0.0251, 0.0636, 0.0427, 0.1251, 0.1708, 0.0611, 0.0952,
        0.1262, 0.1705], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:58,634][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0160, 0.0672, 0.0193, 0.0471, 0.0729, 0.0222, 0.0672, 0.2816, 0.0415,
        0.1645, 0.1039, 0.0967], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,635][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ the] are: tensor([9.9795e-01, 2.2239e-05, 4.5038e-05, 6.5373e-05, 8.7004e-04, 9.4737e-05,
        7.7155e-05, 8.3468e-05, 2.0822e-04, 3.8351e-04, 1.2933e-04, 6.9256e-05],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,639][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2187, 0.0927, 0.0870, 0.0333, 0.0671, 0.0450, 0.0359, 0.1373, 0.0497,
        0.1230, 0.0507, 0.0596], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,642][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0002, 0.0758, 0.0705, 0.1057, 0.0228, 0.0380, 0.0343, 0.0734, 0.1053,
        0.1344, 0.1565, 0.1829], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,643][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2668, 0.0196, 0.0072, 0.0839, 0.0129, 0.0502, 0.0341, 0.0134, 0.0528,
        0.0384, 0.0551, 0.3656], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,644][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0206, 0.0879, 0.0846, 0.0815, 0.0826, 0.1063, 0.0983, 0.1554, 0.0614,
        0.0794, 0.0776, 0.0645], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,645][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ the] are: tensor([3.6034e-04, 1.9844e-01, 9.3789e-02, 7.1060e-02, 1.9612e-02, 7.6542e-02,
        3.4013e-02, 3.7249e-01, 2.6362e-02, 3.7503e-02, 3.7476e-02, 3.2347e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,646][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0005, 0.0503, 0.0539, 0.0818, 0.0681, 0.1033, 0.1111, 0.1448, 0.1058,
        0.0905, 0.0950, 0.0949], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,649][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0102, 0.0840, 0.0816, 0.0814, 0.0722, 0.1029, 0.0922, 0.1321, 0.0878,
        0.0946, 0.0799, 0.0812], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,653][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0134, 0.0249, 0.0170, 0.0281, 0.0190, 0.0673, 0.0402, 0.5969, 0.0271,
        0.0530, 0.0674, 0.0458], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,654][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.5787, 0.0589, 0.0218, 0.0649, 0.0238, 0.0404, 0.0190, 0.0063, 0.0384,
        0.0207, 0.0308, 0.0963], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,655][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0673, 0.0379, 0.0267, 0.0541, 0.0496, 0.1258, 0.0981, 0.0619, 0.0548,
        0.0882, 0.1166, 0.2190], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:58,655][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0118, 0.0501, 0.0174, 0.0280, 0.0522, 0.0175, 0.0315, 0.4350, 0.0230,
        0.1123, 0.0807, 0.0686, 0.0718], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,656][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ store] are: tensor([9.9970e-01, 2.8319e-06, 5.3345e-06, 9.5817e-06, 1.3479e-04, 1.3751e-05,
        1.1651e-05, 8.7580e-06, 3.1929e-05, 4.4789e-05, 1.7537e-05, 1.1247e-05,
        9.9447e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,660][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.1253, 0.1094, 0.0855, 0.0398, 0.0643, 0.0453, 0.0363, 0.1089, 0.0470,
        0.1025, 0.0488, 0.0645, 0.1225], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,663][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0007, 0.0836, 0.0984, 0.1257, 0.0401, 0.0427, 0.0325, 0.1002, 0.0549,
        0.0957, 0.1251, 0.1117, 0.0886], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,664][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.1855, 0.0114, 0.0027, 0.0463, 0.0046, 0.0331, 0.0198, 0.0084, 0.0307,
        0.0198, 0.0369, 0.2504, 0.3506], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,665][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0206, 0.0860, 0.0800, 0.0782, 0.0775, 0.1016, 0.0923, 0.1507, 0.0564,
        0.0729, 0.0712, 0.0592, 0.0534], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,666][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0004, 0.1830, 0.0930, 0.0708, 0.0202, 0.0810, 0.0331, 0.3412, 0.0256,
        0.0360, 0.0370, 0.0324, 0.0463], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,667][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0004, 0.0448, 0.0470, 0.0736, 0.0589, 0.0945, 0.1021, 0.1382, 0.0968,
        0.0824, 0.0885, 0.0899, 0.0830], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,671][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.0097, 0.0771, 0.0767, 0.0731, 0.0675, 0.0958, 0.0858, 0.1215, 0.0807,
        0.0817, 0.0736, 0.0746, 0.0823], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,674][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0118, 0.0231, 0.0153, 0.0251, 0.0171, 0.0613, 0.0342, 0.6058, 0.0207,
        0.0417, 0.0562, 0.0354, 0.0523], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,675][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.4481, 0.0572, 0.0166, 0.0608, 0.0168, 0.0449, 0.0157, 0.0079, 0.0303,
        0.0199, 0.0305, 0.0810, 0.1704], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,676][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0728, 0.0246, 0.0148, 0.0415, 0.0284, 0.0976, 0.0750, 0.0570, 0.0349,
        0.0637, 0.0854, 0.1638, 0.2405], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:58,677][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0077, 0.0384, 0.0114, 0.0307, 0.0679, 0.0210, 0.0430, 0.2354, 0.0301,
        0.1134, 0.0955, 0.0894, 0.0813, 0.1347], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,678][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [.] are: tensor([9.9911e-01, 6.8052e-06, 1.2886e-05, 2.4476e-05, 3.8906e-04, 3.5444e-05,
        2.9884e-05, 2.5054e-05, 8.7244e-05, 1.4502e-04, 4.8454e-05, 2.8608e-05,
        3.2081e-05, 2.2835e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,681][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0998, 0.0898, 0.0731, 0.0333, 0.0628, 0.0431, 0.0349, 0.1142, 0.0449,
        0.1004, 0.0457, 0.0569, 0.1089, 0.0923], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,685][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [.] are: tensor([1.3039e-04, 6.0754e-02, 7.1366e-02, 9.0064e-02, 2.3259e-02, 2.9133e-02,
        2.4829e-02, 5.8537e-02, 5.4574e-02, 9.5417e-02, 1.0770e-01, 1.1777e-01,
        9.2626e-02, 1.7384e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,686][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.2285, 0.0241, 0.0052, 0.0788, 0.0075, 0.0354, 0.0101, 0.0068, 0.0165,
        0.0129, 0.0199, 0.1354, 0.2050, 0.2138], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,687][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0178, 0.0840, 0.0778, 0.0752, 0.0743, 0.0964, 0.0861, 0.1406, 0.0527,
        0.0686, 0.0673, 0.0561, 0.0509, 0.0523], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,687][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0003, 0.1994, 0.0897, 0.0672, 0.0176, 0.0720, 0.0303, 0.3325, 0.0228,
        0.0321, 0.0330, 0.0288, 0.0420, 0.0322], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,688][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0005, 0.0471, 0.0498, 0.0741, 0.0586, 0.0903, 0.0915, 0.1165, 0.0833,
        0.0718, 0.0750, 0.0782, 0.0711, 0.0922], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,692][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0075, 0.0737, 0.0745, 0.0679, 0.0614, 0.0900, 0.0778, 0.1142, 0.0695,
        0.0745, 0.0644, 0.0675, 0.0755, 0.0817], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,695][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0082, 0.0177, 0.0110, 0.0207, 0.0122, 0.0555, 0.0283, 0.6539, 0.0160,
        0.0343, 0.0465, 0.0290, 0.0390, 0.0277], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,696][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.4779, 0.0610, 0.0200, 0.0616, 0.0206, 0.0290, 0.0117, 0.0036, 0.0248,
        0.0131, 0.0193, 0.0618, 0.1098, 0.0857], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,697][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0509, 0.0316, 0.0230, 0.0461, 0.0329, 0.0912, 0.0545, 0.0297, 0.0266,
        0.0454, 0.0583, 0.1224, 0.2110, 0.1763], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:58,698][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0102, 0.0145, 0.0116, 0.0129, 0.0364, 0.0120, 0.0262, 0.4743, 0.0135,
        0.1285, 0.0700, 0.0469, 0.0463, 0.0450, 0.0517], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,699][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.7163, 0.0026, 0.0042, 0.0079, 0.0580, 0.0153, 0.0132, 0.0096, 0.0318,
        0.0278, 0.0193, 0.0113, 0.0073, 0.0105, 0.0648], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,703][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0524, 0.0820, 0.0638, 0.0333, 0.0591, 0.0409, 0.0285, 0.1002, 0.0379,
        0.1024, 0.0383, 0.0497, 0.1150, 0.0836, 0.1129], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,706][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.0022, 0.0593, 0.0839, 0.0871, 0.0676, 0.0422, 0.0363, 0.0933, 0.0486,
        0.0794, 0.0983, 0.0882, 0.0599, 0.1271, 0.0268], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,707][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0138, 0.0022, 0.0012, 0.0100, 0.0021, 0.0120, 0.0210, 0.0050, 0.0280,
        0.0263, 0.0377, 0.1990, 0.3372, 0.2829, 0.0216], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,708][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0145, 0.0808, 0.0759, 0.0735, 0.0727, 0.0976, 0.0864, 0.1497, 0.0498,
        0.0662, 0.0637, 0.0521, 0.0453, 0.0464, 0.0257], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,709][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([3.6026e-05, 2.0069e-01, 6.9406e-02, 4.3279e-02, 7.5326e-03, 5.1983e-02,
        1.7514e-02, 4.8828e-01, 1.2137e-02, 2.0532e-02, 2.0103e-02, 1.6259e-02,
        3.0069e-02, 2.0493e-02, 1.6865e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,710][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0004, 0.0400, 0.0416, 0.0618, 0.0488, 0.0775, 0.0827, 0.1075, 0.0796,
        0.0704, 0.0762, 0.0758, 0.0738, 0.0873, 0.0766], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,713][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.0040, 0.0609, 0.0587, 0.0575, 0.0507, 0.0893, 0.0744, 0.1270, 0.0728,
        0.0704, 0.0631, 0.0616, 0.0752, 0.0873, 0.0470], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,717][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0022, 0.0074, 0.0045, 0.0092, 0.0056, 0.0312, 0.0179, 0.7873, 0.0091,
        0.0226, 0.0375, 0.0177, 0.0243, 0.0157, 0.0078], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,718][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.2051, 0.0304, 0.0160, 0.0406, 0.0187, 0.0340, 0.0247, 0.0092, 0.0445,
        0.0317, 0.0441, 0.1044, 0.1850, 0.1316, 0.0802], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,719][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0130, 0.0083, 0.0081, 0.0181, 0.0165, 0.0410, 0.0701, 0.0328, 0.0400,
        0.0619, 0.0816, 0.1321, 0.2167, 0.1759, 0.0840], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:58,719][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0060, 0.1536, 0.0192, 0.0479, 0.0413, 0.0085, 0.0319, 0.1214, 0.0229,
        0.1028, 0.0548, 0.0610, 0.0726, 0.0991, 0.0591, 0.0978],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,720][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([9.9839e-01, 8.3319e-06, 1.2991e-05, 2.3317e-05, 2.8523e-04, 3.4505e-05,
        2.7855e-05, 2.5322e-05, 7.5569e-05, 1.1651e-04, 4.4116e-05, 2.6163e-05,
        2.7618e-05, 2.2032e-05, 8.4574e-04, 3.1766e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,724][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0972, 0.0687, 0.0629, 0.0253, 0.0498, 0.0322, 0.0269, 0.1024, 0.0359,
        0.0918, 0.0360, 0.0481, 0.0969, 0.0742, 0.1012, 0.0504],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,727][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0005, 0.0397, 0.0515, 0.0816, 0.0261, 0.0351, 0.0280, 0.0465, 0.0667,
        0.0716, 0.0824, 0.1029, 0.0791, 0.1837, 0.0229, 0.0816],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,728][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1778, 0.0130, 0.0038, 0.0438, 0.0061, 0.0282, 0.0109, 0.0058, 0.0161,
        0.0118, 0.0178, 0.1263, 0.1695, 0.1669, 0.0199, 0.1823],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,729][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0160, 0.0743, 0.0700, 0.0674, 0.0678, 0.0869, 0.0800, 0.1249, 0.0504,
        0.0645, 0.0634, 0.0529, 0.0496, 0.0495, 0.0308, 0.0516],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,730][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0003, 0.1679, 0.0843, 0.0623, 0.0177, 0.0727, 0.0293, 0.3287, 0.0220,
        0.0330, 0.0337, 0.0280, 0.0413, 0.0314, 0.0054, 0.0419],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,731][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0012, 0.0491, 0.0444, 0.0614, 0.0493, 0.0709, 0.0742, 0.0819, 0.0710,
        0.0633, 0.0694, 0.0676, 0.0674, 0.0838, 0.0701, 0.0749],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,735][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0106, 0.0641, 0.0617, 0.0614, 0.0540, 0.0780, 0.0717, 0.0847, 0.0694,
        0.0671, 0.0580, 0.0620, 0.0658, 0.0784, 0.0495, 0.0637],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,738][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0290, 0.0494, 0.0253, 0.0379, 0.0206, 0.0663, 0.0434, 0.2219, 0.0338,
        0.0545, 0.0759, 0.0555, 0.1020, 0.0656, 0.0333, 0.0858],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,739][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.5861, 0.0361, 0.0107, 0.0297, 0.0087, 0.0146, 0.0079, 0.0021, 0.0172,
        0.0095, 0.0137, 0.0455, 0.0733, 0.0563, 0.0328, 0.0559],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,740][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0500, 0.0222, 0.0132, 0.0311, 0.0230, 0.0523, 0.0539, 0.0324, 0.0238,
        0.0426, 0.0545, 0.1076, 0.1768, 0.1548, 0.0766, 0.0851],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:58,741][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0086, 0.0524, 0.0108, 0.0316, 0.0485, 0.0121, 0.0337, 0.1777, 0.0198,
        0.0779, 0.0596, 0.0537, 0.0568, 0.0924, 0.0593, 0.0929, 0.1122],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,742][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([9.9135e-01, 5.9467e-05, 9.8878e-05, 1.4628e-04, 1.5297e-03, 1.9502e-04,
        1.7327e-04, 1.8071e-04, 4.2351e-04, 7.5374e-04, 2.7944e-04, 1.5632e-04,
        2.1035e-04, 1.5524e-04, 3.9672e-03, 2.0641e-04, 1.1158e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,745][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1181, 0.0611, 0.0611, 0.0228, 0.0516, 0.0302, 0.0263, 0.0961, 0.0348,
        0.0877, 0.0347, 0.0437, 0.0892, 0.0705, 0.0992, 0.0442, 0.0286],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,749][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([6.3627e-05, 2.5410e-02, 3.7631e-02, 6.3326e-02, 1.5296e-02, 2.1969e-02,
        2.0524e-02, 3.5414e-02, 7.7300e-02, 7.3369e-02, 8.4922e-02, 1.1400e-01,
        7.6590e-02, 1.6143e-01, 9.2816e-03, 5.9530e-02, 1.2394e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,750][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1887, 0.0107, 0.0020, 0.0361, 0.0031, 0.0174, 0.0051, 0.0031, 0.0081,
        0.0045, 0.0100, 0.0740, 0.0814, 0.1106, 0.0096, 0.1279, 0.3077],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,750][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0168, 0.0730, 0.0670, 0.0654, 0.0638, 0.0837, 0.0750, 0.1189, 0.0463,
        0.0600, 0.0582, 0.0492, 0.0448, 0.0463, 0.0279, 0.0496, 0.0543],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,751][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([2.7461e-04, 1.7523e-01, 8.0850e-02, 5.9309e-02, 1.5936e-02, 6.5657e-02,
        2.8185e-02, 3.2710e-01, 2.1136e-02, 3.1073e-02, 3.0491e-02, 2.6407e-02,
        3.9317e-02, 3.0503e-02, 4.6278e-03, 3.7959e-02, 2.5950e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,752][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0004, 0.0375, 0.0382, 0.0565, 0.0453, 0.0685, 0.0705, 0.0866, 0.0661,
        0.0568, 0.0602, 0.0611, 0.0574, 0.0736, 0.0662, 0.0741, 0.0811],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,756][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0069, 0.0597, 0.0591, 0.0568, 0.0505, 0.0712, 0.0637, 0.0950, 0.0600,
        0.0649, 0.0547, 0.0555, 0.0640, 0.0694, 0.0450, 0.0617, 0.0619],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,760][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0202, 0.0280, 0.0159, 0.0253, 0.0158, 0.0557, 0.0351, 0.3751, 0.0221,
        0.0416, 0.0567, 0.0403, 0.0596, 0.0371, 0.0170, 0.0743, 0.0804],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,760][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.5285, 0.0356, 0.0103, 0.0339, 0.0097, 0.0163, 0.0069, 0.0020, 0.0144,
        0.0068, 0.0110, 0.0398, 0.0669, 0.0497, 0.0287, 0.0582, 0.0812],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,761][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0430, 0.0230, 0.0095, 0.0303, 0.0154, 0.0497, 0.0298, 0.0191, 0.0142,
        0.0235, 0.0317, 0.0729, 0.1140, 0.0954, 0.0430, 0.0758, 0.3096],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:58,762][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.0115, 0.0221, 0.0108, 0.0122, 0.0321, 0.0111, 0.0217, 0.3612, 0.0107,
        0.0665, 0.0502, 0.0395, 0.0463, 0.0456, 0.0473, 0.0881, 0.0983, 0.0247],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,763][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([9.9568e-01, 2.5446e-05, 4.2098e-05, 7.1410e-05, 6.7678e-04, 1.1436e-04,
        9.6369e-05, 7.8005e-05, 2.5566e-04, 3.1980e-04, 1.5565e-04, 9.7120e-05,
        7.6193e-05, 7.9611e-05, 1.8667e-03, 1.0559e-04, 7.3627e-05, 1.8772e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,767][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0617, 0.0701, 0.0565, 0.0242, 0.0476, 0.0308, 0.0232, 0.0746, 0.0303,
        0.0768, 0.0299, 0.0402, 0.0914, 0.0673, 0.0838, 0.0431, 0.0259, 0.1228],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,770][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.0002, 0.0195, 0.0352, 0.0594, 0.0199, 0.0283, 0.0227, 0.0307, 0.0667,
        0.0531, 0.0615, 0.0976, 0.0710, 0.1422, 0.0174, 0.0732, 0.1101, 0.0913],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,771][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.1072, 0.0042, 0.0010, 0.0172, 0.0015, 0.0106, 0.0041, 0.0021, 0.0058,
        0.0034, 0.0075, 0.0569, 0.0787, 0.0895, 0.0074, 0.1360, 0.2945, 0.1724],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,772][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.0147, 0.0744, 0.0668, 0.0644, 0.0621, 0.0829, 0.0735, 0.1251, 0.0427,
        0.0570, 0.0544, 0.0457, 0.0412, 0.0425, 0.0242, 0.0459, 0.0514, 0.0310],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,773][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([1.9040e-04, 1.8298e-01, 7.8658e-02, 5.7473e-02, 1.3347e-02, 6.3493e-02,
        2.5215e-02, 3.2626e-01, 1.9021e-02, 2.7536e-02, 2.8380e-02, 2.4442e-02,
        3.7360e-02, 2.9784e-02, 3.8010e-03, 3.6976e-02, 2.3933e-02, 2.1149e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,776][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0003, 0.0340, 0.0323, 0.0500, 0.0379, 0.0632, 0.0664, 0.0830, 0.0618,
        0.0520, 0.0568, 0.0589, 0.0531, 0.0720, 0.0602, 0.0717, 0.0784, 0.0679],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,781][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.0057, 0.0532, 0.0535, 0.0510, 0.0452, 0.0690, 0.0634, 0.0921, 0.0588,
        0.0595, 0.0510, 0.0537, 0.0614, 0.0702, 0.0402, 0.0571, 0.0601, 0.0548],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,782][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.0105, 0.0230, 0.0105, 0.0187, 0.0126, 0.0391, 0.0232, 0.4746, 0.0157,
        0.0289, 0.0450, 0.0288, 0.0389, 0.0236, 0.0125, 0.0554, 0.0500, 0.0889],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,783][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.4639, 0.0282, 0.0079, 0.0295, 0.0073, 0.0155, 0.0059, 0.0025, 0.0120,
        0.0061, 0.0115, 0.0354, 0.0609, 0.0454, 0.0248, 0.0601, 0.0643, 0.1189],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,783][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.0329, 0.0142, 0.0062, 0.0280, 0.0084, 0.0344, 0.0253, 0.0121, 0.0180,
        0.0167, 0.0285, 0.0742, 0.0889, 0.0935, 0.0293, 0.0629, 0.2483, 0.1782],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:58,784][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0071, 0.0158, 0.0047, 0.0162, 0.0378, 0.0130, 0.0293, 0.2286, 0.0154,
        0.0662, 0.0679, 0.0601, 0.0475, 0.0789, 0.0419, 0.1001, 0.1194, 0.0207,
        0.0292], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,786][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([9.8716e-01, 9.5110e-05, 1.4374e-04, 2.2506e-04, 1.9711e-03, 3.5149e-04,
        2.7629e-04, 2.6663e-04, 6.2216e-04, 1.1260e-03, 4.1185e-04, 2.4046e-04,
        3.0068e-04, 2.3953e-04, 5.0226e-03, 3.2629e-04, 1.8270e-04, 7.1580e-04,
        3.2384e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,790][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0816, 0.0590, 0.0513, 0.0212, 0.0436, 0.0272, 0.0236, 0.0777, 0.0304,
        0.0731, 0.0319, 0.0392, 0.0813, 0.0645, 0.0849, 0.0389, 0.0254, 0.1141,
        0.0314], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,792][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.3528e-04, 2.2560e-02, 3.3216e-02, 4.6130e-02, 1.7357e-02, 1.8889e-02,
        1.7937e-02, 3.2144e-02, 3.9157e-02, 5.4057e-02, 5.2776e-02, 7.5899e-02,
        6.7409e-02, 1.1645e-01, 8.9829e-03, 4.8763e-02, 1.0292e-01, 6.9027e-02,
        1.7618e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,793][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0762, 0.0033, 0.0005, 0.0136, 0.0009, 0.0072, 0.0033, 0.0019, 0.0048,
        0.0033, 0.0070, 0.0557, 0.0616, 0.0900, 0.0048, 0.1013, 0.2988, 0.1439,
        0.1217], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,794][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0137, 0.0666, 0.0608, 0.0601, 0.0578, 0.0784, 0.0707, 0.1179, 0.0424,
        0.0558, 0.0540, 0.0452, 0.0405, 0.0424, 0.0242, 0.0454, 0.0506, 0.0317,
        0.0418], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,795][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([2.5627e-04, 1.6850e-01, 7.4797e-02, 5.5407e-02, 1.4687e-02, 6.1842e-02,
        2.7001e-02, 3.0692e-01, 2.0246e-02, 2.9387e-02, 2.9282e-02, 2.5932e-02,
        3.9182e-02, 3.1035e-02, 4.7102e-03, 3.7754e-02, 2.6020e-02, 2.2805e-02,
        2.4228e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,797][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0003, 0.0299, 0.0314, 0.0462, 0.0374, 0.0574, 0.0607, 0.0807, 0.0575,
        0.0499, 0.0532, 0.0535, 0.0495, 0.0659, 0.0567, 0.0654, 0.0727, 0.0631,
        0.0687], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,802][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0059, 0.0517, 0.0523, 0.0487, 0.0450, 0.0648, 0.0574, 0.0869, 0.0533,
        0.0571, 0.0484, 0.0502, 0.0586, 0.0629, 0.0398, 0.0544, 0.0552, 0.0527,
        0.0547], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,803][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0088, 0.0166, 0.0084, 0.0171, 0.0098, 0.0397, 0.0228, 0.4803, 0.0138,
        0.0283, 0.0390, 0.0250, 0.0338, 0.0234, 0.0095, 0.0577, 0.0519, 0.0744,
        0.0399], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,804][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.3952, 0.0251, 0.0068, 0.0283, 0.0067, 0.0152, 0.0061, 0.0022, 0.0133,
        0.0064, 0.0113, 0.0373, 0.0631, 0.0481, 0.0240, 0.0665, 0.0772, 0.1048,
        0.0624], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,805][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0467, 0.0121, 0.0040, 0.0149, 0.0084, 0.0279, 0.0193, 0.0138, 0.0089,
        0.0146, 0.0209, 0.0487, 0.0754, 0.0688, 0.0297, 0.0538, 0.2289, 0.1797,
        0.1234], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:58,900][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:58,901][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,902][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,903][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,904][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,904][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,905][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,906][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,906][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,907][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,908][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,908][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,909][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:58,910][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9625, 0.0375], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,910][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0113, 0.9887], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,912][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.8628, 0.1372], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,913][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.7172, 0.2828], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,914][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.7048, 0.2952], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,914][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9219, 0.0781], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,917][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.6725, 0.3275], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,920][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.8601, 0.1399], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,921][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8664, 0.1336], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,922][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.8483, 0.1517], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,922][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7643, 0.2357], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,923][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.7725, 0.2275], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:58,924][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Jamie] are: tensor([0.9712, 0.0180, 0.0108], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,927][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Jamie] are: tensor([0.0201, 0.3974, 0.5825], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,931][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Jamie] are: tensor([0.7401, 0.1036, 0.1563], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,932][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Jamie] are: tensor([0.6860, 0.1142, 0.1998], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,932][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Jamie] are: tensor([0.4781, 0.1164, 0.4055], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,933][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Jamie] are: tensor([0.9464, 0.0286, 0.0250], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,934][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Jamie] are: tensor([0.8438, 0.0977, 0.0585], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,935][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Jamie] are: tensor([0.8779, 0.0748, 0.0473], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,938][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Jamie] are: tensor([0.7855, 0.0854, 0.1290], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,942][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Jamie] are: tensor([0.8497, 0.0616, 0.0887], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,942][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Jamie] are: tensor([0.8500, 0.0873, 0.0627], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,943][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Jamie] are: tensor([0.5711, 0.1182, 0.3107], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:58,944][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9411, 0.0199, 0.0093, 0.0297], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,945][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0110, 0.2264, 0.6018, 0.1607], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,946][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5818, 0.1074, 0.1635, 0.1473], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,951][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.6120, 0.1038, 0.2156, 0.0686], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,953][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.4330, 0.1502, 0.1916, 0.2252], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,953][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.8843, 0.0564, 0.0321, 0.0273], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,954][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6994, 0.0864, 0.1185, 0.0957], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,955][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.9056, 0.0586, 0.0116, 0.0243], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,955][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.7969, 0.0803, 0.0835, 0.0393], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,958][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.7805, 0.0902, 0.0755, 0.0538], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,962][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.7202, 0.1062, 0.0581, 0.1156], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,963][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4139, 0.1421, 0.2062, 0.2378], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:58,964][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.9296, 0.0186, 0.0103, 0.0366, 0.0049], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,965][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0092, 0.2018, 0.4447, 0.1475, 0.1967], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,966][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.3771, 0.0975, 0.1689, 0.2360, 0.1205], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,966][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.5105, 0.0819, 0.1654, 0.0613, 0.1809], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,969][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.4141, 0.0754, 0.1185, 0.2640, 0.1281], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,972][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.8943, 0.0341, 0.0221, 0.0308, 0.0187], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,974][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.7499, 0.0593, 0.0618, 0.0519, 0.0772], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,975][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.9079, 0.0331, 0.0094, 0.0355, 0.0141], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,976][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.6425, 0.0811, 0.1230, 0.0650, 0.0884], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,977][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.7362, 0.0837, 0.0719, 0.0562, 0.0521], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,977][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.7209, 0.0783, 0.0493, 0.0965, 0.0550], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,980][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.2106, 0.1059, 0.1698, 0.2614, 0.2523], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:58,983][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.9615, 0.0117, 0.0044, 0.0194, 0.0017, 0.0012], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,985][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0817, 0.2414, 0.3924, 0.0965, 0.1316, 0.0564], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,986][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.3071, 0.1317, 0.1481, 0.1816, 0.0909, 0.1406], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,987][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.6294, 0.0512, 0.1233, 0.0374, 0.1027, 0.0560], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,988][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.5381, 0.0631, 0.0527, 0.1580, 0.0819, 0.1062], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,988][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.9163, 0.0294, 0.0148, 0.0198, 0.0102, 0.0095], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,991][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.8943, 0.0237, 0.0319, 0.0184, 0.0204, 0.0113], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,996][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.9589, 0.0214, 0.0024, 0.0089, 0.0026, 0.0059], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,997][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.7816, 0.0519, 0.0681, 0.0331, 0.0543, 0.0110], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,997][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.8785, 0.0426, 0.0290, 0.0247, 0.0148, 0.0104], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,998][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.8202, 0.0506, 0.0235, 0.0522, 0.0217, 0.0318], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:58,999][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.2485, 0.0861, 0.1035, 0.1583, 0.1381, 0.2655], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:59,000][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.8488, 0.0175, 0.0036, 0.0291, 0.0021, 0.0017, 0.0973],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,003][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0732, 0.2337, 0.2702, 0.1387, 0.0966, 0.1004, 0.0873],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,007][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3949, 0.1281, 0.1126, 0.1528, 0.0517, 0.1113, 0.0486],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,008][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.3041, 0.0742, 0.1640, 0.0631, 0.1344, 0.1366, 0.1236],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,008][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.4888, 0.0293, 0.0144, 0.1852, 0.0332, 0.1176, 0.1315],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,009][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.8906, 0.0196, 0.0068, 0.0351, 0.0096, 0.0184, 0.0199],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,010][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.8988, 0.0196, 0.0194, 0.0197, 0.0136, 0.0148, 0.0141],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,012][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([9.5442e-01, 9.2207e-03, 5.1506e-04, 1.5904e-02, 1.7126e-03, 1.0957e-02,
        7.2680e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,016][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.6016, 0.0732, 0.0940, 0.0723, 0.0977, 0.0295, 0.0316],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,018][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.8338, 0.0553, 0.0305, 0.0333, 0.0177, 0.0176, 0.0118],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,019][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.7205, 0.0586, 0.0263, 0.0842, 0.0318, 0.0478, 0.0309],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,019][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1039, 0.0630, 0.0571, 0.1211, 0.0885, 0.2462, 0.3202],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,020][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([8.9059e-01, 9.2305e-03, 4.2215e-03, 1.6806e-02, 1.1977e-03, 8.7060e-04,
        6.0664e-02, 1.6418e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,021][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.4959, 0.2095, 0.1205, 0.0641, 0.0375, 0.0274, 0.0304, 0.0147],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,024][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.1002, 0.1202, 0.1011, 0.2722, 0.0883, 0.1806, 0.0921, 0.0454],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,026][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([9.2820e-01, 1.2094e-02, 2.6872e-02, 7.0634e-03, 9.7708e-03, 4.1398e-03,
        1.1101e-02, 7.5443e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,029][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.6111, 0.0339, 0.0204, 0.1348, 0.0422, 0.0756, 0.0741, 0.0079],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,030][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([9.6781e-01, 9.6097e-03, 1.7531e-03, 1.0013e-02, 2.1201e-03, 3.6108e-03,
        4.6148e-03, 4.6642e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,030][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([9.7868e-01, 5.5029e-03, 5.0027e-03, 3.3345e-03, 2.0231e-03, 1.7124e-03,
        3.4486e-03, 2.9863e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,031][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([9.9063e-01, 4.0023e-03, 2.0509e-04, 2.6198e-03, 3.2474e-04, 9.6507e-04,
        1.1893e-03, 6.7984e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,032][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([8.6972e-01, 2.5070e-02, 4.0503e-02, 2.2851e-02, 2.9979e-02, 3.5892e-03,
        8.0959e-03, 1.9431e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,034][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([9.2421e-01, 2.6640e-02, 1.6900e-02, 1.7518e-02, 6.7961e-03, 4.0647e-03,
        3.6219e-03, 2.4522e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,038][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.8944, 0.0306, 0.0104, 0.0274, 0.0103, 0.0124, 0.0119, 0.0026],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,040][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0924, 0.0377, 0.0364, 0.0956, 0.0754, 0.1988, 0.3589, 0.1048],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,040][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.7512, 0.0216, 0.0047, 0.0349, 0.0035, 0.0027, 0.1244, 0.0397, 0.0173],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,041][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0369, 0.1504, 0.2629, 0.0989, 0.0914, 0.1192, 0.0983, 0.0315, 0.1106],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,042][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.3636, 0.1107, 0.0820, 0.1207, 0.0569, 0.0934, 0.0508, 0.0233, 0.0986],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,043][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.1989, 0.0679, 0.1256, 0.0716, 0.1497, 0.1473, 0.1055, 0.0365, 0.0968],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,045][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.3810, 0.0197, 0.0084, 0.1386, 0.0231, 0.0785, 0.1164, 0.0370, 0.1975],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,050][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.8143, 0.0194, 0.0052, 0.0362, 0.0087, 0.0185, 0.0282, 0.0060, 0.0636],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,051][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.7368, 0.0298, 0.0273, 0.0361, 0.0239, 0.0311, 0.0286, 0.0082, 0.0782],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,052][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([9.0989e-01, 8.2879e-03, 6.5378e-04, 1.7509e-02, 2.4036e-03, 1.3732e-02,
        1.0946e-02, 6.0000e-03, 3.0579e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,053][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.5455, 0.0645, 0.0843, 0.0671, 0.1013, 0.0291, 0.0355, 0.0038, 0.0691],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,053][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.7260, 0.0781, 0.0357, 0.0451, 0.0270, 0.0271, 0.0183, 0.0054, 0.0373],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,054][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.5891, 0.0624, 0.0255, 0.0912, 0.0389, 0.0635, 0.0330, 0.0101, 0.0862],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,058][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0765, 0.0342, 0.0368, 0.0752, 0.0806, 0.2076, 0.2417, 0.1047, 0.1427],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,061][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.8100, 0.0152, 0.0031, 0.0259, 0.0014, 0.0014, 0.0867, 0.0272, 0.0105,
        0.0185], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,062][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0740, 0.1341, 0.1703, 0.0869, 0.0674, 0.0983, 0.0947, 0.0329, 0.1220,
        0.1193], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,063][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.2476, 0.1162, 0.0756, 0.1449, 0.0528, 0.1143, 0.0563, 0.0212, 0.1180,
        0.0532], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,064][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.5060, 0.0330, 0.0886, 0.0301, 0.0770, 0.0597, 0.0640, 0.0141, 0.0737,
        0.0540], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,065][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.4115, 0.0142, 0.0058, 0.1056, 0.0130, 0.0670, 0.1018, 0.0124, 0.1634,
        0.1053], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,067][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.8774, 0.0126, 0.0027, 0.0208, 0.0040, 0.0096, 0.0130, 0.0018, 0.0421,
        0.0159], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,072][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.8443, 0.0193, 0.0148, 0.0163, 0.0096, 0.0153, 0.0178, 0.0032, 0.0434,
        0.0161], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,073][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([9.4289e-01, 5.0212e-03, 2.7492e-04, 1.0038e-02, 8.4024e-04, 6.4164e-03,
        5.6738e-03, 1.5996e-03, 1.6736e-02, 1.0507e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,074][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.6647, 0.0460, 0.0597, 0.0509, 0.0633, 0.0190, 0.0254, 0.0016, 0.0502,
        0.0191], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,075][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([8.9930e-01, 3.1241e-02, 1.4891e-02, 1.5341e-02, 8.4306e-03, 7.2409e-03,
        4.5977e-03, 7.6659e-04, 1.2249e-02, 5.9387e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,075][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.7764, 0.0339, 0.0137, 0.0468, 0.0149, 0.0277, 0.0178, 0.0047, 0.0420,
        0.0221], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,078][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0899, 0.0293, 0.0232, 0.0718, 0.0486, 0.1527, 0.2219, 0.0734, 0.1216,
        0.1678], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,082][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.8012, 0.0176, 0.0038, 0.0255, 0.0018, 0.0013, 0.0742, 0.0243, 0.0084,
        0.0159, 0.0259], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,083][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.1016, 0.1682, 0.1661, 0.0831, 0.0692, 0.0617, 0.0692, 0.0249, 0.0997,
        0.0785, 0.0779], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,084][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.2491, 0.1195, 0.0886, 0.1240, 0.0507, 0.0979, 0.0477, 0.0159, 0.1190,
        0.0371, 0.0504], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,085][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.3482, 0.0501, 0.0885, 0.0546, 0.0772, 0.0687, 0.0823, 0.0203, 0.0903,
        0.0561, 0.0638], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,086][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.3529, 0.0188, 0.0076, 0.1156, 0.0174, 0.0758, 0.0697, 0.0135, 0.1266,
        0.0912, 0.1109], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,087][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.8318, 0.0139, 0.0035, 0.0248, 0.0048, 0.0119, 0.0147, 0.0025, 0.0398,
        0.0178, 0.0344], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,090][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.8364, 0.0228, 0.0139, 0.0167, 0.0090, 0.0122, 0.0152, 0.0038, 0.0365,
        0.0110, 0.0224], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,094][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([9.5826e-01, 4.4544e-03, 1.9161e-04, 7.0311e-03, 6.3388e-04, 3.7307e-03,
        3.0123e-03, 8.7628e-04, 8.5682e-03, 5.2940e-03, 7.9455e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,095][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.6799, 0.0555, 0.0552, 0.0471, 0.0603, 0.0133, 0.0188, 0.0014, 0.0411,
        0.0145, 0.0128], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,096][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.8628, 0.0424, 0.0178, 0.0222, 0.0107, 0.0095, 0.0058, 0.0011, 0.0126,
        0.0066, 0.0086], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,097][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.7388, 0.0409, 0.0135, 0.0519, 0.0160, 0.0262, 0.0178, 0.0042, 0.0400,
        0.0195, 0.0312], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,097][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0909, 0.0288, 0.0251, 0.0636, 0.0427, 0.1251, 0.1708, 0.0611, 0.0952,
        0.1262, 0.1705], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,101][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.6470, 0.0162, 0.0038, 0.0246, 0.0021, 0.0017, 0.0685, 0.0273, 0.0088,
        0.0173, 0.0240, 0.1587], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,105][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0272, 0.1362, 0.1655, 0.0873, 0.0629, 0.0623, 0.0706, 0.0269, 0.0915,
        0.0735, 0.0853, 0.1107], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,106][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3325, 0.1040, 0.0752, 0.1026, 0.0452, 0.0661, 0.0376, 0.0148, 0.0809,
        0.0343, 0.0413, 0.0656], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,106][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.1928, 0.0682, 0.1035, 0.0558, 0.0933, 0.0935, 0.0683, 0.0235, 0.0642,
        0.0612, 0.0581, 0.1176], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,107][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.2668, 0.0196, 0.0072, 0.0839, 0.0129, 0.0502, 0.0341, 0.0134, 0.0528,
        0.0384, 0.0551, 0.3656], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,108][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.8390, 0.0157, 0.0034, 0.0194, 0.0037, 0.0081, 0.0061, 0.0018, 0.0150,
        0.0059, 0.0133, 0.0685], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,112][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.6931, 0.0324, 0.0291, 0.0299, 0.0214, 0.0218, 0.0203, 0.0070, 0.0449,
        0.0195, 0.0331, 0.0474], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,115][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([9.2390e-01, 7.8265e-03, 3.1328e-04, 9.4075e-03, 8.5695e-04, 5.0196e-03,
        1.8484e-03, 1.5740e-03, 5.4574e-03, 3.2013e-03, 5.1636e-03, 3.5427e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,116][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.5782, 0.0795, 0.0614, 0.0567, 0.0650, 0.0240, 0.0173, 0.0033, 0.0344,
        0.0178, 0.0145, 0.0479], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,117][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.8086, 0.0510, 0.0206, 0.0236, 0.0117, 0.0125, 0.0062, 0.0021, 0.0134,
        0.0082, 0.0105, 0.0316], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,118][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.5787, 0.0589, 0.0218, 0.0649, 0.0238, 0.0404, 0.0190, 0.0063, 0.0384,
        0.0207, 0.0308, 0.0963], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,119][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0673, 0.0379, 0.0267, 0.0541, 0.0496, 0.1258, 0.0981, 0.0619, 0.0548,
        0.0882, 0.1166, 0.2190], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,122][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.4859, 0.0225, 0.0048, 0.0375, 0.0029, 0.0027, 0.0978, 0.0565, 0.0110,
        0.0252, 0.0326, 0.2048, 0.0158], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,126][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0128, 0.0647, 0.0960, 0.0618, 0.0453, 0.0848, 0.0830, 0.0228, 0.0893,
        0.0651, 0.0970, 0.1212, 0.1561], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,127][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.2681, 0.0895, 0.0682, 0.0847, 0.0337, 0.0778, 0.0345, 0.0224, 0.0499,
        0.0324, 0.0464, 0.0576, 0.1348], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,128][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.1336, 0.0556, 0.0752, 0.0508, 0.0804, 0.1134, 0.0549, 0.0368, 0.0516,
        0.0667, 0.0609, 0.1002, 0.1198], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,129][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.1855, 0.0114, 0.0027, 0.0463, 0.0046, 0.0331, 0.0198, 0.0084, 0.0307,
        0.0198, 0.0369, 0.2504, 0.3506], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,129][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.6161, 0.0125, 0.0024, 0.0184, 0.0029, 0.0090, 0.0056, 0.0023, 0.0129,
        0.0058, 0.0123, 0.0715, 0.2284], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,133][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.3262, 0.0431, 0.0382, 0.0446, 0.0329, 0.0563, 0.0493, 0.0171, 0.0796,
        0.0347, 0.0596, 0.0909, 0.1276], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,137][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([7.8042e-01, 8.2000e-03, 3.7520e-04, 1.3142e-02, 9.8133e-04, 7.5648e-03,
        2.5971e-03, 2.6682e-03, 5.9470e-03, 3.8350e-03, 7.5700e-03, 5.7132e-02,
        1.0957e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,137][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.3971, 0.0746, 0.0571, 0.0543, 0.0520, 0.0319, 0.0245, 0.0046, 0.0356,
        0.0222, 0.0220, 0.0722, 0.1519], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,138][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.7184, 0.0624, 0.0230, 0.0274, 0.0142, 0.0163, 0.0071, 0.0033, 0.0132,
        0.0093, 0.0127, 0.0320, 0.0606], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,139][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.4481, 0.0572, 0.0166, 0.0608, 0.0168, 0.0449, 0.0157, 0.0079, 0.0303,
        0.0199, 0.0305, 0.0810, 0.1704], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,140][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.0728, 0.0246, 0.0148, 0.0415, 0.0284, 0.0976, 0.0750, 0.0570, 0.0349,
        0.0637, 0.0854, 0.1638, 0.2405], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,143][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.6392, 0.0239, 0.0037, 0.0294, 0.0021, 0.0017, 0.0515, 0.0263, 0.0070,
        0.0138, 0.0207, 0.1387, 0.0116, 0.0304], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,147][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0119, 0.0823, 0.1234, 0.0660, 0.0505, 0.0703, 0.0576, 0.0229, 0.0530,
        0.0608, 0.0680, 0.0851, 0.1405, 0.1077], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,148][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.3023, 0.0951, 0.0549, 0.0799, 0.0359, 0.0546, 0.0263, 0.0115, 0.0443,
        0.0229, 0.0310, 0.0482, 0.1255, 0.0675], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,149][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.1800, 0.0710, 0.1036, 0.0458, 0.0768, 0.0825, 0.0486, 0.0188, 0.0397,
        0.0441, 0.0419, 0.0906, 0.0793, 0.0771], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,150][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.2285, 0.0241, 0.0052, 0.0788, 0.0075, 0.0354, 0.0101, 0.0068, 0.0165,
        0.0129, 0.0199, 0.1354, 0.2050, 0.2138], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,151][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.6420, 0.0201, 0.0035, 0.0239, 0.0037, 0.0101, 0.0037, 0.0012, 0.0085,
        0.0037, 0.0073, 0.0496, 0.1340, 0.0885], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,154][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.3958, 0.0429, 0.0356, 0.0433, 0.0283, 0.0439, 0.0342, 0.0099, 0.0526,
        0.0242, 0.0416, 0.0738, 0.0987, 0.0751], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,158][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([9.0338e-01, 8.5776e-03, 2.3974e-04, 1.0342e-02, 5.7502e-04, 3.6598e-03,
        6.7647e-04, 8.0469e-04, 1.5731e-03, 9.7094e-04, 1.8256e-03, 1.6045e-02,
        2.7200e-02, 2.4125e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,159][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.4105, 0.1013, 0.0632, 0.0649, 0.0525, 0.0283, 0.0150, 0.0029, 0.0274,
        0.0126, 0.0122, 0.0436, 0.1182, 0.0475], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,160][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.6584, 0.0733, 0.0269, 0.0333, 0.0148, 0.0202, 0.0085, 0.0030, 0.0141,
        0.0097, 0.0129, 0.0372, 0.0512, 0.0364], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,161][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.4779, 0.0610, 0.0200, 0.0616, 0.0206, 0.0290, 0.0117, 0.0036, 0.0248,
        0.0131, 0.0193, 0.0618, 0.1098, 0.0857], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,161][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0509, 0.0316, 0.0230, 0.0461, 0.0329, 0.0912, 0.0545, 0.0297, 0.0266,
        0.0454, 0.0583, 0.1224, 0.2110, 0.1763], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,165][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.3364, 0.0163, 0.0059, 0.0306, 0.0034, 0.0029, 0.1236, 0.0548, 0.0168,
        0.0401, 0.0448, 0.2229, 0.0222, 0.0527, 0.0265], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,169][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0029, 0.0478, 0.0795, 0.0408, 0.0368, 0.0650, 0.0667, 0.0189, 0.0713,
        0.0689, 0.0782, 0.1014, 0.1381, 0.1077, 0.0760], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,170][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.1108, 0.0547, 0.0582, 0.0870, 0.0422, 0.0808, 0.0356, 0.0303, 0.0525,
        0.0405, 0.0439, 0.0488, 0.1479, 0.0808, 0.0858], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,171][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.0965, 0.0374, 0.0606, 0.0360, 0.0640, 0.0729, 0.0475, 0.0413, 0.0505,
        0.0560, 0.0611, 0.0830, 0.0844, 0.0666, 0.1421], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,172][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0138, 0.0022, 0.0012, 0.0100, 0.0021, 0.0120, 0.0210, 0.0050, 0.0280,
        0.0263, 0.0377, 0.1990, 0.3372, 0.2829, 0.0216], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,173][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.1686, 0.0055, 0.0018, 0.0081, 0.0022, 0.0063, 0.0112, 0.0030, 0.0294,
        0.0150, 0.0275, 0.1073, 0.3832, 0.1949, 0.0358], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,176][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.2304, 0.0328, 0.0278, 0.0289, 0.0289, 0.0386, 0.0343, 0.0181, 0.0639,
        0.0432, 0.0588, 0.0877, 0.1128, 0.0840, 0.1099], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,180][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([1.6167e-01, 2.5632e-03, 3.4715e-04, 5.4692e-03, 8.4482e-04, 5.3852e-03,
        8.3924e-03, 3.3710e-03, 2.1788e-02, 1.6829e-02, 2.7997e-02, 1.3416e-01,
        3.7233e-01, 2.1298e-01, 2.5873e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,180][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.1891, 0.0486, 0.0389, 0.0432, 0.0335, 0.0293, 0.0299, 0.0054, 0.0556,
        0.0298, 0.0377, 0.0778, 0.1706, 0.0870, 0.1237], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,181][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.2759, 0.0576, 0.0312, 0.0454, 0.0260, 0.0423, 0.0281, 0.0133, 0.0391,
        0.0330, 0.0496, 0.0815, 0.1176, 0.0799, 0.0793], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,182][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.2051, 0.0304, 0.0160, 0.0406, 0.0187, 0.0340, 0.0247, 0.0092, 0.0445,
        0.0317, 0.0441, 0.1044, 0.1850, 0.1316, 0.0802], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,183][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0130, 0.0083, 0.0081, 0.0181, 0.0165, 0.0410, 0.0701, 0.0328, 0.0400,
        0.0619, 0.0816, 0.1321, 0.2167, 0.1759, 0.0840], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,187][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.6549, 0.0150, 0.0040, 0.0236, 0.0019, 0.0013, 0.0537, 0.0201, 0.0086,
        0.0131, 0.0176, 0.1165, 0.0122, 0.0300, 0.0163, 0.0113],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,191][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0606, 0.0850, 0.0885, 0.0635, 0.0369, 0.0355, 0.0388, 0.0132, 0.0488,
        0.0394, 0.0556, 0.0734, 0.1166, 0.1217, 0.0873, 0.0353],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,192][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1618, 0.0701, 0.0540, 0.0898, 0.0307, 0.0510, 0.0270, 0.0122, 0.0554,
        0.0263, 0.0315, 0.0444, 0.1258, 0.0829, 0.0673, 0.0697],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,192][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.4144, 0.0394, 0.0562, 0.0298, 0.0354, 0.0289, 0.0279, 0.0075, 0.0346,
        0.0212, 0.0241, 0.0616, 0.0515, 0.0507, 0.0800, 0.0369],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,193][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1778, 0.0130, 0.0038, 0.0438, 0.0061, 0.0282, 0.0109, 0.0058, 0.0161,
        0.0118, 0.0178, 0.1263, 0.1695, 0.1669, 0.0199, 0.1823],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,194][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([7.9194e-01, 1.2031e-02, 1.4332e-03, 8.6355e-03, 1.2250e-03, 2.5969e-03,
        1.6571e-03, 3.6974e-04, 4.4761e-03, 1.4968e-03, 3.2663e-03, 2.1364e-02,
        8.0077e-02, 3.7024e-02, 8.6765e-03, 2.3729e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,198][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.6925, 0.0186, 0.0144, 0.0130, 0.0089, 0.0088, 0.0106, 0.0030, 0.0296,
        0.0105, 0.0190, 0.0290, 0.0476, 0.0345, 0.0433, 0.0165],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,201][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([9.5798e-01, 3.1425e-03, 8.8713e-05, 2.2445e-03, 1.4525e-04, 6.8764e-04,
        2.1496e-04, 1.1364e-04, 6.2606e-04, 2.7504e-04, 5.0489e-04, 3.9186e-03,
        1.0036e-02, 6.1788e-03, 1.2303e-03, 1.2613e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,202][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.6067, 0.0581, 0.0403, 0.0329, 0.0313, 0.0089, 0.0074, 0.0008, 0.0169,
        0.0055, 0.0059, 0.0202, 0.0555, 0.0285, 0.0679, 0.0131],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,203][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([8.1864e-01, 3.4087e-02, 1.2202e-02, 1.5116e-02, 6.1964e-03, 5.4907e-03,
        2.7493e-03, 7.1641e-04, 6.1719e-03, 3.2174e-03, 4.8230e-03, 1.3569e-02,
        2.6690e-02, 1.5911e-02, 2.3013e-02, 1.1403e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,204][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.5861, 0.0361, 0.0107, 0.0297, 0.0087, 0.0146, 0.0079, 0.0021, 0.0172,
        0.0095, 0.0137, 0.0455, 0.0733, 0.0563, 0.0328, 0.0559],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,205][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0500, 0.0222, 0.0132, 0.0311, 0.0230, 0.0523, 0.0539, 0.0324, 0.0238,
        0.0426, 0.0545, 0.1076, 0.1768, 0.1548, 0.0766, 0.0851],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,208][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.5963, 0.0142, 0.0025, 0.0210, 0.0015, 0.0012, 0.0422, 0.0229, 0.0051,
        0.0105, 0.0154, 0.1006, 0.0074, 0.0213, 0.0125, 0.0107, 0.1145],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,214][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0296, 0.0745, 0.0836, 0.0514, 0.0344, 0.0387, 0.0344, 0.0151, 0.0440,
        0.0406, 0.0485, 0.0695, 0.1149, 0.0962, 0.0766, 0.0488, 0.0993],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,215][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2479, 0.0614, 0.0432, 0.0711, 0.0282, 0.0384, 0.0211, 0.0087, 0.0468,
        0.0229, 0.0260, 0.0360, 0.1064, 0.0609, 0.0549, 0.0547, 0.0714],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,216][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1649, 0.0428, 0.0687, 0.0363, 0.0507, 0.0534, 0.0368, 0.0129, 0.0330,
        0.0297, 0.0302, 0.0667, 0.0586, 0.0546, 0.0653, 0.0555, 0.1398],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,217][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1887, 0.0107, 0.0020, 0.0361, 0.0031, 0.0174, 0.0051, 0.0031, 0.0081,
        0.0045, 0.0100, 0.0740, 0.0814, 0.1106, 0.0096, 0.1279, 0.3077],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,218][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([7.5012e-01, 1.2093e-02, 1.7491e-03, 1.1547e-02, 1.5347e-03, 4.0488e-03,
        1.2474e-03, 4.2135e-04, 3.5208e-03, 1.1815e-03, 2.9138e-03, 2.0398e-02,
        6.0394e-02, 3.5768e-02, 8.8033e-03, 3.7757e-02, 4.6500e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,222][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.6822, 0.0200, 0.0147, 0.0168, 0.0108, 0.0108, 0.0099, 0.0040, 0.0211,
        0.0095, 0.0159, 0.0252, 0.0401, 0.0290, 0.0451, 0.0196, 0.0254],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,225][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([8.8260e-01, 4.7872e-03, 1.1278e-04, 4.7908e-03, 2.3299e-04, 1.6183e-03,
        2.6664e-04, 3.3625e-04, 7.3760e-04, 3.6721e-04, 7.6317e-04, 6.6058e-03,
        1.2597e-02, 1.0197e-02, 1.7326e-03, 3.1559e-02, 4.0696e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,226][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.5217, 0.0686, 0.0346, 0.0414, 0.0340, 0.0143, 0.0075, 0.0017, 0.0145,
        0.0068, 0.0065, 0.0226, 0.0642, 0.0284, 0.0657, 0.0209, 0.0467],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,227][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.7705, 0.0373, 0.0126, 0.0168, 0.0068, 0.0076, 0.0036, 0.0010, 0.0066,
        0.0039, 0.0056, 0.0181, 0.0287, 0.0171, 0.0203, 0.0176, 0.0259],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,228][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.5285, 0.0356, 0.0103, 0.0339, 0.0097, 0.0163, 0.0069, 0.0020, 0.0144,
        0.0068, 0.0110, 0.0398, 0.0669, 0.0497, 0.0287, 0.0582, 0.0812],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,230][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0430, 0.0230, 0.0095, 0.0303, 0.0154, 0.0497, 0.0298, 0.0191, 0.0142,
        0.0235, 0.0317, 0.0729, 0.1140, 0.0954, 0.0430, 0.0758, 0.3096],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,234][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.4735, 0.0174, 0.0038, 0.0249, 0.0023, 0.0017, 0.0601, 0.0318, 0.0070,
        0.0140, 0.0197, 0.1271, 0.0109, 0.0277, 0.0166, 0.0147, 0.1439, 0.0030],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,236][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.0399, 0.0555, 0.0694, 0.0462, 0.0375, 0.0345, 0.0321, 0.0086, 0.0472,
        0.0300, 0.0424, 0.0636, 0.0978, 0.0713, 0.0967, 0.0367, 0.0680, 0.1227],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,237][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.1338, 0.0790, 0.0585, 0.0763, 0.0296, 0.0568, 0.0234, 0.0109, 0.0333,
        0.0201, 0.0253, 0.0375, 0.0978, 0.0519, 0.0535, 0.0627, 0.0663, 0.0833],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,238][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.1671, 0.0439, 0.0476, 0.0492, 0.0423, 0.0603, 0.0300, 0.0185, 0.0299,
        0.0259, 0.0301, 0.0565, 0.0475, 0.0460, 0.0685, 0.0544, 0.0733, 0.1090],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,239][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.1072, 0.0042, 0.0010, 0.0172, 0.0015, 0.0106, 0.0041, 0.0021, 0.0058,
        0.0034, 0.0075, 0.0569, 0.0787, 0.0895, 0.0074, 0.1360, 0.2945, 0.1724],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,242][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.5127, 0.0085, 0.0012, 0.0094, 0.0011, 0.0037, 0.0018, 0.0007, 0.0042,
        0.0016, 0.0035, 0.0284, 0.0916, 0.0515, 0.0079, 0.0530, 0.0988, 0.1202],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,246][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.5096, 0.0316, 0.0276, 0.0231, 0.0171, 0.0161, 0.0140, 0.0060, 0.0295,
        0.0120, 0.0196, 0.0321, 0.0465, 0.0403, 0.0570, 0.0328, 0.0358, 0.0493],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,247][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([7.4126e-01, 3.2363e-03, 9.1455e-05, 3.5992e-03, 1.6800e-04, 1.4671e-03,
        3.6846e-04, 3.2693e-04, 8.8188e-04, 4.3708e-04, 1.0765e-03, 9.0747e-03,
        1.7477e-02, 1.6057e-02, 1.8136e-03, 4.4731e-02, 7.3458e-02, 8.4473e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,248][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.3850, 0.0589, 0.0279, 0.0383, 0.0239, 0.0148, 0.0098, 0.0020, 0.0203,
        0.0083, 0.0090, 0.0335, 0.0730, 0.0388, 0.0577, 0.0307, 0.0691, 0.0990],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,249][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.6845, 0.0390, 0.0122, 0.0157, 0.0094, 0.0085, 0.0039, 0.0020, 0.0075,
        0.0048, 0.0079, 0.0200, 0.0299, 0.0164, 0.0273, 0.0235, 0.0249, 0.0625],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,250][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.4639, 0.0282, 0.0079, 0.0295, 0.0073, 0.0155, 0.0059, 0.0025, 0.0120,
        0.0061, 0.0115, 0.0354, 0.0609, 0.0454, 0.0248, 0.0601, 0.0643, 0.1189],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,254][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0329, 0.0142, 0.0062, 0.0280, 0.0084, 0.0344, 0.0253, 0.0121, 0.0180,
        0.0167, 0.0285, 0.0742, 0.0889, 0.0935, 0.0293, 0.0629, 0.2483, 0.1782],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,258][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.5615, 0.0146, 0.0020, 0.0214, 0.0014, 0.0013, 0.0437, 0.0214, 0.0049,
        0.0096, 0.0157, 0.1156, 0.0083, 0.0215, 0.0117, 0.0116, 0.1229, 0.0019,
        0.0091], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,258][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0169, 0.0532, 0.0591, 0.0279, 0.0228, 0.0313, 0.0234, 0.0118, 0.0253,
        0.0282, 0.0362, 0.0464, 0.0773, 0.0667, 0.0534, 0.0342, 0.0856, 0.2001,
        0.1001], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,259][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2565, 0.0697, 0.0373, 0.0576, 0.0237, 0.0337, 0.0168, 0.0076, 0.0305,
        0.0145, 0.0193, 0.0312, 0.0857, 0.0456, 0.0490, 0.0507, 0.0590, 0.0728,
        0.0387], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,260][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1600, 0.0327, 0.0431, 0.0224, 0.0330, 0.0356, 0.0254, 0.0115, 0.0241,
        0.0241, 0.0251, 0.0527, 0.0579, 0.0418, 0.0551, 0.0484, 0.1146, 0.1215,
        0.0710], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,263][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0762, 0.0033, 0.0005, 0.0136, 0.0009, 0.0072, 0.0033, 0.0019, 0.0048,
        0.0033, 0.0070, 0.0557, 0.0616, 0.0900, 0.0048, 0.1013, 0.2988, 0.1439,
        0.1217], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,268][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.3990, 0.0072, 0.0010, 0.0086, 0.0011, 0.0037, 0.0020, 0.0006, 0.0044,
        0.0018, 0.0040, 0.0320, 0.0871, 0.0595, 0.0082, 0.0574, 0.1051, 0.1371,
        0.0803], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,269][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.4664, 0.0258, 0.0152, 0.0227, 0.0112, 0.0173, 0.0145, 0.0043, 0.0267,
        0.0099, 0.0197, 0.0392, 0.0525, 0.0424, 0.0502, 0.0328, 0.0461, 0.0528,
        0.0504], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,270][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([6.5405e-01, 2.6000e-03, 6.3167e-05, 3.8128e-03, 1.8395e-04, 1.5318e-03,
        3.7269e-04, 4.7201e-04, 1.0543e-03, 5.3188e-04, 1.2774e-03, 1.2454e-02,
        1.9266e-02, 2.1358e-02, 2.2510e-03, 5.5961e-02, 9.7674e-02, 8.1540e-02,
        4.3549e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,271][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.3894, 0.0492, 0.0214, 0.0326, 0.0232, 0.0121, 0.0076, 0.0016, 0.0142,
        0.0063, 0.0066, 0.0281, 0.0639, 0.0319, 0.0549, 0.0236, 0.0631, 0.1074,
        0.0629], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,272][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.6443, 0.0441, 0.0111, 0.0163, 0.0064, 0.0100, 0.0040, 0.0017, 0.0069,
        0.0049, 0.0073, 0.0213, 0.0332, 0.0194, 0.0204, 0.0285, 0.0331, 0.0598,
        0.0274], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,275][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3952, 0.0251, 0.0068, 0.0283, 0.0067, 0.0152, 0.0061, 0.0022, 0.0133,
        0.0064, 0.0113, 0.0373, 0.0631, 0.0481, 0.0240, 0.0665, 0.0772, 0.1048,
        0.0624], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,279][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0467, 0.0121, 0.0040, 0.0149, 0.0084, 0.0279, 0.0193, 0.0138, 0.0089,
        0.0146, 0.0209, 0.0487, 0.0754, 0.0688, 0.0297, 0.0538, 0.2289, 0.1797,
        0.1234], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,282][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:59,285][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[3551],
        [  77],
        [1196],
        [ 237],
        [ 294],
        [ 283],
        [  68],
        [1039],
        [  19],
        [  24],
        [  33],
        [  16],
        [  10],
        [   4],
        [   6],
        [  18],
        [   1],
        [  28],
        [   2]], device='cuda:0')
[2024-07-24 10:17:59,288][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[3389],
        [ 218],
        [3266],
        [1540],
        [1281],
        [ 935],
        [ 807],
        [1893],
        [ 134],
        [ 134],
        [ 257],
        [ 207],
        [  96],
        [  21],
        [  60],
        [ 132],
        [   6],
        [ 196],
        [  21]], device='cuda:0')
[2024-07-24 10:17:59,291][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[17513],
        [ 7710],
        [12198],
        [10558],
        [13162],
        [10823],
        [12370],
        [ 7593],
        [ 9656],
        [ 8455],
        [ 8838],
        [ 9668],
        [ 9766],
        [10772],
        [10194],
        [10631],
        [11853],
        [11255],
        [11839]], device='cuda:0')
[2024-07-24 10:17:59,293][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[18865],
        [18865],
        [18865],
        [18873],
        [19294],
        [18881],
        [18877],
        [18874],
        [18946],
        [18890],
        [18892],
        [18900],
        [18874],
        [18881],
        [22907],
        [18929],
        [19171],
        [19013],
        [19247]], device='cuda:0')
[2024-07-24 10:17:59,294][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 966],
        [1306],
        [ 784],
        [ 821],
        [ 621],
        [ 674],
        [ 689],
        [ 658],
        [ 715],
        [ 608],
        [ 610],
        [ 667],
        [ 727],
        [ 860],
        [ 754],
        [ 742],
        [ 724],
        [ 676],
        [ 674]], device='cuda:0')
[2024-07-24 10:17:59,296][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 6437],
        [10989],
        [13686],
        [15385],
        [16018],
        [14838],
        [14525],
        [13328],
        [12074],
        [10087],
        [ 8242],
        [ 7304],
        [ 8470],
        [ 6907],
        [ 7883],
        [ 6638],
        [ 5411],
        [ 5779],
        [ 5287]], device='cuda:0')
[2024-07-24 10:17:59,300][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[29499],
        [19350],
        [20879],
        [15716],
        [14451],
        [15668],
        [13803],
        [15746],
        [13383],
        [15079],
        [16277],
        [19232],
        [13442],
        [14141],
        [13789],
        [16749],
        [16872],
        [17530],
        [16896]], device='cuda:0')
[2024-07-24 10:17:59,303][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 8775],
        [10141],
        [ 8553],
        [ 7446],
        [ 7176],
        [ 6445],
        [ 6022],
        [ 5483],
        [ 5349],
        [ 5593],
        [ 5568],
        [ 5558],
        [ 5706],
        [ 5868],
        [ 5944],
        [ 6178],
        [ 6176],
        [ 6215],
        [ 6286]], device='cuda:0')
[2024-07-24 10:17:59,304][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[15591],
        [15813],
        [17690],
        [16811],
        [16752],
        [15746],
        [15134],
        [11058],
        [ 8955],
        [ 8988],
        [ 8971],
        [ 9008],
        [ 9063],
        [ 9095],
        [ 7793],
        [ 8953],
        [ 8966],
        [ 9078],
        [ 9035]], device='cuda:0')
[2024-07-24 10:17:59,306][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 9115],
        [13640],
        [13610],
        [12671],
        [12756],
        [13128],
        [13300],
        [12648],
        [12743],
        [13062],
        [12655],
        [12824],
        [13093],
        [13605],
        [13810],
        [13674],
        [13908],
        [13647],
        [14097]], device='cuda:0')
[2024-07-24 10:17:59,308][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[16973],
        [11118],
        [  582],
        [ 1445],
        [ 1305],
        [ 1811],
        [ 2223],
        [ 3186],
        [ 4127],
        [ 4286],
        [ 4208],
        [ 4542],
        [ 4661],
        [ 4399],
        [ 4414],
        [ 3968],
        [ 4250],
        [ 4291],
        [ 4301]], device='cuda:0')
[2024-07-24 10:17:59,311][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[34104],
        [29068],
        [20533],
        [18723],
        [18015],
        [18960],
        [19031],
        [20130],
        [29071],
        [26814],
        [27309],
        [28269],
        [28189],
        [28347],
        [29162],
        [22989],
        [25022],
        [26349],
        [26299]], device='cuda:0')
[2024-07-24 10:17:59,315][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[36778],
        [22923],
        [19772],
        [17129],
        [17925],
        [24888],
        [22289],
        [30857],
        [24507],
        [28784],
        [27395],
        [23618],
        [29504],
        [26973],
        [27190],
        [29447],
        [29145],
        [33772],
        [33697]], device='cuda:0')
[2024-07-24 10:17:59,316][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[35597],
        [49449],
        [50257],
        [50243],
        [49879],
        [48426],
        [42312],
        [41549],
        [41673],
        [40973],
        [41441],
        [37992],
        [29485],
        [30903],
        [27046],
        [30471],
        [28095],
        [24450],
        [22989]], device='cuda:0')
[2024-07-24 10:17:59,318][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[22151],
        [11484],
        [ 5248],
        [ 3013],
        [ 3848],
        [ 3030],
        [ 2059],
        [ 4080],
        [ 6000],
        [ 3941],
        [ 6915],
        [ 3127],
        [ 5893],
        [ 8626],
        [ 4381],
        [ 4153],
        [ 2248],
        [ 6222],
        [ 4386]], device='cuda:0')
[2024-07-24 10:17:59,320][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[20508],
        [17565],
        [16926],
        [16535],
        [15521],
        [18108],
        [11241],
        [14921],
        [ 7881],
        [10345],
        [ 9464],
        [ 5171],
        [ 4869],
        [ 4888],
        [ 5107],
        [ 4521],
        [ 5218],
        [ 5043],
        [ 5145]], device='cuda:0')
[2024-07-24 10:17:59,323][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[14751],
        [42615],
        [36338],
        [37059],
        [38678],
        [38007],
        [37528],
        [35068],
        [36287],
        [36825],
        [38271],
        [36082],
        [34080],
        [35898],
        [33899],
        [36310],
        [34712],
        [33861],
        [30779]], device='cuda:0')
[2024-07-24 10:17:59,326][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[37416],
        [30475],
        [ 9435],
        [ 9689],
        [10799],
        [ 9194],
        [ 9012],
        [ 9022],
        [ 8361],
        [ 8301],
        [ 7981],
        [ 8540],
        [ 9562],
        [ 9654],
        [10509],
        [10141],
        [10017],
        [ 9675],
        [ 9813]], device='cuda:0')
[2024-07-24 10:17:59,328][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[45392],
        [29737],
        [18629],
        [10856],
        [ 8047],
        [10525],
        [ 9071],
        [43405],
        [ 9706],
        [ 9770],
        [ 8838],
        [ 8958],
        [ 9215],
        [ 8866],
        [ 9785],
        [10049],
        [ 9412],
        [ 9770],
        [ 9848]], device='cuda:0')
[2024-07-24 10:17:59,329][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[31856],
        [21210],
        [14406],
        [16257],
        [14417],
        [12677],
        [13074],
        [13462],
        [16511],
        [13362],
        [11268],
        [13748],
        [13626],
        [13005],
        [12224],
        [16491],
        [16787],
        [15885],
        [15053]], device='cuda:0')
[2024-07-24 10:17:59,331][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[40153],
        [37978],
        [38559],
        [37667],
        [38166],
        [38639],
        [38524],
        [39559],
        [34744],
        [37088],
        [35665],
        [36454],
        [33350],
        [31713],
        [26638],
        [35930],
        [33379],
        [28927],
        [25918]], device='cuda:0')
[2024-07-24 10:17:59,335][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[22601],
        [24306],
        [ 9881],
        [10192],
        [ 6973],
        [11717],
        [13590],
        [20884],
        [14436],
        [15145],
        [14931],
        [17003],
        [24043],
        [22218],
        [22332],
        [15977],
        [14653],
        [21335],
        [20271]], device='cuda:0')
[2024-07-24 10:17:59,338][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[27792],
        [29959],
        [31351],
        [29231],
        [29180],
        [28386],
        [27984],
        [27870],
        [27336],
        [27773],
        [28091],
        [26624],
        [27517],
        [27158],
        [ 7264],
        [28160],
        [27045],
        [27651],
        [22392]], device='cuda:0')
[2024-07-24 10:17:59,339][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[14916],
        [31308],
        [31468],
        [30976],
        [32735],
        [28504],
        [30871],
        [22230],
        [28885],
        [30384],
        [30997],
        [31365],
        [25810],
        [27664],
        [19105],
        [28071],
        [26548],
        [23910],
        [23587]], device='cuda:0')
[2024-07-24 10:17:59,341][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[22511],
        [38602],
        [35996],
        [35226],
        [30949],
        [30499],
        [30617],
        [27666],
        [26847],
        [27603],
        [28799],
        [28372],
        [24628],
        [23710],
        [17624],
        [26841],
        [25556],
        [23208],
        [22032]], device='cuda:0')
[2024-07-24 10:17:59,343][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 6993],
        [ 6102],
        [ 3745],
        [11481],
        [10380],
        [ 5336],
        [10021],
        [ 4073],
        [14921],
        [ 7023],
        [ 8117],
        [14881],
        [16472],
        [16197],
        [20767],
        [13043],
        [14558],
        [15180],
        [16460]], device='cuda:0')
[2024-07-24 10:17:59,346][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[14458],
        [ 2589],
        [30302],
        [25534],
        [26067],
        [33339],
        [27155],
        [20342],
        [19843],
        [14884],
        [17917],
        [23172],
        [14206],
        [17047],
        [15268],
        [19210],
        [13393],
        [16061],
        [16501]], device='cuda:0')
[2024-07-24 10:17:59,349][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[10339],
        [ 5983],
        [16941],
        [15268],
        [18364],
        [19953],
        [20585],
        [12114],
        [21914],
        [23082],
        [24522],
        [21849],
        [25436],
        [25866],
        [35545],
        [22998],
        [27314],
        [28705],
        [32156]], device='cuda:0')
[2024-07-24 10:17:59,351][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[16873],
        [26850],
        [29350],
        [33023],
        [31029],
        [36811],
        [32679],
        [24670],
        [29820],
        [34009],
        [23116],
        [29864],
        [29415],
        [29844],
        [38275],
        [26508],
        [33208],
        [29370],
        [30193]], device='cuda:0')
[2024-07-24 10:17:59,352][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[6018],
        [6018],
        [6018],
        [6018],
        [6018],
        [6018],
        [6018],
        [6018],
        [6018],
        [6018],
        [6018],
        [6018],
        [6018],
        [6018],
        [6018],
        [6018],
        [6018],
        [6018],
        [6018]], device='cuda:0')
[2024-07-24 10:17:59,448][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:59,449][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,450][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,451][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,452][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,454][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,457][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,459][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,460][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,460][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,461][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,462][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,462][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,466][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6728, 0.3272], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,470][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1678, 0.8322], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,470][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3864, 0.6136], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,471][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9465, 0.0535], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,472][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4750, 0.5250], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,472][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.6610, 0.3390], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,473][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0020, 0.9980], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,477][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.8454, 0.1546], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,480][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5406, 0.4594], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,481][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2626, 0.7374], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,482][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7144, 0.2856], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,482][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0265, 0.9735], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,483][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Jamie] are: tensor([0.8780, 0.0567, 0.0653], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,485][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Jamie] are: tensor([0.1509, 0.1293, 0.7198], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,489][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Jamie] are: tensor([0.6210, 0.0932, 0.2859], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,491][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Jamie] are: tensor([0.9913, 0.0052, 0.0035], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,492][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Jamie] are: tensor([0.8397, 0.0558, 0.1045], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,492][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Jamie] are: tensor([0.7984, 0.1522, 0.0494], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,493][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Jamie] are: tensor([0.0034, 0.1932, 0.8034], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,494][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Jamie] are: tensor([0.8496, 0.0504, 0.1001], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,496][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Jamie] are: tensor([0.5906, 0.0768, 0.3326], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,500][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Jamie] are: tensor([0.2226, 0.1041, 0.6734], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,502][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Jamie] are: tensor([0.9158, 0.0367, 0.0476], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,502][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Jamie] are: tensor([0.0211, 0.4182, 0.5607], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,503][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7771, 0.1204, 0.0736, 0.0289], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,504][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1032, 0.2581, 0.4936, 0.1450], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,505][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3134, 0.2690, 0.2710, 0.1466], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,507][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.9538, 0.0281, 0.0078, 0.0104], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,511][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4807, 0.1386, 0.2310, 0.1497], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,512][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.7381, 0.1567, 0.0430, 0.0622], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,513][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0028, 0.2033, 0.5455, 0.2484], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,514][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.6999, 0.0919, 0.1335, 0.0747], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,515][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2493, 0.1913, 0.4314, 0.1281], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,515][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3232, 0.1162, 0.5310, 0.0296], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,517][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.6850, 0.1078, 0.0403, 0.1669], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,521][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0130, 0.3428, 0.5198, 0.1243], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,523][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.8119, 0.0651, 0.0520, 0.0320, 0.0391], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:59,524][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0441, 0.1293, 0.5377, 0.0982, 0.1908], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:59,525][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.4136, 0.1196, 0.1959, 0.1049, 0.1660], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:59,525][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.9743, 0.0078, 0.0027, 0.0116, 0.0037], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:59,526][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.4988, 0.1228, 0.1833, 0.0745, 0.1207], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:59,529][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.6873, 0.1891, 0.0359, 0.0682, 0.0196], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:59,533][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0024, 0.1258, 0.4317, 0.1116, 0.3285], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:59,537][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.6071, 0.0557, 0.0833, 0.0949, 0.1590], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:59,537][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.2257, 0.0750, 0.2785, 0.1991, 0.2217], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:59,538][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.2015, 0.0914, 0.3500, 0.0218, 0.3352], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:59,539][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.8133, 0.0212, 0.0115, 0.1302, 0.0238], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:59,540][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0072, 0.2430, 0.3723, 0.1944, 0.1832], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:17:59,542][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.8761, 0.0838, 0.0177, 0.0121, 0.0087, 0.0016], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:59,546][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.2292, 0.2042, 0.3419, 0.0911, 0.0957, 0.0379], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:59,548][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.5012, 0.1903, 0.1824, 0.0494, 0.0623, 0.0143], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:59,548][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.9732, 0.0176, 0.0023, 0.0050, 0.0010, 0.0010], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:59,549][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.8021, 0.0839, 0.0497, 0.0237, 0.0328, 0.0079], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:59,550][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.9140, 0.0517, 0.0104, 0.0144, 0.0041, 0.0055], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:59,551][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0037, 0.1441, 0.4315, 0.0817, 0.1840, 0.1550], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:59,553][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.7249, 0.0590, 0.0523, 0.0525, 0.0411, 0.0701], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:59,558][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.3321, 0.1543, 0.2350, 0.0817, 0.1018, 0.0952], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:59,559][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3689, 0.1561, 0.2275, 0.0176, 0.1359, 0.0939], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:59,559][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.8771, 0.0404, 0.0063, 0.0564, 0.0066, 0.0132], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:59,560][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0087, 0.2615, 0.3363, 0.1019, 0.0967, 0.1949], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:17:59,561][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.8203, 0.0990, 0.0346, 0.0238, 0.0114, 0.0045, 0.0062],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,562][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0995, 0.2372, 0.3346, 0.0991, 0.0970, 0.0781, 0.0546],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,565][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2687, 0.2715, 0.1817, 0.1174, 0.0834, 0.0531, 0.0243],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,567][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([9.9507e-01, 5.5513e-04, 1.1792e-05, 1.2466e-03, 3.4173e-05, 4.2850e-04,
        2.6549e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,569][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.3135, 0.1784, 0.2060, 0.0870, 0.1187, 0.0427, 0.0536],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,570][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.7950, 0.1317, 0.0123, 0.0390, 0.0053, 0.0120, 0.0047],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,571][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0010, 0.1421, 0.3825, 0.0892, 0.1337, 0.1546, 0.0969],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,572][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.5645, 0.0484, 0.0229, 0.0597, 0.0284, 0.1269, 0.1492],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,572][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2678, 0.1956, 0.2500, 0.0916, 0.0604, 0.1138, 0.0209],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,575][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2291, 0.1392, 0.2130, 0.0185, 0.1474, 0.1252, 0.1276],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,577][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.5922e-01, 1.8340e-03, 6.6060e-05, 1.8679e-02, 2.3659e-04, 4.0162e-03,
        1.5950e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,580][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0069, 0.2266, 0.3629, 0.0784, 0.0727, 0.1495, 0.1030],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:17:59,581][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([9.5961e-01, 3.1251e-02, 3.9427e-03, 2.9706e-03, 1.6096e-03, 8.8094e-05,
        5.2149e-04, 3.6055e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,581][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.3808, 0.1994, 0.1822, 0.0976, 0.0724, 0.0212, 0.0431, 0.0033],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,582][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([5.6957e-01, 2.2261e-01, 1.6153e-01, 2.1362e-02, 1.8460e-02, 8.3654e-04,
        5.6090e-03, 1.7009e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,583][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([9.9757e-01, 1.8070e-03, 2.3816e-05, 4.7626e-04, 9.8318e-06, 1.8853e-05,
        9.4364e-05, 3.2028e-07], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,585][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([9.8446e-01, 1.1492e-02, 2.2320e-03, 9.7294e-04, 4.3307e-04, 2.5594e-05,
        3.7899e-04, 1.6868e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,587][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([9.6896e-01, 1.9173e-02, 2.9492e-03, 5.2158e-03, 1.3348e-03, 1.1883e-03,
        8.4277e-04, 3.3172e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,591][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0333, 0.2312, 0.4154, 0.0814, 0.1114, 0.0478, 0.0734, 0.0061],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,591][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.6124, 0.0465, 0.0152, 0.0912, 0.0201, 0.0700, 0.1112, 0.0334],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,592][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.2361, 0.1521, 0.1823, 0.1450, 0.1284, 0.0943, 0.0354, 0.0264],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,593][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.5535, 0.1102, 0.1461, 0.0066, 0.1040, 0.0157, 0.0510, 0.0130],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,594][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([9.7917e-01, 7.4576e-03, 2.0744e-04, 8.4418e-03, 2.6059e-04, 9.5565e-04,
        3.3290e-03, 1.7768e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,596][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0084, 0.0815, 0.2133, 0.0712, 0.0906, 0.1847, 0.3181, 0.0322],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:17:59,601][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.7333, 0.1204, 0.0469, 0.0385, 0.0187, 0.0122, 0.0099, 0.0031, 0.0170],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,602][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0579, 0.1669, 0.4053, 0.0797, 0.0914, 0.0976, 0.0447, 0.0102, 0.0463],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,603][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.2138, 0.2805, 0.1086, 0.1429, 0.0790, 0.1104, 0.0274, 0.0112, 0.0261],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,603][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ of] are: tensor([9.3890e-01, 3.3536e-04, 1.3499e-05, 1.7122e-03, 6.4714e-05, 9.4971e-04,
        1.3405e-02, 2.6793e-03, 4.1945e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,604][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1722, 0.1503, 0.2221, 0.0796, 0.1362, 0.0690, 0.0634, 0.0216, 0.0857],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,605][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.6329, 0.2117, 0.0204, 0.0619, 0.0124, 0.0241, 0.0102, 0.0041, 0.0223],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,609][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0007, 0.1132, 0.2669, 0.0753, 0.1615, 0.1951, 0.1124, 0.0289, 0.0461],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,612][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.2887, 0.0248, 0.0092, 0.0512, 0.0155, 0.0866, 0.1604, 0.0171, 0.3466],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,613][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.2438, 0.2822, 0.1917, 0.0725, 0.0456, 0.1018, 0.0203, 0.0222, 0.0200],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,614][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.2037, 0.0585, 0.1325, 0.0073, 0.0957, 0.0840, 0.1134, 0.0765, 0.2283],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,615][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ of] are: tensor([7.5838e-01, 9.9038e-04, 4.0620e-05, 1.6374e-02, 2.0925e-04, 3.1014e-03,
        2.4439e-02, 3.4325e-02, 1.6214e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,615][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0043, 0.2337, 0.2204, 0.0813, 0.0573, 0.1761, 0.1196, 0.0154, 0.0920],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:17:59,617][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([8.7159e-01, 7.8635e-02, 1.5789e-02, 1.2774e-02, 6.6794e-03, 1.7464e-03,
        2.4662e-03, 2.5296e-04, 6.4389e-03, 3.6330e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,621][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0999, 0.1370, 0.2491, 0.0885, 0.0749, 0.0644, 0.0791, 0.0091, 0.1221,
        0.0758], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,623][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.4791, 0.2338, 0.1422, 0.0600, 0.0400, 0.0136, 0.0107, 0.0007, 0.0133,
        0.0066], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,624][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([9.8615e-01, 3.3519e-04, 4.8998e-06, 6.1522e-04, 1.0305e-05, 1.4347e-04,
        1.1828e-03, 5.6105e-05, 9.6891e-03, 1.8149e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,625][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.6992, 0.0957, 0.0828, 0.0266, 0.0258, 0.0072, 0.0115, 0.0007, 0.0374,
        0.0132], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,625][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.8793, 0.0707, 0.0074, 0.0207, 0.0037, 0.0062, 0.0025, 0.0014, 0.0056,
        0.0027], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,626][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0026, 0.1257, 0.3620, 0.0709, 0.1140, 0.0977, 0.0885, 0.0085, 0.0753,
        0.0549], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,630][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.4581, 0.0228, 0.0067, 0.0383, 0.0095, 0.0582, 0.0964, 0.0125, 0.2139,
        0.0835], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,634][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.3573, 0.1922, 0.1361, 0.0937, 0.0567, 0.0738, 0.0191, 0.0132, 0.0327,
        0.0253], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,634][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.3161, 0.0363, 0.1012, 0.0048, 0.0849, 0.0359, 0.0602, 0.0261, 0.2357,
        0.0987], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,635][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([8.7833e-01, 1.8195e-03, 4.7961e-05, 1.1156e-02, 1.2130e-04, 2.3368e-03,
        1.1695e-02, 6.8787e-03, 7.0574e-02, 1.7040e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,636][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0048, 0.0907, 0.1906, 0.0731, 0.0464, 0.1818, 0.1786, 0.0231, 0.0938,
        0.1172], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:17:59,637][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ at] are: tensor([8.1571e-01, 1.2735e-01, 1.7277e-02, 1.8411e-02, 6.1295e-03, 2.0700e-03,
        2.2926e-03, 2.3550e-04, 5.5263e-03, 2.5731e-03, 2.4250e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,639][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.1334, 0.2282, 0.2509, 0.1030, 0.0655, 0.0406, 0.0422, 0.0051, 0.0803,
        0.0308, 0.0199], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,644][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.3752, 0.3827, 0.0989, 0.0715, 0.0291, 0.0138, 0.0095, 0.0008, 0.0097,
        0.0046, 0.0042], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,645][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ at] are: tensor([9.9105e-01, 3.9752e-04, 5.5368e-06, 5.1170e-04, 8.1901e-06, 8.1387e-05,
        6.1323e-04, 2.7156e-05, 4.8736e-03, 1.0414e-03, 1.3948e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,646][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.6889, 0.1344, 0.0613, 0.0267, 0.0269, 0.0054, 0.0103, 0.0008, 0.0317,
        0.0091, 0.0046], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,646][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.8717, 0.0774, 0.0082, 0.0202, 0.0032, 0.0058, 0.0021, 0.0011, 0.0040,
        0.0019, 0.0044], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,647][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0024, 0.1446, 0.3637, 0.0721, 0.1248, 0.0800, 0.0763, 0.0062, 0.0641,
        0.0409, 0.0248], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,649][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.4701, 0.0293, 0.0072, 0.0484, 0.0099, 0.0569, 0.0665, 0.0170, 0.1439,
        0.0629, 0.0879], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,653][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.3160, 0.2293, 0.1561, 0.0916, 0.0578, 0.0682, 0.0136, 0.0151, 0.0169,
        0.0201, 0.0153], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,655][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1814, 0.0515, 0.1017, 0.0051, 0.0769, 0.0330, 0.0613, 0.0245, 0.2671,
        0.0984, 0.0989], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,656][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ at] are: tensor([8.9292e-01, 2.2990e-03, 4.3231e-05, 1.2417e-02, 1.0346e-04, 1.8629e-03,
        6.7992e-03, 5.0386e-03, 4.3200e-02, 1.0150e-02, 2.5163e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,657][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0067, 0.1325, 0.2223, 0.0616, 0.0498, 0.1561, 0.1226, 0.0201, 0.0810,
        0.0746, 0.0729], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:17:59,658][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.6434, 0.1963, 0.0476, 0.0355, 0.0184, 0.0094, 0.0056, 0.0018, 0.0084,
        0.0092, 0.0058, 0.0185], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,659][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0499, 0.1678, 0.3385, 0.0818, 0.0854, 0.0676, 0.0389, 0.0073, 0.0450,
        0.0366, 0.0206, 0.0607], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,662][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2042, 0.3866, 0.1174, 0.0994, 0.0554, 0.0484, 0.0157, 0.0042, 0.0127,
        0.0129, 0.0110, 0.0320], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,664][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ the] are: tensor([9.7012e-01, 8.7747e-04, 1.5716e-05, 1.0901e-03, 2.0537e-05, 2.9786e-04,
        6.0805e-04, 3.2702e-04, 2.2327e-03, 1.0172e-03, 1.9621e-03, 2.1433e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,666][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1868, 0.1628, 0.1847, 0.0584, 0.0946, 0.0417, 0.0442, 0.0102, 0.0641,
        0.0412, 0.0252, 0.0862], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,667][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.7105, 0.1441, 0.0165, 0.0478, 0.0085, 0.0150, 0.0045, 0.0018, 0.0095,
        0.0042, 0.0080, 0.0296], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,668][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0005, 0.1152, 0.3445, 0.0569, 0.1375, 0.1013, 0.0729, 0.0120, 0.0340,
        0.0487, 0.0270, 0.0495], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,669][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.2984, 0.0452, 0.0127, 0.0532, 0.0133, 0.0712, 0.0466, 0.0129, 0.0905,
        0.0499, 0.0565, 0.2496], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,669][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.2181, 0.3104, 0.1814, 0.0760, 0.0414, 0.0729, 0.0122, 0.0130, 0.0143,
        0.0141, 0.0132, 0.0329], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,673][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.2033, 0.0436, 0.0864, 0.0062, 0.0524, 0.0471, 0.0586, 0.0315, 0.2010,
        0.0944, 0.0849, 0.0908], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,675][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ the] are: tensor([7.8739e-01, 2.9488e-03, 8.8758e-05, 1.4865e-02, 1.5976e-04, 2.5538e-03,
        3.5863e-03, 1.2456e-02, 1.6174e-02, 5.2709e-03, 1.6090e-02, 1.3842e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,677][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0032, 0.1185, 0.1988, 0.0713, 0.0411, 0.1459, 0.1116, 0.0169, 0.0798,
        0.0777, 0.0690, 0.0661], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:17:59,678][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.4848, 0.2205, 0.0299, 0.0310, 0.0162, 0.0106, 0.0074, 0.0030, 0.0117,
        0.0175, 0.0094, 0.0308, 0.1273], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,679][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0368, 0.1072, 0.2376, 0.0746, 0.0669, 0.0759, 0.0545, 0.0119, 0.0581,
        0.0473, 0.0368, 0.0797, 0.1126], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,680][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.1748, 0.2367, 0.0914, 0.0887, 0.0593, 0.0910, 0.0266, 0.0170, 0.0196,
        0.0295, 0.0283, 0.0641, 0.0730], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,680][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ store] are: tensor([8.6282e-01, 4.2838e-04, 7.3437e-06, 9.6366e-04, 1.1191e-05, 2.8893e-04,
        6.4337e-04, 5.1407e-04, 1.8562e-03, 7.9184e-04, 1.8091e-03, 2.8156e-02,
        1.0171e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,684][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0706, 0.1558, 0.1818, 0.0832, 0.1022, 0.0627, 0.0402, 0.0216, 0.0554,
        0.0390, 0.0260, 0.0617, 0.0999], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,688][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.4299, 0.2229, 0.0232, 0.0725, 0.0103, 0.0283, 0.0080, 0.0080, 0.0138,
        0.0092, 0.0172, 0.0399, 0.1167], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,688][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0006, 0.0897, 0.2003, 0.0671, 0.0946, 0.1316, 0.1064, 0.0120, 0.0656,
        0.0537, 0.0383, 0.0777, 0.0624], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,689][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.1568, 0.0312, 0.0041, 0.0297, 0.0051, 0.0339, 0.0227, 0.0082, 0.0399,
        0.0247, 0.0305, 0.1307, 0.4825], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,690][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.3279, 0.1938, 0.0935, 0.0771, 0.0277, 0.0811, 0.0134, 0.0293, 0.0173,
        0.0187, 0.0222, 0.0447, 0.0532], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,691][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0643, 0.0255, 0.0732, 0.0034, 0.0867, 0.0344, 0.0624, 0.0260, 0.2271,
        0.0896, 0.1036, 0.1005, 0.1033], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,693][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ store] are: tensor([4.3963e-01, 1.8856e-03, 5.3349e-05, 1.0589e-02, 9.3970e-05, 2.1336e-03,
        2.8955e-03, 8.5323e-03, 1.1688e-02, 4.6284e-03, 1.3634e-02, 1.3950e-01,
        3.6473e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,696][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0023, 0.1100, 0.1452, 0.0694, 0.0359, 0.1892, 0.0982, 0.0122, 0.0557,
        0.0628, 0.0636, 0.0653, 0.0902], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:17:59,696][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.4450, 0.2615, 0.0813, 0.0476, 0.0171, 0.0132, 0.0058, 0.0039, 0.0065,
        0.0095, 0.0054, 0.0214, 0.0536, 0.0284], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,700][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0374, 0.1950, 0.2997, 0.0670, 0.0721, 0.0809, 0.0295, 0.0070, 0.0215,
        0.0255, 0.0146, 0.0326, 0.0846, 0.0326], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,701][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.2022, 0.3792, 0.0945, 0.1062, 0.0395, 0.0619, 0.0099, 0.0072, 0.0073,
        0.0101, 0.0094, 0.0261, 0.0270, 0.0196], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,701][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [.] are: tensor([8.6413e-01, 1.0676e-03, 1.0860e-05, 1.4515e-03, 1.4341e-05, 2.6616e-04,
        1.6982e-04, 1.9371e-04, 5.9416e-04, 2.4136e-04, 5.1023e-04, 8.4419e-03,
        3.4420e-02, 8.8487e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,702][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0785, 0.1857, 0.2228, 0.0582, 0.1017, 0.0384, 0.0314, 0.0117, 0.0351,
        0.0251, 0.0157, 0.0515, 0.0564, 0.0878], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,703][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.5349, 0.2349, 0.0153, 0.0617, 0.0081, 0.0145, 0.0039, 0.0024, 0.0076,
        0.0037, 0.0071, 0.0238, 0.0700, 0.0120], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,706][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0005, 0.1511, 0.3227, 0.0629, 0.1211, 0.1160, 0.0479, 0.0178, 0.0188,
        0.0321, 0.0201, 0.0358, 0.0332, 0.0199], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,710][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.1557, 0.0285, 0.0057, 0.0244, 0.0045, 0.0265, 0.0122, 0.0041, 0.0212,
        0.0124, 0.0159, 0.0832, 0.3523, 0.2534], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,711][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.2142, 0.3815, 0.1607, 0.0604, 0.0292, 0.0508, 0.0077, 0.0079, 0.0075,
        0.0066, 0.0068, 0.0202, 0.0263, 0.0203], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,712][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.2002, 0.0464, 0.0911, 0.0047, 0.0717, 0.0521, 0.0595, 0.0293, 0.1301,
        0.0748, 0.0744, 0.0663, 0.0634, 0.0360], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,713][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [.] are: tensor([6.0606e-01, 3.5617e-03, 7.7920e-05, 2.0396e-02, 1.2380e-04, 2.6027e-03,
        9.5879e-04, 1.0989e-02, 4.2991e-03, 1.6630e-03, 4.9880e-03, 4.5890e-02,
        1.0430e-01, 1.9409e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,714][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0031, 0.2250, 0.1976, 0.0671, 0.0368, 0.1156, 0.0619, 0.0121, 0.0383,
        0.0426, 0.0434, 0.0389, 0.0912, 0.0263], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:17:59,717][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.3696, 0.1325, 0.0582, 0.0431, 0.0323, 0.0204, 0.0156, 0.0073, 0.0179,
        0.0248, 0.0192, 0.0452, 0.1019, 0.0533, 0.0588], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,721][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0102, 0.0930, 0.2181, 0.0563, 0.0716, 0.0820, 0.0470, 0.0111, 0.0421,
        0.0436, 0.0333, 0.0638, 0.1006, 0.0613, 0.0662], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,722][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.1178, 0.1552, 0.1026, 0.0840, 0.0683, 0.1092, 0.0254, 0.0283, 0.0181,
        0.0392, 0.0382, 0.0501, 0.0500, 0.0350, 0.0785], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,723][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([6.3013e-02, 1.2268e-04, 8.6653e-06, 3.1486e-04, 1.4505e-05, 2.3952e-04,
        2.6958e-03, 5.4964e-04, 1.0863e-02, 4.3959e-03, 9.9339e-03, 6.7529e-02,
        3.1943e-01, 5.1517e-01, 5.7158e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,724][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0501, 0.1034, 0.1525, 0.0573, 0.0829, 0.0490, 0.0329, 0.0299, 0.0460,
        0.0460, 0.0251, 0.0563, 0.0699, 0.0809, 0.1179], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,725][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.3443, 0.1787, 0.0212, 0.0650, 0.0130, 0.0299, 0.0119, 0.0083, 0.0221,
        0.0113, 0.0250, 0.0481, 0.1514, 0.0238, 0.0459], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,728][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0004, 0.0850, 0.2204, 0.0546, 0.1226, 0.1144, 0.0642, 0.0217, 0.0414,
        0.0534, 0.0354, 0.0470, 0.0500, 0.0343, 0.0552], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,732][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0270, 0.0034, 0.0016, 0.0067, 0.0030, 0.0148, 0.0251, 0.0061, 0.0488,
        0.0284, 0.0348, 0.0960, 0.3333, 0.3102, 0.0608], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,733][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.0864, 0.1018, 0.1432, 0.0707, 0.0611, 0.0914, 0.0241, 0.0230, 0.0269,
        0.0353, 0.0304, 0.0582, 0.1066, 0.0564, 0.0845], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,734][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0604, 0.0328, 0.0716, 0.0058, 0.0713, 0.0447, 0.0454, 0.0220, 0.1606,
        0.0885, 0.0675, 0.0975, 0.0828, 0.0604, 0.0886], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,735][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([1.3202e-02, 1.4203e-04, 2.1204e-05, 1.2220e-03, 4.7645e-05, 5.7611e-04,
        4.9305e-03, 3.9357e-03, 1.9079e-02, 7.6418e-03, 1.8511e-02, 1.2302e-01,
        3.7948e-01, 4.2149e-01, 6.7010e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,736][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0016, 0.1073, 0.1217, 0.0829, 0.0481, 0.1241, 0.0927, 0.0184, 0.0750,
        0.0620, 0.0686, 0.0548, 0.0706, 0.0472, 0.0249], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:17:59,738][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([8.1023e-01, 1.1043e-01, 9.7225e-03, 9.7869e-03, 3.7969e-03, 8.0449e-04,
        1.0416e-03, 6.7601e-05, 3.3192e-03, 1.0490e-03, 8.9130e-04, 5.2479e-03,
        1.6763e-02, 1.4709e-02, 1.0361e-02, 1.7794e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,743][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0590, 0.1299, 0.2401, 0.0678, 0.0424, 0.0220, 0.0282, 0.0022, 0.0529,
        0.0220, 0.0128, 0.0559, 0.1109, 0.0777, 0.0566, 0.0195],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,743][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([4.4553e-01, 3.1345e-01, 1.1048e-01, 3.0695e-02, 1.8809e-02, 4.0777e-03,
        4.2293e-03, 1.4963e-04, 6.2724e-03, 1.5752e-03, 1.5335e-03, 1.0587e-02,
        1.1864e-02, 1.3577e-02, 2.5312e-02, 1.8566e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,744][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([9.7670e-01, 8.2058e-04, 4.5330e-06, 2.4528e-04, 2.2589e-06, 1.6726e-05,
        1.8679e-05, 2.3934e-06, 1.4392e-04, 2.5214e-05, 3.7519e-05, 1.0577e-03,
        9.5789e-03, 1.0359e-02, 2.1900e-04, 7.6874e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,745][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([6.3005e-01, 8.9391e-02, 3.4963e-02, 1.2866e-02, 7.7549e-03, 1.9207e-03,
        5.9085e-03, 2.2433e-04, 2.8840e-02, 4.2461e-03, 2.2596e-03, 2.2615e-02,
        4.3240e-02, 5.9076e-02, 5.2997e-02, 3.6523e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,746][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([8.5697e-01, 4.7676e-02, 6.2653e-03, 1.3111e-02, 2.2508e-03, 2.7871e-03,
        1.2884e-03, 2.6996e-04, 2.9236e-03, 8.8363e-04, 1.6780e-03, 8.2816e-03,
        2.9599e-02, 5.0841e-03, 1.1213e-02, 9.7240e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,749][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0025, 0.1366, 0.2858, 0.0533, 0.0812, 0.0526, 0.0476, 0.0056, 0.0508,
        0.0314, 0.0187, 0.0446, 0.0707, 0.0478, 0.0470, 0.0238],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,753][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1772, 0.0205, 0.0038, 0.0229, 0.0034, 0.0197, 0.0109, 0.0043, 0.0263,
        0.0123, 0.0146, 0.0748, 0.2315, 0.2070, 0.0522, 0.1187],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,754][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.3017, 0.2025, 0.1056, 0.0585, 0.0370, 0.0433, 0.0086, 0.0098, 0.0138,
        0.0130, 0.0091, 0.0256, 0.0552, 0.0356, 0.0453, 0.0353],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,755][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1981, 0.0415, 0.0684, 0.0030, 0.0627, 0.0192, 0.0261, 0.0197, 0.1684,
        0.0743, 0.0559, 0.0565, 0.0578, 0.0447, 0.0748, 0.0289],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,756][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([7.3258e-01, 5.0912e-03, 9.5937e-05, 7.9847e-03, 9.1761e-05, 9.2357e-04,
        7.0028e-04, 9.3017e-04, 3.8709e-03, 7.5009e-04, 1.8621e-03, 2.7725e-02,
        7.5733e-02, 9.1877e-02, 3.0367e-03, 4.6749e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,757][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0043, 0.1609, 0.1272, 0.0510, 0.0337, 0.0944, 0.0847, 0.0118, 0.0658,
        0.0522, 0.0477, 0.0643, 0.0819, 0.0476, 0.0223, 0.0502],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:17:59,759][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.6393, 0.1955, 0.0277, 0.0215, 0.0071, 0.0042, 0.0020, 0.0007, 0.0033,
        0.0033, 0.0022, 0.0099, 0.0298, 0.0125, 0.0112, 0.0096, 0.0201],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,764][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0533, 0.1546, 0.1917, 0.0592, 0.0531, 0.0435, 0.0284, 0.0059, 0.0318,
        0.0233, 0.0129, 0.0405, 0.1037, 0.0424, 0.0556, 0.0322, 0.0678],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,765][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2549, 0.3845, 0.1055, 0.0723, 0.0358, 0.0271, 0.0070, 0.0022, 0.0048,
        0.0050, 0.0049, 0.0138, 0.0135, 0.0119, 0.0228, 0.0110, 0.0230],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,766][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([9.3484e-01, 1.1260e-03, 6.9772e-06, 6.3010e-04, 5.7113e-06, 9.3920e-05,
        4.1690e-05, 4.6271e-05, 1.7789e-04, 6.2839e-05, 1.4921e-04, 2.2463e-03,
        1.0609e-02, 2.6503e-02, 3.9149e-04, 6.2784e-03, 1.6794e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,767][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1885, 0.1311, 0.0926, 0.0374, 0.0377, 0.0146, 0.0235, 0.0027, 0.0462,
        0.0150, 0.0089, 0.0583, 0.0609, 0.0894, 0.0862, 0.0245, 0.0826],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,768][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.6888, 0.1314, 0.0113, 0.0318, 0.0038, 0.0083, 0.0020, 0.0010, 0.0041,
        0.0016, 0.0036, 0.0136, 0.0363, 0.0059, 0.0121, 0.0243, 0.0201],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,771][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0008, 0.1376, 0.2449, 0.0551, 0.0754, 0.0835, 0.0465, 0.0135, 0.0259,
        0.0356, 0.0191, 0.0425, 0.0467, 0.0269, 0.0300, 0.0461, 0.0701],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,775][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1621, 0.0285, 0.0045, 0.0210, 0.0032, 0.0214, 0.0067, 0.0029, 0.0126,
        0.0069, 0.0085, 0.0473, 0.1751, 0.1678, 0.0365, 0.0943, 0.2007],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,776][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2415, 0.2722, 0.1322, 0.0760, 0.0321, 0.0521, 0.0076, 0.0092, 0.0084,
        0.0080, 0.0076, 0.0213, 0.0260, 0.0210, 0.0238, 0.0276, 0.0336],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,777][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1132, 0.0489, 0.0712, 0.0058, 0.0538, 0.0356, 0.0353, 0.0233, 0.1408,
        0.0711, 0.0619, 0.0647, 0.0682, 0.0562, 0.0576, 0.0377, 0.0546],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,778][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([5.6786e-01, 3.1587e-03, 5.3540e-05, 1.0846e-02, 6.1932e-05, 1.1770e-03,
        4.8749e-04, 3.7387e-03, 2.0804e-03, 6.4465e-04, 2.2344e-03, 2.2549e-02,
        6.1157e-02, 8.1305e-02, 1.8167e-03, 1.0496e-01, 1.3587e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,780][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0040, 0.1691, 0.1736, 0.0571, 0.0363, 0.1089, 0.0568, 0.0268, 0.0368,
        0.0595, 0.0350, 0.0350, 0.0786, 0.0198, 0.0151, 0.0410, 0.0466],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:17:59,784][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.6252, 0.1222, 0.0228, 0.0241, 0.0094, 0.0044, 0.0027, 0.0008, 0.0064,
        0.0045, 0.0036, 0.0124, 0.0382, 0.0208, 0.0171, 0.0088, 0.0174, 0.0592],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,786][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0626, 0.1055, 0.1278, 0.0506, 0.0464, 0.0329, 0.0245, 0.0052, 0.0300,
        0.0258, 0.0129, 0.0401, 0.0946, 0.0461, 0.0614, 0.0334, 0.0520, 0.1481],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,787][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.3210, 0.3378, 0.0587, 0.0536, 0.0260, 0.0236, 0.0062, 0.0033, 0.0070,
        0.0050, 0.0062, 0.0177, 0.0206, 0.0125, 0.0266, 0.0151, 0.0256, 0.0335],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,788][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([6.8837e-01, 7.8390e-04, 6.7195e-06, 7.8087e-04, 6.3271e-06, 1.2786e-04,
        1.7663e-04, 7.2478e-05, 6.7280e-04, 1.6759e-04, 4.4022e-04, 7.9130e-03,
        3.7486e-02, 9.4315e-02, 8.7437e-04, 1.4554e-02, 9.0858e-02, 6.2391e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,789][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0916, 0.1591, 0.1202, 0.0553, 0.0635, 0.0370, 0.0229, 0.0074, 0.0335,
        0.0187, 0.0120, 0.0368, 0.0339, 0.0396, 0.0935, 0.0284, 0.0383, 0.1084],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,792][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.5425, 0.1687, 0.0154, 0.0416, 0.0049, 0.0113, 0.0031, 0.0025, 0.0057,
        0.0027, 0.0054, 0.0144, 0.0451, 0.0068, 0.0150, 0.0364, 0.0220, 0.0566],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,796][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0007, 0.1055, 0.1519, 0.0513, 0.0670, 0.0698, 0.0621, 0.0054, 0.0504,
        0.0394, 0.0198, 0.0524, 0.0509, 0.0351, 0.0471, 0.0458, 0.0747, 0.0705],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,797][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0890, 0.0121, 0.0018, 0.0123, 0.0018, 0.0139, 0.0075, 0.0023, 0.0120,
        0.0070, 0.0084, 0.0510, 0.1413, 0.1630, 0.0287, 0.0822, 0.1754, 0.1903],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,798][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.2168, 0.1527, 0.1147, 0.0708, 0.0284, 0.0554, 0.0113, 0.0136, 0.0135,
        0.0118, 0.0122, 0.0317, 0.0442, 0.0287, 0.0339, 0.0519, 0.0502, 0.0580],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,799][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.1380, 0.0241, 0.0656, 0.0025, 0.0525, 0.0170, 0.0322, 0.0187, 0.1276,
        0.0629, 0.0615, 0.0618, 0.0557, 0.0423, 0.0697, 0.0247, 0.0486, 0.0946],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,800][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([3.0012e-01, 1.1731e-03, 1.9013e-05, 4.3546e-03, 2.3927e-05, 5.8930e-04,
        5.0372e-04, 2.7774e-03, 2.4200e-03, 7.9246e-04, 2.3731e-03, 2.8250e-02,
        9.4590e-02, 1.0997e-01, 1.5344e-03, 1.1906e-01, 2.0414e-01, 1.2730e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,803][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.0048, 0.1908, 0.1340, 0.0605, 0.0367, 0.1153, 0.0657, 0.0080, 0.0418,
        0.0291, 0.0254, 0.0419, 0.0552, 0.0251, 0.0232, 0.0512, 0.0468, 0.0445],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:17:59,807][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4888, 0.1902, 0.0246, 0.0273, 0.0075, 0.0081, 0.0035, 0.0014, 0.0048,
        0.0064, 0.0037, 0.0163, 0.0512, 0.0177, 0.0132, 0.0238, 0.0317, 0.0616,
        0.0181], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,808][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0395, 0.1696, 0.1814, 0.0539, 0.0418, 0.0499, 0.0208, 0.0048, 0.0178,
        0.0154, 0.0111, 0.0252, 0.0589, 0.0263, 0.0325, 0.0241, 0.0465, 0.1520,
        0.0285], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,809][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2180, 0.3348, 0.0567, 0.0763, 0.0272, 0.0518, 0.0069, 0.0058, 0.0052,
        0.0071, 0.0072, 0.0204, 0.0195, 0.0140, 0.0256, 0.0332, 0.0385, 0.0386,
        0.0131], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,810][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([5.6130e-01, 3.2811e-04, 2.8224e-06, 4.4913e-04, 3.3155e-06, 1.0395e-04,
        1.2870e-04, 8.2962e-05, 4.5638e-04, 1.7070e-04, 4.2590e-04, 9.1369e-03,
        4.0015e-02, 1.0858e-01, 6.4057e-04, 2.0769e-02, 1.1705e-01, 8.4180e-02,
        5.6179e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,813][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1127, 0.1151, 0.1334, 0.0381, 0.0549, 0.0230, 0.0197, 0.0055, 0.0266,
        0.0164, 0.0104, 0.0421, 0.0443, 0.0562, 0.0940, 0.0298, 0.0562, 0.0911,
        0.0306], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,816][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.6130, 0.1180, 0.0094, 0.0351, 0.0036, 0.0100, 0.0025, 0.0018, 0.0042,
        0.0021, 0.0049, 0.0157, 0.0435, 0.0071, 0.0125, 0.0334, 0.0246, 0.0488,
        0.0097], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,818][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0008, 0.1153, 0.1952, 0.0481, 0.0677, 0.0879, 0.0514, 0.0110, 0.0197,
        0.0255, 0.0160, 0.0387, 0.0295, 0.0194, 0.0262, 0.0467, 0.0622, 0.0879,
        0.0508], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,819][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0487, 0.0080, 0.0009, 0.0076, 0.0007, 0.0082, 0.0037, 0.0009, 0.0066,
        0.0032, 0.0045, 0.0333, 0.1272, 0.1142, 0.0121, 0.0567, 0.1570, 0.2514,
        0.1549], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,820][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2710, 0.3098, 0.0669, 0.0515, 0.0187, 0.0338, 0.0061, 0.0070, 0.0079,
        0.0058, 0.0052, 0.0191, 0.0273, 0.0180, 0.0184, 0.0340, 0.0486, 0.0333,
        0.0174], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,821][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0824, 0.0234, 0.0420, 0.0039, 0.0389, 0.0256, 0.0399, 0.0153, 0.1045,
        0.0547, 0.0496, 0.0626, 0.0530, 0.0347, 0.0401, 0.0262, 0.0603, 0.0845,
        0.1583], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,823][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.9284e-01, 6.5677e-04, 9.3821e-06, 4.1370e-03, 1.7331e-05, 5.5176e-04,
        4.3747e-04, 3.9693e-03, 2.1691e-03, 7.6984e-04, 3.0891e-03, 3.0958e-02,
        7.3250e-02, 1.1683e-01, 1.3969e-03, 1.2397e-01, 2.0804e-01, 1.4232e-01,
        9.4594e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,827][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0035, 0.2109, 0.1489, 0.0539, 0.0356, 0.1166, 0.0558, 0.0111, 0.0342,
        0.0317, 0.0346, 0.0290, 0.0595, 0.0209, 0.0165, 0.0375, 0.0346, 0.0509,
        0.0143], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:17:59,936][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:59,938][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,938][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,939][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,940][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,940][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,942][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,945][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,946][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,947][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,947][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,948][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,949][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:59,949][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.6728, 0.3272], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,950][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1678, 0.8322], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,951][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.3864, 0.6136], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,951][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9465, 0.0535], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,952][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4750, 0.5250], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,953][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6610, 0.3390], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,953][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0020, 0.9980], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,954][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.8454, 0.1546], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,957][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.5406, 0.4594], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,958][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([8.8054e-04, 9.9912e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,959][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7144, 0.2856], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,959][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0827, 0.9173], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:59,960][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Jamie] are: tensor([0.8780, 0.0567, 0.0653], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,961][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Jamie] are: tensor([0.1509, 0.1293, 0.7198], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,963][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Jamie] are: tensor([0.6210, 0.0932, 0.2859], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,968][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Jamie] are: tensor([0.9913, 0.0052, 0.0035], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,969][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Jamie] are: tensor([0.8397, 0.0558, 0.1045], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,969][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Jamie] are: tensor([0.7984, 0.1522, 0.0494], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,970][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Jamie] are: tensor([0.0034, 0.1932, 0.8034], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,971][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Jamie] are: tensor([0.8496, 0.0504, 0.1001], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,971][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Jamie] are: tensor([0.5906, 0.0768, 0.3326], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,974][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Jamie] are: tensor([0.0016, 0.1200, 0.8784], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,978][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Jamie] are: tensor([0.9158, 0.0367, 0.0476], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,979][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Jamie] are: tensor([0.1383, 0.3782, 0.4835], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:17:59,980][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.7771, 0.1204, 0.0736, 0.0289], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,981][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1032, 0.2581, 0.4936, 0.1450], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,981][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3134, 0.2690, 0.2710, 0.1466], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,982][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.9538, 0.0281, 0.0078, 0.0104], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,985][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.4807, 0.1386, 0.2310, 0.1497], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,989][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.7381, 0.1567, 0.0430, 0.0622], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,990][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0028, 0.2033, 0.5455, 0.2484], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,991][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.6999, 0.0919, 0.1335, 0.0747], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,991][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2493, 0.1913, 0.4314, 0.1281], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,992][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([7.1856e-04, 1.0763e-01, 7.7806e-01, 1.1360e-01], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,993][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6850, 0.1078, 0.0403, 0.1669], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:17:59,995][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0639, 0.3482, 0.4455, 0.1425], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:00,000][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.8119, 0.0651, 0.0520, 0.0320, 0.0391], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,001][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0441, 0.1293, 0.5377, 0.0982, 0.1908], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,002][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.4136, 0.1196, 0.1959, 0.1049, 0.1660], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,002][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.9743, 0.0078, 0.0027, 0.0116, 0.0037], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,003][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.4988, 0.1228, 0.1833, 0.0745, 0.1207], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,005][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.6873, 0.1891, 0.0359, 0.0682, 0.0196], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,009][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0024, 0.1258, 0.4317, 0.1116, 0.3285], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,011][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.6071, 0.0557, 0.0833, 0.0949, 0.1590], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,012][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.2257, 0.0750, 0.2785, 0.1991, 0.2217], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,012][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.0008, 0.0992, 0.4331, 0.0668, 0.4001], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,013][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.8133, 0.0212, 0.0115, 0.1302, 0.0238], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,014][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0380, 0.2502, 0.3184, 0.1718, 0.2215], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,017][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.8761, 0.0838, 0.0177, 0.0121, 0.0087, 0.0016], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,021][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.2292, 0.2042, 0.3419, 0.0911, 0.0957, 0.0379], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,022][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.5012, 0.1903, 0.1824, 0.0494, 0.0623, 0.0143], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,023][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.9732, 0.0176, 0.0023, 0.0050, 0.0010, 0.0010], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,023][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.8021, 0.0839, 0.0497, 0.0237, 0.0328, 0.0079], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,024][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.9140, 0.0517, 0.0104, 0.0144, 0.0041, 0.0055], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,025][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0037, 0.1441, 0.4315, 0.0817, 0.1840, 0.1550], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,028][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.7249, 0.0590, 0.0523, 0.0525, 0.0411, 0.0701], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,032][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.3321, 0.1543, 0.2350, 0.0817, 0.1018, 0.0952], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,033][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0012, 0.0866, 0.4718, 0.0521, 0.2161, 0.1722], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,034][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.8771, 0.0404, 0.0063, 0.0564, 0.0066, 0.0132], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,034][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0415, 0.2133, 0.2336, 0.1135, 0.1710, 0.2270], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,035][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.8203, 0.0990, 0.0346, 0.0238, 0.0114, 0.0045, 0.0062],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,038][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0995, 0.2372, 0.3346, 0.0991, 0.0970, 0.0781, 0.0546],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,042][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2687, 0.2715, 0.1817, 0.1174, 0.0834, 0.0531, 0.0243],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,043][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([9.9507e-01, 5.5513e-04, 1.1792e-05, 1.2466e-03, 3.4173e-05, 4.2850e-04,
        2.6549e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,044][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.3135, 0.1784, 0.2060, 0.0870, 0.1187, 0.0427, 0.0536],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,045][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.7950, 0.1317, 0.0123, 0.0390, 0.0053, 0.0120, 0.0047],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,045][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0010, 0.1421, 0.3825, 0.0892, 0.1337, 0.1546, 0.0969],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,046][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.5645, 0.0484, 0.0229, 0.0597, 0.0284, 0.1269, 0.1492],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,049][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2678, 0.1956, 0.2500, 0.0916, 0.0604, 0.1138, 0.0209],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,053][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0006, 0.0994, 0.4415, 0.0424, 0.1382, 0.1057, 0.1721],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,054][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([9.5922e-01, 1.8340e-03, 6.6060e-05, 1.8679e-02, 2.3659e-04, 4.0162e-03,
        1.5950e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,055][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0300, 0.1817, 0.3015, 0.0831, 0.1110, 0.1848, 0.1079],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,056][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([9.5961e-01, 3.1251e-02, 3.9427e-03, 2.9706e-03, 1.6096e-03, 8.8094e-05,
        5.2149e-04, 3.6055e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,057][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.3808, 0.1994, 0.1822, 0.0976, 0.0724, 0.0212, 0.0431, 0.0033],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,058][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([5.6957e-01, 2.2261e-01, 1.6153e-01, 2.1362e-02, 1.8460e-02, 8.3654e-04,
        5.6090e-03, 1.7009e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,061][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([9.9757e-01, 1.8070e-03, 2.3816e-05, 4.7626e-04, 9.8318e-06, 1.8853e-05,
        9.4364e-05, 3.2028e-07], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,064][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([9.8446e-01, 1.1492e-02, 2.2320e-03, 9.7294e-04, 4.3307e-04, 2.5594e-05,
        3.7899e-04, 1.6868e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,064][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([9.6896e-01, 1.9173e-02, 2.9492e-03, 5.2158e-03, 1.3348e-03, 1.1883e-03,
        8.4277e-04, 3.3172e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,065][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0333, 0.2312, 0.4154, 0.0814, 0.1114, 0.0478, 0.0734, 0.0061],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,066][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.6124, 0.0465, 0.0152, 0.0912, 0.0201, 0.0700, 0.1112, 0.0334],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,067][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.2361, 0.1521, 0.1823, 0.1450, 0.1284, 0.0943, 0.0354, 0.0264],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,068][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0035, 0.2001, 0.4137, 0.0419, 0.1347, 0.0574, 0.1390, 0.0097],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,070][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([9.7917e-01, 7.4576e-03, 2.0744e-04, 8.4418e-03, 2.6059e-04, 9.5565e-04,
        3.3290e-03, 1.7768e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,074][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0293, 0.0753, 0.1230, 0.0833, 0.1010, 0.1748, 0.3709, 0.0424],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,075][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.7333, 0.1204, 0.0469, 0.0385, 0.0187, 0.0122, 0.0099, 0.0031, 0.0170],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,076][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0579, 0.1669, 0.4053, 0.0797, 0.0914, 0.0976, 0.0447, 0.0102, 0.0463],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,077][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.2138, 0.2805, 0.1086, 0.1429, 0.0790, 0.1104, 0.0274, 0.0112, 0.0261],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,077][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([9.3890e-01, 3.3536e-04, 1.3499e-05, 1.7122e-03, 6.4714e-05, 9.4971e-04,
        1.3405e-02, 2.6793e-03, 4.1945e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,079][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.1722, 0.1503, 0.2221, 0.0796, 0.1362, 0.0690, 0.0634, 0.0216, 0.0857],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,083][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.6329, 0.2117, 0.0204, 0.0619, 0.0124, 0.0241, 0.0102, 0.0041, 0.0223],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,085][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0007, 0.1132, 0.2669, 0.0753, 0.1615, 0.1951, 0.1124, 0.0289, 0.0461],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,086][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.2887, 0.0248, 0.0092, 0.0512, 0.0155, 0.0866, 0.1604, 0.0171, 0.3466],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,087][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.2438, 0.2822, 0.1917, 0.0725, 0.0456, 0.1018, 0.0203, 0.0222, 0.0200],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,088][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([2.8133e-04, 8.0662e-02, 2.9638e-01, 3.5343e-02, 1.4335e-01, 1.2680e-01,
        1.6780e-01, 1.5031e-02, 1.3436e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,088][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([7.5838e-01, 9.9038e-04, 4.0620e-05, 1.6374e-02, 2.0925e-04, 3.1014e-03,
        2.4439e-02, 3.4325e-02, 1.6214e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,092][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0203, 0.1717, 0.2155, 0.0846, 0.1149, 0.1807, 0.1007, 0.0235, 0.0880],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,094][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([8.7159e-01, 7.8635e-02, 1.5789e-02, 1.2774e-02, 6.6794e-03, 1.7464e-03,
        2.4662e-03, 2.5296e-04, 6.4389e-03, 3.6330e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,096][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0999, 0.1370, 0.2491, 0.0885, 0.0749, 0.0644, 0.0791, 0.0091, 0.1221,
        0.0758], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,097][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.4791, 0.2338, 0.1422, 0.0600, 0.0400, 0.0136, 0.0107, 0.0007, 0.0133,
        0.0066], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,098][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([9.8615e-01, 3.3519e-04, 4.8998e-06, 6.1522e-04, 1.0305e-05, 1.4347e-04,
        1.1828e-03, 5.6105e-05, 9.6891e-03, 1.8149e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,098][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.6992, 0.0957, 0.0828, 0.0266, 0.0258, 0.0072, 0.0115, 0.0007, 0.0374,
        0.0132], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,099][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.8793, 0.0707, 0.0074, 0.0207, 0.0037, 0.0062, 0.0025, 0.0014, 0.0056,
        0.0027], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,103][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0026, 0.1257, 0.3620, 0.0709, 0.1140, 0.0977, 0.0885, 0.0085, 0.0753,
        0.0549], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,107][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.4581, 0.0228, 0.0067, 0.0383, 0.0095, 0.0582, 0.0964, 0.0125, 0.2139,
        0.0835], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,107][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.3573, 0.1922, 0.1361, 0.0937, 0.0567, 0.0738, 0.0191, 0.0132, 0.0327,
        0.0253], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,108][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0005, 0.0534, 0.2340, 0.0319, 0.1007, 0.1076, 0.1433, 0.0146, 0.1842,
        0.1297], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,109][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([8.7833e-01, 1.8195e-03, 4.7961e-05, 1.1156e-02, 1.2130e-04, 2.3368e-03,
        1.1695e-02, 6.8787e-03, 7.0574e-02, 1.7040e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,110][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0175, 0.0486, 0.1236, 0.0593, 0.0770, 0.1841, 0.1623, 0.0457, 0.1027,
        0.1792], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,111][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([8.1571e-01, 1.2735e-01, 1.7277e-02, 1.8411e-02, 6.1295e-03, 2.0700e-03,
        2.2926e-03, 2.3550e-04, 5.5263e-03, 2.5731e-03, 2.4250e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,115][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.1334, 0.2282, 0.2509, 0.1030, 0.0655, 0.0406, 0.0422, 0.0051, 0.0803,
        0.0308, 0.0199], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,117][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.3752, 0.3827, 0.0989, 0.0715, 0.0291, 0.0138, 0.0095, 0.0008, 0.0097,
        0.0046, 0.0042], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,118][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([9.9105e-01, 3.9752e-04, 5.5368e-06, 5.1170e-04, 8.1901e-06, 8.1387e-05,
        6.1323e-04, 2.7156e-05, 4.8736e-03, 1.0414e-03, 1.3948e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,119][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.6889, 0.1344, 0.0613, 0.0267, 0.0269, 0.0054, 0.0103, 0.0008, 0.0317,
        0.0091, 0.0046], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,120][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.8717, 0.0774, 0.0082, 0.0202, 0.0032, 0.0058, 0.0021, 0.0011, 0.0040,
        0.0019, 0.0044], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,121][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0024, 0.1446, 0.3637, 0.0721, 0.1248, 0.0800, 0.0763, 0.0062, 0.0641,
        0.0409, 0.0248], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,124][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.4701, 0.0293, 0.0072, 0.0484, 0.0099, 0.0569, 0.0665, 0.0170, 0.1439,
        0.0629, 0.0879], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,128][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.3160, 0.2293, 0.1561, 0.0916, 0.0578, 0.0682, 0.0136, 0.0151, 0.0169,
        0.0201, 0.0153], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,129][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0006, 0.0807, 0.2961, 0.0326, 0.1067, 0.0595, 0.1108, 0.0060, 0.1672,
        0.0895, 0.0502], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,130][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([8.9292e-01, 2.2990e-03, 4.3231e-05, 1.2417e-02, 1.0346e-04, 1.8629e-03,
        6.7992e-03, 5.0386e-03, 4.3200e-02, 1.0150e-02, 2.5163e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,130][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0240, 0.0875, 0.1659, 0.0568, 0.0815, 0.1436, 0.1258, 0.0311, 0.0932,
        0.1040, 0.0866], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,131][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.6434, 0.1963, 0.0476, 0.0355, 0.0184, 0.0094, 0.0056, 0.0018, 0.0084,
        0.0092, 0.0058, 0.0185], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,135][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0499, 0.1678, 0.3385, 0.0818, 0.0854, 0.0676, 0.0389, 0.0073, 0.0450,
        0.0366, 0.0206, 0.0607], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,139][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2042, 0.3866, 0.1174, 0.0994, 0.0554, 0.0484, 0.0157, 0.0042, 0.0127,
        0.0129, 0.0110, 0.0320], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,140][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([9.7012e-01, 8.7747e-04, 1.5716e-05, 1.0901e-03, 2.0537e-05, 2.9786e-04,
        6.0805e-04, 3.2702e-04, 2.2327e-03, 1.0172e-03, 1.9621e-03, 2.1433e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,140][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1868, 0.1628, 0.1847, 0.0584, 0.0946, 0.0417, 0.0442, 0.0102, 0.0641,
        0.0412, 0.0252, 0.0862], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,141][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.7105, 0.1441, 0.0165, 0.0478, 0.0085, 0.0150, 0.0045, 0.0018, 0.0095,
        0.0042, 0.0080, 0.0296], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,142][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0005, 0.1152, 0.3445, 0.0569, 0.1375, 0.1013, 0.0729, 0.0120, 0.0340,
        0.0487, 0.0270, 0.0495], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,146][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.2984, 0.0452, 0.0127, 0.0532, 0.0133, 0.0712, 0.0466, 0.0129, 0.0905,
        0.0499, 0.0565, 0.2496], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,149][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.2181, 0.3104, 0.1814, 0.0760, 0.0414, 0.0729, 0.0122, 0.0130, 0.0143,
        0.0141, 0.0132, 0.0329], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,150][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([2.4478e-04, 5.6300e-02, 2.7446e-01, 2.5079e-02, 1.1350e-01, 7.4765e-02,
        1.0595e-01, 7.5954e-03, 1.0586e-01, 7.1604e-02, 4.3143e-02, 1.2150e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,151][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([7.8739e-01, 2.9488e-03, 8.8758e-05, 1.4865e-02, 1.5976e-04, 2.5538e-03,
        3.5863e-03, 1.2456e-02, 1.6174e-02, 5.2709e-03, 1.6090e-02, 1.3842e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,152][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0141, 0.0906, 0.1509, 0.0630, 0.0706, 0.1290, 0.1090, 0.0264, 0.0861,
        0.0891, 0.0749, 0.0963], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,153][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.4848, 0.2205, 0.0299, 0.0310, 0.0162, 0.0106, 0.0074, 0.0030, 0.0117,
        0.0175, 0.0094, 0.0308, 0.1273], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,156][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0368, 0.1072, 0.2376, 0.0746, 0.0669, 0.0759, 0.0545, 0.0119, 0.0581,
        0.0473, 0.0368, 0.0797, 0.1126], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,160][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.1748, 0.2367, 0.0914, 0.0887, 0.0593, 0.0910, 0.0266, 0.0170, 0.0196,
        0.0295, 0.0283, 0.0641, 0.0730], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,161][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([8.6282e-01, 4.2838e-04, 7.3437e-06, 9.6366e-04, 1.1191e-05, 2.8893e-04,
        6.4337e-04, 5.1407e-04, 1.8562e-03, 7.9184e-04, 1.8091e-03, 2.8156e-02,
        1.0171e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,162][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0706, 0.1558, 0.1818, 0.0832, 0.1022, 0.0627, 0.0402, 0.0216, 0.0554,
        0.0390, 0.0260, 0.0617, 0.0999], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,163][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.4299, 0.2229, 0.0232, 0.0725, 0.0103, 0.0283, 0.0080, 0.0080, 0.0138,
        0.0092, 0.0172, 0.0399, 0.1167], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,163][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.0006, 0.0897, 0.2003, 0.0671, 0.0946, 0.1316, 0.1064, 0.0120, 0.0656,
        0.0537, 0.0383, 0.0777, 0.0624], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,168][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.1568, 0.0312, 0.0041, 0.0297, 0.0051, 0.0339, 0.0227, 0.0082, 0.0399,
        0.0247, 0.0305, 0.1307, 0.4825], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,173][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.3279, 0.1938, 0.0935, 0.0771, 0.0277, 0.0811, 0.0134, 0.0293, 0.0173,
        0.0187, 0.0222, 0.0447, 0.0532], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,174][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.0002, 0.0308, 0.1402, 0.0248, 0.0918, 0.1281, 0.1194, 0.0228, 0.1050,
        0.0965, 0.0710, 0.1125, 0.0569], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,175][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([4.3963e-01, 1.8856e-03, 5.3349e-05, 1.0589e-02, 9.3970e-05, 2.1336e-03,
        2.8955e-03, 8.5323e-03, 1.1688e-02, 4.6284e-03, 1.3634e-02, 1.3950e-01,
        3.6473e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,176][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.0114, 0.0720, 0.1407, 0.0665, 0.0664, 0.1688, 0.0895, 0.0224, 0.0547,
        0.0790, 0.0694, 0.0934, 0.0657], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,177][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.4450, 0.2615, 0.0813, 0.0476, 0.0171, 0.0132, 0.0058, 0.0039, 0.0065,
        0.0095, 0.0054, 0.0214, 0.0536, 0.0284], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,180][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0374, 0.1950, 0.2997, 0.0670, 0.0721, 0.0809, 0.0295, 0.0070, 0.0215,
        0.0255, 0.0146, 0.0326, 0.0846, 0.0326], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,184][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.2022, 0.3792, 0.0945, 0.1062, 0.0395, 0.0619, 0.0099, 0.0072, 0.0073,
        0.0101, 0.0094, 0.0261, 0.0270, 0.0196], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,185][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([8.6413e-01, 1.0676e-03, 1.0860e-05, 1.4515e-03, 1.4341e-05, 2.6616e-04,
        1.6982e-04, 1.9371e-04, 5.9416e-04, 2.4136e-04, 5.1023e-04, 8.4419e-03,
        3.4420e-02, 8.8487e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,186][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0785, 0.1857, 0.2228, 0.0582, 0.1017, 0.0384, 0.0314, 0.0117, 0.0351,
        0.0251, 0.0157, 0.0515, 0.0564, 0.0878], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,187][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.5349, 0.2349, 0.0153, 0.0617, 0.0081, 0.0145, 0.0039, 0.0024, 0.0076,
        0.0037, 0.0071, 0.0238, 0.0700, 0.0120], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,187][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0005, 0.1511, 0.3227, 0.0629, 0.1211, 0.1160, 0.0479, 0.0178, 0.0188,
        0.0321, 0.0201, 0.0358, 0.0332, 0.0199], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,191][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.1557, 0.0285, 0.0057, 0.0244, 0.0045, 0.0265, 0.0122, 0.0041, 0.0212,
        0.0124, 0.0159, 0.0832, 0.3523, 0.2534], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,195][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.2142, 0.3815, 0.1607, 0.0604, 0.0292, 0.0508, 0.0077, 0.0079, 0.0075,
        0.0066, 0.0068, 0.0202, 0.0263, 0.0203], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,196][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([2.0409e-04, 7.6545e-02, 3.1980e-01, 3.0550e-02, 1.0573e-01, 9.7128e-02,
        7.9918e-02, 9.8522e-03, 5.6723e-02, 4.5729e-02, 2.9490e-02, 7.6989e-02,
        4.3173e-02, 2.8173e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,196][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([6.0606e-01, 3.5617e-03, 7.7920e-05, 2.0396e-02, 1.2380e-04, 2.6027e-03,
        9.5879e-04, 1.0989e-02, 4.2991e-03, 1.6630e-03, 4.9880e-03, 4.5890e-02,
        1.0430e-01, 1.9409e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,197][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0131, 0.1564, 0.1918, 0.0592, 0.0803, 0.1003, 0.0579, 0.0168, 0.0429,
        0.0520, 0.0473, 0.0657, 0.0675, 0.0488], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,198][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.3696, 0.1325, 0.0582, 0.0431, 0.0323, 0.0204, 0.0156, 0.0073, 0.0179,
        0.0248, 0.0192, 0.0452, 0.1019, 0.0533, 0.0588], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,202][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0102, 0.0930, 0.2181, 0.0563, 0.0716, 0.0820, 0.0470, 0.0111, 0.0421,
        0.0436, 0.0333, 0.0638, 0.1006, 0.0613, 0.0662], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,205][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.1178, 0.1552, 0.1026, 0.0840, 0.0683, 0.1092, 0.0254, 0.0283, 0.0181,
        0.0392, 0.0382, 0.0501, 0.0500, 0.0350, 0.0785], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,206][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([6.3013e-02, 1.2268e-04, 8.6653e-06, 3.1486e-04, 1.4505e-05, 2.3952e-04,
        2.6958e-03, 5.4964e-04, 1.0863e-02, 4.3959e-03, 9.9339e-03, 6.7529e-02,
        3.1943e-01, 5.1517e-01, 5.7158e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,207][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0501, 0.1034, 0.1525, 0.0573, 0.0829, 0.0490, 0.0329, 0.0299, 0.0460,
        0.0460, 0.0251, 0.0563, 0.0699, 0.0809, 0.1179], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,208][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.3443, 0.1787, 0.0212, 0.0650, 0.0130, 0.0299, 0.0119, 0.0083, 0.0221,
        0.0113, 0.0250, 0.0481, 0.1514, 0.0238, 0.0459], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,209][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0004, 0.0850, 0.2204, 0.0546, 0.1226, 0.1144, 0.0642, 0.0217, 0.0414,
        0.0534, 0.0354, 0.0470, 0.0500, 0.0343, 0.0552], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,212][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0270, 0.0034, 0.0016, 0.0067, 0.0030, 0.0148, 0.0251, 0.0061, 0.0488,
        0.0284, 0.0348, 0.0960, 0.3333, 0.3102, 0.0608], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,216][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.0864, 0.1018, 0.1432, 0.0707, 0.0611, 0.0914, 0.0241, 0.0230, 0.0269,
        0.0353, 0.0304, 0.0582, 0.1066, 0.0564, 0.0845], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,217][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([1.0767e-04, 3.8987e-02, 1.6294e-01, 2.3386e-02, 1.0123e-01, 8.2582e-02,
        8.8077e-02, 9.4646e-03, 1.1298e-01, 6.9884e-02, 5.2804e-02, 9.2966e-02,
        5.7324e-02, 4.2689e-02, 6.4588e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,218][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([1.3202e-02, 1.4203e-04, 2.1204e-05, 1.2220e-03, 4.7645e-05, 5.7611e-04,
        4.9305e-03, 3.9357e-03, 1.9079e-02, 7.6418e-03, 1.8511e-02, 1.2302e-01,
        3.7948e-01, 4.2149e-01, 6.7010e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,219][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0068, 0.1103, 0.1144, 0.0644, 0.0688, 0.0898, 0.0782, 0.0164, 0.0759,
        0.0608, 0.0537, 0.0784, 0.0571, 0.0695, 0.0556], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,220][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([8.1023e-01, 1.1043e-01, 9.7225e-03, 9.7869e-03, 3.7969e-03, 8.0449e-04,
        1.0416e-03, 6.7601e-05, 3.3192e-03, 1.0490e-03, 8.9130e-04, 5.2479e-03,
        1.6763e-02, 1.4709e-02, 1.0361e-02, 1.7794e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,223][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0590, 0.1299, 0.2401, 0.0678, 0.0424, 0.0220, 0.0282, 0.0022, 0.0529,
        0.0220, 0.0128, 0.0559, 0.1109, 0.0777, 0.0566, 0.0195],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,227][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([4.4553e-01, 3.1345e-01, 1.1048e-01, 3.0695e-02, 1.8809e-02, 4.0777e-03,
        4.2293e-03, 1.4963e-04, 6.2724e-03, 1.5752e-03, 1.5335e-03, 1.0587e-02,
        1.1864e-02, 1.3577e-02, 2.5312e-02, 1.8566e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,228][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([9.7670e-01, 8.2058e-04, 4.5330e-06, 2.4528e-04, 2.2589e-06, 1.6726e-05,
        1.8679e-05, 2.3934e-06, 1.4392e-04, 2.5214e-05, 3.7519e-05, 1.0577e-03,
        9.5789e-03, 1.0359e-02, 2.1900e-04, 7.6874e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,228][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([6.3005e-01, 8.9391e-02, 3.4963e-02, 1.2866e-02, 7.7549e-03, 1.9207e-03,
        5.9085e-03, 2.2433e-04, 2.8840e-02, 4.2461e-03, 2.2596e-03, 2.2615e-02,
        4.3240e-02, 5.9076e-02, 5.2997e-02, 3.6523e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,229][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([8.5697e-01, 4.7676e-02, 6.2653e-03, 1.3111e-02, 2.2508e-03, 2.7871e-03,
        1.2884e-03, 2.6996e-04, 2.9236e-03, 8.8363e-04, 1.6780e-03, 8.2816e-03,
        2.9599e-02, 5.0841e-03, 1.1213e-02, 9.7240e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,230][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0025, 0.1366, 0.2858, 0.0533, 0.0812, 0.0526, 0.0476, 0.0056, 0.0508,
        0.0314, 0.0187, 0.0446, 0.0707, 0.0478, 0.0470, 0.0238],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,234][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.1772, 0.0205, 0.0038, 0.0229, 0.0034, 0.0197, 0.0109, 0.0043, 0.0263,
        0.0123, 0.0146, 0.0748, 0.2315, 0.2070, 0.0522, 0.1187],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,237][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.3017, 0.2025, 0.1056, 0.0585, 0.0370, 0.0433, 0.0086, 0.0098, 0.0138,
        0.0130, 0.0091, 0.0256, 0.0552, 0.0356, 0.0453, 0.0353],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,238][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0004, 0.0658, 0.2334, 0.0210, 0.0695, 0.0410, 0.0691, 0.0045, 0.1056,
        0.0636, 0.0384, 0.1013, 0.0814, 0.0397, 0.0563, 0.0090],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,239][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([7.3258e-01, 5.0912e-03, 9.5937e-05, 7.9847e-03, 9.1761e-05, 9.2357e-04,
        7.0028e-04, 9.3017e-04, 3.8709e-03, 7.5009e-04, 1.8621e-03, 2.7725e-02,
        7.5733e-02, 9.1877e-02, 3.0367e-03, 4.6749e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,240][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0141, 0.0859, 0.0965, 0.0489, 0.0525, 0.0815, 0.0836, 0.0175, 0.0713,
        0.0658, 0.0594, 0.0942, 0.0554, 0.0820, 0.0512, 0.0401],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,242][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.6393, 0.1955, 0.0277, 0.0215, 0.0071, 0.0042, 0.0020, 0.0007, 0.0033,
        0.0033, 0.0022, 0.0099, 0.0298, 0.0125, 0.0112, 0.0096, 0.0201],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,246][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0533, 0.1546, 0.1917, 0.0592, 0.0531, 0.0435, 0.0284, 0.0059, 0.0318,
        0.0233, 0.0129, 0.0405, 0.1037, 0.0424, 0.0556, 0.0322, 0.0678],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,248][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2549, 0.3845, 0.1055, 0.0723, 0.0358, 0.0271, 0.0070, 0.0022, 0.0048,
        0.0050, 0.0049, 0.0138, 0.0135, 0.0119, 0.0228, 0.0110, 0.0230],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,249][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([9.3484e-01, 1.1260e-03, 6.9772e-06, 6.3010e-04, 5.7113e-06, 9.3920e-05,
        4.1690e-05, 4.6271e-05, 1.7789e-04, 6.2839e-05, 1.4921e-04, 2.2463e-03,
        1.0609e-02, 2.6503e-02, 3.9149e-04, 6.2784e-03, 1.6794e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,250][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1885, 0.1311, 0.0926, 0.0374, 0.0377, 0.0146, 0.0235, 0.0027, 0.0462,
        0.0150, 0.0089, 0.0583, 0.0609, 0.0894, 0.0862, 0.0245, 0.0826],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,251][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.6888, 0.1314, 0.0113, 0.0318, 0.0038, 0.0083, 0.0020, 0.0010, 0.0041,
        0.0016, 0.0036, 0.0136, 0.0363, 0.0059, 0.0121, 0.0243, 0.0201],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,254][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0008, 0.1376, 0.2449, 0.0551, 0.0754, 0.0835, 0.0465, 0.0135, 0.0259,
        0.0356, 0.0191, 0.0425, 0.0467, 0.0269, 0.0300, 0.0461, 0.0701],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,259][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1621, 0.0285, 0.0045, 0.0210, 0.0032, 0.0214, 0.0067, 0.0029, 0.0126,
        0.0069, 0.0085, 0.0473, 0.1751, 0.1678, 0.0365, 0.0943, 0.2007],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,260][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2415, 0.2722, 0.1322, 0.0760, 0.0321, 0.0521, 0.0076, 0.0092, 0.0084,
        0.0080, 0.0076, 0.0213, 0.0260, 0.0210, 0.0238, 0.0276, 0.0336],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,261][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0006, 0.0675, 0.2253, 0.0284, 0.0627, 0.0600, 0.0614, 0.0068, 0.0747,
        0.0481, 0.0322, 0.0882, 0.0661, 0.0394, 0.0417, 0.0120, 0.0850],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,261][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([5.6786e-01, 3.1587e-03, 5.3540e-05, 1.0846e-02, 6.1932e-05, 1.1770e-03,
        4.8749e-04, 3.7387e-03, 2.0804e-03, 6.4465e-04, 2.2344e-03, 2.2549e-02,
        6.1157e-02, 8.1305e-02, 1.8167e-03, 1.0496e-01, 1.3587e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,262][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0157, 0.0821, 0.1297, 0.0507, 0.0548, 0.1089, 0.0593, 0.0311, 0.0453,
        0.0706, 0.0483, 0.0600, 0.0539, 0.0391, 0.0451, 0.0457, 0.0597],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,266][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.6252, 0.1222, 0.0228, 0.0241, 0.0094, 0.0044, 0.0027, 0.0008, 0.0064,
        0.0045, 0.0036, 0.0124, 0.0382, 0.0208, 0.0171, 0.0088, 0.0174, 0.0592],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,270][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.0626, 0.1055, 0.1278, 0.0506, 0.0464, 0.0329, 0.0245, 0.0052, 0.0300,
        0.0258, 0.0129, 0.0401, 0.0946, 0.0461, 0.0614, 0.0334, 0.0520, 0.1481],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,271][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.3210, 0.3378, 0.0587, 0.0536, 0.0260, 0.0236, 0.0062, 0.0033, 0.0070,
        0.0050, 0.0062, 0.0177, 0.0206, 0.0125, 0.0266, 0.0151, 0.0256, 0.0335],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,272][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([6.8837e-01, 7.8390e-04, 6.7195e-06, 7.8087e-04, 6.3271e-06, 1.2786e-04,
        1.7663e-04, 7.2478e-05, 6.7280e-04, 1.6759e-04, 4.4022e-04, 7.9130e-03,
        3.7486e-02, 9.4315e-02, 8.7437e-04, 1.4554e-02, 9.0858e-02, 6.2391e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,272][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.0916, 0.1591, 0.1202, 0.0553, 0.0635, 0.0370, 0.0229, 0.0074, 0.0335,
        0.0187, 0.0120, 0.0368, 0.0339, 0.0396, 0.0935, 0.0284, 0.0383, 0.1084],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,275][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.5425, 0.1687, 0.0154, 0.0416, 0.0049, 0.0113, 0.0031, 0.0025, 0.0057,
        0.0027, 0.0054, 0.0144, 0.0451, 0.0068, 0.0150, 0.0364, 0.0220, 0.0566],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,280][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.0007, 0.1055, 0.1519, 0.0513, 0.0670, 0.0698, 0.0621, 0.0054, 0.0504,
        0.0394, 0.0198, 0.0524, 0.0509, 0.0351, 0.0471, 0.0458, 0.0747, 0.0705],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,281][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0890, 0.0121, 0.0018, 0.0123, 0.0018, 0.0139, 0.0075, 0.0023, 0.0120,
        0.0070, 0.0084, 0.0510, 0.1413, 0.1630, 0.0287, 0.0822, 0.1754, 0.1903],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,282][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.2168, 0.1527, 0.1147, 0.0708, 0.0284, 0.0554, 0.0113, 0.0136, 0.0135,
        0.0118, 0.0122, 0.0317, 0.0442, 0.0287, 0.0339, 0.0519, 0.0502, 0.0580],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,283][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.0004, 0.0448, 0.1058, 0.0220, 0.0669, 0.0692, 0.0680, 0.0087, 0.1002,
        0.0680, 0.0454, 0.0838, 0.0507, 0.0335, 0.0567, 0.0181, 0.0755, 0.0822],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,284][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([3.0012e-01, 1.1731e-03, 1.9013e-05, 4.3546e-03, 2.3927e-05, 5.8930e-04,
        5.0372e-04, 2.7774e-03, 2.4200e-03, 7.9246e-04, 2.3731e-03, 2.8250e-02,
        9.4590e-02, 1.0997e-01, 1.5344e-03, 1.1906e-01, 2.0414e-01, 1.2730e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,288][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0161, 0.1171, 0.1314, 0.0590, 0.0525, 0.1068, 0.0560, 0.0139, 0.0413,
        0.0390, 0.0315, 0.0531, 0.0403, 0.0396, 0.0501, 0.0508, 0.0470, 0.0543],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,291][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4888, 0.1902, 0.0246, 0.0273, 0.0075, 0.0081, 0.0035, 0.0014, 0.0048,
        0.0064, 0.0037, 0.0163, 0.0512, 0.0177, 0.0132, 0.0238, 0.0317, 0.0616,
        0.0181], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,292][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0395, 0.1696, 0.1814, 0.0539, 0.0418, 0.0499, 0.0208, 0.0048, 0.0178,
        0.0154, 0.0111, 0.0252, 0.0589, 0.0263, 0.0325, 0.0241, 0.0465, 0.1520,
        0.0285], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,293][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2180, 0.3348, 0.0567, 0.0763, 0.0272, 0.0518, 0.0069, 0.0058, 0.0052,
        0.0071, 0.0072, 0.0204, 0.0195, 0.0140, 0.0256, 0.0332, 0.0385, 0.0386,
        0.0131], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,294][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([5.6130e-01, 3.2811e-04, 2.8224e-06, 4.4913e-04, 3.3155e-06, 1.0395e-04,
        1.2870e-04, 8.2962e-05, 4.5638e-04, 1.7070e-04, 4.2590e-04, 9.1369e-03,
        4.0015e-02, 1.0858e-01, 6.4057e-04, 2.0769e-02, 1.1705e-01, 8.4180e-02,
        5.6179e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,296][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1127, 0.1151, 0.1334, 0.0381, 0.0549, 0.0230, 0.0197, 0.0055, 0.0266,
        0.0164, 0.0104, 0.0421, 0.0443, 0.0562, 0.0940, 0.0298, 0.0562, 0.0911,
        0.0306], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,301][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.6130, 0.1180, 0.0094, 0.0351, 0.0036, 0.0100, 0.0025, 0.0018, 0.0042,
        0.0021, 0.0049, 0.0157, 0.0435, 0.0071, 0.0125, 0.0334, 0.0246, 0.0488,
        0.0097], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,302][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0008, 0.1153, 0.1952, 0.0481, 0.0677, 0.0879, 0.0514, 0.0110, 0.0197,
        0.0255, 0.0160, 0.0387, 0.0295, 0.0194, 0.0262, 0.0467, 0.0622, 0.0879,
        0.0508], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,303][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0487, 0.0080, 0.0009, 0.0076, 0.0007, 0.0082, 0.0037, 0.0009, 0.0066,
        0.0032, 0.0045, 0.0333, 0.1272, 0.1142, 0.0121, 0.0567, 0.1570, 0.2514,
        0.1549], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,304][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2710, 0.3098, 0.0669, 0.0515, 0.0187, 0.0338, 0.0061, 0.0070, 0.0079,
        0.0058, 0.0052, 0.0191, 0.0273, 0.0180, 0.0184, 0.0340, 0.0486, 0.0333,
        0.0174], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,305][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0005, 0.0469, 0.1745, 0.0232, 0.0783, 0.0746, 0.0645, 0.0097, 0.0495,
        0.0412, 0.0265, 0.0661, 0.0410, 0.0271, 0.0451, 0.0141, 0.0656, 0.0868,
        0.0647], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,307][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.9284e-01, 6.5677e-04, 9.3821e-06, 4.1370e-03, 1.7331e-05, 5.5176e-04,
        4.3747e-04, 3.9693e-03, 2.1691e-03, 7.6984e-04, 3.0891e-03, 3.0958e-02,
        7.3250e-02, 1.1683e-01, 1.3969e-03, 1.2397e-01, 2.0804e-01, 1.4232e-01,
        9.4594e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,312][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0100, 0.1529, 0.1501, 0.0504, 0.0629, 0.0902, 0.0468, 0.0090, 0.0358,
        0.0340, 0.0326, 0.0446, 0.0441, 0.0355, 0.0465, 0.0327, 0.0357, 0.0539,
        0.0324], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,316][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:00,318][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[1686],
        [  25],
        [ 100],
        [  30],
        [  55],
        [  41],
        [  69],
        [  42],
        [  53],
        [  27],
        [  53],
        [  75],
        [  31],
        [  22],
        [   4],
        [  13],
        [  14],
        [  29],
        [   9]], device='cuda:0')
[2024-07-24 10:18:00,322][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[1266],
        [  16],
        [  92],
        [  24],
        [  42],
        [  39],
        [  55],
        [  18],
        [  40],
        [  27],
        [  47],
        [  58],
        [  32],
        [  13],
        [   4],
        [  15],
        [  11],
        [  25],
        [   8]], device='cuda:0')
[2024-07-24 10:18:00,325][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 4296],
        [24443],
        [30951],
        [35968],
        [29156],
        [15284],
        [24059],
        [ 6490],
        [31058],
        [14838],
        [19531],
        [33233],
        [28018],
        [38192],
        [35103],
        [17590],
        [29549],
        [28323],
        [30511]], device='cuda:0')
[2024-07-24 10:18:00,326][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[19251],
        [29839],
        [12784],
        [20060],
        [17195],
        [20324],
        [21640],
        [24389],
        [19851],
        [23946],
        [24567],
        [21616],
        [22182],
        [21116],
        [22477],
        [22787],
        [22899],
        [19542],
        [19466]], device='cuda:0')
[2024-07-24 10:18:00,328][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 7213],
        [33444],
        [35882],
        [39052],
        [37653],
        [36696],
        [38148],
        [34747],
        [37501],
        [35413],
        [35795],
        [36458],
        [33639],
        [35927],
        [33471],
        [34395],
        [35671],
        [32719],
        [32689]], device='cuda:0')
[2024-07-24 10:18:00,330][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[34151],
        [33494],
        [33951],
        [33175],
        [33392],
        [33618],
        [33948],
        [34090],
        [31131],
        [33516],
        [33766],
        [32739],
        [29016],
        [29352],
        [11250],
        [33275],
        [31892],
        [23948],
        [19604]], device='cuda:0')
[2024-07-24 10:18:00,333][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 3726],
        [43504],
        [11628],
        [25065],
        [25545],
        [18285],
        [33544],
        [ 4698],
        [36526],
        [26125],
        [29613],
        [39921],
        [41369],
        [38007],
        [40017],
        [29334],
        [38888],
        [41810],
        [39713]], device='cuda:0')
[2024-07-24 10:18:00,337][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[46572],
        [22662],
        [29386],
        [23479],
        [20275],
        [42794],
        [31538],
        [45776],
        [20944],
        [40773],
        [40109],
        [28004],
        [21023],
        [21703],
        [20434],
        [42511],
        [30650],
        [25428],
        [30732]], device='cuda:0')
[2024-07-24 10:18:00,338][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[36640],
        [24363],
        [50188],
        [49771],
        [49882],
        [49846],
        [49485],
        [49684],
        [48166],
        [49155],
        [49163],
        [48979],
        [42770],
        [48725],
        [46130],
        [47696],
        [46117],
        [39143],
        [42540]], device='cuda:0')
[2024-07-24 10:18:00,340][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 3149],
        [18887],
        [ 8275],
        [18140],
        [27175],
        [18481],
        [27375],
        [25024],
        [27027],
        [30276],
        [31839],
        [38884],
        [46371],
        [46095],
        [46349],
        [45780],
        [46092],
        [45244],
        [45019]], device='cuda:0')
[2024-07-24 10:18:00,342][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[39814],
        [49452],
        [50255],
        [50255],
        [50253],
        [50251],
        [50251],
        [50240],
        [50240],
        [50234],
        [50238],
        [50236],
        [50196],
        [50230],
        [50205],
        [50214],
        [50227],
        [50206],
        [50135]], device='cuda:0')
[2024-07-24 10:18:00,345][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 954],
        [1119],
        [   1],
        [   1],
        [   2],
        [   4],
        [  17],
        [   7],
        [ 150],
        [ 214],
        [ 290],
        [ 312],
        [ 479],
        [ 224],
        [ 394],
        [ 347],
        [ 379],
        [ 298],
        [ 605]], device='cuda:0')
[2024-07-24 10:18:00,348][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[18348],
        [36974],
        [24773],
        [35502],
        [29500],
        [26573],
        [20245],
        [19660],
        [31063],
        [24625],
        [24565],
        [28399],
        [28666],
        [29990],
        [31566],
        [29099],
        [32899],
        [32707],
        [33190]], device='cuda:0')
[2024-07-24 10:18:00,350][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[10213],
        [12601],
        [28546],
        [26645],
        [24177],
        [17243],
        [16648],
        [ 5212],
        [ 7493],
        [ 3136],
        [ 5088],
        [ 3910],
        [ 2090],
        [ 5515],
        [ 2101],
        [ 2316],
        [ 3840],
        [ 3177],
        [ 3790]], device='cuda:0')
[2024-07-24 10:18:00,351][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[32297],
        [25978],
        [22837],
        [22045],
        [22299],
        [21863],
        [21729],
        [22111],
        [23160],
        [22079],
        [21568],
        [21293],
        [25241],
        [21636],
        [23914],
        [22461],
        [23107],
        [23074],
        [23457]], device='cuda:0')
[2024-07-24 10:18:00,354][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[18122],
        [19327],
        [23029],
        [24605],
        [28295],
        [20817],
        [23492],
        [19304],
        [27169],
        [20692],
        [21170],
        [26039],
        [29374],
        [30609],
        [37357],
        [22891],
        [25974],
        [28762],
        [28719]], device='cuda:0')
[2024-07-24 10:18:00,357][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 7219],
        [15228],
        [ 7620],
        [ 7479],
        [10424],
        [ 9787],
        [ 9184],
        [10642],
        [ 8370],
        [ 8338],
        [ 9378],
        [ 8095],
        [ 6582],
        [ 6951],
        [ 6789],
        [ 6194],
        [ 7018],
        [ 7376],
        [ 7640]], device='cuda:0')
[2024-07-24 10:18:00,360][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 8425],
        [13828],
        [16478],
        [21714],
        [22386],
        [20631],
        [24873],
        [16600],
        [27547],
        [20262],
        [19291],
        [23264],
        [26985],
        [23632],
        [28829],
        [17951],
        [21752],
        [21623],
        [24279]], device='cuda:0')
[2024-07-24 10:18:00,362][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 4614],
        [ 4745],
        [ 4587],
        [ 4641],
        [ 4677],
        [ 4662],
        [ 4681],
        [ 4615],
        [ 5694],
        [ 4803],
        [ 4726],
        [ 5009],
        [ 5840],
        [ 5810],
        [15266],
        [ 4701],
        [ 5114],
        [10007],
        [12403]], device='cuda:0')
[2024-07-24 10:18:00,363][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[1184],
        [2957],
        [3034],
        [5440],
        [5352],
        [2722],
        [5370],
        [1060],
        [6006],
        [3461],
        [2977],
        [5425],
        [5507],
        [5246],
        [5433],
        [2652],
        [4306],
        [5240],
        [5579]], device='cuda:0')
[2024-07-24 10:18:00,365][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 1843],
        [11988],
        [11702],
        [17856],
        [16452],
        [ 4842],
        [14591],
        [ 2469],
        [17268],
        [ 7651],
        [ 8320],
        [21643],
        [24738],
        [23852],
        [24158],
        [14417],
        [29699],
        [30044],
        [31643]], device='cuda:0')
[2024-07-24 10:18:00,369][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[25374],
        [14182],
        [19263],
        [25929],
        [21302],
        [22727],
        [23190],
        [23182],
        [21850],
        [21494],
        [21327],
        [19739],
        [19685],
        [21191],
        [18993],
        [21215],
        [19373],
        [18948],
        [18230]], device='cuda:0')
[2024-07-24 10:18:00,372][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[  458],
        [ 7966],
        [ 3389],
        [ 6876],
        [10472],
        [10559],
        [13066],
        [12487],
        [ 8567],
        [ 8919],
        [ 8379],
        [ 9566],
        [ 8507],
        [ 8512],
        [ 9284],
        [ 8737],
        [ 8860],
        [ 8675],
        [ 8153]], device='cuda:0')
[2024-07-24 10:18:00,373][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 8368],
        [34423],
        [28632],
        [37108],
        [38385],
        [40121],
        [41647],
        [42550],
        [42243],
        [41610],
        [41365],
        [41998],
        [41566],
        [40600],
        [40286],
        [39016],
        [40349],
        [38310],
        [38355]], device='cuda:0')
[2024-07-24 10:18:00,375][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[32814],
        [38578],
        [47044],
        [47219],
        [48913],
        [48373],
        [48246],
        [48390],
        [47708],
        [46069],
        [47538],
        [47533],
        [43589],
        [48076],
        [44748],
        [46816],
        [47327],
        [42709],
        [46111]], device='cuda:0')
[2024-07-24 10:18:00,377][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 6209],
        [23515],
        [ 6215],
        [14108],
        [ 7896],
        [ 7100],
        [ 5683],
        [ 6186],
        [11671],
        [ 6375],
        [ 7265],
        [10794],
        [21756],
        [14584],
        [23137],
        [12201],
        [20540],
        [25529],
        [28286]], device='cuda:0')
[2024-07-24 10:18:00,380][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 7865],
        [17217],
        [11166],
        [11994],
        [ 9302],
        [12671],
        [12452],
        [14482],
        [13764],
        [16045],
        [15720],
        [16061],
        [15981],
        [14116],
        [14581],
        [15669],
        [16093],
        [15537],
        [14425]], device='cuda:0')
[2024-07-24 10:18:00,384][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[49110],
        [39555],
        [43916],
        [31050],
        [30605],
        [36784],
        [30209],
        [34703],
        [25750],
        [36263],
        [35989],
        [25810],
        [22098],
        [23003],
        [17037],
        [34983],
        [24471],
        [21289],
        [18733]], device='cuda:0')
[2024-07-24 10:18:00,385][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[15909],
        [20878],
        [23090],
        [24639],
        [26371],
        [24500],
        [25876],
        [25984],
        [25472],
        [26280],
        [27281],
        [27550],
        [25187],
        [27447],
        [24992],
        [26728],
        [26226],
        [28263],
        [26055]], device='cuda:0')
[2024-07-24 10:18:00,387][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[3643],
        [3643],
        [3643],
        [3643],
        [3643],
        [3643],
        [3643],
        [3643],
        [3643],
        [3643],
        [3643],
        [3643],
        [3643],
        [3643],
        [3643],
        [3643],
        [3643],
        [3643],
        [3643]], device='cuda:0')
[2024-07-24 10:18:00,503][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:00,504][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,505][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,506][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,506][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,507][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,508][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,508][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,509][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,510][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,510][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,511][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,512][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,512][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0791, 0.9209], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:00,513][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0056, 0.9944], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:00,514][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2059, 0.7941], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:00,517][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1275, 0.8725], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:00,518][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3502, 0.6498], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:00,519][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8965, 0.1035], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:00,521][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0189, 0.9811], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:00,521][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4795, 0.5205], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:00,522][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0068, 0.9933], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:00,523][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3580, 0.6420], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:00,524][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1934, 0.8066], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:00,525][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0095, 0.9905], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:00,528][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Jamie] are: tensor([0.1011, 0.0947, 0.8042], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:00,532][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Jamie] are: tensor([0.0055, 0.0566, 0.9379], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:00,532][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Jamie] are: tensor([0.1455, 0.4446, 0.4098], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:00,533][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Jamie] are: tensor([0.4142, 0.4619, 0.1239], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:00,534][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Jamie] are: tensor([0.2797, 0.2706, 0.4497], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:00,534][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Jamie] are: tensor([0.9888, 0.0033, 0.0079], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:00,535][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Jamie] are: tensor([0.0428, 0.1393, 0.8178], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:00,539][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Jamie] are: tensor([0.6503, 0.2543, 0.0954], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:00,542][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Jamie] are: tensor([0.1074, 0.4353, 0.4572], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:00,543][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Jamie] are: tensor([0.8968, 0.0174, 0.0858], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:00,544][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Jamie] are: tensor([0.1545, 0.0421, 0.8034], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:00,544][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Jamie] are: tensor([0.1001, 0.3995, 0.5004], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:00,545][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1164, 0.1916, 0.6372, 0.0548], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:00,546][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0013, 0.1387, 0.5306, 0.3294], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:00,550][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1026, 0.2591, 0.2910, 0.3473], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:00,553][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1143, 0.5691, 0.1926, 0.1241], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:00,554][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0625, 0.2912, 0.2158, 0.4304], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:00,554][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.9000, 0.0306, 0.0249, 0.0445], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:00,555][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0120, 0.1754, 0.6662, 0.1464], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:00,556][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2159, 0.6111, 0.0894, 0.0836], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:00,558][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0088, 0.4965, 0.3403, 0.1544], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:00,562][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3030, 0.1467, 0.0844, 0.4659], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:00,564][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0533, 0.1219, 0.8092, 0.0156], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:00,565][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0280, 0.6152, 0.1326, 0.2241], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:00,565][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0856, 0.1041, 0.4382, 0.0227, 0.3494], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,566][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0023, 0.0796, 0.3308, 0.1734, 0.4139], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,567][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0513, 0.2043, 0.2198, 0.2446, 0.2799], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,569][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.1153, 0.4963, 0.0959, 0.1322, 0.1602], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,573][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0504, 0.1708, 0.1172, 0.2941, 0.3676], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,575][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([9.8232e-01, 7.4299e-04, 1.0549e-03, 7.8421e-03, 8.0443e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,576][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0145, 0.1822, 0.4706, 0.1215, 0.2113], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,576][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.2748, 0.5265, 0.0613, 0.0435, 0.0938], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,577][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.0351, 0.5462, 0.2416, 0.1623, 0.0148], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,578][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.4695, 0.0074, 0.0053, 0.4259, 0.0919], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,580][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.1456, 0.1478, 0.6707, 0.0086, 0.0273], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,584][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0457, 0.5497, 0.1424, 0.2205, 0.0416], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:00,586][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1096, 0.3331, 0.2010, 0.0333, 0.1006, 0.2225], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,587][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0027, 0.2018, 0.3470, 0.1304, 0.2509, 0.0671], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,587][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0497, 0.1661, 0.1735, 0.2023, 0.2030, 0.2053], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,588][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0447, 0.7182, 0.0882, 0.0836, 0.0433, 0.0219], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,589][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1260, 0.1274, 0.1451, 0.3420, 0.1560, 0.1035], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,591][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.8600, 0.0364, 0.0075, 0.0328, 0.0069, 0.0566], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,596][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0138, 0.3487, 0.3171, 0.1141, 0.1225, 0.0839], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,597][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.2603, 0.6106, 0.0486, 0.0357, 0.0325, 0.0123], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,598][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0167, 0.6222, 0.2464, 0.1050, 0.0069, 0.0027], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,598][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.4615, 0.1054, 0.0135, 0.2316, 0.0297, 0.1582], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,599][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0557, 0.2845, 0.6038, 0.0178, 0.0194, 0.0188], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,600][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ had] are: tensor([4.5587e-02, 7.9907e-01, 7.0565e-02, 7.9883e-02, 4.3293e-03, 5.6316e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:00,602][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1081, 0.3432, 0.1138, 0.0441, 0.0546, 0.2579, 0.0782],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,605][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([2.3130e-04, 1.3515e-01, 2.5562e-01, 1.4458e-01, 1.3446e-01, 1.3202e-01,
        1.9793e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,608][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0283, 0.1372, 0.1473, 0.1788, 0.1826, 0.2078, 0.1181],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,608][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0234, 0.7601, 0.0612, 0.0894, 0.0188, 0.0208, 0.0263],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,609][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0525, 0.2499, 0.0636, 0.3430, 0.0810, 0.1357, 0.0742],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,610][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([9.6166e-01, 1.2351e-04, 1.1999e-06, 7.4644e-04, 6.4047e-06, 2.5238e-03,
        3.4943e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,611][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0014, 0.2499, 0.3472, 0.1066, 0.0619, 0.1459, 0.0870],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,613][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0260, 0.8650, 0.0602, 0.0251, 0.0123, 0.0043, 0.0071],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,617][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0248, 0.6617, 0.1319, 0.1550, 0.0068, 0.0107, 0.0092],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,619][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([4.8059e-01, 3.7755e-04, 2.9137e-06, 1.1555e-02, 3.5968e-05, 1.5468e-02,
        4.9197e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,619][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0142, 0.2466, 0.7026, 0.0105, 0.0085, 0.0167, 0.0009],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,620][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0061, 0.6483, 0.0877, 0.2366, 0.0137, 0.0037, 0.0038],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:00,621][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.3418, 0.3780, 0.0693, 0.0168, 0.0910, 0.0338, 0.0457, 0.0235],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,622][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0226, 0.3237, 0.3144, 0.0848, 0.1899, 0.0119, 0.0494, 0.0034],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,624][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0975, 0.1638, 0.1565, 0.1730, 0.1629, 0.1156, 0.0997, 0.0311],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,629][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.1135, 0.4707, 0.1444, 0.1520, 0.0543, 0.0184, 0.0437, 0.0029],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,630][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.4623, 0.0378, 0.1729, 0.1968, 0.0774, 0.0314, 0.0123, 0.0091],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,631][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([9.9567e-01, 8.5549e-04, 3.8188e-05, 9.7753e-04, 3.0035e-05, 3.7157e-04,
        1.6683e-03, 3.8667e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,632][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0701, 0.5306, 0.1980, 0.0713, 0.0733, 0.0224, 0.0181, 0.0162],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,632][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.6523, 0.1719, 0.0525, 0.0475, 0.0406, 0.0107, 0.0180, 0.0065],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,633][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([2.7066e-01, 4.4294e-01, 1.3176e-01, 1.4010e-01, 9.3061e-03, 1.4324e-03,
        3.6742e-03, 1.2579e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,635][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([9.4156e-01, 1.4921e-02, 2.1517e-04, 2.7071e-02, 2.3444e-04, 4.7608e-03,
        1.0075e-02, 1.1612e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,640][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0439, 0.4952, 0.3738, 0.0434, 0.0294, 0.0070, 0.0036, 0.0038],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,641][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([4.6819e-01, 5.1862e-01, 9.8834e-03, 3.1728e-03, 9.6261e-05, 1.6264e-06,
        3.8054e-05, 5.5984e-09], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:00,641][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0548, 0.2529, 0.1181, 0.0245, 0.0401, 0.2684, 0.0962, 0.0886, 0.0564],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,642][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ of] are: tensor([1.2073e-04, 1.3846e-01, 1.5423e-01, 1.1010e-01, 1.6048e-01, 1.4780e-01,
        2.1273e-01, 5.3138e-02, 2.2946e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,643][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0373, 0.1156, 0.1095, 0.1248, 0.1322, 0.1429, 0.0888, 0.1668, 0.0821],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,644][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0340, 0.6471, 0.0668, 0.0924, 0.0328, 0.0413, 0.0458, 0.0017, 0.0381],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,648][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0304, 0.3393, 0.0444, 0.1874, 0.0562, 0.1369, 0.0933, 0.0438, 0.0684],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,651][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ of] are: tensor([8.9276e-01, 3.4189e-05, 3.2069e-07, 3.0116e-04, 2.9428e-06, 1.6398e-03,
        3.4929e-02, 3.5047e-02, 3.5286e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,652][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0013, 0.2507, 0.2302, 0.0889, 0.0723, 0.1919, 0.0966, 0.0337, 0.0344],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,653][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ of] are: tensor([1.4922e-02, 8.8732e-01, 5.1425e-02, 1.7246e-02, 1.2509e-02, 4.0172e-03,
        4.1011e-03, 4.3015e-04, 8.0260e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,653][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ of] are: tensor([9.6584e-03, 6.6130e-01, 1.7234e-01, 8.3857e-02, 1.1709e-02, 1.8598e-02,
        1.4193e-02, 4.8901e-04, 2.7856e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,654][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ of] are: tensor([1.4983e-01, 4.6143e-05, 1.9444e-07, 1.8135e-03, 4.4431e-06, 6.5319e-03,
        3.8473e-01, 3.2680e-02, 4.2436e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,656][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ of] are: tensor([1.2314e-02, 3.5891e-01, 5.5378e-01, 8.1247e-03, 8.6329e-03, 1.8845e-02,
        6.8358e-04, 3.8633e-02, 7.0047e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,660][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0028, 0.4723, 0.0781, 0.3439, 0.0356, 0.0219, 0.0089, 0.0033, 0.0332],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:00,662][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0742, 0.2249, 0.0577, 0.0188, 0.0337, 0.1787, 0.0743, 0.0512, 0.0766,
        0.2098], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,663][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0010, 0.0959, 0.3552, 0.0858, 0.1683, 0.0557, 0.1450, 0.0126, 0.0435,
        0.0369], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,664][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0267, 0.1068, 0.1025, 0.1181, 0.1218, 0.1334, 0.0806, 0.1456, 0.0801,
        0.0845], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,664][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0404, 0.6739, 0.0460, 0.0818, 0.0225, 0.0335, 0.0343, 0.0033, 0.0566,
        0.0078], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,665][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.2432, 0.1404, 0.0443, 0.2459, 0.0555, 0.0779, 0.0378, 0.0318, 0.0577,
        0.0654], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,667][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([9.2118e-01, 2.0329e-04, 2.5294e-06, 6.5496e-04, 6.0680e-06, 1.6150e-03,
        2.0505e-02, 7.6860e-03, 2.4648e-02, 2.3498e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,671][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0058, 0.3290, 0.3166, 0.0727, 0.0759, 0.0731, 0.0439, 0.0143, 0.0338,
        0.0349], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,673][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.1301, 0.7374, 0.0459, 0.0228, 0.0158, 0.0067, 0.0075, 0.0009, 0.0276,
        0.0054], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,674][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([5.9726e-02, 6.2650e-01, 1.4718e-01, 1.0994e-01, 6.9543e-03, 6.8757e-03,
        6.2429e-03, 3.6923e-04, 3.3433e-02, 2.7803e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,674][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([5.4267e-01, 3.7987e-04, 1.4488e-06, 7.5915e-03, 1.0732e-05, 5.7250e-03,
        1.3438e-01, 1.1497e-02, 1.4297e-01, 1.5477e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,675][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([2.6184e-02, 2.5938e-01, 6.5946e-01, 1.1790e-02, 1.2569e-02, 1.1052e-02,
        1.2643e-03, 1.4990e-02, 4.6034e-04, 2.8512e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,676][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([4.7414e-02, 7.7739e-01, 8.2511e-02, 6.8703e-02, 5.6045e-03, 8.2541e-04,
        1.3363e-03, 5.3120e-05, 1.5167e-02, 9.9684e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:00,679][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.1143, 0.3080, 0.0860, 0.0152, 0.0402, 0.0987, 0.0611, 0.0267, 0.0564,
        0.1693, 0.0241], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,684][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0010, 0.2597, 0.3160, 0.1061, 0.1431, 0.0245, 0.0796, 0.0031, 0.0371,
        0.0185, 0.0113], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,684][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0340, 0.1090, 0.1032, 0.1159, 0.1126, 0.1157, 0.0694, 0.1072, 0.0735,
        0.0706, 0.0888], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,685][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0420, 0.7489, 0.0364, 0.0831, 0.0146, 0.0174, 0.0161, 0.0012, 0.0340,
        0.0026, 0.0036], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,686][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1674, 0.1842, 0.0558, 0.2850, 0.0490, 0.0983, 0.0203, 0.0388, 0.0213,
        0.0294, 0.0505], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,687][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ at] are: tensor([9.3143e-01, 1.7103e-04, 1.5689e-06, 4.9573e-04, 3.8650e-06, 1.0066e-03,
        1.0259e-02, 5.2034e-03, 1.2291e-02, 1.2059e-02, 2.7083e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,690][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0038, 0.5054, 0.2367, 0.0758, 0.0432, 0.0480, 0.0256, 0.0076, 0.0276,
        0.0162, 0.0101], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,694][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0701, 0.8395, 0.0315, 0.0218, 0.0105, 0.0055, 0.0033, 0.0008, 0.0120,
        0.0021, 0.0027], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,695][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ at] are: tensor([4.7879e-02, 6.7287e-01, 1.1737e-01, 1.2053e-01, 6.4116e-03, 3.4934e-03,
        3.8917e-03, 1.4290e-04, 2.4383e-02, 1.2367e-03, 1.7908e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,696][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ at] are: tensor([6.4546e-01, 5.1457e-04, 1.2931e-06, 5.8820e-03, 8.6744e-06, 3.1663e-03,
        6.1421e-02, 6.4413e-03, 6.8409e-02, 7.3706e-02, 1.3499e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,697][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ at] are: tensor([1.5064e-02, 4.6120e-01, 4.9131e-01, 1.2453e-02, 7.7329e-03, 5.4174e-03,
        6.7203e-04, 4.0657e-03, 3.0141e-04, 1.0779e-03, 6.9860e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,698][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ at] are: tensor([2.4659e-02, 8.6269e-01, 5.8333e-02, 4.5724e-02, 2.6215e-03, 2.7117e-04,
        4.5508e-04, 8.7923e-06, 4.7707e-03, 2.2589e-04, 2.4167e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:00,700][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0760, 0.3524, 0.0525, 0.0215, 0.0232, 0.1391, 0.0356, 0.0502, 0.0435,
        0.1169, 0.0240, 0.0651], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,702][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ the] are: tensor([1.4808e-04, 1.4687e-01, 2.8365e-01, 1.1167e-01, 1.4097e-01, 6.1630e-02,
        1.1748e-01, 1.2846e-02, 2.2848e-02, 2.0584e-02, 1.3850e-02, 6.7457e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,706][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0258, 0.0959, 0.0876, 0.0955, 0.1030, 0.1083, 0.0635, 0.1316, 0.0627,
        0.0663, 0.0851, 0.0746], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,706][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0166, 0.7502, 0.0627, 0.0730, 0.0197, 0.0238, 0.0154, 0.0013, 0.0170,
        0.0028, 0.0025, 0.0152], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,707][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0380, 0.4133, 0.0475, 0.2109, 0.0309, 0.0744, 0.0200, 0.0258, 0.0201,
        0.0211, 0.0360, 0.0622], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,708][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ the] are: tensor([6.4206e-01, 6.5011e-04, 3.4279e-06, 8.3393e-04, 5.8441e-06, 1.7026e-03,
        4.1384e-03, 1.1008e-02, 3.5539e-03, 4.4111e-03, 1.1501e-02, 3.2013e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,709][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0006, 0.2301, 0.3455, 0.0653, 0.0621, 0.1003, 0.0561, 0.0088, 0.0214,
        0.0259, 0.0152, 0.0689], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,711][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ the] are: tensor([1.7034e-02, 8.4541e-01, 5.9308e-02, 2.2124e-02, 1.4447e-02, 4.5980e-03,
        3.7954e-03, 3.0295e-04, 1.0307e-02, 1.0516e-03, 1.1579e-03, 2.0460e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,713][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ the] are: tensor([4.7943e-03, 7.3560e-01, 1.2330e-01, 9.4158e-02, 4.6175e-03, 6.0704e-03,
        4.6220e-03, 1.3281e-04, 1.5973e-02, 9.0577e-04, 1.2064e-03, 8.6200e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,716][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ the] are: tensor([1.4086e-01, 6.2342e-04, 1.5932e-06, 2.6799e-03, 5.9316e-06, 1.8773e-03,
        1.0052e-02, 3.7320e-03, 6.5078e-03, 9.4782e-03, 1.6257e-02, 8.0792e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,717][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ the] are: tensor([6.2059e-03, 2.7003e-01, 6.9263e-01, 5.5729e-03, 7.1413e-03, 6.6192e-03,
        4.0358e-04, 9.4850e-03, 6.0731e-05, 1.0830e-03, 5.5465e-04, 2.1215e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,718][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0042, 0.4729, 0.2111, 0.2176, 0.0380, 0.0081, 0.0051, 0.0009, 0.0195,
        0.0046, 0.0050, 0.0131], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:00,719][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.1248, 0.2119, 0.0606, 0.0119, 0.0469, 0.0943, 0.0264, 0.0789, 0.0172,
        0.1317, 0.0214, 0.0422, 0.1319], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,720][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ store] are: tensor([1.7125e-04, 6.5079e-02, 1.9844e-01, 1.0225e-01, 1.0309e-01, 1.4317e-01,
        1.6685e-01, 2.7404e-02, 3.7391e-02, 2.8654e-02, 2.9160e-02, 7.2074e-02,
        2.6275e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,723][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0283, 0.0931, 0.0736, 0.0744, 0.0853, 0.0949, 0.0631, 0.1386, 0.0583,
        0.0685, 0.0840, 0.0673, 0.0707], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,727][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0204, 0.6954, 0.0401, 0.0807, 0.0264, 0.0513, 0.0231, 0.0052, 0.0178,
        0.0040, 0.0039, 0.0168, 0.0150], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,728][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0418, 0.4133, 0.0323, 0.1482, 0.0216, 0.0847, 0.0149, 0.0502, 0.0148,
        0.0233, 0.0392, 0.0575, 0.0583], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,729][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ store] are: tensor([2.8080e-01, 3.2986e-04, 2.1748e-06, 4.4999e-04, 3.3036e-06, 1.3060e-03,
        3.3350e-03, 1.4108e-02, 1.5973e-03, 4.2232e-03, 1.1310e-02, 2.2348e-01,
        4.5906e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,730][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0011, 0.1294, 0.3575, 0.0514, 0.0934, 0.1277, 0.0719, 0.0110, 0.0211,
        0.0339, 0.0172, 0.0624, 0.0220], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,731][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0221, 0.8462, 0.0583, 0.0155, 0.0180, 0.0065, 0.0029, 0.0011, 0.0049,
        0.0017, 0.0011, 0.0095, 0.0121], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,734][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.0104, 0.5675, 0.1740, 0.0762, 0.0087, 0.0227, 0.0173, 0.0009, 0.0425,
        0.0055, 0.0080, 0.0315, 0.0350], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,738][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ store] are: tensor([4.3468e-02, 2.0775e-04, 3.5841e-07, 7.8511e-04, 1.2794e-06, 7.3545e-04,
        3.3676e-03, 2.1440e-03, 2.4115e-03, 2.9745e-03, 6.5288e-03, 2.9355e-01,
        6.4383e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,739][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ store] are: tensor([8.5398e-03, 1.8470e-01, 7.4984e-01, 6.8217e-03, 1.0237e-02, 1.3507e-02,
        7.6783e-04, 2.0156e-02, 9.9817e-05, 2.0287e-03, 1.1739e-03, 2.5676e-04,
        1.8634e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,739][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0028, 0.3871, 0.2342, 0.2206, 0.0304, 0.0191, 0.0060, 0.0055, 0.0262,
        0.0100, 0.0077, 0.0163, 0.0340], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:00,740][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0282, 0.2691, 0.0889, 0.0168, 0.0327, 0.1819, 0.0342, 0.0661, 0.0223,
        0.0945, 0.0217, 0.0440, 0.0742, 0.0253], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,741][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [.] are: tensor([1.5705e-04, 2.0364e-01, 2.1183e-01, 1.0897e-01, 1.0771e-01, 1.0381e-01,
        1.1285e-01, 4.8837e-02, 1.1817e-02, 2.0685e-02, 1.1626e-02, 3.3837e-02,
        1.5886e-02, 8.3489e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,744][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0286, 0.0865, 0.0773, 0.0800, 0.0913, 0.0879, 0.0550, 0.1215, 0.0514,
        0.0570, 0.0706, 0.0647, 0.0716, 0.0569], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,746][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [.] are: tensor([1.3670e-02, 8.3904e-01, 4.0984e-02, 4.6753e-02, 1.3928e-02, 1.5398e-02,
        7.9338e-03, 7.0886e-04, 6.0232e-03, 7.8180e-04, 6.0108e-04, 4.4693e-03,
        5.4257e-03, 4.2868e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,749][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0307, 0.4731, 0.0403, 0.1688, 0.0241, 0.0788, 0.0159, 0.0230, 0.0092,
        0.0136, 0.0193, 0.0421, 0.0489, 0.0122], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,750][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [.] are: tensor([4.2226e-01, 4.8224e-04, 1.7118e-06, 5.2090e-04, 2.1089e-06, 1.0843e-03,
        4.4256e-04, 9.4896e-03, 1.7364e-04, 9.4701e-04, 2.1729e-03, 3.9393e-02,
        6.5658e-02, 4.5738e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,751][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0008, 0.3240, 0.2951, 0.0670, 0.0406, 0.1134, 0.0437, 0.0159, 0.0093,
        0.0185, 0.0109, 0.0447, 0.0071, 0.0090], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,751][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [.] are: tensor([5.8865e-03, 9.0795e-01, 4.5940e-02, 1.0293e-02, 8.8383e-03, 1.2754e-03,
        1.2514e-03, 8.2210e-05, 3.2472e-03, 3.2523e-04, 2.2609e-04, 5.5936e-03,
        2.9688e-03, 6.1262e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,752][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [.] are: tensor([3.1920e-03, 7.3142e-01, 1.4141e-01, 6.2666e-02, 5.9347e-03, 1.4266e-02,
        7.2035e-03, 5.5255e-04, 1.0637e-02, 1.8952e-03, 2.2657e-03, 7.3168e-03,
        4.5152e-03, 6.7225e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,754][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [.] are: tensor([8.3299e-02, 4.9925e-04, 5.2426e-07, 1.4143e-03, 1.1054e-06, 6.4120e-04,
        4.0113e-04, 1.0700e-03, 2.4266e-04, 3.9899e-04, 7.4397e-04, 3.6037e-02,
        5.6932e-02, 8.1832e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,756][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [.] are: tensor([1.4514e-02, 3.7959e-01, 5.7093e-01, 4.8585e-03, 4.6946e-03, 6.7374e-03,
        1.9521e-04, 1.6728e-02, 2.3821e-05, 6.5526e-04, 3.3822e-04, 1.0048e-04,
        6.1036e-04, 3.1379e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,760][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0015, 0.3783, 0.1198, 0.3400, 0.0312, 0.0089, 0.0038, 0.0012, 0.0146,
        0.0034, 0.0028, 0.0101, 0.0109, 0.0735], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:00,760][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0087, 0.1049, 0.0855, 0.0077, 0.0520, 0.1440, 0.0268, 0.0285, 0.0160,
        0.2255, 0.0154, 0.0282, 0.1566, 0.0168, 0.0833], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,761][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([7.3779e-05, 6.5552e-02, 1.2443e-01, 8.9045e-02, 1.0578e-01, 2.0867e-01,
        1.2965e-01, 1.1111e-01, 1.4464e-02, 3.0736e-02, 3.3111e-02, 4.4839e-02,
        1.2214e-02, 8.4511e-03, 2.1871e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,762][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0115, 0.0615, 0.0532, 0.0609, 0.0727, 0.0799, 0.0560, 0.1443, 0.0565,
        0.0640, 0.0798, 0.0633, 0.0693, 0.0561, 0.0710], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,763][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.0102, 0.5456, 0.0576, 0.0871, 0.0414, 0.0706, 0.0435, 0.0069, 0.0347,
        0.0061, 0.0073, 0.0265, 0.0192, 0.0143, 0.0288], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,767][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0094, 0.2019, 0.0402, 0.1087, 0.0323, 0.0975, 0.0368, 0.0698, 0.0266,
        0.0617, 0.0582, 0.1016, 0.1066, 0.0181, 0.0308], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,770][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([9.7730e-04, 1.5267e-06, 1.1760e-07, 7.5048e-06, 3.3911e-07, 5.8716e-05,
        2.4472e-03, 6.1285e-04, 1.6157e-03, 2.9481e-03, 6.7041e-03, 7.6105e-02,
        2.3159e-01, 6.7548e-01, 1.4504e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,771][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0004, 0.1380, 0.3096, 0.0527, 0.0648, 0.1248, 0.0594, 0.0257, 0.0152,
        0.0428, 0.0334, 0.0618, 0.0183, 0.0103, 0.0429], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,772][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0223, 0.7271, 0.0769, 0.0172, 0.0252, 0.0097, 0.0091, 0.0014, 0.0235,
        0.0043, 0.0027, 0.0260, 0.0179, 0.0181, 0.0187], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,773][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.0047, 0.6706, 0.1274, 0.0735, 0.0094, 0.0197, 0.0110, 0.0016, 0.0217,
        0.0056, 0.0057, 0.0137, 0.0141, 0.0143, 0.0069], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,773][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([5.2451e-05, 2.8282e-07, 8.1861e-09, 6.3828e-06, 6.0858e-08, 1.1564e-05,
        1.4338e-03, 4.4348e-05, 1.3669e-03, 1.1866e-03, 2.3093e-03, 6.7420e-02,
        1.6073e-01, 7.6517e-01, 2.6687e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,775][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([6.2012e-03, 2.4752e-01, 6.6822e-01, 5.9358e-03, 1.4346e-02, 1.2234e-02,
        6.7673e-04, 3.8636e-02, 9.7151e-05, 2.7239e-03, 1.3350e-03, 2.4177e-04,
        1.1013e-03, 7.5426e-05, 6.5565e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,779][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0006, 0.2679, 0.1264, 0.2930, 0.0523, 0.0576, 0.0118, 0.0346, 0.0174,
        0.0242, 0.0248, 0.0200, 0.0142, 0.0328, 0.0224], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:00,781][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0705, 0.2864, 0.0825, 0.0097, 0.0701, 0.0506, 0.0168, 0.0175, 0.0221,
        0.0813, 0.0065, 0.0248, 0.0859, 0.0107, 0.1403, 0.0242],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,782][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0017, 0.3286, 0.1480, 0.0968, 0.0733, 0.0176, 0.0625, 0.0038, 0.0335,
        0.0160, 0.0116, 0.0511, 0.0489, 0.0422, 0.0579, 0.0063],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,783][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0221, 0.0849, 0.0699, 0.0774, 0.0770, 0.0735, 0.0510, 0.0806, 0.0548,
        0.0524, 0.0643, 0.0588, 0.0629, 0.0502, 0.0625, 0.0577],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,784][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0144, 0.6661, 0.0521, 0.0671, 0.0166, 0.0142, 0.0147, 0.0012, 0.0343,
        0.0033, 0.0042, 0.0258, 0.0225, 0.0190, 0.0340, 0.0103],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,786][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1280, 0.2241, 0.1123, 0.2420, 0.0389, 0.0528, 0.0053, 0.0184, 0.0096,
        0.0111, 0.0120, 0.0180, 0.0501, 0.0237, 0.0262, 0.0276],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,788][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([3.5321e-01, 1.1769e-03, 1.4988e-05, 8.2915e-04, 9.8165e-06, 6.1763e-04,
        6.7275e-04, 8.9956e-04, 7.6775e-04, 5.4661e-04, 1.1758e-03, 3.7658e-02,
        1.4501e-01, 3.3680e-01, 3.3764e-03, 1.1724e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,792][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0024, 0.5058, 0.1913, 0.0392, 0.0529, 0.0154, 0.0154, 0.0016, 0.0255,
        0.0094, 0.0051, 0.0356, 0.0246, 0.0168, 0.0505, 0.0085],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,793][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0868, 0.6199, 0.0737, 0.0259, 0.0215, 0.0060, 0.0081, 0.0008, 0.0454,
        0.0043, 0.0043, 0.0323, 0.0180, 0.0216, 0.0263, 0.0052],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,794][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([7.9161e-03, 6.7006e-01, 1.3988e-01, 7.9053e-02, 5.4350e-03, 1.7742e-03,
        2.9154e-03, 3.9376e-05, 2.1597e-02, 8.6077e-04, 1.2464e-03, 1.4843e-02,
        1.6642e-02, 2.8891e-02, 4.9931e-03, 3.8608e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,794][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([8.0380e-02, 2.3945e-03, 3.4095e-06, 1.8691e-03, 3.9936e-06, 5.4120e-04,
        4.8022e-04, 2.6693e-04, 2.8452e-04, 4.4490e-04, 6.7797e-04, 4.2180e-02,
        1.0490e-01, 5.7527e-01, 1.1156e-03, 1.8918e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,795][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0107, 0.4180, 0.5028, 0.0176, 0.0188, 0.0061, 0.0012, 0.0049, 0.0010,
        0.0024, 0.0014, 0.0012, 0.0052, 0.0010, 0.0023, 0.0054],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,797][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([4.2063e-02, 8.5775e-01, 4.4799e-02, 2.9851e-02, 1.4180e-03, 9.2298e-05,
        2.7462e-04, 9.6323e-07, 2.9961e-03, 5.3296e-05, 4.9650e-05, 8.8550e-04,
        6.8294e-03, 8.5439e-03, 4.2766e-03, 1.1229e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:00,802][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0558, 0.3819, 0.0451, 0.0245, 0.0240, 0.1007, 0.0184, 0.0387, 0.0285,
        0.0550, 0.0129, 0.0300, 0.0505, 0.0196, 0.0452, 0.0246, 0.0446],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,803][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0003, 0.2548, 0.1962, 0.1250, 0.0881, 0.0550, 0.0795, 0.0121, 0.0181,
        0.0140, 0.0085, 0.0399, 0.0220, 0.0119, 0.0192, 0.0101, 0.0452],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,804][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0157, 0.0681, 0.0581, 0.0674, 0.0667, 0.0767, 0.0423, 0.1221, 0.0415,
        0.0501, 0.0623, 0.0521, 0.0563, 0.0421, 0.0570, 0.0667, 0.0549],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,805][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.0183e-02, 8.4662e-01, 2.5156e-02, 5.1190e-02, 6.1120e-03, 1.3325e-02,
        7.1422e-03, 6.7980e-04, 7.4095e-03, 8.5878e-04, 1.0294e-03, 5.5790e-03,
        5.6556e-03, 4.4518e-03, 4.0912e-03, 3.6455e-03, 6.8754e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,806][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0523, 0.5158, 0.0478, 0.1671, 0.0185, 0.0517, 0.0045, 0.0165, 0.0045,
        0.0061, 0.0093, 0.0130, 0.0325, 0.0067, 0.0071, 0.0256, 0.0210],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,808][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([1.2549e-01, 6.3601e-04, 2.2697e-06, 3.7985e-04, 1.6211e-06, 4.2096e-04,
        2.1293e-04, 1.1081e-03, 1.3291e-04, 2.0143e-04, 5.1046e-04, 1.8409e-02,
        4.7693e-02, 1.6891e-01, 6.8086e-04, 1.2925e-01, 5.0597e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,813][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0008, 0.4439, 0.2544, 0.0540, 0.0365, 0.0463, 0.0204, 0.0042, 0.0117,
        0.0096, 0.0055, 0.0304, 0.0085, 0.0068, 0.0177, 0.0128, 0.0366],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,814][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([1.6224e-02, 8.4004e-01, 7.1855e-02, 2.1471e-02, 8.4636e-03, 2.8199e-03,
        2.1736e-03, 1.5788e-04, 7.1261e-03, 4.7045e-04, 5.1791e-04, 8.7703e-03,
        4.1513e-03, 6.1649e-03, 3.8977e-03, 9.4682e-04, 4.7518e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,814][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([1.2136e-02, 6.9396e-01, 1.1290e-01, 9.7631e-02, 5.9397e-03, 8.0971e-03,
        4.9502e-03, 2.8175e-04, 1.3199e-02, 1.4911e-03, 2.0570e-03, 1.0964e-02,
        6.5361e-03, 1.0168e-02, 3.0407e-03, 6.1053e-03, 1.0537e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,815][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([2.4520e-02, 6.9600e-04, 9.1698e-07, 8.4537e-04, 8.7011e-07, 3.3752e-04,
        1.8284e-04, 2.6024e-04, 8.8883e-05, 1.6943e-04, 3.2235e-04, 1.6608e-02,
        3.9786e-02, 2.6741e-01, 2.3691e-04, 2.5014e-01, 3.9840e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,816][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([5.0742e-03, 4.2977e-01, 5.2473e-01, 9.9564e-03, 7.1347e-03, 6.3685e-03,
        3.9553e-04, 6.8181e-03, 1.0216e-04, 9.1212e-04, 4.4221e-04, 2.4907e-04,
        1.1034e-03, 9.2499e-05, 3.2952e-04, 5.4854e-03, 1.0414e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,818][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([6.1037e-03, 6.4803e-01, 1.1611e-01, 1.3361e-01, 1.2661e-02, 2.7624e-03,
        1.7476e-03, 2.7279e-04, 1.0153e-02, 1.5418e-03, 1.3036e-03, 4.1876e-03,
        9.9147e-03, 2.4010e-02, 1.0513e-02, 4.2672e-03, 1.2804e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:00,822][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.0465, 0.1648, 0.0383, 0.0070, 0.0297, 0.0712, 0.0205, 0.0239, 0.0212,
        0.1113, 0.0086, 0.0308, 0.0570, 0.0139, 0.0633, 0.0313, 0.0437, 0.2170],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,827][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0011, 0.1930, 0.1437, 0.1145, 0.1067, 0.0558, 0.0670, 0.0107, 0.0351,
        0.0168, 0.0128, 0.0487, 0.0339, 0.0167, 0.0584, 0.0170, 0.0338, 0.0342],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,828][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0191, 0.0691, 0.0514, 0.0569, 0.0613, 0.0723, 0.0450, 0.1006, 0.0435,
        0.0500, 0.0614, 0.0503, 0.0501, 0.0382, 0.0560, 0.0617, 0.0508, 0.0623],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,828][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.0212, 0.7628, 0.0281, 0.0661, 0.0179, 0.0187, 0.0090, 0.0018, 0.0118,
        0.0018, 0.0019, 0.0080, 0.0062, 0.0050, 0.0147, 0.0076, 0.0076, 0.0097],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,829][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0403, 0.3732, 0.0470, 0.1948, 0.0321, 0.0616, 0.0061, 0.0159, 0.0095,
        0.0092, 0.0101, 0.0293, 0.0315, 0.0121, 0.0170, 0.0387, 0.0418, 0.0296],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,831][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([5.7509e-02, 1.1055e-04, 3.8968e-07, 8.5414e-05, 3.6635e-07, 1.4452e-04,
        1.8852e-04, 4.9987e-04, 1.0261e-04, 1.8448e-04, 4.7106e-04, 1.6991e-02,
        5.2480e-02, 1.8297e-01, 3.8442e-04, 7.7952e-02, 4.7026e-01, 1.3966e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,834][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0023, 0.3915, 0.1513, 0.0540, 0.0416, 0.0559, 0.0258, 0.0059, 0.0247,
        0.0150, 0.0091, 0.0448, 0.0227, 0.0094, 0.0376, 0.0208, 0.0475, 0.0401],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,837][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([3.5751e-02, 7.5085e-01, 7.9253e-02, 2.0081e-02, 1.7647e-02, 7.8552e-03,
        4.0629e-03, 6.1727e-04, 1.1278e-02, 1.8512e-03, 1.7017e-03, 1.3921e-02,
        8.7026e-03, 8.2849e-03, 1.2297e-02, 2.5416e-03, 5.1113e-03, 1.8194e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,838][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([2.3592e-02, 6.0697e-01, 1.5248e-01, 8.6216e-02, 1.0041e-02, 9.8770e-03,
        7.2883e-03, 3.2421e-04, 2.1615e-02, 1.9736e-03, 2.2778e-03, 1.4337e-02,
        1.1497e-02, 1.1291e-02, 5.8446e-03, 8.8949e-03, 1.1601e-02, 1.3879e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,839][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([1.1618e-02, 1.0842e-04, 8.2491e-08, 1.5551e-04, 1.1139e-07, 9.1237e-05,
        1.7096e-04, 2.1779e-04, 1.0339e-04, 1.5881e-04, 3.8590e-04, 1.6417e-02,
        5.2857e-02, 3.0640e-01, 1.2215e-04, 1.5413e-01, 3.9369e-01, 6.3373e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,840][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([1.2475e-02, 4.1876e-01, 4.9614e-01, 9.7624e-03, 1.2691e-02, 7.9782e-03,
        7.1899e-04, 9.1978e-03, 2.2291e-04, 1.7060e-03, 1.0104e-03, 4.2002e-04,
        2.4751e-03, 1.3817e-04, 1.0873e-03, 1.1081e-02, 1.4906e-03, 1.2642e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,842][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.0094, 0.5360, 0.1528, 0.1327, 0.0232, 0.0052, 0.0039, 0.0006, 0.0157,
        0.0028, 0.0027, 0.0061, 0.0161, 0.0268, 0.0180, 0.0100, 0.0143, 0.0236],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:00,847][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0271, 0.2383, 0.0376, 0.0154, 0.0121, 0.1077, 0.0206, 0.0220, 0.0198,
        0.0482, 0.0130, 0.0357, 0.0463, 0.0223, 0.0205, 0.0310, 0.0596, 0.1999,
        0.0227], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,848][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0003, 0.1687, 0.1533, 0.0985, 0.0773, 0.0922, 0.1046, 0.0445, 0.0123,
        0.0212, 0.0106, 0.0376, 0.0242, 0.0090, 0.0179, 0.0208, 0.0504, 0.0404,
        0.0162], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,849][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0300, 0.0631, 0.0509, 0.0561, 0.0575, 0.0632, 0.0402, 0.0779, 0.0359,
        0.0400, 0.0522, 0.0497, 0.0549, 0.0403, 0.0602, 0.0609, 0.0547, 0.0639,
        0.0484], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,850][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.4434e-02, 8.5157e-01, 2.4685e-02, 4.0812e-02, 6.5278e-03, 1.6074e-02,
        6.4163e-03, 7.2887e-04, 5.2269e-03, 6.1421e-04, 5.4856e-04, 4.8128e-03,
        4.5558e-03, 3.6137e-03, 2.9808e-03, 2.8493e-03, 5.6488e-03, 6.2864e-03,
        1.6111e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,851][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0273, 0.4284, 0.0212, 0.1462, 0.0089, 0.0767, 0.0069, 0.0313, 0.0050,
        0.0077, 0.0223, 0.0293, 0.0332, 0.0078, 0.0046, 0.0607, 0.0397, 0.0336,
        0.0091], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,853][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.1216e-02, 2.5332e-05, 8.3026e-08, 2.8316e-05, 8.4259e-08, 6.4211e-05,
        8.7719e-05, 2.9677e-04, 3.5722e-05, 9.1282e-05, 2.5177e-04, 1.1591e-02,
        4.0502e-02, 1.6326e-01, 1.5383e-04, 6.9142e-02, 5.0053e-01, 1.4876e-01,
        4.3968e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,858][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0009, 0.3480, 0.1839, 0.0590, 0.0352, 0.0870, 0.0371, 0.0089, 0.0111,
        0.0159, 0.0084, 0.0421, 0.0082, 0.0077, 0.0178, 0.0201, 0.0583, 0.0318,
        0.0185], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,859][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([8.3056e-03, 8.5631e-01, 8.2048e-02, 1.4641e-02, 9.8536e-03, 1.8422e-03,
        1.3127e-03, 1.2094e-04, 2.8695e-03, 3.0569e-04, 2.1873e-04, 4.6783e-03,
        4.0909e-03, 4.6550e-03, 3.2664e-03, 6.8948e-04, 2.1729e-03, 1.3523e-03,
        1.2655e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,860][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([4.8546e-03, 7.2175e-01, 1.4530e-01, 5.0318e-02, 6.2554e-03, 7.6981e-03,
        4.9854e-03, 1.7690e-04, 8.5372e-03, 1.2092e-03, 1.3945e-03, 6.6610e-03,
        5.5636e-03, 6.8374e-03, 2.2557e-03, 3.3757e-03, 7.5129e-03, 7.8584e-03,
        7.4567e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,861][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.4625e-03, 1.8632e-05, 1.0041e-08, 4.6974e-05, 2.0197e-08, 3.7501e-05,
        9.7546e-05, 4.3029e-05, 5.0593e-05, 7.2697e-05, 2.0585e-04, 1.4184e-02,
        2.4544e-02, 2.7678e-01, 3.6849e-05, 1.1061e-01, 4.6703e-01, 5.0651e-02,
        5.4128e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,862][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.4065e-02, 4.4826e-01, 4.6577e-01, 8.9404e-03, 6.0958e-03, 1.0903e-02,
        3.3413e-04, 2.6788e-02, 3.9436e-05, 1.1494e-03, 6.3513e-04, 1.6703e-04,
        9.4608e-04, 5.1033e-05, 2.2877e-04, 9.0593e-03, 9.2763e-04, 5.5766e-03,
        6.5262e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,865][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0022, 0.4408, 0.0859, 0.2255, 0.0233, 0.0112, 0.0036, 0.0024, 0.0113,
        0.0051, 0.0054, 0.0081, 0.0088, 0.0434, 0.0167, 0.0168, 0.0240, 0.0116,
        0.0539], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:00,984][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:00,985][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,986][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,987][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,987][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,988][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,990][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,991][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,991][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,993][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,996][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,998][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,999][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:00,999][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0399, 0.9601], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,000][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0056, 0.9944], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,001][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1460, 0.8540], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,003][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1275, 0.8725], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,007][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3502, 0.6498], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,009][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.8965, 0.1035], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,009][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0189, 0.9811], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,010][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4795, 0.5205], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,011][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0068, 0.9933], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,011][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.3580, 0.6420], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,014][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1934, 0.8066], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,017][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0095, 0.9905], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,019][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Jamie] are: tensor([0.0700, 0.2698, 0.6602], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,020][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Jamie] are: tensor([0.0055, 0.0566, 0.9379], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,021][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Jamie] are: tensor([0.4090, 0.2608, 0.3302], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,021][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Jamie] are: tensor([0.4142, 0.4619, 0.1239], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,022][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Jamie] are: tensor([0.2797, 0.2706, 0.4497], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,024][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Jamie] are: tensor([0.9888, 0.0033, 0.0079], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,028][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Jamie] are: tensor([0.0428, 0.1393, 0.8178], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,030][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Jamie] are: tensor([0.6503, 0.2543, 0.0954], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,031][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Jamie] are: tensor([0.1074, 0.4353, 0.4572], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,031][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Jamie] are: tensor([0.8968, 0.0174, 0.0858], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,032][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Jamie] are: tensor([0.1545, 0.0421, 0.8034], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,033][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Jamie] are: tensor([0.1001, 0.3995, 0.5004], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,035][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0243, 0.3733, 0.4852, 0.1172], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,039][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0013, 0.1387, 0.5306, 0.3294], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,040][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1441, 0.2264, 0.4712, 0.1583], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,041][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1143, 0.5691, 0.1926, 0.1241], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,042][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0625, 0.2912, 0.2158, 0.4304], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,043][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9000, 0.0306, 0.0249, 0.0445], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,043][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0120, 0.1754, 0.6662, 0.1464], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,046][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2159, 0.6111, 0.0894, 0.0836], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,051][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0088, 0.4965, 0.3403, 0.1544], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,051][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.3030, 0.1467, 0.0844, 0.4659], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,052][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0533, 0.1219, 0.8092, 0.0156], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,053][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0280, 0.6152, 0.1326, 0.2241], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,054][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0305, 0.3472, 0.3435, 0.1006, 0.1782], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,054][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0023, 0.0796, 0.3308, 0.1734, 0.4139], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,057][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.0830, 0.1996, 0.4060, 0.0939, 0.2174], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,061][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.1153, 0.4963, 0.0959, 0.1322, 0.1602], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,062][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0504, 0.1708, 0.1172, 0.2941, 0.3676], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,063][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([9.8232e-01, 7.4299e-04, 1.0549e-03, 7.8421e-03, 8.0443e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,064][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0145, 0.1822, 0.4706, 0.1215, 0.2113], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,064][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.2748, 0.5265, 0.0613, 0.0435, 0.0938], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,065][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.0351, 0.5462, 0.2416, 0.1623, 0.0148], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,068][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.4695, 0.0074, 0.0053, 0.4259, 0.0919], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,072][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.1456, 0.1478, 0.6707, 0.0086, 0.0273], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,073][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0457, 0.5497, 0.1424, 0.2205, 0.0416], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,074][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0172, 0.5106, 0.1843, 0.0750, 0.1073, 0.1056], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,074][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0027, 0.2018, 0.3470, 0.1304, 0.2509, 0.0671], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,075][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0642, 0.4179, 0.2942, 0.1023, 0.0974, 0.0240], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,076][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0447, 0.7182, 0.0882, 0.0836, 0.0433, 0.0219], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,079][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1260, 0.1274, 0.1451, 0.3420, 0.1560, 0.1035], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,083][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.8600, 0.0364, 0.0075, 0.0328, 0.0069, 0.0566], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,084][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0138, 0.3487, 0.3171, 0.1141, 0.1225, 0.0839], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,085][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.2603, 0.6106, 0.0486, 0.0357, 0.0325, 0.0123], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,085][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0167, 0.6222, 0.2464, 0.1050, 0.0069, 0.0027], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,086][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.4615, 0.1054, 0.0135, 0.2316, 0.0297, 0.1582], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,089][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0557, 0.2845, 0.6038, 0.0178, 0.0194, 0.0188], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,091][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([4.5587e-02, 7.9907e-01, 7.0565e-02, 7.9883e-02, 4.3293e-03, 5.6316e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,094][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0076, 0.5670, 0.1653, 0.0655, 0.0198, 0.1079, 0.0670],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,095][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([2.3130e-04, 1.3515e-01, 2.5562e-01, 1.4458e-01, 1.3446e-01, 1.3202e-01,
        1.9793e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,095][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0149, 0.2970, 0.3963, 0.0898, 0.0996, 0.0589, 0.0436],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,096][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0234, 0.7601, 0.0612, 0.0894, 0.0188, 0.0208, 0.0263],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,097][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0525, 0.2499, 0.0636, 0.3430, 0.0810, 0.1357, 0.0742],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,099][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([9.6166e-01, 1.2351e-04, 1.1999e-06, 7.4644e-04, 6.4047e-06, 2.5238e-03,
        3.4943e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,103][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0014, 0.2499, 0.3472, 0.1066, 0.0619, 0.1459, 0.0870],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,104][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0260, 0.8650, 0.0602, 0.0251, 0.0123, 0.0043, 0.0071],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,105][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0248, 0.6617, 0.1319, 0.1550, 0.0068, 0.0107, 0.0092],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,106][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([4.8059e-01, 3.7755e-04, 2.9137e-06, 1.1555e-02, 3.5968e-05, 1.5468e-02,
        4.9197e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,107][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0142, 0.2466, 0.7026, 0.0105, 0.0085, 0.0167, 0.0009],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,108][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0061, 0.6483, 0.0877, 0.2366, 0.0137, 0.0037, 0.0038],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,110][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0210, 0.6591, 0.1062, 0.0475, 0.0885, 0.0332, 0.0362, 0.0083],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,115][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0226, 0.3237, 0.3144, 0.0848, 0.1899, 0.0119, 0.0494, 0.0034],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,115][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([7.8383e-02, 4.7084e-01, 2.5227e-01, 1.0688e-01, 6.8478e-02, 5.2673e-03,
        1.7748e-02, 1.3591e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,116][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.1135, 0.4707, 0.1444, 0.1520, 0.0543, 0.0184, 0.0437, 0.0029],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,117][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.4623, 0.0378, 0.1729, 0.1968, 0.0774, 0.0314, 0.0123, 0.0091],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,118][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([9.9567e-01, 8.5549e-04, 3.8188e-05, 9.7753e-04, 3.0035e-05, 3.7157e-04,
        1.6683e-03, 3.8667e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,118][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0701, 0.5306, 0.1980, 0.0713, 0.0733, 0.0224, 0.0181, 0.0162],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,122][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.6523, 0.1719, 0.0525, 0.0475, 0.0406, 0.0107, 0.0180, 0.0065],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,124][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([2.7066e-01, 4.4294e-01, 1.3176e-01, 1.4010e-01, 9.3061e-03, 1.4324e-03,
        3.6742e-03, 1.2579e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,126][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([9.4156e-01, 1.4921e-02, 2.1517e-04, 2.7071e-02, 2.3444e-04, 4.7608e-03,
        1.0075e-02, 1.1612e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,127][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0439, 0.4952, 0.3738, 0.0434, 0.0294, 0.0070, 0.0036, 0.0038],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,127][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([4.6819e-01, 5.1862e-01, 9.8834e-03, 3.1728e-03, 9.6261e-05, 1.6264e-06,
        3.8054e-05, 5.5984e-09], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,128][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0062, 0.6076, 0.1257, 0.0528, 0.0214, 0.1145, 0.0539, 0.0127, 0.0052],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,129][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([1.2073e-04, 1.3846e-01, 1.5423e-01, 1.1010e-01, 1.6048e-01, 1.4780e-01,
        2.1273e-01, 5.3138e-02, 2.2946e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,131][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0170, 0.3381, 0.3096, 0.0697, 0.0994, 0.0706, 0.0506, 0.0206, 0.0243],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,136][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0340, 0.6471, 0.0668, 0.0924, 0.0328, 0.0413, 0.0458, 0.0017, 0.0381],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,137][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0304, 0.3393, 0.0444, 0.1874, 0.0562, 0.1369, 0.0933, 0.0438, 0.0684],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,138][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([8.9276e-01, 3.4189e-05, 3.2069e-07, 3.0116e-04, 2.9428e-06, 1.6398e-03,
        3.4929e-02, 3.5047e-02, 3.5286e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,138][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0013, 0.2507, 0.2302, 0.0889, 0.0723, 0.1919, 0.0966, 0.0337, 0.0344],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,139][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([1.4922e-02, 8.8732e-01, 5.1425e-02, 1.7246e-02, 1.2509e-02, 4.0172e-03,
        4.1011e-03, 4.3015e-04, 8.0260e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,140][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([9.6584e-03, 6.6130e-01, 1.7234e-01, 8.3857e-02, 1.1709e-02, 1.8598e-02,
        1.4193e-02, 4.8901e-04, 2.7856e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,142][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([1.4983e-01, 4.6143e-05, 1.9444e-07, 1.8135e-03, 4.4431e-06, 6.5319e-03,
        3.8473e-01, 3.2680e-02, 4.2436e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,145][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([1.2314e-02, 3.5891e-01, 5.5378e-01, 8.1247e-03, 8.6329e-03, 1.8845e-02,
        6.8358e-04, 3.8633e-02, 7.0047e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,150][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0028, 0.4723, 0.0781, 0.3439, 0.0356, 0.0219, 0.0089, 0.0033, 0.0332],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,151][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0066, 0.6655, 0.0944, 0.0475, 0.0323, 0.0745, 0.0435, 0.0057, 0.0127,
        0.0174], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,152][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0010, 0.0959, 0.3552, 0.0858, 0.1683, 0.0557, 0.1450, 0.0126, 0.0435,
        0.0369], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,153][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0227, 0.3572, 0.3175, 0.0904, 0.0934, 0.0305, 0.0330, 0.0037, 0.0374,
        0.0142], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,153][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0404, 0.6739, 0.0460, 0.0818, 0.0225, 0.0335, 0.0343, 0.0033, 0.0566,
        0.0078], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,156][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.2432, 0.1404, 0.0443, 0.2459, 0.0555, 0.0779, 0.0378, 0.0318, 0.0577,
        0.0654], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,158][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([9.2118e-01, 2.0329e-04, 2.5294e-06, 6.5496e-04, 6.0680e-06, 1.6150e-03,
        2.0505e-02, 7.6860e-03, 2.4648e-02, 2.3498e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,161][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0058, 0.3290, 0.3166, 0.0727, 0.0759, 0.0731, 0.0439, 0.0143, 0.0338,
        0.0349], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,162][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.1301, 0.7374, 0.0459, 0.0228, 0.0158, 0.0067, 0.0075, 0.0009, 0.0276,
        0.0054], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,163][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([5.9726e-02, 6.2650e-01, 1.4718e-01, 1.0994e-01, 6.9543e-03, 6.8757e-03,
        6.2429e-03, 3.6923e-04, 3.3433e-02, 2.7803e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,164][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([5.4267e-01, 3.7987e-04, 1.4488e-06, 7.5915e-03, 1.0732e-05, 5.7250e-03,
        1.3438e-01, 1.1497e-02, 1.4297e-01, 1.5477e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,164][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([2.6184e-02, 2.5938e-01, 6.5946e-01, 1.1790e-02, 1.2569e-02, 1.1052e-02,
        1.2643e-03, 1.4990e-02, 4.6034e-04, 2.8512e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,166][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([4.7414e-02, 7.7739e-01, 8.2511e-02, 6.8703e-02, 5.6045e-03, 8.2541e-04,
        1.3363e-03, 5.3120e-05, 1.5167e-02, 9.9684e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,170][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0049, 0.8199, 0.0561, 0.0318, 0.0188, 0.0331, 0.0168, 0.0022, 0.0039,
        0.0074, 0.0052], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,172][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0010, 0.2597, 0.3160, 0.1061, 0.1431, 0.0245, 0.0796, 0.0031, 0.0371,
        0.0185, 0.0113], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,173][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0167, 0.4466, 0.3233, 0.0862, 0.0578, 0.0167, 0.0157, 0.0014, 0.0234,
        0.0060, 0.0063], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,174][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0420, 0.7489, 0.0364, 0.0831, 0.0146, 0.0174, 0.0161, 0.0012, 0.0340,
        0.0026, 0.0036], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,175][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.1674, 0.1842, 0.0558, 0.2850, 0.0490, 0.0983, 0.0203, 0.0388, 0.0213,
        0.0294, 0.0505], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,175][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([9.3143e-01, 1.7103e-04, 1.5689e-06, 4.9573e-04, 3.8650e-06, 1.0066e-03,
        1.0259e-02, 5.2034e-03, 1.2291e-02, 1.2059e-02, 2.7083e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,179][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0038, 0.5054, 0.2367, 0.0758, 0.0432, 0.0480, 0.0256, 0.0076, 0.0276,
        0.0162, 0.0101], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,183][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0701, 0.8395, 0.0315, 0.0218, 0.0105, 0.0055, 0.0033, 0.0008, 0.0120,
        0.0021, 0.0027], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,183][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([4.7879e-02, 6.7287e-01, 1.1737e-01, 1.2053e-01, 6.4116e-03, 3.4934e-03,
        3.8917e-03, 1.4290e-04, 2.4383e-02, 1.2367e-03, 1.7908e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,184][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([6.4546e-01, 5.1457e-04, 1.2931e-06, 5.8820e-03, 8.6744e-06, 3.1663e-03,
        6.1421e-02, 6.4413e-03, 6.8409e-02, 7.3706e-02, 1.3499e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,185][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([1.5064e-02, 4.6120e-01, 4.9131e-01, 1.2453e-02, 7.7329e-03, 5.4174e-03,
        6.7203e-04, 4.0657e-03, 3.0141e-04, 1.0779e-03, 6.9860e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,186][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([2.4659e-02, 8.6269e-01, 5.8333e-02, 4.5724e-02, 2.6215e-03, 2.7117e-04,
        4.5508e-04, 8.7923e-06, 4.7707e-03, 2.2589e-04, 2.4167e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,188][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0029, 0.6965, 0.1158, 0.0415, 0.0147, 0.0570, 0.0234, 0.0050, 0.0031,
        0.0079, 0.0055, 0.0266], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,191][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([1.4808e-04, 1.4687e-01, 2.8365e-01, 1.1167e-01, 1.4097e-01, 6.1630e-02,
        1.1748e-01, 1.2846e-02, 2.2848e-02, 2.0584e-02, 1.3850e-02, 6.7457e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,194][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0087, 0.3076, 0.3953, 0.0591, 0.0988, 0.0331, 0.0249, 0.0074, 0.0167,
        0.0107, 0.0095, 0.0282], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,194][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0166, 0.7502, 0.0627, 0.0730, 0.0197, 0.0238, 0.0154, 0.0013, 0.0170,
        0.0028, 0.0025, 0.0152], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,195][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0380, 0.4133, 0.0475, 0.2109, 0.0309, 0.0744, 0.0200, 0.0258, 0.0201,
        0.0211, 0.0360, 0.0622], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,196][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([6.4206e-01, 6.5011e-04, 3.4279e-06, 8.3393e-04, 5.8441e-06, 1.7026e-03,
        4.1384e-03, 1.1008e-02, 3.5539e-03, 4.4111e-03, 1.1501e-02, 3.2013e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,197][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0006, 0.2301, 0.3455, 0.0653, 0.0621, 0.1003, 0.0561, 0.0088, 0.0214,
        0.0259, 0.0152, 0.0689], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,199][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([1.7034e-02, 8.4541e-01, 5.9308e-02, 2.2124e-02, 1.4447e-02, 4.5980e-03,
        3.7954e-03, 3.0295e-04, 1.0307e-02, 1.0516e-03, 1.1579e-03, 2.0460e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,201][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([4.7943e-03, 7.3560e-01, 1.2330e-01, 9.4158e-02, 4.6175e-03, 6.0704e-03,
        4.6220e-03, 1.3281e-04, 1.5973e-02, 9.0577e-04, 1.2064e-03, 8.6200e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,204][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([1.4086e-01, 6.2342e-04, 1.5932e-06, 2.6799e-03, 5.9316e-06, 1.8773e-03,
        1.0052e-02, 3.7320e-03, 6.5078e-03, 9.4782e-03, 1.6257e-02, 8.0792e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,205][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([6.2059e-03, 2.7003e-01, 6.9263e-01, 5.5729e-03, 7.1413e-03, 6.6192e-03,
        4.0358e-04, 9.4850e-03, 6.0731e-05, 1.0830e-03, 5.5465e-04, 2.1215e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,206][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0042, 0.4729, 0.2111, 0.2176, 0.0380, 0.0081, 0.0051, 0.0009, 0.0195,
        0.0046, 0.0050, 0.0131], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,207][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.0039, 0.6309, 0.1480, 0.0387, 0.0151, 0.0650, 0.0200, 0.0054, 0.0036,
        0.0101, 0.0092, 0.0305, 0.0197], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,208][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([1.7125e-04, 6.5079e-02, 1.9844e-01, 1.0225e-01, 1.0309e-01, 1.4317e-01,
        1.6685e-01, 2.7404e-02, 3.7391e-02, 2.8654e-02, 2.9160e-02, 7.2074e-02,
        2.6275e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,211][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.0091, 0.3224, 0.2922, 0.0505, 0.0907, 0.0716, 0.0384, 0.0271, 0.0176,
        0.0252, 0.0171, 0.0243, 0.0136], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,215][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.0204, 0.6954, 0.0401, 0.0807, 0.0264, 0.0513, 0.0231, 0.0052, 0.0178,
        0.0040, 0.0039, 0.0168, 0.0150], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,216][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0418, 0.4133, 0.0323, 0.1482, 0.0216, 0.0847, 0.0149, 0.0502, 0.0148,
        0.0233, 0.0392, 0.0575, 0.0583], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,217][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([2.8080e-01, 3.2986e-04, 2.1748e-06, 4.4999e-04, 3.3036e-06, 1.3060e-03,
        3.3350e-03, 1.4108e-02, 1.5973e-03, 4.2232e-03, 1.1310e-02, 2.2348e-01,
        4.5906e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,218][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.0011, 0.1294, 0.3575, 0.0514, 0.0934, 0.1277, 0.0719, 0.0110, 0.0211,
        0.0339, 0.0172, 0.0624, 0.0220], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,218][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0221, 0.8462, 0.0583, 0.0155, 0.0180, 0.0065, 0.0029, 0.0011, 0.0049,
        0.0017, 0.0011, 0.0095, 0.0121], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,222][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.0104, 0.5675, 0.1740, 0.0762, 0.0087, 0.0227, 0.0173, 0.0009, 0.0425,
        0.0055, 0.0080, 0.0315, 0.0350], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,226][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([4.3468e-02, 2.0775e-04, 3.5841e-07, 7.8511e-04, 1.2794e-06, 7.3545e-04,
        3.3676e-03, 2.1440e-03, 2.4115e-03, 2.9745e-03, 6.5288e-03, 2.9355e-01,
        6.4383e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,226][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([8.5398e-03, 1.8470e-01, 7.4984e-01, 6.8217e-03, 1.0237e-02, 1.3507e-02,
        7.6783e-04, 2.0156e-02, 9.9817e-05, 2.0287e-03, 1.1739e-03, 2.5676e-04,
        1.8634e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,227][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.0028, 0.3871, 0.2342, 0.2206, 0.0304, 0.0191, 0.0060, 0.0055, 0.0262,
        0.0100, 0.0077, 0.0163, 0.0340], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,228][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0021, 0.7404, 0.0996, 0.0355, 0.0095, 0.0574, 0.0150, 0.0062, 0.0010,
        0.0040, 0.0038, 0.0135, 0.0075, 0.0045], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,229][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([1.5705e-04, 2.0364e-01, 2.1183e-01, 1.0897e-01, 1.0771e-01, 1.0381e-01,
        1.1285e-01, 4.8837e-02, 1.1817e-02, 2.0685e-02, 1.1626e-02, 3.3837e-02,
        1.5886e-02, 8.3489e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,233][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0095, 0.3499, 0.3444, 0.0580, 0.0861, 0.0409, 0.0222, 0.0180, 0.0101,
        0.0126, 0.0079, 0.0205, 0.0133, 0.0065], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,236][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([1.3670e-02, 8.3904e-01, 4.0984e-02, 4.6753e-02, 1.3928e-02, 1.5398e-02,
        7.9338e-03, 7.0886e-04, 6.0232e-03, 7.8180e-04, 6.0108e-04, 4.4693e-03,
        5.4257e-03, 4.2868e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,237][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0307, 0.4731, 0.0403, 0.1688, 0.0241, 0.0788, 0.0159, 0.0230, 0.0092,
        0.0136, 0.0193, 0.0421, 0.0489, 0.0122], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,238][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([4.2226e-01, 4.8224e-04, 1.7118e-06, 5.2090e-04, 2.1089e-06, 1.0843e-03,
        4.4256e-04, 9.4896e-03, 1.7364e-04, 9.4701e-04, 2.1729e-03, 3.9393e-02,
        6.5658e-02, 4.5738e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,239][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0008, 0.3240, 0.2951, 0.0670, 0.0406, 0.1134, 0.0437, 0.0159, 0.0093,
        0.0185, 0.0109, 0.0447, 0.0071, 0.0090], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,240][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([5.8865e-03, 9.0795e-01, 4.5940e-02, 1.0293e-02, 8.8383e-03, 1.2754e-03,
        1.2514e-03, 8.2210e-05, 3.2472e-03, 3.2523e-04, 2.2609e-04, 5.5936e-03,
        2.9688e-03, 6.1262e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,242][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([3.1920e-03, 7.3142e-01, 1.4141e-01, 6.2666e-02, 5.9347e-03, 1.4266e-02,
        7.2035e-03, 5.5255e-04, 1.0637e-02, 1.8952e-03, 2.2657e-03, 7.3168e-03,
        4.5152e-03, 6.7225e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,244][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([8.3299e-02, 4.9925e-04, 5.2426e-07, 1.4143e-03, 1.1054e-06, 6.4120e-04,
        4.0113e-04, 1.0700e-03, 2.4266e-04, 3.9899e-04, 7.4397e-04, 3.6037e-02,
        5.6932e-02, 8.1832e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,247][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([1.4514e-02, 3.7959e-01, 5.7093e-01, 4.8585e-03, 4.6946e-03, 6.7374e-03,
        1.9521e-04, 1.6728e-02, 2.3821e-05, 6.5526e-04, 3.3822e-04, 1.0048e-04,
        6.1036e-04, 3.1379e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,248][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0015, 0.3783, 0.1198, 0.3400, 0.0312, 0.0089, 0.0038, 0.0012, 0.0146,
        0.0034, 0.0028, 0.0101, 0.0109, 0.0735], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,249][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0013, 0.3936, 0.2236, 0.0334, 0.0393, 0.1131, 0.0550, 0.0086, 0.0066,
        0.0218, 0.0141, 0.0330, 0.0252, 0.0095, 0.0217], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,250][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([7.3779e-05, 6.5552e-02, 1.2443e-01, 8.9045e-02, 1.0578e-01, 2.0867e-01,
        1.2965e-01, 1.1111e-01, 1.4464e-02, 3.0736e-02, 3.3111e-02, 4.4839e-02,
        1.2214e-02, 8.4511e-03, 2.1871e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,251][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.0036, 0.1548, 0.2821, 0.0757, 0.1245, 0.0932, 0.0332, 0.0595, 0.0168,
        0.0389, 0.0283, 0.0316, 0.0158, 0.0067, 0.0353], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,254][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.0102, 0.5456, 0.0576, 0.0871, 0.0414, 0.0706, 0.0435, 0.0069, 0.0347,
        0.0061, 0.0073, 0.0265, 0.0192, 0.0143, 0.0288], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,258][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0094, 0.2019, 0.0402, 0.1087, 0.0323, 0.0975, 0.0368, 0.0698, 0.0266,
        0.0617, 0.0582, 0.1016, 0.1066, 0.0181, 0.0308], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,259][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([9.7730e-04, 1.5267e-06, 1.1760e-07, 7.5048e-06, 3.3911e-07, 5.8716e-05,
        2.4472e-03, 6.1285e-04, 1.6157e-03, 2.9481e-03, 6.7041e-03, 7.6105e-02,
        2.3159e-01, 6.7548e-01, 1.4504e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,259][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0004, 0.1380, 0.3096, 0.0527, 0.0648, 0.1248, 0.0594, 0.0257, 0.0152,
        0.0428, 0.0334, 0.0618, 0.0183, 0.0103, 0.0429], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,260][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0223, 0.7271, 0.0769, 0.0172, 0.0252, 0.0097, 0.0091, 0.0014, 0.0235,
        0.0043, 0.0027, 0.0260, 0.0179, 0.0181, 0.0187], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,261][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.0047, 0.6706, 0.1274, 0.0735, 0.0094, 0.0197, 0.0110, 0.0016, 0.0217,
        0.0056, 0.0057, 0.0137, 0.0141, 0.0143, 0.0069], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,263][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([5.2451e-05, 2.8282e-07, 8.1861e-09, 6.3828e-06, 6.0858e-08, 1.1564e-05,
        1.4338e-03, 4.4348e-05, 1.3669e-03, 1.1866e-03, 2.3093e-03, 6.7420e-02,
        1.6073e-01, 7.6517e-01, 2.6687e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,266][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([6.2012e-03, 2.4752e-01, 6.6822e-01, 5.9358e-03, 1.4346e-02, 1.2234e-02,
        6.7673e-04, 3.8636e-02, 9.7151e-05, 2.7239e-03, 1.3350e-03, 2.4177e-04,
        1.1013e-03, 7.5426e-05, 6.5565e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,269][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0006, 0.2679, 0.1264, 0.2930, 0.0523, 0.0576, 0.0118, 0.0346, 0.0174,
        0.0242, 0.0248, 0.0200, 0.0142, 0.0328, 0.0224], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,269][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0045, 0.7329, 0.0847, 0.0315, 0.0264, 0.0173, 0.0137, 0.0017, 0.0046,
        0.0052, 0.0035, 0.0181, 0.0209, 0.0086, 0.0207, 0.0056],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,270][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0017, 0.3286, 0.1480, 0.0968, 0.0733, 0.0176, 0.0625, 0.0038, 0.0335,
        0.0160, 0.0116, 0.0511, 0.0489, 0.0422, 0.0579, 0.0063],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,271][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([1.2263e-02, 5.7060e-01, 1.9094e-01, 5.8557e-02, 4.2530e-02, 7.3965e-03,
        1.1161e-02, 4.2080e-04, 2.4546e-02, 3.5423e-03, 3.1881e-03, 1.9246e-02,
        2.1731e-02, 1.1867e-02, 2.0456e-02, 1.5598e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,272][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0144, 0.6661, 0.0521, 0.0671, 0.0166, 0.0142, 0.0147, 0.0012, 0.0343,
        0.0033, 0.0042, 0.0258, 0.0225, 0.0190, 0.0340, 0.0103],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,276][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1280, 0.2241, 0.1123, 0.2420, 0.0389, 0.0528, 0.0053, 0.0184, 0.0096,
        0.0111, 0.0120, 0.0180, 0.0501, 0.0237, 0.0262, 0.0276],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,279][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([3.5321e-01, 1.1769e-03, 1.4988e-05, 8.2915e-04, 9.8165e-06, 6.1763e-04,
        6.7275e-04, 8.9956e-04, 7.6775e-04, 5.4661e-04, 1.1758e-03, 3.7658e-02,
        1.4501e-01, 3.3680e-01, 3.3764e-03, 1.1724e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,280][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0024, 0.5058, 0.1913, 0.0392, 0.0529, 0.0154, 0.0154, 0.0016, 0.0255,
        0.0094, 0.0051, 0.0356, 0.0246, 0.0168, 0.0505, 0.0085],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,281][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0868, 0.6199, 0.0737, 0.0259, 0.0215, 0.0060, 0.0081, 0.0008, 0.0454,
        0.0043, 0.0043, 0.0323, 0.0180, 0.0216, 0.0263, 0.0052],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,282][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([7.9161e-03, 6.7006e-01, 1.3988e-01, 7.9053e-02, 5.4350e-03, 1.7742e-03,
        2.9154e-03, 3.9376e-05, 2.1597e-02, 8.6077e-04, 1.2464e-03, 1.4843e-02,
        1.6642e-02, 2.8891e-02, 4.9931e-03, 3.8608e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,283][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([8.0380e-02, 2.3945e-03, 3.4095e-06, 1.8691e-03, 3.9936e-06, 5.4120e-04,
        4.8022e-04, 2.6693e-04, 2.8452e-04, 4.4490e-04, 6.7797e-04, 4.2180e-02,
        1.0490e-01, 5.7527e-01, 1.1156e-03, 1.8918e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,286][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0107, 0.4180, 0.5028, 0.0176, 0.0188, 0.0061, 0.0012, 0.0049, 0.0010,
        0.0024, 0.0014, 0.0012, 0.0052, 0.0010, 0.0023, 0.0054],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,290][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([4.2063e-02, 8.5775e-01, 4.4799e-02, 2.9851e-02, 1.4180e-03, 9.2298e-05,
        2.7462e-04, 9.6323e-07, 2.9961e-03, 5.3296e-05, 4.9650e-05, 8.8550e-04,
        6.8294e-03, 8.5439e-03, 4.2766e-03, 1.1229e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,291][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0020, 0.7861, 0.0849, 0.0307, 0.0074, 0.0295, 0.0093, 0.0030, 0.0013,
        0.0022, 0.0019, 0.0089, 0.0058, 0.0023, 0.0030, 0.0044, 0.0174],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,292][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0003, 0.2548, 0.1962, 0.1250, 0.0881, 0.0550, 0.0795, 0.0121, 0.0181,
        0.0140, 0.0085, 0.0399, 0.0220, 0.0119, 0.0192, 0.0101, 0.0452],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,293][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0109, 0.4464, 0.2761, 0.0637, 0.0509, 0.0246, 0.0168, 0.0046, 0.0121,
        0.0082, 0.0050, 0.0202, 0.0151, 0.0059, 0.0182, 0.0066, 0.0146],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,294][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.0183e-02, 8.4662e-01, 2.5156e-02, 5.1190e-02, 6.1120e-03, 1.3325e-02,
        7.1422e-03, 6.7980e-04, 7.4095e-03, 8.5878e-04, 1.0294e-03, 5.5790e-03,
        5.6556e-03, 4.4518e-03, 4.0912e-03, 3.6455e-03, 6.8754e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,297][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0523, 0.5158, 0.0478, 0.1671, 0.0185, 0.0517, 0.0045, 0.0165, 0.0045,
        0.0061, 0.0093, 0.0130, 0.0325, 0.0067, 0.0071, 0.0256, 0.0210],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,301][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.2549e-01, 6.3601e-04, 2.2697e-06, 3.7985e-04, 1.6211e-06, 4.2096e-04,
        2.1293e-04, 1.1081e-03, 1.3291e-04, 2.0143e-04, 5.1046e-04, 1.8409e-02,
        4.7693e-02, 1.6891e-01, 6.8086e-04, 1.2925e-01, 5.0597e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,302][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0008, 0.4439, 0.2544, 0.0540, 0.0365, 0.0463, 0.0204, 0.0042, 0.0117,
        0.0096, 0.0055, 0.0304, 0.0085, 0.0068, 0.0177, 0.0128, 0.0366],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,303][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([1.6224e-02, 8.4004e-01, 7.1855e-02, 2.1471e-02, 8.4636e-03, 2.8199e-03,
        2.1736e-03, 1.5788e-04, 7.1261e-03, 4.7045e-04, 5.1791e-04, 8.7703e-03,
        4.1513e-03, 6.1649e-03, 3.8977e-03, 9.4682e-04, 4.7518e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,303][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.2136e-02, 6.9396e-01, 1.1290e-01, 9.7631e-02, 5.9397e-03, 8.0971e-03,
        4.9502e-03, 2.8175e-04, 1.3199e-02, 1.4911e-03, 2.0570e-03, 1.0964e-02,
        6.5361e-03, 1.0168e-02, 3.0407e-03, 6.1053e-03, 1.0537e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,304][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.4520e-02, 6.9600e-04, 9.1698e-07, 8.4537e-04, 8.7011e-07, 3.3752e-04,
        1.8284e-04, 2.6024e-04, 8.8883e-05, 1.6943e-04, 3.2235e-04, 1.6608e-02,
        3.9786e-02, 2.6741e-01, 2.3691e-04, 2.5014e-01, 3.9840e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,306][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([5.0742e-03, 4.2977e-01, 5.2473e-01, 9.9564e-03, 7.1347e-03, 6.3685e-03,
        3.9553e-04, 6.8181e-03, 1.0216e-04, 9.1212e-04, 4.4221e-04, 2.4907e-04,
        1.1034e-03, 9.2499e-05, 3.2952e-04, 5.4854e-03, 1.0414e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,309][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([6.1037e-03, 6.4803e-01, 1.1611e-01, 1.3361e-01, 1.2661e-02, 2.7624e-03,
        1.7476e-03, 2.7279e-04, 1.0153e-02, 1.5418e-03, 1.3036e-03, 4.1876e-03,
        9.9147e-03, 2.4010e-02, 1.0513e-02, 4.2672e-03, 1.2804e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,311][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.0044, 0.6953, 0.0605, 0.0279, 0.0159, 0.0304, 0.0148, 0.0027, 0.0040,
        0.0055, 0.0042, 0.0213, 0.0165, 0.0047, 0.0166, 0.0101, 0.0281, 0.0372],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,312][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.0011, 0.1930, 0.1437, 0.1145, 0.1067, 0.0558, 0.0670, 0.0107, 0.0351,
        0.0168, 0.0128, 0.0487, 0.0339, 0.0167, 0.0584, 0.0170, 0.0338, 0.0342],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,313][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.0175, 0.5486, 0.1632, 0.0483, 0.0580, 0.0262, 0.0177, 0.0057, 0.0159,
        0.0086, 0.0065, 0.0182, 0.0094, 0.0051, 0.0236, 0.0066, 0.0092, 0.0118],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,314][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.0212, 0.7628, 0.0281, 0.0661, 0.0179, 0.0187, 0.0090, 0.0018, 0.0118,
        0.0018, 0.0019, 0.0080, 0.0062, 0.0050, 0.0147, 0.0076, 0.0076, 0.0097],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,317][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.0403, 0.3732, 0.0470, 0.1948, 0.0321, 0.0616, 0.0061, 0.0159, 0.0095,
        0.0092, 0.0101, 0.0293, 0.0315, 0.0121, 0.0170, 0.0387, 0.0418, 0.0296],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,319][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([5.7509e-02, 1.1055e-04, 3.8968e-07, 8.5414e-05, 3.6635e-07, 1.4452e-04,
        1.8852e-04, 4.9987e-04, 1.0261e-04, 1.8448e-04, 4.7106e-04, 1.6991e-02,
        5.2480e-02, 1.8297e-01, 3.8442e-04, 7.7952e-02, 4.7026e-01, 1.3966e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,322][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.0023, 0.3915, 0.1513, 0.0540, 0.0416, 0.0559, 0.0258, 0.0059, 0.0247,
        0.0150, 0.0091, 0.0448, 0.0227, 0.0094, 0.0376, 0.0208, 0.0475, 0.0401],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,323][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([3.5751e-02, 7.5085e-01, 7.9253e-02, 2.0081e-02, 1.7647e-02, 7.8552e-03,
        4.0629e-03, 6.1727e-04, 1.1278e-02, 1.8512e-03, 1.7017e-03, 1.3921e-02,
        8.7026e-03, 8.2849e-03, 1.2297e-02, 2.5416e-03, 5.1113e-03, 1.8194e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,324][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([2.3592e-02, 6.0697e-01, 1.5248e-01, 8.6216e-02, 1.0041e-02, 9.8770e-03,
        7.2883e-03, 3.2421e-04, 2.1615e-02, 1.9736e-03, 2.2778e-03, 1.4337e-02,
        1.1497e-02, 1.1291e-02, 5.8446e-03, 8.8949e-03, 1.1601e-02, 1.3879e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,325][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([1.1618e-02, 1.0842e-04, 8.2491e-08, 1.5551e-04, 1.1139e-07, 9.1237e-05,
        1.7096e-04, 2.1779e-04, 1.0339e-04, 1.5881e-04, 3.8590e-04, 1.6417e-02,
        5.2857e-02, 3.0640e-01, 1.2215e-04, 1.5413e-01, 3.9369e-01, 6.3373e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,326][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([1.2475e-02, 4.1876e-01, 4.9614e-01, 9.7624e-03, 1.2691e-02, 7.9782e-03,
        7.1899e-04, 9.1978e-03, 2.2291e-04, 1.7060e-03, 1.0104e-03, 4.2002e-04,
        2.4751e-03, 1.3817e-04, 1.0873e-03, 1.1081e-02, 1.4906e-03, 1.2642e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,329][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0094, 0.5360, 0.1528, 0.1327, 0.0232, 0.0052, 0.0039, 0.0006, 0.0157,
        0.0028, 0.0027, 0.0061, 0.0161, 0.0268, 0.0180, 0.0100, 0.0143, 0.0236],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,333][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0033, 0.7592, 0.0651, 0.0299, 0.0073, 0.0391, 0.0087, 0.0034, 0.0009,
        0.0025, 0.0024, 0.0112, 0.0088, 0.0029, 0.0044, 0.0066, 0.0216, 0.0205,
        0.0022], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,334][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0003, 0.1687, 0.1533, 0.0985, 0.0773, 0.0922, 0.1046, 0.0445, 0.0123,
        0.0212, 0.0106, 0.0376, 0.0242, 0.0090, 0.0179, 0.0208, 0.0504, 0.0404,
        0.0162], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,335][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0175, 0.4292, 0.2612, 0.0535, 0.0389, 0.0352, 0.0177, 0.0071, 0.0089,
        0.0070, 0.0062, 0.0234, 0.0169, 0.0066, 0.0238, 0.0100, 0.0153, 0.0171,
        0.0045], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,336][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.4434e-02, 8.5157e-01, 2.4685e-02, 4.0812e-02, 6.5278e-03, 1.6074e-02,
        6.4163e-03, 7.2887e-04, 5.2269e-03, 6.1421e-04, 5.4856e-04, 4.8128e-03,
        4.5558e-03, 3.6137e-03, 2.9808e-03, 2.8493e-03, 5.6488e-03, 6.2864e-03,
        1.6111e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,338][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0273, 0.4284, 0.0212, 0.1462, 0.0089, 0.0767, 0.0069, 0.0313, 0.0050,
        0.0077, 0.0223, 0.0293, 0.0332, 0.0078, 0.0046, 0.0607, 0.0397, 0.0336,
        0.0091], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,341][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.1216e-02, 2.5332e-05, 8.3026e-08, 2.8316e-05, 8.4259e-08, 6.4211e-05,
        8.7719e-05, 2.9677e-04, 3.5722e-05, 9.1282e-05, 2.5177e-04, 1.1591e-02,
        4.0502e-02, 1.6326e-01, 1.5383e-04, 6.9142e-02, 5.0053e-01, 1.4876e-01,
        4.3968e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,344][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0009, 0.3480, 0.1839, 0.0590, 0.0352, 0.0870, 0.0371, 0.0089, 0.0111,
        0.0159, 0.0084, 0.0421, 0.0082, 0.0077, 0.0178, 0.0201, 0.0583, 0.0318,
        0.0185], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,345][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([8.3056e-03, 8.5631e-01, 8.2048e-02, 1.4641e-02, 9.8536e-03, 1.8422e-03,
        1.3127e-03, 1.2094e-04, 2.8695e-03, 3.0569e-04, 2.1873e-04, 4.6783e-03,
        4.0909e-03, 4.6550e-03, 3.2664e-03, 6.8948e-04, 2.1729e-03, 1.3523e-03,
        1.2655e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,346][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([4.8546e-03, 7.2175e-01, 1.4530e-01, 5.0318e-02, 6.2554e-03, 7.6981e-03,
        4.9854e-03, 1.7690e-04, 8.5372e-03, 1.2092e-03, 1.3945e-03, 6.6610e-03,
        5.5636e-03, 6.8374e-03, 2.2557e-03, 3.3757e-03, 7.5129e-03, 7.8584e-03,
        7.4567e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,346][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.4625e-03, 1.8632e-05, 1.0041e-08, 4.6974e-05, 2.0197e-08, 3.7501e-05,
        9.7546e-05, 4.3029e-05, 5.0593e-05, 7.2697e-05, 2.0585e-04, 1.4184e-02,
        2.4544e-02, 2.7678e-01, 3.6849e-05, 1.1061e-01, 4.6703e-01, 5.0651e-02,
        5.4128e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,348][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.4065e-02, 4.4826e-01, 4.6577e-01, 8.9404e-03, 6.0958e-03, 1.0903e-02,
        3.3413e-04, 2.6788e-02, 3.9436e-05, 1.1494e-03, 6.3513e-04, 1.6703e-04,
        9.4608e-04, 5.1033e-05, 2.2877e-04, 9.0593e-03, 9.2763e-04, 5.5766e-03,
        6.5262e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,351][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0022, 0.4408, 0.0859, 0.2255, 0.0233, 0.0112, 0.0036, 0.0024, 0.0113,
        0.0051, 0.0054, 0.0081, 0.0088, 0.0434, 0.0167, 0.0168, 0.0240, 0.0116,
        0.0539], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,355][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:01,357][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[3095],
        [  38],
        [ 350],
        [  40],
        [ 166],
        [  38],
        [ 163],
        [  55],
        [  96],
        [  91],
        [ 125],
        [ 102],
        [  85],
        [  22],
        [  13],
        [  35],
        [  20],
        [  64],
        [   7]], device='cuda:0')
[2024-07-24 10:18:01,358][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[2771],
        [  30],
        [ 317],
        [  47],
        [ 172],
        [  60],
        [ 173],
        [  68],
        [ 100],
        [ 129],
        [ 135],
        [ 114],
        [  84],
        [  33],
        [  11],
        [  47],
        [  32],
        [  75],
        [  10]], device='cuda:0')
[2024-07-24 10:18:01,360][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 708],
        [7831],
        [   1],
        [   2],
        [  54],
        [ 582],
        [1227],
        [1952],
        [1388],
        [2716],
        [1960],
        [3039],
        [2068],
        [1803],
        [1891],
        [2563],
        [3494],
        [1967],
        [1943]], device='cuda:0')
[2024-07-24 10:18:01,364][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[18505],
        [39486],
        [49150],
        [48061],
        [46326],
        [46931],
        [46142],
        [46603],
        [44437],
        [46981],
        [46602],
        [46262],
        [45012],
        [45305],
        [43206],
        [44313],
        [45124],
        [43973],
        [44031]], device='cuda:0')
[2024-07-24 10:18:01,367][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[11104],
        [11462],
        [49353],
        [45599],
        [45814],
        [41847],
        [39083],
        [39402],
        [30236],
        [28273],
        [27515],
        [24264],
        [21012],
        [22888],
        [19949],
        [22435],
        [20146],
        [19271],
        [19652]], device='cuda:0')
[2024-07-24 10:18:01,368][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[23065],
        [26684],
        [38674],
        [40125],
        [36981],
        [33621],
        [31195],
        [38102],
        [31760],
        [30592],
        [29944],
        [31570],
        [29730],
        [29790],
        [31652],
        [32031],
        [28965],
        [29648],
        [28740]], device='cuda:0')
[2024-07-24 10:18:01,370][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[32790],
        [47576],
        [48682],
        [48427],
        [45631],
        [47270],
        [47314],
        [47722],
        [47329],
        [47058],
        [47512],
        [47603],
        [47196],
        [47438],
        [45583],
        [47601],
        [47666],
        [47227],
        [47120]], device='cuda:0')
[2024-07-24 10:18:01,372][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 5595],
        [ 7716],
        [ 5511],
        [ 7524],
        [ 6001],
        [ 8028],
        [ 5220],
        [ 5542],
        [ 5964],
        [ 5416],
        [ 5520],
        [ 9760],
        [13096],
        [13376],
        [14892],
        [14313],
        [13781],
        [13360],
        [13488]], device='cuda:0')
[2024-07-24 10:18:01,376][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[15125],
        [16913],
        [40572],
        [37265],
        [31126],
        [25403],
        [25453],
        [22056],
        [20310],
        [25135],
        [22696],
        [25679],
        [25324],
        [23922],
        [23146],
        [21564],
        [23872],
        [20611],
        [21511]], device='cuda:0')
[2024-07-24 10:18:01,379][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[44895],
        [27530],
        [ 3153],
        [ 8274],
        [13146],
        [14837],
        [14100],
        [11242],
        [15450],
        [16090],
        [18134],
        [14602],
        [14774],
        [16347],
        [12411],
        [12534],
        [12767],
        [11824],
        [11647]], device='cuda:0')
[2024-07-24 10:18:01,380][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[39402],
        [24659],
        [25354],
        [25949],
        [26323],
        [25737],
        [26209],
        [28126],
        [25570],
        [25766],
        [25702],
        [25255],
        [24831],
        [25192],
        [25087],
        [24503],
        [25100],
        [24820],
        [24759]], device='cuda:0')
[2024-07-24 10:18:01,382][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[30061],
        [16559],
        [23149],
        [ 6745],
        [ 8492],
        [ 8921],
        [ 8634],
        [27123],
        [ 3703],
        [11773],
        [15156],
        [11023],
        [14512],
        [14564],
        [14091],
        [12644],
        [14677],
        [14577],
        [16030]], device='cuda:0')
[2024-07-24 10:18:01,384][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[18239],
        [18916],
        [49787],
        [49610],
        [49385],
        [48583],
        [49102],
        [43089],
        [47711],
        [48915],
        [46609],
        [49032],
        [49316],
        [47990],
        [48891],
        [46751],
        [47161],
        [46603],
        [45936]], device='cuda:0')
[2024-07-24 10:18:01,387][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[24254],
        [13343],
        [33321],
        [17777],
        [19215],
        [15500],
        [16319],
        [15245],
        [16945],
        [16032],
        [15028],
        [22015],
        [23614],
        [19541],
        [21285],
        [14824],
        [17989],
        [20710],
        [19096]], device='cuda:0')
[2024-07-24 10:18:01,390][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[12030],
        [10795],
        [10339],
        [11232],
        [ 9378],
        [ 9676],
        [10714],
        [10239],
        [10942],
        [ 9962],
        [10767],
        [10292],
        [11386],
        [11203],
        [10699],
        [10414],
        [11875],
        [11293],
        [11671]], device='cuda:0')
[2024-07-24 10:18:01,392][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[20054],
        [47010],
        [47551],
        [48173],
        [47544],
        [47980],
        [48187],
        [47803],
        [48107],
        [47993],
        [47616],
        [47960],
        [48020],
        [47862],
        [47913],
        [47678],
        [47734],
        [47573],
        [47628]], device='cuda:0')
[2024-07-24 10:18:01,393][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[36241],
        [23466],
        [18497],
        [21845],
        [21181],
        [22254],
        [22534],
        [23012],
        [22005],
        [23027],
        [23687],
        [23542],
        [23958],
        [23455],
        [21649],
        [26508],
        [24504],
        [25948],
        [24514]], device='cuda:0')
[2024-07-24 10:18:01,396][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[39229],
        [24458],
        [10262],
        [10889],
        [17093],
        [16043],
        [15236],
        [15879],
        [17066],
        [16229],
        [14952],
        [15489],
        [18243],
        [16143],
        [22290],
        [18234],
        [16467],
        [20034],
        [17163]], device='cuda:0')
[2024-07-24 10:18:01,399][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[11099],
        [11589],
        [ 9743],
        [ 7776],
        [ 7605],
        [ 8728],
        [ 8795],
        [ 6909],
        [ 7760],
        [ 7972],
        [ 8753],
        [ 8588],
        [ 8025],
        [ 9548],
        [ 6529],
        [ 7442],
        [ 9531],
        [ 8619],
        [ 9620]], device='cuda:0')
[2024-07-24 10:18:01,402][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[17666],
        [13238],
        [ 3413],
        [ 7480],
        [ 8529],
        [ 7364],
        [10381],
        [ 5301],
        [11616],
        [12484],
        [11151],
        [11740],
        [12900],
        [12248],
        [15409],
        [10563],
        [11784],
        [12384],
        [13018]], device='cuda:0')
[2024-07-24 10:18:01,404][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[28344],
        [35923],
        [29469],
        [33685],
        [29709],
        [36109],
        [26688],
        [28549],
        [30861],
        [29766],
        [30323],
        [30892],
        [33487],
        [31314],
        [31081],
        [33495],
        [29356],
        [30508],
        [30444]], device='cuda:0')
[2024-07-24 10:18:01,405][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[14660],
        [20635],
        [14485],
        [13576],
        [13973],
        [16413],
        [17008],
        [18368],
        [19521],
        [17339],
        [18501],
        [18238],
        [18399],
        [18367],
        [19423],
        [19941],
        [18982],
        [21104],
        [20772]], device='cuda:0')
[2024-07-24 10:18:01,407][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[26124],
        [24558],
        [23823],
        [24053],
        [24826],
        [24319],
        [24546],
        [24476],
        [24501],
        [23919],
        [24450],
        [24160],
        [24195],
        [24512],
        [22971],
        [22108],
        [24025],
        [23144],
        [24102]], device='cuda:0')
[2024-07-24 10:18:01,411][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 9946],
        [39681],
        [20702],
        [25462],
        [29399],
        [30734],
        [34109],
        [29230],
        [31780],
        [31473],
        [33536],
        [34535],
        [28159],
        [34262],
        [32690],
        [31811],
        [33704],
        [30232],
        [33547]], device='cuda:0')
[2024-07-24 10:18:01,414][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[28795],
        [26907],
        [33219],
        [31155],
        [34427],
        [31433],
        [38895],
        [31758],
        [35330],
        [38201],
        [36914],
        [30831],
        [25547],
        [35417],
        [34029],
        [33524],
        [28980],
        [30783],
        [30893]], device='cuda:0')
[2024-07-24 10:18:01,415][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[39914],
        [30679],
        [38901],
        [39221],
        [39353],
        [39046],
        [39234],
        [36900],
        [38232],
        [39075],
        [37549],
        [39028],
        [39362],
        [38215],
        [39041],
        [38130],
        [37926],
        [38074],
        [37479]], device='cuda:0')
[2024-07-24 10:18:01,417][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[16362],
        [19312],
        [11362],
        [21090],
        [21241],
        [19188],
        [22421],
        [17918],
        [27236],
        [18945],
        [18909],
        [21331],
        [22686],
        [26730],
        [29821],
        [18986],
        [20520],
        [20849],
        [25812]], device='cuda:0')
[2024-07-24 10:18:01,419][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 5405],
        [ 4255],
        [11801],
        [ 7818],
        [ 6840],
        [ 6105],
        [ 4776],
        [ 6646],
        [ 4343],
        [ 4824],
        [ 5320],
        [ 5024],
        [ 5372],
        [ 4387],
        [ 4494],
        [ 5823],
        [ 5945],
        [ 5246],
        [ 4780]], device='cuda:0')
[2024-07-24 10:18:01,422][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[30194],
        [23764],
        [27669],
        [23932],
        [27664],
        [25090],
        [24061],
        [21933],
        [22999],
        [24693],
        [23605],
        [23891],
        [21306],
        [21719],
        [23310],
        [22569],
        [20368],
        [21786],
        [21578]], device='cuda:0')
[2024-07-24 10:18:01,426][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[10723],
        [10723],
        [10723],
        [10723],
        [10723],
        [10723],
        [10723],
        [10723],
        [10723],
        [10723],
        [10723],
        [10723],
        [10723],
        [10723],
        [10723],
        [10723],
        [10723],
        [10723],
        [10723]], device='cuda:0')
[2024-07-24 10:18:01,553][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:01,555][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:01,555][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:01,556][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:01,557][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:01,557][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:01,559][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:01,560][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:01,560][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:01,561][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:01,562][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:01,562][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:01,563][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:01,564][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1491, 0.8509], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,564][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0443, 0.9557], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,565][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1483, 0.8517], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,566][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.7280, 0.2720], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,566][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0394, 0.9606], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,569][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0218, 0.9782], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,573][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1107, 0.8893], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,574][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2030, 0.7970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,574][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0102, 0.9898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,575][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0229, 0.9771], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,576][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0281, 0.9719], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,576][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1435, 0.8565], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:01,580][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Jamie] are: tensor([0.1950, 0.7306, 0.0744], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,584][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Jamie] are: tensor([0.1322, 0.3928, 0.4750], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,584][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Jamie] are: tensor([0.3257, 0.3870, 0.2872], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,585][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Jamie] are: tensor([0.4276, 0.1532, 0.4193], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,586][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Jamie] are: tensor([0.0134, 0.2261, 0.7605], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,586][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Jamie] are: tensor([0.0153, 0.0878, 0.8969], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,588][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Jamie] are: tensor([0.5329, 0.1735, 0.2936], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,592][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Jamie] are: tensor([0.1627, 0.2486, 0.5887], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,594][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Jamie] are: tensor([0.0440, 0.5378, 0.4181], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,595][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Jamie] are: tensor([0.0726, 0.3200, 0.6074], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,596][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Jamie] are: tensor([0.3847, 0.2679, 0.3474], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,596][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Jamie] are: tensor([0.0676, 0.3825, 0.5499], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:01,597][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0437, 0.7563, 0.0082, 0.1918], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,599][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0047, 0.5470, 0.1679, 0.2804], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,603][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0126, 0.5330, 0.2995, 0.1549], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,605][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2373, 0.1103, 0.1212, 0.5312], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,606][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([6.5792e-04, 1.4995e-01, 1.5582e-01, 6.9358e-01], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,606][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([7.7996e-04, 7.8862e-02, 9.4762e-02, 8.2560e-01], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,607][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1220, 0.3628, 0.2742, 0.2410], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,608][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0022, 0.1669, 0.0739, 0.7571], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,610][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0013, 0.2979, 0.0180, 0.6828], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,614][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0095, 0.6501, 0.2246, 0.1157], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,616][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0023, 0.0339, 0.0191, 0.9447], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,616][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([1.1227e-04, 1.7115e-02, 6.9892e-03, 9.7578e-01], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:01,617][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.1153, 0.5210, 0.0122, 0.2252, 0.1264], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,618][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0083, 0.4318, 0.0782, 0.1961, 0.2855], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,618][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0175, 0.4667, 0.0781, 0.1856, 0.2521], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,621][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.0182, 0.0294, 0.0412, 0.7022, 0.2090], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,626][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0033, 0.3432, 0.1726, 0.4253, 0.0556], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,626][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0020, 0.1048, 0.1451, 0.5088, 0.2393], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,627][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.1423, 0.2200, 0.0875, 0.1223, 0.4280], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,628][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0045, 0.0723, 0.0737, 0.2205, 0.6291], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,629][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.0023, 0.2221, 0.0338, 0.3641, 0.3777], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,629][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0337, 0.4719, 0.2161, 0.0717, 0.2066], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,632][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0051, 0.0270, 0.0105, 0.8922, 0.0652], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,634][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([4.7971e-04, 2.0524e-02, 1.0728e-02, 8.4882e-01, 1.1944e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:01,637][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0093, 0.8040, 0.0015, 0.1304, 0.0047, 0.0501], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,638][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0014, 0.5177, 0.0666, 0.2083, 0.0880, 0.1179], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,638][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0020, 0.7370, 0.1134, 0.0800, 0.0522, 0.0154], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,639][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0228, 0.2335, 0.0265, 0.6379, 0.0134, 0.0659], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,640][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ had] are: tensor([3.0252e-05, 7.3044e-02, 4.8871e-02, 6.9340e-01, 5.9955e-02, 1.2470e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,642][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ had] are: tensor([2.0888e-04, 1.3621e-01, 5.0257e-02, 7.0117e-01, 8.3222e-02, 2.8930e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,646][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0637, 0.4471, 0.1095, 0.0857, 0.2776, 0.0164], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,647][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0013, 0.2516, 0.0553, 0.2924, 0.2825, 0.1170], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,648][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ had] are: tensor([7.6917e-05, 7.2300e-01, 1.3271e-02, 1.8464e-01, 5.8246e-03, 7.3187e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,649][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ had] are: tensor([1.3697e-02, 8.2515e-01, 8.6766e-02, 4.4926e-02, 2.9393e-02, 6.8835e-05],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,650][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0018, 0.0821, 0.0214, 0.8420, 0.0146, 0.0382], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,650][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ had] are: tensor([2.1072e-04, 1.4800e-01, 3.8233e-03, 7.7300e-01, 1.8627e-02, 5.6338e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:01,653][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0251, 0.9033, 0.0024, 0.0305, 0.0031, 0.0338, 0.0018],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,655][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([2.4547e-05, 1.5515e-01, 2.6893e-02, 3.4567e-01, 3.7575e-02, 4.0541e-01,
        2.9274e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,658][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([7.7176e-05, 4.7540e-01, 1.2066e-01, 1.8462e-01, 1.1397e-01, 4.6985e-02,
        5.8283e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,659][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0016, 0.0328, 0.0116, 0.2601, 0.0127, 0.5158, 0.1654],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,660][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([6.4773e-06, 1.1964e-01, 9.9384e-02, 6.4362e-01, 2.5766e-02, 7.4745e-02,
        3.6845e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,660][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([3.4022e-05, 1.5740e-01, 8.1677e-02, 5.7944e-01, 8.0661e-02, 4.0904e-02,
        5.9880e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,661][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0027, 0.1894, 0.1456, 0.3508, 0.1846, 0.0708, 0.0561],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,663][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([5.9590e-06, 3.3790e-02, 3.6465e-02, 3.7182e-01, 1.5075e-01, 3.3790e-01,
        6.9261e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,665][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([2.4064e-04, 4.2172e-01, 1.4895e-03, 1.7920e-01, 2.4059e-03, 3.9449e-01,
        4.5308e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,668][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([4.3473e-04, 7.6151e-01, 1.2646e-01, 9.0423e-02, 1.5871e-02, 2.3617e-04,
        5.0673e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,669][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([5.7192e-05, 1.9637e-02, 1.1447e-02, 8.5867e-01, 3.9110e-03, 9.1930e-02,
        1.4351e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,670][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.8126e-05, 4.4601e-02, 4.0830e-03, 6.7812e-01, 2.3018e-02, 2.0051e-01,
        4.9651e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:01,670][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0036, 0.6235, 0.0007, 0.3127, 0.0013, 0.0550, 0.0014, 0.0017],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,671][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([6.5056e-02, 7.0674e-01, 6.5183e-02, 1.1351e-01, 4.1603e-02, 3.8148e-03,
        3.8145e-03, 2.7732e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,672][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([6.5240e-03, 8.7338e-01, 6.0410e-02, 5.2712e-02, 2.1312e-03, 2.2178e-03,
        2.2977e-03, 3.2712e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,674][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([5.0439e-02, 5.4391e-01, 5.0222e-03, 2.1073e-01, 9.5874e-04, 5.1776e-03,
        1.8376e-01, 2.4865e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,676][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([5.0031e-05, 1.1411e-01, 5.1029e-02, 7.0690e-01, 2.3456e-02, 7.9942e-02,
        2.4439e-02, 6.7377e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,679][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([2.1082e-02, 5.7298e-01, 1.0597e-01, 2.7883e-01, 1.5968e-02, 6.6798e-04,
        4.5028e-03, 6.6801e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,680][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([3.3849e-01, 5.5006e-01, 4.9504e-02, 4.0440e-02, 1.6604e-02, 1.2678e-03,
        3.3447e-03, 2.8886e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,680][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0982, 0.7420, 0.0641, 0.0608, 0.0242, 0.0043, 0.0043, 0.0021],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,681][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([9.2988e-05, 9.7628e-01, 1.1943e-02, 1.0894e-02, 1.1865e-04, 6.5316e-04,
        9.0288e-06, 1.4665e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,682][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([6.4720e-01, 3.3953e-01, 8.9259e-03, 3.4486e-03, 7.5445e-04, 1.1568e-06,
        1.3741e-04, 1.1856e-08], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,683][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([6.3791e-02, 7.7090e-01, 1.8926e-02, 1.4537e-01, 5.9865e-04, 2.3826e-04,
        1.5938e-04, 1.4931e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,684][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([4.0438e-02, 9.1312e-01, 4.7777e-03, 3.8041e-02, 4.4644e-04, 1.6829e-03,
        1.4805e-03, 1.1338e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:01,688][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0503, 0.7152, 0.0021, 0.0173, 0.0033, 0.0435, 0.0026, 0.1577, 0.0080],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,690][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ of] are: tensor([4.1071e-05, 2.1415e-01, 3.0386e-02, 2.4997e-01, 3.1694e-02, 3.8497e-01,
        4.8659e-02, 3.1406e-03, 3.6986e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,691][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ of] are: tensor([1.5097e-04, 6.6098e-01, 8.6237e-02, 7.4382e-02, 8.2626e-02, 1.9326e-02,
        5.7005e-02, 1.1580e-04, 1.9176e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,692][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0014, 0.0208, 0.0041, 0.0637, 0.0085, 0.4552, 0.2190, 0.1324, 0.0948],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,692][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ of] are: tensor([2.1707e-05, 3.3686e-01, 8.0267e-02, 4.3504e-01, 1.7332e-02, 5.1971e-02,
        5.1375e-02, 1.8497e-03, 2.5288e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,693][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ of] are: tensor([1.6152e-05, 8.9764e-02, 4.4545e-02, 4.0821e-01, 1.2217e-01, 6.8093e-02,
        1.5204e-01, 4.3832e-04, 1.1473e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,696][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0031, 0.3612, 0.1196, 0.1190, 0.1889, 0.0472, 0.0976, 0.0118, 0.0516],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,698][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ of] are: tensor([1.5360e-05, 6.3408e-02, 2.4796e-02, 3.5703e-01, 1.0109e-01, 2.9838e-01,
        9.6113e-02, 3.3243e-03, 5.5838e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,701][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ of] are: tensor([1.1646e-04, 6.0038e-02, 1.1866e-03, 1.8171e-01, 1.0747e-02, 6.8946e-01,
        3.5540e-02, 1.0311e-02, 1.0896e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,701][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ of] are: tensor([9.9529e-05, 7.1602e-01, 1.4089e-01, 7.2209e-02, 3.8815e-02, 1.3357e-03,
        9.6624e-03, 1.9524e-05, 2.0943e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,702][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ of] are: tensor([2.3943e-04, 6.0055e-02, 1.7527e-02, 6.4722e-01, 6.5833e-03, 1.8668e-01,
        2.2723e-02, 3.7525e-02, 2.1444e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,703][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ of] are: tensor([7.5231e-05, 1.3327e-01, 6.3665e-03, 3.8577e-01, 2.5037e-02, 3.3302e-01,
        5.4120e-02, 1.3039e-02, 4.9303e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:01,704][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0434, 0.7836, 0.0014, 0.0626, 0.0018, 0.0483, 0.0021, 0.0316, 0.0236,
        0.0018], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,705][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([2.0769e-04, 4.7836e-01, 3.0200e-02, 1.9325e-01, 4.3687e-02, 1.8537e-01,
        2.1078e-02, 9.5270e-04, 4.0299e-02, 6.5961e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,708][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([3.4731e-04, 6.4047e-01, 6.8808e-02, 1.4049e-01, 6.7229e-02, 2.2324e-02,
        3.4161e-02, 3.0856e-04, 1.9908e-02, 5.9559e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,711][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0023, 0.0405, 0.0013, 0.1165, 0.0010, 0.0672, 0.2049, 0.0009, 0.5278,
        0.0376], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,712][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([5.4851e-06, 1.1232e-01, 5.7123e-02, 6.4916e-01, 2.7105e-02, 7.9883e-02,
        2.9555e-02, 2.4301e-04, 2.8456e-02, 1.6157e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,713][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([1.7546e-04, 1.6062e-01, 6.6527e-02, 4.9932e-01, 5.3262e-02, 5.7797e-03,
        3.7890e-02, 6.3063e-06, 1.6695e-01, 9.4682e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,714][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0199, 0.3563, 0.1528, 0.1702, 0.1499, 0.0398, 0.0306, 0.0045, 0.0397,
        0.0363], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,714][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([2.1361e-04, 1.7911e-01, 5.0565e-02, 2.5642e-01, 1.3338e-01, 1.8589e-01,
        3.8055e-02, 4.0709e-03, 8.4755e-02, 6.7530e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,716][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([1.3858e-04, 6.2222e-01, 3.7057e-03, 1.6680e-01, 2.9213e-03, 2.0020e-01,
        1.9183e-03, 9.8360e-04, 4.6846e-04, 6.4308e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,718][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([1.0305e-02, 8.1964e-01, 9.1759e-02, 2.0470e-02, 9.9112e-03, 2.9906e-05,
        1.7820e-03, 1.0033e-07, 4.5130e-02, 9.7807e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,722][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0040, 0.3334, 0.0210, 0.5599, 0.0030, 0.0365, 0.0062, 0.0061, 0.0267,
        0.0032], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,723][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0012, 0.2995, 0.0045, 0.4587, 0.0154, 0.1016, 0.0371, 0.0046, 0.0661,
        0.0111], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:01,723][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ at] are: tensor([1.2376e-02, 8.7320e-01, 8.8452e-04, 5.3807e-02, 9.5918e-04, 2.6966e-02,
        5.2141e-04, 1.2318e-02, 7.9203e-03, 6.0772e-04, 1.0444e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,724][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ at] are: tensor([1.2457e-04, 4.6870e-01, 3.3467e-02, 2.4337e-01, 4.6965e-02, 1.5540e-01,
        1.6004e-02, 6.6347e-04, 2.5943e-02, 6.3196e-03, 3.0408e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,725][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ at] are: tensor([1.0965e-04, 8.3837e-01, 6.1581e-02, 7.0772e-02, 1.4864e-02, 3.2370e-03,
        5.0856e-03, 2.1436e-05, 4.8885e-03, 6.3877e-04, 4.3147e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,728][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0037, 0.1093, 0.0023, 0.1383, 0.0011, 0.0627, 0.2306, 0.0016, 0.3564,
        0.0483, 0.0457], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,730][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ at] are: tensor([3.9638e-06, 1.9293e-01, 5.4708e-02, 6.2896e-01, 1.6351e-02, 5.6859e-02,
        1.6427e-02, 1.4921e-04, 1.7516e-02, 1.0490e-02, 5.6014e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,733][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ at] are: tensor([3.0311e-05, 2.0281e-01, 3.7087e-02, 6.0745e-01, 3.7678e-02, 3.6981e-03,
        1.7292e-02, 4.1689e-06, 8.8542e-02, 4.2322e-03, 1.1768e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,733][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ at] are: tensor([5.6066e-03, 5.8925e-01, 1.2533e-01, 1.3211e-01, 8.4570e-02, 9.5728e-03,
        1.2120e-02, 4.6514e-04, 2.7281e-02, 1.0576e-02, 3.1131e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,734][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ at] are: tensor([1.2786e-04, 3.3991e-01, 5.2360e-02, 3.0831e-01, 9.4113e-02, 9.8691e-02,
        2.0778e-02, 2.1802e-03, 4.5955e-02, 2.5724e-02, 1.1844e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,735][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ at] are: tensor([4.1077e-05, 8.7870e-01, 3.0264e-03, 8.1896e-02, 1.4219e-03, 3.3362e-02,
        5.3458e-04, 2.1226e-04, 8.3176e-05, 1.3702e-04, 5.8245e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,736][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ at] are: tensor([1.6628e-03, 8.6010e-01, 9.5942e-02, 1.5492e-02, 8.4888e-03, 1.3453e-05,
        6.5158e-04, 3.7338e-08, 1.7273e-02, 3.2238e-04, 5.8618e-05],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,737][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ at] are: tensor([4.9492e-04, 2.3077e-01, 2.1435e-02, 7.1611e-01, 2.0426e-03, 1.6793e-02,
        2.0821e-03, 8.0737e-04, 6.1391e-03, 9.0988e-04, 2.4125e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,740][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ at] are: tensor([1.9915e-04, 3.9366e-01, 3.9082e-03, 4.9694e-01, 4.5797e-03, 5.9994e-02,
        1.0005e-02, 3.2010e-04, 2.7045e-02, 2.1798e-03, 1.1657e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:01,743][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ the] are: tensor([1.4775e-02, 8.6792e-01, 1.6137e-03, 3.2880e-02, 1.8079e-03, 3.5596e-02,
        8.0543e-04, 2.9773e-02, 4.4505e-03, 8.1550e-04, 6.6970e-03, 2.8623e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,744][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ the] are: tensor([4.8323e-06, 2.2168e-01, 1.4741e-02, 3.2647e-01, 1.5837e-02, 3.8130e-01,
        1.0635e-02, 1.1279e-03, 8.2835e-03, 4.0223e-03, 2.1199e-03, 1.3785e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,745][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ the] are: tensor([2.0893e-05, 6.3405e-01, 8.1758e-02, 1.5975e-01, 6.1102e-02, 9.9477e-03,
        2.0371e-02, 2.3368e-05, 8.0379e-03, 2.9410e-03, 8.1484e-04, 2.1179e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,746][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ the] are: tensor([2.1676e-04, 4.5160e-02, 3.7386e-03, 1.6832e-01, 2.6790e-03, 4.0529e-01,
        4.9965e-02, 3.1704e-02, 1.8305e-02, 5.6451e-02, 3.8505e-02, 1.7967e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,747][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ the] are: tensor([3.7019e-06, 2.1011e-01, 5.8234e-02, 6.1785e-01, 1.7587e-02, 3.7730e-02,
        1.7615e-02, 4.3246e-04, 8.5094e-03, 7.8765e-03, 3.7069e-03, 2.0348e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,748][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ the] are: tensor([2.7853e-06, 7.9900e-02, 4.2526e-02, 6.8155e-01, 4.7981e-02, 1.4851e-02,
        2.8106e-02, 3.6948e-05, 2.6034e-02, 9.7067e-03, 1.6701e-03, 6.7631e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,752][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0013, 0.3872, 0.1440, 0.2017, 0.1161, 0.0217, 0.0208, 0.0024, 0.0122,
        0.0188, 0.0037, 0.0700], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,754][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ the] are: tensor([3.5616e-06, 7.8565e-02, 3.6749e-02, 4.3713e-01, 1.1023e-01, 1.8401e-01,
        2.1907e-02, 9.7783e-04, 1.2435e-02, 2.3035e-02, 9.2719e-03, 8.5688e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,755][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ the] are: tensor([7.5988e-05, 4.1397e-01, 2.2219e-03, 2.9066e-01, 4.3382e-03, 2.7788e-01,
        2.0001e-03, 2.2297e-03, 4.2087e-04, 5.6526e-04, 1.5767e-03, 4.0610e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,756][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ the] are: tensor([2.5296e-05, 8.1516e-01, 1.2561e-01, 4.2328e-02, 6.7983e-03, 5.8853e-05,
        1.0446e-03, 1.2212e-07, 6.1796e-03, 8.1741e-04, 6.0510e-05, 1.9164e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,757][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ the] are: tensor([6.3820e-05, 4.4268e-02, 2.1534e-02, 8.4998e-01, 2.7104e-03, 4.9728e-02,
        3.7001e-03, 4.3934e-03, 4.8896e-03, 1.7281e-03, 1.4287e-03, 1.5576e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,757][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ the] are: tensor([3.1883e-05, 1.9877e-01, 5.2816e-03, 5.9967e-01, 1.0418e-02, 1.1957e-01,
        8.7752e-03, 2.0728e-03, 4.3945e-03, 2.4890e-03, 8.7796e-04, 4.7645e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:01,761][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0230, 0.8723, 0.0020, 0.0146, 0.0018, 0.0199, 0.0014, 0.0484, 0.0042,
        0.0013, 0.0066, 0.0036, 0.0010], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,765][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ store] are: tensor([5.8452e-05, 3.0674e-01, 2.7067e-02, 2.7161e-01, 1.7298e-02, 3.2703e-01,
        1.6349e-02, 2.9097e-03, 7.8124e-03, 2.9263e-03, 2.3988e-03, 9.2010e-03,
        8.5950e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,766][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ store] are: tensor([8.8573e-05, 4.0888e-01, 7.8716e-02, 3.0004e-01, 8.8153e-02, 3.0605e-02,
        4.0879e-02, 1.5786e-04, 1.1728e-02, 5.1511e-03, 1.3864e-03, 1.9010e-02,
        1.5205e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,766][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0051, 0.1091, 0.0031, 0.0419, 0.0006, 0.2192, 0.0327, 0.4296, 0.0079,
        0.0199, 0.0158, 0.0728, 0.0422], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,767][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ store] are: tensor([2.0532e-05, 1.8411e-01, 1.1328e-01, 5.6368e-01, 2.2228e-02, 5.0607e-02,
        2.4074e-02, 1.4817e-03, 8.4871e-03, 8.7339e-03, 5.5623e-03, 1.5096e-02,
        2.6387e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,768][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ store] are: tensor([5.4735e-06, 5.0972e-02, 5.0460e-02, 4.6936e-01, 3.5999e-02, 6.1425e-02,
        4.9299e-02, 1.3149e-04, 5.3431e-02, 2.0866e-02, 8.4114e-03, 1.5260e-01,
        4.7048e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,772][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0010, 0.2326, 0.1642, 0.2090, 0.1333, 0.0391, 0.0405, 0.0027, 0.0178,
        0.0271, 0.0055, 0.1003, 0.0268], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,775][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ store] are: tensor([9.5994e-06, 8.2484e-02, 2.0965e-02, 3.5766e-01, 7.1994e-02, 2.8735e-01,
        3.0877e-02, 3.4593e-03, 1.1092e-02, 3.2525e-02, 2.4962e-02, 6.1424e-02,
        1.5190e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,776][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ store] are: tensor([7.3726e-05, 1.5610e-01, 5.2895e-03, 2.3768e-01, 2.1485e-02, 3.7263e-01,
        7.6196e-02, 2.3293e-03, 1.0663e-02, 5.4994e-03, 1.0463e-02, 8.6078e-02,
        1.5511e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,777][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ store] are: tensor([8.0437e-05, 5.1307e-01, 2.3305e-01, 1.4740e-01, 3.3386e-02, 1.3744e-03,
        6.5224e-03, 9.8043e-06, 1.9332e-02, 8.3470e-03, 8.9686e-04, 9.9820e-03,
        2.6538e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,778][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ store] are: tensor([1.6113e-04, 2.0778e-01, 4.9902e-02, 5.3859e-01, 3.9965e-03, 1.1526e-01,
        3.9123e-03, 5.5300e-02, 3.8910e-03, 4.0724e-03, 2.2872e-03, 8.9232e-03,
        5.9215e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,779][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ store] are: tensor([9.2314e-05, 2.7381e-01, 1.8212e-02, 5.0381e-01, 7.6182e-03, 1.3353e-01,
        7.6589e-03, 1.8793e-02, 4.9298e-03, 4.7286e-03, 1.8603e-03, 2.1665e-02,
        3.2881e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:01,780][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [.] are: tensor([1.8162e-02, 8.8021e-01, 2.1288e-03, 1.4568e-02, 1.6436e-03, 2.3317e-02,
        7.5337e-04, 4.6256e-02, 1.7363e-03, 6.5744e-04, 3.4302e-03, 2.0632e-03,
        5.8009e-04, 4.4897e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,783][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [.] are: tensor([2.7725e-06, 1.0486e-01, 1.3677e-02, 3.1406e-01, 9.9188e-03, 5.1982e-01,
        1.0251e-02, 2.1484e-03, 4.2351e-03, 2.5710e-03, 1.8434e-03, 9.2806e-03,
        2.6277e-03, 4.7043e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,786][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [.] are: tensor([2.3497e-05, 5.2509e-01, 1.0872e-01, 1.2400e-01, 1.1529e-01, 2.2844e-02,
        4.0989e-02, 1.0462e-04, 5.8193e-03, 4.9878e-03, 1.3053e-03, 2.0154e-02,
        1.1719e-02, 1.8950e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,787][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0008, 0.0392, 0.0109, 0.0941, 0.0072, 0.3851, 0.0130, 0.2197, 0.0029,
        0.0305, 0.0149, 0.0336, 0.0323, 0.1159], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,788][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [.] are: tensor([9.7012e-06, 3.0821e-01, 9.2238e-02, 4.6186e-01, 1.8684e-02, 5.0319e-02,
        2.1325e-02, 1.7735e-03, 7.0501e-03, 7.3660e-03, 4.2814e-03, 1.7202e-02,
        7.2314e-04, 8.9559e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,788][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [.] are: tensor([4.3732e-06, 1.2871e-01, 5.1785e-02, 4.7306e-01, 6.0266e-02, 5.8864e-02,
        5.9225e-02, 3.5828e-04, 3.2428e-02, 1.9504e-02, 3.3036e-03, 7.7757e-02,
        5.6211e-03, 2.9114e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,789][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0009, 0.3024, 0.1208, 0.1861, 0.0932, 0.0782, 0.0390, 0.0160, 0.0109,
        0.0259, 0.0067, 0.0914, 0.0052, 0.0234], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,791][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [.] are: tensor([1.3892e-06, 6.1043e-02, 2.1976e-02, 4.6006e-01, 5.4195e-02, 2.3408e-01,
        3.3783e-02, 6.3456e-04, 9.6553e-03, 2.0049e-02, 9.1634e-03, 8.1096e-02,
        6.7873e-03, 7.4709e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,794][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [.] are: tensor([5.8493e-05, 2.8214e-01, 3.0983e-03, 2.9607e-01, 1.2812e-02, 3.8360e-01,
        6.1164e-03, 2.5483e-03, 9.0766e-04, 8.4069e-04, 2.1256e-03, 6.4928e-03,
        5.7599e-04, 2.6141e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,798][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [.] are: tensor([1.3414e-05, 7.4055e-01, 1.4061e-01, 6.5631e-02, 1.8985e-02, 6.9560e-04,
        4.0545e-03, 3.9716e-06, 7.0204e-03, 3.5943e-03, 2.4657e-04, 3.9253e-03,
        2.7594e-03, 1.1913e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,800][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [.] are: tensor([4.9034e-05, 2.6793e-02, 2.8710e-02, 7.7326e-01, 2.7368e-03, 9.0719e-02,
        4.5801e-03, 1.9713e-02, 3.6954e-03, 1.8079e-03, 1.2210e-03, 1.1364e-02,
        1.4884e-03, 3.3865e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,800][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [.] are: tensor([2.9309e-05, 1.3096e-01, 5.9772e-03, 5.5341e-01, 1.5521e-02, 1.3442e-01,
        9.4699e-03, 1.3872e-02, 2.8933e-03, 3.9032e-03, 1.4089e-03, 3.5497e-02,
        1.6286e-03, 9.1016e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:01,801][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0105, 0.3682, 0.0039, 0.0600, 0.0102, 0.1649, 0.0103, 0.1240, 0.0549,
        0.0135, 0.0682, 0.0476, 0.0114, 0.0448, 0.0077], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,802][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([1.2386e-05, 1.0880e-01, 1.0725e-02, 2.0466e-01, 1.0302e-02, 6.0256e-01,
        1.0627e-02, 2.2783e-03, 4.7636e-03, 4.3550e-03, 2.4221e-03, 1.5891e-02,
        5.3614e-03, 9.9706e-03, 7.2666e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,803][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([6.2087e-05, 2.6737e-01, 5.5839e-02, 1.4427e-01, 1.2485e-01, 6.2898e-02,
        5.6501e-02, 9.0253e-04, 8.4162e-03, 1.2474e-02, 3.5715e-03, 4.5561e-02,
        1.8287e-02, 2.0393e-02, 1.7860e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,805][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([1.7794e-05, 2.6444e-03, 8.5553e-04, 1.4788e-02, 1.8254e-03, 1.8585e-01,
        3.5551e-02, 1.9812e-01, 8.9468e-03, 1.3138e-01, 6.6379e-02, 8.5419e-02,
        3.2536e-02, 2.0515e-01, 3.0530e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,808][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([2.9346e-05, 2.5504e-01, 7.3960e-02, 4.1967e-01, 2.2676e-02, 1.1996e-01,
        2.1541e-02, 7.5437e-03, 9.3285e-03, 1.8543e-02, 1.0859e-02, 2.7574e-02,
        2.4421e-03, 8.4894e-03, 2.3488e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,810][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([1.2865e-05, 5.3295e-02, 5.5511e-02, 3.3624e-01, 5.8648e-02, 1.1477e-01,
        7.1940e-02, 8.0647e-04, 3.9610e-02, 3.6628e-02, 6.8882e-03, 1.5421e-01,
        1.0798e-02, 3.3732e-02, 2.6915e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,811][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0008, 0.1260, 0.0559, 0.1674, 0.1476, 0.2075, 0.0337, 0.0652, 0.0112,
        0.0538, 0.0112, 0.0814, 0.0036, 0.0121, 0.0228], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,812][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([5.5474e-06, 2.6838e-02, 2.8230e-02, 1.6191e-01, 1.0466e-01, 4.9378e-01,
        2.1389e-02, 1.1769e-02, 6.2414e-03, 5.4678e-02, 1.8499e-02, 4.6763e-02,
        6.2506e-03, 3.6315e-03, 1.5358e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,813][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([2.6017e-05, 2.1157e-01, 4.1740e-03, 1.2908e-01, 1.6591e-02, 4.9330e-01,
        1.7073e-02, 4.2278e-03, 3.1042e-03, 5.4772e-03, 1.1801e-02, 2.0339e-02,
        2.5041e-03, 7.8258e-03, 7.2911e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,814][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([1.5339e-04, 5.4687e-01, 1.8977e-01, 1.3515e-01, 4.0361e-02, 3.8992e-03,
        6.7366e-03, 8.6255e-05, 1.1011e-02, 8.1950e-03, 1.1407e-03, 9.7765e-03,
        1.1778e-02, 2.2764e-02, 1.2310e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,816][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([4.6718e-05, 1.3368e-02, 1.5741e-02, 4.4385e-01, 7.3352e-03, 2.2355e-01,
        1.7558e-02, 6.2430e-02, 1.3140e-02, 1.2958e-02, 6.0932e-03, 4.4510e-02,
        1.5146e-02, 5.6705e-02, 6.7567e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,818][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([4.5868e-06, 1.1740e-02, 4.2353e-03, 8.1098e-02, 1.0431e-02, 3.9932e-01,
        2.3955e-02, 3.1461e-01, 3.1488e-03, 2.7231e-02, 9.8305e-03, 5.4543e-02,
        1.3690e-03, 4.6032e-02, 1.2447e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:01,821][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([1.7675e-03, 4.2866e-01, 3.2874e-04, 4.7252e-02, 4.9741e-04, 4.3209e-02,
        2.7170e-04, 8.1632e-03, 6.7450e-03, 4.7081e-04, 9.0081e-03, 1.7270e-03,
        3.5072e-04, 3.7743e-03, 2.1614e-03, 4.4562e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,822][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([9.5542e-05, 6.5402e-01, 2.4922e-02, 1.4162e-01, 2.6250e-02, 4.3804e-02,
        3.9985e-03, 3.5456e-04, 9.1953e-03, 2.7259e-03, 1.2377e-03, 1.3728e-02,
        1.4366e-02, 1.3367e-02, 3.7791e-02, 1.2528e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,823][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([5.5846e-05, 5.7941e-01, 8.0362e-02, 1.3478e-01, 3.5356e-02, 7.5638e-03,
        1.1574e-02, 4.0982e-05, 9.5208e-03, 1.4704e-03, 5.9331e-04, 2.3070e-02,
        1.2722e-02, 1.8990e-02, 8.2132e-02, 2.3586e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,824][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([1.9497e-03, 1.0267e-01, 1.2354e-03, 2.4784e-02, 1.5989e-04, 3.9282e-03,
        7.3020e-03, 2.2993e-05, 1.4930e-02, 8.3557e-04, 6.4989e-04, 6.2144e-02,
        6.6371e-02, 6.8427e-01, 1.3392e-02, 1.5355e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,825][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([1.2520e-06, 9.0075e-02, 2.2998e-02, 7.2500e-01, 1.6908e-02, 5.6902e-02,
        1.3146e-02, 6.0828e-05, 1.8631e-02, 9.7272e-03, 3.0876e-03, 2.6106e-02,
        1.9961e-03, 9.5725e-03, 3.0056e-03, 2.7799e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,826][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([1.4441e-05, 1.0950e-01, 5.1724e-02, 6.7845e-01, 4.0488e-02, 4.5659e-03,
        1.2528e-02, 3.5914e-06, 4.2324e-02, 4.2539e-03, 7.8044e-04, 1.7912e-02,
        6.6792e-03, 2.1695e-02, 8.5421e-03, 5.4462e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,829][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([3.3078e-03, 4.3481e-01, 8.5555e-02, 9.0734e-02, 9.0042e-02, 5.8881e-03,
        1.3148e-02, 2.6426e-04, 3.3958e-02, 6.4241e-03, 1.6835e-03, 7.1184e-02,
        4.2920e-02, 5.7335e-02, 5.7928e-02, 4.8211e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,832][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([7.7745e-05, 3.4056e-01, 5.5141e-02, 2.8755e-01, 1.1367e-01, 5.1162e-02,
        1.0404e-02, 5.5212e-04, 2.9785e-02, 1.2058e-02, 4.1258e-03, 4.3561e-02,
        2.7629e-02, 8.0411e-03, 1.2626e-02, 3.0588e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,833][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([1.2480e-05, 9.2985e-01, 1.6004e-03, 3.7086e-02, 2.3533e-04, 8.5955e-03,
        9.3378e-05, 1.3659e-05, 3.0718e-05, 3.7201e-05, 1.3316e-04, 7.8922e-04,
        1.0996e-04, 9.8383e-05, 1.6841e-04, 2.1146e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,834][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([5.3373e-04, 7.9890e-01, 4.5635e-02, 1.2607e-02, 5.5765e-03, 2.9042e-06,
        3.9657e-04, 2.4159e-09, 2.7213e-02, 1.9389e-04, 2.1314e-05, 1.3439e-03,
        3.9447e-02, 5.1616e-02, 1.6514e-02, 4.0860e-07], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,834][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([1.8996e-04, 3.8461e-01, 3.7788e-02, 5.3486e-01, 1.2369e-03, 5.9449e-03,
        5.8196e-04, 1.1605e-04, 3.4287e-03, 3.3650e-04, 5.8245e-04, 5.9769e-03,
        3.1833e-03, 1.2445e-02, 4.5441e-03, 4.1728e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,835][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([2.8814e-04, 6.9571e-01, 7.8144e-03, 1.9723e-01, 2.6799e-03, 4.8072e-02,
        1.9816e-03, 1.1811e-03, 4.2351e-03, 9.3880e-04, 2.8057e-04, 1.0589e-02,
        6.9424e-04, 1.1396e-02, 1.1155e-03, 1.5799e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:01,837][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([1.3131e-02, 8.6968e-01, 7.1075e-04, 2.6784e-02, 7.9739e-04, 1.7677e-02,
        3.2317e-04, 1.1327e-02, 2.0721e-03, 4.5535e-04, 3.8449e-03, 1.4201e-03,
        6.4541e-04, 2.5456e-03, 7.0528e-04, 4.6791e-02, 1.0867e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,840][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.2560e-06, 9.6393e-02, 8.9437e-03, 3.4922e-01, 1.1198e-02, 4.7480e-01,
        4.3972e-03, 2.1028e-03, 2.7987e-03, 3.5260e-03, 1.3824e-03, 8.7329e-03,
        2.3843e-03, 3.6736e-03, 2.9909e-03, 2.3298e-02, 4.1616e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,841][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([4.3826e-06, 3.7034e-01, 8.2770e-02, 2.0155e-01, 1.4703e-01, 2.5174e-02,
        1.5646e-02, 1.6825e-04, 2.3242e-03, 4.1987e-03, 1.1852e-03, 7.7877e-03,
        3.9122e-03, 6.3101e-03, 1.2710e-01, 1.3975e-03, 3.1036e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,842][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.1201e-04, 3.3645e-02, 5.6711e-03, 7.2322e-02, 1.9432e-03, 1.8397e-01,
        4.1017e-03, 5.2041e-02, 1.0763e-03, 9.9346e-03, 6.3022e-03, 9.7453e-03,
        1.2147e-02, 5.5482e-02, 5.1149e-03, 4.8200e-01, 6.4398e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,844][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([4.1638e-07, 1.3219e-01, 4.5004e-02, 6.8289e-01, 1.6406e-02, 6.9899e-02,
        1.0808e-02, 1.2604e-04, 7.1473e-03, 4.9775e-03, 1.7920e-03, 1.7139e-02,
        3.3054e-04, 4.0839e-03, 4.0290e-04, 1.4784e-03, 5.3209e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,845][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([4.5219e-06, 1.0799e-01, 7.4933e-02, 6.5005e-01, 4.5350e-02, 8.8375e-03,
        1.6478e-02, 1.0350e-05, 2.2902e-02, 3.3387e-03, 5.5943e-04, 2.7349e-02,
        2.2493e-03, 1.5690e-02, 4.6691e-03, 1.1824e-03, 1.8408e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,846][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0006, 0.1908, 0.1523, 0.3087, 0.1597, 0.0316, 0.0179, 0.0045, 0.0097,
        0.0159, 0.0028, 0.0489, 0.0023, 0.0112, 0.0121, 0.0152, 0.0157],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,847][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([1.0371e-06, 5.8244e-02, 5.4129e-02, 4.1440e-01, 1.5551e-01, 1.6719e-01,
        1.8665e-02, 5.6299e-04, 1.0715e-02, 1.8541e-02, 6.0474e-03, 7.4488e-02,
        3.7732e-03, 4.0184e-03, 4.4166e-03, 3.0352e-03, 6.2577e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,847][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([7.6683e-05, 7.9600e-01, 2.9175e-04, 7.4089e-02, 2.6536e-04, 6.6654e-02,
        1.2861e-05, 6.9408e-04, 6.4833e-06, 1.4692e-05, 1.2366e-04, 7.1688e-05,
        3.1318e-06, 3.8638e-06, 2.4326e-05, 6.1670e-02, 2.5876e-06],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,849][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([4.0272e-05, 8.4227e-01, 9.2431e-02, 4.1375e-02, 5.0462e-03, 1.9878e-05,
        6.2893e-04, 1.9037e-08, 6.0069e-03, 2.6092e-04, 1.7797e-05, 7.6103e-04,
        1.2082e-03, 8.6016e-03, 1.1110e-03, 7.7002e-07, 2.2177e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,852][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([4.0987e-05, 4.8199e-02, 2.1096e-02, 8.0035e-01, 9.6889e-04, 4.2475e-02,
        1.4721e-03, 3.4658e-03, 2.1291e-03, 3.8862e-04, 6.8429e-04, 4.6176e-03,
        1.5132e-03, 2.1388e-02, 3.8972e-03, 3.9290e-02, 8.0224e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,855][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.1256e-05, 1.8379e-01, 4.9224e-03, 3.2584e-01, 9.6776e-03, 2.3684e-01,
        6.5782e-03, 7.4556e-02, 1.3382e-03, 4.4044e-03, 1.8279e-03, 1.8951e-02,
        4.1215e-04, 2.7156e-02, 6.2025e-03, 8.8004e-02, 9.4897e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:01,856][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.0328, 0.6668, 0.0010, 0.0245, 0.0009, 0.0318, 0.0008, 0.0417, 0.0051,
        0.0012, 0.0077, 0.0028, 0.0013, 0.0047, 0.0008, 0.1696, 0.0027, 0.0039],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,857][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([2.9241e-05, 2.1025e-01, 1.0128e-02, 2.9802e-01, 1.7519e-02, 3.8400e-01,
        5.1434e-03, 2.7215e-03, 3.7045e-03, 2.3183e-03, 1.3617e-03, 1.1559e-02,
        1.8140e-03, 4.9566e-03, 7.5565e-03, 2.6001e-02, 5.9503e-03, 6.9659e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,857][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([1.9724e-05, 1.9666e-01, 3.3780e-02, 1.9634e-01, 2.2298e-01, 2.5398e-02,
        2.5691e-02, 2.0551e-04, 3.0759e-03, 5.1641e-03, 1.4762e-03, 1.2142e-02,
        4.6641e-03, 5.6144e-03, 2.5690e-01, 1.9171e-03, 6.3101e-03, 1.6692e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,859][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([1.7971e-04, 3.8059e-02, 1.0553e-03, 4.3057e-02, 4.4030e-04, 5.3762e-02,
        6.8974e-03, 1.0429e-02, 3.3660e-03, 5.3636e-03, 5.3412e-03, 2.8600e-02,
        1.8932e-02, 2.9395e-01, 5.7559e-03, 2.2626e-01, 2.1834e-01, 4.0209e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,860][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([4.1244e-06, 1.7546e-01, 7.1024e-02, 5.6913e-01, 3.1310e-02, 8.0693e-02,
        1.6187e-02, 1.6237e-04, 1.2484e-02, 5.8411e-03, 2.2369e-03, 1.7977e-02,
        9.0728e-04, 4.2981e-03, 9.8059e-04, 1.9236e-03, 4.7457e-03, 4.6399e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,863][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([5.0173e-06, 6.0931e-02, 6.5294e-02, 6.0672e-01, 5.8003e-02, 5.2461e-03,
        1.9415e-02, 2.9047e-06, 4.1777e-02, 3.3457e-03, 6.3742e-04, 5.2027e-02,
        3.5485e-03, 3.3325e-02, 1.1251e-02, 1.4710e-03, 3.0385e-02, 6.6219e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,866][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0023, 0.2419, 0.0906, 0.2806, 0.1742, 0.0510, 0.0147, 0.0057, 0.0091,
        0.0142, 0.0027, 0.0436, 0.0023, 0.0100, 0.0157, 0.0230, 0.0128, 0.0056],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,867][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([8.8048e-06, 6.0102e-02, 4.7631e-02, 2.4695e-01, 2.5885e-01, 1.5534e-01,
        2.0620e-02, 1.4948e-03, 1.5972e-02, 3.8407e-02, 7.9103e-03, 7.8075e-02,
        5.2090e-03, 6.1683e-03, 1.8159e-02, 7.2800e-03, 1.0307e-02, 2.1510e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,867][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([3.3321e-04, 8.9775e-01, 3.1095e-04, 4.7892e-02, 2.8756e-04, 2.9231e-02,
        6.5135e-05, 7.1160e-05, 5.0342e-05, 1.9489e-05, 1.3676e-04, 2.8038e-04,
        4.2966e-05, 4.7433e-05, 1.6330e-04, 2.3279e-02, 1.9323e-05, 1.7732e-05],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,868][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([3.6844e-04, 8.9471e-01, 5.0859e-02, 2.6437e-02, 4.7586e-03, 1.6387e-05,
        3.7155e-04, 4.0427e-08, 6.9133e-03, 2.3503e-04, 2.5806e-05, 6.1573e-04,
        2.0508e-03, 9.2795e-03, 1.8945e-03, 1.0312e-06, 1.7114e-04, 1.2874e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,869][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([2.0224e-04, 1.6895e-01, 1.6449e-02, 5.7446e-01, 1.5382e-03, 5.3904e-02,
        2.2220e-03, 1.1026e-02, 4.6903e-03, 1.4857e-03, 1.9837e-03, 1.1476e-02,
        3.8508e-03, 3.8054e-02, 8.8812e-03, 7.4332e-02, 1.4443e-02, 1.2047e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,871][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([1.2431e-04, 3.2662e-01, 7.3069e-03, 1.8826e-01, 7.4551e-03, 1.6667e-01,
        8.2707e-03, 7.5370e-02, 3.2469e-03, 7.7351e-03, 2.7967e-03, 2.8783e-02,
        1.6082e-03, 4.2438e-02, 5.7799e-03, 1.0920e-01, 1.3557e-02, 4.7835e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:01,874][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([5.0476e-02, 7.1552e-01, 2.6389e-03, 1.8393e-02, 1.8304e-03, 2.7116e-02,
        1.0139e-03, 8.8357e-02, 3.4532e-03, 1.3567e-03, 6.2854e-03, 3.8909e-03,
        1.3012e-03, 8.9029e-03, 6.7315e-04, 5.9714e-02, 3.3981e-03, 1.5580e-03,
        4.1219e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,876][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([6.3754e-06, 1.0829e-01, 1.4045e-02, 2.6992e-01, 1.3751e-02, 4.8684e-01,
        1.5686e-02, 3.2141e-03, 7.1828e-03, 5.4081e-03, 3.0537e-03, 1.8930e-02,
        4.6002e-03, 9.5764e-03, 3.4857e-03, 1.7197e-02, 1.0452e-02, 7.7546e-03,
        6.0780e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,877][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([3.0333e-05, 4.2866e-01, 8.4550e-02, 1.0272e-01, 1.0421e-01, 2.5442e-02,
        3.4387e-02, 2.2447e-04, 6.6245e-03, 6.1559e-03, 1.9673e-03, 2.2603e-02,
        2.0635e-02, 1.9966e-02, 1.2062e-01, 1.3003e-03, 9.0496e-03, 7.0252e-03,
        3.8200e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,878][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.3932e-04, 1.0759e-02, 2.5057e-03, 1.2878e-02, 1.2088e-03, 1.1840e-01,
        6.8925e-03, 2.0553e-01, 8.2134e-04, 1.7275e-02, 1.0086e-02, 1.1735e-02,
        1.3194e-02, 4.2852e-02, 6.4779e-03, 3.8059e-01, 1.0802e-01, 4.4175e-02,
        6.4623e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,879][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([8.7727e-06, 3.0573e-01, 6.3123e-02, 3.7984e-01, 1.5664e-02, 7.3160e-02,
        3.4574e-02, 1.4343e-03, 1.6452e-02, 1.9822e-02, 1.0662e-02, 3.2374e-02,
        1.2538e-03, 1.9168e-02, 1.1282e-03, 3.5097e-03, 1.3644e-02, 4.9476e-03,
        3.4982e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,880][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([6.3393e-06, 4.9513e-02, 3.8891e-02, 4.4343e-01, 4.2887e-02, 5.4978e-02,
        6.7519e-02, 3.1464e-04, 4.0460e-02, 1.9249e-02, 4.1497e-03, 1.1062e-01,
        8.0208e-03, 2.9159e-02, 7.2426e-03, 5.7689e-03, 5.7343e-02, 1.3375e-02,
        7.0801e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,884][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0011, 0.2156, 0.0983, 0.1147, 0.1058, 0.0481, 0.0493, 0.0113, 0.0214,
        0.0324, 0.0092, 0.1168, 0.0116, 0.0464, 0.0337, 0.0242, 0.0378, 0.0152,
        0.0071], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,887][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([3.9714e-06, 5.4692e-02, 2.4535e-02, 3.0663e-01, 5.9067e-02, 2.8438e-01,
        3.7349e-02, 1.6578e-03, 1.1586e-02, 2.9900e-02, 1.5613e-02, 9.7589e-02,
        1.4198e-02, 1.1416e-02, 7.6204e-03, 8.0060e-03, 1.5801e-02, 1.8258e-02,
        1.6970e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,888][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([4.0526e-05, 1.8381e-01, 1.3818e-03, 1.6301e-01, 4.3041e-03, 2.2736e-01,
        4.9674e-03, 1.7726e-03, 9.7751e-04, 1.1673e-03, 3.7658e-03, 1.0413e-02,
        7.2555e-04, 2.7556e-03, 7.5871e-03, 3.8188e-01, 2.6465e-03, 6.7962e-04,
        7.4965e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,889][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([7.4651e-05, 6.3243e-01, 1.5982e-01, 6.2058e-02, 3.3059e-02, 1.8955e-03,
        7.7921e-03, 5.7322e-05, 1.2909e-02, 9.2729e-03, 1.0582e-03, 1.0241e-02,
        9.0805e-03, 2.6224e-02, 1.0984e-02, 1.7015e-04, 4.0216e-03, 1.5578e-02,
        3.2740e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,890][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([5.7714e-05, 5.5863e-02, 3.6761e-02, 5.8239e-01, 1.6464e-03, 1.3085e-01,
        5.4955e-03, 3.3975e-02, 4.3076e-03, 1.6166e-03, 2.4854e-03, 1.0313e-02,
        2.5581e-03, 3.2419e-02, 3.6085e-03, 6.8820e-02, 1.7453e-02, 4.4655e-03,
        4.9110e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:01,891][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.6292e-05, 7.9206e-02, 5.4665e-03, 1.6898e-01, 9.2974e-03, 2.4308e-01,
        9.4191e-03, 1.9003e-01, 2.0859e-03, 1.1942e-02, 4.7986e-03, 2.1853e-02,
        1.8342e-03, 3.9469e-02, 1.2321e-02, 1.7455e-01, 1.9127e-02, 2.3327e-03,
        4.1785e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:02,023][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:02,024][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:02,025][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:02,026][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:02,027][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:02,027][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:02,028][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:02,029][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:02,029][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:02,030][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:02,031][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:02,031][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:02,032][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:02,033][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1491, 0.8509], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:02,033][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0443, 0.9557], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:02,034][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1483, 0.8517], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:02,035][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.7280, 0.2720], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:02,035][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0394, 0.9606], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:02,036][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0218, 0.9782], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:02,038][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1107, 0.8893], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:02,038][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2030, 0.7970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:02,042][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([1.0000e+00, 6.8205e-15], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:02,044][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0229, 0.9771], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:02,044][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0281, 0.9719], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:02,045][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1435, 0.8565], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:02,046][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Jamie] are: tensor([0.1950, 0.7306, 0.0744], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:02,046][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Jamie] are: tensor([0.1322, 0.3928, 0.4750], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:02,048][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Jamie] are: tensor([0.3257, 0.3870, 0.2872], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:02,052][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Jamie] are: tensor([0.4276, 0.1532, 0.4193], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:02,054][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Jamie] are: tensor([0.0134, 0.2261, 0.7605], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:02,055][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Jamie] are: tensor([0.0153, 0.0878, 0.8969], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:02,056][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Jamie] are: tensor([0.5329, 0.1735, 0.2936], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:02,056][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Jamie] are: tensor([0.1627, 0.2486, 0.5887], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:02,057][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Jamie] are: tensor([1.0000e+00, 2.6046e-12, 7.4595e-14], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:02,059][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Jamie] are: tensor([0.0726, 0.3200, 0.6074], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:02,063][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Jamie] are: tensor([0.3847, 0.2679, 0.3474], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:02,065][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Jamie] are: tensor([0.0676, 0.3825, 0.5499], device='cuda:0') for source tokens [Then, Jamie]
[2024-07-24 10:18:02,066][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0437, 0.7563, 0.0082, 0.1918], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:02,066][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0047, 0.5470, 0.1679, 0.2804], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:02,067][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0126, 0.5330, 0.2995, 0.1549], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:02,068][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2373, 0.1103, 0.1212, 0.5312], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:02,069][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([6.5792e-04, 1.4995e-01, 1.5582e-01, 6.9358e-01], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:02,071][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([7.7996e-04, 7.8862e-02, 9.4762e-02, 8.2560e-01], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:02,075][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1220, 0.3628, 0.2742, 0.2410], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:02,076][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0022, 0.1669, 0.0739, 0.7571], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:02,077][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([1.0000e+00, 1.0459e-11, 4.0384e-13, 8.0754e-10], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:02,078][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0095, 0.6501, 0.2246, 0.1157], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:02,078][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0023, 0.0339, 0.0191, 0.9447], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:02,079][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([1.1227e-04, 1.7115e-02, 6.9892e-03, 9.7578e-01], device='cuda:0') for source tokens [Then, Jamie and]
[2024-07-24 10:18:02,082][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.1153, 0.5210, 0.0122, 0.2252, 0.1264], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:02,086][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0083, 0.4318, 0.0782, 0.1961, 0.2855], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:02,087][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.0175, 0.4667, 0.0781, 0.1856, 0.2521], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:02,088][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.0182, 0.0294, 0.0412, 0.7022, 0.2090], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:02,089][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0033, 0.3432, 0.1726, 0.4253, 0.0556], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:02,089][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.0020, 0.1048, 0.1451, 0.5088, 0.2393], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:02,090][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.1423, 0.2200, 0.0875, 0.1223, 0.4280], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:02,094][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0045, 0.0723, 0.0737, 0.2205, 0.6291], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:02,096][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([9.8740e-01, 3.0976e-04, 4.1101e-05, 5.4190e-04, 1.1711e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:02,098][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.0337, 0.4719, 0.2161, 0.0717, 0.2066], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:02,098][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0051, 0.0270, 0.0105, 0.8922, 0.0652], device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:02,099][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([4.7971e-04, 2.0524e-02, 1.0728e-02, 8.4882e-01, 1.1944e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany]
[2024-07-24 10:18:02,100][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0093, 0.8040, 0.0015, 0.1304, 0.0047, 0.0501], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:02,101][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0014, 0.5177, 0.0666, 0.2083, 0.0880, 0.1179], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:02,103][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0020, 0.7370, 0.1134, 0.0800, 0.0522, 0.0154], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:02,107][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0228, 0.2335, 0.0265, 0.6379, 0.0134, 0.0659], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:02,109][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([3.0252e-05, 7.3044e-02, 4.8871e-02, 6.9340e-01, 5.9955e-02, 1.2470e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:02,109][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([2.0888e-04, 1.3621e-01, 5.0257e-02, 7.0117e-01, 8.3222e-02, 2.8930e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:02,110][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0637, 0.4471, 0.1095, 0.0857, 0.2776, 0.0164], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:02,111][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0013, 0.2516, 0.0553, 0.2924, 0.2825, 0.1170], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:02,112][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([9.9998e-01, 2.9175e-09, 1.3697e-10, 4.2352e-08, 1.9096e-05, 2.5392e-06],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:02,113][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([1.3697e-02, 8.2515e-01, 8.6766e-02, 4.4926e-02, 2.9393e-02, 6.8835e-05],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:02,116][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0018, 0.0821, 0.0214, 0.8420, 0.0146, 0.0382], device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:02,119][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([2.1072e-04, 1.4800e-01, 3.8233e-03, 7.7300e-01, 1.8627e-02, 5.6338e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had]
[2024-07-24 10:18:02,120][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0251, 0.9033, 0.0024, 0.0305, 0.0031, 0.0338, 0.0018],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:02,121][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([2.4547e-05, 1.5515e-01, 2.6893e-02, 3.4567e-01, 3.7575e-02, 4.0541e-01,
        2.9274e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:02,121][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([7.7176e-05, 4.7540e-01, 1.2066e-01, 1.8462e-01, 1.1397e-01, 4.6985e-02,
        5.8283e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:02,122][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0016, 0.0328, 0.0116, 0.2601, 0.0127, 0.5158, 0.1654],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:02,123][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([6.4773e-06, 1.1964e-01, 9.9384e-02, 6.4362e-01, 2.5766e-02, 7.4745e-02,
        3.6845e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:02,125][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([3.4022e-05, 1.5740e-01, 8.1677e-02, 5.7944e-01, 8.0661e-02, 4.0904e-02,
        5.9880e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:02,131][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0027, 0.1894, 0.1456, 0.3508, 0.1846, 0.0708, 0.0561],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:02,133][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([5.9590e-06, 3.3790e-02, 3.6465e-02, 3.7182e-01, 1.5075e-01, 3.3790e-01,
        6.9261e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:02,134][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([9.9999e-01, 1.1395e-10, 2.8172e-12, 3.9158e-09, 6.5809e-06, 5.2052e-07,
        1.3588e-09], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:02,134][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([4.3473e-04, 7.6151e-01, 1.2646e-01, 9.0423e-02, 1.5871e-02, 2.3617e-04,
        5.0673e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:02,135][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([5.7192e-05, 1.9637e-02, 1.1447e-02, 8.5867e-01, 3.9110e-03, 9.1930e-02,
        1.4351e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:02,136][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.8126e-05, 4.4601e-02, 4.0830e-03, 6.7812e-01, 2.3018e-02, 2.0051e-01,
        4.9651e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a]
[2024-07-24 10:18:02,138][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0036, 0.6235, 0.0007, 0.3127, 0.0013, 0.0550, 0.0014, 0.0017],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:02,140][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([6.5056e-02, 7.0674e-01, 6.5183e-02, 1.1351e-01, 4.1603e-02, 3.8148e-03,
        3.8145e-03, 2.7732e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:02,143][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([6.5240e-03, 8.7338e-01, 6.0410e-02, 5.2712e-02, 2.1312e-03, 2.2178e-03,
        2.2977e-03, 3.2712e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:02,144][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([5.0439e-02, 5.4391e-01, 5.0222e-03, 2.1073e-01, 9.5874e-04, 5.1776e-03,
        1.8376e-01, 2.4865e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:02,145][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([5.0031e-05, 1.1411e-01, 5.1029e-02, 7.0690e-01, 2.3456e-02, 7.9942e-02,
        2.4439e-02, 6.7377e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:02,146][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([2.1082e-02, 5.7298e-01, 1.0597e-01, 2.7883e-01, 1.5968e-02, 6.6798e-04,
        4.5028e-03, 6.6801e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:02,146][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([3.3849e-01, 5.5006e-01, 4.9504e-02, 4.0440e-02, 1.6604e-02, 1.2678e-03,
        3.3447e-03, 2.8886e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:02,149][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0982, 0.7420, 0.0641, 0.0608, 0.0242, 0.0043, 0.0043, 0.0021],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:02,151][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([9.9709e-01, 5.7128e-07, 2.1550e-07, 3.7406e-06, 2.6621e-04, 2.2832e-05,
        8.4036e-07, 2.6147e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:02,154][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([6.4720e-01, 3.3953e-01, 8.9259e-03, 3.4486e-03, 7.5445e-04, 1.1568e-06,
        1.3741e-04, 1.1856e-08], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:02,155][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([6.3791e-02, 7.7090e-01, 1.8926e-02, 1.4537e-01, 5.9865e-04, 2.3826e-04,
        1.5938e-04, 1.4931e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:02,156][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([4.0438e-02, 9.1312e-01, 4.7777e-03, 3.8041e-02, 4.4644e-04, 1.6829e-03,
        1.4805e-03, 1.1338e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot]
[2024-07-24 10:18:02,157][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0503, 0.7152, 0.0021, 0.0173, 0.0033, 0.0435, 0.0026, 0.1577, 0.0080],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:02,157][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([4.1071e-05, 2.1415e-01, 3.0386e-02, 2.4997e-01, 3.1694e-02, 3.8497e-01,
        4.8659e-02, 3.1406e-03, 3.6986e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:02,159][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([1.5097e-04, 6.6098e-01, 8.6237e-02, 7.4382e-02, 8.2626e-02, 1.9326e-02,
        5.7005e-02, 1.1580e-04, 1.9176e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:02,163][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0014, 0.0208, 0.0041, 0.0637, 0.0085, 0.4552, 0.2190, 0.1324, 0.0948],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:02,165][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([2.1707e-05, 3.3686e-01, 8.0267e-02, 4.3504e-01, 1.7332e-02, 5.1971e-02,
        5.1375e-02, 1.8497e-03, 2.5288e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:02,166][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([1.6152e-05, 8.9764e-02, 4.4545e-02, 4.0821e-01, 1.2217e-01, 6.8093e-02,
        1.5204e-01, 4.3832e-04, 1.1473e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:02,167][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0031, 0.3612, 0.1196, 0.1190, 0.1889, 0.0472, 0.0976, 0.0118, 0.0516],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:02,168][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([1.5360e-05, 6.3408e-02, 2.4796e-02, 3.5703e-01, 1.0109e-01, 2.9838e-01,
        9.6113e-02, 3.3243e-03, 5.5838e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:02,168][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([9.9839e-01, 3.8489e-10, 2.2720e-11, 2.1260e-08, 3.0305e-05, 2.2934e-06,
        2.3542e-08, 1.5820e-03, 9.8411e-08], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:02,170][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([9.9529e-05, 7.1602e-01, 1.4089e-01, 7.2209e-02, 3.8815e-02, 1.3357e-03,
        9.6624e-03, 1.9524e-05, 2.0943e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:02,173][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([2.3943e-04, 6.0055e-02, 1.7527e-02, 6.4722e-01, 6.5833e-03, 1.8668e-01,
        2.2723e-02, 3.7525e-02, 2.1444e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:02,176][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([7.5231e-05, 1.3327e-01, 6.3665e-03, 3.8577e-01, 2.5037e-02, 3.3302e-01,
        5.4120e-02, 1.3039e-02, 4.9303e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of]
[2024-07-24 10:18:02,177][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0434, 0.7836, 0.0014, 0.0626, 0.0018, 0.0483, 0.0021, 0.0316, 0.0236,
        0.0018], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:02,177][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([2.0769e-04, 4.7836e-01, 3.0200e-02, 1.9325e-01, 4.3687e-02, 1.8537e-01,
        2.1078e-02, 9.5270e-04, 4.0299e-02, 6.5961e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:02,178][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([3.4731e-04, 6.4047e-01, 6.8808e-02, 1.4049e-01, 6.7229e-02, 2.2324e-02,
        3.4161e-02, 3.0856e-04, 1.9908e-02, 5.9559e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:02,179][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0023, 0.0405, 0.0013, 0.1165, 0.0010, 0.0672, 0.2049, 0.0009, 0.5278,
        0.0376], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:02,181][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([5.4851e-06, 1.1232e-01, 5.7123e-02, 6.4916e-01, 2.7105e-02, 7.9883e-02,
        2.9555e-02, 2.4301e-04, 2.8456e-02, 1.6157e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:02,183][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([1.7546e-04, 1.6062e-01, 6.6527e-02, 4.9932e-01, 5.3262e-02, 5.7797e-03,
        3.7890e-02, 6.3063e-06, 1.6695e-01, 9.4682e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:02,187][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0199, 0.3563, 0.1528, 0.1702, 0.1499, 0.0398, 0.0306, 0.0045, 0.0397,
        0.0363], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:02,187][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([2.1361e-04, 1.7911e-01, 5.0565e-02, 2.5642e-01, 1.3338e-01, 1.8589e-01,
        3.8055e-02, 4.0709e-03, 8.4755e-02, 6.7530e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:02,188][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([9.9672e-01, 2.0790e-07, 1.4773e-08, 1.7632e-06, 2.1762e-04, 4.1120e-05,
        7.1006e-07, 3.0016e-03, 2.0390e-06, 1.1150e-05], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:02,189][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([1.0305e-02, 8.1964e-01, 9.1759e-02, 2.0470e-02, 9.9112e-03, 2.9906e-05,
        1.7820e-03, 1.0033e-07, 4.5130e-02, 9.7807e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:02,190][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0040, 0.3334, 0.0210, 0.5599, 0.0030, 0.0365, 0.0062, 0.0061, 0.0267,
        0.0032], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:02,192][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0012, 0.2995, 0.0045, 0.4587, 0.0154, 0.1016, 0.0371, 0.0046, 0.0661,
        0.0111], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun]
[2024-07-24 10:18:02,195][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([1.2376e-02, 8.7320e-01, 8.8452e-04, 5.3807e-02, 9.5918e-04, 2.6966e-02,
        5.2141e-04, 1.2318e-02, 7.9203e-03, 6.0772e-04, 1.0444e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:02,198][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([1.2457e-04, 4.6870e-01, 3.3467e-02, 2.4337e-01, 4.6965e-02, 1.5540e-01,
        1.6004e-02, 6.6347e-04, 2.5943e-02, 6.3196e-03, 3.0408e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:02,198][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([1.0965e-04, 8.3837e-01, 6.1581e-02, 7.0772e-02, 1.4864e-02, 3.2370e-03,
        5.0856e-03, 2.1436e-05, 4.8885e-03, 6.3877e-04, 4.3147e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:02,199][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0037, 0.1093, 0.0023, 0.1383, 0.0011, 0.0627, 0.2306, 0.0016, 0.3564,
        0.0483, 0.0457], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:02,200][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([3.9638e-06, 1.9293e-01, 5.4708e-02, 6.2896e-01, 1.6351e-02, 5.6859e-02,
        1.6427e-02, 1.4921e-04, 1.7516e-02, 1.0490e-02, 5.6014e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:02,201][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([3.0311e-05, 2.0281e-01, 3.7087e-02, 6.0745e-01, 3.7678e-02, 3.6981e-03,
        1.7292e-02, 4.1689e-06, 8.8542e-02, 4.2322e-03, 1.1768e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:02,202][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([5.6066e-03, 5.8925e-01, 1.2533e-01, 1.3211e-01, 8.4570e-02, 9.5728e-03,
        1.2120e-02, 4.6514e-04, 2.7281e-02, 1.0576e-02, 3.1131e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:02,205][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([1.2786e-04, 3.3991e-01, 5.2360e-02, 3.0831e-01, 9.4113e-02, 9.8691e-02,
        2.0778e-02, 2.1802e-03, 4.5955e-02, 2.5724e-02, 1.1844e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:02,208][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([9.9908e-01, 2.8641e-09, 1.6300e-10, 4.8459e-08, 2.3039e-05, 2.1224e-06,
        1.5349e-08, 8.9380e-04, 5.3557e-08, 5.3589e-07, 1.2502e-07],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:02,209][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([1.6628e-03, 8.6010e-01, 9.5942e-02, 1.5492e-02, 8.4888e-03, 1.3453e-05,
        6.5158e-04, 3.7338e-08, 1.7273e-02, 3.2238e-04, 5.8618e-05],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:02,210][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([4.9492e-04, 2.3077e-01, 2.1435e-02, 7.1611e-01, 2.0426e-03, 1.6793e-02,
        2.0821e-03, 8.0737e-04, 6.1391e-03, 9.0988e-04, 2.4125e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:02,211][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([1.9915e-04, 3.9366e-01, 3.9082e-03, 4.9694e-01, 4.5797e-03, 5.9994e-02,
        1.0005e-02, 3.2010e-04, 2.7045e-02, 2.1798e-03, 1.1657e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at]
[2024-07-24 10:18:02,211][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([1.4775e-02, 8.6792e-01, 1.6137e-03, 3.2880e-02, 1.8079e-03, 3.5596e-02,
        8.0543e-04, 2.9773e-02, 4.4505e-03, 8.1550e-04, 6.6970e-03, 2.8623e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:02,213][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([4.8323e-06, 2.2168e-01, 1.4741e-02, 3.2647e-01, 1.5837e-02, 3.8130e-01,
        1.0635e-02, 1.1279e-03, 8.2835e-03, 4.0223e-03, 2.1199e-03, 1.3785e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:02,216][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([2.0893e-05, 6.3405e-01, 8.1758e-02, 1.5975e-01, 6.1102e-02, 9.9477e-03,
        2.0371e-02, 2.3368e-05, 8.0379e-03, 2.9410e-03, 8.1484e-04, 2.1179e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:02,219][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([2.1676e-04, 4.5160e-02, 3.7386e-03, 1.6832e-01, 2.6790e-03, 4.0529e-01,
        4.9965e-02, 3.1704e-02, 1.8305e-02, 5.6451e-02, 3.8505e-02, 1.7967e-01],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:02,220][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([3.7019e-06, 2.1011e-01, 5.8234e-02, 6.1785e-01, 1.7587e-02, 3.7730e-02,
        1.7615e-02, 4.3246e-04, 8.5094e-03, 7.8765e-03, 3.7069e-03, 2.0348e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:02,220][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([2.7853e-06, 7.9900e-02, 4.2526e-02, 6.8155e-01, 4.7981e-02, 1.4851e-02,
        2.8106e-02, 3.6948e-05, 2.6034e-02, 9.7067e-03, 1.6701e-03, 6.7631e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:02,221][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0013, 0.3872, 0.1440, 0.2017, 0.1161, 0.0217, 0.0208, 0.0024, 0.0122,
        0.0188, 0.0037, 0.0700], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:02,222][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([3.5616e-06, 7.8565e-02, 3.6749e-02, 4.3713e-01, 1.1023e-01, 1.8401e-01,
        2.1907e-02, 9.7783e-04, 1.2435e-02, 2.3035e-02, 9.2719e-03, 8.5688e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:02,224][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([9.9901e-01, 1.4193e-10, 5.6487e-12, 6.3566e-09, 1.0582e-05, 7.6845e-07,
        3.2018e-09, 9.8082e-04, 1.6858e-08, 1.7322e-07, 3.2563e-08, 7.1247e-09],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:02,227][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([2.5296e-05, 8.1516e-01, 1.2561e-01, 4.2328e-02, 6.7983e-03, 5.8853e-05,
        1.0446e-03, 1.2212e-07, 6.1796e-03, 8.1741e-04, 6.0510e-05, 1.9164e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:02,230][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([6.3820e-05, 4.4268e-02, 2.1534e-02, 8.4998e-01, 2.7104e-03, 4.9728e-02,
        3.7001e-03, 4.3934e-03, 4.8896e-03, 1.7281e-03, 1.4287e-03, 1.5576e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:02,230][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([3.1883e-05, 1.9877e-01, 5.2816e-03, 5.9967e-01, 1.0418e-02, 1.1957e-01,
        8.7752e-03, 2.0728e-03, 4.3945e-03, 2.4890e-03, 8.7796e-04, 4.7645e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the]
[2024-07-24 10:18:02,231][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.0230, 0.8723, 0.0020, 0.0146, 0.0018, 0.0199, 0.0014, 0.0484, 0.0042,
        0.0013, 0.0066, 0.0036, 0.0010], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:02,232][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([5.8452e-05, 3.0674e-01, 2.7067e-02, 2.7161e-01, 1.7298e-02, 3.2703e-01,
        1.6349e-02, 2.9097e-03, 7.8124e-03, 2.9263e-03, 2.3988e-03, 9.2010e-03,
        8.5950e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:02,233][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([8.8573e-05, 4.0888e-01, 7.8716e-02, 3.0004e-01, 8.8153e-02, 3.0605e-02,
        4.0879e-02, 1.5786e-04, 1.1728e-02, 5.1511e-03, 1.3864e-03, 1.9010e-02,
        1.5205e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:02,237][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.0051, 0.1091, 0.0031, 0.0419, 0.0006, 0.2192, 0.0327, 0.4296, 0.0079,
        0.0199, 0.0158, 0.0728, 0.0422], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:02,240][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([2.0532e-05, 1.8411e-01, 1.1328e-01, 5.6368e-01, 2.2228e-02, 5.0607e-02,
        2.4074e-02, 1.4817e-03, 8.4871e-03, 8.7339e-03, 5.5623e-03, 1.5096e-02,
        2.6387e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:02,241][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([5.4735e-06, 5.0972e-02, 5.0460e-02, 4.6936e-01, 3.5999e-02, 6.1425e-02,
        4.9299e-02, 1.3149e-04, 5.3431e-02, 2.0866e-02, 8.4114e-03, 1.5260e-01,
        4.7048e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:02,242][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.0010, 0.2326, 0.1642, 0.2090, 0.1333, 0.0391, 0.0405, 0.0027, 0.0178,
        0.0271, 0.0055, 0.1003, 0.0268], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:02,243][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([9.5994e-06, 8.2484e-02, 2.0965e-02, 3.5766e-01, 7.1994e-02, 2.8735e-01,
        3.0877e-02, 3.4593e-03, 1.1092e-02, 3.2525e-02, 2.4962e-02, 6.1424e-02,
        1.5190e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:02,243][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([9.9973e-01, 2.4525e-13, 8.3945e-15, 5.2236e-11, 8.5865e-07, 2.9417e-08,
        4.2680e-11, 2.7005e-04, 3.5412e-10, 6.6358e-09, 1.0912e-09, 1.0352e-10,
        2.0656e-14], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:02,245][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([8.0437e-05, 5.1307e-01, 2.3305e-01, 1.4740e-01, 3.3386e-02, 1.3744e-03,
        6.5224e-03, 9.8043e-06, 1.9332e-02, 8.3470e-03, 8.9686e-04, 9.9820e-03,
        2.6538e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:02,248][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([1.6113e-04, 2.0778e-01, 4.9902e-02, 5.3859e-01, 3.9965e-03, 1.1526e-01,
        3.9123e-03, 5.5300e-02, 3.8910e-03, 4.0724e-03, 2.2872e-03, 8.9232e-03,
        5.9215e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:02,251][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([9.2314e-05, 2.7381e-01, 1.8212e-02, 5.0381e-01, 7.6182e-03, 1.3353e-01,
        7.6589e-03, 1.8793e-02, 4.9298e-03, 4.7286e-03, 1.8603e-03, 2.1665e-02,
        3.2881e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store]
[2024-07-24 10:18:02,252][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([1.8162e-02, 8.8021e-01, 2.1288e-03, 1.4568e-02, 1.6436e-03, 2.3317e-02,
        7.5337e-04, 4.6256e-02, 1.7363e-03, 6.5744e-04, 3.4302e-03, 2.0632e-03,
        5.8009e-04, 4.4897e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:02,252][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([2.7725e-06, 1.0486e-01, 1.3677e-02, 3.1406e-01, 9.9188e-03, 5.1982e-01,
        1.0251e-02, 2.1484e-03, 4.2351e-03, 2.5710e-03, 1.8434e-03, 9.2806e-03,
        2.6277e-03, 4.7043e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:02,253][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([2.3497e-05, 5.2509e-01, 1.0872e-01, 1.2400e-01, 1.1529e-01, 2.2844e-02,
        4.0989e-02, 1.0462e-04, 5.8193e-03, 4.9878e-03, 1.3053e-03, 2.0154e-02,
        1.1719e-02, 1.8950e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:02,254][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0008, 0.0392, 0.0109, 0.0941, 0.0072, 0.3851, 0.0130, 0.2197, 0.0029,
        0.0305, 0.0149, 0.0336, 0.0323, 0.1159], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:02,256][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([9.7012e-06, 3.0821e-01, 9.2238e-02, 4.6186e-01, 1.8684e-02, 5.0319e-02,
        2.1325e-02, 1.7735e-03, 7.0501e-03, 7.3660e-03, 4.2814e-03, 1.7202e-02,
        7.2314e-04, 8.9559e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:02,259][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([4.3732e-06, 1.2871e-01, 5.1785e-02, 4.7306e-01, 6.0266e-02, 5.8864e-02,
        5.9225e-02, 3.5828e-04, 3.2428e-02, 1.9504e-02, 3.3036e-03, 7.7757e-02,
        5.6211e-03, 2.9114e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:02,262][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0009, 0.3024, 0.1208, 0.1861, 0.0932, 0.0782, 0.0390, 0.0160, 0.0109,
        0.0259, 0.0067, 0.0914, 0.0052, 0.0234], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:02,262][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([1.3892e-06, 6.1043e-02, 2.1976e-02, 4.6006e-01, 5.4195e-02, 2.3408e-01,
        3.3783e-02, 6.3456e-04, 9.6553e-03, 2.0049e-02, 9.1634e-03, 8.1096e-02,
        6.7873e-03, 7.4709e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:02,263][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([9.9974e-01, 2.2565e-12, 8.9823e-14, 3.0870e-10, 1.9905e-06, 8.3686e-08,
        1.8614e-10, 2.5869e-04, 1.4450e-09, 1.7730e-08, 2.8915e-09, 4.3101e-10,
        1.8055e-13, 2.6723e-12], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:02,264][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([1.3414e-05, 7.4055e-01, 1.4061e-01, 6.5631e-02, 1.8985e-02, 6.9560e-04,
        4.0545e-03, 3.9716e-06, 7.0204e-03, 3.5943e-03, 2.4657e-04, 3.9253e-03,
        2.7594e-03, 1.1913e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:02,265][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([4.9034e-05, 2.6793e-02, 2.8710e-02, 7.7326e-01, 2.7368e-03, 9.0719e-02,
        4.5801e-03, 1.9713e-02, 3.6954e-03, 1.8079e-03, 1.2210e-03, 1.1364e-02,
        1.4884e-03, 3.3865e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:02,267][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([2.9309e-05, 1.3096e-01, 5.9772e-03, 5.5341e-01, 1.5521e-02, 1.3442e-01,
        9.4699e-03, 1.3872e-02, 2.8933e-03, 3.9032e-03, 1.4089e-03, 3.5497e-02,
        1.6286e-03, 9.1016e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store.]
[2024-07-24 10:18:02,272][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0105, 0.3682, 0.0039, 0.0600, 0.0102, 0.1649, 0.0103, 0.1240, 0.0549,
        0.0135, 0.0682, 0.0476, 0.0114, 0.0448, 0.0077], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:02,273][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([1.2386e-05, 1.0880e-01, 1.0725e-02, 2.0466e-01, 1.0302e-02, 6.0256e-01,
        1.0627e-02, 2.2783e-03, 4.7636e-03, 4.3550e-03, 2.4221e-03, 1.5891e-02,
        5.3614e-03, 9.9706e-03, 7.2666e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:02,274][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([6.2087e-05, 2.6737e-01, 5.5839e-02, 1.4427e-01, 1.2485e-01, 6.2898e-02,
        5.6501e-02, 9.0253e-04, 8.4162e-03, 1.2474e-02, 3.5715e-03, 4.5561e-02,
        1.8287e-02, 2.0393e-02, 1.7860e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:02,275][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([1.7794e-05, 2.6444e-03, 8.5553e-04, 1.4788e-02, 1.8254e-03, 1.8585e-01,
        3.5551e-02, 1.9812e-01, 8.9468e-03, 1.3138e-01, 6.6379e-02, 8.5419e-02,
        3.2536e-02, 2.0515e-01, 3.0530e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:02,276][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([2.9346e-05, 2.5504e-01, 7.3960e-02, 4.1967e-01, 2.2676e-02, 1.1996e-01,
        2.1541e-02, 7.5437e-03, 9.3285e-03, 1.8543e-02, 1.0859e-02, 2.7574e-02,
        2.4421e-03, 8.4894e-03, 2.3488e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:02,277][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([1.2865e-05, 5.3295e-02, 5.5511e-02, 3.3624e-01, 5.8648e-02, 1.1477e-01,
        7.1940e-02, 8.0647e-04, 3.9610e-02, 3.6628e-02, 6.8882e-03, 1.5421e-01,
        1.0798e-02, 3.3732e-02, 2.6915e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:02,283][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0008, 0.1260, 0.0559, 0.1674, 0.1476, 0.2075, 0.0337, 0.0652, 0.0112,
        0.0538, 0.0112, 0.0814, 0.0036, 0.0121, 0.0228], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:02,284][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([5.5474e-06, 2.6838e-02, 2.8230e-02, 1.6191e-01, 1.0466e-01, 4.9378e-01,
        2.1389e-02, 1.1769e-02, 6.2414e-03, 5.4678e-02, 1.8499e-02, 4.6763e-02,
        6.2506e-03, 3.6315e-03, 1.5358e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:02,285][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.5756, 0.0106, 0.0038, 0.0121, 0.0686, 0.0345, 0.0116, 0.0288, 0.0132,
        0.0189, 0.0106, 0.0226, 0.0096, 0.0132, 0.1663], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:02,285][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([1.5339e-04, 5.4687e-01, 1.8977e-01, 1.3515e-01, 4.0361e-02, 3.8992e-03,
        6.7366e-03, 8.6255e-05, 1.1011e-02, 8.1950e-03, 1.1407e-03, 9.7765e-03,
        1.1778e-02, 2.2764e-02, 1.2310e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:02,286][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([4.6718e-05, 1.3368e-02, 1.5741e-02, 4.4385e-01, 7.3352e-03, 2.2355e-01,
        1.7558e-02, 6.2430e-02, 1.3140e-02, 1.2958e-02, 6.0932e-03, 4.4510e-02,
        1.5146e-02, 5.6705e-02, 6.7567e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:02,288][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([4.5868e-06, 1.1740e-02, 4.2353e-03, 8.1098e-02, 1.0431e-02, 3.9932e-01,
        2.3955e-02, 3.1461e-01, 3.1488e-03, 2.7231e-02, 9.8305e-03, 5.4543e-02,
        1.3690e-03, 4.6032e-02, 1.2447e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany]
[2024-07-24 10:18:02,291][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([1.7675e-03, 4.2866e-01, 3.2874e-04, 4.7252e-02, 4.9741e-04, 4.3209e-02,
        2.7170e-04, 8.1632e-03, 6.7450e-03, 4.7081e-04, 9.0081e-03, 1.7270e-03,
        3.5072e-04, 3.7743e-03, 2.1614e-03, 4.4562e-01], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:02,294][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([9.5542e-05, 6.5402e-01, 2.4922e-02, 1.4162e-01, 2.6250e-02, 4.3804e-02,
        3.9985e-03, 3.5456e-04, 9.1953e-03, 2.7259e-03, 1.2377e-03, 1.3728e-02,
        1.4366e-02, 1.3367e-02, 3.7791e-02, 1.2528e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:02,294][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([5.5846e-05, 5.7941e-01, 8.0362e-02, 1.3478e-01, 3.5356e-02, 7.5638e-03,
        1.1574e-02, 4.0982e-05, 9.5208e-03, 1.4704e-03, 5.9331e-04, 2.3070e-02,
        1.2722e-02, 1.8990e-02, 8.2132e-02, 2.3586e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:02,295][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([1.9497e-03, 1.0267e-01, 1.2354e-03, 2.4784e-02, 1.5989e-04, 3.9282e-03,
        7.3020e-03, 2.2993e-05, 1.4930e-02, 8.3557e-04, 6.4989e-04, 6.2144e-02,
        6.6371e-02, 6.8427e-01, 1.3392e-02, 1.5355e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:02,296][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([1.2520e-06, 9.0075e-02, 2.2998e-02, 7.2500e-01, 1.6908e-02, 5.6902e-02,
        1.3146e-02, 6.0828e-05, 1.8631e-02, 9.7272e-03, 3.0876e-03, 2.6106e-02,
        1.9961e-03, 9.5725e-03, 3.0056e-03, 2.7799e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:02,297][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([1.4441e-05, 1.0950e-01, 5.1724e-02, 6.7845e-01, 4.0488e-02, 4.5659e-03,
        1.2528e-02, 3.5914e-06, 4.2324e-02, 4.2539e-03, 7.8044e-04, 1.7912e-02,
        6.6792e-03, 2.1695e-02, 8.5421e-03, 5.4462e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:02,299][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([3.3078e-03, 4.3481e-01, 8.5555e-02, 9.0734e-02, 9.0042e-02, 5.8881e-03,
        1.3148e-02, 2.6426e-04, 3.3958e-02, 6.4241e-03, 1.6835e-03, 7.1184e-02,
        4.2920e-02, 5.7335e-02, 5.7928e-02, 4.8211e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:02,302][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([7.7745e-05, 3.4056e-01, 5.5141e-02, 2.8755e-01, 1.1367e-01, 5.1162e-02,
        1.0404e-02, 5.5212e-04, 2.9785e-02, 1.2058e-02, 4.1258e-03, 4.3561e-02,
        2.7629e-02, 8.0411e-03, 1.2626e-02, 3.0588e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:02,304][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([9.9687e-01, 6.1307e-10, 5.8552e-11, 2.1871e-08, 3.2592e-05, 1.5086e-06,
        1.3327e-08, 8.0614e-04, 4.7343e-08, 6.5354e-07, 1.2633e-07, 3.7750e-08,
        7.7252e-11, 5.5012e-10, 2.2865e-03, 6.4207e-06], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:02,305][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([5.3373e-04, 7.9890e-01, 4.5635e-02, 1.2607e-02, 5.5765e-03, 2.9042e-06,
        3.9657e-04, 2.4159e-09, 2.7213e-02, 1.9389e-04, 2.1314e-05, 1.3439e-03,
        3.9447e-02, 5.1616e-02, 1.6514e-02, 4.0860e-07], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:02,306][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([1.8996e-04, 3.8461e-01, 3.7788e-02, 5.3486e-01, 1.2369e-03, 5.9449e-03,
        5.8196e-04, 1.1605e-04, 3.4287e-03, 3.3650e-04, 5.8245e-04, 5.9769e-03,
        3.1833e-03, 1.2445e-02, 4.5441e-03, 4.1728e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:02,307][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([2.8814e-04, 6.9571e-01, 7.8144e-03, 1.9723e-01, 2.6799e-03, 4.8072e-02,
        1.9816e-03, 1.1811e-03, 4.2351e-03, 9.3880e-04, 2.8057e-04, 1.0589e-02,
        6.9424e-04, 1.1396e-02, 1.1155e-03, 1.5799e-02], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave]
[2024-07-24 10:18:02,308][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.3131e-02, 8.6968e-01, 7.1075e-04, 2.6784e-02, 7.9739e-04, 1.7677e-02,
        3.2317e-04, 1.1327e-02, 2.0721e-03, 4.5535e-04, 3.8449e-03, 1.4201e-03,
        6.4541e-04, 2.5456e-03, 7.0528e-04, 4.6791e-02, 1.0867e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:02,310][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.2560e-06, 9.6393e-02, 8.9437e-03, 3.4922e-01, 1.1198e-02, 4.7480e-01,
        4.3972e-03, 2.1028e-03, 2.7987e-03, 3.5260e-03, 1.3824e-03, 8.7329e-03,
        2.3843e-03, 3.6736e-03, 2.9909e-03, 2.3298e-02, 4.1616e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:02,312][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([4.3826e-06, 3.7034e-01, 8.2770e-02, 2.0155e-01, 1.4703e-01, 2.5174e-02,
        1.5646e-02, 1.6825e-04, 2.3242e-03, 4.1987e-03, 1.1852e-03, 7.7877e-03,
        3.9122e-03, 6.3101e-03, 1.2710e-01, 1.3975e-03, 3.1036e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:02,315][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.1201e-04, 3.3645e-02, 5.6711e-03, 7.2322e-02, 1.9432e-03, 1.8397e-01,
        4.1017e-03, 5.2041e-02, 1.0763e-03, 9.9346e-03, 6.3022e-03, 9.7453e-03,
        1.2147e-02, 5.5482e-02, 5.1149e-03, 4.8200e-01, 6.4398e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:02,316][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([4.1638e-07, 1.3219e-01, 4.5004e-02, 6.8289e-01, 1.6406e-02, 6.9899e-02,
        1.0808e-02, 1.2604e-04, 7.1473e-03, 4.9775e-03, 1.7920e-03, 1.7139e-02,
        3.3054e-04, 4.0839e-03, 4.0290e-04, 1.4784e-03, 5.3209e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:02,317][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([4.5219e-06, 1.0799e-01, 7.4933e-02, 6.5005e-01, 4.5350e-02, 8.8375e-03,
        1.6478e-02, 1.0350e-05, 2.2902e-02, 3.3387e-03, 5.5943e-04, 2.7349e-02,
        2.2493e-03, 1.5690e-02, 4.6691e-03, 1.1824e-03, 1.8408e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:02,318][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0006, 0.1908, 0.1523, 0.3087, 0.1597, 0.0316, 0.0179, 0.0045, 0.0097,
        0.0159, 0.0028, 0.0489, 0.0023, 0.0112, 0.0121, 0.0152, 0.0157],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:02,319][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([1.0371e-06, 5.8244e-02, 5.4129e-02, 4.1440e-01, 1.5551e-01, 1.6719e-01,
        1.8665e-02, 5.6299e-04, 1.0715e-02, 1.8541e-02, 6.0474e-03, 7.4488e-02,
        3.7732e-03, 4.0184e-03, 4.4166e-03, 3.0352e-03, 6.2577e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:02,321][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([9.9636e-01, 1.8736e-09, 8.7657e-11, 5.1719e-08, 4.4654e-05, 3.4711e-06,
        2.7897e-08, 1.5615e-03, 1.3655e-07, 9.5172e-07, 2.1474e-07, 6.9014e-08,
        1.7268e-10, 1.4674e-09, 2.0159e-03, 1.0616e-05, 8.8417e-08],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:02,323][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([4.0272e-05, 8.4227e-01, 9.2431e-02, 4.1375e-02, 5.0462e-03, 1.9878e-05,
        6.2893e-04, 1.9037e-08, 6.0069e-03, 2.6092e-04, 1.7797e-05, 7.6103e-04,
        1.2082e-03, 8.6016e-03, 1.1110e-03, 7.7002e-07, 2.2177e-04],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:02,326][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([4.0987e-05, 4.8199e-02, 2.1096e-02, 8.0035e-01, 9.6889e-04, 4.2475e-02,
        1.4721e-03, 3.4658e-03, 2.1291e-03, 3.8862e-04, 6.8429e-04, 4.6176e-03,
        1.5132e-03, 2.1388e-02, 3.8972e-03, 3.9290e-02, 8.0224e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:02,327][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.1256e-05, 1.8379e-01, 4.9224e-03, 3.2584e-01, 9.6776e-03, 2.3684e-01,
        6.5782e-03, 7.4556e-02, 1.3382e-03, 4.4044e-03, 1.8279e-03, 1.8951e-02,
        4.1215e-04, 2.7156e-02, 6.2025e-03, 8.8004e-02, 9.4897e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a]
[2024-07-24 10:18:02,328][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.0328, 0.6668, 0.0010, 0.0245, 0.0009, 0.0318, 0.0008, 0.0417, 0.0051,
        0.0012, 0.0077, 0.0028, 0.0013, 0.0047, 0.0008, 0.1696, 0.0027, 0.0039],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:02,329][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([2.9241e-05, 2.1025e-01, 1.0128e-02, 2.9802e-01, 1.7519e-02, 3.8400e-01,
        5.1434e-03, 2.7215e-03, 3.7045e-03, 2.3183e-03, 1.3617e-03, 1.1559e-02,
        1.8140e-03, 4.9566e-03, 7.5565e-03, 2.6001e-02, 5.9503e-03, 6.9659e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:02,329][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([1.9724e-05, 1.9666e-01, 3.3780e-02, 1.9634e-01, 2.2298e-01, 2.5398e-02,
        2.5691e-02, 2.0551e-04, 3.0759e-03, 5.1641e-03, 1.4762e-03, 1.2142e-02,
        4.6641e-03, 5.6144e-03, 2.5690e-01, 1.9171e-03, 6.3101e-03, 1.6692e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:02,331][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([1.7971e-04, 3.8059e-02, 1.0553e-03, 4.3057e-02, 4.4030e-04, 5.3762e-02,
        6.8974e-03, 1.0429e-02, 3.3660e-03, 5.3636e-03, 5.3412e-03, 2.8600e-02,
        1.8932e-02, 2.9395e-01, 5.7559e-03, 2.2626e-01, 2.1834e-01, 4.0209e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:02,334][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([4.1244e-06, 1.7546e-01, 7.1024e-02, 5.6913e-01, 3.1310e-02, 8.0693e-02,
        1.6187e-02, 1.6237e-04, 1.2484e-02, 5.8411e-03, 2.2369e-03, 1.7977e-02,
        9.0728e-04, 4.2981e-03, 9.8059e-04, 1.9236e-03, 4.7457e-03, 4.6399e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:02,337][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([5.0173e-06, 6.0931e-02, 6.5294e-02, 6.0672e-01, 5.8003e-02, 5.2461e-03,
        1.9415e-02, 2.9047e-06, 4.1777e-02, 3.3457e-03, 6.3742e-04, 5.2027e-02,
        3.5485e-03, 3.3325e-02, 1.1251e-02, 1.4710e-03, 3.0385e-02, 6.6219e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:02,338][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.0023, 0.2419, 0.0906, 0.2806, 0.1742, 0.0510, 0.0147, 0.0057, 0.0091,
        0.0142, 0.0027, 0.0436, 0.0023, 0.0100, 0.0157, 0.0230, 0.0128, 0.0056],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:02,338][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([8.8048e-06, 6.0102e-02, 4.7631e-02, 2.4695e-01, 2.5885e-01, 1.5534e-01,
        2.0620e-02, 1.4948e-03, 1.5972e-02, 3.8407e-02, 7.9103e-03, 7.8075e-02,
        5.2090e-03, 6.1683e-03, 1.8159e-02, 7.2800e-03, 1.0307e-02, 2.1510e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:02,339][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([9.9527e-01, 5.7772e-09, 4.4154e-10, 1.3607e-07, 9.5377e-05, 6.2784e-06,
        1.1787e-07, 9.4907e-04, 4.5462e-07, 2.6424e-06, 6.5517e-07, 2.6660e-07,
        1.3164e-09, 9.1017e-09, 3.6557e-03, 1.6282e-05, 3.7346e-07, 2.6407e-07],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:02,341][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([3.6844e-04, 8.9471e-01, 5.0859e-02, 2.6437e-02, 4.7586e-03, 1.6387e-05,
        3.7155e-04, 4.0427e-08, 6.9133e-03, 2.3503e-04, 2.5806e-05, 6.1573e-04,
        2.0508e-03, 9.2795e-03, 1.8945e-03, 1.0312e-06, 1.7114e-04, 1.2874e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:02,342][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([2.0224e-04, 1.6895e-01, 1.6449e-02, 5.7446e-01, 1.5382e-03, 5.3904e-02,
        2.2220e-03, 1.1026e-02, 4.6903e-03, 1.4857e-03, 1.9837e-03, 1.1476e-02,
        3.8508e-03, 3.8054e-02, 8.8812e-03, 7.4332e-02, 1.4443e-02, 1.2047e-02],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:02,345][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([1.2431e-04, 3.2662e-01, 7.3069e-03, 1.8826e-01, 7.4551e-03, 1.6667e-01,
        8.2707e-03, 7.5370e-02, 3.2469e-03, 7.7351e-03, 2.7967e-03, 2.8783e-02,
        1.6082e-03, 4.2438e-02, 5.7799e-03, 1.0920e-01, 1.3557e-02, 4.7835e-03],
       device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink]
[2024-07-24 10:18:02,347][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([5.0476e-02, 7.1552e-01, 2.6389e-03, 1.8393e-02, 1.8304e-03, 2.7116e-02,
        1.0139e-03, 8.8357e-02, 3.4532e-03, 1.3567e-03, 6.2854e-03, 3.8909e-03,
        1.3012e-03, 8.9029e-03, 6.7315e-04, 5.9714e-02, 3.3981e-03, 1.5580e-03,
        4.1219e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:02,348][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([6.3754e-06, 1.0829e-01, 1.4045e-02, 2.6992e-01, 1.3751e-02, 4.8684e-01,
        1.5686e-02, 3.2141e-03, 7.1828e-03, 5.4081e-03, 3.0537e-03, 1.8930e-02,
        4.6002e-03, 9.5764e-03, 3.4857e-03, 1.7197e-02, 1.0452e-02, 7.7546e-03,
        6.0780e-04], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:02,349][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([3.0333e-05, 4.2866e-01, 8.4550e-02, 1.0272e-01, 1.0421e-01, 2.5442e-02,
        3.4387e-02, 2.2447e-04, 6.6245e-03, 6.1559e-03, 1.9673e-03, 2.2603e-02,
        2.0635e-02, 1.9966e-02, 1.2062e-01, 1.3003e-03, 9.0496e-03, 7.0252e-03,
        3.8200e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:02,350][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.3932e-04, 1.0759e-02, 2.5057e-03, 1.2878e-02, 1.2088e-03, 1.1840e-01,
        6.8925e-03, 2.0553e-01, 8.2134e-04, 1.7275e-02, 1.0086e-02, 1.1735e-02,
        1.3194e-02, 4.2852e-02, 6.4779e-03, 3.8059e-01, 1.0802e-01, 4.4175e-02,
        6.4623e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:02,351][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([8.7727e-06, 3.0573e-01, 6.3123e-02, 3.7984e-01, 1.5664e-02, 7.3160e-02,
        3.4574e-02, 1.4343e-03, 1.6452e-02, 1.9822e-02, 1.0662e-02, 3.2374e-02,
        1.2538e-03, 1.9168e-02, 1.1282e-03, 3.5097e-03, 1.3644e-02, 4.9476e-03,
        3.4982e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:02,353][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([6.3393e-06, 4.9513e-02, 3.8891e-02, 4.4343e-01, 4.2887e-02, 5.4978e-02,
        6.7519e-02, 3.1464e-04, 4.0460e-02, 1.9249e-02, 4.1497e-03, 1.1062e-01,
        8.0208e-03, 2.9159e-02, 7.2426e-03, 5.7689e-03, 5.7343e-02, 1.3375e-02,
        7.0801e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:02,358][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0011, 0.2156, 0.0983, 0.1147, 0.1058, 0.0481, 0.0493, 0.0113, 0.0214,
        0.0324, 0.0092, 0.1168, 0.0116, 0.0464, 0.0337, 0.0242, 0.0378, 0.0152,
        0.0071], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:02,359][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([3.9714e-06, 5.4692e-02, 2.4535e-02, 3.0663e-01, 5.9067e-02, 2.8438e-01,
        3.7349e-02, 1.6578e-03, 1.1586e-02, 2.9900e-02, 1.5613e-02, 9.7589e-02,
        1.4198e-02, 1.1416e-02, 7.6204e-03, 8.0060e-03, 1.5801e-02, 1.8258e-02,
        1.6970e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:02,360][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.9871e-01, 1.5083e-11, 9.1548e-13, 1.7249e-09, 7.3574e-06, 3.3650e-07,
        1.7023e-09, 4.8534e-04, 8.7680e-09, 1.0160e-07, 2.0250e-08, 4.0110e-09,
        2.5540e-12, 3.9169e-11, 7.9389e-04, 9.5966e-07, 4.8857e-09, 3.2560e-09,
        7.5039e-11], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:02,361][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([7.4651e-05, 6.3243e-01, 1.5982e-01, 6.2058e-02, 3.3059e-02, 1.8955e-03,
        7.7921e-03, 5.7322e-05, 1.2909e-02, 9.2729e-03, 1.0582e-03, 1.0241e-02,
        9.0805e-03, 2.6224e-02, 1.0984e-02, 1.7015e-04, 4.0216e-03, 1.5578e-02,
        3.2740e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:02,362][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([5.7714e-05, 5.5863e-02, 3.6761e-02, 5.8239e-01, 1.6464e-03, 1.3085e-01,
        5.4955e-03, 3.3975e-02, 4.3076e-03, 1.6166e-03, 2.4854e-03, 1.0313e-02,
        2.5581e-03, 3.2419e-02, 3.6085e-03, 6.8820e-02, 1.7453e-02, 4.4655e-03,
        4.9110e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:02,364][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.6292e-05, 7.9206e-02, 5.4665e-03, 1.6898e-01, 9.2974e-03, 2.4308e-01,
        9.4191e-03, 1.9003e-01, 2.0859e-03, 1.1942e-02, 4.7986e-03, 2.1853e-02,
        1.8342e-03, 3.9469e-02, 1.2321e-02, 1.7455e-01, 1.9127e-02, 2.3327e-03,
        4.1785e-03], device='cuda:0') for source tokens [Then, Jamie and Tiffany had a lot of fun at the store. Tiffany gave a drink to]
[2024-07-24 10:18:02,367][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:02,371][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[3080],
        [  15],
        [ 245],
        [  11],
        [  36],
        [   7],
        [  23],
        [  76],
        [   7],
        [  63],
        [  43],
        [  11],
        [  19],
        [  16],
        [   9],
        [  15],
        [   7],
        [  20],
        [   1]], device='cuda:0')
[2024-07-24 10:18:02,372][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[3136],
        [  11],
        [ 196],
        [   9],
        [  17],
        [   6],
        [  16],
        [  45],
        [   3],
        [  51],
        [  22],
        [   7],
        [  13],
        [   4],
        [   2],
        [   6],
        [   2],
        [  14],
        [   1]], device='cuda:0')
[2024-07-24 10:18:02,374][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[10072],
        [26398],
        [25224],
        [29215],
        [29913],
        [29476],
        [28084],
        [31534],
        [30640],
        [29154],
        [28607],
        [28726],
        [28530],
        [28545],
        [35051],
        [33058],
        [28552],
        [30689],
        [30201]], device='cuda:0')
[2024-07-24 10:18:02,376][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[  305],
        [ 6112],
        [41929],
        [18239],
        [25961],
        [11233],
        [ 5247],
        [11004],
        [ 5144],
        [ 7114],
        [ 7919],
        [ 4433],
        [ 4796],
        [ 3619],
        [ 2922],
        [ 8534],
        [ 3838],
        [ 4167],
        [ 3810]], device='cuda:0')
[2024-07-24 10:18:02,380][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 4431],
        [37780],
        [50008],
        [48701],
        [27929],
        [42436],
        [32499],
        [41294],
        [36718],
        [33321],
        [40266],
        [34814],
        [22618],
        [34184],
        [15412],
        [34637],
        [25204],
        [12625],
        [28700]], device='cuda:0')
[2024-07-24 10:18:02,383][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[34951],
        [30015],
        [18371],
        [16420],
        [13291],
        [15725],
        [ 7879],
        [20277],
        [ 7741],
        [22950],
        [18906],
        [ 8064],
        [ 7410],
        [ 7768],
        [ 9173],
        [25435],
        [10069],
        [16274],
        [ 9235]], device='cuda:0')
[2024-07-24 10:18:02,384][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[13241],
        [19603],
        [11273],
        [23980],
        [22688],
        [27211],
        [25763],
        [26615],
        [24095],
        [26462],
        [25970],
        [26108],
        [25276],
        [24576],
        [25924],
        [27373],
        [26698],
        [26068],
        [25642]], device='cuda:0')
[2024-07-24 10:18:02,386][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[40472],
        [39708],
        [15212],
        [19490],
        [22655],
        [21759],
        [21698],
        [30707],
        [19054],
        [19054],
        [21224],
        [19637],
        [17782],
        [20009],
        [18388],
        [19868],
        [19837],
        [18428],
        [17500]], device='cuda:0')
[2024-07-24 10:18:02,388][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[29939],
        [30929],
        [46453],
        [40067],
        [39588],
        [38661],
        [37754],
        [34139],
        [38757],
        [39257],
        [36776],
        [38566],
        [40374],
        [39310],
        [40191],
        [39225],
        [39205],
        [37964],
        [41034]], device='cuda:0')
[2024-07-24 10:18:02,391][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[49908],
        [32511],
        [35881],
        [31821],
        [45044],
        [41623],
        [41850],
        [32589],
        [40552],
        [41324],
        [37761],
        [39769],
        [41304],
        [39392],
        [44793],
        [38456],
        [40550],
        [43693],
        [41751]], device='cuda:0')
[2024-07-24 10:18:02,394][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 9184],
        [12975],
        [25398],
        [ 5764],
        [ 5045],
        [27441],
        [ 5881],
        [13455],
        [ 4543],
        [17771],
        [15385],
        [ 6029],
        [ 4808],
        [ 5149],
        [ 4848],
        [13944],
        [17729],
        [14473],
        [ 4388]], device='cuda:0')
[2024-07-24 10:18:02,396][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[29345],
        [40718],
        [46999],
        [44545],
        [43704],
        [42455],
        [43313],
        [40410],
        [43576],
        [42838],
        [42584],
        [43111],
        [44954],
        [43495],
        [44389],
        [42084],
        [42618],
        [41936],
        [44038]], device='cuda:0')
[2024-07-24 10:18:02,397][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[40348],
        [24935],
        [  384],
        [26229],
        [24558],
        [25973],
        [27963],
        [23897],
        [29479],
        [25908],
        [25886],
        [26854],
        [26385],
        [26440],
        [28490],
        [23415],
        [26785],
        [27450],
        [27867]], device='cuda:0')
[2024-07-24 10:18:02,400][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[12423],
        [28462],
        [36098],
        [18497],
        [20210],
        [19979],
        [20466],
        [28208],
        [23628],
        [23764],
        [22857],
        [21586],
        [22947],
        [23365],
        [31277],
        [26851],
        [27574],
        [30711],
        [32355]], device='cuda:0')
[2024-07-24 10:18:02,403][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 7673],
        [ 7667],
        [ 7244],
        [ 7740],
        [ 9161],
        [ 8618],
        [ 8829],
        [11750],
        [10261],
        [ 8407],
        [ 8737],
        [ 9152],
        [ 8810],
        [ 8742],
        [10232],
        [ 9990],
        [10116],
        [ 8661],
        [ 8873]], device='cuda:0')
[2024-07-24 10:18:02,406][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[11918],
        [ 9614],
        [ 9670],
        [10727],
        [11835],
        [10605],
        [ 9937],
        [11583],
        [11785],
        [10718],
        [10257],
        [10355],
        [10381],
        [10359],
        [12954],
        [12112],
        [10267],
        [11437],
        [11380]], device='cuda:0')
[2024-07-24 10:18:02,408][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[18240],
        [24819],
        [18525],
        [23242],
        [19942],
        [23752],
        [22581],
        [24136],
        [22821],
        [24273],
        [24045],
        [23302],
        [23507],
        [22996],
        [23086],
        [23866],
        [23015],
        [23300],
        [22784]], device='cuda:0')
[2024-07-24 10:18:02,409][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[23391],
        [26690],
        [27396],
        [29193],
        [33170],
        [29129],
        [31303],
        [27760],
        [29546],
        [29906],
        [28192],
        [29879],
        [31124],
        [30544],
        [31407],
        [29743],
        [32329],
        [33050],
        [30456]], device='cuda:0')
[2024-07-24 10:18:02,411][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[10834],
        [10869],
        [12375],
        [10252],
        [11224],
        [ 9684],
        [ 7830],
        [ 9203],
        [ 6575],
        [ 5655],
        [ 6244],
        [ 7567],
        [ 6985],
        [ 6963],
        [ 6789],
        [ 6324],
        [ 6886],
        [ 6784],
        [ 6544]], device='cuda:0')
[2024-07-24 10:18:02,415][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[16056],
        [ 9446],
        [18454],
        [20380],
        [18610],
        [21560],
        [21406],
        [21279],
        [19551],
        [22256],
        [20898],
        [20704],
        [21156],
        [19692],
        [20890],
        [22499],
        [21497],
        [21334],
        [21096]], device='cuda:0')
[2024-07-24 10:18:02,418][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 8294],
        [15658],
        [ 9778],
        [10926],
        [ 8595],
        [10457],
        [10298],
        [14837],
        [ 8693],
        [10525],
        [11263],
        [ 9949],
        [ 9156],
        [ 9654],
        [ 8284],
        [10504],
        [10427],
        [ 9781],
        [ 8861]], device='cuda:0')
[2024-07-24 10:18:02,419][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[4644],
        [5547],
        [2302],
        [2260],
        [2640],
        [2756],
        [2360],
        [3888],
        [2792],
        [2577],
        [3110],
        [2503],
        [2259],
        [2613],
        [2985],
        [2686],
        [2190],
        [2384],
        [2488]], device='cuda:0')
[2024-07-24 10:18:02,421][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[10338],
        [ 5179],
        [18471],
        [10665],
        [14316],
        [12074],
        [14035],
        [ 6575],
        [13021],
        [12006],
        [10206],
        [12944],
        [13132],
        [12788],
        [15534],
        [10865],
        [13601],
        [14643],
        [14162]], device='cuda:0')
[2024-07-24 10:18:02,423][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[15971],
        [15971],
        [15971],
        [15971],
        [15968],
        [15971],
        [15971],
        [15967],
        [15969],
        [15967],
        [15970],
        [15969],
        [15970],
        [15970],
        [15237],
        [15970],
        [15968],
        [15969],
        [15971]], device='cuda:0')
[2024-07-24 10:18:02,426][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[9007],
        [7120],
        [4637],
        [6081],
        [5644],
        [6712],
        [6547],
        [7023],
        [6375],
        [6660],
        [6673],
        [6550],
        [5873],
        [6434],
        [6017],
        [6868],
        [6707],
        [6901],
        [6251]], device='cuda:0')
[2024-07-24 10:18:02,430][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[7951],
        [8630],
        [5646],
        [5888],
        [5675],
        [5695],
        [5699],
        [7257],
        [5182],
        [5702],
        [5737],
        [5746],
        [5143],
        [5456],
        [4744],
        [5736],
        [5528],
        [5200],
        [4943]], device='cuda:0')
[2024-07-24 10:18:02,431][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[14659],
        [12594],
        [16913],
        [ 9918],
        [10258],
        [10348],
        [10025],
        [12579],
        [10451],
        [10752],
        [11063],
        [10434],
        [10872],
        [10246],
        [13482],
        [11973],
        [11481],
        [11996],
        [13170]], device='cuda:0')
[2024-07-24 10:18:02,433][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[30916],
        [29617],
        [28033],
        [31289],
        [30315],
        [30320],
        [30661],
        [29251],
        [32047],
        [32073],
        [32332],
        [31079],
        [31442],
        [31675],
        [30202],
        [31515],
        [30280],
        [29552],
        [30614]], device='cuda:0')
[2024-07-24 10:18:02,435][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[35124],
        [29907],
        [32237],
        [29386],
        [30243],
        [30539],
        [30831],
        [24830],
        [28803],
        [31130],
        [30198],
        [30293],
        [30093],
        [29658],
        [27374],
        [28908],
        [30615],
        [32392],
        [31287]], device='cuda:0')
[2024-07-24 10:18:02,438][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[7479],
        [7479],
        [7479],
        [7479],
        [7479],
        [7479],
        [7479],
        [7479],
        [7479],
        [7479],
        [7479],
        [7479],
        [7479],
        [7479],
        [7479],
        [7479],
        [7479],
        [7479],
        [7479]], device='cuda:0')
