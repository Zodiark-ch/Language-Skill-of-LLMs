[2024-07-24 10:31:23,001][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isWhen Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to
[2024-07-24 10:31:23,001][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Nathan
[2024-07-24 10:31:23,002][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:31:23,002][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:31:23,002][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:31:23,002][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,002][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:31:23,002][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit24']
[2024-07-24 10:31:23,003][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:31:23,003][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,003][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:31:23,003][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,003][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:31:23,003][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,003][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:31:23,004][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,004][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:31:23,004][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,004][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:31:23,004][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,004][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:31:23,005][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,005][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:31:23,005][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,005][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:31:23,005][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,005][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:31:23,006][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,006][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:31:23,006][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,006][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:31:23,006][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,006][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:31:23,007][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,007][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:31:23,007][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:31:23,007][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:31:23,007][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,007][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:31:23,007][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:31:23,008][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:31:23,008][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:31:23,008][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:31:23,008][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,008][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:31:23,008][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,009][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:31:23,009][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:31:23,009][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:31:23,009][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,009][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:31:23,009][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,010][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:31:23,010][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,010][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:31:23,010][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21']
[2024-07-24 10:31:23,010][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:31:23,010][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,010][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:31:23,011][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,011][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:31:23,011][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,011][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:31:23,011][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,011][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,012][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:31:23,012][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:31:23,012][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,012][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:31:23,012][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit22']
[2024-07-24 10:31:23,012][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20']
[2024-07-24 10:31:23,013][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:31:23,013][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,013][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,013][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:31:23,013][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,013][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,014][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:31:23,014][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,014][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,014][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:31:23,014][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,014][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,015][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:31:23,015][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:31:23,015][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,015][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:31:23,015][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20']
[2024-07-24 10:31:23,015][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:31:23,015][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:31:23,016][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,016][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,016][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:31:23,016][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:31:23,016][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,016][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:31:23,017][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:31:23,017][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,017][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:31:23,017][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:31:23,017][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,017][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:31:23,018][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,018][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,018][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:31:23,018][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,018][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,018][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:31:23,019][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit27']
[2024-07-24 10:31:23,019][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,019][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:31:23,019][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:31:23,019][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,019][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:31:23,019][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,020][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit19', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,020][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:31:23,020][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit22']
[2024-07-24 10:31:23,020][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,020][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:31:23,020][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,021][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:31:23,021][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:31:23,021][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,021][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,021][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:31:23,021][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,022][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,022][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:31:23,022][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,022][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,022][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:31:23,022][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,023][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,023][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:31:23,023][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,023][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,023][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:31:23,023][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit26']
[2024-07-24 10:31:23,023][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,024][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:31:23,024][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,024][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,024][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:31:23,024][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,024][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,025][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:31:23,025][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,025][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,025][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:31:23,025][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,025][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,026][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,026][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:31:23,026][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,026][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,026][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:31:23,026][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:31:23,027][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:31:23,027][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,027][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,027][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:31:23,027][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,027][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,027][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14']
[2024-07-24 10:31:23,028][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:31:23,028][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,028][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,028][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,028][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:31:23,028][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,029][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,029][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,029][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:31:23,029][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:31:23,029][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19']
[2024-07-24 10:31:23,029][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit22', 'circuit23']
[2024-07-24 10:31:23,030][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:31:23,030][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:31:23,030][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,030][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,030][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:31:23,030][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,031][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,031][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,031][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:31:23,031][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit27']
[2024-07-24 10:31:23,031][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17']
[2024-07-24 10:31:23,031][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,031][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:31:23,032][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,032][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,032][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,032][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:31:23,032][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,032][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,033][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit23']
[2024-07-24 10:31:23,033][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:31:23,033][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,033][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,033][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,033][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:31:23,034][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,034][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,034][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,034][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:31:23,034][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:31:23,034][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:31:23,035][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,035][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:31:23,035][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,035][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit4', 'circuit6', 'circuit13', 'circuit20', 'circuit24']
[2024-07-24 10:31:23,035][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:31:23,035][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:31:23,035][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:31:23,036][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:31:23,036][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit25']
[2024-07-24 10:31:23,036][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:31:23,036][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,036][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,036][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,037][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:31:23,037][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,037][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,037][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit7', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,037][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:31:23,037][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,038][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19']
[2024-07-24 10:31:23,038][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,038][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:31:23,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,038][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,038][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,039][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:31:23,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:31:23,039][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,039][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:31:23,039][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:31:23,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:31:23,040][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,040][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:31:23,040][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:31:23,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,040][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:31:23,040][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,041][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:31:23,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,041][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:31:23,041][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit23']
[2024-07-24 10:31:23,041][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:31:23,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:31:23,041][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,042][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit25']
[2024-07-24 10:31:23,042][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:31:23,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,042][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,042][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:31:23,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,043][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,043][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:31:23,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,044][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,044][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:31:23,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,044][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,044][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,045][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:31:23,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,045][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,045][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,045][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:31:23,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit21', 'circuit22', 'circuit27']
[2024-07-24 10:31:23,046][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,046][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:31:23,046][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit25']
[2024-07-24 10:31:23,046][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:31:23,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit17']
[2024-07-24 10:31:23,047][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,047][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,047][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:31:23,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit19', 'circuit20']
[2024-07-24 10:31:23,047][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,048][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,048][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:31:23,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,048][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit9', 'circuit16']
[2024-07-24 10:31:23,048][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit26']
[2024-07-24 10:31:23,048][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,049][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:31:23,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:31:23,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,049][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,049][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,049][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:31:23,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,050][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit11', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,050][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:31:23,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,051][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit2', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,051][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,051][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:31:23,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,052][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,052][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,052][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:31:23,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:31:23,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,052][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,053][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,053][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:31:23,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,053][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17']
[2024-07-24 10:31:23,053][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit27']
[2024-07-24 10:31:23,053][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:31:23,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,054][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,054][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,054][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:31:23,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit6', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,055][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,055][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,055][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:31:23,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit27']
[2024-07-24 10:31:23,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,056][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,056][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,056][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:31:23,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,056][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,057][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,057][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:31:23,057][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,057][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:31:23,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:31:23,057][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,057][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:31:23,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,058][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,058][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,058][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:31:23,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:31:23,059][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,059][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,059][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:31:23,059][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,059][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,060][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20']
[2024-07-24 10:31:23,060][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,060][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:31:23,060][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,060][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,060][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,060][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,061][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:31:23,061][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,061][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,061][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,061][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,061][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:31:23,062][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,062][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,062][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit22', 'circuit27']
[2024-07-24 10:31:23,062][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16']
[2024-07-24 10:31:23,062][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:31:23,062][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:31:23,063][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,063][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,063][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,063][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:31:23,063][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:31:23,063][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16']
[2024-07-24 10:31:23,064][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit22']
[2024-07-24 10:31:23,064][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,064][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:31:23,064][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,064][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit6', 'circuit7', 'circuit9', 'circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:31:23,064][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,065][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,065][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:31:23,065][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,065][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,065][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,065][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,065][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:31:23,066][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,066][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,066][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,066][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,066][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:31:23,066][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,067][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,067][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,067][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,067][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:31:23,067][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,067][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,068][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,068][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,068][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,068][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:31:23,068][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,068][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,069][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,069][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,069][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,069][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:31:23,069][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,069][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,070][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,070][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,070][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit1', 'circuit5', 'circuit8', 'circuit14', 'circuit15', 'circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,070][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:31:23,070][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,070][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit25']
[2024-07-24 10:31:23,071][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit7']
[2024-07-24 10:31:23,071][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12']
[2024-07-24 10:31:23,071][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit4', 'circuit19', 'circuit20', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,071][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:31:23,071][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,071][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,072][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:31:23,072][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,072][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,072][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:31:23,072][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,072][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit26']
[2024-07-24 10:31:23,073][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,073][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,073][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,073][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:31:23,073][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:31:23,073][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,073][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit25', 'circuit26']
[2024-07-24 10:31:23,074][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,074][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,074][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:31:23,074][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,074][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,074][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,075][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,075][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,075][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:31:23,075][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:31:23,075][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,075][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16']
[2024-07-24 10:31:23,076][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19']
[2024-07-24 10:31:23,076][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,076][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:31:23,076][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,076][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit12', 'circuit24']
[2024-07-24 10:31:23,076][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit2', 'circuit7', 'circuit8', 'circuit11']
[2024-07-24 10:31:23,077][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit11']
[2024-07-24 10:31:23,077][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:31:23,077][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:31:23,077][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,077][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:31:23,077][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,078][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,078][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit27']
[2024-07-24 10:31:23,078][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:31:23,078][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,078][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16']
[2024-07-24 10:31:23,078][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,079][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,079][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,079][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:31:23,079][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,079][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit27']
[2024-07-24 10:31:23,079][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit23']
[2024-07-24 10:31:23,080][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,080][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit22']
[2024-07-24 10:31:23,080][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:31:23,080][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,080][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,080][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,081][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,081][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,081][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:31:23,081][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,081][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:31:23,081][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,082][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:31:23,082][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,082][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:31:23,082][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,082][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,082][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit25']
[2024-07-24 10:31:23,083][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24']
[2024-07-24 10:31:23,083][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,083][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:31:23,083][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,083][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,083][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,084][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,084][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,084][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:31:23,084][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,084][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit16', 'circuit17']
[2024-07-24 10:31:23,084][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,085][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24']
[2024-07-24 10:31:23,085][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,085][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:31:23,085][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,085][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21']
[2024-07-24 10:31:23,085][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,086][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,086][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:31:23,086][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:31:23,086][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,086][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,086][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,086][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,087][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,087][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:31:23,087][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,087][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,087][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,087][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14']
[2024-07-24 10:31:23,088][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,088][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:31:23,088][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,088][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,088][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,088][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,089][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,089][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:31:23,089][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:31:23,089][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,089][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit25']
[2024-07-24 10:31:23,089][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24']
[2024-07-24 10:31:23,089][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,090][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:31:23,090][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,090][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit23', 'circuit26']
[2024-07-24 10:31:23,090][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,090][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,090][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:31:23,091][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:31:23,091][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:31:23,091][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit10', 'circuit12', 'circuit21', 'circuit27']
[2024-07-24 10:31:23,091][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,091][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:31:23,091][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,092][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:31:23,092][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit27']
[2024-07-24 10:31:23,092][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,092][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,092][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,092][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,093][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:31:23,093][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,093][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,093][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,093][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,093][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,094][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:31:23,094][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,094][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,094][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,094][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,094][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,094][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:31:23,095][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,095][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,095][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,095][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,095][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,095][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:31:23,096][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,096][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,096][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,096][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,096][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,096][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,097][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:31:23,097][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11']
[2024-07-24 10:31:23,097][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17']
[2024-07-24 10:31:23,097][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,097][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,097][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,098][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,098][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:31:23,098][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:31:23,098][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,098][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,098][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:31:23,099][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,099][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,099][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:31:23,099][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:31:23,099][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit5', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,099][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,100][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,100][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,100][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19', 'circuit23']
[2024-07-24 10:31:23,100][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:31:23,100][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,100][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:31:23,100][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit8', 'circuit22']
[2024-07-24 10:31:23,101][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit22', 'circuit25']
[2024-07-24 10:31:23,101][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,101][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,101][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:31:23,101][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:31:23,101][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:31:23,102][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16']
[2024-07-24 10:31:23,102][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,102][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,102][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,102][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:31:23,102][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,103][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,103][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,103][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit11', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,103][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,103][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit10', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,103][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:31:23,104][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,104][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,104][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,104][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,104][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,104][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit10', 'circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,104][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:31:23,105][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit20', 'circuit27']
[2024-07-24 10:31:23,105][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:31:23,105][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit27']
[2024-07-24 10:31:23,105][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit27']
[2024-07-24 10:31:23,105][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,105][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:31:23,106][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:31:23,106][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit27']
[2024-07-24 10:31:23,106][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,106][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,106][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,106][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,107][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,107][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:31:23,107][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,107][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:31:23,107][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit20']
[2024-07-24 10:31:23,107][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,108][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,108][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:31:23,108][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:31:23,108][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,108][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit6', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:31:23,108][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,109][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,109][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:31:23,109][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,109][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:31:23,109][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,109][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:31:23,109][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:31:23,110][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:31:23,110][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,110][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:31:23,110][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:31:23,110][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,110][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,111][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,111][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,111][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,111][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,111][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:31:23,111][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit10', 'circuit11', 'circuit22', 'circuit23']
[2024-07-24 10:31:23,112][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,112][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,112][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,112][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,112][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,112][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:31:23,113][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,113][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,113][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,113][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,113][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,113][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,113][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:31:23,114][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:31:23,114][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20']
[2024-07-24 10:31:23,114][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,114][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,114][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,114][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,115][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:31:23,115][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,115][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:31:23,115][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16']
[2024-07-24 10:31:23,115][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,115][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15']
[2024-07-24 10:31:23,116][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16']
[2024-07-24 10:31:23,116][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:31:23,116][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,116][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit5']
[2024-07-24 10:31:23,116][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,116][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,117][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,117][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,117][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:31:23,117][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,117][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit11', 'circuit12', 'circuit14', 'circuit15', 'circuit17', 'circuit19']
[2024-07-24 10:31:23,117][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit8', 'circuit14', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:31:23,117][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,118][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,118][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit25']
[2024-07-24 10:31:23,118][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:31:23,118][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,118][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,118][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,119][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:31:23,119][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit20', 'circuit23']
[2024-07-24 10:31:23,119][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:31:23,119][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:31:23,119][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,119][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,120][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,120][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,120][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,120][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,120][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:31:23,120][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,121][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,121][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,121][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,121][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,121][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,121][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:31:23,121][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,122][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:31:23,122][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,122][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16']
[2024-07-24 10:31:23,122][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,122][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,122][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:31:23,123][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:31:23,123][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,123][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit26']
[2024-07-24 10:31:23,123][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:31:23,123][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,123][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,124][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:31:23,124][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,124][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,124][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,124][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,124][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,125][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,125][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:31:23,125][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,125][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,125][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,125][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,126][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,126][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,126][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:31:23,126][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,126][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,126][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,126][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,127][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,127][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,127][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:31:23,127][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,127][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,127][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,128][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,128][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,128][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,128][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:31:23,128][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,128][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,129][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,129][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,129][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,129][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,129][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,129][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:31:23,130][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,130][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,130][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,130][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,130][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,130][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,131][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,131][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:31:23,131][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,131][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,131][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:31:23,131][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:31:23,132][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit22', 'circuit24']
[2024-07-24 10:31:23,132][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,132][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,132][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:31:23,132][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,132][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit20']
[2024-07-24 10:31:23,133][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit20']
[2024-07-24 10:31:23,133][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit19']
[2024-07-24 10:31:23,133][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,133][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,133][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,133][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:31:23,133][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,134][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit12', 'circuit27']
[2024-07-24 10:31:23,134][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,134][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,134][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,134][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,134][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,135][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:31:23,135][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,135][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,135][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,135][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit1']
[2024-07-24 10:31:23,135][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit22', 'circuit26']
[2024-07-24 10:31:23,136][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,136][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,136][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:31:23,136][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,136][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,136][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit12', 'circuit27']
[2024-07-24 10:31:23,136][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,137][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,137][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit10']
[2024-07-24 10:31:23,137][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,137][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:31:23,137][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,137][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:31:23,138][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,138][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,138][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,138][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,138][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,138][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:31:23,139][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,139][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:31:23,139][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:31:23,139][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit19', 'circuit20']
[2024-07-24 10:31:23,139][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit20', 'circuit24', 'circuit27']
[2024-07-24 10:31:23,139][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit15', 'circuit20']
[2024-07-24 10:31:23,140][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:31:23,140][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:31:23,140][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,140][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit17', 'circuit18']
[2024-07-24 10:31:23,140][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,140][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit26']
[2024-07-24 10:31:23,140][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,141][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,141][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,141][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:31:23,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,141][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,141][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:31:23,142][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15']
[2024-07-24 10:31:23,142][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit24']
[2024-07-24 10:31:23,142][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit1', 'circuit2', 'circuit10', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,142][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,142][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:31:23,142][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,143][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:31:23,143][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:31:23,143][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20']
[2024-07-24 10:31:23,143][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,143][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,143][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,144][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:31:23,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,144][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit5', 'circuit7', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,144][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit11', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:31:23,144][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,144][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,145][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,145][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,145][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:31:23,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,145][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,145][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit6', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,146][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,146][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,146][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,146][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit22', 'circuit26']
[2024-07-24 10:31:23,146][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:31:23,146][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,147][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,147][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,147][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,147][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,147][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,147][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:31:23,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,148][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,148][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,148][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,148][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,149][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,149][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:31:23,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,149][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,149][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,150][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,150][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,150][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,150][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:31:23,150][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,150][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,151][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,151][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,151][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,151][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,151][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:31:23,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,152][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,152][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,152][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,152][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,152][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,152][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,153][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:31:23,153][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,153][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,153][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,153][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,153][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,153][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,154][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,154][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:31:23,154][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,154][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,154][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,154][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,155][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,155][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,155][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,155][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:31:23,155][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,156][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,156][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,156][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,156][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,156][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,156][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:31:23,156][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,157][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,157][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,157][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,157][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,157][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,157][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,158][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:31:23,158][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,158][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,158][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,158][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,158][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,159][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,159][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,159][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:31:23,159][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,159][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,159][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,160][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,160][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,160][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,160][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,160][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:31:23,160][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,160][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,161][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,161][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,161][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,161][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,161][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,161][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:31:23,162][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,162][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,162][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,162][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,162][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,162][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,163][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,163][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:31:23,163][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,163][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,163][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,163][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,164][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,164][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,164][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,164][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:31:23,164][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,164][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,165][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,165][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,165][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,165][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,165][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,165][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:31:23,166][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,166][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,166][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,166][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,166][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,166][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,167][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,167][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit7', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,167][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:31:23,167][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,167][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,167][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,168][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit28']
[2024-07-24 10:31:23,168][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,168][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,168][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,168][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit14', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,168][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:31:23,169][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit19', 'circuit21', 'circuit22']
[2024-07-24 10:31:23,169][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:31:23,169][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:31:23,169][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,169][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,169][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,169][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit25']
[2024-07-24 10:31:23,170][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:31:23,170][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:31:23,170][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit13', 'circuit14', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,170][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,170][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,170][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:31:23,171][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,171][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit23']
[2024-07-24 10:31:23,171][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit27']
[2024-07-24 10:31:23,171][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:31:23,171][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:31:23,171][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit26']
[2024-07-24 10:31:23,172][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit15']
[2024-07-24 10:31:23,172][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,172][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,172][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,172][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,172][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,173][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,173][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:31:23,173][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit27']
[2024-07-24 10:31:23,173][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:31:23,173][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit22']
[2024-07-24 10:31:23,173][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,173][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,174][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,174][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,174][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,174][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:31:23,174][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit20']
[2024-07-24 10:31:23,174][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,175][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,175][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,175][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,175][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,175][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,175][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13']
[2024-07-24 10:31:23,176][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:31:23,176][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,176][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:31:23,176][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,176][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,176][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit7', 'circuit9', 'circuit10']
[2024-07-24 10:31:23,177][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit6', 'circuit9', 'circuit27']
[2024-07-24 10:31:23,177][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:31:23,177][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,177][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:31:23,177][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,177][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:31:23,177][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,178][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,178][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,178][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,178][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,178][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,178][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:31:23,179][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit25']
[2024-07-24 10:31:23,179][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,179][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,179][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,179][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,179][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,180][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,180][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,180][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:31:23,180][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,180][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,180][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1']
[2024-07-24 10:31:23,181][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit20']
[2024-07-24 10:31:23,181][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16']
[2024-07-24 10:31:23,181][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,181][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,181][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,181][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:31:23,181][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,182][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit27']
[2024-07-24 10:31:23,182][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:31:23,182][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,182][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,182][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,182][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,183][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,183][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:31:23,183][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit19']
[2024-07-24 10:31:23,183][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit12', 'circuit13', 'circuit14']
[2024-07-24 10:31:23,183][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,183][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,184][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,184][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,184][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,184][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,184][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:31:23,184][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,185][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,185][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,185][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,185][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:31:23,185][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,185][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13']
[2024-07-24 10:31:23,186][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:31:23,186][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:31:23,186][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,186][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,186][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,186][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,187][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,187][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,187][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,187][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,187][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:31:23,187][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,188][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,188][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,188][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,188][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,188][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,188][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,188][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,189][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:31:23,189][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,189][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,189][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,189][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,189][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,190][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,190][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,190][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,190][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:31:23,190][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,190][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,191][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,191][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,191][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,191][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,191][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,191][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,191][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:31:23,192][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,192][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,192][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,192][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,192][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,192][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,193][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,193][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,193][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:31:23,193][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,193][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,193][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,194][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,194][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,194][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,194][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,194][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,194][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:31:23,195][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,195][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,195][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,195][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,195][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,195][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,195][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,196][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,196][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:31:23,196][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,196][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,196][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,196][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,197][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,197][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,197][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,197][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,197][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:31:23,197][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,198][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,198][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,198][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,198][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,198][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,198][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,199][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,199][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:31:23,199][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,199][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,199][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,199][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,199][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,200][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,200][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,200][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,200][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:31:23,200][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,200][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,201][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,201][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,201][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,201][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,201][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,201][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,202][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:31:23,202][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,202][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,202][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,202][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,202][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,203][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,203][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,203][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,203][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:31:23,203][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,203][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,203][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,204][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,204][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,204][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,204][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,204][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,204][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:31:23,205][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,205][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,205][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,205][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,205][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,205][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,206][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,206][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,206][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:31:23,206][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,206][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,206][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,207][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,207][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,207][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,207][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,207][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,207][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:31:23,208][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,208][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,208][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,208][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,208][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,208][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,209][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,209][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,209][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,209][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:31:23,209][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,209][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,210][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,210][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,210][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,210][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,210][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,210][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,211][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,211][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:31:23,211][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,211][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,211][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,211][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,212][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,212][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,212][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,212][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,212][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,212][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:31:23,213][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,213][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:31:23,213][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,213][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,213][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,213][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,213][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,214][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,214][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,214][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:31:23,214][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit18', 'circuit21', 'circuit22']
[2024-07-24 10:31:23,214][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,214][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,215][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,215][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,215][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,215][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,215][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,215][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,216][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:31:23,216][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,216][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13']
[2024-07-24 10:31:23,216][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:31:23,216][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:31:23,216][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14']
[2024-07-24 10:31:23,217][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:31:23,217][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:31:23,217][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22']
[2024-07-24 10:31:23,217][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,217][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:31:23,217][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,218][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,218][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,218][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,218][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,218][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,218][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,218][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,219][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,219][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:31:23,219][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,219][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,219][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,219][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,220][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,220][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,220][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,220][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,220][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,220][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:31:23,221][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:31:23,221][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,221][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,221][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,221][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,221][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,222][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,222][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,222][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,222][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:31:23,222][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17', 'circuit20']
[2024-07-24 10:31:23,222][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,222][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,223][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,223][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,223][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,223][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,223][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,223][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,224][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:31:23,224][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,224][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:31:23,224][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit26']
[2024-07-24 10:31:23,224][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,224][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,225][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,225][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,225][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,225][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:31:23,225][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:31:23,225][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,226][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit27']
[2024-07-24 10:31:23,226][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit8']
[2024-07-24 10:31:23,226][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14']
[2024-07-24 10:31:23,226][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15']
[2024-07-24 10:31:23,226][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,226][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,227][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,227][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit15']
[2024-07-24 10:31:23,227][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:31:23,227][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:31:23,227][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,227][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,228][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,228][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,228][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,228][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit19']
[2024-07-24 10:31:23,228][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,228][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,228][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:31:23,229][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,229][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit7', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,229][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,229][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,229][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,229][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,230][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:31:23,230][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit25']
[2024-07-24 10:31:23,230][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit19', 'circuit21', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:31:23,230][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:31:23,230][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,230][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,231][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,231][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,231][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,231][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,231][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,231][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,232][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,232][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:31:23,232][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,232][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,232][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,232][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,233][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,233][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,233][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,233][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,233][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,233][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:31:23,233][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,234][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,234][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,234][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,234][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,234][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,234][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,235][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,235][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,235][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:31:23,235][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,235][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,235][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,236][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,236][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,236][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,236][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,236][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,236][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,237][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:31:23,237][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,237][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,237][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,237][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,237][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,237][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,238][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,238][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,238][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,238][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:31:23,238][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,238][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,239][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,239][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,239][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,239][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,239][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,239][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,240][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,240][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:31:23,240][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,240][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,240][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,240][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,241][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,241][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,241][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,241][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,241][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,241][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:31:23,241][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,242][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,242][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,242][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,242][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,242][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,242][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,243][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,243][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,243][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:31:23,243][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,243][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,243][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,244][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,244][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,244][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,244][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,244][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,244][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,244][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:31:23,245][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,245][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,245][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,245][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,245][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,245][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,246][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,246][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,246][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,246][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:31:23,246][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,246][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,247][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,247][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,247][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,247][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,247][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,247][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,248][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,248][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:31:23,248][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,248][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,248][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,248][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,248][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,249][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,249][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,249][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,249][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,249][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:31:23,249][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,250][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,250][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,250][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,250][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,250][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,250][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,251][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,251][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,251][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:31:23,251][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,251][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,251][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,252][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,252][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,252][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,252][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,252][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,252][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,253][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:31:23,253][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,253][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,253][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,253][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,253][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,254][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,254][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,254][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,254][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,254][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:31:23,254][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,255][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,255][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,255][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:23,255][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,255][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit6', 'circuit9', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,255][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,256][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,256][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit24', 'circuit27']
[2024-07-24 10:31:23,256][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,256][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:31:23,256][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,256][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,257][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,257][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,257][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,257][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,257][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,257][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,258][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,258][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,258][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:31:23,258][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,258][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,258][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,259][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,259][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,259][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,259][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,259][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,259][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,259][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,260][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:31:23,260][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,260][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,260][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,260][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,260][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,261][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,261][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,261][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,261][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,261][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,261][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:31:23,262][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,262][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,262][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,262][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,262][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,262][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,263][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,263][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,263][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,263][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,263][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:31:23,263][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,263][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,264][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,264][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,264][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,264][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,264][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,264][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,265][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,265][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,265][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:31:23,265][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,265][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,265][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,266][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,266][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,266][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,266][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,266][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,266][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,267][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,267][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:31:23,267][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,267][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,267][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,267][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,267][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,268][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,268][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,268][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,268][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,268][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,268][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:31:23,269][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,269][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,269][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,269][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,269][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,269][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,270][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,270][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,270][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,270][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,270][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:31:23,270][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,271][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,271][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,271][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,271][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,271][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,271][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,271][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,272][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,272][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,272][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:31:23,272][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,272][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,272][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,273][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,273][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,273][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,273][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,273][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,273][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,274][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,274][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:31:23,274][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,274][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,274][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,274][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,275][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,275][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,275][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,275][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:31:23,275][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,275][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit12']
[2024-07-24 10:31:23,275][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:31:23,276][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,276][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,276][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,276][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,276][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,276][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,277][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,277][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,277][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,277][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit14', 'circuit15', 'circuit17']
[2024-07-24 10:31:23,277][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:31:23,277][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit8', 'circuit9', 'circuit10', 'circuit13']
[2024-07-24 10:31:23,278][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,278][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,278][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,278][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23']
[2024-07-24 10:31:23,278][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,278][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:31:23,279][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,279][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:31:23,279][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,279][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:31:23,279][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,279][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,279][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,280][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,280][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,280][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,280][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,280][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,280][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,281][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,281][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:31:23,281][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,281][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,281][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,281][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,282][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,282][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,282][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,282][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,282][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,282][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,283][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:31:23,283][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,283][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,283][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,283][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,283][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,284][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,284][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,284][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,284][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,284][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,284][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:31:23,284][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,285][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,285][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,285][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,285][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,285][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,285][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,286][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,286][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,286][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,286][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:31:23,286][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,286][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,287][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,287][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,287][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,287][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,287][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,287][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,288][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,288][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,288][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:31:23,288][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,288][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,288][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,289][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,289][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,289][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,289][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,289][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,289][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,290][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,290][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:31:23,290][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,290][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,290][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,290][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,291][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,291][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,291][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,291][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,291][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,291][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,292][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:31:23,292][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,292][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,292][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,292][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,292][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,293][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,293][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,293][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,293][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,293][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,293][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:31:23,294][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,294][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,294][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,294][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,294][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,294][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,295][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,295][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,295][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,295][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,295][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:31:23,295][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,296][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,296][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,296][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,296][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,296][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,296][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,297][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,297][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,297][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,297][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:31:23,297][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,297][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,298][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,298][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,298][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,298][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,298][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,298][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,299][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,299][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,299][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:31:23,299][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,299][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,299][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,300][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,300][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,300][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,300][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,300][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,300][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,301][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,301][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:31:23,301][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,301][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,301][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,301][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,302][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,302][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,302][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,302][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,302][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,302][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,303][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:31:23,303][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,303][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,303][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,303][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,303][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,304][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,304][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,304][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,304][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,304][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,304][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:31:23,305][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,305][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,305][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,305][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,305][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,306][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,306][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,306][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,306][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,306][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,306][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:31:23,307][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,307][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit24']
[2024-07-24 10:31:23,307][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:23,307][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,307][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:23,307][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit20']
[2024-07-24 10:31:23,308][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit6', 'circuit10', 'circuit13', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:31:23,308][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:31:23,308][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit20']
[2024-07-24 10:31:23,308][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit19', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,308][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit25']
[2024-07-24 10:31:23,308][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:31:23,309][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,309][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,309][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,309][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,309][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,309][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,310][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,310][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,310][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,310][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,310][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,310][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:31:23,311][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,311][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,311][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,311][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,311][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,311][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,312][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,312][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,312][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,312][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,312][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,312][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:31:23,313][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,313][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,313][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,313][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,313][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,313][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,314][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,314][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,314][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,314][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,314][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:31:23,314][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:31:23,315][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,315][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,315][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,315][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,315][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,315][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,316][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,316][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,316][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,316][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,316][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,316][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:31:23,317][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,317][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,317][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,317][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,317][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,317][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,318][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,318][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,318][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,318][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,318][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,318][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:31:23,319][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,319][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,319][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,319][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,319][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,319][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,320][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,320][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,320][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,320][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,320][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,320][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:31:23,321][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,321][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,321][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,321][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,321][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,321][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,322][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,322][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,322][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,322][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,322][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,322][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:31:23,323][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,323][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,323][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,323][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,323][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,323][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,324][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,324][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,324][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,324][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit11', 'circuit12', 'circuit27']
[2024-07-24 10:31:23,324][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,324][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:31:23,324][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,325][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:31:23,325][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit26']
[2024-07-24 10:31:23,325][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:31:23,325][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:31:23,325][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:31:23,326][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:31:23,326][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:31:23,326][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:31:23,326][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:31:23,326][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:31:23,326][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:31:23,326][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,327][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,327][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,327][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,327][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,327][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,327][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,328][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,328][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,328][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,328][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,328][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:31:23,328][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,329][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,329][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,329][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,329][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,329][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,329][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,330][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,330][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,330][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,330][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,330][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:31:23,330][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,331][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,331][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,331][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,331][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,331][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,331][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,332][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,332][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,332][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,332][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,332][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:31:23,332][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,333][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17']
[2024-07-24 10:31:23,333][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit21']
[2024-07-24 10:31:23,333][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,333][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,333][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit23']
[2024-07-24 10:31:23,333][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,334][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,334][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit3', 'circuit5', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:23,334][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit25']
[2024-07-24 10:31:23,334][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:23,334][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:31:23,334][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,335][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,335][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,335][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,335][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,335][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,335][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,336][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,336][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,336][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,336][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,336][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:31:23,337][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,337][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,337][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,337][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,337][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,337][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,338][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,338][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,338][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,338][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,338][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,338][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:31:23,339][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,339][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,339][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,339][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,339][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,339][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,340][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,340][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,340][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,340][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,340][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,340][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:31:23,341][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,341][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,341][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,341][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,341][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,341][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,342][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,342][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,342][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,342][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,342][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,342][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:31:23,343][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,343][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,343][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,343][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,343][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,343][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,344][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,344][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,344][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,344][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,344][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,344][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:31:23,345][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,345][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,345][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,345][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,345][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,345][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,346][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,346][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,346][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,346][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,346][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,346][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:31:23,346][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,347][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,347][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,347][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,347][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,347][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,347][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,348][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,348][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,348][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,348][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,348][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:31:23,348][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,349][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,349][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,349][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,349][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,349][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,349][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,350][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,350][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,350][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,350][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,350][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:31:23,350][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,351][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,351][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,351][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,351][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,351][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,351][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,352][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,352][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,352][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,352][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,352][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:31:23,352][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,353][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,353][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,353][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,353][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,353][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,353][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,353][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,354][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,354][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,354][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,354][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:31:23,354][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,354][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,355][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,355][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,355][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,355][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,355][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,355][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,356][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,356][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,356][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,356][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:31:23,356][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:23,356][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:23,356][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:23,357][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:23,357][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:23,357][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:23,357][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:23,357][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:23,357][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:23,358][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:23,358][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:23,358][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:31:23,358][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,358][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,358][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,359][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,359][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,359][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,359][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,359][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,359][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,360][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,360][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,360][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:31:23,360][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,360][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,360][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,361][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,361][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,361][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,361][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,361][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,361][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,362][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,362][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,362][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:31:23,362][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,362][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,362][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,363][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,363][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,363][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,363][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,363][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,363][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,364][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:23,364][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:24,593][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:24,594][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,596][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,597][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,597][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,598][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,598][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,599][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,599][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,600][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,600][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,600][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,601][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,602][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.9054, 0.0946], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,603][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([1.0927e-04, 9.9989e-01], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,606][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.8425, 0.1575], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,606][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.0886, 0.9114], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,607][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.2560, 0.7440], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,607][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.0142, 0.9858], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,608][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.8002, 0.1998], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,608][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.9782, 0.0218], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,608][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.8354, 0.1646], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,609][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.9203, 0.0797], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,609][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.7082, 0.2918], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,610][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.7376, 0.2624], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,611][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7615, 0.1802, 0.0584], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,612][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0042, 0.0012, 0.9945], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,614][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4144, 0.0278, 0.5578], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,615][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2451, 0.0940, 0.6609], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,616][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.5616, 0.2631, 0.1754], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,617][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2181, 0.0054, 0.7765], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,618][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6048, 0.3695, 0.0257], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,620][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4333, 0.3605, 0.2062], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,621][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2509, 0.0384, 0.7107], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,623][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.6148, 0.1261, 0.2591], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,624][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.6423, 0.1099, 0.2479], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,625][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.5373, 0.1205, 0.3422], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,627][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Nathan] are: tensor([0.3671, 0.3246, 0.2092, 0.0990], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,628][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Nathan] are: tensor([1.8776e-05, 5.6958e-04, 2.8164e-05, 9.9938e-01], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,629][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Nathan] are: tensor([0.5397, 0.1142, 0.1235, 0.2226], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,630][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Nathan] are: tensor([2.0585e-02, 1.0308e-02, 6.1407e-04, 9.6849e-01], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,631][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Nathan] are: tensor([0.0395, 0.0275, 0.0031, 0.9299], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,632][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Nathan] are: tensor([2.8757e-03, 1.7040e-05, 3.6807e-08, 9.9711e-01], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,633][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Nathan] are: tensor([0.2815, 0.3232, 0.1729, 0.2223], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,633][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Nathan] are: tensor([0.3287, 0.1508, 0.3612, 0.1593], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,633][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Nathan] are: tensor([0.5058, 0.2063, 0.1819, 0.1060], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,634][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Nathan] are: tensor([0.5853, 0.1658, 0.2202, 0.0287], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,634][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Nathan] are: tensor([0.4008, 0.1127, 0.1691, 0.3175], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,635][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Nathan] are: tensor([0.3573, 0.1672, 0.2571, 0.2184], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,635][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.4891, 0.1229, 0.1110, 0.0593, 0.2177], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,636][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ got] are: tensor([4.9812e-04, 2.3745e-03, 9.1610e-04, 1.0456e-03, 9.9517e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,637][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.5325, 0.0401, 0.1793, 0.1294, 0.1187], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,638][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.0570, 0.0020, 0.0130, 0.0136, 0.9144], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,640][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.3683, 0.0439, 0.0445, 0.0756, 0.4678], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,641][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ got] are: tensor([1.2121e-02, 3.3970e-04, 9.5170e-05, 2.2407e-04, 9.8722e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,642][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.3649, 0.2715, 0.0429, 0.2262, 0.0945], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,643][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.2595, 0.1293, 0.2141, 0.1766, 0.2206], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,645][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.3739, 0.0799, 0.3666, 0.0727, 0.1070], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,646][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.4414, 0.1032, 0.2362, 0.0999, 0.1192], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,647][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.3790, 0.0929, 0.1931, 0.0648, 0.2701], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,649][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.4535, 0.0978, 0.2195, 0.1224, 0.1068], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,650][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4751, 0.2096, 0.0462, 0.0933, 0.1421, 0.0338], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,651][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([3.3931e-03, 8.4158e-04, 6.0312e-03, 5.8443e-03, 1.3844e-03, 9.8251e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,652][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.4134, 0.0739, 0.2408, 0.1097, 0.1124, 0.0498], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,654][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0700, 0.0110, 0.0379, 0.0397, 0.0993, 0.7420], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,655][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2001, 0.0446, 0.0392, 0.1000, 0.4451, 0.1709], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,657][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1234, 0.0045, 0.1348, 0.0031, 0.0327, 0.7014], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,658][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3068, 0.2880, 0.0131, 0.2067, 0.1717, 0.0136], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,659][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1595, 0.0712, 0.1248, 0.1603, 0.2130, 0.2713], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,659][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0527, 0.0131, 0.2300, 0.0100, 0.0569, 0.6373], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,659][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.3609, 0.1045, 0.1986, 0.0975, 0.0924, 0.1462], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,660][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.3414, 0.0834, 0.2014, 0.0730, 0.0648, 0.2360], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,660][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3445, 0.0994, 0.1748, 0.1287, 0.1214, 0.1312], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,661][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.2927, 0.0644, 0.2635, 0.1529, 0.0725, 0.1051, 0.0489],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,661][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([2.1327e-04, 1.0243e-02, 3.8550e-04, 1.7876e-02, 6.2966e-04, 2.0847e-04,
        9.7044e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,661][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.3832, 0.1118, 0.1441, 0.0968, 0.1129, 0.1222, 0.0288],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,662][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([6.8566e-03, 4.4011e-04, 1.9922e-05, 8.5473e-04, 8.8955e-04, 1.2640e-04,
        9.9081e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,663][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0658, 0.0255, 0.0016, 0.0357, 0.0136, 0.0034, 0.8544],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,664][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([3.0908e-05, 1.1350e-04, 2.4233e-09, 5.5185e-06, 1.9879e-08, 3.9282e-10,
        9.9985e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,666][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.2063, 0.2412, 0.1302, 0.1618, 0.0216, 0.1017, 0.1373],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,667][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.1291, 0.0341, 0.1304, 0.0737, 0.2457, 0.3288, 0.0582],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,668][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.3017, 0.1124, 0.1004, 0.0367, 0.0863, 0.0788, 0.2836],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,670][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.3631, 0.0880, 0.1666, 0.1461, 0.0960, 0.1274, 0.0128],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,671][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.2558, 0.1300, 0.1539, 0.0729, 0.0725, 0.0787, 0.2362],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,673][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.1615, 0.1000, 0.1575, 0.0926, 0.1458, 0.1917, 0.1509],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,674][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.2484, 0.1943, 0.0405, 0.0798, 0.1486, 0.0565, 0.2061, 0.0259],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,675][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ at] are: tensor([1.6172e-03, 1.5048e-03, 5.4843e-03, 3.1725e-04, 1.2728e-04, 1.8797e-03,
        5.3710e-05, 9.8902e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,676][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.3213, 0.0522, 0.1688, 0.0865, 0.1289, 0.0599, 0.0394, 0.1430],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,677][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ at] are: tensor([4.0017e-03, 8.4289e-04, 2.7539e-03, 5.4720e-04, 1.2692e-02, 3.7485e-02,
        2.9636e-02, 9.1204e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,679][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1266, 0.0264, 0.0193, 0.0244, 0.1883, 0.0737, 0.2405, 0.3009],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,680][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ at] are: tensor([7.7642e-02, 4.5956e-03, 1.4741e-02, 1.4066e-03, 7.9711e-03, 1.8410e-02,
        5.9337e-04, 8.7464e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,681][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1461, 0.2242, 0.0165, 0.1978, 0.0939, 0.0195, 0.2806, 0.0214],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,682][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0852, 0.0412, 0.0555, 0.0675, 0.1006, 0.2006, 0.1376, 0.3118],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,684][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0632, 0.0094, 0.3111, 0.0161, 0.0671, 0.3371, 0.0333, 0.1627],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,685][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.2735, 0.0660, 0.1716, 0.0782, 0.0890, 0.1294, 0.0531, 0.1392],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,685][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.2327, 0.0765, 0.1731, 0.0538, 0.0574, 0.1234, 0.0292, 0.2538],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,686][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.2975, 0.0734, 0.1151, 0.1092, 0.0720, 0.0607, 0.1236, 0.1485],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,686][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.3431, 0.1996, 0.0243, 0.0778, 0.0845, 0.0194, 0.2112, 0.0187, 0.0214],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,687][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ the] are: tensor([9.2959e-03, 9.3490e-04, 5.7367e-02, 5.8101e-04, 1.7154e-04, 4.4580e-02,
        3.6169e-05, 5.6582e-02, 8.3045e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,687][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.3101, 0.0441, 0.1345, 0.0636, 0.1315, 0.0394, 0.0333, 0.2057, 0.0378],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,687][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0287, 0.0027, 0.0062, 0.0067, 0.0169, 0.0714, 0.0223, 0.1892, 0.6559],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,688][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1834, 0.0373, 0.0248, 0.0404, 0.1321, 0.0572, 0.1679, 0.1966, 0.1603],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,690][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1294, 0.0130, 0.1246, 0.0064, 0.0609, 0.2397, 0.0037, 0.0761, 0.3463],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,691][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1645, 0.2610, 0.0042, 0.1860, 0.0748, 0.0044, 0.2952, 0.0074, 0.0026],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,692][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0737, 0.0204, 0.0323, 0.0366, 0.0547, 0.0845, 0.1355, 0.2768, 0.2854],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,694][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0197, 0.0049, 0.1385, 0.0068, 0.0294, 0.3256, 0.0113, 0.0645, 0.3993],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,695][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.2637, 0.0736, 0.1357, 0.0762, 0.0739, 0.1017, 0.0488, 0.1151, 0.1113],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,697][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.2781, 0.0740, 0.1469, 0.0561, 0.0453, 0.1314, 0.0189, 0.0847, 0.1646],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,698][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2049, 0.0826, 0.0981, 0.1047, 0.0669, 0.1021, 0.1316, 0.0967, 0.1124],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,700][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([0.1957, 0.1415, 0.0812, 0.0830, 0.0389, 0.0772, 0.1425, 0.0498, 0.0758,
        0.1143], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,700][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([1.1724e-04, 1.9043e-03, 1.3223e-04, 7.3705e-05, 1.8127e-04, 3.9501e-05,
        2.0035e-04, 3.9268e-04, 3.2716e-05, 9.9693e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,702][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([0.2605, 0.1041, 0.0578, 0.0888, 0.0452, 0.0640, 0.0905, 0.0562, 0.0619,
        0.1710], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,703][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([1.2390e-03, 2.4141e-04, 2.6842e-06, 5.5144e-05, 2.7581e-05, 2.4160e-05,
        1.1108e-02, 2.0015e-04, 1.3323e-04, 9.8697e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,704][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([6.8727e-03, 4.9740e-03, 2.2463e-04, 2.4854e-03, 1.1614e-03, 5.9127e-04,
        5.7088e-03, 1.7793e-03, 1.5131e-03, 9.7469e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,705][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([2.4340e-03, 2.0361e-04, 1.5660e-06, 1.2948e-05, 1.7656e-05, 5.6462e-07,
        6.0551e-05, 6.6447e-07, 2.5378e-07, 9.9727e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,706][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.1989, 0.1997, 0.0535, 0.1058, 0.0270, 0.0338, 0.1141, 0.0201, 0.0307,
        0.2165], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,708][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([0.0916, 0.0079, 0.0317, 0.0258, 0.0541, 0.0856, 0.0088, 0.2062, 0.3516,
        0.1367], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,709][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.2470, 0.0749, 0.1060, 0.0566, 0.0539, 0.1188, 0.0473, 0.0848, 0.1238,
        0.0870], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,711][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([0.2835, 0.0735, 0.1176, 0.0703, 0.0633, 0.0986, 0.0981, 0.0879, 0.0945,
        0.0127], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,711][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([0.2043, 0.0810, 0.1089, 0.0348, 0.0455, 0.0873, 0.0356, 0.0693, 0.0624,
        0.2707], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,712][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([0.2037, 0.0780, 0.1049, 0.0840, 0.0628, 0.0599, 0.1030, 0.1333, 0.0684,
        0.1020], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,712][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3713, 0.1284, 0.0137, 0.0552, 0.0963, 0.0245, 0.1935, 0.0163, 0.0439,
        0.0469, 0.0100], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,713][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([4.0958e-03, 3.1974e-04, 2.0231e-02, 3.1091e-04, 2.6248e-04, 3.2642e-04,
        5.3582e-05, 2.4365e-03, 9.4233e-04, 5.6458e-05, 9.7096e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,713][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2825, 0.0351, 0.1098, 0.0207, 0.0270, 0.0099, 0.0327, 0.0524, 0.0122,
        0.0187, 0.3992], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,713][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0346, 0.0015, 0.0027, 0.0008, 0.0094, 0.0122, 0.0072, 0.0505, 0.1298,
        0.0734, 0.6780], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,714][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3970, 0.0213, 0.0122, 0.0292, 0.0366, 0.0152, 0.0564, 0.0817, 0.0393,
        0.0640, 0.2472], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,715][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1190, 0.0231, 0.1727, 0.0196, 0.0375, 0.1294, 0.0159, 0.1097, 0.1218,
        0.0191, 0.2323], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,716][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2099, 0.1924, 0.0077, 0.1297, 0.0575, 0.0090, 0.1863, 0.0125, 0.0053,
        0.1845, 0.0051], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,717][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0346, 0.0187, 0.0147, 0.0252, 0.0284, 0.0423, 0.0544, 0.1062, 0.1678,
        0.1791, 0.3286], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,719][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0293, 0.0049, 0.1530, 0.0061, 0.0156, 0.1440, 0.0066, 0.0620, 0.2200,
        0.0112, 0.3475], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,720][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2251, 0.0616, 0.1168, 0.0737, 0.0663, 0.0812, 0.0475, 0.0938, 0.0870,
        0.0550, 0.0921], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,722][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1831, 0.0740, 0.1406, 0.0681, 0.0614, 0.0893, 0.0398, 0.1020, 0.0869,
        0.0507, 0.1040], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,723][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1940, 0.0667, 0.0924, 0.0931, 0.0670, 0.0565, 0.1195, 0.1019, 0.0482,
        0.0590, 0.1015], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,724][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.2776, 0.0671, 0.1182, 0.0585, 0.0211, 0.0643, 0.0106, 0.1145, 0.1005,
        0.0286, 0.0849, 0.0540], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,725][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([2.0113e-05, 3.8438e-01, 2.6747e-05, 4.2553e-05, 2.3316e-05, 6.0455e-06,
        5.3076e-04, 6.5096e-05, 8.0152e-06, 7.1814e-05, 6.7160e-07, 6.1482e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,727][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.2148, 0.1700, 0.0511, 0.0491, 0.0466, 0.0666, 0.0364, 0.0526, 0.0740,
        0.0791, 0.0398, 0.1199], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,728][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([2.7910e-03, 3.9289e-03, 4.5490e-06, 1.2249e-04, 2.9014e-05, 1.9770e-05,
        6.6625e-03, 8.6214e-05, 8.2373e-05, 6.2442e-03, 2.3958e-04, 9.7979e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,729][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.0122, 0.0538, 0.0010, 0.0201, 0.0014, 0.0012, 0.0038, 0.0033, 0.0037,
        0.0145, 0.0075, 0.8773], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,730][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([6.5527e-04, 7.2463e-01, 3.9223e-08, 7.7299e-06, 5.7924e-07, 3.5934e-09,
        4.0462e-04, 5.7596e-08, 1.6187e-09, 2.7574e-06, 2.1354e-09, 2.7430e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,732][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.1780, 0.1675, 0.0812, 0.0486, 0.0134, 0.0749, 0.0346, 0.0227, 0.1036,
        0.0740, 0.0787, 0.1227], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,733][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.0808, 0.0056, 0.0261, 0.0092, 0.0213, 0.0513, 0.0146, 0.1214, 0.1320,
        0.1908, 0.2649, 0.0820], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,734][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.2255, 0.0903, 0.0928, 0.1341, 0.0254, 0.0705, 0.0428, 0.0532, 0.0570,
        0.0705, 0.0711, 0.0668], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,736][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.2268, 0.0246, 0.1080, 0.0614, 0.0514, 0.0800, 0.0641, 0.0765, 0.0965,
        0.0984, 0.0951, 0.0171], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,737][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.1623, 0.2528, 0.0739, 0.0435, 0.0335, 0.0458, 0.0307, 0.0496, 0.0475,
        0.0336, 0.0472, 0.1797], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,738][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.0910, 0.0710, 0.0985, 0.0809, 0.0944, 0.0801, 0.0837, 0.0983, 0.0799,
        0.0496, 0.0943, 0.0782], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,738][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.2954, 0.0741, 0.0328, 0.0659, 0.0622, 0.0295, 0.0675, 0.0347, 0.0360,
        0.0419, 0.0399, 0.0968, 0.1234], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,739][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([4.1913e-04, 7.4695e-04, 2.0229e-04, 6.2452e-03, 1.2683e-02, 4.1229e-04,
        1.9076e-04, 1.3241e-04, 9.3985e-05, 7.0325e-05, 5.3637e-05, 1.7764e-04,
        9.7857e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,739][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.2667, 0.0444, 0.0818, 0.0778, 0.1271, 0.0633, 0.0208, 0.0683, 0.0676,
        0.0539, 0.0307, 0.0356, 0.0619], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,739][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([9.1964e-04, 6.2168e-06, 8.9574e-06, 5.2521e-06, 9.8193e-05, 2.6829e-05,
        3.7551e-05, 1.0295e-04, 1.5237e-04, 3.1331e-04, 9.5980e-04, 5.3074e-04,
        9.9684e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,740][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0381, 0.0041, 0.0048, 0.0025, 0.0075, 0.0068, 0.0043, 0.0228, 0.0140,
        0.0407, 0.0256, 0.0302, 0.7987], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,741][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([1.1281e-02, 3.5215e-04, 4.4781e-05, 2.2619e-04, 2.1529e-03, 5.7162e-06,
        2.0233e-05, 1.9063e-05, 1.8314e-06, 4.9789e-05, 1.9803e-06, 2.6105e-05,
        9.8582e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,742][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.1341, 0.1420, 0.0184, 0.1140, 0.0358, 0.0231, 0.0900, 0.0162, 0.0149,
        0.1250, 0.0146, 0.1794, 0.0926], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,744][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0298, 0.0113, 0.0084, 0.0101, 0.0149, 0.0277, 0.0075, 0.0494, 0.0770,
        0.0233, 0.2002, 0.3843, 0.1560], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,745][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.1444, 0.0270, 0.1139, 0.0145, 0.0781, 0.1151, 0.0445, 0.0941, 0.1497,
        0.0697, 0.0945, 0.0300, 0.0245], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,746][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.1784, 0.0598, 0.0799, 0.0829, 0.0665, 0.0607, 0.0628, 0.0633, 0.0663,
        0.0878, 0.0741, 0.0639, 0.0536], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,747][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.1701, 0.0449, 0.0776, 0.0545, 0.0717, 0.0653, 0.0394, 0.0555, 0.0652,
        0.0457, 0.0620, 0.0328, 0.2152], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,749][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.3048, 0.0395, 0.0752, 0.0716, 0.0435, 0.0406, 0.0729, 0.1008, 0.0304,
        0.0483, 0.0814, 0.0355, 0.0555], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,750][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2091, 0.0746, 0.0204, 0.0377, 0.0685, 0.0197, 0.1411, 0.0179, 0.0271,
        0.0305, 0.0238, 0.1085, 0.2066, 0.0146], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,751][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([5.7921e-03, 5.4867e-05, 3.9655e-02, 1.2353e-04, 4.6691e-04, 1.6741e-03,
        2.2317e-05, 1.9515e-02, 1.9054e-03, 2.4502e-05, 8.6326e-03, 1.4078e-05,
        2.9706e-05, 9.2209e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,753][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1977, 0.0238, 0.1002, 0.0582, 0.0544, 0.0261, 0.0226, 0.1370, 0.0288,
        0.0277, 0.0622, 0.0188, 0.0675, 0.1749], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,754][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([6.1250e-03, 1.9895e-05, 2.8181e-04, 9.2836e-04, 8.1967e-04, 1.6157e-03,
        2.2280e-03, 3.5074e-03, 1.5090e-02, 2.8952e-03, 3.7077e-02, 1.1906e-03,
        9.9244e-02, 8.2898e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,755][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.2073e-02, 6.0535e-04, 1.3494e-03, 8.4109e-04, 1.9565e-02, 3.7309e-03,
        1.1164e-02, 7.8288e-03, 6.2094e-03, 9.9782e-03, 9.1721e-03, 6.4292e-03,
        8.1240e-01, 9.8656e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,756][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([4.4400e-02, 7.4750e-04, 9.0702e-02, 1.1780e-03, 5.0416e-02, 2.1617e-01,
        6.2771e-04, 2.1169e-02, 1.7773e-01, 8.2989e-04, 1.8078e-02, 9.6774e-05,
        5.7967e-03, 3.7207e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,757][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0957, 0.0566, 0.0052, 0.0581, 0.0450, 0.0043, 0.0986, 0.0188, 0.0036,
        0.1129, 0.0043, 0.0775, 0.1379, 0.2814], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,758][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0240, 0.0059, 0.0050, 0.0093, 0.0084, 0.0101, 0.0178, 0.0218, 0.0361,
        0.0344, 0.0956, 0.2021, 0.2961, 0.2333], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,760][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0167, 0.0030, 0.0999, 0.0032, 0.0167, 0.1347, 0.0076, 0.0490, 0.2151,
        0.0119, 0.1801, 0.0048, 0.0076, 0.2498], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,762][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1528, 0.0404, 0.0919, 0.0599, 0.0534, 0.0746, 0.0366, 0.0768, 0.0805,
        0.0591, 0.0767, 0.0372, 0.0563, 0.1038], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,763][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1293, 0.0371, 0.1164, 0.0415, 0.0668, 0.0963, 0.0270, 0.0880, 0.0877,
        0.0328, 0.0817, 0.0263, 0.0481, 0.1209], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,764][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1659, 0.0546, 0.0772, 0.0729, 0.0610, 0.0491, 0.0823, 0.0782, 0.0372,
        0.0368, 0.0803, 0.0603, 0.0652, 0.0789], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,766][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.2233, 0.0481, 0.0278, 0.0287, 0.0632, 0.0242, 0.1143, 0.0169, 0.0279,
        0.1001, 0.0243, 0.0577, 0.1735, 0.0255, 0.0444], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:24,767][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ give] are: tensor([6.2318e-04, 4.0257e-04, 5.1063e-04, 3.4046e-03, 4.3711e-03, 4.5957e-04,
        2.4088e-04, 7.7272e-04, 2.1268e-04, 2.7309e-05, 1.6674e-04, 1.3122e-04,
        1.3223e-03, 5.6210e-04, 9.8679e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:24,768][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.1900, 0.0338, 0.0518, 0.0523, 0.0875, 0.0410, 0.0208, 0.0777, 0.0506,
        0.0654, 0.0334, 0.0295, 0.1073, 0.1096, 0.0494], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:24,768][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ give] are: tensor([8.9619e-04, 1.0297e-06, 4.9676e-06, 7.7136e-06, 3.2037e-05, 3.7235e-05,
        1.1775e-05, 6.5403e-05, 2.1139e-04, 2.5572e-04, 9.0913e-04, 1.6137e-04,
        8.8088e-03, 8.6094e-03, 9.7999e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:24,769][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0365, 0.0168, 0.0052, 0.0019, 0.0081, 0.0079, 0.0045, 0.0194, 0.0133,
        0.0720, 0.0229, 0.1246, 0.1074, 0.1011, 0.4584], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:24,769][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ give] are: tensor([9.2252e-03, 1.7483e-04, 5.0118e-05, 1.2551e-03, 1.4824e-03, 4.0168e-05,
        5.2041e-06, 3.3117e-05, 2.2217e-05, 1.0381e-06, 3.1410e-06, 1.0558e-05,
        1.6464e-04, 8.3903e-06, 9.8752e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:24,770][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.1169, 0.1093, 0.0127, 0.0939, 0.0287, 0.0141, 0.1374, 0.0119, 0.0121,
        0.1678, 0.0122, 0.1586, 0.0887, 0.0112, 0.0245], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:24,770][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0257, 0.0034, 0.0058, 0.0025, 0.0088, 0.0124, 0.0038, 0.0245, 0.0319,
        0.0158, 0.0880, 0.0764, 0.1475, 0.3157, 0.2380], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:24,771][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0739, 0.0218, 0.0876, 0.0127, 0.0726, 0.0719, 0.0990, 0.0637, 0.0914,
        0.0444, 0.0952, 0.0301, 0.0411, 0.1513, 0.0433], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:24,772][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.1314, 0.0412, 0.0760, 0.0403, 0.0612, 0.0650, 0.0633, 0.0631, 0.0656,
        0.0577, 0.0711, 0.0431, 0.0715, 0.0937, 0.0558], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:24,774][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.1065, 0.0258, 0.0692, 0.0527, 0.0760, 0.0603, 0.0387, 0.0667, 0.0573,
        0.0304, 0.0604, 0.0228, 0.0618, 0.0808, 0.1902], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:24,775][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.2640, 0.0405, 0.0903, 0.0521, 0.0523, 0.0265, 0.0520, 0.0793, 0.0204,
        0.0361, 0.0637, 0.0345, 0.0498, 0.0625, 0.0760], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:24,777][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.2477, 0.0724, 0.0181, 0.0270, 0.0431, 0.0113, 0.1399, 0.0147, 0.0166,
        0.0398, 0.0205, 0.1054, 0.1313, 0.0127, 0.0663, 0.0333],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:24,778][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ it] are: tensor([3.1333e-03, 4.7559e-04, 2.0978e-03, 6.2834e-04, 2.5794e-04, 3.3402e-03,
        1.1923e-05, 6.0166e-04, 1.0981e-02, 2.0315e-05, 7.2930e-04, 1.8868e-04,
        1.1510e-04, 3.1594e-03, 4.1423e-04, 9.7384e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:24,779][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.1628, 0.0213, 0.0777, 0.0363, 0.1053, 0.0236, 0.0232, 0.0640, 0.0245,
        0.0756, 0.0430, 0.0188, 0.1268, 0.0938, 0.0716, 0.0315],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:24,780][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ it] are: tensor([8.5283e-04, 8.4485e-06, 1.4941e-05, 2.5973e-05, 5.9203e-05, 1.0302e-04,
        3.5448e-05, 2.5983e-04, 8.7415e-04, 2.1593e-04, 3.2510e-03, 1.2545e-03,
        9.4382e-03, 1.8072e-02, 7.2860e-02, 8.9267e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:24,782][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.0454, 0.0032, 0.0056, 0.0067, 0.0158, 0.0061, 0.0132, 0.0130, 0.0133,
        0.0134, 0.0246, 0.0220, 0.2715, 0.0916, 0.1927, 0.2618],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:24,783][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ it] are: tensor([2.6661e-02, 2.0838e-03, 4.1835e-03, 1.0709e-04, 8.1109e-03, 6.5875e-03,
        1.6358e-03, 1.8985e-03, 8.3218e-03, 4.0228e-04, 4.5019e-04, 1.3321e-04,
        1.0293e-03, 1.9188e-03, 5.6499e-04, 9.3591e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:24,784][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.1018, 0.1111, 0.0052, 0.0970, 0.0383, 0.0050, 0.1179, 0.0056, 0.0034,
        0.1254, 0.0043, 0.2025, 0.1225, 0.0071, 0.0463, 0.0067],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:24,785][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0257, 0.0020, 0.0040, 0.0064, 0.0060, 0.0067, 0.0070, 0.0162, 0.0188,
        0.0113, 0.0605, 0.0439, 0.0688, 0.1725, 0.2943, 0.2559],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:24,787][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0314, 0.0035, 0.0868, 0.0051, 0.0338, 0.1338, 0.0133, 0.0414, 0.1853,
        0.0112, 0.1235, 0.0049, 0.0149, 0.1132, 0.0262, 0.1718],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:24,789][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.1520, 0.0463, 0.0742, 0.0497, 0.0495, 0.0565, 0.0405, 0.0590, 0.0631,
        0.0457, 0.0648, 0.0473, 0.0450, 0.0831, 0.0563, 0.0673],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:24,790][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.1117, 0.0337, 0.0700, 0.0355, 0.0382, 0.0683, 0.0195, 0.0517, 0.0861,
        0.0199, 0.0560, 0.0287, 0.0403, 0.0681, 0.0427, 0.2297],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:24,791][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.2030, 0.0477, 0.0578, 0.0626, 0.0427, 0.0352, 0.0743, 0.0647, 0.0306,
        0.0389, 0.0686, 0.0475, 0.0541, 0.0606, 0.0638, 0.0479],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:24,793][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1855, 0.0643, 0.0166, 0.0324, 0.0596, 0.0166, 0.1222, 0.0142, 0.0226,
        0.0272, 0.0192, 0.0941, 0.1785, 0.0118, 0.0700, 0.0509, 0.0141],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:24,794][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.8644e-03, 2.3288e-05, 1.7571e-02, 5.0366e-05, 2.1398e-04, 7.1511e-04,
        9.3619e-06, 8.8276e-03, 8.9413e-04, 1.1725e-05, 4.6307e-03, 6.9564e-06,
        1.4759e-05, 4.6292e-01, 4.0146e-04, 6.5272e-04, 5.0019e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:24,794][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1520, 0.0183, 0.0761, 0.0450, 0.0433, 0.0198, 0.0182, 0.1049, 0.0220,
        0.0219, 0.0480, 0.0153, 0.0545, 0.1340, 0.0562, 0.0273, 0.1433],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:24,795][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.6398e-03, 3.1399e-06, 4.0779e-05, 1.2977e-04, 8.5025e-05, 1.4147e-04,
        2.2946e-04, 2.4137e-04, 9.9467e-04, 1.9846e-04, 2.5224e-03, 8.2011e-05,
        6.2125e-03, 4.7919e-02, 4.0169e-01, 9.8673e-02, 4.3920e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:24,795][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0134, 0.0005, 0.0012, 0.0007, 0.0147, 0.0025, 0.0078, 0.0046, 0.0035,
        0.0054, 0.0050, 0.0035, 0.4312, 0.0499, 0.2338, 0.0621, 0.1600],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:24,796][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.7085e-02, 4.9384e-04, 6.1670e-02, 7.4141e-04, 3.5924e-02, 1.5530e-01,
        3.7425e-04, 1.5512e-02, 1.2601e-01, 5.0851e-04, 1.1445e-02, 6.3836e-05,
        3.9650e-03, 2.5977e-01, 9.0582e-03, 5.2704e-02, 2.3938e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:24,796][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0671, 0.0390, 0.0034, 0.0415, 0.0313, 0.0028, 0.0684, 0.0129, 0.0023,
        0.0765, 0.0028, 0.0556, 0.0984, 0.1980, 0.0532, 0.0075, 0.2393],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:24,797][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0201, 0.0036, 0.0031, 0.0053, 0.0041, 0.0043, 0.0079, 0.0076, 0.0122,
        0.0110, 0.0322, 0.0684, 0.0923, 0.0680, 0.1413, 0.2503, 0.2684],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:24,797][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0119, 0.0021, 0.0698, 0.0023, 0.0120, 0.0924, 0.0055, 0.0338, 0.1455,
        0.0085, 0.1255, 0.0035, 0.0055, 0.1723, 0.0140, 0.0892, 0.2062],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:24,798][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1195, 0.0317, 0.0710, 0.0481, 0.0429, 0.0577, 0.0301, 0.0590, 0.0619,
        0.0491, 0.0600, 0.0302, 0.0460, 0.0801, 0.0543, 0.0706, 0.0877],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:24,800][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0920, 0.0265, 0.0814, 0.0317, 0.0517, 0.0720, 0.0223, 0.0682, 0.0679,
        0.0273, 0.0662, 0.0228, 0.0416, 0.0999, 0.0498, 0.0772, 0.1014],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:24,801][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1507, 0.0469, 0.0678, 0.0641, 0.0540, 0.0431, 0.0659, 0.0658, 0.0318,
        0.0291, 0.0641, 0.0476, 0.0530, 0.0647, 0.0517, 0.0339, 0.0657],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:24,824][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:24,824][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,825][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,825][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,825][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,826][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,826][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,827][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,828][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,830][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,831][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,832][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,833][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:24,834][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.9054, 0.0946], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,835][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([1.0927e-04, 9.9989e-01], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,836][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.8425, 0.1575], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,838][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.0886, 0.9114], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,839][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.2560, 0.7440], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,840][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.0142, 0.9858], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,842][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.8002, 0.1998], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,843][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.9782, 0.0218], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,845][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.8354, 0.1646], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,846][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.9203, 0.0797], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,848][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.7082, 0.2918], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,849][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.7376, 0.2624], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:24,849][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.7615, 0.1802, 0.0584], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,850][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0042, 0.0012, 0.9945], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,850][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4144, 0.0278, 0.5578], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,850][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2451, 0.0940, 0.6609], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,851][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.5616, 0.2631, 0.1754], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,851][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2181, 0.0054, 0.7765], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,852][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6048, 0.3695, 0.0257], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,852][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4333, 0.3605, 0.2062], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,852][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2509, 0.0384, 0.7107], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,853][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.6148, 0.1261, 0.2591], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,855][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6423, 0.1099, 0.2479], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,856][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.5373, 0.1205, 0.3422], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:24,857][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Nathan] are: tensor([0.3671, 0.3246, 0.2092, 0.0990], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,858][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Nathan] are: tensor([1.8776e-05, 5.6958e-04, 2.8164e-05, 9.9938e-01], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,859][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Nathan] are: tensor([0.5397, 0.1142, 0.1235, 0.2226], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,860][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Nathan] are: tensor([2.0585e-02, 1.0308e-02, 6.1407e-04, 9.6849e-01], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,861][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Nathan] are: tensor([0.0395, 0.0275, 0.0031, 0.9299], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,862][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Nathan] are: tensor([2.8757e-03, 1.7040e-05, 3.6807e-08, 9.9711e-01], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,864][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Nathan] are: tensor([0.2815, 0.3232, 0.1729, 0.2223], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,865][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Nathan] are: tensor([0.3287, 0.1508, 0.3612, 0.1593], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,866][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Nathan] are: tensor([0.5058, 0.2063, 0.1819, 0.1060], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,868][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Nathan] are: tensor([0.5853, 0.1658, 0.2202, 0.0287], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,869][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Nathan] are: tensor([0.4008, 0.1127, 0.1691, 0.3175], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,871][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Nathan] are: tensor([0.3573, 0.1672, 0.2571, 0.2184], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:24,872][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.4891, 0.1229, 0.1110, 0.0593, 0.2177], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,873][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([4.9812e-04, 2.3745e-03, 9.1610e-04, 1.0456e-03, 9.9517e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,874][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.5325, 0.0401, 0.1793, 0.1294, 0.1187], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,875][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.0570, 0.0020, 0.0130, 0.0136, 0.9144], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,876][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.3683, 0.0439, 0.0445, 0.0756, 0.4678], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,876][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([1.2121e-02, 3.3970e-04, 9.5170e-05, 2.2407e-04, 9.8722e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,876][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.3649, 0.2715, 0.0429, 0.2262, 0.0945], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,877][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.2595, 0.1293, 0.2141, 0.1766, 0.2206], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,877][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.3739, 0.0799, 0.3666, 0.0727, 0.1070], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,878][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.4414, 0.1032, 0.2362, 0.0999, 0.1192], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,878][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.3790, 0.0929, 0.1931, 0.0648, 0.2701], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,878][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.4535, 0.0978, 0.2195, 0.1224, 0.1068], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:24,879][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4751, 0.2096, 0.0462, 0.0933, 0.1421, 0.0338], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,880][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.3931e-03, 8.4158e-04, 6.0312e-03, 5.8443e-03, 1.3844e-03, 9.8251e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,881][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.4134, 0.0739, 0.2408, 0.1097, 0.1124, 0.0498], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,883][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0700, 0.0110, 0.0379, 0.0397, 0.0993, 0.7420], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,884][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.2001, 0.0446, 0.0392, 0.1000, 0.4451, 0.1709], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,885][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1234, 0.0045, 0.1348, 0.0031, 0.0327, 0.7014], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,887][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.3068, 0.2880, 0.0131, 0.2067, 0.1717, 0.0136], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,888][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1595, 0.0712, 0.1248, 0.1603, 0.2130, 0.2713], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,889][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0527, 0.0131, 0.2300, 0.0100, 0.0569, 0.6373], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,891][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.3609, 0.1045, 0.1986, 0.0975, 0.0924, 0.1462], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,892][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.3414, 0.0834, 0.2014, 0.0730, 0.0648, 0.2360], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,893][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3445, 0.0994, 0.1748, 0.1287, 0.1214, 0.1312], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:24,895][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.2927, 0.0644, 0.2635, 0.1529, 0.0725, 0.1051, 0.0489],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,896][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([2.1327e-04, 1.0243e-02, 3.8550e-04, 1.7876e-02, 6.2966e-04, 2.0847e-04,
        9.7044e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,897][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.3832, 0.1118, 0.1441, 0.0968, 0.1129, 0.1222, 0.0288],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,898][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([6.8566e-03, 4.4011e-04, 1.9922e-05, 8.5473e-04, 8.8955e-04, 1.2640e-04,
        9.9081e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,900][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0658, 0.0255, 0.0016, 0.0357, 0.0136, 0.0034, 0.8544],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,901][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([3.0908e-05, 1.1350e-04, 2.4233e-09, 5.5185e-06, 1.9879e-08, 3.9282e-10,
        9.9985e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,902][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.2063, 0.2412, 0.1302, 0.1618, 0.0216, 0.1017, 0.1373],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,902][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.1291, 0.0341, 0.1304, 0.0737, 0.2457, 0.3288, 0.0582],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,903][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.3017, 0.1124, 0.1004, 0.0367, 0.0863, 0.0788, 0.2836],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,903][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.3631, 0.0880, 0.1666, 0.1461, 0.0960, 0.1274, 0.0128],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,903][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.2558, 0.1300, 0.1539, 0.0729, 0.0725, 0.0787, 0.2362],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,904][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.1615, 0.1000, 0.1575, 0.0926, 0.1458, 0.1917, 0.1509],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:24,904][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.2484, 0.1943, 0.0405, 0.0798, 0.1486, 0.0565, 0.2061, 0.0259],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,904][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([1.6172e-03, 1.5048e-03, 5.4843e-03, 3.1725e-04, 1.2728e-04, 1.8797e-03,
        5.3710e-05, 9.8902e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,905][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.3213, 0.0522, 0.1688, 0.0865, 0.1289, 0.0599, 0.0394, 0.1430],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,906][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([4.0017e-03, 8.4289e-04, 2.7539e-03, 5.4720e-04, 1.2692e-02, 3.7485e-02,
        2.9636e-02, 9.1204e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,907][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.1266, 0.0264, 0.0193, 0.0244, 0.1883, 0.0737, 0.2405, 0.3009],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,908][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([7.7642e-02, 4.5956e-03, 1.4741e-02, 1.4066e-03, 7.9711e-03, 1.8410e-02,
        5.9337e-04, 8.7464e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,909][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.1461, 0.2242, 0.0165, 0.1978, 0.0939, 0.0195, 0.2806, 0.0214],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,911][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0852, 0.0412, 0.0555, 0.0675, 0.1006, 0.2006, 0.1376, 0.3118],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,912][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0632, 0.0094, 0.3111, 0.0161, 0.0671, 0.3371, 0.0333, 0.1627],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,913][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.2735, 0.0660, 0.1716, 0.0782, 0.0890, 0.1294, 0.0531, 0.1392],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,915][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.2327, 0.0765, 0.1731, 0.0538, 0.0574, 0.1234, 0.0292, 0.2538],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,916][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.2975, 0.0734, 0.1151, 0.1092, 0.0720, 0.0607, 0.1236, 0.1485],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:24,918][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.3431, 0.1996, 0.0243, 0.0778, 0.0845, 0.0194, 0.2112, 0.0187, 0.0214],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,919][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([9.2959e-03, 9.3490e-04, 5.7367e-02, 5.8101e-04, 1.7154e-04, 4.4580e-02,
        3.6169e-05, 5.6582e-02, 8.3045e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,920][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3101, 0.0441, 0.1345, 0.0636, 0.1315, 0.0394, 0.0333, 0.2057, 0.0378],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,922][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0287, 0.0027, 0.0062, 0.0067, 0.0169, 0.0714, 0.0223, 0.1892, 0.6559],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,923][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1834, 0.0373, 0.0248, 0.0404, 0.1321, 0.0572, 0.1679, 0.1966, 0.1603],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,925][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1294, 0.0130, 0.1246, 0.0064, 0.0609, 0.2397, 0.0037, 0.0761, 0.3463],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,926][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1645, 0.2610, 0.0042, 0.1860, 0.0748, 0.0044, 0.2952, 0.0074, 0.0026],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,928][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0737, 0.0204, 0.0323, 0.0366, 0.0547, 0.0845, 0.1355, 0.2768, 0.2854],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,928][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0197, 0.0049, 0.1385, 0.0068, 0.0294, 0.3256, 0.0113, 0.0645, 0.3993],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,929][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.2637, 0.0736, 0.1357, 0.0762, 0.0739, 0.1017, 0.0488, 0.1151, 0.1113],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,929][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.2781, 0.0740, 0.1469, 0.0561, 0.0453, 0.1314, 0.0189, 0.0847, 0.1646],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,929][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2049, 0.0826, 0.0981, 0.1047, 0.0669, 0.1021, 0.1316, 0.0967, 0.1124],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:24,930][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([0.1957, 0.1415, 0.0812, 0.0830, 0.0389, 0.0772, 0.1425, 0.0498, 0.0758,
        0.1143], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,930][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([1.1724e-04, 1.9043e-03, 1.3223e-04, 7.3705e-05, 1.8127e-04, 3.9501e-05,
        2.0035e-04, 3.9268e-04, 3.2716e-05, 9.9693e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,931][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([0.2605, 0.1041, 0.0578, 0.0888, 0.0452, 0.0640, 0.0905, 0.0562, 0.0619,
        0.1710], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,931][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([1.2390e-03, 2.4141e-04, 2.6842e-06, 5.5144e-05, 2.7581e-05, 2.4160e-05,
        1.1108e-02, 2.0015e-04, 1.3323e-04, 9.8697e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,932][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([6.8727e-03, 4.9740e-03, 2.2463e-04, 2.4854e-03, 1.1614e-03, 5.9127e-04,
        5.7088e-03, 1.7793e-03, 1.5131e-03, 9.7469e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,933][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([2.4340e-03, 2.0361e-04, 1.5660e-06, 1.2948e-05, 1.7656e-05, 5.6462e-07,
        6.0551e-05, 6.6447e-07, 2.5378e-07, 9.9727e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,934][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([0.1989, 0.1997, 0.0535, 0.1058, 0.0270, 0.0338, 0.1141, 0.0201, 0.0307,
        0.2165], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,935][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([0.0916, 0.0079, 0.0317, 0.0258, 0.0541, 0.0856, 0.0088, 0.2062, 0.3516,
        0.1367], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,937][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([0.2470, 0.0749, 0.1060, 0.0566, 0.0539, 0.1188, 0.0473, 0.0848, 0.1238,
        0.0870], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,938][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([0.2835, 0.0735, 0.1176, 0.0703, 0.0633, 0.0986, 0.0981, 0.0879, 0.0945,
        0.0127], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,939][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([0.2043, 0.0810, 0.1089, 0.0348, 0.0455, 0.0873, 0.0356, 0.0693, 0.0624,
        0.2707], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,941][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([0.2037, 0.0780, 0.1049, 0.0840, 0.0628, 0.0599, 0.1030, 0.1333, 0.0684,
        0.1020], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:24,942][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3713, 0.1284, 0.0137, 0.0552, 0.0963, 0.0245, 0.1935, 0.0163, 0.0439,
        0.0469, 0.0100], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,943][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([4.0958e-03, 3.1974e-04, 2.0231e-02, 3.1091e-04, 2.6248e-04, 3.2642e-04,
        5.3582e-05, 2.4365e-03, 9.4233e-04, 5.6458e-05, 9.7096e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,945][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2825, 0.0351, 0.1098, 0.0207, 0.0270, 0.0099, 0.0327, 0.0524, 0.0122,
        0.0187, 0.3992], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,946][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0346, 0.0015, 0.0027, 0.0008, 0.0094, 0.0122, 0.0072, 0.0505, 0.1298,
        0.0734, 0.6780], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,948][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3970, 0.0213, 0.0122, 0.0292, 0.0366, 0.0152, 0.0564, 0.0817, 0.0393,
        0.0640, 0.2472], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,949][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1190, 0.0231, 0.1727, 0.0196, 0.0375, 0.1294, 0.0159, 0.1097, 0.1218,
        0.0191, 0.2323], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,950][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2099, 0.1924, 0.0077, 0.1297, 0.0575, 0.0090, 0.1863, 0.0125, 0.0053,
        0.1845, 0.0051], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,952][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0346, 0.0187, 0.0147, 0.0252, 0.0284, 0.0423, 0.0544, 0.1062, 0.1678,
        0.1791, 0.3286], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,953][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0293, 0.0049, 0.1530, 0.0061, 0.0156, 0.1440, 0.0066, 0.0620, 0.2200,
        0.0112, 0.3475], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,954][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2251, 0.0616, 0.1168, 0.0737, 0.0663, 0.0812, 0.0475, 0.0938, 0.0870,
        0.0550, 0.0921], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,955][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1831, 0.0740, 0.1406, 0.0681, 0.0614, 0.0893, 0.0398, 0.1020, 0.0869,
        0.0507, 0.1040], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,955][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1940, 0.0667, 0.0924, 0.0931, 0.0670, 0.0565, 0.1195, 0.1019, 0.0482,
        0.0590, 0.1015], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:24,956][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.2776, 0.0671, 0.1182, 0.0585, 0.0211, 0.0643, 0.0106, 0.1145, 0.1005,
        0.0286, 0.0849, 0.0540], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,956][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([2.0113e-05, 3.8438e-01, 2.6747e-05, 4.2553e-05, 2.3316e-05, 6.0455e-06,
        5.3076e-04, 6.5096e-05, 8.0152e-06, 7.1814e-05, 6.7160e-07, 6.1482e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,957][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.2148, 0.1700, 0.0511, 0.0491, 0.0466, 0.0666, 0.0364, 0.0526, 0.0740,
        0.0791, 0.0398, 0.1199], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,957][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([2.7910e-03, 3.9289e-03, 4.5490e-06, 1.2249e-04, 2.9014e-05, 1.9770e-05,
        6.6625e-03, 8.6214e-05, 8.2373e-05, 6.2442e-03, 2.3958e-04, 9.7979e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,957][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.0122, 0.0538, 0.0010, 0.0201, 0.0014, 0.0012, 0.0038, 0.0033, 0.0037,
        0.0145, 0.0075, 0.8773], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,958][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([6.5527e-04, 7.2463e-01, 3.9223e-08, 7.7299e-06, 5.7924e-07, 3.5934e-09,
        4.0462e-04, 5.7596e-08, 1.6187e-09, 2.7574e-06, 2.1354e-09, 2.7430e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,960][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.1780, 0.1675, 0.0812, 0.0486, 0.0134, 0.0749, 0.0346, 0.0227, 0.1036,
        0.0740, 0.0787, 0.1227], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,961][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.0808, 0.0056, 0.0261, 0.0092, 0.0213, 0.0513, 0.0146, 0.1214, 0.1320,
        0.1908, 0.2649, 0.0820], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,962][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.2255, 0.0903, 0.0928, 0.1341, 0.0254, 0.0705, 0.0428, 0.0532, 0.0570,
        0.0705, 0.0711, 0.0668], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,964][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.2268, 0.0246, 0.1080, 0.0614, 0.0514, 0.0800, 0.0641, 0.0765, 0.0965,
        0.0984, 0.0951, 0.0171], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,965][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.1623, 0.2528, 0.0739, 0.0435, 0.0335, 0.0458, 0.0307, 0.0496, 0.0475,
        0.0336, 0.0472, 0.1797], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,967][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.0910, 0.0710, 0.0985, 0.0809, 0.0944, 0.0801, 0.0837, 0.0983, 0.0799,
        0.0496, 0.0943, 0.0782], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:24,968][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.2954, 0.0741, 0.0328, 0.0659, 0.0622, 0.0295, 0.0675, 0.0347, 0.0360,
        0.0419, 0.0399, 0.0968, 0.1234], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,969][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([4.1913e-04, 7.4695e-04, 2.0229e-04, 6.2452e-03, 1.2683e-02, 4.1229e-04,
        1.9076e-04, 1.3241e-04, 9.3985e-05, 7.0325e-05, 5.3637e-05, 1.7764e-04,
        9.7857e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,971][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.2667, 0.0444, 0.0818, 0.0778, 0.1271, 0.0633, 0.0208, 0.0683, 0.0676,
        0.0539, 0.0307, 0.0356, 0.0619], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,972][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([9.1964e-04, 6.2168e-06, 8.9574e-06, 5.2521e-06, 9.8193e-05, 2.6829e-05,
        3.7551e-05, 1.0295e-04, 1.5237e-04, 3.1331e-04, 9.5980e-04, 5.3074e-04,
        9.9684e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,973][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0381, 0.0041, 0.0048, 0.0025, 0.0075, 0.0068, 0.0043, 0.0228, 0.0140,
        0.0407, 0.0256, 0.0302, 0.7987], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,974][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([1.1281e-02, 3.5215e-04, 4.4781e-05, 2.2619e-04, 2.1529e-03, 5.7162e-06,
        2.0233e-05, 1.9063e-05, 1.8314e-06, 4.9789e-05, 1.9803e-06, 2.6105e-05,
        9.8582e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,976][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.1341, 0.1420, 0.0184, 0.1140, 0.0358, 0.0231, 0.0900, 0.0162, 0.0149,
        0.1250, 0.0146, 0.1794, 0.0926], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,977][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0298, 0.0113, 0.0084, 0.0101, 0.0149, 0.0277, 0.0075, 0.0494, 0.0770,
        0.0233, 0.2002, 0.3843, 0.1560], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,979][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.1444, 0.0270, 0.1139, 0.0145, 0.0781, 0.1151, 0.0445, 0.0941, 0.1497,
        0.0697, 0.0945, 0.0300, 0.0245], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,980][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.1784, 0.0598, 0.0799, 0.0829, 0.0665, 0.0607, 0.0628, 0.0633, 0.0663,
        0.0878, 0.0741, 0.0639, 0.0536], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,981][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.1701, 0.0449, 0.0776, 0.0545, 0.0717, 0.0653, 0.0394, 0.0555, 0.0652,
        0.0457, 0.0620, 0.0328, 0.2152], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,981][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.3048, 0.0395, 0.0752, 0.0716, 0.0435, 0.0406, 0.0729, 0.1008, 0.0304,
        0.0483, 0.0814, 0.0355, 0.0555], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:24,982][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2091, 0.0746, 0.0204, 0.0377, 0.0685, 0.0197, 0.1411, 0.0179, 0.0271,
        0.0305, 0.0238, 0.1085, 0.2066, 0.0146], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,982][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.7921e-03, 5.4867e-05, 3.9655e-02, 1.2353e-04, 4.6691e-04, 1.6741e-03,
        2.2317e-05, 1.9515e-02, 1.9054e-03, 2.4502e-05, 8.6326e-03, 1.4078e-05,
        2.9706e-05, 9.2209e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,983][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1977, 0.0238, 0.1002, 0.0582, 0.0544, 0.0261, 0.0226, 0.1370, 0.0288,
        0.0277, 0.0622, 0.0188, 0.0675, 0.1749], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,983][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([6.1250e-03, 1.9895e-05, 2.8181e-04, 9.2836e-04, 8.1967e-04, 1.6157e-03,
        2.2280e-03, 3.5074e-03, 1.5090e-02, 2.8952e-03, 3.7077e-02, 1.1906e-03,
        9.9244e-02, 8.2898e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,984][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.2073e-02, 6.0535e-04, 1.3494e-03, 8.4109e-04, 1.9565e-02, 3.7309e-03,
        1.1164e-02, 7.8288e-03, 6.2094e-03, 9.9782e-03, 9.1721e-03, 6.4292e-03,
        8.1240e-01, 9.8656e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,984][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([4.4400e-02, 7.4750e-04, 9.0702e-02, 1.1780e-03, 5.0416e-02, 2.1617e-01,
        6.2771e-04, 2.1169e-02, 1.7773e-01, 8.2989e-04, 1.8078e-02, 9.6774e-05,
        5.7967e-03, 3.7207e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,985][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0957, 0.0566, 0.0052, 0.0581, 0.0450, 0.0043, 0.0986, 0.0188, 0.0036,
        0.1129, 0.0043, 0.0775, 0.1379, 0.2814], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,987][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0240, 0.0059, 0.0050, 0.0093, 0.0084, 0.0101, 0.0178, 0.0218, 0.0361,
        0.0344, 0.0956, 0.2021, 0.2961, 0.2333], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,988][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0167, 0.0030, 0.0999, 0.0032, 0.0167, 0.1347, 0.0076, 0.0490, 0.2151,
        0.0119, 0.1801, 0.0048, 0.0076, 0.2498], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,990][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1528, 0.0404, 0.0919, 0.0599, 0.0534, 0.0746, 0.0366, 0.0768, 0.0805,
        0.0591, 0.0767, 0.0372, 0.0563, 0.1038], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,991][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1293, 0.0371, 0.1164, 0.0415, 0.0668, 0.0963, 0.0270, 0.0880, 0.0877,
        0.0328, 0.0817, 0.0263, 0.0481, 0.1209], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,993][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1659, 0.0546, 0.0772, 0.0729, 0.0610, 0.0491, 0.0823, 0.0782, 0.0372,
        0.0368, 0.0803, 0.0603, 0.0652, 0.0789], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:24,994][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.2233, 0.0481, 0.0278, 0.0287, 0.0632, 0.0242, 0.1143, 0.0169, 0.0279,
        0.1001, 0.0243, 0.0577, 0.1735, 0.0255, 0.0444], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:24,995][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([6.2318e-04, 4.0257e-04, 5.1063e-04, 3.4046e-03, 4.3711e-03, 4.5957e-04,
        2.4088e-04, 7.7272e-04, 2.1268e-04, 2.7309e-05, 1.6674e-04, 1.3122e-04,
        1.3223e-03, 5.6210e-04, 9.8679e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:24,997][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.1900, 0.0338, 0.0518, 0.0523, 0.0875, 0.0410, 0.0208, 0.0777, 0.0506,
        0.0654, 0.0334, 0.0295, 0.1073, 0.1096, 0.0494], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:24,998][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([8.9619e-04, 1.0297e-06, 4.9676e-06, 7.7136e-06, 3.2037e-05, 3.7235e-05,
        1.1775e-05, 6.5403e-05, 2.1139e-04, 2.5572e-04, 9.0913e-04, 1.6137e-04,
        8.8088e-03, 8.6094e-03, 9.7999e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:24,999][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0365, 0.0168, 0.0052, 0.0019, 0.0081, 0.0079, 0.0045, 0.0194, 0.0133,
        0.0720, 0.0229, 0.1246, 0.1074, 0.1011, 0.4584], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,000][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([9.2252e-03, 1.7483e-04, 5.0118e-05, 1.2551e-03, 1.4824e-03, 4.0168e-05,
        5.2041e-06, 3.3117e-05, 2.2217e-05, 1.0381e-06, 3.1410e-06, 1.0558e-05,
        1.6464e-04, 8.3903e-06, 9.8752e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,002][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.1169, 0.1093, 0.0127, 0.0939, 0.0287, 0.0141, 0.1374, 0.0119, 0.0121,
        0.1678, 0.0122, 0.1586, 0.0887, 0.0112, 0.0245], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,003][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0257, 0.0034, 0.0058, 0.0025, 0.0088, 0.0124, 0.0038, 0.0245, 0.0319,
        0.0158, 0.0880, 0.0764, 0.1475, 0.3157, 0.2380], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,005][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0739, 0.0218, 0.0876, 0.0127, 0.0726, 0.0719, 0.0990, 0.0637, 0.0914,
        0.0444, 0.0952, 0.0301, 0.0411, 0.1513, 0.0433], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,006][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.1314, 0.0412, 0.0760, 0.0403, 0.0612, 0.0650, 0.0633, 0.0631, 0.0656,
        0.0577, 0.0711, 0.0431, 0.0715, 0.0937, 0.0558], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,007][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.1065, 0.0258, 0.0692, 0.0527, 0.0760, 0.0603, 0.0387, 0.0667, 0.0573,
        0.0304, 0.0604, 0.0228, 0.0618, 0.0808, 0.1902], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,007][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.2640, 0.0405, 0.0903, 0.0521, 0.0523, 0.0265, 0.0520, 0.0793, 0.0204,
        0.0361, 0.0637, 0.0345, 0.0498, 0.0625, 0.0760], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,008][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.2477, 0.0724, 0.0181, 0.0270, 0.0431, 0.0113, 0.1399, 0.0147, 0.0166,
        0.0398, 0.0205, 0.1054, 0.1313, 0.0127, 0.0663, 0.0333],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,008][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([3.1333e-03, 4.7559e-04, 2.0978e-03, 6.2834e-04, 2.5794e-04, 3.3402e-03,
        1.1923e-05, 6.0166e-04, 1.0981e-02, 2.0315e-05, 7.2930e-04, 1.8868e-04,
        1.1510e-04, 3.1594e-03, 4.1423e-04, 9.7384e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,009][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.1628, 0.0213, 0.0777, 0.0363, 0.1053, 0.0236, 0.0232, 0.0640, 0.0245,
        0.0756, 0.0430, 0.0188, 0.1268, 0.0938, 0.0716, 0.0315],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,009][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([8.5283e-04, 8.4485e-06, 1.4941e-05, 2.5973e-05, 5.9203e-05, 1.0302e-04,
        3.5448e-05, 2.5983e-04, 8.7415e-04, 2.1593e-04, 3.2510e-03, 1.2545e-03,
        9.4382e-03, 1.8072e-02, 7.2860e-02, 8.9267e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,010][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.0454, 0.0032, 0.0056, 0.0067, 0.0158, 0.0061, 0.0132, 0.0130, 0.0133,
        0.0134, 0.0246, 0.0220, 0.2715, 0.0916, 0.1927, 0.2618],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,011][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([2.6661e-02, 2.0838e-03, 4.1835e-03, 1.0709e-04, 8.1109e-03, 6.5875e-03,
        1.6358e-03, 1.8985e-03, 8.3218e-03, 4.0228e-04, 4.5019e-04, 1.3321e-04,
        1.0293e-03, 1.9188e-03, 5.6499e-04, 9.3591e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,012][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.1018, 0.1111, 0.0052, 0.0970, 0.0383, 0.0050, 0.1179, 0.0056, 0.0034,
        0.1254, 0.0043, 0.2025, 0.1225, 0.0071, 0.0463, 0.0067],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,013][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.0257, 0.0020, 0.0040, 0.0064, 0.0060, 0.0067, 0.0070, 0.0162, 0.0188,
        0.0113, 0.0605, 0.0439, 0.0688, 0.1725, 0.2943, 0.2559],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,015][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.0314, 0.0035, 0.0868, 0.0051, 0.0338, 0.1338, 0.0133, 0.0414, 0.1853,
        0.0112, 0.1235, 0.0049, 0.0149, 0.1132, 0.0262, 0.1718],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,016][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.1520, 0.0463, 0.0742, 0.0497, 0.0495, 0.0565, 0.0405, 0.0590, 0.0631,
        0.0457, 0.0648, 0.0473, 0.0450, 0.0831, 0.0563, 0.0673],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,018][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.1117, 0.0337, 0.0700, 0.0355, 0.0382, 0.0683, 0.0195, 0.0517, 0.0861,
        0.0199, 0.0560, 0.0287, 0.0403, 0.0681, 0.0427, 0.2297],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,019][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.2030, 0.0477, 0.0578, 0.0626, 0.0427, 0.0352, 0.0743, 0.0647, 0.0306,
        0.0389, 0.0686, 0.0475, 0.0541, 0.0606, 0.0638, 0.0479],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,021][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1855, 0.0643, 0.0166, 0.0324, 0.0596, 0.0166, 0.1222, 0.0142, 0.0226,
        0.0272, 0.0192, 0.0941, 0.1785, 0.0118, 0.0700, 0.0509, 0.0141],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,022][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.8644e-03, 2.3288e-05, 1.7571e-02, 5.0366e-05, 2.1398e-04, 7.1511e-04,
        9.3619e-06, 8.8276e-03, 8.9413e-04, 1.1725e-05, 4.6307e-03, 6.9564e-06,
        1.4759e-05, 4.6292e-01, 4.0146e-04, 6.5272e-04, 5.0019e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,023][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1520, 0.0183, 0.0761, 0.0450, 0.0433, 0.0198, 0.0182, 0.1049, 0.0220,
        0.0219, 0.0480, 0.0153, 0.0545, 0.1340, 0.0562, 0.0273, 0.1433],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,024][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.6398e-03, 3.1399e-06, 4.0779e-05, 1.2977e-04, 8.5025e-05, 1.4147e-04,
        2.2946e-04, 2.4137e-04, 9.9467e-04, 1.9846e-04, 2.5224e-03, 8.2011e-05,
        6.2125e-03, 4.7919e-02, 4.0169e-01, 9.8673e-02, 4.3920e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,026][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0134, 0.0005, 0.0012, 0.0007, 0.0147, 0.0025, 0.0078, 0.0046, 0.0035,
        0.0054, 0.0050, 0.0035, 0.4312, 0.0499, 0.2338, 0.0621, 0.1600],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,027][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.7085e-02, 4.9384e-04, 6.1670e-02, 7.4141e-04, 3.5924e-02, 1.5530e-01,
        3.7425e-04, 1.5512e-02, 1.2601e-01, 5.0851e-04, 1.1445e-02, 6.3836e-05,
        3.9650e-03, 2.5977e-01, 9.0582e-03, 5.2704e-02, 2.3938e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,029][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0671, 0.0390, 0.0034, 0.0415, 0.0313, 0.0028, 0.0684, 0.0129, 0.0023,
        0.0765, 0.0028, 0.0556, 0.0984, 0.1980, 0.0532, 0.0075, 0.2393],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,030][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0201, 0.0036, 0.0031, 0.0053, 0.0041, 0.0043, 0.0079, 0.0076, 0.0122,
        0.0110, 0.0322, 0.0684, 0.0923, 0.0680, 0.1413, 0.2503, 0.2684],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,032][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0119, 0.0021, 0.0698, 0.0023, 0.0120, 0.0924, 0.0055, 0.0338, 0.1455,
        0.0085, 0.1255, 0.0035, 0.0055, 0.1723, 0.0140, 0.0892, 0.2062],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,033][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1195, 0.0317, 0.0710, 0.0481, 0.0429, 0.0577, 0.0301, 0.0590, 0.0619,
        0.0491, 0.0600, 0.0302, 0.0460, 0.0801, 0.0543, 0.0706, 0.0877],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,034][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0920, 0.0265, 0.0814, 0.0317, 0.0517, 0.0720, 0.0223, 0.0682, 0.0679,
        0.0273, 0.0662, 0.0228, 0.0416, 0.0999, 0.0498, 0.0772, 0.1014],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,034][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1507, 0.0469, 0.0678, 0.0641, 0.0540, 0.0431, 0.0659, 0.0658, 0.0318,
        0.0291, 0.0641, 0.0476, 0.0530, 0.0647, 0.0517, 0.0339, 0.0657],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,036][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:25,037][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 7431],
        [ 2460],
        [10493],
        [    1],
        [15477],
        [18666],
        [22417],
        [15178],
        [30159],
        [28511],
        [ 6398],
        [ 2672],
        [14587],
        [ 9809],
        [ 6825],
        [32824],
        [12033]], device='cuda:0')
[2024-07-24 10:31:25,038][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[28442],
        [ 1790],
        [41221],
        [    1],
        [43342],
        [36292],
        [34533],
        [36049],
        [30986],
        [43914],
        [40614],
        [ 1946],
        [33227],
        [38441],
        [34109],
        [26573],
        [36743]], device='cuda:0')
[2024-07-24 10:31:25,040][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 7327],
        [ 7593],
        [ 8701],
        [12972],
        [ 8092],
        [ 8905],
        [12140],
        [ 5653],
        [ 4974],
        [14588],
        [ 5978],
        [17210],
        [ 9811],
        [ 7360],
        [ 9827],
        [ 7669],
        [ 8403]], device='cuda:0')
[2024-07-24 10:31:25,041][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[20612],
        [ 3528],
        [13802],
        [14910],
        [27583],
        [43029],
        [19357],
        [35588],
        [46091],
        [39684],
        [ 3962],
        [ 3221],
        [14954],
        [30660],
        [11596],
        [37684],
        [30953]], device='cuda:0')
[2024-07-24 10:31:25,043][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[17567],
        [18563],
        [20909],
        [15560],
        [16991],
        [17230],
        [16212],
        [19813],
        [20951],
        [25846],
        [12411],
        [22286],
        [19266],
        [25915],
        [23445],
        [22838],
        [26810]], device='cuda:0')
[2024-07-24 10:31:25,044][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[21577],
        [23832],
        [14536],
        [  125],
        [13591],
        [14141],
        [36624],
        [28492],
        [21467],
        [35585],
        [27694],
        [27142],
        [40160],
        [26379],
        [15997],
        [32107],
        [22041]], device='cuda:0')
[2024-07-24 10:31:25,046][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[37939],
        [ 5802],
        [18159],
        [   49],
        [17743],
        [10806],
        [39960],
        [25440],
        [22648],
        [24628],
        [23319],
        [ 3209],
        [ 7442],
        [ 7743],
        [ 8548],
        [13081],
        [ 9383]], device='cuda:0')
[2024-07-24 10:31:25,047][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[26648],
        [12630],
        [33365],
        [ 7115],
        [30155],
        [26452],
        [ 9741],
        [30289],
        [29203],
        [37895],
        [31293],
        [13734],
        [20115],
        [31909],
        [37006],
        [27956],
        [32806]], device='cuda:0')
[2024-07-24 10:31:25,049][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[35163],
        [19236],
        [ 6996],
        [  670],
        [ 1191],
        [ 1320],
        [  849],
        [ 1783],
        [ 2113],
        [ 8201],
        [ 8909],
        [ 2418],
        [ 2013],
        [ 7948],
        [ 4989],
        [ 3548],
        [ 8036]], device='cuda:0')
[2024-07-24 10:31:25,050][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 9359],
        [ 9204],
        [16153],
        [20265],
        [22649],
        [38753],
        [42752],
        [33270],
        [37576],
        [38418],
        [28899],
        [26743],
        [17294],
        [14975],
        [24248],
        [34483],
        [34205]], device='cuda:0')
[2024-07-24 10:31:25,052][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[14614],
        [15129],
        [17462],
        [13359],
        [13003],
        [12314],
        [35197],
        [11148],
        [10889],
        [14858],
        [16232],
        [17082],
        [13832],
        [13268],
        [16209],
        [12857],
        [12818]], device='cuda:0')
[2024-07-24 10:31:25,053][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[12984],
        [10790],
        [21020],
        [17305],
        [19042],
        [19338],
        [15496],
        [20874],
        [20225],
        [14307],
        [21121],
        [17647],
        [12124],
        [23926],
        [22327],
        [21109],
        [25202]], device='cuda:0')
[2024-07-24 10:31:25,055][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[17200],
        [32584],
        [12397],
        [37806],
        [17485],
        [24909],
        [35615],
        [14276],
        [24111],
        [41885],
        [17939],
        [40230],
        [23494],
        [11818],
        [23283],
        [34308],
        [13731]], device='cuda:0')
[2024-07-24 10:31:25,056][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[27312],
        [23048],
        [14531],
        [14426],
        [14291],
        [14968],
        [11977],
        [12626],
        [15361],
        [10791],
        [11858],
        [11355],
        [13348],
        [10351],
        [10669],
        [12410],
        [10340]], device='cuda:0')
[2024-07-24 10:31:25,057][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[11182],
        [ 1251],
        [14055],
        [    1],
        [33898],
        [21560],
        [20543],
        [ 3849],
        [40156],
        [38090],
        [ 3128],
        [  803],
        [33057],
        [13632],
        [18036],
        [31695],
        [13709]], device='cuda:0')
[2024-07-24 10:31:25,059][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 9238],
        [ 9155],
        [ 9603],
        [13956],
        [10272],
        [10048],
        [10297],
        [10003],
        [ 9356],
        [11304],
        [ 9267],
        [11325],
        [ 8264],
        [ 7388],
        [ 8734],
        [ 7842],
        [ 7826]], device='cuda:0')
[2024-07-24 10:31:25,061][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[21464],
        [41396],
        [35074],
        [29716],
        [36632],
        [27050],
        [39076],
        [28193],
        [25683],
        [29321],
        [43257],
        [42540],
        [35989],
        [26476],
        [30751],
        [23397],
        [25112]], device='cuda:0')
[2024-07-24 10:31:25,062][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[46770],
        [46364],
        [45442],
        [45920],
        [45714],
        [45991],
        [45928],
        [44990],
        [44604],
        [41478],
        [36901],
        [42678],
        [45196],
        [41476],
        [43791],
        [43807],
        [40497]], device='cuda:0')
[2024-07-24 10:31:25,063][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[37242],
        [41123],
        [39214],
        [42869],
        [41316],
        [33353],
        [40920],
        [30508],
        [31167],
        [38679],
        [35166],
        [44512],
        [44271],
        [38714],
        [42605],
        [35710],
        [40231]], device='cuda:0')
[2024-07-24 10:31:25,064][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[23610],
        [33586],
        [28560],
        [28813],
        [25664],
        [28792],
        [ 9108],
        [28829],
        [28727],
        [33249],
        [30028],
        [11943],
        [36095],
        [35750],
        [34072],
        [33630],
        [35131]], device='cuda:0')
[2024-07-24 10:31:25,065][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[23954],
        [25288],
        [21693],
        [23985],
        [ 9810],
        [17204],
        [11200],
        [21383],
        [13551],
        [25285],
        [19334],
        [23816],
        [19481],
        [17868],
        [ 7128],
        [ 5246],
        [17838]], device='cuda:0')
[2024-07-24 10:31:25,066][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[46958],
        [46735],
        [43141],
        [19605],
        [26098],
        [29594],
        [16682],
        [20106],
        [22394],
        [18150],
        [22081],
        [23382],
        [18759],
        [39870],
        [20335],
        [23460],
        [42673]], device='cuda:0')
[2024-07-24 10:31:25,068][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[15511],
        [15714],
        [13494],
        [ 8671],
        [ 8925],
        [ 4319],
        [ 3399],
        [ 2933],
        [ 3176],
        [ 7099],
        [ 7823],
        [ 9358],
        [ 8197],
        [ 9501],
        [ 8281],
        [10313],
        [ 8550]], device='cuda:0')
[2024-07-24 10:31:25,069][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[32392],
        [29716],
        [29093],
        [25856],
        [27769],
        [20188],
        [25450],
        [23795],
        [20476],
        [24094],
        [21811],
        [22310],
        [22726],
        [24255],
        [22636],
        [25209],
        [27190]], device='cuda:0')
[2024-07-24 10:31:25,071][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[24323],
        [25240],
        [33852],
        [32895],
        [34702],
        [36420],
        [35071],
        [38703],
        [38377],
        [38582],
        [39409],
        [40950],
        [41072],
        [40285],
        [40581],
        [40380],
        [40581]], device='cuda:0')
[2024-07-24 10:31:25,072][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[48752],
        [41246],
        [49974],
        [43559],
        [48622],
        [49791],
        [42265],
        [50096],
        [49943],
        [41773],
        [49802],
        [38765],
        [48632],
        [50042],
        [49347],
        [49556],
        [50032]], device='cuda:0')
[2024-07-24 10:31:25,074][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[21929],
        [15277],
        [ 5942],
        [13652],
        [ 7106],
        [14323],
        [19659],
        [10188],
        [16388],
        [17695],
        [17943],
        [25966],
        [12879],
        [19576],
        [12718],
        [14670],
        [16374]], device='cuda:0')
[2024-07-24 10:31:25,075][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 1575],
        [ 4027],
        [ 2141],
        [ 7628],
        [ 4881],
        [ 4533],
        [10062],
        [ 5275],
        [ 5544],
        [ 9156],
        [ 4394],
        [ 8740],
        [ 5370],
        [ 3520],
        [ 5816],
        [ 5280],
        [ 3047]], device='cuda:0')
[2024-07-24 10:31:25,077][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[29339],
        [47047],
        [26341],
        [50257],
        [10269],
        [20199],
        [21658],
        [41934],
        [ 4944],
        [ 7658],
        [41714],
        [48082],
        [10754],
        [27792],
        [23183],
        [12789],
        [27610]], device='cuda:0')
[2024-07-24 10:31:25,078][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[11173],
        [11173],
        [11173],
        [11173],
        [11173],
        [11173],
        [11173],
        [11173],
        [11173],
        [11173],
        [11173],
        [11173],
        [11173],
        [11173],
        [11173],
        [11173],
        [11173]], device='cuda:0')
[2024-07-24 10:31:25,104][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:25,105][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,105][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,105][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,106][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,106][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,106][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,107][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,107][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,107][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,108][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,108][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,108][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,109][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.7779, 0.2221], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,109][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.2883, 0.7117], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,109][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.8983, 0.1017], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,110][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.6720, 0.3280], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,110][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.1889, 0.8111], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,110][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([9.9982e-01, 1.7943e-04], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,111][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.0543, 0.9457], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,111][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.9395, 0.0605], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,111][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.9845, 0.0155], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,112][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.5304, 0.4696], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,112][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.0371, 0.9629], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,112][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.4888, 0.5112], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,113][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1801, 0.1110, 0.7088], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,113][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0534, 0.2758, 0.6707], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,113][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.5754, 0.0884, 0.3362], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,114][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4868, 0.2579, 0.2553], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,114][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1262, 0.5454, 0.3284], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,114][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.6363, 0.0015, 0.3622], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,115][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0073, 0.9879, 0.0048], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,116][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.7981, 0.1183, 0.0835], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,118][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.8130, 0.0341, 0.1529], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,119][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0840, 0.0865, 0.8294], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,120][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0226, 0.6382, 0.3392], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,122][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1691, 0.0167, 0.8141], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,123][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Nathan] are: tensor([0.1846, 0.0486, 0.7121, 0.0547], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,124][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Nathan] are: tensor([0.0365, 0.1633, 0.6856, 0.1145], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,125][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Nathan] are: tensor([0.4438, 0.0875, 0.3018, 0.1669], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,125][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Nathan] are: tensor([0.4289, 0.1703, 0.1987, 0.2022], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,125][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Nathan] are: tensor([0.0814, 0.3584, 0.2331, 0.3271], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,126][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Nathan] are: tensor([8.6308e-01, 1.4241e-04, 1.3668e-01, 9.4724e-05], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,126][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Nathan] are: tensor([0.0144, 0.1693, 0.6464, 0.1699], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,126][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Nathan] are: tensor([0.5830, 0.1900, 0.1810, 0.0460], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,127][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Nathan] are: tensor([0.7751, 0.0385, 0.1341, 0.0524], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,127][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Nathan] are: tensor([0.0373, 0.1241, 0.8236, 0.0150], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,128][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Nathan] are: tensor([0.0223, 0.3828, 0.2665, 0.3284], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,129][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Nathan] are: tensor([0.4110, 0.0117, 0.0697, 0.5075], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,130][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.0745, 0.0351, 0.3874, 0.0463, 0.4567], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,132][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.0310, 0.1593, 0.5292, 0.1490, 0.1314], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,133][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.3774, 0.0869, 0.2324, 0.1609, 0.1424], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,135][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.3620, 0.1280, 0.1472, 0.1753, 0.1875], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,136][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.0607, 0.2735, 0.1744, 0.2573, 0.2341], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,137][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ got] are: tensor([6.3527e-01, 8.3854e-04, 3.1756e-01, 4.5835e-04, 4.5870e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,139][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.0158, 0.1461, 0.7229, 0.0515, 0.0637], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,140][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.4529, 0.1645, 0.0821, 0.1970, 0.1035], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,141][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.6617, 0.0381, 0.1487, 0.0562, 0.0953], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,143][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.0697, 0.2634, 0.5952, 0.0499, 0.0217], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,144][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.0125, 0.2688, 0.1604, 0.2547, 0.3036], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,146][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.7642, 0.0043, 0.1135, 0.0009, 0.1171], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,147][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0330, 0.0212, 0.1422, 0.0233, 0.1725, 0.6078], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,148][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0286, 0.0887, 0.3333, 0.0735, 0.1054, 0.3704], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,150][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.3208, 0.0664, 0.2074, 0.1369, 0.1056, 0.1629], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,150][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2848, 0.1264, 0.1214, 0.1584, 0.1628, 0.1461], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,151][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0559, 0.2146, 0.1467, 0.2164, 0.2027, 0.1636], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,151][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.3790, 0.0018, 0.2892, 0.0008, 0.0535, 0.2757], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,152][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0033, 0.3715, 0.0348, 0.3037, 0.2827, 0.0040], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,152][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.4428, 0.1238, 0.0797, 0.1009, 0.1459, 0.1070], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,152][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.5347, 0.0438, 0.1156, 0.0455, 0.0662, 0.1942], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,153][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1087, 0.2153, 0.5568, 0.0444, 0.0189, 0.0559], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,153][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0112, 0.2398, 0.1345, 0.2247, 0.2644, 0.1253], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,155][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0403, 0.0105, 0.1473, 0.0018, 0.0374, 0.7626], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,156][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.0180, 0.0044, 0.0995, 0.0056, 0.1279, 0.6915, 0.0532],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,157][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.0115, 0.0711, 0.2818, 0.0722, 0.0839, 0.4485, 0.0309],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,159][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.2672, 0.0640, 0.2246, 0.1080, 0.1199, 0.1227, 0.0937],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,160][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.2532, 0.1166, 0.1244, 0.1343, 0.1500, 0.1125, 0.1089],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,161][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0403, 0.1812, 0.1282, 0.1690, 0.1643, 0.1322, 0.1847],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,162][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([6.1956e-01, 1.6491e-04, 1.8277e-01, 9.9395e-05, 1.3874e-02, 1.8348e-01,
        5.4337e-05], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,163][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([2.6502e-04, 3.8228e-02, 7.5760e-02, 2.6495e-03, 1.8600e-03, 1.7853e-02,
        8.6338e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,165][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.1886, 0.1493, 0.0599, 0.1401, 0.2865, 0.1652, 0.0105],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,166][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.4372, 0.0135, 0.1084, 0.0279, 0.0909, 0.2719, 0.0502],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,167][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0387, 0.2202, 0.4390, 0.0793, 0.0559, 0.1449, 0.0220],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,169][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0105, 0.1876, 0.1448, 0.1845, 0.2289, 0.1089, 0.1347],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,170][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.3052, 0.0351, 0.0542, 0.0117, 0.0010, 0.0018, 0.5910],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,172][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0223, 0.0176, 0.0817, 0.0188, 0.1004, 0.3169, 0.1285, 0.3138],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,173][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0115, 0.0571, 0.2220, 0.0617, 0.0871, 0.3677, 0.0552, 0.1377],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,175][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.2520, 0.0637, 0.1501, 0.1194, 0.0927, 0.1119, 0.0933, 0.1172],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,176][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.2282, 0.0949, 0.0974, 0.1229, 0.1361, 0.0938, 0.1091, 0.1177],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,177][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0387, 0.1592, 0.1009, 0.1628, 0.1416, 0.1114, 0.1631, 0.1222],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,177][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ at] are: tensor([1.7506e-01, 1.2596e-03, 1.3923e-01, 5.0307e-04, 2.6180e-02, 1.2154e-01,
        5.3355e-04, 5.3569e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,177][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0113, 0.0102, 0.0322, 0.1782, 0.0669, 0.0061, 0.6925, 0.0026],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,178][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.3041, 0.1201, 0.0640, 0.0788, 0.1144, 0.0615, 0.1844, 0.0727],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,178][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.4472, 0.0456, 0.0968, 0.0436, 0.0714, 0.1624, 0.0398, 0.0932],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,179][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1106, 0.2353, 0.4307, 0.0568, 0.0213, 0.0638, 0.0576, 0.0239],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,179][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0101, 0.1768, 0.1054, 0.1591, 0.1983, 0.0852, 0.1462, 0.1189],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,179][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ at] are: tensor([8.1822e-04, 1.1165e-02, 3.3962e-02, 4.7338e-04, 4.0896e-02, 1.9399e-01,
        4.5063e-03, 7.1419e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,180][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0124, 0.0092, 0.0529, 0.0101, 0.0667, 0.2106, 0.0774, 0.2260, 0.3347],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,180][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0113, 0.0464, 0.1811, 0.0415, 0.0614, 0.2504, 0.0326, 0.2215, 0.1538],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,182][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2043, 0.0548, 0.1231, 0.1061, 0.0835, 0.1066, 0.1003, 0.0916, 0.1298],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,183][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1987, 0.0875, 0.0847, 0.1125, 0.1163, 0.0960, 0.1052, 0.0971, 0.1020],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,184][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0340, 0.1380, 0.0882, 0.1374, 0.1275, 0.0984, 0.1559, 0.1058, 0.1147],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,186][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1365, 0.0011, 0.1200, 0.0004, 0.0234, 0.1073, 0.0004, 0.4078, 0.2029],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,187][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ the] are: tensor([4.8617e-04, 6.5542e-02, 5.7399e-03, 6.5454e-02, 7.9755e-03, 1.1523e-04,
        8.5332e-01, 1.2294e-03, 1.3620e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,188][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.2804, 0.0803, 0.0569, 0.0698, 0.0967, 0.0794, 0.1352, 0.0798, 0.1215],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,189][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.3982, 0.0395, 0.0939, 0.0349, 0.0490, 0.1275, 0.0324, 0.0755, 0.1492],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,191][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0872, 0.2383, 0.4097, 0.0417, 0.0212, 0.0334, 0.0976, 0.0122, 0.0587],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,192][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0091, 0.1658, 0.0907, 0.1499, 0.1770, 0.0858, 0.1350, 0.0955, 0.0911],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,193][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.8714e-03, 1.1876e-02, 3.9354e-02, 3.9657e-04, 3.8853e-02, 1.9918e-01,
        4.9780e-03, 2.3355e-01, 4.6994e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,195][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([0.0057, 0.0015, 0.0311, 0.0019, 0.0403, 0.1963, 0.0182, 0.2645, 0.3730,
        0.0676], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,196][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([0.0067, 0.0392, 0.1351, 0.0429, 0.0539, 0.2199, 0.0214, 0.2747, 0.1770,
        0.0290], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,198][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([0.2102, 0.0488, 0.1551, 0.0888, 0.0854, 0.0831, 0.0805, 0.0973, 0.0867,
        0.0641], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,199][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([0.2169, 0.0760, 0.0867, 0.0992, 0.1095, 0.0788, 0.0836, 0.0995, 0.0730,
        0.0769], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,201][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([0.0269, 0.1216, 0.0836, 0.1152, 0.1081, 0.0875, 0.1245, 0.0958, 0.1023,
        0.1344], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,202][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([2.1458e-01, 1.2997e-04, 8.2134e-02, 6.9954e-05, 7.3610e-03, 8.5696e-02,
        4.6711e-05, 4.3285e-01, 1.7653e-01, 6.0071e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,203][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([4.0984e-04, 5.1464e-03, 3.2828e-01, 2.9256e-04, 1.8898e-02, 2.3552e-02,
        2.2304e-03, 1.5790e-02, 4.2260e-02, 5.6314e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,204][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([0.1813, 0.0832, 0.0612, 0.1405, 0.0784, 0.1189, 0.1286, 0.0665, 0.1355,
        0.0059], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,204][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.2426, 0.0237, 0.0684, 0.0437, 0.0749, 0.1794, 0.0394, 0.0827, 0.2091,
        0.0362], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,204][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([0.0996, 0.2329, 0.1829, 0.0705, 0.0847, 0.0717, 0.0719, 0.0543, 0.1201,
        0.0113], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,205][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([0.0084, 0.1330, 0.0967, 0.1403, 0.1592, 0.0784, 0.1083, 0.1035, 0.0716,
        0.1006], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,205][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([0.0214, 0.0262, 0.0896, 0.0019, 0.0032, 0.0115, 0.0379, 0.0290, 0.0051,
        0.7740], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,206][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0069, 0.0042, 0.0314, 0.0046, 0.0387, 0.1437, 0.0383, 0.1612, 0.2431,
        0.1022, 0.2258], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,206][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0097, 0.0521, 0.1493, 0.0437, 0.0607, 0.2022, 0.0349, 0.1628, 0.1579,
        0.0554, 0.0712], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,207][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1570, 0.0440, 0.0871, 0.0846, 0.0799, 0.0705, 0.0770, 0.0794, 0.0816,
        0.0718, 0.1671], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,208][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1753, 0.0699, 0.0737, 0.0901, 0.1025, 0.0758, 0.0820, 0.0902, 0.0695,
        0.0795, 0.0915], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,209][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0279, 0.1100, 0.0714, 0.1087, 0.1026, 0.0772, 0.1150, 0.0843, 0.0886,
        0.1250, 0.0893], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,210][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([1.0422e-01, 5.7125e-04, 9.7834e-02, 2.6511e-04, 1.7779e-02, 9.6016e-02,
        2.7294e-04, 3.6449e-01, 1.8287e-01, 2.1854e-03, 1.3350e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,211][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0047, 0.4734, 0.0041, 0.0136, 0.0121, 0.0013, 0.4448, 0.0061, 0.0008,
        0.0349, 0.0043], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,213][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2134, 0.0717, 0.0415, 0.0780, 0.0705, 0.0396, 0.1603, 0.0432, 0.0618,
        0.1588, 0.0610], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,214][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3535, 0.0272, 0.1267, 0.0250, 0.0489, 0.1011, 0.0332, 0.0530, 0.1252,
        0.0320, 0.0743], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,215][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0588, 0.3910, 0.2924, 0.0368, 0.0164, 0.0198, 0.0847, 0.0094, 0.0320,
        0.0065, 0.0522], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,216][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0067, 0.1330, 0.0776, 0.1194, 0.1610, 0.0644, 0.1079, 0.0913, 0.0651,
        0.1146, 0.0590], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,218][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0011, 0.0148, 0.0788, 0.0007, 0.0663, 0.1595, 0.0041, 0.1446, 0.1629,
        0.0060, 0.3612], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,219][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.0053, 0.0011, 0.0249, 0.0013, 0.0308, 0.1529, 0.0109, 0.2124, 0.2876,
        0.0444, 0.2230, 0.0054], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,221][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.0063, 0.0219, 0.1490, 0.0295, 0.0483, 0.2054, 0.0238, 0.1643, 0.1965,
        0.0390, 0.0974, 0.0186], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,222][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.1485, 0.0354, 0.1189, 0.0638, 0.0643, 0.0673, 0.0556, 0.0788, 0.0760,
        0.0513, 0.1852, 0.0549], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,224][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.1780, 0.0556, 0.0734, 0.0801, 0.1015, 0.0718, 0.0684, 0.0829, 0.0700,
        0.0632, 0.0964, 0.0587], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,225][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.0225, 0.1005, 0.0678, 0.0933, 0.0878, 0.0717, 0.0972, 0.0782, 0.0839,
        0.1090, 0.0847, 0.1033], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,226][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([2.8001e-01, 6.9283e-05, 6.2907e-02, 4.0200e-05, 4.5867e-03, 5.8304e-02,
        1.9504e-05, 3.9453e-01, 1.2739e-01, 2.5674e-04, 7.1865e-02, 2.0825e-05],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,228][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.0045, 0.1241, 0.1030, 0.0080, 0.0197, 0.0479, 0.0416, 0.0143, 0.0380,
        0.2464, 0.1729, 0.1796], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,229][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.1088, 0.0174, 0.0464, 0.0765, 0.0831, 0.0920, 0.0972, 0.0506, 0.1374,
        0.1352, 0.1443, 0.0111], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,230][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.2222, 0.0088, 0.0600, 0.0148, 0.0462, 0.2082, 0.0264, 0.0466, 0.1810,
        0.0212, 0.1487, 0.0159], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,231][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.0090, 0.2665, 0.1247, 0.0518, 0.0320, 0.0884, 0.0135, 0.1573, 0.1138,
        0.0015, 0.1147, 0.0267], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,231][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.0084, 0.0989, 0.0829, 0.1101, 0.1404, 0.0720, 0.0894, 0.0874, 0.0672,
        0.0936, 0.0639, 0.0859], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,231][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([1.1696e-02, 9.0709e-01, 2.4946e-03, 5.2054e-04, 8.2944e-04, 1.0517e-03,
        3.8445e-03, 9.6486e-04, 3.6355e-04, 1.8439e-04, 3.5775e-04, 7.0606e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,232][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0040, 0.0017, 0.0219, 0.0021, 0.0265, 0.1364, 0.0212, 0.1649, 0.2555,
        0.0717, 0.2249, 0.0113, 0.0581], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,232][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0065, 0.0325, 0.1510, 0.0392, 0.0406, 0.2135, 0.0268, 0.1077, 0.1694,
        0.0499, 0.1042, 0.0360, 0.0225], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,233][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.1340, 0.0372, 0.0854, 0.0710, 0.0619, 0.0601, 0.0670, 0.0674, 0.0653,
        0.0605, 0.1508, 0.0596, 0.0799], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,233][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.1527, 0.0546, 0.0617, 0.0760, 0.0913, 0.0652, 0.0705, 0.0732, 0.0628,
        0.0666, 0.0831, 0.0570, 0.0852], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,235][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0206, 0.0946, 0.0589, 0.0876, 0.0815, 0.0616, 0.0918, 0.0701, 0.0726,
        0.1018, 0.0755, 0.0995, 0.0839], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,235][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([1.4524e-01, 1.7171e-04, 7.7454e-02, 9.1612e-05, 9.5798e-03, 7.9808e-02,
        6.1484e-05, 4.1296e-01, 1.6348e-01, 6.7443e-04, 1.0391e-01, 5.8344e-05,
        6.5019e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,236][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([2.1270e-04, 1.2539e-02, 8.5647e-02, 2.0145e-03, 1.8905e-03, 1.9083e-04,
        4.1855e-01, 6.3782e-04, 3.7213e-04, 5.3194e-03, 7.2479e-03, 6.1194e-02,
        4.0419e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,238][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.1625, 0.0432, 0.0314, 0.0284, 0.1167, 0.0412, 0.1655, 0.0378, 0.0592,
        0.2024, 0.0556, 0.0239, 0.0321], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,239][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.2471, 0.0176, 0.0919, 0.0339, 0.0569, 0.1164, 0.0358, 0.0439, 0.1680,
        0.0332, 0.0939, 0.0240, 0.0374], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,241][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0117, 0.6300, 0.1159, 0.0414, 0.0206, 0.0118, 0.0570, 0.0119, 0.0216,
        0.0027, 0.0253, 0.0225, 0.0276], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,242][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0053, 0.1111, 0.0648, 0.0980, 0.1228, 0.0495, 0.0859, 0.0739, 0.0531,
        0.0936, 0.0469, 0.0970, 0.0982], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,244][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0740, 0.1791, 0.1525, 0.0128, 0.0746, 0.0735, 0.0144, 0.0225, 0.0222,
        0.0084, 0.0395, 0.0475, 0.2788], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,245][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0055, 0.0045, 0.0231, 0.0048, 0.0284, 0.0898, 0.0354, 0.0948, 0.1422,
        0.0822, 0.1401, 0.0219, 0.0603, 0.2669], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,247][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0062, 0.0352, 0.1117, 0.0312, 0.0391, 0.1907, 0.0232, 0.1151, 0.1447,
        0.0473, 0.0634, 0.0345, 0.0319, 0.1258], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,248][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1086, 0.0389, 0.0615, 0.0612, 0.0571, 0.0576, 0.0556, 0.0607, 0.0635,
        0.0572, 0.1253, 0.0758, 0.0811, 0.0960], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,250][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1461, 0.0517, 0.0504, 0.0719, 0.0877, 0.0563, 0.0622, 0.0742, 0.0532,
        0.0637, 0.0742, 0.0600, 0.0830, 0.0654], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,251][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0220, 0.0825, 0.0537, 0.0830, 0.0774, 0.0606, 0.0860, 0.0647, 0.0689,
        0.0972, 0.0689, 0.0914, 0.0794, 0.0642], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,252][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([4.4514e-02, 8.3921e-04, 5.8611e-02, 3.1978e-04, 1.3625e-02, 5.4708e-02,
        3.8838e-04, 1.7610e-01, 1.0095e-01, 2.3162e-03, 7.6334e-02, 3.4521e-04,
        1.2068e-02, 4.5887e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,253][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([4.8492e-03, 6.3659e-04, 7.2543e-03, 1.1929e-01, 4.5685e-02, 1.4347e-03,
        2.0755e-01, 1.1543e-03, 2.5388e-04, 4.1744e-02, 7.4318e-04, 2.4968e-03,
        5.6169e-01, 5.2233e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,255][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1525, 0.0525, 0.0427, 0.0431, 0.0541, 0.0527, 0.1438, 0.0451, 0.0587,
        0.1187, 0.0914, 0.0258, 0.0572, 0.0617], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,256][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2989, 0.0371, 0.0757, 0.0285, 0.0441, 0.1025, 0.0259, 0.0659, 0.0914,
        0.0297, 0.0634, 0.0303, 0.0375, 0.0691], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,257][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0720, 0.2843, 0.1266, 0.0591, 0.0368, 0.0427, 0.0870, 0.0086, 0.0645,
        0.0089, 0.0248, 0.0257, 0.1542, 0.0048], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,257][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0054, 0.1034, 0.0558, 0.0987, 0.1160, 0.0518, 0.0787, 0.0719, 0.0500,
        0.0841, 0.0461, 0.0910, 0.1022, 0.0448], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,258][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0016, 0.0082, 0.0824, 0.0007, 0.0634, 0.1779, 0.0030, 0.1592, 0.1446,
        0.0064, 0.2218, 0.0139, 0.0196, 0.0973], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,258][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0031, 0.0016, 0.0155, 0.0019, 0.0182, 0.0809, 0.0186, 0.0932, 0.1445,
        0.0562, 0.1353, 0.0101, 0.0411, 0.3198, 0.0600], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,259][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0053, 0.0321, 0.0910, 0.0328, 0.0310, 0.1616, 0.0248, 0.0973, 0.1517,
        0.0408, 0.0591, 0.0324, 0.0367, 0.1590, 0.0445], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,259][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.1098, 0.0356, 0.0811, 0.0541, 0.0507, 0.0486, 0.0503, 0.0567, 0.0535,
        0.0462, 0.1358, 0.0560, 0.0788, 0.0824, 0.0600], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,259][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.1459, 0.0442, 0.0523, 0.0670, 0.0799, 0.0517, 0.0557, 0.0670, 0.0499,
        0.0543, 0.0757, 0.0484, 0.0744, 0.0582, 0.0755], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,261][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0180, 0.0772, 0.0501, 0.0753, 0.0695, 0.0537, 0.0786, 0.0611, 0.0631,
        0.0854, 0.0651, 0.0820, 0.0758, 0.0583, 0.0868], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,262][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ give] are: tensor([5.7119e-02, 1.7357e-04, 4.1559e-02, 9.7793e-05, 6.6627e-03, 4.2095e-02,
        7.2336e-05, 1.8661e-01, 8.1065e-02, 6.3133e-04, 5.7273e-02, 6.1386e-05,
        5.2305e-03, 4.8335e-01, 3.8000e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,263][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ give] are: tensor([3.3577e-05, 2.3557e-04, 2.2845e-02, 4.6809e-04, 2.1988e-03, 1.6559e-05,
        7.5192e-01, 1.1990e-03, 1.1471e-05, 1.9649e-01, 3.4883e-04, 1.9300e-03,
        1.2569e-03, 5.2874e-03, 1.5764e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,264][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0843, 0.0568, 0.0397, 0.0465, 0.0511, 0.0554, 0.0934, 0.0460, 0.0845,
        0.0823, 0.1145, 0.0530, 0.0920, 0.0754, 0.0251], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,266][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.2395, 0.0125, 0.0773, 0.0203, 0.0484, 0.1250, 0.0202, 0.0489, 0.1379,
        0.0235, 0.0844, 0.0156, 0.0324, 0.0778, 0.0361], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,267][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0262, 0.2440, 0.0982, 0.0557, 0.0383, 0.0681, 0.0365, 0.0258, 0.1088,
        0.0049, 0.0524, 0.0325, 0.1182, 0.0122, 0.0782], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,269][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0053, 0.0872, 0.0522, 0.0942, 0.1164, 0.0461, 0.0731, 0.0657, 0.0463,
        0.0753, 0.0443, 0.0788, 0.0964, 0.0386, 0.0801], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,270][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.2082, 0.0098, 0.3078, 0.0047, 0.1421, 0.0413, 0.0129, 0.0296, 0.0176,
        0.0112, 0.0224, 0.0023, 0.0050, 0.0234, 0.1617], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,272][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.0032, 0.0022, 0.0149, 0.0025, 0.0206, 0.0689, 0.0208, 0.0771, 0.1140,
        0.0552, 0.1114, 0.0121, 0.0432, 0.2408, 0.0612, 0.1520],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,273][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.0057, 0.0239, 0.0910, 0.0243, 0.0296, 0.1506, 0.0177, 0.0936, 0.1034,
        0.0293, 0.0580, 0.0222, 0.0275, 0.1563, 0.0621, 0.1049],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,274][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.1080, 0.0322, 0.0610, 0.0570, 0.0458, 0.0514, 0.0495, 0.0538, 0.0620,
        0.0474, 0.1175, 0.0555, 0.0714, 0.0656, 0.0624, 0.0595],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,276][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.1307, 0.0465, 0.0470, 0.0660, 0.0720, 0.0522, 0.0549, 0.0569, 0.0501,
        0.0563, 0.0665, 0.0519, 0.0721, 0.0479, 0.0687, 0.0603],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,278][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.0177, 0.0731, 0.0468, 0.0710, 0.0660, 0.0514, 0.0759, 0.0561, 0.0600,
        0.0812, 0.0611, 0.0802, 0.0700, 0.0531, 0.0810, 0.0555],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,279][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ it] are: tensor([5.9076e-02, 4.1393e-04, 5.1047e-02, 1.8422e-04, 8.9489e-03, 4.9459e-02,
        1.6560e-04, 1.5702e-01, 8.8474e-02, 1.2626e-03, 6.3567e-02, 1.4701e-04,
        6.7659e-03, 4.2966e-01, 3.6298e-02, 4.7513e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,280][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ it] are: tensor([7.2144e-05, 2.7725e-03, 5.7102e-04, 7.8399e-04, 1.1671e-04, 4.2943e-06,
        9.8278e-01, 8.3472e-05, 1.0327e-05, 1.9955e-03, 2.0478e-05, 9.3106e-03,
        1.1885e-03, 7.6476e-05, 1.5136e-04, 6.1325e-05], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,281][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.1242, 0.0562, 0.0395, 0.0989, 0.0264, 0.0857, 0.0862, 0.0391, 0.0969,
        0.0542, 0.0861, 0.0224, 0.0489, 0.0643, 0.0372, 0.0339],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,283][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.2619, 0.0260, 0.0630, 0.0264, 0.0389, 0.1061, 0.0224, 0.0612, 0.0984,
        0.0253, 0.0518, 0.0224, 0.0334, 0.0681, 0.0352, 0.0595],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,283][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.0406, 0.2488, 0.1226, 0.0585, 0.0278, 0.0462, 0.0536, 0.0111, 0.0676,
        0.0056, 0.0345, 0.0240, 0.1338, 0.0065, 0.0506, 0.0681],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,284][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.0077, 0.0871, 0.0502, 0.0855, 0.0941, 0.0473, 0.0743, 0.0571, 0.0484,
        0.0717, 0.0418, 0.0796, 0.0841, 0.0361, 0.0738, 0.0613],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,284][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.0126, 0.0222, 0.1279, 0.0018, 0.0470, 0.0675, 0.0109, 0.0660, 0.0556,
        0.0287, 0.0625, 0.0073, 0.0051, 0.0253, 0.0077, 0.4520],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,285][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0037, 0.0031, 0.0151, 0.0033, 0.0191, 0.0584, 0.0246, 0.0607, 0.0914,
        0.0566, 0.0914, 0.0154, 0.0408, 0.1702, 0.0496, 0.1220, 0.1745],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,285][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0051, 0.0261, 0.0785, 0.0219, 0.0261, 0.1273, 0.0167, 0.0798, 0.0959,
        0.0329, 0.0448, 0.0245, 0.0221, 0.0857, 0.0441, 0.1407, 0.1279],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,285][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0890, 0.0335, 0.0508, 0.0518, 0.0485, 0.0467, 0.0473, 0.0494, 0.0508,
        0.0478, 0.0998, 0.0623, 0.0685, 0.0762, 0.0585, 0.0487, 0.0705],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,286][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1240, 0.0423, 0.0408, 0.0593, 0.0726, 0.0455, 0.0507, 0.0607, 0.0427,
        0.0519, 0.0605, 0.0484, 0.0683, 0.0533, 0.0707, 0.0531, 0.0553],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,288][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0185, 0.0677, 0.0439, 0.0683, 0.0635, 0.0500, 0.0707, 0.0531, 0.0567,
        0.0799, 0.0566, 0.0751, 0.0651, 0.0527, 0.0787, 0.0520, 0.0475],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,289][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([3.1216e-02, 6.2875e-04, 3.9549e-02, 2.3839e-04, 9.1027e-03, 3.5442e-02,
        2.8064e-04, 1.1087e-01, 6.4205e-02, 1.6265e-03, 4.9498e-02, 2.4661e-04,
        8.0897e-03, 2.8172e-01, 3.1460e-02, 3.4995e-02, 3.0083e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,290][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([2.1065e-03, 4.0038e-04, 3.8202e-03, 5.6224e-02, 2.1935e-02, 5.5969e-04,
        1.0209e-01, 5.7637e-04, 1.1401e-04, 1.8720e-02, 3.4349e-04, 1.7004e-03,
        2.7851e-01, 2.5309e-03, 5.0141e-01, 6.4880e-03, 2.4648e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,291][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1402, 0.0450, 0.0413, 0.0416, 0.0341, 0.0484, 0.1150, 0.0423, 0.0547,
        0.0943, 0.1042, 0.0182, 0.0387, 0.0625, 0.0474, 0.0233, 0.0487],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,293][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2510, 0.0353, 0.0601, 0.0237, 0.0382, 0.1031, 0.0223, 0.0585, 0.0762,
        0.0228, 0.0562, 0.0254, 0.0296, 0.0599, 0.0346, 0.0453, 0.0577],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,294][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0437, 0.2827, 0.0985, 0.0564, 0.0307, 0.0412, 0.0784, 0.0063, 0.0597,
        0.0070, 0.0150, 0.0202, 0.1331, 0.0031, 0.0637, 0.0587, 0.0016],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,296][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0047, 0.0858, 0.0464, 0.0819, 0.0963, 0.0432, 0.0657, 0.0596, 0.0415,
        0.0699, 0.0386, 0.0757, 0.0849, 0.0375, 0.0731, 0.0579, 0.0375],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,297][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0885, 0.0083, 0.3041, 0.0011, 0.0710, 0.1028, 0.0051, 0.0972, 0.0436,
        0.0111, 0.0838, 0.0042, 0.0085, 0.1163, 0.0086, 0.0060, 0.0397],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,323][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:25,323][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,324][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,324][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,324][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,325][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,325][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,325][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,326][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,326][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,326][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,327][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,327][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,328][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.7699, 0.2301], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,329][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.2155, 0.7845], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,331][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.6598, 0.3402], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,332][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.6140, 0.3860], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,334][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.3903, 0.6097], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,335][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.6527, 0.3473], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,336][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.4225, 0.5775], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,338][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.5077, 0.4923], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,339][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.4999, 0.5001], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,340][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.4989, 0.5011], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,342][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.1928, 0.8072], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,343][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.5153, 0.4847], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,344][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.5313, 0.2185, 0.2502], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,346][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1243, 0.4184, 0.4573], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,347][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4685, 0.2506, 0.2809], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,349][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.4137, 0.2829, 0.3034], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,349][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2300, 0.3574, 0.4125], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,349][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4205, 0.1516, 0.4279], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,350][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1347, 0.1920, 0.6732], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,350][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2816, 0.2456, 0.4728], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,350][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3332, 0.3334, 0.3334], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,351][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.3327, 0.3342, 0.3331], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,351][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1220, 0.5337, 0.3443], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,352][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2632, 0.2566, 0.4803], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,352][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Nathan] are: tensor([0.4970, 0.1571, 0.2210, 0.1249], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,353][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Nathan] are: tensor([0.0847, 0.3052, 0.3595, 0.2506], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,354][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Nathan] are: tensor([0.3527, 0.1887, 0.2191, 0.2395], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,356][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Nathan] are: tensor([0.3250, 0.1940, 0.2294, 0.2516], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,357][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Nathan] are: tensor([0.1577, 0.2461, 0.2848, 0.3114], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,358][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Nathan] are: tensor([0.1536, 0.0885, 0.1992, 0.5587], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,359][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Nathan] are: tensor([0.1550, 0.1365, 0.5111, 0.1975], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,361][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Nathan] are: tensor([0.2106, 0.1546, 0.2478, 0.3869], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,362][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Nathan] are: tensor([0.2499, 0.2500, 0.2501, 0.2499], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,364][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Nathan] are: tensor([0.2496, 0.2507, 0.2499, 0.2498], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,365][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Nathan] are: tensor([0.0897, 0.3567, 0.2426, 0.3110], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,366][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Nathan] are: tensor([0.1241, 0.1196, 0.1507, 0.6056], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,368][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.3507, 0.1278, 0.1832, 0.1142, 0.2240], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,369][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.0628, 0.2125, 0.2428, 0.1707, 0.3112], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,371][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.2929, 0.1525, 0.1714, 0.1932, 0.1900], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,372][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.2614, 0.1537, 0.1810, 0.2075, 0.1964], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,374][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.1170, 0.1825, 0.2134, 0.2336, 0.2535], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,375][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.0166, 0.0128, 0.0758, 0.1249, 0.7699], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,375][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.1012, 0.1003, 0.4150, 0.1502, 0.2333], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,376][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.1417, 0.1084, 0.1898, 0.2578, 0.3023], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,376][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.2000, 0.2000, 0.2001, 0.2000, 0.2000], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,377][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.1999, 0.2008, 0.2001, 0.2000, 0.1992], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,377][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.0623, 0.2648, 0.1747, 0.2420, 0.2562], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,377][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.0577, 0.0555, 0.0796, 0.3595, 0.4477], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,378][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2341, 0.1012, 0.1285, 0.0927, 0.1780, 0.2655], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,378][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0510, 0.1497, 0.1611, 0.1223, 0.2063, 0.3096], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,379][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2449, 0.1296, 0.1480, 0.1695, 0.1629, 0.1452], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,380][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2118, 0.1390, 0.1496, 0.1820, 0.1678, 0.1498], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,382][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0905, 0.1388, 0.1638, 0.1818, 0.1979, 0.2272], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,383][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0196, 0.0121, 0.0513, 0.1079, 0.6860, 0.1230], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,385][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0555, 0.0977, 0.3716, 0.1352, 0.1927, 0.1474], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,386][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1064, 0.0818, 0.1529, 0.1584, 0.2190, 0.2815], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,387][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1667, 0.1668, 0.1668, 0.1667, 0.1667, 0.1663], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,389][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1665, 0.1672, 0.1666, 0.1666, 0.1659, 0.1672], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,390][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0528, 0.2260, 0.1481, 0.2095, 0.2214, 0.1422], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,392][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0248, 0.0236, 0.0246, 0.1127, 0.1627, 0.6516], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,393][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.2676, 0.0705, 0.1143, 0.0568, 0.1418, 0.2437, 0.1054],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,395][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0304, 0.1134, 0.1371, 0.0869, 0.1815, 0.3279, 0.1227],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,396][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.2168, 0.1129, 0.1328, 0.1406, 0.1448, 0.1215, 0.1306],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,397][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.1923, 0.1167, 0.1356, 0.1531, 0.1474, 0.1272, 0.1277],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,399][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0734, 0.1159, 0.1373, 0.1465, 0.1605, 0.1952, 0.1711],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,400][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.0282, 0.0169, 0.0398, 0.1245, 0.6116, 0.0960, 0.0830],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,402][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.0773, 0.0567, 0.2223, 0.0893, 0.1344, 0.1150, 0.3049],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,402][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0993, 0.0738, 0.1436, 0.1597, 0.2205, 0.2563, 0.0467],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,402][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.1429, 0.1430, 0.1430, 0.1429, 0.1429, 0.1426, 0.1428],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,403][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.1427, 0.1433, 0.1428, 0.1428, 0.1422, 0.1433, 0.1429],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,403][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0476, 0.1877, 0.1285, 0.1708, 0.1789, 0.1173, 0.1693],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,404][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0165, 0.0157, 0.0162, 0.0712, 0.0960, 0.4053, 0.3791],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,404][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.1746, 0.0778, 0.0974, 0.0730, 0.1322, 0.1954, 0.1234, 0.1262],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,404][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0367, 0.1058, 0.1167, 0.0864, 0.1466, 0.2265, 0.1164, 0.1649],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,405][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1939, 0.1016, 0.1108, 0.1323, 0.1251, 0.1084, 0.1172, 0.1107],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,406][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.1656, 0.1045, 0.1158, 0.1380, 0.1290, 0.1101, 0.1196, 0.1174],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,408][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0633, 0.0961, 0.1133, 0.1246, 0.1355, 0.1574, 0.1427, 0.1670],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,409][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0050, 0.0034, 0.0218, 0.0313, 0.1942, 0.0434, 0.0264, 0.6745],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,410][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0253, 0.0441, 0.1857, 0.0696, 0.0998, 0.0740, 0.3691, 0.1324],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,412][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0866, 0.0665, 0.1135, 0.1312, 0.1699, 0.1981, 0.0465, 0.1878],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,413][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.1251, 0.1251, 0.1251, 0.1251, 0.1251, 0.1248, 0.1249, 0.1249],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,414][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.1248, 0.1254, 0.1250, 0.1249, 0.1244, 0.1254, 0.1251, 0.1251],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,416][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0394, 0.1641, 0.1076, 0.1497, 0.1604, 0.1003, 0.1614, 0.1171],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,417][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0110, 0.0105, 0.0122, 0.0491, 0.0619, 0.2649, 0.2607, 0.3296],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,419][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1407, 0.0651, 0.0831, 0.0613, 0.1187, 0.1709, 0.1080, 0.1101, 0.1421],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,420][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0317, 0.0902, 0.0973, 0.0744, 0.1247, 0.1871, 0.0983, 0.1369, 0.1594],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,422][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1661, 0.0914, 0.1003, 0.1195, 0.1140, 0.0994, 0.1082, 0.0979, 0.1032],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,423][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.1444, 0.0964, 0.1026, 0.1265, 0.1153, 0.1004, 0.1104, 0.1031, 0.1008],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,424][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0528, 0.0801, 0.0952, 0.1052, 0.1149, 0.1320, 0.1219, 0.1409, 0.1569],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,426][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0035, 0.0027, 0.0162, 0.0264, 0.1405, 0.0315, 0.0198, 0.4264, 0.3331],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,427][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0166, 0.0383, 0.1645, 0.0607, 0.0874, 0.0643, 0.3788, 0.1134, 0.0759],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,428][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0678, 0.0512, 0.1012, 0.0842, 0.1300, 0.1686, 0.0345, 0.1781, 0.1844],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,429][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1112, 0.1112, 0.1112, 0.1112, 0.1112, 0.1109, 0.1110, 0.1110, 0.1112],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,429][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1110, 0.1115, 0.1111, 0.1111, 0.1106, 0.1115, 0.1112, 0.1112, 0.1106],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,430][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0357, 0.1480, 0.0964, 0.1374, 0.1450, 0.0932, 0.1466, 0.1035, 0.0942],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,430][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0113, 0.0107, 0.0098, 0.0359, 0.0410, 0.1800, 0.1916, 0.2291, 0.2906],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,430][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([0.1512, 0.0454, 0.0771, 0.0393, 0.0982, 0.1719, 0.0753, 0.0967, 0.1312,
        0.1138], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,431][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([0.0176, 0.0695, 0.0829, 0.0534, 0.1081, 0.2014, 0.0774, 0.1412, 0.1741,
        0.0744], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,431][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([0.1628, 0.0808, 0.0930, 0.1024, 0.1016, 0.0857, 0.0943, 0.0872, 0.0874,
        0.1048], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,432][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([0.1437, 0.0833, 0.0990, 0.1103, 0.1059, 0.0924, 0.0914, 0.0972, 0.0901,
        0.0867], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,433][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([0.0454, 0.0700, 0.0832, 0.0893, 0.0975, 0.1174, 0.1027, 0.1258, 0.1432,
        0.1256], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,435][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([0.0076, 0.0038, 0.0172, 0.0171, 0.0814, 0.0147, 0.0199, 0.4255, 0.1623,
        0.2505], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,436][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([0.0378, 0.0347, 0.1456, 0.0582, 0.0834, 0.0660, 0.1807, 0.1271, 0.0844,
        0.1821], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,438][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([0.0649, 0.0501, 0.0763, 0.1286, 0.1365, 0.1479, 0.0354, 0.1231, 0.1410,
        0.0963], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,439][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([0.1000, 0.1001, 0.1001, 0.1000, 0.1000, 0.0998, 0.0999, 0.0999, 0.1001,
        0.1000], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,440][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([0.0999, 0.1003, 0.1000, 0.0999, 0.0995, 0.1003, 0.1001, 0.1001, 0.0995,
        0.1004], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,442][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([0.0324, 0.1305, 0.0887, 0.1209, 0.1259, 0.0826, 0.1214, 0.0936, 0.0815,
        0.1227], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,443][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([0.0116, 0.0109, 0.0074, 0.0261, 0.0282, 0.1221, 0.1320, 0.1410, 0.1894,
        0.3313], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,445][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1108, 0.0484, 0.0612, 0.0447, 0.0888, 0.1310, 0.0814, 0.0839, 0.1092,
        0.1140, 0.1265], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,446][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0240, 0.0702, 0.0773, 0.0574, 0.0995, 0.1582, 0.0770, 0.1164, 0.1394,
        0.0731, 0.1074], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,448][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1370, 0.0734, 0.0803, 0.0959, 0.0930, 0.0784, 0.0854, 0.0789, 0.0805,
        0.0978, 0.0992], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,449][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1216, 0.0792, 0.0861, 0.1032, 0.0960, 0.0821, 0.0889, 0.0867, 0.0805,
        0.0845, 0.0912], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,451][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0409, 0.0617, 0.0731, 0.0803, 0.0878, 0.1008, 0.0925, 0.1076, 0.1193,
        0.1136, 0.1223], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,452][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0063, 0.0022, 0.0099, 0.0132, 0.0695, 0.0101, 0.0125, 0.2606, 0.1478,
        0.1730, 0.2949], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,454][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0159, 0.0290, 0.1156, 0.0459, 0.0639, 0.0447, 0.2655, 0.0828, 0.0559,
        0.1667, 0.1141], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,455][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0469, 0.0421, 0.0815, 0.0688, 0.0956, 0.1466, 0.0288, 0.1293, 0.1526,
        0.0714, 0.1363], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,455][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0909, 0.0910, 0.0910, 0.0909, 0.0909, 0.0907, 0.0908, 0.0908, 0.0910,
        0.0909, 0.0911], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,456][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0908, 0.0912, 0.0909, 0.0909, 0.0905, 0.0912, 0.0910, 0.0910, 0.0905,
        0.0912, 0.0908], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,456][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0283, 0.1191, 0.0785, 0.1104, 0.1196, 0.0738, 0.1178, 0.0862, 0.0737,
        0.1201, 0.0727], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,457][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0083, 0.0078, 0.0071, 0.0270, 0.0270, 0.1021, 0.1034, 0.1216, 0.1512,
        0.2548, 0.1898], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,457][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.1530, 0.0397, 0.0694, 0.0343, 0.0863, 0.1412, 0.0553, 0.0822, 0.1050,
        0.0896, 0.1258, 0.0183], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,457][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.0166, 0.0589, 0.0726, 0.0471, 0.0956, 0.1670, 0.0666, 0.1173, 0.1448,
        0.0651, 0.1074, 0.0412], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,458][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.1327, 0.0657, 0.0779, 0.0842, 0.0844, 0.0720, 0.0782, 0.0730, 0.0736,
        0.0890, 0.0940, 0.0752], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,459][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.1195, 0.0669, 0.0842, 0.0917, 0.0907, 0.0795, 0.0774, 0.0814, 0.0773,
        0.0725, 0.0896, 0.0694], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,461][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.0365, 0.0564, 0.0662, 0.0711, 0.0775, 0.0928, 0.0816, 0.0990, 0.1129,
        0.0994, 0.1136, 0.0928], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,462][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.0247, 0.0121, 0.0168, 0.0397, 0.1931, 0.0218, 0.0207, 0.3671, 0.0758,
        0.1221, 0.0995, 0.0067], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,463][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.0333, 0.0280, 0.1177, 0.0422, 0.0624, 0.0574, 0.1732, 0.0958, 0.0693,
        0.1372, 0.1315, 0.0519], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,465][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.0474, 0.0371, 0.0567, 0.1106, 0.1061, 0.1193, 0.0306, 0.1037, 0.1344,
        0.0752, 0.1238, 0.0550], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,466][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.0834, 0.0834, 0.0834, 0.0834, 0.0834, 0.0832, 0.0833, 0.0832, 0.0834,
        0.0833, 0.0835, 0.0832], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,467][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.0832, 0.0836, 0.0833, 0.0833, 0.0829, 0.0836, 0.0834, 0.0834, 0.0829,
        0.0836, 0.0832, 0.0836], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,469][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.0278, 0.1058, 0.0743, 0.0988, 0.1051, 0.0696, 0.1008, 0.0779, 0.0690,
        0.1040, 0.0679, 0.0990], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,470][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.0069, 0.0066, 0.0071, 0.0259, 0.0254, 0.0957, 0.0933, 0.1062, 0.1280,
        0.2286, 0.1660, 0.1103], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,472][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.1115, 0.0396, 0.0582, 0.0349, 0.0772, 0.1274, 0.0645, 0.0755, 0.1011,
        0.0986, 0.1293, 0.0230, 0.0592], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,473][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0163, 0.0561, 0.0650, 0.0465, 0.0848, 0.1485, 0.0653, 0.1068, 0.1303,
        0.0634, 0.1014, 0.0432, 0.0724], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,475][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.1210, 0.0616, 0.0681, 0.0790, 0.0762, 0.0648, 0.0728, 0.0664, 0.0663,
        0.0825, 0.0837, 0.0700, 0.0877], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,476][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.1073, 0.0636, 0.0743, 0.0852, 0.0818, 0.0720, 0.0747, 0.0739, 0.0710,
        0.0703, 0.0808, 0.0656, 0.0797], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,478][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0330, 0.0510, 0.0602, 0.0656, 0.0715, 0.0842, 0.0753, 0.0905, 0.1014,
        0.0931, 0.1032, 0.0844, 0.0868], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,479][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.0026, 0.0016, 0.0117, 0.0151, 0.1133, 0.0185, 0.0080, 0.2657, 0.1352,
        0.0783, 0.1719, 0.0050, 0.1730], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,481][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0246, 0.0229, 0.0975, 0.0386, 0.0585, 0.0437, 0.1701, 0.0806, 0.0576,
        0.1336, 0.1095, 0.0518, 0.1110], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,481][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0546, 0.0395, 0.0582, 0.0882, 0.0967, 0.1076, 0.0252, 0.0908, 0.1039,
        0.0720, 0.1021, 0.0635, 0.0979], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,482][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0769, 0.0770, 0.0770, 0.0769, 0.0769, 0.0768, 0.0769, 0.0768, 0.0770,
        0.0769, 0.0771, 0.0768, 0.0770], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,482][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0768, 0.0771, 0.0769, 0.0769, 0.0765, 0.0771, 0.0770, 0.0770, 0.0765,
        0.0772, 0.0768, 0.0772, 0.0770], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,483][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0231, 0.0997, 0.0650, 0.0895, 0.0957, 0.0598, 0.0938, 0.0699, 0.0610,
        0.0971, 0.0591, 0.0947, 0.0918], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,483][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0048, 0.0047, 0.0087, 0.0262, 0.0350, 0.1106, 0.0894, 0.0957, 0.0920,
        0.1390, 0.0965, 0.0739, 0.2236], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,484][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0880, 0.0409, 0.0511, 0.0386, 0.0736, 0.1058, 0.0683, 0.0689, 0.0886,
        0.0979, 0.1067, 0.0290, 0.0616, 0.0812], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,484][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0190, 0.0550, 0.0620, 0.0447, 0.0783, 0.1240, 0.0625, 0.0910, 0.1068,
        0.0591, 0.0857, 0.0424, 0.0666, 0.1031], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,485][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1052, 0.0579, 0.0620, 0.0748, 0.0726, 0.0618, 0.0666, 0.0618, 0.0633,
        0.0772, 0.0779, 0.0679, 0.0830, 0.0681], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,486][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0965, 0.0615, 0.0672, 0.0819, 0.0768, 0.0654, 0.0704, 0.0695, 0.0645,
        0.0669, 0.0736, 0.0650, 0.0748, 0.0659], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,488][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0309, 0.0466, 0.0548, 0.0605, 0.0662, 0.0754, 0.0698, 0.0805, 0.0888,
        0.0863, 0.0912, 0.0768, 0.0794, 0.0928], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,489][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0399, 0.0695, 0.0279, 0.0208, 0.0848, 0.0137, 0.0184, 0.1477, 0.0556,
        0.0991, 0.1132, 0.0238, 0.1124, 0.1733], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,491][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0130, 0.0230, 0.0762, 0.0330, 0.0483, 0.0310, 0.1940, 0.0567, 0.0380,
        0.1263, 0.0749, 0.0489, 0.0928, 0.1438], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,492][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0282, 0.0275, 0.0564, 0.0589, 0.0743, 0.1018, 0.0236, 0.1042, 0.1196,
        0.0640, 0.0985, 0.0572, 0.0878, 0.0981], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,494][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0715, 0.0715, 0.0715, 0.0715, 0.0714, 0.0713, 0.0714, 0.0713, 0.0715,
        0.0714, 0.0716, 0.0713, 0.0715, 0.0714], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,495][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0713, 0.0716, 0.0714, 0.0714, 0.0711, 0.0716, 0.0715, 0.0715, 0.0711,
        0.0717, 0.0713, 0.0717, 0.0715, 0.0714], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,497][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0221, 0.0914, 0.0593, 0.0862, 0.0898, 0.0569, 0.0891, 0.0662, 0.0562,
        0.0917, 0.0559, 0.0896, 0.0890, 0.0565], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,498][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0043, 0.0042, 0.0064, 0.0231, 0.0270, 0.0867, 0.0800, 0.0830, 0.0836,
        0.1291, 0.0852, 0.0581, 0.1144, 0.2150], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,499][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0932, 0.0349, 0.0500, 0.0316, 0.0649, 0.1064, 0.0612, 0.0644, 0.0850,
        0.0897, 0.1114, 0.0217, 0.0524, 0.0756, 0.0578], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,501][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0157, 0.0486, 0.0564, 0.0387, 0.0696, 0.1216, 0.0547, 0.0878, 0.1061,
        0.0523, 0.0832, 0.0367, 0.0596, 0.1013, 0.0676], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,503][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.1025, 0.0536, 0.0598, 0.0669, 0.0663, 0.0561, 0.0612, 0.0577, 0.0578,
        0.0705, 0.0735, 0.0612, 0.0782, 0.0627, 0.0720], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,504][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0948, 0.0542, 0.0645, 0.0753, 0.0714, 0.0612, 0.0633, 0.0652, 0.0607,
        0.0600, 0.0703, 0.0569, 0.0693, 0.0620, 0.0709], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,506][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0278, 0.0423, 0.0502, 0.0544, 0.0595, 0.0703, 0.0626, 0.0754, 0.0845,
        0.0771, 0.0856, 0.0697, 0.0719, 0.0877, 0.0810], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,507][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0025, 0.0015, 0.0080, 0.0108, 0.0512, 0.0090, 0.0094, 0.1632, 0.0821,
        0.0956, 0.1462, 0.0043, 0.1421, 0.0095, 0.2647], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,508][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0139, 0.0186, 0.0777, 0.0302, 0.0449, 0.0307, 0.1388, 0.0593, 0.0384,
        0.1111, 0.0752, 0.0398, 0.0919, 0.1563, 0.0731], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,508][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0466, 0.0339, 0.0486, 0.0793, 0.0848, 0.0909, 0.0233, 0.0784, 0.0897,
        0.0634, 0.0858, 0.0533, 0.0852, 0.0738, 0.0629], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,509][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0667, 0.0667, 0.0667, 0.0667, 0.0667, 0.0665, 0.0666, 0.0666, 0.0667,
        0.0667, 0.0668, 0.0665, 0.0667, 0.0667, 0.0667], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,509][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0666, 0.0669, 0.0666, 0.0666, 0.0663, 0.0669, 0.0667, 0.0667, 0.0663,
        0.0669, 0.0666, 0.0669, 0.0668, 0.0666, 0.0667], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,510][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0206, 0.0837, 0.0550, 0.0801, 0.0846, 0.0521, 0.0820, 0.0606, 0.0524,
        0.0844, 0.0518, 0.0821, 0.0827, 0.0511, 0.0769], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,510][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0028, 0.0026, 0.0024, 0.0093, 0.0117, 0.0344, 0.0347, 0.0328, 0.0343,
        0.0506, 0.0320, 0.0200, 0.0232, 0.0621, 0.6471], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,511][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.0803, 0.0349, 0.0452, 0.0322, 0.0641, 0.0953, 0.0580, 0.0601, 0.0776,
        0.0831, 0.0957, 0.0223, 0.0513, 0.0692, 0.0574, 0.0732],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,512][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.0155, 0.0469, 0.0522, 0.0381, 0.0665, 0.1077, 0.0526, 0.0797, 0.0937,
        0.0497, 0.0745, 0.0358, 0.0570, 0.0912, 0.0640, 0.0749],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,513][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.0928, 0.0504, 0.0553, 0.0647, 0.0619, 0.0540, 0.0583, 0.0541, 0.0558,
        0.0668, 0.0687, 0.0582, 0.0725, 0.0581, 0.0677, 0.0606],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,515][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([0.0841, 0.0530, 0.0588, 0.0721, 0.0662, 0.0576, 0.0615, 0.0592, 0.0572,
        0.0590, 0.0648, 0.0569, 0.0656, 0.0565, 0.0660, 0.0613],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,516][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.0258, 0.0391, 0.0464, 0.0510, 0.0557, 0.0647, 0.0590, 0.0693, 0.0771,
        0.0725, 0.0788, 0.0655, 0.0672, 0.0800, 0.0752, 0.0729],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,518][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.0024, 0.0020, 0.0057, 0.0218, 0.0722, 0.0136, 0.0107, 0.1159, 0.0819,
        0.0876, 0.0978, 0.0047, 0.1136, 0.0073, 0.2913, 0.0714],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,519][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.0080, 0.0170, 0.0733, 0.0275, 0.0411, 0.0272, 0.1633, 0.0499, 0.0321,
        0.1059, 0.0683, 0.0419, 0.0838, 0.1452, 0.0609, 0.0546],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,521][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.0305, 0.0248, 0.0493, 0.0472, 0.0647, 0.0859, 0.0176, 0.0859, 0.0926,
        0.0567, 0.0835, 0.0551, 0.0751, 0.1022, 0.0592, 0.0699],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,522][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.0625, 0.0626, 0.0626, 0.0625, 0.0625, 0.0624, 0.0625, 0.0624, 0.0626,
        0.0625, 0.0626, 0.0624, 0.0626, 0.0625, 0.0625, 0.0624],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,524][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.0624, 0.0627, 0.0625, 0.0625, 0.0622, 0.0627, 0.0625, 0.0625, 0.0622,
        0.0627, 0.0624, 0.0627, 0.0626, 0.0625, 0.0625, 0.0625],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,525][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.0213, 0.0786, 0.0521, 0.0747, 0.0767, 0.0502, 0.0783, 0.0563, 0.0503,
        0.0789, 0.0492, 0.0777, 0.0764, 0.0484, 0.0718, 0.0591],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,527][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.0012, 0.0011, 0.0011, 0.0042, 0.0059, 0.0169, 0.0185, 0.0141, 0.0149,
        0.0245, 0.0147, 0.0091, 0.0110, 0.0305, 0.3963, 0.4359],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,528][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0719, 0.0336, 0.0415, 0.0315, 0.0590, 0.0854, 0.0569, 0.0554, 0.0713,
        0.0796, 0.0871, 0.0234, 0.0494, 0.0654, 0.0542, 0.0684, 0.0659],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,530][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0173, 0.0451, 0.0501, 0.0370, 0.0625, 0.0955, 0.0506, 0.0708, 0.0818,
        0.0475, 0.0673, 0.0352, 0.0526, 0.0794, 0.0579, 0.0679, 0.0815],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,531][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0846, 0.0481, 0.0509, 0.0619, 0.0600, 0.0512, 0.0554, 0.0509, 0.0523,
        0.0638, 0.0639, 0.0565, 0.0684, 0.0560, 0.0645, 0.0568, 0.0550],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,533][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0791, 0.0509, 0.0550, 0.0683, 0.0633, 0.0541, 0.0587, 0.0575, 0.0534,
        0.0558, 0.0608, 0.0544, 0.0620, 0.0547, 0.0628, 0.0569, 0.0523],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,534][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0251, 0.0373, 0.0437, 0.0483, 0.0527, 0.0598, 0.0558, 0.0639, 0.0703,
        0.0688, 0.0721, 0.0613, 0.0630, 0.0735, 0.0700, 0.0675, 0.0671],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,534][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0684, 0.1112, 0.0204, 0.0159, 0.0539, 0.0098, 0.0127, 0.0695, 0.0232,
        0.0602, 0.0420, 0.0174, 0.0632, 0.1687, 0.0814, 0.0305, 0.1514],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,534][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0082, 0.0171, 0.0522, 0.0244, 0.0361, 0.0213, 0.1338, 0.0387, 0.0249,
        0.0919, 0.0485, 0.0360, 0.0690, 0.0944, 0.0524, 0.0436, 0.2074],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,535][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0198, 0.0201, 0.0427, 0.0479, 0.0574, 0.0797, 0.0199, 0.0851, 0.0993,
        0.0534, 0.0821, 0.0438, 0.0700, 0.0742, 0.0558, 0.0643, 0.0844],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,535][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0589, 0.0589, 0.0589, 0.0589, 0.0588, 0.0587, 0.0588, 0.0588, 0.0589,
        0.0588, 0.0590, 0.0587, 0.0589, 0.0588, 0.0588, 0.0588, 0.0588],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,536][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0587, 0.0590, 0.0588, 0.0588, 0.0585, 0.0590, 0.0589, 0.0589, 0.0585,
        0.0590, 0.0587, 0.0590, 0.0589, 0.0588, 0.0589, 0.0588, 0.0588],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,536][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0188, 0.0754, 0.0488, 0.0717, 0.0739, 0.0471, 0.0741, 0.0547, 0.0467,
        0.0761, 0.0464, 0.0746, 0.0739, 0.0470, 0.0695, 0.0561, 0.0452],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,537][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0011, 0.0011, 0.0011, 0.0039, 0.0052, 0.0143, 0.0159, 0.0134, 0.0146,
        0.0232, 0.0145, 0.0091, 0.0104, 0.0302, 0.2882, 0.2905, 0.2634],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,539][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:25,540][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 9951],
        [10844],
        [19964],
        [  132],
        [15706],
        [ 9825],
        [12678],
        [ 8171],
        [17167],
        [20979],
        [10563],
        [11066],
        [21730],
        [13233],
        [ 8963],
        [20991],
        [10305]], device='cuda:0')
[2024-07-24 10:31:25,542][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 6120],
        [ 4686],
        [10416],
        [    2],
        [16759],
        [16100],
        [21859],
        [12036],
        [26928],
        [17403],
        [ 7024],
        [ 5692],
        [18479],
        [ 6987],
        [ 5897],
        [33234],
        [ 7807]], device='cuda:0')
[2024-07-24 10:31:25,543][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[17943],
        [16233],
        [22901],
        [23594],
        [22566],
        [26504],
        [27428],
        [25927],
        [27434],
        [28007],
        [28767],
        [29149],
        [29181],
        [30152],
        [30747],
        [30614],
        [30855]], device='cuda:0')
[2024-07-24 10:31:25,545][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[31919],
        [44789],
        [28653],
        [26572],
        [28567],
        [14469],
        [12918],
        [17860],
        [18280],
        [20059],
        [18531],
        [16040],
        [16898],
        [18785],
        [18722],
        [17755],
        [18045]], device='cuda:0')
[2024-07-24 10:31:25,546][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[31324],
        [32817],
        [36983],
        [40507],
        [40536],
        [42645],
        [40885],
        [39125],
        [39438],
        [37645],
        [36320],
        [36458],
        [35325],
        [35646],
        [35036],
        [35216],
        [35279]], device='cuda:0')
[2024-07-24 10:31:25,548][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[25392],
        [20209],
        [22652],
        [23826],
        [23352],
        [21485],
        [20391],
        [20186],
        [19107],
        [18076],
        [18564],
        [19107],
        [19038],
        [19961],
        [20971],
        [20652],
        [21530]], device='cuda:0')
[2024-07-24 10:31:25,549][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[31153],
        [34246],
        [32859],
        [28728],
        [28684],
        [29625],
        [29514],
        [29412],
        [29879],
        [29272],
        [29687],
        [29919],
        [29196],
        [29262],
        [29185],
        [29399],
        [29384]], device='cuda:0')
[2024-07-24 10:31:25,551][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[25029],
        [25032],
        [27835],
        [26106],
        [27769],
        [30276],
        [28539],
        [32333],
        [32600],
        [32171],
        [32951],
        [31777],
        [32746],
        [34275],
        [34305],
        [34157],
        [34712]], device='cuda:0')
[2024-07-24 10:31:25,552][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[16868],
        [16777],
        [17057],
        [20284],
        [27703],
        [ 2974],
        [10850],
        [ 4630],
        [ 8159],
        [29264],
        [11197],
        [17683],
        [11493],
        [ 8957],
        [12281],
        [10458],
        [ 2532]], device='cuda:0')
[2024-07-24 10:31:25,554][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[40426],
        [35008],
        [29959],
        [12970],
        [  753],
        [ 5810],
        [ 3343],
        [14789],
        [18371],
        [ 8411],
        [28060],
        [27416],
        [37342],
        [29286],
        [19417],
        [11993],
        [26931]], device='cuda:0')
[2024-07-24 10:31:25,555][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 2496],
        [ 2749],
        [ 4178],
        [ 7692],
        [ 7217],
        [ 9981],
        [ 8547],
        [15588],
        [14049],
        [14975],
        [10746],
        [10627],
        [11790],
        [13833],
        [ 9150],
        [14575],
        [15813]], device='cuda:0')
[2024-07-24 10:31:25,557][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[10697],
        [10634],
        [ 4561],
        [ 5115],
        [ 7391],
        [ 6031],
        [ 6549],
        [ 7273],
        [ 6664],
        [ 6879],
        [ 9001],
        [ 7354],
        [13525],
        [14001],
        [10608],
        [10725],
        [11605]], device='cuda:0')
[2024-07-24 10:31:25,558][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[4822],
        [2084],
        [2301],
        [1727],
        [1609],
        [1424],
        [1365],
        [1227],
        [1386],
        [1341],
        [1471],
        [1472],
        [1353],
        [1476],
        [1475],
        [1581],
        [1712]], device='cuda:0')
[2024-07-24 10:31:25,560][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[34972],
        [46370],
        [39758],
        [40912],
        [39188],
        [36613],
        [45773],
        [29844],
        [29991],
        [44482],
        [30033],
        [47263],
        [43166],
        [30565],
        [37619],
        [29346],
        [34355]], device='cuda:0')
[2024-07-24 10:31:25,561][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[10459],
        [ 7433],
        [15860],
        [10667],
        [13891],
        [14703],
        [ 2832],
        [13490],
        [18802],
        [27016],
        [13587],
        [ 7548],
        [19634],
        [17486],
        [13589],
        [11916],
        [18338]], device='cuda:0')
[2024-07-24 10:31:25,562][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[10637],
        [10497],
        [10329],
        [10145],
        [ 9932],
        [10293],
        [10367],
        [10576],
        [10936],
        [10884],
        [11102],
        [10936],
        [11234],
        [11436],
        [11615],
        [11780],
        [11898]], device='cuda:0')
[2024-07-24 10:31:25,564][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[4592],
        [3479],
        [3759],
        [3570],
        [3693],
        [3885],
        [3597],
        [3556],
        [3636],
        [3546],
        [3436],
        [3398],
        [3246],
        [3190],
        [3199],
        [3236],
        [3266]], device='cuda:0')
[2024-07-24 10:31:25,566][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[20630],
        [21736],
        [21783],
        [22608],
        [23436],
        [23358],
        [23513],
        [23838],
        [23391],
        [23352],
        [23123],
        [22964],
        [23109],
        [22891],
        [22628],
        [22422],
        [22270]], device='cuda:0')
[2024-07-24 10:31:25,567][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[10498],
        [10407],
        [10342],
        [ 9758],
        [ 9660],
        [ 9835],
        [ 9833],
        [ 9889],
        [10021],
        [10075],
        [10025],
        [ 9962],
        [ 9892],
        [ 9887],
        [ 9874],
        [ 9906],
        [ 9919]], device='cuda:0')
[2024-07-24 10:31:25,568][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[20229],
        [17616],
        [17166],
        [17036],
        [16600],
        [16580],
        [16418],
        [16259],
        [16219],
        [16198],
        [16370],
        [16434],
        [16458],
        [16518],
        [16483],
        [16514],
        [16503]], device='cuda:0')
[2024-07-24 10:31:25,569][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[13751],
        [10751],
        [ 6097],
        [ 1377],
        [  939],
        [  928],
        [  866],
        [ 1328],
        [ 1384],
        [ 1625],
        [ 1897],
        [ 1370],
        [ 1469],
        [ 1244],
        [ 1672],
        [ 1550],
        [ 1306]], device='cuda:0')
[2024-07-24 10:31:25,570][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[12232],
        [11513],
        [ 9941],
        [10341],
        [ 9649],
        [ 9687],
        [10155],
        [10641],
        [10934],
        [11232],
        [11932],
        [11914],
        [12195],
        [12465],
        [12575],
        [12769],
        [13042]], device='cuda:0')
[2024-07-24 10:31:25,572][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[33499],
        [32948],
        [32724],
        [35618],
        [35248],
        [36388],
        [36489],
        [37518],
        [38952],
        [39197],
        [40444],
        [40110],
        [39667],
        [39371],
        [39146],
        [39048],
        [38482]], device='cuda:0')
[2024-07-24 10:31:25,573][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[12274],
        [12262],
        [12269],
        [12270],
        [12269],
        [12271],
        [12274],
        [12276],
        [12276],
        [12273],
        [12274],
        [12274],
        [12274],
        [12272],
        [12272],
        [12270],
        [12271]], device='cuda:0')
[2024-07-24 10:31:25,575][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[10827],
        [10835],
        [10830],
        [10833],
        [10831],
        [10830],
        [10834],
        [10833],
        [10832],
        [10834],
        [10834],
        [10836],
        [10833],
        [10832],
        [10833],
        [10829],
        [10829]], device='cuda:0')
[2024-07-24 10:31:25,576][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[9536],
        [8418],
        [7968],
        [7946],
        [8012],
        [8096],
        [8160],
        [8145],
        [8073],
        [8277],
        [8193],
        [8321],
        [8467],
        [8373],
        [8453],
        [8393],
        [8297]], device='cuda:0')
[2024-07-24 10:31:25,578][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[10072],
        [10112],
        [11553],
        [12162],
        [12498],
        [14502],
        [15494],
        [14237],
        [13293],
        [13110],
        [12914],
        [12868],
        [13854],
        [14300],
        [20746],
        [23319],
        [23110]], device='cuda:0')
[2024-07-24 10:31:25,579][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[33356],
        [35367],
        [38021],
        [41278],
        [41459],
        [40749],
        [40542],
        [38289],
        [37487],
        [37724],
        [36422],
        [37747],
        [37615],
        [38096],
        [36341],
        [36278],
        [37505]], device='cuda:0')
[2024-07-24 10:31:25,581][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 3710],
        [20396],
        [20537],
        [28724],
        [29712],
        [25280],
        [45380],
        [29844],
        [22708],
        [16697],
        [31983],
        [37757],
        [24991],
        [26778],
        [30881],
        [34795],
        [23457]], device='cuda:0')
[2024-07-24 10:31:25,582][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[15705],
        [15705],
        [15705],
        [15705],
        [15705],
        [15705],
        [15705],
        [15705],
        [15705],
        [15705],
        [15705],
        [15705],
        [15705],
        [15705],
        [15705],
        [15705],
        [15705]], device='cuda:0')
[2024-07-24 10:31:25,622][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:25,623][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,623][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,623][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,624][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,624][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,624][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,625][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,625][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,625][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,626][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,627][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,628][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,629][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.2501, 0.7499], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,631][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.9815, 0.0185], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,632][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,633][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.3037, 0.6963], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,635][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.0280, 0.9720], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,636][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.7236, 0.2764], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,637][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.2275, 0.7725], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,639][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.5522, 0.4478], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,640][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.7857, 0.2143], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,642][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.3571, 0.6429], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,643][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.1474, 0.8526], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,644][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.4178, 0.5822], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,646][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1872, 0.4786, 0.3342], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,647][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.7675, 0.0190, 0.2136], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,648][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([4.5629e-05, 3.2442e-01, 6.7554e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,649][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1220, 0.2626, 0.6155], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,649][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0043, 0.6419, 0.3537], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,649][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.5687, 0.2000, 0.2314], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,650][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3024, 0.5019, 0.1957], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,650][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3837, 0.3586, 0.2577], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,650][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.4067, 0.2671, 0.3262], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,651][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1071, 0.6303, 0.2627], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,651][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0862, 0.4184, 0.4954], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,651][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3174, 0.3579, 0.3247], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,652][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Nathan] are: tensor([0.0965, 0.2610, 0.1812, 0.4613], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,653][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Nathan] are: tensor([0.3335, 0.0240, 0.2766, 0.3659], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,654][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Nathan] are: tensor([2.6049e-06, 3.8359e-03, 9.3065e-02, 9.0310e-01], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,655][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Nathan] are: tensor([0.0540, 0.1106, 0.3959, 0.4395], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,656][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Nathan] are: tensor([0.0007, 0.0714, 0.3348, 0.5931], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,658][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Nathan] are: tensor([0.4524, 0.1737, 0.2014, 0.1724], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,659][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Nathan] are: tensor([0.1033, 0.3595, 0.1273, 0.4099], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,660][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Nathan] are: tensor([0.2967, 0.2672, 0.2109, 0.2252], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,662][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Nathan] are: tensor([0.3255, 0.1540, 0.3549, 0.1657], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,663][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Nathan] are: tensor([0.0631, 0.4573, 0.2832, 0.1965], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,665][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Nathan] are: tensor([0.0474, 0.2741, 0.3321, 0.3463], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,666][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Nathan] are: tensor([0.1852, 0.2878, 0.2033, 0.3236], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,668][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.0679, 0.1713, 0.1188, 0.3309, 0.3111], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,669][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.3676, 0.0274, 0.2054, 0.2613, 0.1383], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,670][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ got] are: tensor([1.9797e-07, 2.4141e-04, 1.2507e-02, 8.4347e-01, 1.4378e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,671][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.0334, 0.0751, 0.1946, 0.2847, 0.4123], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,672][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ got] are: tensor([2.3795e-04, 1.0447e-02, 1.0654e-01, 2.4381e-01, 6.3896e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,674][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.3782, 0.1421, 0.1646, 0.1405, 0.1746], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,675][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.0930, 0.2204, 0.0739, 0.2978, 0.3150], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,675][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.2565, 0.2174, 0.1814, 0.2039, 0.1407], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,675][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.2555, 0.1217, 0.2550, 0.1568, 0.2110], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,676][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.0391, 0.3285, 0.1692, 0.3207, 0.1424], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,676][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.0356, 0.1804, 0.2190, 0.2215, 0.3435], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,676][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.1289, 0.2417, 0.1821, 0.3245, 0.1228], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,677][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0406, 0.1267, 0.0902, 0.2473, 0.2355, 0.2598], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,677][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.3556, 0.0160, 0.1532, 0.1689, 0.0425, 0.2639], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,678][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([9.8109e-08, 9.4783e-05, 5.4096e-03, 2.0370e-01, 4.8086e-01, 3.0993e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,679][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0271, 0.0516, 0.1259, 0.1691, 0.2840, 0.3423], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,680][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([5.6799e-05, 6.8201e-03, 1.7258e-02, 1.8912e-01, 6.1120e-01, 1.7555e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,681][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.3391, 0.1139, 0.1341, 0.1141, 0.1440, 0.1548], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,683][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1031, 0.1756, 0.0911, 0.2536, 0.3003, 0.0763], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,684][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2016, 0.1948, 0.1472, 0.1767, 0.1246, 0.1550], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,685][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1712, 0.1244, 0.1731, 0.1314, 0.2416, 0.1584], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,687][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0443, 0.2059, 0.1499, 0.2692, 0.2043, 0.1265], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,688][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0283, 0.1361, 0.1648, 0.1667, 0.2569, 0.2473], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,690][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1356, 0.1533, 0.1963, 0.2814, 0.1454, 0.0881], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,691][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.0212, 0.0692, 0.0538, 0.1535, 0.1569, 0.1749, 0.3705],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,692][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.1781, 0.0122, 0.1342, 0.1793, 0.0574, 0.3144, 0.1245],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,693][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([1.2677e-08, 1.3348e-05, 8.8181e-04, 9.7389e-03, 4.7800e-02, 3.8624e-01,
        5.5532e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,695][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0059, 0.0137, 0.0570, 0.0662, 0.1549, 0.2052, 0.4970],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,696][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([2.8347e-05, 1.5759e-03, 1.5326e-02, 7.3228e-02, 1.0336e-01, 2.9444e-01,
        5.1204e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,697][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.2882, 0.1015, 0.1194, 0.1012, 0.1280, 0.1364, 0.1253],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,699][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.0663, 0.1935, 0.0557, 0.2480, 0.2727, 0.0535, 0.1102],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,700][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.1929, 0.1637, 0.1381, 0.1434, 0.1101, 0.1349, 0.1170],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,701][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.1561, 0.0610, 0.1668, 0.1217, 0.2187, 0.1710, 0.1046],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,701][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0309, 0.1861, 0.1010, 0.1903, 0.2152, 0.1641, 0.1123],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,701][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0174, 0.1057, 0.1288, 0.1296, 0.2111, 0.1989, 0.2085],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,702][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0697, 0.2223, 0.0640, 0.2911, 0.1149, 0.0503, 0.1877],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,702][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0212, 0.0623, 0.0507, 0.1368, 0.1280, 0.1511, 0.3236, 0.1262],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,703][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.3055, 0.0101, 0.1363, 0.1453, 0.0532, 0.2573, 0.0574, 0.0349],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,703][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ at] are: tensor([1.0132e-08, 9.9693e-07, 4.7863e-05, 1.1702e-03, 3.5412e-03, 3.2946e-02,
        1.8312e-01, 7.7917e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,703][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0121, 0.0225, 0.0536, 0.0716, 0.1169, 0.1490, 0.3926, 0.1817],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,704][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ at] are: tensor([1.7422e-05, 9.8576e-04, 2.2033e-03, 4.6650e-03, 9.8172e-02, 5.5014e-02,
        5.4735e-01, 2.9159e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,705][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.2532, 0.0904, 0.1057, 0.0899, 0.1129, 0.1203, 0.1114, 0.1162],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,706][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0950, 0.1490, 0.0681, 0.2042, 0.2675, 0.0584, 0.1137, 0.0441],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,708][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.1658, 0.1542, 0.1110, 0.1351, 0.0997, 0.1209, 0.1108, 0.1024],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,709][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.1222, 0.0661, 0.1215, 0.0730, 0.2005, 0.1779, 0.1010, 0.1378],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,711][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0257, 0.1213, 0.0990, 0.1912, 0.1718, 0.1552, 0.1750, 0.0609],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,712][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0199, 0.0930, 0.1124, 0.1120, 0.1715, 0.1653, 0.1716, 0.1544],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,713][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0969, 0.1289, 0.1358, 0.1980, 0.0977, 0.0729, 0.1346, 0.1353],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,715][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0154, 0.0505, 0.0411, 0.1126, 0.1052, 0.1150, 0.3139, 0.0973, 0.1491],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,716][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.2109, 0.0117, 0.1161, 0.1499, 0.0470, 0.1865, 0.0866, 0.0306, 0.1607],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,717][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ the] are: tensor([3.5749e-10, 4.9373e-08, 2.1567e-06, 9.2942e-05, 1.6334e-04, 4.4236e-04,
        9.8106e-03, 8.1490e-01, 1.7458e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,718][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0062, 0.0126, 0.0373, 0.0509, 0.0885, 0.1133, 0.2985, 0.1596, 0.2332],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,719][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ the] are: tensor([9.7994e-06, 8.0463e-04, 9.6575e-04, 1.8486e-02, 2.1057e-02, 1.3430e-02,
        3.0132e-01, 3.0969e-01, 3.3423e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,721][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.2445, 0.0757, 0.0899, 0.0759, 0.0964, 0.1038, 0.0949, 0.1011, 0.1178],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,722][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0934, 0.1341, 0.0711, 0.1695, 0.2513, 0.0551, 0.1271, 0.0544, 0.0440],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,724][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1465, 0.1293, 0.1051, 0.1204, 0.0882, 0.1087, 0.1028, 0.0959, 0.1030],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,725][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0932, 0.0680, 0.1062, 0.0729, 0.1418, 0.1209, 0.1112, 0.1971, 0.0886],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,727][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0337, 0.1197, 0.1022, 0.1492, 0.1513, 0.0830, 0.1885, 0.1148, 0.0576],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,727][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0171, 0.0795, 0.0963, 0.0967, 0.1468, 0.1419, 0.1469, 0.1328, 0.1421],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,728][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0993, 0.0851, 0.1688, 0.1330, 0.1082, 0.0666, 0.1045, 0.1594, 0.0750],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,728][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([0.0148, 0.0395, 0.0370, 0.0910, 0.0880, 0.0987, 0.2148, 0.0962, 0.1272,
        0.1927], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,729][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([0.2696, 0.0105, 0.1145, 0.0925, 0.0395, 0.1484, 0.0440, 0.0475, 0.2061,
        0.0273], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,729][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([1.5082e-10, 3.2534e-08, 5.1338e-07, 6.6753e-05, 4.0319e-05, 2.2715e-04,
        3.5319e-03, 8.4473e-02, 2.0544e-01, 7.0622e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,729][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([0.0042, 0.0073, 0.0265, 0.0273, 0.0611, 0.0785, 0.1723, 0.1279, 0.1942,
        0.3008], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,730][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([3.0629e-06, 8.6418e-05, 2.1297e-04, 6.2012e-03, 3.7980e-03, 6.0244e-03,
        2.3909e-02, 5.8458e-02, 2.4069e-01, 6.6062e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,731][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([0.2044, 0.0739, 0.0853, 0.0727, 0.0905, 0.0954, 0.0899, 0.0933, 0.1058,
        0.0887], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,732][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.0512, 0.1426, 0.0418, 0.2249, 0.2403, 0.0454, 0.1034, 0.0415, 0.0340,
        0.0750], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,734][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([0.1446, 0.1231, 0.0992, 0.1078, 0.0805, 0.0971, 0.0893, 0.0872, 0.0909,
        0.0804], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,735][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.1109, 0.0390, 0.0961, 0.0546, 0.1002, 0.1264, 0.0953, 0.1890, 0.1108,
        0.0777], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,736][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([0.0168, 0.1523, 0.0756, 0.1503, 0.1122, 0.1115, 0.1354, 0.0790, 0.0802,
        0.0867], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,738][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([0.0127, 0.0685, 0.0823, 0.0835, 0.1290, 0.1207, 0.1251, 0.1157, 0.1197,
        0.1426], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,739][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([0.0793, 0.1251, 0.0749, 0.2016, 0.0935, 0.0453, 0.1344, 0.0723, 0.0631,
        0.1105], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,741][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0123, 0.0385, 0.0336, 0.0854, 0.0803, 0.0794, 0.2131, 0.0748, 0.1017,
        0.1765, 0.1044], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,742][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1751, 0.0068, 0.0668, 0.1167, 0.0316, 0.1962, 0.0479, 0.0316, 0.2111,
        0.0238, 0.0925], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,743][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([2.8410e-11, 2.9059e-09, 6.8141e-08, 2.6693e-06, 3.9352e-06, 2.4482e-05,
        4.9609e-04, 3.5687e-03, 2.8825e-02, 6.2260e-01, 3.4448e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,744][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0039, 0.0073, 0.0216, 0.0269, 0.0491, 0.0627, 0.1476, 0.0890, 0.1307,
        0.2543, 0.2069], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,745][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([2.4385e-06, 1.5432e-04, 1.7558e-04, 1.7412e-03, 2.0979e-03, 4.2465e-03,
        2.8346e-02, 1.9421e-02, 1.1539e-01, 5.2883e-01, 2.9959e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,747][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2105, 0.0611, 0.0728, 0.0612, 0.0781, 0.0840, 0.0768, 0.0817, 0.0953,
        0.0793, 0.0993], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,748][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0766, 0.1082, 0.0550, 0.1752, 0.1926, 0.0495, 0.1021, 0.0481, 0.0417,
        0.0710, 0.0799], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,750][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1247, 0.1102, 0.0863, 0.1021, 0.0746, 0.0911, 0.0842, 0.0804, 0.0848,
        0.0795, 0.0822], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,751][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0846, 0.0528, 0.0754, 0.0562, 0.0986, 0.1042, 0.0963, 0.1433, 0.0895,
        0.0948, 0.1043], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,753][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0201, 0.0926, 0.0739, 0.1156, 0.0951, 0.1063, 0.1179, 0.0882, 0.0736,
        0.1550, 0.0618], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,753][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0142, 0.0620, 0.0747, 0.0746, 0.1120, 0.1069, 0.1114, 0.1008, 0.1064,
        0.1233, 0.1139], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,754][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0874, 0.0858, 0.1122, 0.1179, 0.0825, 0.0507, 0.0926, 0.0963, 0.0707,
        0.0989, 0.1052], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,754][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.0124, 0.0276, 0.0255, 0.0627, 0.0663, 0.0687, 0.1379, 0.0687, 0.0905,
        0.1345, 0.0977, 0.2074], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,755][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.1388, 0.0062, 0.1104, 0.0889, 0.0319, 0.1612, 0.0450, 0.0418, 0.1838,
        0.0241, 0.1530, 0.0149], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,755][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([1.2432e-11, 1.7983e-10, 1.6560e-08, 8.2249e-07, 3.9405e-07, 8.5522e-06,
        6.8808e-05, 1.8413e-04, 4.7421e-03, 6.6220e-02, 2.8575e-01, 6.4303e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,756][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.0011, 0.0022, 0.0105, 0.0122, 0.0290, 0.0391, 0.1018, 0.0731, 0.1198,
        0.2113, 0.2144, 0.1857], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,756][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([6.3843e-07, 6.5602e-06, 5.0350e-05, 4.5331e-04, 2.1213e-04, 8.5766e-04,
        2.6959e-02, 8.7679e-03, 2.9256e-02, 2.2912e-01, 2.2491e-01, 4.7940e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,757][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.1793, 0.0597, 0.0699, 0.0593, 0.0743, 0.0786, 0.0737, 0.0768, 0.0874,
        0.0742, 0.0900, 0.0767], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,759][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.0295, 0.1118, 0.0398, 0.1757, 0.1926, 0.0334, 0.0744, 0.0295, 0.0260,
        0.0751, 0.0586, 0.1536], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,760][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.1221, 0.0946, 0.0838, 0.0897, 0.0716, 0.0870, 0.0726, 0.0752, 0.0794,
        0.0686, 0.0850, 0.0706], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,762][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.0817, 0.0212, 0.0865, 0.0617, 0.1048, 0.0964, 0.0601, 0.1414, 0.0970,
        0.0789, 0.1316, 0.0387], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,763][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.0165, 0.0330, 0.0639, 0.1083, 0.1079, 0.0985, 0.1048, 0.0754, 0.0820,
        0.1891, 0.0779, 0.0427], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,764][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.0095, 0.0532, 0.0646, 0.0657, 0.1043, 0.0971, 0.0997, 0.0928, 0.0962,
        0.1156, 0.1027, 0.0986], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,765][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.0593, 0.0829, 0.0607, 0.1328, 0.0928, 0.0463, 0.1283, 0.0446, 0.0577,
        0.1167, 0.0748, 0.1031], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:25,767][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0098, 0.0245, 0.0218, 0.0541, 0.0538, 0.0594, 0.1208, 0.0579, 0.0766,
        0.1241, 0.0789, 0.2115, 0.1068], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,768][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.1504, 0.0114, 0.1209, 0.1638, 0.0657, 0.0841, 0.0471, 0.0342, 0.1063,
        0.0279, 0.0878, 0.0361, 0.0643], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,769][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([6.7205e-12, 2.4423e-11, 2.5132e-09, 5.1634e-08, 2.8622e-07, 7.0379e-07,
        1.4767e-05, 2.6746e-04, 9.4212e-04, 1.8626e-02, 1.0182e-01, 6.2637e-01,
        2.5197e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,771][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0025, 0.0049, 0.0146, 0.0177, 0.0323, 0.0424, 0.1039, 0.0638, 0.0965,
        0.1851, 0.1568, 0.1734, 0.1061], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,772][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([1.9446e-06, 2.8784e-06, 5.1348e-05, 4.2543e-05, 6.7971e-04, 1.0222e-03,
        6.5822e-04, 4.5701e-03, 1.8239e-02, 9.2975e-02, 2.0964e-01, 2.0188e-01,
        4.7024e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,773][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.1639, 0.0548, 0.0647, 0.0544, 0.0683, 0.0728, 0.0673, 0.0703, 0.0812,
        0.0676, 0.0843, 0.0713, 0.0792], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,775][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0534, 0.1003, 0.0293, 0.1280, 0.1602, 0.0291, 0.0696, 0.0275, 0.0286,
        0.0572, 0.0546, 0.1415, 0.1206], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,776][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.1076, 0.0960, 0.0797, 0.0821, 0.0587, 0.0780, 0.0666, 0.0697, 0.0746,
        0.0645, 0.0793, 0.0695, 0.0735], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,778][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0687, 0.0344, 0.0606, 0.0499, 0.0794, 0.0847, 0.0635, 0.1113, 0.0767,
        0.0709, 0.1060, 0.0718, 0.1220], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,779][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0141, 0.0687, 0.0586, 0.0826, 0.0696, 0.0982, 0.0954, 0.0840, 0.0697,
        0.1437, 0.0753, 0.0795, 0.0606], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,780][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0097, 0.0478, 0.0592, 0.0589, 0.0928, 0.0875, 0.0879, 0.0837, 0.0869,
        0.1010, 0.0929, 0.0859, 0.1060], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,780][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0466, 0.1022, 0.0609, 0.1114, 0.0605, 0.0312, 0.0976, 0.0591, 0.0540,
        0.0946, 0.0827, 0.1292, 0.0701], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:25,781][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0073, 0.0196, 0.0180, 0.0527, 0.0538, 0.0581, 0.1413, 0.0476, 0.0726,
        0.0990, 0.0753, 0.1968, 0.1069, 0.0509], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,781][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1668, 0.0027, 0.0516, 0.0603, 0.0157, 0.1547, 0.0303, 0.0131, 0.1505,
        0.0167, 0.0728, 0.0118, 0.0288, 0.2241], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,781][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.7637e-12, 2.0195e-12, 5.6923e-11, 1.8771e-09, 5.3729e-09, 3.2841e-08,
        5.5668e-07, 4.3159e-06, 4.2374e-05, 6.0185e-04, 2.2718e-03, 2.6287e-02,
        4.8181e-02, 9.2261e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,782][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0022, 0.0050, 0.0129, 0.0164, 0.0274, 0.0356, 0.0873, 0.0487, 0.0748,
        0.1554, 0.1194, 0.1519, 0.0880, 0.1749], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,783][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([8.9228e-08, 4.5898e-07, 1.4439e-06, 2.5879e-05, 8.7507e-05, 2.6574e-05,
        5.0830e-04, 2.2317e-04, 6.2114e-04, 4.6755e-03, 6.7860e-03, 3.3176e-02,
        7.1852e-01, 2.3535e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,784][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1726, 0.0472, 0.0561, 0.0472, 0.0599, 0.0643, 0.0590, 0.0627, 0.0731,
        0.0616, 0.0767, 0.0646, 0.0727, 0.0822], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,786][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0650, 0.0837, 0.0542, 0.1130, 0.1237, 0.0460, 0.0631, 0.0359, 0.0361,
        0.0476, 0.0748, 0.1153, 0.1227, 0.0190], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,787][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0972, 0.0851, 0.0704, 0.0781, 0.0627, 0.0720, 0.0670, 0.0664, 0.0699,
        0.0638, 0.0705, 0.0638, 0.0772, 0.0559], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,788][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0500, 0.0348, 0.0615, 0.0559, 0.0879, 0.0695, 0.0699, 0.0848, 0.0621,
        0.0750, 0.0893, 0.0676, 0.1366, 0.0549], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,790][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0151, 0.0737, 0.0482, 0.0980, 0.0715, 0.0760, 0.0972, 0.0431, 0.0532,
        0.1357, 0.0576, 0.0987, 0.1146, 0.0174], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,791][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0109, 0.0467, 0.0558, 0.0554, 0.0831, 0.0799, 0.0837, 0.0746, 0.0792,
        0.0921, 0.0843, 0.0817, 0.0955, 0.0771], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,793][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0545, 0.0537, 0.0916, 0.0845, 0.0598, 0.0421, 0.0614, 0.0943, 0.0676,
        0.0571, 0.1156, 0.0671, 0.0801, 0.0705], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:25,794][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0081, 0.0193, 0.0177, 0.0478, 0.0467, 0.0526, 0.1160, 0.0473, 0.0648,
        0.0986, 0.0650, 0.1712, 0.0979, 0.0557, 0.0913], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,796][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.1295, 0.0089, 0.0916, 0.0765, 0.0497, 0.0962, 0.0496, 0.0223, 0.1194,
        0.0236, 0.0700, 0.0233, 0.0745, 0.1142, 0.0508], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,797][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ give] are: tensor([1.1410e-13, 1.7576e-13, 3.0798e-12, 1.1967e-10, 5.1420e-11, 8.1553e-10,
        3.4032e-08, 2.5700e-07, 1.2396e-06, 5.3657e-05, 1.2502e-04, 2.1958e-03,
        1.9609e-03, 7.9147e-01, 2.0419e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,798][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0023, 0.0046, 0.0123, 0.0144, 0.0250, 0.0328, 0.0765, 0.0439, 0.0667,
        0.1349, 0.1055, 0.1232, 0.0781, 0.1611, 0.1186], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,799][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ give] are: tensor([9.4570e-08, 4.4663e-07, 1.8040e-06, 6.2846e-06, 1.3545e-05, 4.0589e-05,
        2.0623e-04, 2.1268e-04, 1.0200e-03, 6.2514e-03, 9.9882e-03, 4.0671e-02,
        5.2415e-02, 3.9659e-01, 4.9258e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,801][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.1374, 0.0488, 0.0562, 0.0479, 0.0591, 0.0625, 0.0585, 0.0604, 0.0686,
        0.0582, 0.0708, 0.0612, 0.0676, 0.0749, 0.0680], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,802][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0411, 0.0922, 0.0295, 0.1234, 0.1299, 0.0259, 0.0641, 0.0283, 0.0212,
        0.0528, 0.0520, 0.1284, 0.1245, 0.0135, 0.0731], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,804][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0981, 0.0801, 0.0689, 0.0724, 0.0555, 0.0706, 0.0582, 0.0622, 0.0659,
        0.0545, 0.0671, 0.0570, 0.0743, 0.0537, 0.0617], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,805][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0593, 0.0303, 0.0500, 0.0366, 0.0546, 0.0647, 0.0618, 0.0766, 0.0639,
        0.0547, 0.0769, 0.0552, 0.1524, 0.0856, 0.0773], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,805][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0128, 0.0674, 0.0392, 0.0663, 0.0535, 0.0724, 0.0973, 0.0744, 0.0538,
        0.1707, 0.0488, 0.0931, 0.0977, 0.0210, 0.0318], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,806][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0088, 0.0410, 0.0505, 0.0500, 0.0771, 0.0735, 0.0742, 0.0701, 0.0730,
        0.0843, 0.0777, 0.0723, 0.0880, 0.0704, 0.0890], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,806][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0456, 0.0704, 0.0541, 0.1162, 0.0635, 0.0372, 0.0783, 0.0631, 0.0595,
        0.0676, 0.0709, 0.0864, 0.0861, 0.0553, 0.0456], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:25,807][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.0060, 0.0159, 0.0151, 0.0408, 0.0415, 0.0421, 0.1059, 0.0389, 0.0530,
        0.0895, 0.0565, 0.1776, 0.0884, 0.0500, 0.0876, 0.0912],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,807][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.1288, 0.0058, 0.0520, 0.0737, 0.0320, 0.1288, 0.0474, 0.0171, 0.1104,
        0.0218, 0.0681, 0.0213, 0.0317, 0.1554, 0.0260, 0.0797],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,808][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ it] are: tensor([3.4243e-14, 6.4360e-14, 7.3704e-13, 2.2415e-11, 5.0751e-11, 3.8799e-10,
        7.1527e-09, 7.3657e-08, 3.7072e-07, 1.5064e-05, 1.9362e-05, 5.2763e-04,
        4.0548e-04, 6.9361e-02, 7.9892e-01, 1.3075e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,808][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.0019, 0.0035, 0.0099, 0.0121, 0.0216, 0.0264, 0.0642, 0.0388, 0.0563,
        0.1138, 0.0924, 0.1049, 0.0682, 0.1441, 0.1084, 0.1333],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,810][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ it] are: tensor([3.2874e-08, 8.8297e-08, 4.2417e-07, 2.1064e-06, 4.1328e-06, 4.9449e-06,
        3.6384e-05, 5.6210e-05, 1.2310e-04, 8.6846e-04, 1.5981e-03, 5.3601e-03,
        3.7711e-02, 5.8204e-02, 7.5244e-01, 1.4359e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,811][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.1362, 0.0442, 0.0515, 0.0436, 0.0542, 0.0575, 0.0535, 0.0556, 0.0639,
        0.0540, 0.0663, 0.0568, 0.0630, 0.0705, 0.0640, 0.0653],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,812][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.0483, 0.0719, 0.0351, 0.0997, 0.1392, 0.0306, 0.0620, 0.0312, 0.0230,
        0.0492, 0.0531, 0.0970, 0.1067, 0.0155, 0.0931, 0.0444],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,814][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0896, 0.0752, 0.0637, 0.0687, 0.0530, 0.0660, 0.0586, 0.0594, 0.0628,
        0.0538, 0.0633, 0.0556, 0.0679, 0.0504, 0.0565, 0.0553],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,815][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0453, 0.0272, 0.0486, 0.0332, 0.0625, 0.0627, 0.0485, 0.0964, 0.0532,
        0.0534, 0.0767, 0.0537, 0.1160, 0.0805, 0.1067, 0.0354],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,817][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.0116, 0.0640, 0.0481, 0.0849, 0.0671, 0.0727, 0.0893, 0.0508, 0.0473,
        0.1134, 0.0584, 0.0787, 0.0885, 0.0236, 0.0698, 0.0319],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,818][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.0084, 0.0391, 0.0471, 0.0471, 0.0711, 0.0686, 0.0707, 0.0645, 0.0683,
        0.0783, 0.0724, 0.0686, 0.0818, 0.0662, 0.0823, 0.0654],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,820][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.0611, 0.0504, 0.0753, 0.0917, 0.0530, 0.0434, 0.0544, 0.0834, 0.0514,
        0.0566, 0.0998, 0.0631, 0.0654, 0.0690, 0.0518, 0.0301],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:25,821][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0060, 0.0150, 0.0147, 0.0427, 0.0448, 0.0496, 0.1153, 0.0383, 0.0592,
        0.0719, 0.0600, 0.1493, 0.0889, 0.0413, 0.0749, 0.0956, 0.0327],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,823][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1140, 0.0022, 0.0353, 0.0460, 0.0124, 0.1184, 0.0236, 0.0106, 0.1180,
        0.0133, 0.0539, 0.0097, 0.0231, 0.1567, 0.0205, 0.0609, 0.1815],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,824][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.1247e-14, 3.5857e-15, 6.3288e-14, 1.9526e-12, 4.2226e-12, 2.4716e-11,
        5.5259e-10, 2.3012e-09, 2.3808e-08, 4.8675e-07, 1.0721e-06, 1.5257e-05,
        2.1233e-05, 3.8240e-04, 5.6365e-02, 1.2283e-01, 8.2038e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,825][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0017, 0.0035, 0.0089, 0.0111, 0.0183, 0.0237, 0.0578, 0.0319, 0.0486,
        0.1031, 0.0780, 0.0994, 0.0581, 0.1128, 0.0908, 0.1186, 0.1337],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,826][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([6.2586e-09, 1.3032e-08, 3.9344e-08, 6.8456e-07, 1.7955e-06, 5.8056e-07,
        1.5533e-05, 5.4201e-06, 1.3945e-05, 1.2577e-04, 1.4926e-04, 5.9592e-04,
        1.0380e-02, 4.4899e-03, 1.5438e-01, 6.4255e-01, 1.8729e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,828][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1403, 0.0394, 0.0464, 0.0390, 0.0492, 0.0524, 0.0485, 0.0509, 0.0588,
        0.0499, 0.0616, 0.0523, 0.0585, 0.0655, 0.0598, 0.0613, 0.0663],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,829][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0571, 0.0712, 0.0466, 0.0940, 0.1040, 0.0395, 0.0554, 0.0319, 0.0310,
        0.0412, 0.0652, 0.0991, 0.1083, 0.0167, 0.0701, 0.0546, 0.0141],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,831][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0819, 0.0720, 0.0598, 0.0657, 0.0533, 0.0608, 0.0568, 0.0564, 0.0594,
        0.0542, 0.0597, 0.0543, 0.0650, 0.0477, 0.0553, 0.0541, 0.0436],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,831][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0402, 0.0278, 0.0482, 0.0466, 0.0712, 0.0539, 0.0569, 0.0679, 0.0489,
        0.0600, 0.0696, 0.0536, 0.1060, 0.0428, 0.1195, 0.0445, 0.0427],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,832][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0135, 0.0653, 0.0403, 0.0864, 0.0619, 0.0639, 0.0875, 0.0366, 0.0459,
        0.1180, 0.0485, 0.0878, 0.0986, 0.0147, 0.0656, 0.0535, 0.0120],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,832][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0092, 0.0381, 0.0452, 0.0449, 0.0665, 0.0644, 0.0668, 0.0602, 0.0637,
        0.0738, 0.0675, 0.0654, 0.0761, 0.0618, 0.0757, 0.0608, 0.0601],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,833][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0461, 0.0470, 0.0771, 0.0721, 0.0513, 0.0357, 0.0535, 0.0786, 0.0575,
        0.0491, 0.0987, 0.0584, 0.0686, 0.0596, 0.0440, 0.0451, 0.0576],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:25,861][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:25,862][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,863][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,864][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,865][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,867][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,867][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,869][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,870][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,871][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,872][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,873][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,874][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:25,876][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.6247, 0.3753], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,877][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.9763, 0.0237], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,878][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.1905, 0.8095], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,880][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.3963, 0.6037], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,881][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.9844, 0.0156], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,883][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.4116, 0.5884], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,883][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.3297, 0.6703], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,883][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.6372, 0.3628], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,884][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.7494, 0.2506], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,884][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.9043, 0.0957], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,885][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.1863, 0.8137], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,885][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.6668, 0.3332], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:25,885][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3225, 0.3764, 0.3011], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,886][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.9518, 0.0208, 0.0274], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,887][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0411, 0.1228, 0.8361], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,889][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2033, 0.3122, 0.4845], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,890][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.6850, 0.1476, 0.1674], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,891][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1478, 0.2904, 0.5618], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,892][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3040, 0.4263, 0.2697], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,894][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4652, 0.2677, 0.2671], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,895][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3985, 0.2735, 0.3280], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,896][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9354, 0.0326, 0.0320], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,898][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0176, 0.5735, 0.4088], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,899][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.5682, 0.2430, 0.1888], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:25,900][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Nathan] are: tensor([0.1906, 0.2483, 0.3031, 0.2580], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,902][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Nathan] are: tensor([0.9384, 0.0185, 0.0253, 0.0177], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,903][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Nathan] are: tensor([0.0165, 0.0516, 0.6336, 0.2983], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,904][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Nathan] are: tensor([0.1230, 0.1931, 0.3067, 0.3771], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,906][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Nathan] are: tensor([0.6577, 0.1064, 0.2317, 0.0042], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,907][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Nathan] are: tensor([0.0659, 0.1685, 0.5032, 0.2624], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,909][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Nathan] are: tensor([0.1464, 0.3038, 0.1781, 0.3717], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,909][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Nathan] are: tensor([0.3673, 0.2207, 0.2207, 0.1913], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,909][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Nathan] are: tensor([0.3239, 0.1684, 0.3437, 0.1640], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,910][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Nathan] are: tensor([0.8401, 0.0509, 0.1030, 0.0060], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,910][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Nathan] are: tensor([0.0178, 0.4131, 0.2109, 0.3582], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,911][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Nathan] are: tensor([0.3611, 0.1884, 0.1506, 0.2999], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:25,911][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.1423, 0.2080, 0.2110, 0.2691, 0.1697], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,911][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.9284, 0.0173, 0.0233, 0.0161, 0.0149], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,912][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.0121, 0.0305, 0.2994, 0.1728, 0.4852], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,913][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.0764, 0.1228, 0.1986, 0.2530, 0.3493], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,915][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.6084, 0.0174, 0.3425, 0.0155, 0.0161], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,916][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.0357, 0.1098, 0.3419, 0.3467, 0.1659], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,917][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.1086, 0.1852, 0.1051, 0.2613, 0.3398], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,919][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.3011, 0.1874, 0.1878, 0.1631, 0.1607], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,920][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.2538, 0.1279, 0.2505, 0.1457, 0.2221], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,921][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.7505, 0.0794, 0.1503, 0.0083, 0.0115], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,923][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.0173, 0.2675, 0.1495, 0.2238, 0.3419], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,924][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.2474, 0.1522, 0.1206, 0.2746, 0.2052], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:25,925][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1339, 0.1376, 0.1742, 0.2479, 0.1638, 0.1426], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,927][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.8835, 0.0202, 0.0267, 0.0189, 0.0177, 0.0329], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,928][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0041, 0.0132, 0.1376, 0.0977, 0.2919, 0.4555], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,930][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0633, 0.0965, 0.1501, 0.1884, 0.2654, 0.2362], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,931][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.2612, 0.1106, 0.4100, 0.0428, 0.1327, 0.0427], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,933][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0406, 0.1165, 0.2508, 0.2517, 0.2368, 0.1036], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,934][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1039, 0.1553, 0.1103, 0.2204, 0.2989, 0.1112], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,935][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2660, 0.1567, 0.1563, 0.1360, 0.1341, 0.1509], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,935][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1767, 0.1295, 0.1790, 0.1240, 0.2478, 0.1430], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,935][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.7989, 0.0654, 0.1130, 0.0058, 0.0104, 0.0065], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,936][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0068, 0.2217, 0.0895, 0.1497, 0.2349, 0.2974], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,936][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.2175, 0.1000, 0.1025, 0.2446, 0.2278, 0.1076], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:25,937][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.0849, 0.1206, 0.1467, 0.2032, 0.1655, 0.1187, 0.1605],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,937][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.8071, 0.0200, 0.0276, 0.0190, 0.0175, 0.0334, 0.0754],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,937][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.0014, 0.0051, 0.0972, 0.0434, 0.1968, 0.5440, 0.1121],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,938][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.0423, 0.0697, 0.1184, 0.1456, 0.2261, 0.2021, 0.1958],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,939][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.5028, 0.0562, 0.2043, 0.0276, 0.1477, 0.0562, 0.0052],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,940][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.0224, 0.0759, 0.2129, 0.2198, 0.1725, 0.1665, 0.1300],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,942][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.0740, 0.1420, 0.0759, 0.1972, 0.2767, 0.0794, 0.1547],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,943][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.2299, 0.1389, 0.1384, 0.1200, 0.1185, 0.1344, 0.1198],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,945][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.1629, 0.0730, 0.1734, 0.1152, 0.2238, 0.1541, 0.0976],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,946][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.9340, 0.0172, 0.0369, 0.0029, 0.0045, 0.0032, 0.0012],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,947][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0085, 0.1737, 0.0620, 0.1129, 0.1709, 0.2021, 0.2700],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,949][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.1366, 0.1356, 0.0521, 0.2454, 0.1936, 0.0840, 0.1526],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:25,950][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0730, 0.1134, 0.0988, 0.1680, 0.1162, 0.1012, 0.1638, 0.1656],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,951][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.7518, 0.0216, 0.0284, 0.0198, 0.0183, 0.0339, 0.0676, 0.0586],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,953][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0032, 0.0097, 0.0864, 0.0616, 0.1699, 0.2594, 0.1403, 0.2695],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,954][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0428, 0.0651, 0.1006, 0.1226, 0.1734, 0.1562, 0.1647, 0.1746],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,956][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.2177, 0.1054, 0.3784, 0.0104, 0.1423, 0.0927, 0.0226, 0.0305],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,957][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0276, 0.0478, 0.1729, 0.1411, 0.1491, 0.1229, 0.2593, 0.0793],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,959][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0860, 0.1201, 0.0816, 0.1645, 0.2473, 0.0833, 0.1497, 0.0674],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,960][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.2077, 0.1227, 0.1217, 0.1064, 0.1040, 0.1172, 0.1058, 0.1144],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,961][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.1352, 0.0794, 0.1291, 0.0741, 0.2052, 0.1553, 0.0909, 0.1308],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,961][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([9.1663e-01, 2.6047e-02, 4.5488e-02, 2.6059e-03, 4.5045e-03, 3.2636e-03,
        1.1932e-03, 2.6822e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,962][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0116, 0.1815, 0.0565, 0.0913, 0.1413, 0.1547, 0.2011, 0.1620],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,962][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.1857, 0.0876, 0.0727, 0.1648, 0.1498, 0.0852, 0.0983, 0.1559],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:25,963][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0721, 0.0886, 0.0934, 0.1454, 0.0939, 0.0845, 0.1344, 0.2097, 0.0779],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,963][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.6708, 0.0210, 0.0280, 0.0193, 0.0183, 0.0336, 0.0656, 0.0581, 0.0853],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,963][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0019, 0.0070, 0.0703, 0.0520, 0.1434, 0.2000, 0.1234, 0.2365, 0.1657],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,964][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0383, 0.0571, 0.0875, 0.1081, 0.1500, 0.1341, 0.1436, 0.1532, 0.1281],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,966][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1913, 0.1775, 0.2059, 0.1423, 0.0455, 0.0736, 0.0705, 0.0722, 0.0211],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,967][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0233, 0.0563, 0.1655, 0.1278, 0.1524, 0.0946, 0.2029, 0.1078, 0.0694],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,968][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0812, 0.1091, 0.0798, 0.1428, 0.2233, 0.0766, 0.1489, 0.0716, 0.0666],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,970][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1963, 0.1067, 0.1058, 0.0918, 0.0904, 0.1021, 0.0915, 0.0995, 0.1158],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,970][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1037, 0.0810, 0.1185, 0.0762, 0.1548, 0.1129, 0.1003, 0.1799, 0.0726],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,971][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([9.3140e-01, 1.9426e-02, 3.9143e-02, 2.1923e-03, 3.5595e-03, 2.5198e-03,
        9.8020e-04, 2.3259e-04, 5.4397e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,973][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0056, 0.1403, 0.0420, 0.0718, 0.1112, 0.1243, 0.1718, 0.1309, 0.2023],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,974][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1674, 0.0550, 0.0744, 0.1204, 0.1671, 0.0791, 0.0810, 0.1889, 0.0666],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:25,976][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([0.0576, 0.0849, 0.0735, 0.1322, 0.0860, 0.0712, 0.1234, 0.1747, 0.0813,
        0.1151], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,977][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([0.6543, 0.0170, 0.0232, 0.0158, 0.0143, 0.0280, 0.0614, 0.0529, 0.0796,
        0.0535], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,979][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([0.0013, 0.0037, 0.0525, 0.0254, 0.0938, 0.2024, 0.0536, 0.2273, 0.1928,
        0.1473], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,980][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([0.0226, 0.0354, 0.0635, 0.0744, 0.1186, 0.1088, 0.1038, 0.1250, 0.1031,
        0.2447], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,982][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([0.1426, 0.0343, 0.2090, 0.0474, 0.1578, 0.0939, 0.0369, 0.0412, 0.2184,
        0.0185], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,983][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([0.0144, 0.0404, 0.1229, 0.1461, 0.1280, 0.1040, 0.1767, 0.0890, 0.0861,
        0.0924], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,984][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([0.0580, 0.1030, 0.0568, 0.1578, 0.2200, 0.0609, 0.1221, 0.0575, 0.0525,
        0.1115], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,986][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([0.1646, 0.0995, 0.0988, 0.0859, 0.0840, 0.0953, 0.0860, 0.0928, 0.1074,
        0.0856], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,987][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([0.1194, 0.0494, 0.1055, 0.0571, 0.1100, 0.1192, 0.0901, 0.1797, 0.0916,
        0.0779], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,987][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([9.3550e-01, 1.8145e-02, 3.4398e-02, 2.8353e-03, 3.5162e-03, 2.8018e-03,
        1.2594e-03, 3.5559e-04, 7.5007e-04, 4.3436e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,988][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([0.0078, 0.1350, 0.0372, 0.0590, 0.0943, 0.0938, 0.1397, 0.1053, 0.1566,
        0.1712], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,988][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([0.1623, 0.0819, 0.0481, 0.1521, 0.1591, 0.0715, 0.0961, 0.0989, 0.0604,
        0.0696], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:25,989][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0545, 0.0717, 0.0714, 0.1209, 0.0883, 0.0767, 0.1028, 0.1487, 0.0710,
        0.1026, 0.0913], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,989][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.5870, 0.0183, 0.0241, 0.0170, 0.0161, 0.0284, 0.0567, 0.0498, 0.0744,
        0.0502, 0.0781], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,990][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0014, 0.0040, 0.0397, 0.0286, 0.0827, 0.1258, 0.0616, 0.1403, 0.1154,
        0.1807, 0.2197], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,990][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0256, 0.0379, 0.0598, 0.0734, 0.1044, 0.0939, 0.0962, 0.1069, 0.0902,
        0.2032, 0.1086], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,991][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1668, 0.2526, 0.0708, 0.0233, 0.0314, 0.1405, 0.0681, 0.0420, 0.1639,
        0.0153, 0.0251], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,993][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0175, 0.0360, 0.1119, 0.1038, 0.1076, 0.0711, 0.1308, 0.0849, 0.0704,
        0.1434, 0.1224], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,994][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0648, 0.0830, 0.0599, 0.1273, 0.1679, 0.0628, 0.1149, 0.0591, 0.0569,
        0.1032, 0.1003], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,996][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1644, 0.0880, 0.0869, 0.0755, 0.0743, 0.0841, 0.0755, 0.0819, 0.0954,
        0.0759, 0.0981], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,997][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0937, 0.0639, 0.0856, 0.0601, 0.1101, 0.1009, 0.0902, 0.1369, 0.0762,
        0.0937, 0.0885], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,998][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([9.2692e-01, 2.5532e-02, 3.6419e-02, 2.4323e-03, 3.2567e-03, 2.8160e-03,
        1.0414e-03, 2.2859e-04, 5.6255e-04, 3.2446e-04, 4.7128e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:25,999][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0055, 0.1135, 0.0311, 0.0506, 0.0744, 0.0815, 0.1196, 0.0883, 0.1351,
        0.1459, 0.1544], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,001][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1516, 0.0512, 0.0591, 0.1079, 0.1464, 0.0704, 0.0763, 0.1272, 0.0668,
        0.0679, 0.0750], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,002][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.0429, 0.0299, 0.0587, 0.1070, 0.0716, 0.0648, 0.1063, 0.1386, 0.0751,
        0.1216, 0.0977, 0.0859], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,003][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.5864, 0.0129, 0.0181, 0.0120, 0.0109, 0.0217, 0.0480, 0.0432, 0.0687,
        0.0432, 0.0727, 0.0623], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,005][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.0004, 0.0012, 0.0255, 0.0118, 0.0521, 0.1312, 0.0300, 0.1434, 0.1306,
        0.0980, 0.2604, 0.1154], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,006][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.0184, 0.0282, 0.0496, 0.0604, 0.0941, 0.0838, 0.0845, 0.0972, 0.0796,
        0.1965, 0.1023, 0.1052], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,008][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.0981, 0.0011, 0.0820, 0.0070, 0.0211, 0.0501, 0.3692, 0.0463, 0.0673,
        0.1087, 0.1482, 0.0008], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,009][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.0101, 0.0175, 0.1099, 0.0777, 0.0797, 0.0854, 0.1543, 0.0731, 0.0787,
        0.1149, 0.1541, 0.0445], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,011][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.0383, 0.0835, 0.0491, 0.1234, 0.1793, 0.0463, 0.0929, 0.0407, 0.0397,
        0.0994, 0.0833, 0.1243], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,012][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.1356, 0.0831, 0.0825, 0.0720, 0.0706, 0.0796, 0.0721, 0.0776, 0.0894,
        0.0720, 0.0914, 0.0740], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,013][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.0890, 0.0285, 0.0950, 0.0644, 0.1140, 0.0947, 0.0607, 0.1393, 0.0837,
        0.0814, 0.1130, 0.0363], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,013][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([9.2642e-01, 1.7485e-02, 3.4315e-02, 4.6037e-03, 4.8710e-03, 3.8222e-03,
        2.2329e-03, 6.7765e-04, 1.3574e-03, 9.3338e-04, 1.4371e-03, 1.8413e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,014][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.0007, 0.0807, 0.0223, 0.0393, 0.0637, 0.0703, 0.1030, 0.0735, 0.1238,
        0.1256, 0.1423, 0.1549], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,014][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.1179, 0.0616, 0.0432, 0.1168, 0.1381, 0.0652, 0.0996, 0.0734, 0.0581,
        0.0807, 0.0564, 0.0890], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,015][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0422, 0.0515, 0.0611, 0.0719, 0.0681, 0.0603, 0.0680, 0.1522, 0.0627,
        0.0798, 0.0923, 0.1372, 0.0527], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,015][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.5733, 0.0132, 0.0180, 0.0122, 0.0114, 0.0215, 0.0482, 0.0419, 0.0652,
        0.0402, 0.0684, 0.0585, 0.0280], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,016][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0007, 0.0018, 0.0247, 0.0133, 0.0455, 0.0984, 0.0335, 0.1123, 0.0979,
        0.1073, 0.2116, 0.1487, 0.1043], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,017][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0161, 0.0254, 0.0438, 0.0534, 0.0796, 0.0719, 0.0747, 0.0847, 0.0690,
        0.1766, 0.0881, 0.0952, 0.1216], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,018][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.5382, 0.0077, 0.1103, 0.0067, 0.0427, 0.0445, 0.0051, 0.0415, 0.1069,
        0.0051, 0.0808, 0.0059, 0.0046], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,020][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.0104, 0.0247, 0.0803, 0.0833, 0.0806, 0.0652, 0.1312, 0.0798, 0.0677,
        0.1159, 0.1327, 0.0635, 0.0648], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,021][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0476, 0.0724, 0.0382, 0.0987, 0.1466, 0.0425, 0.0867, 0.0389, 0.0413,
        0.0858, 0.0737, 0.1117, 0.1160], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,022][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.1250, 0.0778, 0.0770, 0.0674, 0.0657, 0.0740, 0.0675, 0.0723, 0.0827,
        0.0674, 0.0845, 0.0693, 0.0694], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,024][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0774, 0.0423, 0.0687, 0.0526, 0.0899, 0.0811, 0.0605, 0.1086, 0.0656,
        0.0722, 0.0911, 0.0618, 0.1283], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,025][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([9.0483e-01, 2.6448e-02, 5.0215e-02, 3.2509e-03, 4.0365e-03, 3.7270e-03,
        1.3813e-03, 3.9364e-04, 9.2332e-04, 4.9656e-04, 9.4588e-04, 1.1893e-03,
        2.1633e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,026][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0042, 0.0880, 0.0265, 0.0410, 0.0623, 0.0651, 0.0857, 0.0656, 0.1029,
        0.1077, 0.1191, 0.1179, 0.1139], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,028][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0941, 0.0678, 0.0441, 0.1039, 0.1135, 0.0485, 0.0852, 0.0844, 0.0510,
        0.0667, 0.0574, 0.0930, 0.0902], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,029][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0452, 0.0509, 0.0512, 0.0602, 0.0581, 0.0504, 0.0887, 0.1200, 0.0474,
        0.0834, 0.0719, 0.1350, 0.0616, 0.0759], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,031][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.4424, 0.0145, 0.0195, 0.0135, 0.0126, 0.0231, 0.0459, 0.0408, 0.0610,
        0.0420, 0.0648, 0.0567, 0.0293, 0.1340], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,032][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0008, 0.0022, 0.0227, 0.0183, 0.0529, 0.0751, 0.0427, 0.0868, 0.0754,
        0.1136, 0.1447, 0.1629, 0.1079, 0.0940], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,034][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0196, 0.0291, 0.0455, 0.0540, 0.0758, 0.0673, 0.0724, 0.0773, 0.0646,
        0.1451, 0.0784, 0.0903, 0.1093, 0.0713], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,035][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0417, 0.0191, 0.1256, 0.0854, 0.1097, 0.0399, 0.0641, 0.0694, 0.0345,
        0.0199, 0.0611, 0.0170, 0.3007, 0.0122], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,037][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0122, 0.0346, 0.0818, 0.0759, 0.0750, 0.0513, 0.0959, 0.0614, 0.0559,
        0.1073, 0.1048, 0.0926, 0.1003, 0.0510], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,038][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0499, 0.0640, 0.0518, 0.0886, 0.1181, 0.0527, 0.0818, 0.0436, 0.0458,
        0.0771, 0.0847, 0.0988, 0.1079, 0.0352], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,039][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1291, 0.0700, 0.0688, 0.0601, 0.0592, 0.0666, 0.0604, 0.0649, 0.0750,
        0.0606, 0.0769, 0.0629, 0.0631, 0.0822], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,039][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0583, 0.0435, 0.0700, 0.0581, 0.0957, 0.0687, 0.0684, 0.0841, 0.0545,
        0.0746, 0.0780, 0.0582, 0.1412, 0.0469], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,040][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.6136e-01, 1.1982e-02, 1.8444e-02, 1.3703e-03, 1.8259e-03, 1.4070e-03,
        6.4581e-04, 1.5139e-04, 3.3308e-04, 2.3541e-04, 3.7679e-04, 5.9322e-04,
        1.0845e-03, 1.9460e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,040][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0039, 0.0825, 0.0212, 0.0346, 0.0528, 0.0528, 0.0744, 0.0557, 0.0832,
        0.0871, 0.0955, 0.0978, 0.1016, 0.1571], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,041][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1098, 0.0473, 0.0401, 0.0921, 0.1096, 0.0503, 0.0655, 0.0981, 0.0491,
        0.0498, 0.0581, 0.0636, 0.0923, 0.0743], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,041][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0356, 0.0500, 0.0450, 0.0620, 0.0526, 0.0460, 0.0732, 0.1020, 0.0487,
        0.0799, 0.0617, 0.1216, 0.0851, 0.0955, 0.0412], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,042][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.4629, 0.0121, 0.0164, 0.0112, 0.0104, 0.0199, 0.0429, 0.0368, 0.0561,
        0.0364, 0.0597, 0.0508, 0.0249, 0.1259, 0.0337], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,043][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0008, 0.0020, 0.0227, 0.0142, 0.0374, 0.0719, 0.0328, 0.0809, 0.0692,
        0.0982, 0.1460, 0.1337, 0.0851, 0.1258, 0.0795], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,045][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0145, 0.0223, 0.0375, 0.0453, 0.0652, 0.0589, 0.0635, 0.0696, 0.0573,
        0.1428, 0.0721, 0.0792, 0.0999, 0.0644, 0.1075], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,046][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.2171, 0.0168, 0.2222, 0.0145, 0.0251, 0.0474, 0.0340, 0.0556, 0.0930,
        0.0350, 0.1663, 0.0109, 0.0376, 0.0234, 0.0011], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,048][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0107, 0.0282, 0.0764, 0.0644, 0.0434, 0.0587, 0.0940, 0.0583, 0.0697,
        0.1071, 0.1186, 0.0657, 0.0895, 0.0796, 0.0356], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,049][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0382, 0.0635, 0.0355, 0.0894, 0.1215, 0.0373, 0.0768, 0.0380, 0.0332,
        0.0756, 0.0682, 0.0982, 0.1088, 0.0282, 0.0877], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,051][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.1058, 0.0665, 0.0665, 0.0584, 0.0574, 0.0644, 0.0585, 0.0628, 0.0717,
        0.0583, 0.0731, 0.0598, 0.0600, 0.0771, 0.0597], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,052][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0673, 0.0383, 0.0595, 0.0408, 0.0637, 0.0663, 0.0620, 0.0790, 0.0569,
        0.0566, 0.0697, 0.0495, 0.1543, 0.0676, 0.0685], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,053][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([9.5435e-01, 1.3271e-02, 2.2063e-02, 1.7332e-03, 2.1844e-03, 1.7501e-03,
        7.5732e-04, 2.1274e-04, 4.2310e-04, 2.8659e-04, 4.7592e-04, 7.0230e-04,
        1.1752e-03, 2.6324e-04, 3.5497e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,055][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0031, 0.0714, 0.0186, 0.0322, 0.0459, 0.0484, 0.0714, 0.0505, 0.0770,
        0.0858, 0.0918, 0.1048, 0.0922, 0.1483, 0.0585], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,056][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0950, 0.0512, 0.0350, 0.1013, 0.1107, 0.0501, 0.0676, 0.0771, 0.0459,
        0.0468, 0.0428, 0.0639, 0.0875, 0.0659, 0.0594], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,058][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.0306, 0.0448, 0.0453, 0.0739, 0.0579, 0.0435, 0.0712, 0.1005, 0.0412,
        0.0654, 0.0636, 0.1108, 0.0675, 0.0855, 0.0668, 0.0315],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,059][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.4388, 0.0118, 0.0159, 0.0109, 0.0102, 0.0189, 0.0403, 0.0349, 0.0532,
        0.0348, 0.0568, 0.0485, 0.0242, 0.1199, 0.0330, 0.0480],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,061][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.0006, 0.0016, 0.0193, 0.0129, 0.0373, 0.0633, 0.0319, 0.0741, 0.0603,
        0.0933, 0.1294, 0.1373, 0.0867, 0.1163, 0.0884, 0.0473],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,062][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([0.0151, 0.0221, 0.0364, 0.0435, 0.0610, 0.0545, 0.0593, 0.0638, 0.0529,
        0.1227, 0.0656, 0.0730, 0.0918, 0.0600, 0.0975, 0.0807],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,064][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.1081, 0.0366, 0.2115, 0.0464, 0.0214, 0.0964, 0.0898, 0.0433, 0.0371,
        0.0230, 0.1263, 0.0324, 0.0752, 0.0327, 0.0191, 0.0008],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,065][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.0080, 0.0217, 0.0693, 0.0669, 0.0652, 0.0498, 0.1122, 0.0563, 0.0449,
        0.1067, 0.1016, 0.0580, 0.0826, 0.0620, 0.0665, 0.0283],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,065][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.0411, 0.0557, 0.0383, 0.0767, 0.1171, 0.0394, 0.0723, 0.0375, 0.0337,
        0.0695, 0.0654, 0.0836, 0.0932, 0.0287, 0.0909, 0.0570],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,066][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.1084, 0.0620, 0.0616, 0.0537, 0.0529, 0.0595, 0.0537, 0.0581, 0.0667,
        0.0539, 0.0684, 0.0558, 0.0557, 0.0728, 0.0558, 0.0608],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,066][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.0525, 0.0351, 0.0579, 0.0364, 0.0716, 0.0644, 0.0499, 0.0971, 0.0491,
        0.0553, 0.0694, 0.0491, 0.1230, 0.0661, 0.0912, 0.0320],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,067][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([9.5037e-01, 1.5239e-02, 2.4173e-02, 1.6987e-03, 2.1419e-03, 1.6221e-03,
        7.1661e-04, 1.9253e-04, 3.8339e-04, 2.5682e-04, 4.2635e-04, 6.2316e-04,
        1.2018e-03, 2.3284e-04, 3.7111e-04, 3.4560e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,067][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.0019, 0.0676, 0.0150, 0.0282, 0.0415, 0.0436, 0.0735, 0.0471, 0.0746,
        0.0833, 0.0880, 0.1050, 0.0894, 0.1463, 0.0545, 0.0404],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,067][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.1043, 0.0350, 0.0398, 0.0805, 0.0935, 0.0495, 0.0480, 0.0942, 0.0420,
        0.0413, 0.0563, 0.0506, 0.0738, 0.0737, 0.0639, 0.0535],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,069][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0398, 0.0434, 0.0439, 0.0520, 0.0486, 0.0427, 0.0782, 0.1036, 0.0396,
        0.0720, 0.0612, 0.1127, 0.0516, 0.0652, 0.0525, 0.0350, 0.0582],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,070][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.3439, 0.0115, 0.0155, 0.0106, 0.0101, 0.0185, 0.0358, 0.0328, 0.0490,
        0.0332, 0.0520, 0.0450, 0.0237, 0.1077, 0.0314, 0.0449, 0.1344],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,072][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0008, 0.0020, 0.0197, 0.0170, 0.0433, 0.0618, 0.0372, 0.0686, 0.0604,
        0.0936, 0.1171, 0.1359, 0.0887, 0.0743, 0.0891, 0.0451, 0.0453],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,073][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0160, 0.0237, 0.0368, 0.0431, 0.0596, 0.0532, 0.0576, 0.0607, 0.0511,
        0.1110, 0.0613, 0.0713, 0.0851, 0.0563, 0.0878, 0.0746, 0.0508],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,074][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0411, 0.0133, 0.1111, 0.0722, 0.0909, 0.0336, 0.0547, 0.0660, 0.0325,
        0.0179, 0.0599, 0.0119, 0.2435, 0.0108, 0.0662, 0.0665, 0.0080],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,076][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0110, 0.0303, 0.0679, 0.0641, 0.0627, 0.0424, 0.0825, 0.0529, 0.0464,
        0.0921, 0.0893, 0.0805, 0.0824, 0.0423, 0.0689, 0.0467, 0.0376],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,077][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0426, 0.0528, 0.0431, 0.0723, 0.0973, 0.0440, 0.0691, 0.0371, 0.0384,
        0.0648, 0.0714, 0.0820, 0.0902, 0.0300, 0.0762, 0.0615, 0.0274],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,079][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1071, 0.0576, 0.0569, 0.0496, 0.0490, 0.0551, 0.0498, 0.0537, 0.0619,
        0.0499, 0.0635, 0.0520, 0.0520, 0.0680, 0.0522, 0.0567, 0.0652],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,080][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0479, 0.0366, 0.0568, 0.0495, 0.0798, 0.0553, 0.0590, 0.0691, 0.0446,
        0.0622, 0.0633, 0.0491, 0.1141, 0.0383, 0.1004, 0.0393, 0.0346],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,081][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.3836e-01, 1.9765e-02, 3.0532e-02, 1.7554e-03, 2.2599e-03, 1.9029e-03,
        7.5582e-04, 1.8598e-04, 4.0943e-04, 2.7251e-04, 4.5861e-04, 6.7836e-04,
        1.3032e-03, 2.2710e-04, 3.7370e-04, 3.8084e-04, 3.8031e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,082][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0055, 0.0876, 0.0161, 0.0288, 0.0425, 0.0385, 0.0671, 0.0434, 0.0668,
        0.0769, 0.0754, 0.0914, 0.0854, 0.1245, 0.0516, 0.0385, 0.0601],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,084][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0941, 0.0363, 0.0347, 0.0723, 0.0895, 0.0411, 0.0520, 0.0839, 0.0403,
        0.0395, 0.0502, 0.0502, 0.0749, 0.0629, 0.0530, 0.0592, 0.0661],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,085][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:26,088][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 7979],
        [13569],
        [24783],
        [  259],
        [13173],
        [ 6369],
        [11728],
        [ 5369],
        [10351],
        [22262],
        [13899],
        [12894],
        [16041],
        [ 9063],
        [11359],
        [13440],
        [ 7384]], device='cuda:0')
[2024-07-24 10:31:26,089][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 9545],
        [14474],
        [21616],
        [  269],
        [15893],
        [ 6290],
        [ 9203],
        [ 3813],
        [ 9720],
        [13740],
        [11047],
        [13809],
        [20047],
        [ 8810],
        [ 6824],
        [14724],
        [ 5534]], device='cuda:0')
[2024-07-24 10:31:26,091][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[1584],
        [3210],
        [2800],
        [2797],
        [2531],
        [2309],
        [3078],
        [2988],
        [2983],
        [2908],
        [3166],
        [3255],
        [3332],
        [3346],
        [3313],
        [3449],
        [3432]], device='cuda:0')
[2024-07-24 10:31:26,092][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[19976],
        [19434],
        [19745],
        [ 3015],
        [ 4593],
        [ 7687],
        [ 5257],
        [ 7351],
        [ 6603],
        [ 9951],
        [ 8792],
        [10119],
        [ 5312],
        [12865],
        [ 9191],
        [10663],
        [15126]], device='cuda:0')
[2024-07-24 10:31:26,093][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[29455],
        [19302],
        [28487],
        [24670],
        [24341],
        [28114],
        [22363],
        [11311],
        [13317],
        [39272],
        [41003],
        [22214],
        [19193],
        [43973],
        [43404],
        [32364],
        [44373]], device='cuda:0')
[2024-07-24 10:31:26,094][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[33110],
        [35635],
        [36039],
        [35664],
        [36061],
        [34740],
        [36999],
        [35920],
        [35508],
        [36088],
        [36065],
        [35797],
        [36207],
        [35462],
        [35608],
        [35314],
        [34685]], device='cuda:0')
[2024-07-24 10:31:26,096][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[23133],
        [36669],
        [36695],
        [48577],
        [42883],
        [40816],
        [43017],
        [37639],
        [30542],
        [21364],
        [22873],
        [32536],
        [25584],
        [20075],
        [26014],
        [24315],
        [ 8665]], device='cuda:0')
[2024-07-24 10:31:26,097][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[35641],
        [36300],
        [36453],
        [36502],
        [36478],
        [36350],
        [36407],
        [36416],
        [36334],
        [36250],
        [36095],
        [36247],
        [36256],
        [36311],
        [36347],
        [36344],
        [36372]], device='cuda:0')
[2024-07-24 10:31:26,098][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[17617],
        [31339],
        [29749],
        [32226],
        [32574],
        [31958],
        [32015],
        [31712],
        [31801],
        [32800],
        [32212],
        [32146],
        [33379],
        [32980],
        [34306],
        [34820],
        [34338]], device='cuda:0')
[2024-07-24 10:31:26,100][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[20322],
        [23450],
        [22103],
        [23902],
        [23931],
        [24048],
        [23185],
        [23340],
        [22894],
        [22658],
        [22629],
        [22773],
        [22769],
        [22508],
        [22738],
        [22454],
        [22286]], device='cuda:0')
[2024-07-24 10:31:26,102][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[2281],
        [2762],
        [3381],
        [3529],
        [2676],
        [3504],
        [3421],
        [3046],
        [3250],
        [3453],
        [3701],
        [3926],
        [3583],
        [3453],
        [3374],
        [3392],
        [3410]], device='cuda:0')
[2024-07-24 10:31:26,103][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[36181],
        [27984],
        [28093],
        [26537],
        [24729],
        [25446],
        [27920],
        [29482],
        [30081],
        [28358],
        [29852],
        [30194],
        [29557],
        [29576],
        [30190],
        [29307],
        [29115]], device='cuda:0')
[2024-07-24 10:31:26,105][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[17624],
        [17670],
        [15234],
        [16004],
        [14969],
        [14164],
        [15369],
        [14535],
        [13768],
        [14056],
        [13484],
        [14083],
        [14016],
        [13773],
        [13596],
        [13481],
        [13352]], device='cuda:0')
[2024-07-24 10:31:26,106][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[22272],
        [32821],
        [29792],
        [37238],
        [36583],
        [34070],
        [34214],
        [31381],
        [29734],
        [34400],
        [28806],
        [31550],
        [32542],
        [28645],
        [31212],
        [27896],
        [26846]], device='cuda:0')
[2024-07-24 10:31:26,107][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 8105],
        [ 9341],
        [26272],
        [20068],
        [40841],
        [23071],
        [ 8420],
        [22926],
        [33256],
        [46598],
        [28080],
        [ 7211],
        [30080],
        [30781],
        [20307],
        [35798],
        [23998]], device='cuda:0')
[2024-07-24 10:31:26,109][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[12576],
        [12310],
        [11170],
        [10860],
        [10171],
        [10488],
        [ 9980],
        [10144],
        [10505],
        [10425],
        [10019],
        [10268],
        [10548],
        [10707],
        [10305],
        [10087],
        [10339]], device='cuda:0')
[2024-07-24 10:31:26,110][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 8419],
        [ 8563],
        [ 8839],
        [ 9052],
        [ 9245],
        [ 9885],
        [10751],
        [11344],
        [12373],
        [12067],
        [12526],
        [12242],
        [12438],
        [12987],
        [12683],
        [12972],
        [13312]], device='cuda:0')
[2024-07-24 10:31:26,112][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[22017],
        [22822],
        [23343],
        [22029],
        [20841],
        [22680],
        [22440],
        [22123],
        [22764],
        [22031],
        [21418],
        [21539],
        [20326],
        [19068],
        [19331],
        [18987],
        [18833]], device='cuda:0')
[2024-07-24 10:31:26,113][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[2359],
        [2210],
        [2320],
        [2323],
        [2370],
        [2482],
        [2413],
        [2486],
        [2529],
        [2454],
        [2518],
        [2471],
        [2508],
        [2485],
        [2530],
        [2554],
        [2530]], device='cuda:0')
[2024-07-24 10:31:26,115][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[13585],
        [13771],
        [15259],
        [13885],
        [11914],
        [16028],
        [16676],
        [15169],
        [21637],
        [19848],
        [26089],
        [ 7938],
        [13133],
        [20284],
        [10525],
        [12375],
        [22185]], device='cuda:0')
[2024-07-24 10:31:26,116][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[18553],
        [18168],
        [17894],
        [15936],
        [14695],
        [15013],
        [15340],
        [15593],
        [15738],
        [15259],
        [15137],
        [15635],
        [15013],
        [14919],
        [15040],
        [14700],
        [14828]], device='cuda:0')
[2024-07-24 10:31:26,118][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[18033],
        [16725],
        [15222],
        [16125],
        [13739],
        [13499],
        [13570],
        [13090],
        [13230],
        [13366],
        [12876],
        [13184],
        [13004],
        [12681],
        [12821],
        [12731],
        [12553]], device='cuda:0')
[2024-07-24 10:31:26,119][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[18213],
        [17920],
        [17883],
        [18066],
        [18148],
        [18234],
        [18284],
        [18325],
        [18346],
        [18280],
        [18213],
        [18199],
        [18239],
        [18219],
        [18208],
        [18253],
        [18269]], device='cuda:0')
[2024-07-24 10:31:26,120][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[14678],
        [14787],
        [15594],
        [15810],
        [15485],
        [15075],
        [15203],
        [14873],
        [14865],
        [14909],
        [15044],
        [14969],
        [14710],
        [14844],
        [15286],
        [15276],
        [15410]], device='cuda:0')
[2024-07-24 10:31:26,121][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[7733],
        [7287],
        [7173],
        [5856],
        [5546],
        [5660],
        [7090],
        [6902],
        [7062],
        [7118],
        [7040],
        [7017],
        [6745],
        [7411],
        [7337],
        [7294],
        [7165]], device='cuda:0')
[2024-07-24 10:31:26,122][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[21871],
        [ 6863],
        [ 6936],
        [ 6989],
        [ 7675],
        [ 7699],
        [ 7521],
        [ 7611],
        [ 7881],
        [ 7682],
        [ 7801],
        [ 7611],
        [ 7719],
        [ 7938],
        [ 7805],
        [ 7768],
        [ 7668]], device='cuda:0')
[2024-07-24 10:31:26,124][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[12596],
        [10886],
        [11888],
        [11082],
        [11383],
        [12885],
        [11426],
        [13431],
        [14762],
        [13197],
        [14377],
        [12661],
        [11900],
        [12670],
        [12278],
        [13173],
        [13136]], device='cuda:0')
[2024-07-24 10:31:26,125][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[17846],
        [20688],
        [19651],
        [20893],
        [21551],
        [20489],
        [20406],
        [19993],
        [18849],
        [19393],
        [18573],
        [21556],
        [20951],
        [20587],
        [21143],
        [20721],
        [20263]], device='cuda:0')
[2024-07-24 10:31:26,127][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[25375],
        [26607],
        [17513],
        [12622],
        [ 9416],
        [15536],
        [36883],
        [18585],
        [11096],
        [ 5356],
        [15480],
        [34861],
        [15428],
        [ 6885],
        [21346],
        [ 7053],
        [11081]], device='cuda:0')
[2024-07-24 10:31:26,128][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[38355],
        [38355],
        [38355],
        [38355],
        [38355],
        [38355],
        [38355],
        [38355],
        [38355],
        [38355],
        [38355],
        [38355],
        [38355],
        [38355],
        [38355],
        [38355],
        [38355]], device='cuda:0')
[2024-07-24 10:31:26,162][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:26,163][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,164][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,166][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,167][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,168][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,169][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,170][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,171][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,171][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,171][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,172][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,172][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,172][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.9411, 0.0589], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,173][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.4233, 0.5767], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,173][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.3083, 0.6917], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,173][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.0360, 0.9640], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,174][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.9656, 0.0344], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,174][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.8016, 0.1984], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,175][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.0656, 0.9344], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,176][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.0443, 0.9557], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,177][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.9637, 0.0363], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,179][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.5278, 0.4722], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,180][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.5806, 0.4194], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,181][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.5048, 0.4952], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,182][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.8591, 0.0418, 0.0991], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,183][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2418, 0.3927, 0.3655], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,185][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1769, 0.4964, 0.3266], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,186][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([2.3562e-05, 1.6049e-07, 9.9998e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,187][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3023, 0.2799, 0.4178], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,189][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.6371, 0.1565, 0.2064], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,190][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0612, 0.6915, 0.2474], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,191][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([6.3208e-05, 2.3410e-06, 9.9993e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,192][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.5763, 0.3903, 0.0334], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,193][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([1.3147e-01, 2.1307e-04, 8.6832e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,195][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4048, 0.2856, 0.3096], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,196][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([8.9044e-02, 2.6427e-04, 9.1069e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,197][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Nathan] are: tensor([0.9249, 0.0168, 0.0384, 0.0199], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,198][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Nathan] are: tensor([0.1800, 0.2538, 0.2970, 0.2692], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,198][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Nathan] are: tensor([0.1427, 0.2979, 0.2791, 0.2803], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,198][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Nathan] are: tensor([5.8057e-06, 7.2392e-08, 9.9171e-01, 8.2837e-03], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,199][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Nathan] are: tensor([6.8113e-02, 8.8569e-01, 4.5899e-02, 2.9453e-04], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,199][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Nathan] are: tensor([0.5037, 0.1269, 0.1830, 0.1864], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,199][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Nathan] are: tensor([0.0266, 0.5930, 0.1528, 0.2277], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,200][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Nathan] are: tensor([7.8700e-06, 2.2517e-07, 9.9188e-01, 8.1147e-03], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,200][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Nathan] are: tensor([0.3066, 0.1668, 0.4851, 0.0415], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,201][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Nathan] are: tensor([2.4644e-02, 3.3030e-04, 8.3028e-01, 1.4474e-01], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,203][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Nathan] are: tensor([0.3016, 0.2387, 0.2366, 0.2231], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,203][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Nathan] are: tensor([1.0172e-02, 1.5405e-04, 9.6555e-01, 2.4128e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,205][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.9241, 0.0156, 0.0451, 0.0064, 0.0088], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,206][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.1236, 0.2099, 0.2272, 0.2392, 0.2000], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,207][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.0842, 0.2524, 0.1837, 0.2259, 0.2537], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,208][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ got] are: tensor([2.7531e-06, 3.8311e-08, 9.0792e-01, 8.1813e-02, 1.0261e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,210][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.1768, 0.5069, 0.1154, 0.0966, 0.1044], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,211][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.4376, 0.1038, 0.1544, 0.1529, 0.1512], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,212][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.0301, 0.3557, 0.1095, 0.3934, 0.1113], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,213][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ got] are: tensor([4.0576e-06, 3.3227e-07, 8.7007e-01, 1.1891e-01, 1.1017e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,215][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.2511, 0.0607, 0.5826, 0.0814, 0.0242], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,216][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ got] are: tensor([9.6250e-03, 1.5561e-04, 8.5763e-01, 7.8913e-02, 5.3672e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,217][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.2740, 0.1985, 0.1991, 0.1711, 0.1572], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,218][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ got] are: tensor([5.2494e-03, 4.2250e-05, 9.2948e-01, 9.6070e-03, 5.5623e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,219][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.8303, 0.0207, 0.0506, 0.0117, 0.0076, 0.0792], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,221][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1190, 0.1760, 0.1829, 0.1831, 0.1794, 0.1595], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,222][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0687, 0.1849, 0.1439, 0.1897, 0.2351, 0.1777], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,223][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([2.2315e-05, 3.4505e-09, 3.9276e-03, 8.6949e-04, 3.5216e-04, 9.9483e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,224][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2270, 0.3180, 0.0892, 0.0163, 0.1121, 0.2374], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,224][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.3781, 0.0908, 0.1248, 0.1353, 0.1262, 0.1447], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,224][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0190, 0.2920, 0.1643, 0.2368, 0.1806, 0.1074], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,225][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([4.7498e-05, 7.0654e-08, 7.7452e-03, 2.4041e-03, 7.5648e-04, 9.8905e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,225][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1810, 0.2821, 0.1660, 0.0932, 0.2718, 0.0059], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,225][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([6.6371e-02, 3.9557e-05, 6.7144e-02, 9.0875e-03, 1.9935e-02, 8.3742e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,226][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2138, 0.1657, 0.1678, 0.1562, 0.1305, 0.1659], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,226][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([8.6002e-02, 5.4987e-05, 8.7304e-02, 5.9807e-03, 1.8592e-02, 8.0207e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,227][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.8905, 0.0207, 0.0312, 0.0061, 0.0040, 0.0238, 0.0237],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,229][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.0911, 0.1484, 0.1570, 0.1783, 0.1668, 0.1339, 0.1245],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,230][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.0649, 0.1403, 0.1239, 0.1466, 0.2022, 0.1895, 0.1326],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,231][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([1.9014e-05, 2.2044e-08, 1.0400e-02, 1.4405e-03, 7.7097e-04, 9.2888e-01,
        5.8487e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,232][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([3.8173e-03, 9.5370e-01, 1.0991e-02, 4.3393e-03, 1.4939e-02, 1.2118e-02,
        9.3166e-05], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,233][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.2576, 0.0836, 0.1141, 0.1233, 0.1322, 0.1377, 0.1516],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,234][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.0244, 0.2842, 0.1221, 0.2426, 0.1264, 0.1397, 0.0606],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,235][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([9.4488e-06, 1.4310e-07, 1.0305e-02, 2.1973e-03, 1.4101e-03, 9.5057e-01,
        3.5512e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,236][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.3523, 0.0345, 0.1651, 0.0629, 0.3284, 0.0489, 0.0078],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,237][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([3.4307e-02, 3.3273e-05, 5.9096e-02, 1.3045e-02, 2.6026e-02, 7.2570e-01,
        1.4179e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,239][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.2001, 0.1440, 0.1465, 0.1219, 0.1139, 0.1368, 0.1368],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,240][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([1.3224e-02, 6.5788e-05, 8.5589e-02, 4.6582e-03, 7.0783e-03, 7.8294e-01,
        1.0645e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,241][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.7737, 0.0337, 0.0569, 0.0080, 0.0071, 0.0467, 0.0151, 0.0588],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,243][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0923, 0.1409, 0.1443, 0.1462, 0.1522, 0.1293, 0.1189, 0.0759],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,244][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0517, 0.1318, 0.1082, 0.1371, 0.1743, 0.1566, 0.1413, 0.0989],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,245][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ at] are: tensor([3.7762e-05, 7.9090e-10, 1.7050e-03, 4.4208e-04, 2.5924e-04, 3.4186e-01,
        5.3993e-02, 6.0170e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,246][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1116, 0.2843, 0.1159, 0.0071, 0.1224, 0.1054, 0.2056, 0.0476],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,248][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.2960, 0.0726, 0.0965, 0.1119, 0.1012, 0.1111, 0.1244, 0.0863],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,249][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0148, 0.2660, 0.1009, 0.1698, 0.1493, 0.1234, 0.1300, 0.0460],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,250][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ at] are: tensor([2.4225e-05, 2.8577e-08, 1.7274e-03, 7.2245e-04, 2.7678e-04, 6.5518e-01,
        1.5444e-01, 1.8763e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,250][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0979, 0.1299, 0.0411, 0.0280, 0.0490, 0.0246, 0.5477, 0.0818],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,250][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ at] are: tensor([6.9806e-02, 8.5377e-06, 2.5415e-02, 4.5464e-03, 6.8761e-03, 7.4817e-01,
        8.3280e-02, 6.1899e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,251][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1774, 0.1302, 0.1375, 0.1140, 0.0963, 0.1183, 0.1234, 0.1028],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,251][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ at] are: tensor([2.6496e-02, 1.9925e-05, 3.0858e-02, 1.8323e-03, 7.3581e-03, 5.5843e-01,
        2.0914e-01, 1.6586e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,251][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.7053, 0.0250, 0.0551, 0.0111, 0.0087, 0.0556, 0.0203, 0.0295, 0.0892],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,252][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0788, 0.1217, 0.1279, 0.1227, 0.1316, 0.1079, 0.1086, 0.0735, 0.1273],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,252][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0489, 0.1072, 0.0937, 0.1132, 0.1552, 0.1281, 0.1276, 0.1022, 0.1239],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,253][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ the] are: tensor([1.6212e-05, 6.8297e-10, 1.4022e-04, 1.3756e-04, 1.5696e-05, 4.0269e-02,
        1.3687e-02, 3.7801e-01, 5.6772e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,254][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0943, 0.1613, 0.1404, 0.0096, 0.0274, 0.2283, 0.0081, 0.0273, 0.3032],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,256][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.2609, 0.0658, 0.0870, 0.0973, 0.0862, 0.0980, 0.1183, 0.0833, 0.1032],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,257][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0096, 0.2473, 0.1018, 0.1490, 0.1133, 0.1121, 0.1104, 0.0638, 0.0926],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,258][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ the] are: tensor([2.0492e-05, 5.5553e-09, 2.1876e-04, 1.3652e-04, 5.3976e-05, 1.2003e-01,
        3.4014e-02, 7.5763e-02, 7.6977e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,260][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0515, 0.0785, 0.0312, 0.0344, 0.0877, 0.0052, 0.2483, 0.4519, 0.0114],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,260][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ the] are: tensor([5.8280e-02, 1.1807e-05, 1.5396e-02, 4.3412e-03, 5.0512e-03, 2.6837e-01,
        5.7875e-02, 1.3009e-01, 4.6058e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,262][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1517, 0.1146, 0.1151, 0.1064, 0.0948, 0.1110, 0.1091, 0.0806, 0.1169],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,263][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ the] are: tensor([3.4097e-02, 1.2225e-05, 8.7197e-03, 1.0327e-03, 1.5125e-03, 2.6172e-01,
        1.3231e-01, 1.4659e-01, 4.1401e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,264][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([0.8614, 0.0151, 0.0276, 0.0034, 0.0030, 0.0230, 0.0094, 0.0161, 0.0360,
        0.0050], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,266][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([0.0606, 0.1123, 0.1172, 0.1266, 0.1205, 0.1017, 0.0945, 0.0688, 0.1149,
        0.0830], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,267][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([0.0513, 0.0929, 0.0824, 0.0994, 0.1373, 0.1195, 0.0987, 0.0971, 0.1343,
        0.0870], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,268][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([7.1655e-05, 2.3518e-09, 3.7209e-04, 1.2072e-04, 3.3687e-05, 3.7744e-02,
        8.0416e-03, 1.7176e-01, 5.3657e-01, 2.4529e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,269][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([7.0998e-03, 7.3133e-01, 5.6999e-02, 2.9297e-02, 4.7364e-02, 2.1354e-02,
        4.6900e-02, 1.5364e-02, 4.3578e-02, 7.1243e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,270][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([0.2312, 0.0586, 0.0818, 0.0862, 0.0897, 0.0910, 0.1096, 0.0758, 0.1051,
        0.0710], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,272][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.0202, 0.1627, 0.0969, 0.1710, 0.1130, 0.0885, 0.0691, 0.0893, 0.1140,
        0.0753], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,273][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([4.8655e-05, 1.2978e-08, 3.0521e-04, 2.2423e-04, 5.6085e-05, 4.0102e-02,
        8.0756e-03, 8.3186e-02, 7.6515e-01, 1.0285e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,274][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.0525, 0.0089, 0.0569, 0.0309, 0.0524, 0.0060, 0.0228, 0.7528, 0.0150,
        0.0019], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,275][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([2.7596e-02, 2.0128e-05, 1.1548e-02, 2.4838e-03, 3.2885e-03, 1.2704e-01,
        3.0897e-02, 4.0241e-01, 2.2228e-01, 1.7243e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,276][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([0.1516, 0.1040, 0.1083, 0.0902, 0.0865, 0.0941, 0.1021, 0.0769, 0.1012,
        0.0851], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,276][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([3.2142e-02, 1.8287e-05, 1.0055e-02, 1.2104e-03, 1.5137e-03, 1.2658e-01,
        5.6876e-02, 1.4508e-01, 5.1027e-01, 1.1625e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,277][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6309, 0.0271, 0.0582, 0.0092, 0.0089, 0.0521, 0.0198, 0.0337, 0.0706,
        0.0095, 0.0798], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,277][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0633, 0.0989, 0.1086, 0.1060, 0.1050, 0.0944, 0.0805, 0.0599, 0.1111,
        0.0785, 0.0938], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,278][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0327, 0.0873, 0.0763, 0.0923, 0.1274, 0.1059, 0.0929, 0.0771, 0.1088,
        0.0767, 0.1225], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,278][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([1.0348e-05, 6.8786e-11, 1.5316e-05, 1.0327e-05, 2.1519e-06, 1.6786e-02,
        2.2653e-03, 1.8877e-02, 1.9547e-01, 3.9969e-01, 3.6688e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,279][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1448, 0.1493, 0.1549, 0.0029, 0.0543, 0.1378, 0.0883, 0.0332, 0.1574,
        0.0013, 0.0758], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,281][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2331, 0.0543, 0.0748, 0.0794, 0.0733, 0.0847, 0.0956, 0.0677, 0.0953,
        0.0700, 0.0719], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,282][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0135, 0.1924, 0.0680, 0.1233, 0.0808, 0.0967, 0.0798, 0.0457, 0.1461,
        0.0937, 0.0599], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,283][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([9.9924e-06, 1.8698e-09, 2.7316e-05, 2.5120e-05, 1.1582e-05, 1.9812e-02,
        5.3127e-03, 1.8963e-02, 3.4992e-01, 3.0351e-01, 3.0240e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,284][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0487, 0.0346, 0.0248, 0.0488, 0.1909, 0.0418, 0.0449, 0.2799, 0.1684,
        0.0957, 0.0215], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,285][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([2.1622e-02, 7.3459e-06, 4.8220e-03, 2.5516e-03, 4.4645e-04, 1.4160e-01,
        1.2025e-02, 3.2379e-02, 3.0826e-01, 1.8084e-01, 2.9545e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,287][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1297, 0.0921, 0.1042, 0.0830, 0.0774, 0.0904, 0.0879, 0.0715, 0.0945,
        0.0762, 0.0932], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,288][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.1636e-02, 3.4070e-06, 4.4975e-03, 2.6969e-04, 8.3572e-04, 9.6647e-02,
        2.4149e-02, 6.0485e-02, 3.1840e-01, 2.3087e-01, 2.5220e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,289][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.7818, 0.0316, 0.0285, 0.0042, 0.0040, 0.0209, 0.0115, 0.0191, 0.0314,
        0.0041, 0.0439, 0.0191], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,291][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.0555, 0.0825, 0.0972, 0.0997, 0.0945, 0.0856, 0.0769, 0.0584, 0.0993,
        0.0726, 0.0867, 0.0911], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,292][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.0410, 0.0678, 0.0716, 0.0765, 0.1037, 0.0896, 0.0789, 0.0675, 0.0904,
        0.0624, 0.1294, 0.1213], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,293][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([1.2076e-04, 9.4295e-10, 6.1540e-05, 4.1122e-05, 3.6141e-05, 7.8895e-03,
        2.4110e-03, 1.7400e-02, 7.0756e-02, 2.5519e-01, 3.8807e-01, 2.5803e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,295][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.0311, 0.0006, 0.0914, 0.2566, 0.0364, 0.0728, 0.1918, 0.0251, 0.0618,
        0.1791, 0.0526, 0.0004], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,296][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.1912, 0.0474, 0.0734, 0.0730, 0.0761, 0.0864, 0.0945, 0.0696, 0.0927,
        0.0701, 0.0735, 0.0518], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,298][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.0081, 0.1332, 0.0780, 0.1063, 0.0913, 0.0954, 0.0691, 0.0645, 0.0926,
        0.0783, 0.0773, 0.1058], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,299][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([8.9694e-05, 2.7944e-09, 8.1725e-05, 5.0350e-05, 4.9729e-05, 1.7156e-02,
        6.5218e-03, 1.6244e-02, 1.5033e-01, 2.0280e-01, 4.9282e-01, 1.1385e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,300][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.0606, 0.0015, 0.0313, 0.0129, 0.0205, 0.0114, 0.0205, 0.7378, 0.0323,
        0.0142, 0.0457, 0.0113], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,301][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([8.6403e-02, 1.9719e-05, 4.3352e-03, 2.0101e-03, 8.2928e-04, 8.0461e-02,
        1.5166e-02, 2.1440e-02, 1.9074e-01, 6.6615e-02, 2.9367e-01, 2.3831e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,302][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.1235, 0.0873, 0.0893, 0.0833, 0.0732, 0.0826, 0.0850, 0.0641, 0.0894,
        0.0680, 0.0787, 0.0757], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,302][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([5.0151e-02, 9.7291e-06, 3.2683e-03, 5.1108e-04, 1.0731e-03, 8.3065e-02,
        3.8376e-02, 4.7814e-02, 2.1419e-01, 1.9208e-01, 2.5995e-01, 1.0951e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,303][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.7293, 0.0145, 0.0392, 0.0057, 0.0062, 0.0323, 0.0085, 0.0215, 0.0507,
        0.0039, 0.0562, 0.0108, 0.0212], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,303][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0556, 0.0806, 0.0937, 0.0881, 0.0832, 0.0811, 0.0659, 0.0488, 0.1018,
        0.0644, 0.0809, 0.0855, 0.0705], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,303][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0294, 0.0626, 0.0538, 0.0667, 0.0814, 0.0712, 0.0684, 0.0553, 0.0767,
        0.0540, 0.1052, 0.1235, 0.1521], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,304][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([2.8135e-06, 1.1334e-10, 5.4328e-05, 1.8174e-05, 3.3273e-06, 4.4795e-03,
        1.0885e-03, 9.6497e-03, 6.8663e-02, 1.7326e-01, 6.2582e-01, 1.1310e-01,
        3.8565e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,304][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.1316, 0.1291, 0.0494, 0.0302, 0.1024, 0.1209, 0.0567, 0.0629, 0.0902,
        0.0590, 0.0429, 0.1099, 0.0147], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,306][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.1696, 0.0436, 0.0671, 0.0752, 0.0670, 0.0725, 0.0889, 0.0628, 0.0848,
        0.0712, 0.0648, 0.0518, 0.0807], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,307][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0127, 0.2549, 0.0301, 0.1215, 0.0322, 0.0505, 0.0732, 0.0303, 0.0637,
        0.0996, 0.0299, 0.1887, 0.0126], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,308][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([1.3553e-06, 1.5512e-09, 4.0689e-05, 4.8951e-05, 6.7640e-06, 1.0724e-02,
        2.5462e-03, 1.0897e-02, 7.8379e-02, 1.3762e-01, 2.8949e-01, 4.6312e-01,
        7.1210e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,310][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0398, 0.0184, 0.0475, 0.0231, 0.0433, 0.0141, 0.0413, 0.3290, 0.0218,
        0.2392, 0.0530, 0.1279, 0.0015], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,310][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([1.7708e-02, 7.6367e-06, 7.8624e-03, 8.1044e-04, 1.3737e-03, 1.0489e-01,
        3.4220e-03, 2.7815e-02, 1.5324e-01, 6.6779e-02, 5.0685e-01, 7.6990e-02,
        3.2244e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,312][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.1137, 0.0831, 0.0876, 0.0724, 0.0634, 0.0765, 0.0816, 0.0585, 0.0818,
        0.0683, 0.0777, 0.0709, 0.0644], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,313][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([6.7413e-03, 2.4700e-06, 6.3827e-03, 1.8973e-04, 5.9692e-04, 1.1403e-01,
        2.7995e-02, 4.7335e-02, 1.8426e-01, 1.3235e-01, 4.0117e-01, 3.7940e-02,
        4.1002e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,314][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.5947, 0.0213, 0.0453, 0.0101, 0.0082, 0.0464, 0.0147, 0.0293, 0.0595,
        0.0071, 0.0635, 0.0169, 0.0148, 0.0682], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,316][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0518, 0.0750, 0.0803, 0.0809, 0.0817, 0.0716, 0.0710, 0.0487, 0.0839,
        0.0649, 0.0750, 0.0806, 0.0812, 0.0534], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,317][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0305, 0.0567, 0.0477, 0.0596, 0.0814, 0.0650, 0.0610, 0.0472, 0.0677,
        0.0490, 0.0874, 0.1055, 0.1545, 0.0867], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,318][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([2.3082e-05, 9.9566e-12, 5.6803e-06, 1.4400e-06, 2.3850e-06, 4.6017e-03,
        7.2338e-04, 3.5195e-03, 3.4757e-02, 6.7397e-02, 1.8383e-01, 5.8988e-02,
        4.3005e-02, 6.0314e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,320][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0704, 0.0916, 0.0855, 0.0025, 0.1116, 0.1478, 0.0544, 0.0700, 0.1469,
        0.0060, 0.0502, 0.1110, 0.0193, 0.0329], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,321][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2029, 0.0436, 0.0580, 0.0627, 0.0597, 0.0678, 0.0796, 0.0548, 0.0732,
        0.0568, 0.0599, 0.0515, 0.0708, 0.0588], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,323][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0067, 0.1681, 0.0536, 0.0948, 0.0664, 0.0713, 0.0567, 0.0335, 0.0838,
        0.0732, 0.0712, 0.1524, 0.0476, 0.0205], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,324][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([7.6417e-06, 3.8161e-10, 6.5139e-06, 5.0259e-06, 1.5121e-06, 3.9452e-03,
        1.7165e-03, 3.0901e-03, 5.6769e-02, 9.2693e-02, 1.4189e-01, 2.5952e-01,
        2.9903e-02, 4.1046e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,325][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0168, 0.0287, 0.0386, 0.0061, 0.0581, 0.0081, 0.0221, 0.0392, 0.1209,
        0.2158, 0.1710, 0.2429, 0.0270, 0.0047], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,326][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([3.7087e-02, 2.6696e-06, 3.0359e-03, 9.4364e-04, 8.9091e-04, 6.7850e-02,
        6.9452e-03, 5.8769e-03, 1.0531e-01, 2.0787e-02, 2.7181e-01, 6.8646e-02,
        1.6478e-01, 2.4605e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,328][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1068, 0.0739, 0.0809, 0.0695, 0.0653, 0.0735, 0.0760, 0.0627, 0.0757,
        0.0637, 0.0741, 0.0636, 0.0600, 0.0543], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,329][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.4475e-02, 1.0815e-06, 1.3873e-03, 1.0336e-04, 4.0317e-04, 3.4591e-02,
        1.8536e-02, 2.4711e-02, 1.2801e-01, 9.3511e-02, 1.6432e-01, 4.3745e-02,
        1.6208e-01, 3.1413e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,330][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.6557, 0.0115, 0.0437, 0.0064, 0.0070, 0.0381, 0.0107, 0.0214, 0.0440,
        0.0054, 0.0572, 0.0085, 0.0086, 0.0565, 0.0254], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,332][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0406, 0.0698, 0.0773, 0.0757, 0.0756, 0.0701, 0.0602, 0.0466, 0.0829,
        0.0553, 0.0727, 0.0789, 0.0794, 0.0507, 0.0643], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,332][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0328, 0.0498, 0.0445, 0.0488, 0.0623, 0.0565, 0.0491, 0.0423, 0.0582,
        0.0397, 0.0783, 0.0869, 0.1238, 0.0895, 0.1375], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,333][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ give] are: tensor([1.1010e-05, 3.9445e-11, 8.3012e-06, 1.6902e-06, 2.8797e-07, 1.1491e-03,
        3.7257e-04, 1.9868e-03, 1.5737e-02, 3.6614e-02, 1.2749e-01, 3.9220e-02,
        5.0261e-03, 7.3075e-01, 4.1635e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,333][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0359, 0.1605, 0.0514, 0.0352, 0.0811, 0.0376, 0.0653, 0.0234, 0.0656,
        0.0036, 0.0386, 0.1377, 0.2052, 0.0372, 0.0215], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,334][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.1621, 0.0403, 0.0587, 0.0593, 0.0619, 0.0651, 0.0778, 0.0538, 0.0715,
        0.0564, 0.0580, 0.0461, 0.0723, 0.0576, 0.0591], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,334][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0112, 0.1348, 0.0565, 0.0978, 0.0466, 0.0800, 0.0379, 0.0758, 0.1034,
        0.0823, 0.0623, 0.1160, 0.0354, 0.0425, 0.0175], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,335][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ give] are: tensor([8.9542e-06, 1.2178e-09, 1.3727e-05, 9.0267e-06, 1.0395e-06, 5.1252e-03,
        1.3156e-03, 2.3923e-03, 3.4919e-02, 4.5839e-02, 1.6323e-01, 2.3188e-01,
        1.0256e-02, 4.6120e-01, 4.3809e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,335][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0833, 0.0140, 0.0210, 0.0248, 0.0900, 0.0052, 0.0294, 0.2410, 0.0267,
        0.0527, 0.0679, 0.1277, 0.1350, 0.0789, 0.0026], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,336][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ give] are: tensor([1.1679e-02, 3.4136e-06, 2.8301e-03, 5.5023e-04, 2.7313e-04, 4.2695e-02,
        9.5044e-03, 1.2015e-02, 5.4543e-02, 4.2735e-02, 1.6717e-01, 4.1884e-02,
        1.2186e-01, 4.8159e-01, 1.0670e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,337][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.1013, 0.0733, 0.0763, 0.0640, 0.0641, 0.0727, 0.0717, 0.0540, 0.0720,
        0.0592, 0.0684, 0.0622, 0.0585, 0.0489, 0.0534], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,338][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ give] are: tensor([9.9451e-03, 2.8240e-06, 1.5729e-03, 9.5028e-05, 1.8675e-04, 2.2802e-02,
        1.3261e-02, 2.4301e-02, 7.1806e-02, 7.7660e-02, 1.6862e-01, 4.7100e-02,
        9.9465e-02, 3.8756e-01, 7.5624e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,340][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.6015, 0.0128, 0.0416, 0.0055, 0.0058, 0.0420, 0.0109, 0.0185, 0.0659,
        0.0052, 0.0551, 0.0109, 0.0110, 0.0458, 0.0107, 0.0567],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,341][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.0390, 0.0661, 0.0701, 0.0709, 0.0701, 0.0605, 0.0575, 0.0399, 0.0748,
        0.0575, 0.0667, 0.0720, 0.0653, 0.0449, 0.0610, 0.0836],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,342][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0249, 0.0386, 0.0379, 0.0421, 0.0590, 0.0499, 0.0460, 0.0405, 0.0515,
        0.0353, 0.0700, 0.0735, 0.1179, 0.0784, 0.1372, 0.0972],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,343][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ it] are: tensor([1.3844e-05, 1.9279e-11, 2.7221e-06, 7.1339e-07, 9.0961e-07, 1.1962e-03,
        2.9223e-04, 2.9784e-03, 9.7636e-03, 2.3482e-02, 5.1843e-02, 4.6764e-02,
        1.5435e-02, 5.5108e-01, 2.0068e-01, 9.6469e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,345][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.0648, 0.1480, 0.0963, 0.0023, 0.0130, 0.1232, 0.0303, 0.0072, 0.1324,
        0.0049, 0.0515, 0.1775, 0.0391, 0.0045, 0.0194, 0.0856],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,346][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.1570, 0.0389, 0.0553, 0.0562, 0.0523, 0.0654, 0.0682, 0.0515, 0.0720,
        0.0520, 0.0549, 0.0446, 0.0641, 0.0543, 0.0534, 0.0602],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,348][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.0085, 0.2059, 0.0472, 0.0739, 0.0406, 0.0600, 0.0552, 0.0411, 0.0633,
        0.0712, 0.0603, 0.1586, 0.0292, 0.0295, 0.0208, 0.0347],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,349][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ it] are: tensor([1.2944e-05, 6.9524e-10, 4.7609e-06, 1.7566e-06, 1.3071e-06, 1.9068e-03,
        4.7654e-04, 1.5076e-03, 1.7446e-02, 2.4881e-02, 4.8477e-02, 2.5151e-01,
        1.8065e-02, 2.7180e-01, 1.4616e-01, 2.1775e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,350][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0193, 0.0140, 0.0097, 0.0139, 0.0370, 0.0021, 0.0329, 0.2169, 0.0029,
        0.1765, 0.0362, 0.1328, 0.0456, 0.0378, 0.2201, 0.0025],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,351][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ it] are: tensor([3.8292e-02, 4.4395e-06, 1.4451e-03, 4.8032e-04, 5.5219e-04, 2.5245e-02,
        9.8804e-03, 1.2002e-02, 5.6703e-02, 4.7024e-02, 1.1007e-01, 5.8317e-02,
        5.5888e-02, 3.7539e-01, 1.0771e-01, 1.0100e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,353][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.0953, 0.0696, 0.0728, 0.0647, 0.0560, 0.0653, 0.0665, 0.0515, 0.0720,
        0.0541, 0.0640, 0.0581, 0.0553, 0.0455, 0.0480, 0.0613],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,354][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ it] are: tensor([2.1470e-02, 1.8419e-06, 8.2020e-04, 8.9780e-05, 1.8370e-04, 2.0887e-02,
        1.5667e-02, 1.4289e-02, 4.9953e-02, 5.1437e-02, 8.6282e-02, 3.2341e-02,
        5.1808e-02, 2.9325e-01, 2.5505e-01, 1.0647e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,355][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.5159, 0.0196, 0.0417, 0.0092, 0.0075, 0.0415, 0.0129, 0.0267, 0.0540,
        0.0064, 0.0583, 0.0159, 0.0142, 0.0616, 0.0142, 0.0306, 0.0698],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,357][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0420, 0.0598, 0.0651, 0.0652, 0.0661, 0.0581, 0.0582, 0.0397, 0.0678,
        0.0529, 0.0605, 0.0649, 0.0666, 0.0431, 0.0624, 0.0845, 0.0430],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,358][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0259, 0.0399, 0.0347, 0.0411, 0.0576, 0.0456, 0.0433, 0.0330, 0.0464,
        0.0343, 0.0621, 0.0704, 0.1044, 0.0598, 0.1303, 0.1017, 0.0695],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,359][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.2879e-05, 2.7895e-12, 9.4717e-07, 2.5331e-07, 4.2848e-07, 9.1864e-04,
        1.3324e-04, 4.9946e-04, 5.5054e-03, 1.0412e-02, 2.2990e-02, 1.0228e-02,
        7.1879e-03, 8.8027e-02, 1.2783e-01, 2.6606e-01, 4.6019e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,359][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0577, 0.0785, 0.0740, 0.0023, 0.0983, 0.1271, 0.0485, 0.0541, 0.1284,
        0.0048, 0.0425, 0.0929, 0.0182, 0.0268, 0.0470, 0.0726, 0.0264],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,360][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1757, 0.0364, 0.0490, 0.0521, 0.0505, 0.0573, 0.0665, 0.0463, 0.0615,
        0.0478, 0.0506, 0.0429, 0.0596, 0.0499, 0.0513, 0.0551, 0.0474],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,360][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0056, 0.1539, 0.0478, 0.0814, 0.0575, 0.0675, 0.0523, 0.0297, 0.0792,
        0.0665, 0.0632, 0.1393, 0.0394, 0.0188, 0.0240, 0.0582, 0.0157],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,361][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([4.2557e-06, 8.4544e-11, 1.1337e-06, 7.1629e-07, 2.1154e-07, 6.1861e-04,
        2.3759e-04, 4.4263e-04, 8.3482e-03, 1.3039e-02, 1.9838e-02, 3.5755e-02,
        4.2163e-03, 5.4470e-02, 9.1885e-02, 5.1863e-01, 2.5252e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,361][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0144, 0.0216, 0.0288, 0.0046, 0.0441, 0.0060, 0.0174, 0.0296, 0.0893,
        0.1652, 0.1382, 0.1866, 0.0209, 0.0036, 0.0309, 0.1955, 0.0032],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,362][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([4.1789e-02, 1.8325e-06, 1.4688e-03, 3.9023e-04, 4.0561e-04, 2.7553e-02,
        4.1058e-03, 3.1913e-03, 4.4214e-02, 1.0605e-02, 1.2526e-01, 3.4715e-02,
        7.6310e-02, 1.0478e-01, 9.8061e-02, 2.3299e-01, 1.9416e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,363][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0913, 0.0629, 0.0687, 0.0589, 0.0557, 0.0624, 0.0647, 0.0531, 0.0643,
        0.0542, 0.0630, 0.0540, 0.0510, 0.0461, 0.0479, 0.0569, 0.0449],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,364][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.8084e-02, 8.6783e-07, 6.2566e-04, 5.2145e-05, 2.0163e-04, 1.5678e-02,
        9.1921e-03, 1.0793e-02, 5.5873e-02, 4.1221e-02, 7.5869e-02, 2.5619e-02,
        7.1084e-02, 1.2520e-01, 2.1201e-01, 1.0338e-01, 2.3511e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,396][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:26,397][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,398][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,399][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,401][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,402][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,403][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,404][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,405][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,406][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,407][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,408][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,410][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,411][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.4909, 0.5091], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,411][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.7250, 0.2750], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,411][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.1761, 0.8239], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,412][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.0360, 0.9640], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,412][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.6022, 0.3978], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,412][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.5268, 0.4732], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,413][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.3517, 0.6483], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,413][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.9954, 0.0046], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,413][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.4930, 0.5070], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,414][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.0717, 0.9283], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,415][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.5501, 0.4499], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,416][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.5218, 0.4782], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,418][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3063, 0.3386, 0.3551], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,419][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.5820, 0.1304, 0.2877], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,420][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0736, 0.3859, 0.5405], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,421][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([2.3562e-05, 1.6049e-07, 9.9998e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,422][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.4120, 0.2826, 0.3054], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,424][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3437, 0.3175, 0.3388], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,425][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2235, 0.4089, 0.3676], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,427][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.6353, 0.0809, 0.2838], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,428][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2334, 0.4167, 0.3499], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,430][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0387, 0.4424, 0.5190], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,431][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.3761, 0.2947, 0.3293], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,432][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2932, 0.3274, 0.3794], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,434][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Nathan] are: tensor([0.2079, 0.2623, 0.2567, 0.2731], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,435][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Nathan] are: tensor([0.4440, 0.0800, 0.1948, 0.2812], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,437][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Nathan] are: tensor([0.0358, 0.1803, 0.3814, 0.4025], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,437][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Nathan] are: tensor([5.8057e-06, 7.2392e-08, 9.9171e-01, 8.2837e-03], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,437][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Nathan] are: tensor([0.3168, 0.2154, 0.2330, 0.2348], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,438][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Nathan] are: tensor([0.2533, 0.2286, 0.2468, 0.2712], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,438][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Nathan] are: tensor([0.1463, 0.2902, 0.2546, 0.3089], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,439][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Nathan] are: tensor([0.7401, 0.0020, 0.2387, 0.0192], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,439][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Nathan] are: tensor([0.1963, 0.2904, 0.3280, 0.1854], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,439][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Nathan] are: tensor([0.0170, 0.2401, 0.3107, 0.4322], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,440][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Nathan] are: tensor([0.2740, 0.2564, 0.2457, 0.2239], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,440][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Nathan] are: tensor([0.2350, 0.2291, 0.2945, 0.2414], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,441][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.2051, 0.2096, 0.2044, 0.2188, 0.1621], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,443][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.3184, 0.0700, 0.1684, 0.2473, 0.1959], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,444][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.0238, 0.1484, 0.2374, 0.3143, 0.2761], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,445][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([2.7531e-06, 3.8311e-08, 9.0792e-01, 8.1813e-02, 1.0261e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,446][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.2615, 0.1736, 0.1887, 0.1898, 0.1864], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,448][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.2075, 0.1831, 0.1983, 0.2163, 0.1948], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,449][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.1125, 0.2178, 0.1956, 0.2629, 0.2113], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,450][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.5615, 0.0013, 0.0737, 0.3621, 0.0014], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,452][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.1466, 0.2075, 0.2820, 0.1791, 0.1849], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,453][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.0096, 0.1873, 0.2421, 0.3362, 0.2249], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,455][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.2551, 0.2169, 0.2136, 0.1698, 0.1446], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,456][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.2108, 0.1725, 0.2440, 0.2056, 0.1671], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,458][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1463, 0.1428, 0.1565, 0.1648, 0.1236, 0.2660], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,459][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.2849, 0.0593, 0.1408, 0.2068, 0.1739, 0.1343], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,460][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0143, 0.1103, 0.1887, 0.2672, 0.2840, 0.1355], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,461][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([2.2315e-05, 3.4505e-09, 3.9276e-03, 8.6949e-04, 3.5216e-04, 9.9483e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,463][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.2181, 0.1474, 0.1598, 0.1605, 0.1577, 0.1565], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,463][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1704, 0.1522, 0.1642, 0.1804, 0.1647, 0.1679], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,464][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0911, 0.1758, 0.1697, 0.2005, 0.1804, 0.1825], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,464][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0414, 0.0011, 0.0424, 0.4435, 0.4673, 0.0043], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,464][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1173, 0.2134, 0.2058, 0.1610, 0.2020, 0.1005], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,465][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0092, 0.1638, 0.2009, 0.2726, 0.2000, 0.1535], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,465][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1949, 0.1780, 0.1775, 0.1613, 0.1178, 0.1705], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,466][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1454, 0.1944, 0.2094, 0.1899, 0.1403, 0.1205], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,466][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.1425, 0.1326, 0.1351, 0.1396, 0.1063, 0.2128, 0.1310],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,466][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.2793, 0.0482, 0.1258, 0.1665, 0.1503, 0.1149, 0.1149],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,468][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.0157, 0.0736, 0.1475, 0.1889, 0.2554, 0.1819, 0.1371],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,468][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([1.9014e-05, 2.2044e-08, 1.0400e-02, 1.4405e-03, 7.7097e-04, 9.2888e-01,
        5.8487e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,470][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.1888, 0.1288, 0.1389, 0.1394, 0.1366, 0.1357, 0.1318],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,471][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.1410, 0.1294, 0.1410, 0.1537, 0.1425, 0.1460, 0.1463],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,473][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.0795, 0.1477, 0.1391, 0.1739, 0.1509, 0.1626, 0.1463],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,474][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.2653, 0.0021, 0.0892, 0.1850, 0.1194, 0.3362, 0.0030],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,475][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.1274, 0.1540, 0.1895, 0.1424, 0.1958, 0.1050, 0.0860],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,477][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.0086, 0.1303, 0.1878, 0.2454, 0.1816, 0.1422, 0.1041],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,478][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.1889, 0.1532, 0.1560, 0.1192, 0.1055, 0.1385, 0.1387],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,480][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.1316, 0.1225, 0.1723, 0.1721, 0.1480, 0.1252, 0.1283],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,481][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.1174, 0.1123, 0.1203, 0.1275, 0.0933, 0.2111, 0.1130, 0.1050],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,483][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.2041, 0.0478, 0.1077, 0.1572, 0.1401, 0.1075, 0.1216, 0.1138],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,484][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0157, 0.0734, 0.1326, 0.1537, 0.1721, 0.1519, 0.1668, 0.1339],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,485][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([3.7762e-05, 7.9090e-10, 1.7050e-03, 4.4208e-04, 2.5924e-04, 3.4186e-01,
        5.3993e-02, 6.0170e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,486][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.1674, 0.1137, 0.1231, 0.1234, 0.1211, 0.1202, 0.1165, 0.1145],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,488][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.1252, 0.1142, 0.1227, 0.1359, 0.1244, 0.1268, 0.1291, 0.1218],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,489][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0674, 0.1334, 0.1230, 0.1493, 0.1353, 0.1411, 0.1427, 0.1078],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,490][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([3.3421e-02, 3.4602e-04, 1.5712e-03, 3.0635e-02, 9.2262e-02, 1.1226e-02,
        8.2977e-01, 7.6886e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,490][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0757, 0.1579, 0.1432, 0.1133, 0.1348, 0.0864, 0.1188, 0.1700],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,490][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0068, 0.1124, 0.1524, 0.2208, 0.1492, 0.1355, 0.1018, 0.1212],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,491][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.1652, 0.1411, 0.1476, 0.1111, 0.0830, 0.1122, 0.1230, 0.1169],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,491][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0908, 0.1039, 0.1461, 0.1261, 0.1257, 0.1130, 0.1703, 0.1240],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,492][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1031, 0.0903, 0.1017, 0.1071, 0.0819, 0.1806, 0.0919, 0.0909, 0.1525],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,492][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1894, 0.0411, 0.0977, 0.1453, 0.1254, 0.0949, 0.1084, 0.0997, 0.0982],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,492][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0095, 0.0607, 0.1024, 0.1485, 0.1745, 0.0955, 0.1480, 0.1770, 0.0838],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,493][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([1.6212e-05, 6.8297e-10, 1.4022e-04, 1.3756e-04, 1.5696e-05, 4.0269e-02,
        1.3687e-02, 3.7801e-01, 5.6772e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,495][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1488, 0.1022, 0.1104, 0.1106, 0.1085, 0.1079, 0.1046, 0.1029, 0.1043],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,496][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1119, 0.1018, 0.1093, 0.1215, 0.1103, 0.1121, 0.1145, 0.1078, 0.1108],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,497][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0581, 0.1179, 0.1101, 0.1307, 0.1156, 0.1248, 0.1240, 0.0998, 0.1190],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,498][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([2.8431e-03, 3.0272e-04, 2.6410e-03, 2.6320e-02, 1.4309e-01, 5.6951e-03,
        8.0477e-01, 1.3767e-02, 5.7097e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,500][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0661, 0.1367, 0.1305, 0.1097, 0.1292, 0.0751, 0.0949, 0.1923, 0.0655],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,501][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0064, 0.1130, 0.1354, 0.2020, 0.1255, 0.1064, 0.0835, 0.1162, 0.1115],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,501][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1392, 0.1225, 0.1202, 0.1062, 0.0873, 0.1095, 0.1084, 0.0866, 0.1200],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,502][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0755, 0.1035, 0.1276, 0.1067, 0.0933, 0.0958, 0.1806, 0.1416, 0.0754],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,502][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([0.1143, 0.0968, 0.0935, 0.1012, 0.0708, 0.1834, 0.0934, 0.0737, 0.1496,
        0.0233], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,503][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([0.1671, 0.0415, 0.0896, 0.1228, 0.1105, 0.0827, 0.0960, 0.0925, 0.0861,
        0.1112], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,503][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([0.0102, 0.0434, 0.0929, 0.1123, 0.1624, 0.0930, 0.1080, 0.1728, 0.0890,
        0.1159], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,504][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([7.1655e-05, 2.3518e-09, 3.7209e-04, 1.2072e-04, 3.3687e-05, 3.7744e-02,
        8.0416e-03, 1.7176e-01, 5.3657e-01, 2.4529e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,505][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([0.1363, 0.0927, 0.1002, 0.1006, 0.0985, 0.0978, 0.0948, 0.0932, 0.0944,
        0.0916], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,507][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([0.1003, 0.0907, 0.0990, 0.1080, 0.0981, 0.1006, 0.1023, 0.0975, 0.1003,
        0.1030], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,508][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([0.0551, 0.1016, 0.0990, 0.1198, 0.1057, 0.1096, 0.1052, 0.0921, 0.1093,
        0.1025], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,509][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([2.6532e-02, 1.2212e-03, 2.5356e-02, 5.4688e-02, 6.2103e-02, 1.3139e-02,
        1.3995e-02, 7.9446e-01, 7.7835e-03, 7.2394e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,511][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([0.0697, 0.1080, 0.1373, 0.1007, 0.1238, 0.0637, 0.0732, 0.2094, 0.0579,
        0.0565], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,512][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([0.0059, 0.1063, 0.1246, 0.1721, 0.1077, 0.0909, 0.0716, 0.1219, 0.0995,
        0.0995], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,513][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([0.1392, 0.1084, 0.1125, 0.0849, 0.0786, 0.0884, 0.1022, 0.0861, 0.1008,
        0.0989], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,515][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([0.0762, 0.0749, 0.1151, 0.1012, 0.0975, 0.0892, 0.1452, 0.1458, 0.0866,
        0.0683], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,516][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0939, 0.0781, 0.0888, 0.0901, 0.0688, 0.1569, 0.0783, 0.0781, 0.1332,
        0.0224, 0.1114], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,518][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1429, 0.0382, 0.0830, 0.1325, 0.1063, 0.0803, 0.0906, 0.0810, 0.0800,
        0.1097, 0.0556], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,518][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0083, 0.0429, 0.0786, 0.1075, 0.1336, 0.0966, 0.0841, 0.1429, 0.1000,
        0.1105, 0.0950], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,519][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([1.0348e-05, 6.8786e-11, 1.5316e-05, 1.0327e-05, 2.1519e-06, 1.6786e-02,
        2.2653e-03, 1.8877e-02, 1.9547e-01, 3.9969e-01, 3.6688e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,519][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1237, 0.0848, 0.0917, 0.0919, 0.0902, 0.0896, 0.0869, 0.0854, 0.0866,
        0.0840, 0.0852], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,520][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0907, 0.0832, 0.0894, 0.0990, 0.0902, 0.0922, 0.0938, 0.0884, 0.0911,
        0.0938, 0.0882], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,520][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0480, 0.0931, 0.0866, 0.1062, 0.0922, 0.1009, 0.0988, 0.0801, 0.1034,
        0.0995, 0.0911], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,521][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([2.0433e-03, 2.0044e-04, 3.5512e-03, 6.0214e-02, 3.6018e-01, 1.0036e-01,
        8.5121e-02, 1.0352e-01, 2.4327e-01, 2.9359e-02, 1.2177e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,521][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0647, 0.1043, 0.0977, 0.0953, 0.1127, 0.0694, 0.0645, 0.1430, 0.0627,
        0.0758, 0.1099], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,521][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0061, 0.1035, 0.1124, 0.1753, 0.0957, 0.0920, 0.0684, 0.0939, 0.0985,
        0.0931, 0.0611], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,523][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1192, 0.0935, 0.1112, 0.0773, 0.0680, 0.0855, 0.0832, 0.0782, 0.0932,
        0.0851, 0.1056], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,524][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0756, 0.0827, 0.1029, 0.0907, 0.0787, 0.0863, 0.1179, 0.1178, 0.0806,
        0.0828, 0.0840], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,525][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.1000, 0.0887, 0.0808, 0.0891, 0.0647, 0.1370, 0.0794, 0.0658, 0.1139,
        0.0235, 0.0882, 0.0689], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,527][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.1447, 0.0340, 0.0739, 0.1090, 0.0949, 0.0692, 0.0902, 0.0706, 0.0724,
        0.1049, 0.0540, 0.0823], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,528][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.0078, 0.0294, 0.0681, 0.0831, 0.1294, 0.0809, 0.0852, 0.1435, 0.0802,
        0.1057, 0.1052, 0.0816], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,529][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([1.2076e-04, 9.4295e-10, 6.1540e-05, 4.1122e-05, 3.6141e-05, 7.8895e-03,
        2.4110e-03, 1.7400e-02, 7.0756e-02, 2.5519e-01, 3.8807e-01, 2.5803e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,530][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.1152, 0.0779, 0.0841, 0.0848, 0.0830, 0.0823, 0.0797, 0.0784, 0.0793,
        0.0770, 0.0782, 0.0800], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,532][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.0827, 0.0759, 0.0821, 0.0895, 0.0815, 0.0835, 0.0845, 0.0812, 0.0832,
        0.0862, 0.0813, 0.0884], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,533][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.0422, 0.0819, 0.0803, 0.0957, 0.0880, 0.0938, 0.0888, 0.0756, 0.0903,
        0.0874, 0.0845, 0.0914], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,534][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([1.7328e-02, 4.3783e-06, 2.3124e-02, 1.5239e-02, 2.2421e-01, 7.9843e-03,
        2.3045e-02, 5.1951e-01, 4.6847e-02, 3.8921e-02, 8.3171e-02, 6.1578e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,536][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.0623, 0.0649, 0.1072, 0.0710, 0.0865, 0.0571, 0.0592, 0.1822, 0.0554,
        0.0565, 0.1252, 0.0725], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,537][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.0066, 0.0944, 0.1058, 0.1480, 0.0871, 0.0816, 0.0574, 0.0826, 0.0884,
        0.0790, 0.0592, 0.1099], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,539][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.1154, 0.0903, 0.0914, 0.0810, 0.0657, 0.0778, 0.0822, 0.0701, 0.0884,
        0.0737, 0.0843, 0.0797], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,540][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.0704, 0.0618, 0.0903, 0.0991, 0.0840, 0.0803, 0.0976, 0.1244, 0.0847,
        0.0690, 0.0703, 0.0683], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,542][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0810, 0.0778, 0.0776, 0.0840, 0.0603, 0.1453, 0.0764, 0.0639, 0.1203,
        0.0209, 0.0917, 0.0568, 0.0440], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,543][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.1279, 0.0311, 0.0752, 0.1146, 0.0904, 0.0651, 0.0713, 0.0659, 0.0660,
        0.0876, 0.0494, 0.0778, 0.0778], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,545][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0074, 0.0372, 0.0639, 0.0986, 0.0954, 0.0733, 0.0763, 0.1212, 0.0735,
        0.0991, 0.0940, 0.1056, 0.0545], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,545][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([2.8135e-06, 1.1334e-10, 5.4328e-05, 1.8174e-05, 3.3273e-06, 4.4795e-03,
        1.0885e-03, 9.6497e-03, 6.8663e-02, 1.7326e-01, 6.2582e-01, 1.1310e-01,
        3.8565e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,545][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.1086, 0.0724, 0.0785, 0.0787, 0.0770, 0.0764, 0.0742, 0.0728, 0.0736,
        0.0715, 0.0726, 0.0742, 0.0695], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,546][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.0781, 0.0699, 0.0763, 0.0835, 0.0755, 0.0777, 0.0782, 0.0753, 0.0774,
        0.0791, 0.0749, 0.0813, 0.0729], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,546][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0414, 0.0860, 0.0688, 0.0942, 0.0743, 0.0830, 0.0867, 0.0661, 0.0819,
        0.0895, 0.0729, 0.0968, 0.0585], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,547][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([2.3448e-04, 7.8051e-05, 9.1111e-03, 7.7926e-03, 8.9840e-04, 8.0105e-02,
        1.0726e-02, 5.9603e-01, 5.9751e-02, 1.3475e-02, 1.9008e-01, 3.1707e-02,
        1.2140e-05], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,547][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0655, 0.0833, 0.0934, 0.0685, 0.0834, 0.0522, 0.0539, 0.1376, 0.0451,
        0.0678, 0.1038, 0.0881, 0.0575], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,548][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0067, 0.0990, 0.1114, 0.1413, 0.0867, 0.0766, 0.0472, 0.0793, 0.0808,
        0.0730, 0.0544, 0.0913, 0.0523], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,549][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.1007, 0.0847, 0.0907, 0.0673, 0.0540, 0.0717, 0.0813, 0.0626, 0.0810,
        0.0783, 0.0861, 0.0767, 0.0649], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,550][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0810, 0.0619, 0.0866, 0.0759, 0.0651, 0.0761, 0.1114, 0.1096, 0.0702,
        0.0704, 0.0698, 0.0758, 0.0461], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,552][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0759, 0.0648, 0.0716, 0.0748, 0.0552, 0.1240, 0.0614, 0.0612, 0.1046,
        0.0189, 0.0863, 0.0489, 0.0407, 0.1117], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,553][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1218, 0.0265, 0.0656, 0.0974, 0.0826, 0.0634, 0.0719, 0.0657, 0.0643,
        0.0839, 0.0460, 0.0704, 0.0753, 0.0652], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,554][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0068, 0.0351, 0.0574, 0.0882, 0.0967, 0.0659, 0.0750, 0.0907, 0.0730,
        0.0892, 0.0866, 0.0939, 0.0674, 0.0741], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,555][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.3082e-05, 9.9566e-12, 5.6803e-06, 1.4400e-06, 2.3850e-06, 4.6017e-03,
        7.2338e-04, 3.5195e-03, 3.4757e-02, 6.7397e-02, 1.8383e-01, 5.8988e-02,
        4.3005e-02, 6.0314e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,557][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0991, 0.0679, 0.0734, 0.0733, 0.0717, 0.0714, 0.0695, 0.0682, 0.0691,
        0.0671, 0.0680, 0.0693, 0.0651, 0.0669], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,558][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0715, 0.0653, 0.0705, 0.0780, 0.0709, 0.0730, 0.0735, 0.0698, 0.0720,
        0.0737, 0.0698, 0.0762, 0.0677, 0.0681], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,560][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0373, 0.0744, 0.0691, 0.0834, 0.0738, 0.0806, 0.0770, 0.0634, 0.0794,
        0.0775, 0.0754, 0.0857, 0.0644, 0.0585], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,561][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0118, 0.0002, 0.0079, 0.0776, 0.1435, 0.0823, 0.1880, 0.0399, 0.1364,
        0.0928, 0.1021, 0.0854, 0.0090, 0.0232], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,563][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0403, 0.0756, 0.0818, 0.0582, 0.0816, 0.0496, 0.0506, 0.0987, 0.0503,
        0.0683, 0.1095, 0.0885, 0.0777, 0.0695], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,564][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0057, 0.0832, 0.0936, 0.1274, 0.0875, 0.0731, 0.0521, 0.0727, 0.0788,
        0.0665, 0.0543, 0.0880, 0.0631, 0.0541], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,566][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0996, 0.0747, 0.0829, 0.0651, 0.0578, 0.0677, 0.0736, 0.0719, 0.0729,
        0.0720, 0.0822, 0.0663, 0.0587, 0.0546], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,567][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0510, 0.0589, 0.0817, 0.0759, 0.0681, 0.0635, 0.1066, 0.0921, 0.0606,
        0.0688, 0.0702, 0.0684, 0.0708, 0.0632], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,569][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0725, 0.0639, 0.0665, 0.0715, 0.0508, 0.1216, 0.0644, 0.0559, 0.1015,
        0.0176, 0.0798, 0.0475, 0.0370, 0.1048, 0.0445], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,570][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.1091, 0.0280, 0.0597, 0.0856, 0.0778, 0.0574, 0.0649, 0.0607, 0.0595,
        0.0814, 0.0440, 0.0687, 0.0774, 0.0678, 0.0581], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,571][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0070, 0.0291, 0.0525, 0.0705, 0.0747, 0.0651, 0.0628, 0.1002, 0.0629,
        0.0801, 0.0763, 0.0761, 0.0570, 0.1225, 0.0633], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,571][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([1.1010e-05, 3.9445e-11, 8.3012e-06, 1.6902e-06, 2.8797e-07, 1.1491e-03,
        3.7257e-04, 1.9868e-03, 1.5737e-02, 3.6614e-02, 1.2749e-01, 3.9220e-02,
        5.0261e-03, 7.3075e-01, 4.1635e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,572][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0938, 0.0635, 0.0687, 0.0689, 0.0675, 0.0671, 0.0651, 0.0639, 0.0648,
        0.0628, 0.0638, 0.0652, 0.0610, 0.0626, 0.0614], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,572][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0671, 0.0612, 0.0660, 0.0726, 0.0660, 0.0676, 0.0683, 0.0654, 0.0674,
        0.0693, 0.0654, 0.0713, 0.0642, 0.0640, 0.0642], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,573][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0364, 0.0700, 0.0653, 0.0792, 0.0669, 0.0767, 0.0695, 0.0650, 0.0760,
        0.0746, 0.0701, 0.0780, 0.0583, 0.0579, 0.0562], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,573][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0065, 0.0004, 0.0060, 0.0077, 0.0018, 0.0818, 0.0285, 0.2562, 0.0343,
        0.0085, 0.2785, 0.0658, 0.0009, 0.2227, 0.0003], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,574][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0543, 0.0666, 0.0737, 0.0582, 0.0808, 0.0412, 0.0455, 0.1156, 0.0390,
        0.0514, 0.0917, 0.0770, 0.0814, 0.0769, 0.0468], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,574][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0050, 0.0740, 0.0857, 0.1150, 0.0703, 0.0663, 0.0514, 0.0731, 0.0727,
        0.0706, 0.0515, 0.0859, 0.0615, 0.0582, 0.0587], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,576][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0922, 0.0754, 0.0780, 0.0590, 0.0586, 0.0694, 0.0705, 0.0588, 0.0702,
        0.0662, 0.0753, 0.0663, 0.0591, 0.0483, 0.0528], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,577][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0605, 0.0553, 0.0783, 0.0729, 0.0566, 0.0583, 0.0884, 0.1080, 0.0622,
        0.0625, 0.0617, 0.0662, 0.0640, 0.0676, 0.0376], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,579][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.0618, 0.0553, 0.0603, 0.0648, 0.0471, 0.1090, 0.0570, 0.0515, 0.0912,
        0.0166, 0.0740, 0.0440, 0.0349, 0.0952, 0.0397, 0.0977],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,580][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.0987, 0.0273, 0.0564, 0.0861, 0.0737, 0.0536, 0.0599, 0.0561, 0.0574,
        0.0802, 0.0420, 0.0680, 0.0728, 0.0650, 0.0548, 0.0480],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,582][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.0056, 0.0234, 0.0494, 0.0634, 0.0810, 0.0480, 0.0620, 0.1042, 0.0468,
        0.0715, 0.0679, 0.0651, 0.0629, 0.1028, 0.0898, 0.0560],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,583][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([1.3844e-05, 1.9279e-11, 2.7221e-06, 7.1339e-07, 9.0961e-07, 1.1962e-03,
        2.9223e-04, 2.9784e-03, 9.7636e-03, 2.3482e-02, 5.1843e-02, 4.6764e-02,
        1.5435e-02, 5.5108e-01, 2.0068e-01, 9.6469e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,584][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.0879, 0.0597, 0.0646, 0.0648, 0.0635, 0.0631, 0.0612, 0.0602, 0.0609,
        0.0591, 0.0600, 0.0613, 0.0575, 0.0589, 0.0577, 0.0596],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,586][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.0629, 0.0573, 0.0620, 0.0681, 0.0620, 0.0639, 0.0645, 0.0615, 0.0633,
        0.0649, 0.0614, 0.0670, 0.0599, 0.0602, 0.0600, 0.0612],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,587][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.0334, 0.0690, 0.0614, 0.0731, 0.0631, 0.0708, 0.0696, 0.0576, 0.0684,
        0.0690, 0.0664, 0.0779, 0.0544, 0.0535, 0.0551, 0.0573],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,588][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([2.5681e-02, 3.8537e-04, 6.9592e-03, 6.5260e-03, 7.1074e-02, 2.6038e-02,
        1.0927e-01, 3.5137e-01, 4.5800e-03, 3.3016e-02, 1.0457e-01, 9.0286e-02,
        1.7759e-02, 1.4221e-01, 1.0011e-02, 2.5506e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,590][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.0413, 0.0677, 0.0657, 0.0562, 0.0689, 0.0393, 0.0468, 0.1092, 0.0331,
        0.0565, 0.0861, 0.0785, 0.0704, 0.0744, 0.0706, 0.0354],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,591][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.0054, 0.0711, 0.0776, 0.1056, 0.0718, 0.0602, 0.0477, 0.0689, 0.0685,
        0.0667, 0.0477, 0.0819, 0.0537, 0.0545, 0.0684, 0.0504],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,593][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.0862, 0.0707, 0.0755, 0.0628, 0.0501, 0.0621, 0.0651, 0.0572, 0.0732,
        0.0594, 0.0704, 0.0609, 0.0563, 0.0443, 0.0460, 0.0598],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,594][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.0498, 0.0537, 0.0806, 0.0597, 0.0562, 0.0639, 0.1123, 0.0950, 0.0505,
        0.0588, 0.0662, 0.0632, 0.0477, 0.0695, 0.0485, 0.0243],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,596][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0606, 0.0507, 0.0562, 0.0591, 0.0433, 0.0947, 0.0489, 0.0477, 0.0806,
        0.0154, 0.0678, 0.0380, 0.0321, 0.0853, 0.0362, 0.0821, 0.1012],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,597][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0977, 0.0239, 0.0553, 0.0830, 0.0710, 0.0533, 0.0613, 0.0547, 0.0546,
        0.0712, 0.0388, 0.0600, 0.0651, 0.0558, 0.0529, 0.0493, 0.0522],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,598][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0056, 0.0278, 0.0446, 0.0694, 0.0753, 0.0523, 0.0583, 0.0697, 0.0575,
        0.0680, 0.0671, 0.0730, 0.0534, 0.0575, 0.0759, 0.0854, 0.0592],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,598][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.2879e-05, 2.7895e-12, 9.4717e-07, 2.5331e-07, 4.2848e-07, 9.1864e-04,
        1.3324e-04, 4.9946e-04, 5.5054e-03, 1.0412e-02, 2.2990e-02, 1.0228e-02,
        7.1879e-03, 8.8027e-02, 1.2783e-01, 2.6606e-01, 4.6019e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,599][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0831, 0.0565, 0.0612, 0.0612, 0.0599, 0.0596, 0.0579, 0.0569, 0.0575,
        0.0559, 0.0566, 0.0578, 0.0543, 0.0557, 0.0544, 0.0563, 0.0552],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,599][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0596, 0.0545, 0.0586, 0.0646, 0.0587, 0.0604, 0.0608, 0.0580, 0.0597,
        0.0612, 0.0579, 0.0630, 0.0562, 0.0566, 0.0563, 0.0576, 0.0561],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,599][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0314, 0.0624, 0.0580, 0.0697, 0.0622, 0.0682, 0.0648, 0.0535, 0.0670,
        0.0652, 0.0634, 0.0716, 0.0538, 0.0493, 0.0543, 0.0576, 0.0475],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,600][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0167, 0.0002, 0.0042, 0.0758, 0.0886, 0.0494, 0.1727, 0.0212, 0.0880,
        0.0853, 0.0634, 0.0894, 0.0070, 0.0154, 0.0837, 0.1059, 0.0329],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,601][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0347, 0.0643, 0.0670, 0.0497, 0.0679, 0.0415, 0.0431, 0.0809, 0.0419,
        0.0583, 0.0897, 0.0754, 0.0630, 0.0574, 0.0589, 0.0521, 0.0543],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,602][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0054, 0.0711, 0.0786, 0.1006, 0.0740, 0.0611, 0.0435, 0.0627, 0.0661,
        0.0555, 0.0466, 0.0718, 0.0535, 0.0448, 0.0667, 0.0507, 0.0473],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,604][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0859, 0.0639, 0.0707, 0.0552, 0.0495, 0.0576, 0.0633, 0.0615, 0.0621,
        0.0620, 0.0704, 0.0565, 0.0500, 0.0465, 0.0463, 0.0545, 0.0441],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,605][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0457, 0.0521, 0.0699, 0.0653, 0.0577, 0.0541, 0.0960, 0.0792, 0.0515,
        0.0625, 0.0606, 0.0593, 0.0613, 0.0535, 0.0532, 0.0276, 0.0506],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,607][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:26,608][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 8180],
        [30592],
        [25879],
        [ 6575],
        [14579],
        [ 8558],
        [12223],
        [ 4201],
        [12028],
        [18989],
        [15275],
        [23907],
        [19814],
        [17661],
        [23526],
        [11232],
        [13817]], device='cuda:0')
[2024-07-24 10:31:26,610][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 7916],
        [17421],
        [24680],
        [ 1969],
        [12024],
        [ 4543],
        [ 6042],
        [ 3817],
        [ 7793],
        [15639],
        [12253],
        [14881],
        [15533],
        [ 9246],
        [ 9635],
        [10292],
        [ 6802]], device='cuda:0')
[2024-07-24 10:31:26,611][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[29363],
        [28612],
        [28416],
        [28633],
        [28765],
        [27787],
        [28002],
        [26885],
        [26428],
        [27810],
        [25590],
        [26740],
        [26380],
        [25065],
        [25657],
        [25343],
        [24387]], device='cuda:0')
[2024-07-24 10:31:26,613][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[37129],
        [40028],
        [40508],
        [39624],
        [39994],
        [40470],
        [40490],
        [40405],
        [41238],
        [40885],
        [41136],
        [41000],
        [41117],
        [40984],
        [41150],
        [41431],
        [41409]], device='cuda:0')
[2024-07-24 10:31:26,614][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[46698],
        [47348],
        [47490],
        [47243],
        [47201],
        [47088],
        [46669],
        [46428],
        [46447],
        [46392],
        [46177],
        [46120],
        [46336],
        [46257],
        [45994],
        [45903],
        [45829]], device='cuda:0')
[2024-07-24 10:31:26,616][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[23494],
        [22752],
        [33589],
        [33747],
        [34987],
        [35070],
        [36238],
        [42755],
        [41075],
        [35084],
        [32295],
        [29325],
        [37405],
        [38040],
        [38583],
        [36068],
        [31369]], device='cuda:0')
[2024-07-24 10:31:26,617][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[18861],
        [18373],
        [ 7466],
        [11329],
        [13268],
        [ 8875],
        [11981],
        [10941],
        [ 4614],
        [11195],
        [ 6562],
        [18618],
        [ 9160],
        [ 6733],
        [14325],
        [ 4584],
        [ 5605]], device='cuda:0')
[2024-07-24 10:31:26,619][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[34093],
        [29103],
        [26684],
        [19779],
        [18882],
        [18681],
        [16588],
        [16891],
        [16536],
        [15842],
        [16182],
        [15626],
        [15166],
        [16032],
        [15734],
        [16240],
        [16702]], device='cuda:0')
[2024-07-24 10:31:26,620][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[33818],
        [28506],
        [30672],
        [30545],
        [31426],
        [31350],
        [31241],
        [31394],
        [30166],
        [30401],
        [29734],
        [29957],
        [30007],
        [30195],
        [29599],
        [29418],
        [29230]], device='cuda:0')
[2024-07-24 10:31:26,622][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 4668],
        [16411],
        [ 3898],
        [ 3897],
        [ 3901],
        [ 7256],
        [ 6734],
        [ 3926],
        [ 4103],
        [ 4846],
        [ 7057],
        [ 5650],
        [ 7141],
        [ 6148],
        [ 5225],
        [ 4573],
        [ 4144]], device='cuda:0')
[2024-07-24 10:31:26,623][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[15719],
        [16522],
        [28743],
        [27160],
        [25078],
        [31214],
        [17578],
        [29181],
        [31009],
        [29150],
        [24956],
        [28841],
        [35897],
        [34811],
        [31032],
        [38928],
        [35355]], device='cuda:0')
[2024-07-24 10:31:26,625][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 1928],
        [ 4961],
        [16839],
        [16068],
        [17660],
        [14077],
        [13802],
        [12669],
        [12435],
        [ 9711],
        [15121],
        [14909],
        [16263],
        [16003],
        [18772],
        [16992],
        [13923]], device='cuda:0')
[2024-07-24 10:31:26,626][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[31327],
        [31756],
        [32243],
        [35179],
        [36124],
        [36546],
        [37244],
        [37407],
        [37006],
        [37009],
        [36569],
        [36254],
        [35376],
        [35330],
        [35407],
        [35251],
        [35184]], device='cuda:0')
[2024-07-24 10:31:26,627][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[36639],
        [33298],
        [26698],
        [26753],
        [26969],
        [34080],
        [33696],
        [35113],
        [33334],
        [32135],
        [31446],
        [32024],
        [32091],
        [33913],
        [34370],
        [34335],
        [34492]], device='cuda:0')
[2024-07-24 10:31:26,628][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[15706],
        [32452],
        [20299],
        [33318],
        [28609],
        [30519],
        [28059],
        [12720],
        [18442],
        [15133],
        [ 8564],
        [24519],
        [10930],
        [17257],
        [30021],
        [ 6111],
        [22984]], device='cuda:0')
[2024-07-24 10:31:26,629][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[18612],
        [20777],
        [20677],
        [20835],
        [20655],
        [20846],
        [20200],
        [20285],
        [20774],
        [20745],
        [20789],
        [20784],
        [20759],
        [20804],
        [20686],
        [21023],
        [21053]], device='cuda:0')
[2024-07-24 10:31:26,630][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[30675],
        [27989],
        [30474],
        [28857],
        [28463],
        [29294],
        [30045],
        [30178],
        [30073],
        [29695],
        [29776],
        [29744],
        [29607],
        [29560],
        [29318],
        [29031],
        [29115]], device='cuda:0')
[2024-07-24 10:31:26,632][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[14117],
        [16082],
        [ 7160],
        [13559],
        [10639],
        [10517],
        [11766],
        [13397],
        [13124],
        [13759],
        [13154],
        [13026],
        [13008],
        [12367],
        [12568],
        [12342],
        [12368]], device='cuda:0')
[2024-07-24 10:31:26,633][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[37641],
        [17909],
        [23226],
        [23401],
        [24848],
        [ 6614],
        [ 7404],
        [17622],
        [22467],
        [24903],
        [26671],
        [29218],
        [27150],
        [33679],
        [34705],
        [33248],
        [28343]], device='cuda:0')
[2024-07-24 10:31:26,635][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[40563],
        [38466],
        [37716],
        [36712],
        [36457],
        [36365],
        [36295],
        [36290],
        [36282],
        [36313],
        [36293],
        [36142],
        [36187],
        [36252],
        [36211],
        [36200],
        [36258]], device='cuda:0')
[2024-07-24 10:31:26,636][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[30843],
        [33599],
        [33295],
        [32544],
        [31917],
        [31389],
        [31511],
        [31894],
        [32419],
        [32906],
        [33073],
        [33162],
        [33460],
        [33499],
        [33748],
        [33923],
        [33951]], device='cuda:0')
[2024-07-24 10:31:26,638][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[1166],
        [1237],
        [1237],
        [1268],
        [1239],
        [1229],
        [1222],
        [1218],
        [1248],
        [1224],
        [1216],
        [1213],
        [1191],
        [1183],
        [1174],
        [1175],
        [1176]], device='cuda:0')
[2024-07-24 10:31:26,639][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[20440],
        [20353],
        [29771],
        [33474],
        [28871],
        [15631],
        [28622],
        [ 3700],
        [ 3636],
        [25462],
        [16385],
        [23400],
        [28402],
        [ 9599],
        [27305],
        [16807],
        [11696]], device='cuda:0')
[2024-07-24 10:31:26,641][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[24052],
        [15717],
        [14049],
        [13791],
        [13064],
        [12291],
        [11945],
        [13749],
        [14666],
        [15542],
        [14293],
        [15163],
        [13945],
        [13222],
        [14138],
        [13936],
        [13532]], device='cuda:0')
[2024-07-24 10:31:26,642][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[26560],
        [17687],
        [20278],
        [19612],
        [17046],
        [17144],
        [16808],
        [17207],
        [17075],
        [16280],
        [16179],
        [16050],
        [15851],
        [15314],
        [14676],
        [14517],
        [14370]], device='cuda:0')
[2024-07-24 10:31:26,644][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[5196],
        [7028],
        [5557],
        [7197],
        [6758],
        [6370],
        [6792],
        [6156],
        [5729],
        [5280],
        [4951],
        [5626],
        [5732],
        [5610],
        [5581],
        [5626],
        [5547]], device='cuda:0')
[2024-07-24 10:31:26,645][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[28367],
        [24341],
        [24014],
        [22968],
        [23695],
        [22869],
        [23435],
        [25174],
        [26227],
        [26733],
        [26042],
        [26042],
        [25815],
        [25794],
        [26073],
        [25790],
        [25835]], device='cuda:0')
[2024-07-24 10:31:26,647][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[14891],
        [18590],
        [19937],
        [18544],
        [19633],
        [25651],
        [23446],
        [25859],
        [25063],
        [18720],
        [20922],
        [17900],
        [18355],
        [20978],
        [17962],
        [19252],
        [22447]], device='cuda:0')
[2024-07-24 10:31:26,648][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[17936],
        [18254],
        [19519],
        [18054],
        [ 8288],
        [13181],
        [12738],
        [ 7510],
        [ 8594],
        [17178],
        [17103],
        [14329],
        [18221],
        [14838],
        [13923],
        [21352],
        [11808]], device='cuda:0')
[2024-07-24 10:31:26,650][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[35241],
        [35241],
        [35241],
        [35241],
        [35241],
        [35241],
        [35241],
        [35241],
        [35241],
        [35241],
        [35241],
        [35241],
        [35241],
        [35241],
        [35241],
        [35241],
        [35241]], device='cuda:0')
[2024-07-24 10:31:26,683][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:26,684][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,684][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,685][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,686][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,686][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,687][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,688][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,689][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,690][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,692][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,693][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,694][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:26,696][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.4796, 0.5204], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,697][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.9770, 0.0230], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,699][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.2489, 0.7511], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,701][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.1710, 0.8290], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,702][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.7236, 0.2764], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,704][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.9277, 0.0723], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,705][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.5646, 0.4354], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,707][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.2705, 0.7295], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,709][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.5125, 0.4875], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,710][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.3211, 0.6789], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,711][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.4004, 0.5996], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,711][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([9.9965e-01, 3.4749e-04], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:26,712][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([7.3868e-03, 4.8260e-06, 9.9261e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,713][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.8405, 0.1363, 0.0233], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,714][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1942, 0.4278, 0.3780], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,715][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0798, 0.5097, 0.4105], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,717][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.5728, 0.2175, 0.2097], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,718][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([5.1028e-01, 2.3283e-04, 4.8949e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,719][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3827, 0.2889, 0.3284], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,721][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0173, 0.5316, 0.4511], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,722][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3414, 0.3417, 0.3168], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,724][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1848, 0.4073, 0.4079], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,726][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2352, 0.3894, 0.3755], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,727][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0825, 0.3577, 0.5598], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:26,728][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Nathan] are: tensor([1.6745e-03, 2.0184e-06, 9.8304e-01, 1.5284e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,730][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Nathan] are: tensor([0.6141, 0.0224, 0.1916, 0.1719], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,731][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Nathan] are: tensor([0.0970, 0.3266, 0.2269, 0.3494], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,733][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Nathan] are: tensor([0.0630, 0.3272, 0.2779, 0.3319], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,735][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Nathan] are: tensor([0.4665, 0.1786, 0.1721, 0.1827], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,736][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Nathan] are: tensor([9.0851e-02, 1.0666e-04, 7.6874e-01, 1.4030e-01], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,737][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Nathan] are: tensor([0.2896, 0.2176, 0.2516, 0.2412], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,738][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Nathan] are: tensor([0.0106, 0.2911, 0.2962, 0.4021], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,738][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Nathan] are: tensor([0.2518, 0.2537, 0.2337, 0.2609], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,739][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Nathan] are: tensor([0.1367, 0.2925, 0.2887, 0.2822], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,740][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Nathan] are: tensor([0.1701, 0.2903, 0.2728, 0.2667], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,741][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Nathan] are: tensor([5.7091e-03, 2.6621e-04, 9.9402e-01, 5.6130e-06], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:26,742][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ got] are: tensor([3.5116e-03, 2.7189e-06, 9.2338e-01, 2.9812e-02, 4.3290e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,743][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.7222, 0.0038, 0.0256, 0.2402, 0.0082], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,745][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.0916, 0.2671, 0.2212, 0.2685, 0.1515], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,747][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.0479, 0.2723, 0.2259, 0.2717, 0.1823], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,748][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.3923, 0.1524, 0.1468, 0.1556, 0.1529], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,749][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ got] are: tensor([2.2463e-02, 1.8742e-04, 7.2575e-01, 1.9783e-01, 5.3768e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,751][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.2383, 0.1782, 0.2067, 0.1982, 0.1786], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,752][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.0195, 0.2604, 0.3327, 0.3109, 0.0765], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,754][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.2041, 0.1955, 0.1787, 0.2005, 0.2211], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,756][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.1072, 0.2227, 0.2295, 0.2239, 0.2167], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,757][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.1251, 0.2314, 0.2184, 0.2118, 0.2133], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,758][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ got] are: tensor([1.1324e-01, 6.7488e-04, 8.8571e-01, 3.6755e-04, 1.7348e-07],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:26,759][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([5.0118e-03, 6.3617e-08, 1.1587e-03, 8.9864e-05, 1.8333e-04, 9.9356e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,761][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.2954, 0.0111, 0.0679, 0.2224, 0.4009, 0.0023], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,763][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0909, 0.1926, 0.1760, 0.2415, 0.1346, 0.1644], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,764][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0362, 0.2201, 0.1917, 0.2276, 0.1565, 0.1680], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,765][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.3406, 0.1319, 0.1271, 0.1345, 0.1322, 0.1338], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,765][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([7.5345e-01, 6.0856e-05, 3.7336e-02, 2.2045e-02, 1.0566e-02, 1.7654e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,766][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1966, 0.1495, 0.1763, 0.1693, 0.1542, 0.1541], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,768][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0135, 0.2739, 0.2786, 0.2646, 0.0514, 0.1179], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,769][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1691, 0.1633, 0.1526, 0.1675, 0.1835, 0.1640], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,771][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0828, 0.1861, 0.1861, 0.1834, 0.1822, 0.1794], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,772][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1079, 0.1905, 0.1816, 0.1771, 0.1760, 0.1669], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,774][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([2.2769e-03, 3.8389e-03, 9.8700e-01, 1.7789e-03, 1.5138e-04, 4.9496e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:26,775][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([2.2543e-03, 1.2903e-07, 2.5145e-03, 1.6358e-04, 5.7415e-04, 9.1516e-01,
        7.9337e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,776][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.2435, 0.0077, 0.2570, 0.1828, 0.1575, 0.0654, 0.0862],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,778][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.0643, 0.1856, 0.1534, 0.2636, 0.1425, 0.1358, 0.0547],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,780][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0392, 0.1815, 0.1564, 0.1868, 0.1299, 0.1448, 0.1614],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,781][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.2971, 0.1154, 0.1111, 0.1178, 0.1157, 0.1167, 0.1262],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,782][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([1.6920e-01, 4.6122e-05, 4.4413e-02, 8.8804e-03, 1.8953e-02, 2.8837e-01,
        4.7014e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,784][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.1682, 0.1309, 0.1539, 0.1477, 0.1354, 0.1346, 0.1295],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,786][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.0163, 0.2112, 0.1812, 0.2385, 0.0592, 0.0978, 0.1958],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,787][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.1481, 0.1399, 0.1283, 0.1421, 0.1543, 0.1396, 0.1476],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,789][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0710, 0.1529, 0.1548, 0.1527, 0.1550, 0.1572, 0.1565],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,790][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0963, 0.1627, 0.1556, 0.1533, 0.1509, 0.1417, 0.1395],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,791][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([5.1869e-06, 1.5671e-05, 5.6056e-01, 1.2524e-04, 3.5819e-05, 4.3924e-01,
        9.0539e-06], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:26,791][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ at] are: tensor([7.2265e-03, 4.2536e-08, 6.9057e-04, 6.0820e-05, 1.0847e-04, 7.8822e-01,
        7.6021e-02, 1.2767e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,792][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.6629, 0.0063, 0.0294, 0.0566, 0.1663, 0.0233, 0.0502, 0.0050],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,793][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0656, 0.1611, 0.1595, 0.2138, 0.1059, 0.1235, 0.0702, 0.1004],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,795][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0272, 0.1636, 0.1381, 0.1691, 0.1159, 0.1255, 0.1435, 0.1171],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,796][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.2682, 0.1039, 0.1001, 0.1061, 0.1042, 0.1054, 0.1135, 0.0985],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,797][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ at] are: tensor([3.1592e-02, 2.2617e-05, 1.8970e-02, 9.4818e-03, 3.7766e-03, 1.2696e-01,
        7.8822e-01, 2.0981e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,799][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1521, 0.1164, 0.1364, 0.1308, 0.1197, 0.1194, 0.1155, 0.1097],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,801][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0152, 0.2058, 0.2529, 0.2045, 0.0395, 0.0848, 0.1113, 0.0860],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,802][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.1274, 0.1239, 0.1132, 0.1273, 0.1390, 0.1241, 0.1291, 0.1160],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,804][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0616, 0.1361, 0.1349, 0.1351, 0.1332, 0.1337, 0.1387, 0.1268],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,806][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0818, 0.1442, 0.1368, 0.1334, 0.1326, 0.1243, 0.1226, 0.1242],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,807][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ at] are: tensor([4.0477e-04, 1.4265e-02, 6.8462e-03, 3.6561e-03, 9.1021e-05, 1.6621e-01,
        8.0762e-01, 9.0609e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:26,808][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ the] are: tensor([3.0679e-03, 1.0334e-08, 7.4431e-05, 9.2832e-06, 1.8032e-05, 6.7475e-02,
        1.3798e-02, 8.5174e-02, 8.3038e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,809][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ the] are: tensor([2.7748e-01, 3.1696e-03, 1.1881e-02, 8.4299e-02, 4.2281e-01, 9.7115e-04,
        1.6986e-01, 2.9234e-02, 2.9421e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,811][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0666, 0.1512, 0.1218, 0.1586, 0.0877, 0.1119, 0.0504, 0.0807, 0.1711],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,812][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0206, 0.1415, 0.1260, 0.1465, 0.1049, 0.1131, 0.1269, 0.1107, 0.1098],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,814][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2429, 0.0943, 0.0907, 0.0962, 0.0945, 0.0956, 0.1030, 0.0894, 0.0934],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,815][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ the] are: tensor([1.8361e-01, 1.7306e-05, 1.0178e-02, 4.1631e-03, 1.8091e-03, 6.9225e-02,
        5.3011e-01, 2.7093e-02, 1.7379e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,816][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1387, 0.1038, 0.1228, 0.1174, 0.1067, 0.1069, 0.1030, 0.0981, 0.1028],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,817][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0247, 0.2012, 0.2001, 0.1997, 0.0361, 0.0761, 0.1230, 0.0776, 0.0614],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,818][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1153, 0.1118, 0.1016, 0.1141, 0.1239, 0.1109, 0.1156, 0.1046, 0.1022],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,819][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0535, 0.1186, 0.1200, 0.1180, 0.1172, 0.1161, 0.1209, 0.1151, 0.1206],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,820][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0742, 0.1274, 0.1214, 0.1190, 0.1182, 0.1109, 0.1091, 0.1110, 0.1087],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,822][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ the] are: tensor([4.3730e-06, 1.2400e-04, 7.2397e-03, 1.1735e-04, 1.0145e-05, 2.3392e-04,
        3.6109e-03, 9.0029e-01, 8.8367e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:26,823][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([1.0267e-02, 8.0014e-09, 5.0470e-05, 4.7927e-06, 2.1115e-05, 5.3695e-02,
        8.3678e-03, 8.5911e-02, 5.3746e-01, 3.0422e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,824][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([0.1725, 0.0063, 0.1031, 0.1279, 0.2596, 0.0154, 0.0800, 0.1301, 0.0221,
        0.0830], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,826][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([0.0415, 0.1493, 0.1104, 0.1813, 0.0782, 0.0923, 0.0407, 0.0872, 0.1542,
        0.0648], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,828][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([0.0209, 0.1313, 0.1116, 0.1348, 0.0908, 0.1009, 0.1130, 0.0985, 0.1019,
        0.0963], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,829][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([0.2230, 0.0858, 0.0827, 0.0878, 0.0864, 0.0870, 0.0936, 0.0813, 0.0848,
        0.0877], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,831][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([3.2782e-01, 1.7834e-05, 7.8785e-03, 3.0127e-03, 2.5031e-03, 3.7082e-02,
        1.6428e-01, 2.4727e-02, 1.4790e-01, 2.8478e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,832][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.1175, 0.0953, 0.1107, 0.1066, 0.0998, 0.0984, 0.0954, 0.0917, 0.0960,
        0.0886], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,834][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([0.0306, 0.1601, 0.1165, 0.1362, 0.0578, 0.0851, 0.1271, 0.0991, 0.0742,
        0.1131], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,836][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.1001, 0.0996, 0.0925, 0.1037, 0.1111, 0.0983, 0.1034, 0.0939, 0.0919,
        0.1054], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,837][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([0.0496, 0.1057, 0.1071, 0.1062, 0.1057, 0.1049, 0.1077, 0.1038, 0.1093,
        0.1000], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,839][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([0.0674, 0.1161, 0.1099, 0.1074, 0.1065, 0.0994, 0.0967, 0.0995, 0.0966,
        0.1006], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,840][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([1.1314e-06, 1.1713e-07, 2.1052e-03, 3.1972e-06, 1.3102e-07, 1.8576e-03,
        1.6050e-06, 4.0309e-03, 9.9200e-01, 8.6343e-07], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:26,842][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([4.5863e-03, 2.8858e-09, 6.7095e-06, 9.3498e-07, 1.0933e-06, 1.0892e-02,
        1.8499e-03, 6.9053e-03, 1.4355e-01, 1.6012e-01, 6.7209e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,843][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([3.0335e-01, 1.3340e-02, 1.1193e-02, 1.7155e-01, 1.0003e-01, 7.1103e-02,
        6.7360e-02, 1.2510e-01, 6.0510e-02, 7.6179e-02, 2.8456e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,843][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0612, 0.1307, 0.1062, 0.1443, 0.0715, 0.0939, 0.0437, 0.0742, 0.1377,
        0.0634, 0.0733], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,844][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0175, 0.1192, 0.0997, 0.1229, 0.0863, 0.0943, 0.1047, 0.0882, 0.0936,
        0.0917, 0.0819], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,845][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2042, 0.0795, 0.0764, 0.0810, 0.0796, 0.0805, 0.0866, 0.0752, 0.0785,
        0.0810, 0.0776], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,847][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([1.3973e-01, 1.3989e-05, 5.7371e-03, 1.4253e-03, 9.4605e-04, 2.5976e-02,
        2.7091e-01, 1.1674e-02, 1.0519e-01, 3.0785e-01, 1.3054e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,848][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1111, 0.0870, 0.1014, 0.0980, 0.0894, 0.0898, 0.0866, 0.0830, 0.0866,
        0.0805, 0.0866], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,850][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0234, 0.2070, 0.1935, 0.1696, 0.0349, 0.0645, 0.0875, 0.0671, 0.0507,
        0.0656, 0.0363], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,851][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0906, 0.0896, 0.0830, 0.0916, 0.0999, 0.0901, 0.0945, 0.0848, 0.0839,
        0.0952, 0.0968], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,853][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0437, 0.0965, 0.0959, 0.0951, 0.0939, 0.0939, 0.0982, 0.0919, 0.0991,
        0.0922, 0.0996], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,855][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0615, 0.1040, 0.0997, 0.0973, 0.0974, 0.0916, 0.0894, 0.0910, 0.0893,
        0.0913, 0.0875], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,856][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([9.8104e-08, 4.3930e-07, 2.0502e-08, 3.1642e-06, 1.1815e-08, 2.3718e-04,
        9.5582e-05, 2.6262e-05, 9.9376e-01, 5.8572e-03, 1.7791e-05],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:26,857][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([2.6581e-02, 6.7196e-09, 1.3403e-05, 9.1755e-07, 5.5147e-06, 1.2951e-02,
        4.0049e-03, 8.3197e-03, 1.4788e-01, 6.6745e-02, 4.9127e-01, 2.4224e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,859][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.1162, 0.0010, 0.0529, 0.0390, 0.0760, 0.0157, 0.2310, 0.1200, 0.0128,
        0.2828, 0.0413, 0.0114], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,861][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.0392, 0.1118, 0.0940, 0.1514, 0.0656, 0.0866, 0.0428, 0.0623, 0.1301,
        0.0514, 0.0639, 0.1009], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,863][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.0190, 0.0997, 0.0927, 0.1062, 0.0766, 0.0871, 0.0923, 0.0830, 0.0848,
        0.0828, 0.0778, 0.0980], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,864][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.1891, 0.0729, 0.0701, 0.0745, 0.0733, 0.0738, 0.0794, 0.0689, 0.0719,
        0.0745, 0.0712, 0.0803], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,866][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([6.8169e-01, 4.8773e-07, 1.5785e-04, 3.2821e-05, 1.0000e-04, 2.9714e-03,
        2.5278e-02, 6.9466e-04, 8.4787e-03, 2.7313e-02, 1.7519e-02, 2.3576e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,867][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.0996, 0.0801, 0.0929, 0.0895, 0.0835, 0.0830, 0.0804, 0.0775, 0.0808,
        0.0752, 0.0815, 0.0762], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,868][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.0428, 0.1591, 0.1064, 0.1385, 0.0415, 0.0685, 0.1084, 0.0719, 0.0569,
        0.0882, 0.0374, 0.0804], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,869][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.0852, 0.0842, 0.0759, 0.0851, 0.0909, 0.0811, 0.0836, 0.0768, 0.0757,
        0.0867, 0.0849, 0.0899], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,870][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.0397, 0.0869, 0.0880, 0.0869, 0.0883, 0.0865, 0.0884, 0.0845, 0.0912,
        0.0832, 0.0926, 0.0838], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,871][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.0596, 0.0958, 0.0910, 0.0894, 0.0891, 0.0841, 0.0809, 0.0834, 0.0817,
        0.0842, 0.0805, 0.0803], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,872][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([4.0718e-08, 3.2567e-10, 2.8470e-04, 8.9362e-08, 8.7891e-09, 2.1370e-03,
        7.8313e-08, 2.0917e-03, 9.3756e-01, 3.8455e-06, 5.7916e-02, 2.6738e-06],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:26,873][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([1.1344e-03, 5.7922e-09, 2.3439e-05, 2.1632e-06, 3.9666e-06, 1.0325e-02,
        1.5524e-03, 4.8111e-03, 6.4031e-02, 1.0142e-01, 4.2943e-01, 3.5185e-01,
        3.5423e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,875][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0568, 0.0017, 0.0360, 0.1547, 0.1171, 0.0026, 0.0335, 0.5101, 0.0079,
        0.0102, 0.0190, 0.0481, 0.0024], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,876][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0401, 0.0944, 0.1021, 0.1211, 0.0554, 0.0848, 0.0396, 0.0600, 0.1419,
        0.0617, 0.0651, 0.0895, 0.0443], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,878][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0181, 0.1018, 0.0832, 0.1020, 0.0663, 0.0777, 0.0879, 0.0745, 0.0766,
        0.0757, 0.0676, 0.0996, 0.0690], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,879][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.1747, 0.0680, 0.0654, 0.0694, 0.0682, 0.0689, 0.0740, 0.0643, 0.0672,
        0.0693, 0.0664, 0.0745, 0.0696], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,881][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([1.0011e-02, 3.2402e-06, 1.1468e-03, 3.8936e-04, 2.7424e-04, 5.3071e-03,
        2.2035e-02, 1.1892e-03, 1.6363e-02, 3.9508e-02, 2.8842e-02, 8.6238e-01,
        1.2554e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,882][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0935, 0.0750, 0.0870, 0.0836, 0.0774, 0.0773, 0.0745, 0.0720, 0.0753,
        0.0692, 0.0756, 0.0702, 0.0693], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,884][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0304, 0.1551, 0.1590, 0.1639, 0.0538, 0.0679, 0.0803, 0.0673, 0.0570,
        0.0518, 0.0370, 0.0461, 0.0307], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,886][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0762, 0.0751, 0.0704, 0.0779, 0.0842, 0.0743, 0.0772, 0.0703, 0.0695,
        0.0788, 0.0774, 0.0798, 0.0889], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,888][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0386, 0.0814, 0.0822, 0.0801, 0.0797, 0.0796, 0.0813, 0.0795, 0.0839,
        0.0759, 0.0849, 0.0778, 0.0749], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,889][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0519, 0.0875, 0.0838, 0.0828, 0.0832, 0.0778, 0.0751, 0.0774, 0.0752,
        0.0778, 0.0740, 0.0738, 0.0795], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,890][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([3.0254e-06, 1.2616e-06, 2.9707e-03, 5.1692e-06, 3.0486e-09, 1.1732e-03,
        1.6292e-04, 2.4021e-02, 8.9258e-01, 8.9788e-04, 7.0715e-02, 7.4674e-03,
        5.3860e-08], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:26,892][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([3.2340e-03, 1.5202e-09, 3.1900e-06, 4.6586e-07, 1.0135e-06, 3.4031e-03,
        8.3911e-04, 1.6435e-03, 4.3085e-02, 5.7372e-02, 2.4869e-01, 2.8787e-01,
        6.0670e-02, 2.9318e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,894][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1970, 0.0027, 0.0027, 0.2555, 0.1545, 0.0065, 0.1103, 0.0247, 0.0038,
        0.0955, 0.0013, 0.0472, 0.0972, 0.0010], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,895][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0394, 0.1097, 0.0860, 0.1123, 0.0561, 0.0745, 0.0358, 0.0568, 0.1108,
        0.0499, 0.0590, 0.1005, 0.0534, 0.0557], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,895][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0148, 0.0890, 0.0781, 0.0922, 0.0661, 0.0719, 0.0806, 0.0688, 0.0714,
        0.0712, 0.0665, 0.0883, 0.0702, 0.0709], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,896][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1640, 0.0639, 0.0613, 0.0652, 0.0640, 0.0648, 0.0695, 0.0605, 0.0631,
        0.0651, 0.0624, 0.0700, 0.0653, 0.0607], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,897][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.3787e-02, 1.4123e-06, 3.4634e-04, 6.5512e-05, 5.3214e-05, 3.1444e-03,
        1.1471e-02, 8.7763e-04, 1.7467e-02, 2.6837e-02, 2.2798e-02, 8.7140e-01,
        1.3034e-02, 8.7208e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,899][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0902, 0.0698, 0.0809, 0.0780, 0.0712, 0.0721, 0.0696, 0.0666, 0.0696,
        0.0648, 0.0700, 0.0658, 0.0643, 0.0672], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,900][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0229, 0.1725, 0.1949, 0.1852, 0.0353, 0.0572, 0.0754, 0.0515, 0.0455,
        0.0458, 0.0312, 0.0454, 0.0187, 0.0186], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,902][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0704, 0.0690, 0.0636, 0.0716, 0.0788, 0.0694, 0.0719, 0.0653, 0.0645,
        0.0735, 0.0738, 0.0743, 0.0838, 0.0701], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,904][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0330, 0.0746, 0.0752, 0.0745, 0.0730, 0.0741, 0.0763, 0.0718, 0.0765,
        0.0716, 0.0785, 0.0728, 0.0717, 0.0765], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,906][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0486, 0.0818, 0.0786, 0.0771, 0.0773, 0.0724, 0.0702, 0.0717, 0.0700,
        0.0722, 0.0689, 0.0691, 0.0738, 0.0682], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,907][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.3364e-08, 2.1006e-06, 9.1704e-07, 1.8516e-06, 5.4039e-08, 2.9457e-04,
        2.6061e-04, 1.4307e-05, 8.8950e-01, 2.7290e-03, 1.1026e-02, 5.4202e-02,
        4.7259e-05, 4.1923e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:26,908][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ give] are: tensor([2.3174e-03, 4.8713e-09, 8.1156e-06, 9.5980e-07, 1.4953e-06, 5.0874e-03,
        1.4882e-03, 2.3941e-03, 4.1745e-02, 3.6356e-02, 2.2353e-01, 2.4535e-01,
        5.0540e-02, 3.0863e-01, 8.2546e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,910][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.1125, 0.0025, 0.0182, 0.2431, 0.1391, 0.0024, 0.0371, 0.0953, 0.0038,
        0.0203, 0.0075, 0.0545, 0.0120, 0.1504, 0.1012], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,912][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0360, 0.0884, 0.0829, 0.1119, 0.0512, 0.0718, 0.0379, 0.0523, 0.1214,
        0.0447, 0.0596, 0.0771, 0.0503, 0.0604, 0.0539], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,914][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0139, 0.0891, 0.0723, 0.0892, 0.0607, 0.0662, 0.0745, 0.0668, 0.0668,
        0.0667, 0.0598, 0.0846, 0.0613, 0.0688, 0.0593], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,915][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.1539, 0.0598, 0.0575, 0.0611, 0.0599, 0.0606, 0.0653, 0.0566, 0.0592,
        0.0611, 0.0585, 0.0657, 0.0611, 0.0568, 0.0628], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,916][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ give] are: tensor([7.8171e-03, 2.1601e-06, 4.9466e-04, 2.1771e-04, 6.8960e-05, 2.0311e-03,
        1.2480e-02, 7.7611e-04, 6.6743e-03, 2.2436e-02, 1.8202e-02, 8.6905e-01,
        2.0781e-02, 2.7269e-02, 1.1697e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,918][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0818, 0.0656, 0.0749, 0.0724, 0.0672, 0.0677, 0.0655, 0.0632, 0.0660,
        0.0610, 0.0664, 0.0619, 0.0612, 0.0639, 0.0611], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,920][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0235, 0.1222, 0.1541, 0.1572, 0.0432, 0.0630, 0.0907, 0.0615, 0.0568,
        0.0567, 0.0374, 0.0502, 0.0269, 0.0232, 0.0336], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,921][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0645, 0.0643, 0.0606, 0.0675, 0.0731, 0.0643, 0.0660, 0.0611, 0.0606,
        0.0681, 0.0666, 0.0685, 0.0774, 0.0654, 0.0719], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,922][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0325, 0.0688, 0.0703, 0.0685, 0.0691, 0.0683, 0.0703, 0.0678, 0.0717,
        0.0653, 0.0729, 0.0665, 0.0681, 0.0724, 0.0675], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,923][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0449, 0.0773, 0.0737, 0.0722, 0.0729, 0.0674, 0.0658, 0.0672, 0.0653,
        0.0674, 0.0638, 0.0644, 0.0688, 0.0629, 0.0659], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,924][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ give] are: tensor([2.0975e-09, 1.9146e-07, 3.7270e-05, 7.1827e-09, 9.9812e-10, 2.2628e-05,
        1.9632e-06, 6.6899e-05, 2.8197e-02, 3.2962e-05, 1.7804e-02, 6.1958e-04,
        1.0798e-06, 9.5322e-01, 1.1004e-06], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:26,925][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ it] are: tensor([9.6018e-04, 1.7564e-09, 1.7737e-06, 6.6639e-07, 1.2140e-06, 9.9756e-04,
        7.4417e-04, 1.5116e-03, 1.1999e-02, 3.2078e-02, 8.5493e-02, 1.5402e-01,
        5.1052e-02, 2.0488e-01, 2.3429e-01, 2.2196e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,926][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ it] are: tensor([5.5084e-02, 8.4150e-04, 7.5224e-03, 1.4844e-02, 2.6072e-02, 4.0644e-04,
        1.1059e-02, 4.3918e-02, 4.6657e-04, 4.3346e-02, 4.9176e-03, 3.0574e-02,
        7.1838e-02, 1.8265e-02, 6.6598e-01, 4.8682e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,928][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0365, 0.0985, 0.0694, 0.0884, 0.0433, 0.0573, 0.0340, 0.0483, 0.1038,
        0.0440, 0.0483, 0.0924, 0.0392, 0.0450, 0.0467, 0.1049],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,930][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.0158, 0.0806, 0.0669, 0.0796, 0.0574, 0.0634, 0.0724, 0.0616, 0.0626,
        0.0641, 0.0576, 0.0779, 0.0594, 0.0643, 0.0583, 0.0581],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,931][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.1433, 0.0563, 0.0541, 0.0574, 0.0563, 0.0570, 0.0614, 0.0533, 0.0556,
        0.0574, 0.0550, 0.0618, 0.0575, 0.0534, 0.0590, 0.0613],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,933][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ it] are: tensor([3.1862e-02, 2.0457e-06, 4.1334e-04, 1.5186e-04, 1.0207e-04, 2.8397e-03,
        1.6721e-02, 8.8545e-04, 9.7906e-03, 2.4559e-02, 2.2820e-02, 7.1505e-01,
        4.4574e-02, 4.4128e-02, 2.3059e-02, 6.3046e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,934][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.0785, 0.0616, 0.0713, 0.0687, 0.0633, 0.0636, 0.0614, 0.0591, 0.0618,
        0.0573, 0.0622, 0.0581, 0.0573, 0.0599, 0.0573, 0.0587],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,936][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0217, 0.1272, 0.1694, 0.1867, 0.0410, 0.0625, 0.0820, 0.0561, 0.0498,
        0.0473, 0.0317, 0.0469, 0.0205, 0.0187, 0.0245, 0.0142],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,938][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0622, 0.0612, 0.0557, 0.0623, 0.0675, 0.0598, 0.0619, 0.0573, 0.0563,
        0.0632, 0.0623, 0.0650, 0.0721, 0.0609, 0.0668, 0.0654],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,940][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.0294, 0.0650, 0.0654, 0.0646, 0.0645, 0.0643, 0.0650, 0.0631, 0.0673,
        0.0616, 0.0681, 0.0631, 0.0621, 0.0674, 0.0636, 0.0655],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,942][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.0432, 0.0722, 0.0692, 0.0683, 0.0685, 0.0632, 0.0617, 0.0631, 0.0611,
        0.0635, 0.0602, 0.0604, 0.0649, 0.0593, 0.0617, 0.0597],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,943][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ it] are: tensor([3.3057e-08, 1.1197e-08, 3.1564e-06, 2.8341e-08, 3.8379e-09, 1.3399e-07,
        9.4883e-07, 7.7591e-04, 4.0286e-05, 5.3543e-06, 7.6354e-03, 1.6588e-04,
        1.0974e-06, 9.8923e-01, 2.0609e-03, 7.7288e-05], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:26,944][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([3.2392e-03, 1.1075e-09, 1.0638e-06, 2.0410e-07, 3.1123e-07, 1.0071e-03,
        3.1603e-04, 3.7362e-04, 1.1162e-02, 1.6117e-02, 7.2940e-02, 1.1832e-01,
        2.0834e-02, 6.1548e-02, 1.0352e-01, 3.0462e-01, 2.8600e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,946][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1945, 0.0027, 0.0018, 0.2768, 0.1430, 0.0049, 0.0925, 0.0232, 0.0031,
        0.0623, 0.0010, 0.0427, 0.0739, 0.0008, 0.0557, 0.0202, 0.0010],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,947][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0313, 0.0894, 0.0691, 0.0938, 0.0465, 0.0611, 0.0290, 0.0458, 0.0916,
        0.0401, 0.0473, 0.0816, 0.0436, 0.0441, 0.0453, 0.0961, 0.0441],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,948][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0124, 0.0736, 0.0643, 0.0763, 0.0551, 0.0601, 0.0669, 0.0573, 0.0595,
        0.0593, 0.0551, 0.0731, 0.0581, 0.0586, 0.0555, 0.0563, 0.0586],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,949][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1368, 0.0534, 0.0512, 0.0544, 0.0534, 0.0540, 0.0580, 0.0504, 0.0526,
        0.0543, 0.0520, 0.0584, 0.0544, 0.0505, 0.0557, 0.0578, 0.0527],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,949][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([6.2204e-02, 1.4268e-06, 2.2116e-04, 3.6528e-05, 2.6757e-05, 3.3924e-03,
        6.5996e-03, 9.9099e-04, 2.4098e-02, 2.1004e-02, 3.0341e-02, 6.5214e-01,
        1.0682e-02, 7.7205e-03, 2.0492e-02, 1.3091e-01, 2.9140e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,951][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0749, 0.0583, 0.0673, 0.0648, 0.0593, 0.0600, 0.0579, 0.0555, 0.0580,
        0.0541, 0.0585, 0.0550, 0.0540, 0.0563, 0.0541, 0.0554, 0.0568],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,953][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0276, 0.1586, 0.1935, 0.1897, 0.0333, 0.0523, 0.0668, 0.0473, 0.0419,
        0.0405, 0.0292, 0.0428, 0.0152, 0.0168, 0.0188, 0.0107, 0.0150],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,955][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0597, 0.0579, 0.0517, 0.0584, 0.0643, 0.0569, 0.0595, 0.0537, 0.0528,
        0.0600, 0.0601, 0.0616, 0.0687, 0.0575, 0.0636, 0.0614, 0.0524],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,956][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0272, 0.0608, 0.0614, 0.0610, 0.0598, 0.0605, 0.0623, 0.0588, 0.0625,
        0.0585, 0.0642, 0.0594, 0.0585, 0.0625, 0.0591, 0.0614, 0.0622],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,958][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0404, 0.0685, 0.0655, 0.0641, 0.0643, 0.0602, 0.0585, 0.0593, 0.0580,
        0.0598, 0.0571, 0.0572, 0.0610, 0.0565, 0.0579, 0.0561, 0.0554],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:26,959][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([7.3307e-10, 3.0294e-08, 6.2332e-09, 1.4955e-08, 5.1052e-10, 1.3412e-06,
        4.6688e-06, 1.3140e-07, 4.7863e-03, 4.2779e-05, 8.7187e-05, 6.3825e-04,
        5.4091e-07, 2.7381e-04, 1.8407e-05, 9.9225e-01, 1.8992e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,002][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:27,003][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,004][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,005][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,005][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,006][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,007][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,008][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,009][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,011][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,012][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,013][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,014][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,016][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.9320, 0.0680], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,018][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.6029, 0.3971], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,019][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.6196, 0.3804], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,021][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.5784, 0.4216], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,023][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.4875, 0.5125], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,024][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.1625, 0.8375], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,026][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.7113, 0.2887], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,028][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.0151, 0.9849], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,029][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.9859, 0.0141], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,030][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.3618, 0.6382], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,031][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.1338, 0.8662], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,031][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.0081, 0.9919], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,032][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6820, 0.0858, 0.2322], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,033][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.0642e-02, 3.4115e-05, 9.7932e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,035][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4352, 0.2980, 0.2668], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,036][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([7.3089e-03, 1.2965e-04, 9.9256e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,037][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0982, 0.0141, 0.8877], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,039][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0733, 0.3295, 0.5973], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,040][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4311, 0.2737, 0.2953], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,042][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0227, 0.4539, 0.5234], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,043][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9724, 0.0147, 0.0129], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,045][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1256, 0.1500, 0.7244], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,047][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0742, 0.4460, 0.4798], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,048][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0073, 0.5797, 0.4130], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,050][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Nathan] are: tensor([0.0180, 0.0071, 0.9498, 0.0250], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,051][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Nathan] are: tensor([1.6432e-03, 6.8394e-06, 9.8546e-01, 1.2894e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,053][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Nathan] are: tensor([0.3354, 0.2170, 0.1834, 0.2642], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,054][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Nathan] are: tensor([9.0701e-03, 3.6523e-05, 9.4963e-01, 4.1258e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,055][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Nathan] are: tensor([0.4334, 0.2083, 0.2560, 0.1023], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,056][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Nathan] are: tensor([0.0441, 0.2179, 0.3907, 0.3473], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,057][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Nathan] are: tensor([0.1957, 0.2279, 0.4684, 0.1080], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,057][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Nathan] are: tensor([0.0414, 0.3649, 0.2067, 0.3871], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,058][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Nathan] are: tensor([0.9590, 0.0142, 0.0123, 0.0145], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,060][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Nathan] are: tensor([0.1064, 0.0770, 0.4710, 0.3456], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,061][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Nathan] are: tensor([0.0430, 0.3178, 0.2967, 0.3425], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,063][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Nathan] are: tensor([0.0017, 0.4246, 0.3186, 0.2552], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,064][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.0216, 0.0048, 0.8924, 0.0282, 0.0530], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,066][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([3.8150e-03, 1.3478e-05, 9.6927e-01, 1.7826e-02, 9.0721e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,067][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.2928, 0.1796, 0.1616, 0.2225, 0.1436], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,068][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([4.0699e-04, 6.1553e-05, 8.8654e-01, 6.8404e-02, 4.4589e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,070][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.3292, 0.0306, 0.3982, 0.0328, 0.2092], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,072][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.0448, 0.1647, 0.2902, 0.2976, 0.2027], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,073][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.2104, 0.2009, 0.3250, 0.1317, 0.1321], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,075][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.0100, 0.4506, 0.1903, 0.2608, 0.0882], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,077][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.9499, 0.0133, 0.0116, 0.0133, 0.0119], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,078][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.0637, 0.0711, 0.3363, 0.3173, 0.2117], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,080][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.0368, 0.2185, 0.2189, 0.2416, 0.2841], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,082][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.0021, 0.3253, 0.2341, 0.1976, 0.2409], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,082][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0434, 0.0239, 0.1709, 0.0518, 0.6964, 0.0135], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,083][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.3254e-01, 3.0682e-06, 1.8728e-02, 5.0766e-04, 4.4758e-04, 8.4777e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,084][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2332, 0.1496, 0.1408, 0.2015, 0.1327, 0.1421], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,085][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([6.4381e-03, 7.1615e-06, 1.1460e-02, 2.4180e-03, 1.3763e-03, 9.7830e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,086][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1202, 0.0357, 0.2853, 0.0364, 0.0246, 0.4979], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,088][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0251, 0.1359, 0.2308, 0.2063, 0.1674, 0.2345], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,089][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2150, 0.1382, 0.2579, 0.1299, 0.1409, 0.1182], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,091][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0217, 0.5996, 0.1166, 0.1744, 0.0654, 0.0224], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,092][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.9392, 0.0130, 0.0115, 0.0130, 0.0116, 0.0116], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,094][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0346, 0.0477, 0.2339, 0.2086, 0.1551, 0.3200], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,096][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0312, 0.1895, 0.1771, 0.1859, 0.2123, 0.2039], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,097][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0011, 0.2745, 0.1904, 0.1613, 0.1978, 0.1750], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,099][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.0642, 0.0006, 0.5047, 0.0262, 0.1273, 0.2322, 0.0446],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,100][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([2.2919e-02, 5.4143e-06, 2.5837e-02, 1.5259e-03, 1.3401e-03, 7.9771e-01,
        1.5066e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,102][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.2110, 0.1413, 0.1275, 0.1967, 0.1236, 0.1261, 0.0740],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,103][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([3.6203e-03, 2.2968e-05, 2.1874e-02, 4.4288e-03, 4.9309e-03, 8.4667e-01,
        1.1846e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,105][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0079, 0.0078, 0.0084, 0.0050, 0.0054, 0.0015, 0.9640],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,106][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.0250, 0.1213, 0.2151, 0.1738, 0.1351, 0.2035, 0.1263],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,108][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.1139, 0.0907, 0.3055, 0.1211, 0.1738, 0.1607, 0.0342],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,110][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0319, 0.6099, 0.0815, 0.1589, 0.0639, 0.0184, 0.0354],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,111][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.8999, 0.0169, 0.0151, 0.0172, 0.0153, 0.0154, 0.0202],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,112][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.0404, 0.0284, 0.1773, 0.1597, 0.1476, 0.2928, 0.1537],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,113][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0264, 0.1541, 0.1561, 0.1499, 0.1821, 0.1766, 0.1548],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,114][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0008, 0.2394, 0.1710, 0.1404, 0.1724, 0.1558, 0.1202],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,115][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0544, 0.0014, 0.0265, 0.0064, 0.2286, 0.1468, 0.5187, 0.0172],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,116][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([7.5275e-02, 1.6214e-06, 8.7789e-03, 3.3939e-04, 4.1975e-04, 5.6899e-01,
        9.5778e-02, 2.5042e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,117][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.2038, 0.1263, 0.1195, 0.1697, 0.1008, 0.1118, 0.0826, 0.0853],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,118][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([4.2334e-03, 5.5855e-06, 4.9010e-03, 2.1395e-03, 1.5351e-03, 7.5024e-01,
        1.0951e-01, 1.2743e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,120][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.1173, 0.0155, 0.2107, 0.0036, 0.0063, 0.0231, 0.5323, 0.0912],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,122][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0186, 0.0921, 0.1829, 0.1439, 0.1299, 0.1967, 0.1143, 0.1215],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,123][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.1567, 0.1232, 0.1892, 0.1283, 0.1416, 0.1372, 0.0806, 0.0433],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,125][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0186, 0.6062, 0.1082, 0.1229, 0.0641, 0.0233, 0.0264, 0.0301],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,127][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.8932, 0.0152, 0.0137, 0.0156, 0.0138, 0.0139, 0.0181, 0.0166],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,128][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0228, 0.0315, 0.1422, 0.1261, 0.0973, 0.1960, 0.1513, 0.2328],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,130][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0217, 0.1444, 0.1289, 0.1385, 0.1438, 0.1492, 0.1263, 0.1472],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,132][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0004, 0.2115, 0.1559, 0.1245, 0.1556, 0.1350, 0.1060, 0.1113],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,133][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0137, 0.0043, 0.0077, 0.0127, 0.1171, 0.0008, 0.3825, 0.4543, 0.0069],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,135][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([3.9945e-02, 3.3422e-07, 1.1848e-03, 5.8269e-05, 7.6763e-05, 7.6258e-02,
        3.4890e-02, 9.7349e-02, 7.5024e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,136][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1725, 0.1175, 0.1012, 0.1421, 0.0898, 0.1025, 0.0665, 0.0768, 0.1310],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,138][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([6.2354e-03, 2.5389e-06, 1.7289e-03, 6.1718e-04, 3.0602e-04, 2.1292e-01,
        8.0877e-02, 1.1562e-01, 5.8169e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,139][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0880, 0.0365, 0.0778, 0.0147, 0.0013, 0.0055, 0.7346, 0.0065, 0.0349],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,139][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0121, 0.0818, 0.1527, 0.1308, 0.1109, 0.1593, 0.0907, 0.1257, 0.1361],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,140][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1480, 0.1181, 0.1773, 0.0954, 0.1142, 0.1272, 0.0660, 0.0573, 0.0966],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,141][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0301, 0.5592, 0.1127, 0.1049, 0.0690, 0.0265, 0.0335, 0.0337, 0.0303],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,143][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.8599, 0.0167, 0.0151, 0.0171, 0.0151, 0.0153, 0.0198, 0.0182, 0.0228],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,144][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0173, 0.0249, 0.1178, 0.1049, 0.0775, 0.1625, 0.1250, 0.1968, 0.1734],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,146][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0197, 0.1173, 0.1152, 0.1164, 0.1406, 0.1317, 0.1148, 0.1263, 0.1179],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,148][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0004, 0.1872, 0.1379, 0.1103, 0.1378, 0.1228, 0.0970, 0.1016, 0.1049],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,149][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([7.8084e-03, 5.0030e-05, 5.5600e-03, 3.9784e-03, 3.0485e-03, 3.5985e-03,
        3.2719e-02, 9.1556e-01, 1.8522e-02, 9.1521e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,150][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([8.3391e-02, 5.3318e-07, 1.0660e-03, 7.8523e-05, 6.5606e-05, 4.2768e-02,
        2.5587e-02, 7.9280e-02, 5.0512e-01, 2.6264e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,152][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([0.1567, 0.1083, 0.0949, 0.1453, 0.0820, 0.0929, 0.0580, 0.0735, 0.1211,
        0.0674], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,153][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([5.7009e-02, 5.1178e-06, 1.6456e-03, 1.0372e-03, 5.7522e-04, 1.5955e-01,
        2.3492e-02, 4.9137e-02, 4.8346e-01, 2.2409e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,155][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([0.3488, 0.0128, 0.0784, 0.0027, 0.0021, 0.0140, 0.1128, 0.1407, 0.0130,
        0.2748], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,156][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([0.0138, 0.0676, 0.1307, 0.1144, 0.0864, 0.1325, 0.0868, 0.1219, 0.1185,
        0.1275], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,158][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([0.1059, 0.0935, 0.1941, 0.1086, 0.1094, 0.1085, 0.0544, 0.0513, 0.1444,
        0.0300], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,160][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([0.0223, 0.6548, 0.0645, 0.1444, 0.0429, 0.0122, 0.0172, 0.0144, 0.0120,
        0.0153], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,162][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([0.8337, 0.0173, 0.0156, 0.0178, 0.0158, 0.0158, 0.0200, 0.0184, 0.0228,
        0.0228], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,163][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([0.0283, 0.0227, 0.1015, 0.0934, 0.0847, 0.1518, 0.0879, 0.1819, 0.1594,
        0.0885], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,164][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([0.0145, 0.1037, 0.1013, 0.1045, 0.1206, 0.1239, 0.1100, 0.1115, 0.1067,
        0.1034], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,165][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([0.0005, 0.1749, 0.1276, 0.1012, 0.1272, 0.1150, 0.0866, 0.0943, 0.0977,
        0.0750], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,166][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0042, 0.0012, 0.0019, 0.0044, 0.0260, 0.0067, 0.2293, 0.0799, 0.0594,
        0.5842, 0.0027], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,167][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([4.5472e-02, 1.1707e-07, 1.4994e-04, 6.7737e-06, 5.1824e-06, 7.4509e-03,
        3.4366e-03, 9.4034e-03, 8.1884e-02, 1.4141e-01, 7.1078e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,169][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1436, 0.1018, 0.0902, 0.1244, 0.0779, 0.0893, 0.0555, 0.0683, 0.1102,
        0.0617, 0.0772], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,170][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([7.1325e-03, 9.0116e-07, 2.0404e-04, 1.7553e-04, 1.2122e-04, 6.5306e-02,
        1.8729e-02, 2.3318e-02, 1.8886e-01, 2.0809e-01, 4.8806e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,172][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0377, 0.0063, 0.2160, 0.0017, 0.0009, 0.0021, 0.4122, 0.0075, 0.0059,
        0.0581, 0.2515], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,173][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0124, 0.0605, 0.1189, 0.1043, 0.0854, 0.1331, 0.0736, 0.0980, 0.1093,
        0.1052, 0.0994], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,175][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1495, 0.0723, 0.1334, 0.0855, 0.1039, 0.1041, 0.0573, 0.0440, 0.1065,
        0.0652, 0.0785], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,177][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0303, 0.5533, 0.1037, 0.1149, 0.0545, 0.0198, 0.0331, 0.0272, 0.0209,
        0.0156, 0.0267], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,179][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8201, 0.0161, 0.0146, 0.0166, 0.0147, 0.0148, 0.0191, 0.0176, 0.0219,
        0.0215, 0.0227], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,180][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0177, 0.0205, 0.0887, 0.0862, 0.0644, 0.1275, 0.0948, 0.1612, 0.1411,
        0.0908, 0.1069], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,182][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0164, 0.0969, 0.0930, 0.0939, 0.1050, 0.1101, 0.0905, 0.1006, 0.0934,
        0.0870, 0.1132], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,184][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0007, 0.1548, 0.1078, 0.0882, 0.1085, 0.0957, 0.0762, 0.0820, 0.0835,
        0.0681, 0.1347], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,185][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([1.0882e-02, 6.0385e-05, 1.8114e-02, 1.6979e-03, 1.5376e-02, 1.8119e-02,
        2.8114e-02, 7.3306e-01, 8.6371e-02, 1.5558e-02, 6.8608e-02, 4.0395e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,186][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([3.3364e-02, 1.4909e-07, 1.4500e-04, 6.6646e-06, 8.1472e-06, 7.0715e-03,
        7.4044e-03, 7.8179e-03, 5.8942e-02, 8.7263e-02, 5.3700e-01, 2.6098e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,188][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.1382, 0.0860, 0.0802, 0.1202, 0.0685, 0.0801, 0.0517, 0.0591, 0.1017,
        0.0546, 0.0691, 0.0905], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,189][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([3.2280e-02, 1.1488e-06, 2.7292e-04, 1.0414e-04, 1.2042e-04, 2.3649e-02,
        9.9436e-03, 1.3046e-02, 8.4862e-02, 8.7690e-02, 3.2223e-01, 4.2580e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,190][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.1643, 0.1433, 0.0207, 0.0128, 0.0098, 0.0019, 0.1724, 0.0099, 0.0024,
        0.0745, 0.1000, 0.2881], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,191][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.0097, 0.0562, 0.1013, 0.0925, 0.0653, 0.1113, 0.0674, 0.1091, 0.0996,
        0.1053, 0.0964, 0.0859], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,192][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.0877, 0.0267, 0.1646, 0.0574, 0.1065, 0.0918, 0.0361, 0.0454, 0.1466,
        0.0677, 0.1315, 0.0379], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,193][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.0174, 0.6879, 0.0487, 0.0940, 0.0391, 0.0148, 0.0137, 0.0145, 0.0159,
        0.0154, 0.0140, 0.0246], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,195][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.7963, 0.0163, 0.0144, 0.0166, 0.0146, 0.0146, 0.0190, 0.0172, 0.0214,
        0.0213, 0.0222, 0.0260], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,196][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.0226, 0.0146, 0.0803, 0.0669, 0.0660, 0.1251, 0.0746, 0.1530, 0.1362,
        0.0764, 0.0993, 0.0849], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,198][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.0141, 0.0867, 0.0835, 0.0916, 0.1073, 0.1039, 0.0816, 0.0879, 0.0899,
        0.0724, 0.1056, 0.0756], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,200][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.0004, 0.1381, 0.0965, 0.0779, 0.0989, 0.0893, 0.0663, 0.0762, 0.0775,
        0.0587, 0.1274, 0.0928], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,201][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([3.1047e-03, 6.3422e-04, 1.8557e-02, 2.3549e-03, 2.1011e-03, 5.6950e-03,
        2.2124e-02, 7.7318e-01, 2.4055e-02, 6.8564e-02, 3.5789e-02, 4.2736e-02,
        1.1021e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,202][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([2.7870e-03, 8.2786e-08, 2.1949e-04, 8.9185e-06, 1.5035e-05, 1.6331e-02,
        3.2883e-03, 1.2936e-02, 9.2045e-02, 6.9250e-02, 6.0505e-01, 1.9361e-01,
        4.4596e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,204][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.1321, 0.0824, 0.0802, 0.1057, 0.0611, 0.0759, 0.0468, 0.0560, 0.1031,
        0.0542, 0.0640, 0.0788, 0.0596], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,205][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([9.4020e-05, 6.2961e-07, 2.4378e-04, 1.1029e-04, 2.4492e-05, 1.7176e-02,
        2.7165e-03, 5.0746e-03, 3.9820e-02, 3.2939e-02, 1.1904e-01, 7.5605e-01,
        2.6714e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,207][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0343, 0.0063, 0.1216, 0.0312, 0.0258, 0.0043, 0.0381, 0.0224, 0.0144,
        0.0027, 0.1853, 0.0058, 0.5076], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,209][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.0141, 0.0498, 0.0998, 0.0917, 0.0634, 0.1023, 0.0635, 0.0903, 0.0912,
        0.1067, 0.0838, 0.0883, 0.0550], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,211][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0969, 0.0650, 0.1161, 0.0547, 0.0621, 0.0745, 0.0472, 0.0471, 0.0906,
        0.0749, 0.0916, 0.1048, 0.0743], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,212][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0126, 0.7196, 0.0592, 0.0821, 0.0368, 0.0097, 0.0106, 0.0105, 0.0089,
        0.0074, 0.0098, 0.0101, 0.0225], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,214][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.7820, 0.0155, 0.0139, 0.0158, 0.0142, 0.0142, 0.0183, 0.0167, 0.0208,
        0.0203, 0.0216, 0.0245, 0.0221], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,216][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0172, 0.0186, 0.0806, 0.0726, 0.0580, 0.1107, 0.0740, 0.1262, 0.1180,
        0.0750, 0.0928, 0.0863, 0.0699], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,217][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0144, 0.0795, 0.0810, 0.0760, 0.0952, 0.0905, 0.0761, 0.0848, 0.0801,
        0.0618, 0.0912, 0.0698, 0.0996], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,218][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0005, 0.1192, 0.0880, 0.0728, 0.0914, 0.0820, 0.0634, 0.0699, 0.0701,
        0.0557, 0.1090, 0.0847, 0.0932], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,218][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([5.6623e-03, 1.0336e-04, 6.2822e-04, 2.5120e-03, 4.4739e-02, 6.7882e-03,
        8.7042e-02, 4.8894e-03, 8.3327e-02, 5.8936e-01, 4.0135e-03, 1.4750e-02,
        1.5594e-01, 2.4325e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,220][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([3.8387e-02, 6.2120e-08, 5.1827e-05, 4.8772e-06, 4.7109e-06, 3.3711e-03,
        1.5806e-03, 4.1493e-03, 3.1078e-02, 3.5938e-02, 3.8100e-01, 2.9579e-01,
        6.9207e-03, 2.0172e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,221][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1183, 0.0821, 0.0708, 0.0987, 0.0611, 0.0708, 0.0459, 0.0536, 0.0879,
        0.0479, 0.0618, 0.0817, 0.0649, 0.0544], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,222][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.2614e-03, 3.8924e-07, 7.1035e-05, 3.4105e-05, 1.7693e-05, 1.0470e-02,
        2.4519e-03, 2.9725e-03, 2.3710e-02, 3.2056e-02, 1.1507e-01, 5.7670e-01,
        6.6236e-02, 1.6894e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,224][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1201, 0.0041, 0.2049, 0.0099, 0.0037, 0.0232, 0.2707, 0.0093, 0.0188,
        0.0261, 0.2845, 0.0069, 0.0050, 0.0127], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,226][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0109, 0.0515, 0.0936, 0.0773, 0.0699, 0.1037, 0.0589, 0.0758, 0.0880,
        0.0879, 0.0793, 0.0840, 0.0624, 0.0567], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,227][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0939, 0.0472, 0.1155, 0.0548, 0.0722, 0.0689, 0.0420, 0.0453, 0.0793,
        0.0640, 0.0701, 0.0930, 0.0982, 0.0555], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,229][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0210, 0.5894, 0.0568, 0.1131, 0.0442, 0.0162, 0.0211, 0.0178, 0.0153,
        0.0135, 0.0172, 0.0174, 0.0295, 0.0275], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,231][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.8068, 0.0126, 0.0112, 0.0128, 0.0115, 0.0114, 0.0149, 0.0137, 0.0171,
        0.0169, 0.0178, 0.0206, 0.0185, 0.0143], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,233][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0140, 0.0158, 0.0696, 0.0628, 0.0493, 0.0966, 0.0690, 0.1204, 0.1021,
        0.0664, 0.0812, 0.0789, 0.0655, 0.1085], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,234][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0131, 0.0726, 0.0737, 0.0728, 0.0843, 0.0863, 0.0671, 0.0797, 0.0742,
        0.0641, 0.0837, 0.0663, 0.0848, 0.0773], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,236][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0003, 0.1167, 0.0800, 0.0652, 0.0822, 0.0713, 0.0554, 0.0602, 0.0609,
        0.0486, 0.1004, 0.0759, 0.0855, 0.0975], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,237][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([1.3204e-02, 2.5115e-04, 1.1454e-02, 3.0957e-03, 2.4556e-02, 3.2404e-02,
        8.8941e-02, 3.5436e-01, 1.5589e-01, 4.5122e-02, 3.5560e-02, 1.9566e-02,
        2.8954e-02, 1.8284e-01, 3.8050e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,238][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([4.3627e-03, 9.1647e-08, 7.3522e-05, 5.6696e-06, 4.3501e-06, 2.9572e-03,
        2.5406e-03, 4.0126e-03, 2.8498e-02, 3.1391e-02, 2.5916e-01, 1.5412e-01,
        9.0432e-03, 4.5139e-01, 5.2441e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,240][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.1189, 0.0732, 0.0672, 0.0941, 0.0545, 0.0669, 0.0439, 0.0486, 0.0909,
        0.0434, 0.0593, 0.0716, 0.0601, 0.0555, 0.0517], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,242][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([1.6107e-04, 4.3999e-07, 1.0503e-04, 4.4540e-05, 1.2235e-05, 6.3909e-03,
        2.2919e-03, 3.9338e-03, 1.9391e-02, 3.1248e-02, 7.3402e-02, 6.3981e-01,
        1.9627e-02, 1.6789e-01, 3.5693e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,242][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0659, 0.0007, 0.1443, 0.0063, 0.0112, 0.0469, 0.1266, 0.0088, 0.0637,
        0.0123, 0.3697, 0.0012, 0.0080, 0.0519, 0.0825], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,243][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0105, 0.0452, 0.0874, 0.0745, 0.0549, 0.0901, 0.0527, 0.0769, 0.0801,
        0.0806, 0.0747, 0.0745, 0.0547, 0.0722, 0.0709], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,244][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0788, 0.0462, 0.1119, 0.0485, 0.0613, 0.0708, 0.0278, 0.0386, 0.0803,
        0.0462, 0.0791, 0.0760, 0.0941, 0.0697, 0.0707], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,246][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0122, 0.4854, 0.0650, 0.1288, 0.0503, 0.0165, 0.0261, 0.0227, 0.0190,
        0.0189, 0.0208, 0.0254, 0.0387, 0.0324, 0.0378], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,248][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.7465, 0.0155, 0.0139, 0.0158, 0.0140, 0.0141, 0.0182, 0.0166, 0.0208,
        0.0203, 0.0215, 0.0244, 0.0218, 0.0170, 0.0196], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,249][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0133, 0.0142, 0.0648, 0.0570, 0.0467, 0.0880, 0.0635, 0.1038, 0.0903,
        0.0650, 0.0734, 0.0700, 0.0607, 0.1025, 0.0866], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,251][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0118, 0.0672, 0.0690, 0.0618, 0.0832, 0.0826, 0.0647, 0.0724, 0.0697,
        0.0581, 0.0773, 0.0601, 0.0785, 0.0717, 0.0716], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,253][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0003, 0.1041, 0.0743, 0.0615, 0.0772, 0.0678, 0.0518, 0.0569, 0.0575,
        0.0453, 0.0914, 0.0700, 0.0789, 0.0906, 0.0723], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,254][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([1.1697e-03, 1.4311e-04, 4.9769e-04, 4.2949e-03, 5.1040e-02, 5.0555e-04,
        6.2277e-02, 1.5264e-01, 2.3505e-03, 2.2665e-01, 8.5449e-03, 2.0401e-02,
        2.8303e-01, 7.6969e-02, 1.0849e-01, 9.9647e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,255][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([1.2802e-02, 7.5676e-08, 4.3289e-05, 3.6082e-06, 4.9331e-06, 2.1327e-03,
        1.2720e-03, 2.5513e-03, 1.5697e-02, 3.9803e-02, 2.0565e-01, 1.8109e-01,
        1.2177e-02, 2.3570e-01, 1.1960e-01, 1.7147e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,257][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.1031, 0.0730, 0.0614, 0.0813, 0.0503, 0.0598, 0.0413, 0.0462, 0.0823,
        0.0432, 0.0534, 0.0736, 0.0528, 0.0476, 0.0480, 0.0825],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,258][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([1.4682e-03, 4.2213e-07, 7.7363e-05, 2.1999e-05, 1.5748e-05, 8.7331e-03,
        4.7799e-03, 3.1888e-03, 2.1762e-02, 3.8206e-02, 6.5462e-02, 4.4262e-01,
        3.6359e-02, 1.5665e-01, 1.0089e-01, 1.1976e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,260][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.1068, 0.0170, 0.1121, 0.0041, 0.0063, 0.0017, 0.3076, 0.0029, 0.0304,
        0.0079, 0.0984, 0.0260, 0.0381, 0.0026, 0.0015, 0.2366],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,262][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.0078, 0.0429, 0.0808, 0.0688, 0.0603, 0.0854, 0.0502, 0.0711, 0.0726,
        0.0741, 0.0710, 0.0714, 0.0544, 0.0622, 0.0693, 0.0576],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,264][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.0572, 0.0702, 0.0815, 0.0591, 0.0567, 0.0582, 0.0431, 0.0290, 0.0471,
        0.0486, 0.0548, 0.1162, 0.0820, 0.0516, 0.1088, 0.0361],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,265][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.0194, 0.4491, 0.0700, 0.1216, 0.0547, 0.0193, 0.0249, 0.0234, 0.0214,
        0.0182, 0.0223, 0.0254, 0.0422, 0.0300, 0.0378, 0.0204],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,267][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.7504, 0.0143, 0.0127, 0.0145, 0.0129, 0.0129, 0.0167, 0.0152, 0.0191,
        0.0186, 0.0197, 0.0226, 0.0201, 0.0155, 0.0180, 0.0168],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,268][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.0090, 0.0124, 0.0565, 0.0497, 0.0414, 0.0761, 0.0577, 0.0955, 0.0809,
        0.0564, 0.0665, 0.0640, 0.0548, 0.0967, 0.0827, 0.0997],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,269][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.0116, 0.0578, 0.0633, 0.0620, 0.0746, 0.0738, 0.0586, 0.0707, 0.0645,
        0.0531, 0.0763, 0.0527, 0.0811, 0.0698, 0.0668, 0.0632],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,270][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.0003, 0.0977, 0.0692, 0.0570, 0.0705, 0.0625, 0.0490, 0.0521, 0.0533,
        0.0429, 0.0860, 0.0678, 0.0746, 0.0853, 0.0688, 0.0629],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,271][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([3.3221e-03, 6.2722e-05, 3.1648e-04, 1.4610e-03, 2.3059e-02, 3.6652e-03,
        5.1024e-02, 2.1797e-03, 4.3872e-02, 3.0427e-01, 2.2741e-03, 8.8827e-03,
        8.4968e-02, 1.0357e-04, 4.2774e-01, 4.2672e-02, 1.2730e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,272][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([3.6293e-02, 4.3238e-08, 1.9857e-05, 2.1890e-06, 2.2341e-06, 1.5427e-03,
        9.0641e-04, 1.8803e-03, 1.4966e-02, 1.4141e-02, 1.4018e-01, 1.2871e-01,
        3.7468e-03, 9.9232e-02, 3.2191e-02, 1.9929e-01, 3.2691e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,274][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1002, 0.0679, 0.0587, 0.0827, 0.0514, 0.0592, 0.0382, 0.0444, 0.0738,
        0.0395, 0.0514, 0.0677, 0.0542, 0.0449, 0.0460, 0.0767, 0.0431],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,275][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.5833e-04, 3.4904e-07, 4.7464e-05, 1.7894e-05, 9.8230e-06, 5.9720e-03,
        1.6668e-03, 1.5692e-03, 1.2852e-02, 2.5478e-02, 6.2217e-02, 3.7968e-01,
        3.3331e-02, 9.1800e-02, 4.9726e-02, 1.3986e-01, 1.9482e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,277][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1060, 0.0036, 0.2087, 0.0099, 0.0038, 0.0227, 0.2682, 0.0090, 0.0189,
        0.0299, 0.2736, 0.0063, 0.0044, 0.0136, 0.0007, 0.0058, 0.0149],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,279][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0088, 0.0423, 0.0769, 0.0629, 0.0569, 0.0849, 0.0485, 0.0615, 0.0714,
        0.0708, 0.0647, 0.0681, 0.0509, 0.0465, 0.0715, 0.0664, 0.0472],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,281][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0739, 0.0377, 0.0888, 0.0427, 0.0557, 0.0531, 0.0336, 0.0348, 0.0612,
        0.0518, 0.0539, 0.0733, 0.0741, 0.0426, 0.1050, 0.0718, 0.0460],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,283][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0164, 0.4327, 0.0648, 0.1640, 0.0505, 0.0184, 0.0232, 0.0220, 0.0175,
        0.0195, 0.0175, 0.0216, 0.0349, 0.0289, 0.0295, 0.0149, 0.0235],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,284][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.7846, 0.0115, 0.0101, 0.0116, 0.0104, 0.0103, 0.0136, 0.0123, 0.0155,
        0.0154, 0.0161, 0.0188, 0.0168, 0.0129, 0.0149, 0.0139, 0.0112],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,286][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0103, 0.0114, 0.0510, 0.0468, 0.0359, 0.0695, 0.0533, 0.0869, 0.0734,
        0.0515, 0.0589, 0.0591, 0.0484, 0.0802, 0.0746, 0.0943, 0.0945],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,288][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0110, 0.0578, 0.0610, 0.0591, 0.0682, 0.0713, 0.0544, 0.0658, 0.0617,
        0.0522, 0.0692, 0.0531, 0.0699, 0.0642, 0.0597, 0.0565, 0.0649],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,290][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0003, 0.0922, 0.0633, 0.0525, 0.0648, 0.0580, 0.0449, 0.0490, 0.0499,
        0.0399, 0.0804, 0.0620, 0.0678, 0.0796, 0.0628, 0.0588, 0.0738],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,293][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:27,295][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 7588],
        [ 9869],
        [ 7587],
        [ 2358],
        [ 7578],
        [ 1698],
        [ 2098],
        [  725],
        [ 2505],
        [ 3336],
        [ 3930],
        [ 5558],
        [10647],
        [ 6755],
        [ 7764],
        [ 4346],
        [ 4277]], device='cuda:0')
[2024-07-24 10:31:27,297][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 7906],
        [24269],
        [22955],
        [ 5403],
        [13838],
        [ 8374],
        [11694],
        [ 4185],
        [11905],
        [15534],
        [13166],
        [22223],
        [18837],
        [14146],
        [19086],
        [ 9052],
        [12190]], device='cuda:0')
[2024-07-24 10:31:27,298][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 5137],
        [12515],
        [23720],
        [23985],
        [24488],
        [24869],
        [23867],
        [25456],
        [25607],
        [16250],
        [19277],
        [20762],
        [20899],
        [26471],
        [29644],
        [29438],
        [22469]], device='cuda:0')
[2024-07-24 10:31:27,300][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 7299],
        [ 6981],
        [ 6193],
        [ 3729],
        [ 3069],
        [ 1156],
        [ 1725],
        [ 1512],
        [ 1259],
        [ 2472],
        [ 3051],
        [ 5117],
        [11418],
        [  554],
        [ 2390],
        [ 1897],
        [  677]], device='cuda:0')
[2024-07-24 10:31:27,301][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[13548],
        [ 4448],
        [11043],
        [ 5497],
        [ 6043],
        [ 6356],
        [ 6051],
        [ 7552],
        [ 8566],
        [ 7942],
        [ 9161],
        [ 8046],
        [ 9537],
        [ 9129],
        [ 9834],
        [10676],
        [10629]], device='cuda:0')
[2024-07-24 10:31:27,303][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[40656],
        [40603],
        [39347],
        [37375],
        [37256],
        [37311],
        [38401],
        [37949],
        [37935],
        [37393],
        [37370],
        [37749],
        [37726],
        [37552],
        [37788],
        [38217],
        [38070]], device='cuda:0')
[2024-07-24 10:31:27,305][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[17071],
        [18392],
        [19631],
        [19781],
        [19783],
        [19666],
        [19833],
        [19853],
        [20015],
        [20020],
        [20166],
        [19969],
        [19952],
        [19981],
        [20091],
        [20168],
        [20151]], device='cuda:0')
[2024-07-24 10:31:27,307][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 4336],
        [ 8956],
        [12790],
        [20263],
        [22202],
        [10911],
        [22899],
        [26435],
        [20043],
        [14879],
        [15097],
        [27901],
        [43158],
        [43335],
        [43140],
        [39916],
        [39256]], device='cuda:0')
[2024-07-24 10:31:27,308][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[27854],
        [26690],
        [29046],
        [30567],
        [31897],
        [32769],
        [33299],
        [33140],
        [33097],
        [33335],
        [33414],
        [33603],
        [33613],
        [33622],
        [33673],
        [33653],
        [33647]], device='cuda:0')
[2024-07-24 10:31:27,310][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[26323],
        [ 9364],
        [ 6444],
        [ 7481],
        [ 7166],
        [ 7231],
        [ 7169],
        [ 6851],
        [ 6912],
        [ 7095],
        [ 6946],
        [ 7164],
        [ 6989],
        [ 6931],
        [ 6822],
        [ 6881],
        [ 6913]], device='cuda:0')
[2024-07-24 10:31:27,312][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 5738],
        [ 7308],
        [ 8691],
        [10174],
        [10622],
        [10572],
        [10695],
        [10822],
        [11023],
        [11520],
        [10954],
        [10945],
        [11532],
        [11165],
        [11512],
        [11620],
        [11228]], device='cuda:0')
[2024-07-24 10:31:27,314][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[6530],
        [8773],
        [7480],
        [6038],
        [6133],
        [5984],
        [6047],
        [6110],
        [6162],
        [6340],
        [6317],
        [6592],
        [6874],
        [7073],
        [7097],
        [7361],
        [7546]], device='cuda:0')
[2024-07-24 10:31:27,316][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[17499],
        [16058],
        [12580],
        [11363],
        [10913],
        [10430],
        [ 9087],
        [ 8353],
        [ 7675],
        [ 6896],
        [ 6368],
        [ 5936],
        [ 5571],
        [ 5130],
        [ 4607],
        [ 4188],
        [ 3928]], device='cuda:0')
[2024-07-24 10:31:27,318][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[14398],
        [14389],
        [ 7688],
        [18791],
        [18253],
        [18612],
        [15465],
        [ 1961],
        [23827],
        [12168],
        [12022],
        [12045],
        [12090],
        [10831],
        [ 8604],
        [ 8555],
        [ 6182]], device='cuda:0')
[2024-07-24 10:31:27,319][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 3918],
        [  640],
        [ 2471],
        [14178],
        [ 9154],
        [ 5775],
        [ 5834],
        [15953],
        [14837],
        [ 7433],
        [ 8082],
        [ 6651],
        [ 5813],
        [ 9757],
        [ 7001],
        [ 9354],
        [14242]], device='cuda:0')
[2024-07-24 10:31:27,321][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[10908],
        [10305],
        [ 5097],
        [ 3722],
        [ 3376],
        [ 2577],
        [ 2024],
        [ 1440],
        [  396],
        [  402],
        [ 2715],
        [  666],
        [  517],
        [ 4460],
        [ 1211],
        [  398],
        [ 4641]], device='cuda:0')
[2024-07-24 10:31:27,323][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[24545],
        [14450],
        [ 6001],
        [ 6011],
        [ 6118],
        [20974],
        [20344],
        [18639],
        [14608],
        [14198],
        [16760],
        [15977],
        [16021],
        [15836],
        [15276],
        [14503],
        [14246]], device='cuda:0')
[2024-07-24 10:31:27,325][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 7275],
        [16249],
        [13468],
        [13773],
        [11714],
        [11928],
        [12225],
        [12387],
        [11628],
        [11744],
        [11494],
        [12905],
        [12540],
        [12874],
        [12870],
        [12179],
        [12227]], device='cuda:0')
[2024-07-24 10:31:27,326][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[15863],
        [16723],
        [10213],
        [10597],
        [10937],
        [17774],
        [17583],
        [18707],
        [21834],
        [24530],
        [20786],
        [21481],
        [22026],
        [19678],
        [20876],
        [18362],
        [16821]], device='cuda:0')
[2024-07-24 10:31:27,328][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 3635],
        [ 4170],
        [ 5960],
        [ 1839],
        [ 1249],
        [ 1358],
        [ 2447],
        [  816],
        [ 1665],
        [ 3003],
        [ 1255],
        [ 2204],
        [26203],
        [ 7129],
        [11279],
        [ 2566],
        [ 6043]], device='cuda:0')
[2024-07-24 10:31:27,329][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[10186],
        [10158],
        [14378],
        [13276],
        [13559],
        [13169],
        [13268],
        [14510],
        [15777],
        [15994],
        [16071],
        [15637],
        [15275],
        [15586],
        [15654],
        [15991],
        [16202]], device='cuda:0')
[2024-07-24 10:31:27,331][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 6683],
        [10057],
        [12875],
        [13918],
        [13861],
        [15041],
        [15672],
        [15406],
        [15895],
        [15988],
        [16556],
        [17480],
        [16991],
        [17545],
        [17787],
        [16783],
        [17409]], device='cuda:0')
[2024-07-24 10:31:27,333][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[31675],
        [36794],
        [36366],
        [39235],
        [38548],
        [37877],
        [37710],
        [37354],
        [36910],
        [37510],
        [36988],
        [36997],
        [37278],
        [37305],
        [37524],
        [37295],
        [37440]], device='cuda:0')
[2024-07-24 10:31:27,335][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[4094],
        [4094],
        [4181],
        [4320],
        [4359],
        [4441],
        [4535],
        [4582],
        [4713],
        [4774],
        [4833],
        [4890],
        [4937],
        [4858],
        [5067],
        [5109],
        [5037]], device='cuda:0')
[2024-07-24 10:31:27,336][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[31589],
        [11646],
        [13366],
        [11763],
        [10641],
        [10709],
        [10456],
        [10643],
        [10721],
        [10720],
        [10786],
        [10842],
        [10581],
        [11083],
        [11121],
        [11258],
        [11717]], device='cuda:0')
[2024-07-24 10:31:27,338][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[1141],
        [ 503],
        [ 639],
        [ 389],
        [ 710],
        [ 779],
        [ 591],
        [ 626],
        [ 712],
        [ 663],
        [ 673],
        [ 680],
        [ 834],
        [ 813],
        [ 829],
        [ 890],
        [ 870]], device='cuda:0')
[2024-07-24 10:31:27,340][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[27293],
        [36192],
        [37439],
        [37314],
        [37102],
        [36885],
        [36934],
        [36943],
        [36744],
        [36784],
        [36868],
        [36939],
        [37101],
        [37212],
        [37245],
        [37177],
        [37147]], device='cuda:0')
[2024-07-24 10:31:27,342][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[36113],
        [39234],
        [40882],
        [42549],
        [42850],
        [39098],
        [40195],
        [40505],
        [42464],
        [42286],
        [38586],
        [42163],
        [39373],
        [35423],
        [37947],
        [39895],
        [36059]], device='cuda:0')
[2024-07-24 10:31:27,344][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[47351],
        [47325],
        [45651],
        [37988],
        [45346],
        [41480],
        [40798],
        [24331],
        [25904],
        [32463],
        [36628],
        [28396],
        [38083],
        [35237],
        [38859],
        [41539],
        [26962]], device='cuda:0')
[2024-07-24 10:31:27,346][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[8305],
        [8305],
        [8305],
        [8305],
        [8305],
        [8305],
        [8305],
        [8305],
        [8305],
        [8305],
        [8305],
        [8305],
        [8305],
        [8305],
        [8305],
        [8305],
        [8305]], device='cuda:0')
[2024-07-24 10:31:27,402][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:27,403][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,404][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,405][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,407][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,408][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,409][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,411][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,412][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,413][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,415][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,416][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,417][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,419][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.5834, 0.4166], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,421][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.4646, 0.5354], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,422][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.7562, 0.2438], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,424][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.0902, 0.9098], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,425][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.0836, 0.9164], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,427][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.4219, 0.5781], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,428][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.4991, 0.5009], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,428][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.1496, 0.8504], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,429][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.4288, 0.5712], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,430][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.1434, 0.8566], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,432][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.0852, 0.9148], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,433][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.1657, 0.8343], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,435][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.5550, 0.2617, 0.1833], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,436][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1188, 0.3745, 0.5067], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,438][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.5890, 0.2810, 0.1299], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,439][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0465, 0.4706, 0.4829], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,441][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0176, 0.2255, 0.7569], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,443][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2031, 0.2426, 0.5542], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,444][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.4101, 0.5212, 0.0687], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,446][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1878, 0.4601, 0.3521], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,447][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0548, 0.4865, 0.4587], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,449][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0778, 0.4451, 0.4771], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,450][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0464, 0.5283, 0.4254], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,452][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0754, 0.3931, 0.5315], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,453][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Nathan] are: tensor([0.7536, 0.1211, 0.0682, 0.0572], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,454][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Nathan] are: tensor([0.0399, 0.2758, 0.5016, 0.1827], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,455][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Nathan] are: tensor([0.4864, 0.1673, 0.2128, 0.1334], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,456][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Nathan] are: tensor([0.0302, 0.3262, 0.3361, 0.3075], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,457][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Nathan] are: tensor([0.0100, 0.1269, 0.4759, 0.3871], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,459][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Nathan] are: tensor([0.1119, 0.1575, 0.4076, 0.3230], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,460][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Nathan] are: tensor([0.3968, 0.5046, 0.0526, 0.0460], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,462][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Nathan] are: tensor([0.0743, 0.2943, 0.1849, 0.4465], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,463][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Nathan] are: tensor([0.1237, 0.0591, 0.4600, 0.3571], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,465][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Nathan] are: tensor([0.0505, 0.3052, 0.3273, 0.3170], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,467][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Nathan] are: tensor([0.0264, 0.3906, 0.3105, 0.2725], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,468][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Nathan] are: tensor([0.0569, 0.2829, 0.3557, 0.3046], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,470][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.6589, 0.1459, 0.0858, 0.0511, 0.0583], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,471][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.0422, 0.1511, 0.4277, 0.1330, 0.2460], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,473][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.5371, 0.1638, 0.1373, 0.1077, 0.0542], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,475][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.0236, 0.2572, 0.2624, 0.2402, 0.2165], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,476][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.0094, 0.0953, 0.3179, 0.2607, 0.3167], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,478][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.0931, 0.1074, 0.2494, 0.2077, 0.3425], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,479][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.3562, 0.5575, 0.0349, 0.0316, 0.0197], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,480][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.0471, 0.2653, 0.1964, 0.4499, 0.0412], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,481][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.0336, 0.0922, 0.1209, 0.4355, 0.3178], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,481][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.0369, 0.2351, 0.2530, 0.2446, 0.2303], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,482][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.0146, 0.3497, 0.2729, 0.2274, 0.1353], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,484][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.0405, 0.2098, 0.2798, 0.2255, 0.2445], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,485][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.5908, 0.1564, 0.0859, 0.0473, 0.0522, 0.0673], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,487][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0308, 0.0832, 0.2333, 0.1154, 0.4176, 0.1197], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,489][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.3416, 0.1832, 0.1525, 0.1724, 0.0982, 0.0522], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,490][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0211, 0.2091, 0.2118, 0.1950, 0.1771, 0.1859], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,492][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0099, 0.0598, 0.1724, 0.1415, 0.1721, 0.4442], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,493][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0912, 0.0873, 0.1950, 0.1608, 0.2703, 0.1955], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,495][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2989, 0.5245, 0.0429, 0.0594, 0.0510, 0.0234], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,497][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0744, 0.2475, 0.1861, 0.3381, 0.0706, 0.0833], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,498][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0276, 0.0241, 0.0440, 0.1199, 0.3244, 0.4600], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,500][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0314, 0.1893, 0.2033, 0.1969, 0.1854, 0.1935], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,502][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0240, 0.2605, 0.2025, 0.1795, 0.1166, 0.2169], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,504][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0340, 0.1797, 0.2215, 0.1746, 0.1845, 0.2057], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,505][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.5680, 0.1109, 0.0666, 0.0499, 0.0516, 0.0690, 0.0841],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,506][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.0211, 0.0529, 0.1184, 0.1330, 0.5007, 0.1426, 0.0314],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,507][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.2978, 0.1245, 0.1219, 0.1200, 0.1077, 0.1005, 0.1276],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,508][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0179, 0.1786, 0.1801, 0.1651, 0.1510, 0.1591, 0.1482],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,509][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0105, 0.0420, 0.1282, 0.1025, 0.1263, 0.3308, 0.2596],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,511][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.0492, 0.0795, 0.1946, 0.1501, 0.2280, 0.1420, 0.1566],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,513][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.3193, 0.4924, 0.0368, 0.0421, 0.0230, 0.0159, 0.0704],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,514][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.0321, 0.2216, 0.1560, 0.2467, 0.0407, 0.1138, 0.1892],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,516][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.0300, 0.0072, 0.0149, 0.0364, 0.0848, 0.5445, 0.2823],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,517][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0276, 0.1584, 0.1697, 0.1646, 0.1552, 0.1619, 0.1625],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,519][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0170, 0.2240, 0.1692, 0.1488, 0.0937, 0.1834, 0.1639],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,521][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0307, 0.1505, 0.1864, 0.1589, 0.1588, 0.1641, 0.1506],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,522][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.5786, 0.1432, 0.0702, 0.0379, 0.0440, 0.0527, 0.0429, 0.0305],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,524][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0218, 0.0521, 0.1010, 0.1408, 0.3191, 0.2001, 0.1302, 0.0349],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,526][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.2013, 0.1435, 0.0993, 0.1003, 0.0655, 0.0695, 0.2688, 0.0519],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,528][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0166, 0.1541, 0.1547, 0.1437, 0.1308, 0.1356, 0.1273, 0.1373],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,529][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0056, 0.0320, 0.0954, 0.0779, 0.1006, 0.2667, 0.2128, 0.2089],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,531][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0504, 0.0541, 0.1518, 0.1194, 0.2055, 0.1358, 0.1397, 0.1433],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,532][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1955, 0.4029, 0.0610, 0.0773, 0.0594, 0.0211, 0.1244, 0.0584],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,533][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0315, 0.1733, 0.1388, 0.2227, 0.0522, 0.0822, 0.2091, 0.0902],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,533][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0069, 0.0026, 0.0082, 0.0295, 0.0481, 0.3596, 0.4213, 0.1237],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,534][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0236, 0.1360, 0.1458, 0.1412, 0.1330, 0.1389, 0.1400, 0.1415],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,536][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0164, 0.1842, 0.1433, 0.1279, 0.0832, 0.1533, 0.1340, 0.1578],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,537][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0254, 0.1249, 0.1691, 0.1244, 0.1446, 0.1494, 0.1206, 0.1416],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,539][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.6056, 0.1134, 0.0546, 0.0331, 0.0359, 0.0463, 0.0476, 0.0283, 0.0351],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,541][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0283, 0.0330, 0.1159, 0.0773, 0.3087, 0.1204, 0.0918, 0.1895, 0.0351],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,542][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2262, 0.1117, 0.1000, 0.1060, 0.0656, 0.0513, 0.2042, 0.0734, 0.0617],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,544][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0144, 0.1344, 0.1356, 0.1259, 0.1148, 0.1189, 0.1118, 0.1204, 0.1239],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,546][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0059, 0.0262, 0.0756, 0.0622, 0.0779, 0.2119, 0.1647, 0.1674, 0.2081],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,547][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0570, 0.0483, 0.1322, 0.1020, 0.1758, 0.1160, 0.1264, 0.1281, 0.1142],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,549][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1848, 0.4861, 0.0526, 0.0670, 0.0433, 0.0115, 0.1164, 0.0301, 0.0084],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,551][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0467, 0.1784, 0.1418, 0.2077, 0.0428, 0.0576, 0.1514, 0.1003, 0.0732],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,553][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0129, 0.0040, 0.0038, 0.0191, 0.0338, 0.1452, 0.2916, 0.2257, 0.2637],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,554][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0209, 0.1193, 0.1278, 0.1238, 0.1165, 0.1214, 0.1227, 0.1240, 0.1237],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,556][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0150, 0.1576, 0.1225, 0.1100, 0.0723, 0.1309, 0.1159, 0.1340, 0.1418],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,558][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0246, 0.1142, 0.1446, 0.1114, 0.1249, 0.1295, 0.1045, 0.1140, 0.1322],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,559][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([0.4939, 0.1082, 0.0578, 0.0469, 0.0503, 0.0580, 0.0599, 0.0331, 0.0453,
        0.0465], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,559][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([0.0181, 0.0623, 0.1753, 0.0826, 0.2998, 0.1108, 0.0508, 0.1001, 0.0816,
        0.0185], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,560][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([0.2393, 0.0946, 0.0669, 0.0973, 0.0782, 0.0745, 0.1370, 0.0532, 0.0822,
        0.0768], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,562][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([0.0125, 0.1220, 0.1220, 0.1121, 0.1029, 0.1084, 0.1004, 0.1103, 0.1136,
        0.0958], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,563][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([0.0056, 0.0201, 0.0603, 0.0476, 0.0593, 0.1623, 0.1301, 0.1340, 0.1674,
        0.2134], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,565][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([0.0260, 0.0396, 0.1031, 0.0794, 0.1351, 0.0801, 0.0915, 0.0991, 0.0915,
        0.2545], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,567][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.1675, 0.4987, 0.0593, 0.0686, 0.0469, 0.0079, 0.1241, 0.0180, 0.0045,
        0.0045], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,568][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([0.0334, 0.1681, 0.1290, 0.1888, 0.0329, 0.0646, 0.1560, 0.1024, 0.0716,
        0.0532], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,570][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.0138, 0.0010, 0.0026, 0.0166, 0.0241, 0.1095, 0.1101, 0.1079, 0.3677,
        0.2466], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,572][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([0.0185, 0.1063, 0.1138, 0.1104, 0.1041, 0.1085, 0.1092, 0.1104, 0.1101,
        0.1087], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,573][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([0.0100, 0.1489, 0.1150, 0.0993, 0.0623, 0.1215, 0.1058, 0.1252, 0.1300,
        0.0819], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,575][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([0.0197, 0.1037, 0.1339, 0.1079, 0.1091, 0.1090, 0.0968, 0.1001, 0.1130,
        0.1066], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,577][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4974, 0.1079, 0.0583, 0.0374, 0.0405, 0.0526, 0.0478, 0.0306, 0.0392,
        0.0410, 0.0473], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,579][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0091, 0.0338, 0.0585, 0.0948, 0.3048, 0.1325, 0.0842, 0.0827, 0.0677,
        0.0731, 0.0587], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,580][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1320, 0.1177, 0.0636, 0.1149, 0.0622, 0.0449, 0.1772, 0.0552, 0.0807,
        0.1072, 0.0444], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,582][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0118, 0.1107, 0.1105, 0.1028, 0.0938, 0.0972, 0.0913, 0.0985, 0.1014,
        0.0871, 0.0950], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,583][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0037, 0.0191, 0.0512, 0.0423, 0.0525, 0.1360, 0.1119, 0.1108, 0.1441,
        0.1899, 0.1385], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,584][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0299, 0.0369, 0.0860, 0.0686, 0.1133, 0.0776, 0.0818, 0.0880, 0.0832,
        0.1900, 0.1446], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,585][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3309, 0.4251, 0.0373, 0.0429, 0.0187, 0.0062, 0.0516, 0.0305, 0.0171,
        0.0257, 0.0141], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,586][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0424, 0.1413, 0.1117, 0.2191, 0.0321, 0.0595, 0.1314, 0.0807, 0.0715,
        0.0544, 0.0559], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,587][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0072, 0.0020, 0.0015, 0.0071, 0.0096, 0.0481, 0.0897, 0.0871, 0.2425,
        0.4565, 0.0488], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,588][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0168, 0.0959, 0.1028, 0.0994, 0.0936, 0.0977, 0.0987, 0.0997, 0.0995,
        0.0984, 0.0976], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,590][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0122, 0.1282, 0.1014, 0.0912, 0.0607, 0.1074, 0.0944, 0.1101, 0.1154,
        0.0730, 0.1061], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,592][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0177, 0.0917, 0.1244, 0.0907, 0.0997, 0.1017, 0.0872, 0.0904, 0.1025,
        0.0924, 0.1017], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,593][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.3372, 0.0883, 0.0599, 0.0419, 0.0460, 0.0633, 0.0619, 0.0350, 0.0512,
        0.0485, 0.0538, 0.1131], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,595][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.0131, 0.0386, 0.0709, 0.1040, 0.2315, 0.0989, 0.0229, 0.1118, 0.0695,
        0.0222, 0.1859, 0.0308], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,596][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.2143, 0.0613, 0.0799, 0.0666, 0.0567, 0.0552, 0.1005, 0.0463, 0.0787,
        0.0714, 0.0812, 0.0881], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,598][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.0105, 0.1008, 0.1012, 0.0929, 0.0855, 0.0895, 0.0832, 0.0913, 0.0940,
        0.0794, 0.0880, 0.0835], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,600][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.0039, 0.0164, 0.0461, 0.0377, 0.0472, 0.1214, 0.0980, 0.1011, 0.1237,
        0.1653, 0.1232, 0.1161], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,602][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.0276, 0.0331, 0.0801, 0.0669, 0.1045, 0.0635, 0.0741, 0.0740, 0.0697,
        0.1865, 0.1363, 0.0836], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,603][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.2045, 0.4776, 0.0511, 0.0582, 0.0350, 0.0062, 0.1010, 0.0174, 0.0042,
        0.0046, 0.0272, 0.0130], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,605][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.0240, 0.1335, 0.0868, 0.2313, 0.0263, 0.0474, 0.0912, 0.0609, 0.0562,
        0.0653, 0.0489, 0.1284], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,607][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.0574, 0.0005, 0.0014, 0.0047, 0.0130, 0.0377, 0.0539, 0.0686, 0.1457,
        0.1865, 0.0917, 0.3388], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,609][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.0154, 0.0871, 0.0933, 0.0908, 0.0856, 0.0892, 0.0898, 0.0907, 0.0904,
        0.0895, 0.0887, 0.0896], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,610][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.0084, 0.1244, 0.0941, 0.0839, 0.0528, 0.0996, 0.0872, 0.1015, 0.1062,
        0.0657, 0.0970, 0.0792], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,610][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.0190, 0.0875, 0.1055, 0.0944, 0.0939, 0.0927, 0.0817, 0.0848, 0.0906,
        0.0890, 0.0887, 0.0722], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,611][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.4766, 0.0835, 0.0446, 0.0322, 0.0322, 0.0411, 0.0405, 0.0252, 0.0336,
        0.0345, 0.0354, 0.0679, 0.0526], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,612][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0239, 0.0437, 0.0953, 0.0414, 0.1130, 0.1158, 0.0669, 0.0892, 0.0810,
        0.0795, 0.1676, 0.0382, 0.0445], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,614][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.1371, 0.0797, 0.0751, 0.0708, 0.0555, 0.0497, 0.1229, 0.0547, 0.0754,
        0.0741, 0.0596, 0.1032, 0.0422], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,616][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0097, 0.0940, 0.0939, 0.0864, 0.0791, 0.0829, 0.0773, 0.0841, 0.0868,
        0.0736, 0.0813, 0.0779, 0.0731], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,617][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0028, 0.0152, 0.0397, 0.0337, 0.0397, 0.1053, 0.0896, 0.0887, 0.1129,
        0.1469, 0.1090, 0.1072, 0.1091], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,619][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0177, 0.0266, 0.0669, 0.0563, 0.0939, 0.0559, 0.0608, 0.0659, 0.0646,
        0.1836, 0.1232, 0.0780, 0.1066], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,621][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.1793, 0.5935, 0.0434, 0.0447, 0.0260, 0.0039, 0.0682, 0.0089, 0.0019,
        0.0023, 0.0186, 0.0074, 0.0021], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,623][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0301, 0.1351, 0.1016, 0.1583, 0.0218, 0.0672, 0.1115, 0.0708, 0.0626,
        0.0500, 0.0479, 0.1230, 0.0201], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,624][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([3.1641e-03, 5.2105e-04, 4.1750e-04, 2.5439e-03, 6.3810e-03, 1.8657e-02,
        4.7941e-02, 1.9974e-02, 6.7919e-02, 1.8852e-01, 3.4410e-02, 5.5059e-01,
        5.8957e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,625][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0135, 0.0802, 0.0861, 0.0835, 0.0787, 0.0821, 0.0826, 0.0836, 0.0834,
        0.0825, 0.0819, 0.0825, 0.0793], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,627][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0079, 0.1146, 0.0883, 0.0773, 0.0489, 0.0947, 0.0801, 0.0974, 0.1007,
        0.0610, 0.0929, 0.0732, 0.0631], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,629][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0166, 0.0749, 0.0988, 0.0804, 0.0900, 0.0865, 0.0738, 0.0791, 0.0854,
        0.0754, 0.0845, 0.0618, 0.0927], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,631][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.5124, 0.0823, 0.0380, 0.0257, 0.0254, 0.0346, 0.0337, 0.0198, 0.0256,
        0.0295, 0.0314, 0.0625, 0.0481, 0.0310], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,632][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0083, 0.0315, 0.0441, 0.0863, 0.1009, 0.1111, 0.0574, 0.0436, 0.0705,
        0.0502, 0.0575, 0.0380, 0.2795, 0.0211], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,634][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1388, 0.0911, 0.0508, 0.0743, 0.0339, 0.0426, 0.1396, 0.0449, 0.0661,
        0.0800, 0.0562, 0.1099, 0.0447, 0.0272], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,635][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0094, 0.0873, 0.0873, 0.0811, 0.0740, 0.0765, 0.0716, 0.0777, 0.0799,
        0.0684, 0.0748, 0.0719, 0.0679, 0.0722], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,636][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0027, 0.0144, 0.0363, 0.0314, 0.0376, 0.0933, 0.0807, 0.0784, 0.1014,
        0.1346, 0.0956, 0.0978, 0.0990, 0.0966], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,637][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0257, 0.0267, 0.0628, 0.0523, 0.0892, 0.0618, 0.0639, 0.0642, 0.0607,
        0.1421, 0.1098, 0.0705, 0.0977, 0.0725], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,638][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.4041, 0.4158, 0.0151, 0.0202, 0.0093, 0.0042, 0.0306, 0.0204, 0.0085,
        0.0118, 0.0056, 0.0191, 0.0103, 0.0250], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,639][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0270, 0.1221, 0.0686, 0.1848, 0.0352, 0.0467, 0.1271, 0.0577, 0.0546,
        0.0493, 0.0443, 0.1050, 0.0336, 0.0439], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,641][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([5.0237e-03, 3.7391e-04, 2.6522e-04, 1.4957e-03, 2.5092e-03, 1.5029e-02,
        3.6262e-02, 1.8718e-02, 8.2902e-02, 1.4794e-01, 4.1780e-02, 4.4993e-01,
        9.9456e-02, 9.8314e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,642][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0128, 0.0744, 0.0799, 0.0772, 0.0726, 0.0758, 0.0766, 0.0775, 0.0773,
        0.0764, 0.0758, 0.0764, 0.0735, 0.0738], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,644][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0093, 0.1006, 0.0813, 0.0730, 0.0485, 0.0863, 0.0754, 0.0884, 0.0919,
        0.0580, 0.0843, 0.0693, 0.0590, 0.0747], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,646][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0150, 0.0724, 0.0981, 0.0743, 0.0811, 0.0799, 0.0680, 0.0733, 0.0808,
        0.0730, 0.0798, 0.0593, 0.0750, 0.0698], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,648][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.5379, 0.0743, 0.0376, 0.0218, 0.0238, 0.0300, 0.0317, 0.0185, 0.0241,
        0.0267, 0.0275, 0.0567, 0.0391, 0.0277, 0.0226], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,650][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0132, 0.0849, 0.1220, 0.0405, 0.0870, 0.1238, 0.0263, 0.0924, 0.0698,
        0.0616, 0.0938, 0.0695, 0.0662, 0.0340, 0.0148], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,651][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.1189, 0.0895, 0.0573, 0.0762, 0.0354, 0.0418, 0.1246, 0.0446, 0.0592,
        0.0658, 0.0581, 0.1132, 0.0447, 0.0365, 0.0340], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,653][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0087, 0.0815, 0.0813, 0.0753, 0.0690, 0.0716, 0.0670, 0.0727, 0.0749,
        0.0640, 0.0702, 0.0674, 0.0637, 0.0681, 0.0644], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,655][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0026, 0.0131, 0.0329, 0.0285, 0.0326, 0.0822, 0.0734, 0.0728, 0.0932,
        0.1220, 0.0881, 0.0906, 0.0912, 0.0914, 0.0854], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,657][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0180, 0.0256, 0.0559, 0.0492, 0.0724, 0.0502, 0.0556, 0.0568, 0.0573,
        0.1397, 0.0978, 0.0694, 0.0850, 0.0642, 0.1032], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,658][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.1511, 0.4153, 0.0471, 0.0515, 0.0299, 0.0075, 0.0687, 0.0190, 0.0064,
        0.0104, 0.0317, 0.0361, 0.0106, 0.0955, 0.0193], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,660][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0176, 0.1061, 0.1006, 0.1414, 0.0283, 0.0600, 0.1202, 0.0753, 0.0566,
        0.0435, 0.0563, 0.0875, 0.0220, 0.0617, 0.0229], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,661][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ give] are: tensor([5.5588e-03, 1.0154e-03, 3.1240e-04, 2.0617e-03, 1.5952e-03, 9.9966e-03,
        2.7308e-02, 2.8792e-02, 4.7272e-02, 1.2491e-01, 2.4002e-02, 5.2770e-01,
        5.5455e-02, 1.1359e-01, 3.0430e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,662][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0120, 0.0693, 0.0742, 0.0719, 0.0677, 0.0706, 0.0713, 0.0720, 0.0718,
        0.0712, 0.0705, 0.0712, 0.0682, 0.0687, 0.0694], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,663][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0067, 0.1015, 0.0763, 0.0671, 0.0419, 0.0832, 0.0720, 0.0858, 0.0896,
        0.0525, 0.0817, 0.0650, 0.0541, 0.0706, 0.0518], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,664][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0140, 0.0665, 0.0886, 0.0667, 0.0771, 0.0769, 0.0626, 0.0683, 0.0755,
        0.0678, 0.0732, 0.0535, 0.0733, 0.0611, 0.0749], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,666][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.5042, 0.0710, 0.0328, 0.0224, 0.0204, 0.0286, 0.0343, 0.0174, 0.0232,
        0.0278, 0.0285, 0.0628, 0.0404, 0.0275, 0.0240, 0.0347],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,667][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.0068, 0.0161, 0.0833, 0.0279, 0.1293, 0.0555, 0.0436, 0.1404, 0.0171,
        0.0379, 0.1898, 0.0142, 0.0481, 0.0919, 0.0896, 0.0087],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,669][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0968, 0.0743, 0.0559, 0.0712, 0.0394, 0.0391, 0.1079, 0.0436, 0.0494,
        0.0746, 0.0564, 0.1076, 0.0436, 0.0475, 0.0388, 0.0538],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,671][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.0080, 0.0764, 0.0762, 0.0707, 0.0649, 0.0672, 0.0629, 0.0681, 0.0700,
        0.0605, 0.0658, 0.0634, 0.0600, 0.0639, 0.0605, 0.0614],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,673][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.0024, 0.0115, 0.0293, 0.0263, 0.0306, 0.0763, 0.0662, 0.0653, 0.0831,
        0.1141, 0.0797, 0.0812, 0.0820, 0.0811, 0.0793, 0.0916],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,674][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.0193, 0.0206, 0.0540, 0.0421, 0.0709, 0.0471, 0.0503, 0.0526, 0.0474,
        0.1276, 0.0958, 0.0566, 0.0787, 0.0612, 0.1053, 0.0706],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,676][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.2362, 0.5625, 0.0167, 0.0257, 0.0122, 0.0042, 0.0404, 0.0150, 0.0036,
        0.0057, 0.0106, 0.0133, 0.0038, 0.0314, 0.0053, 0.0133],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,678][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0252, 0.1279, 0.0930, 0.1624, 0.0263, 0.0319, 0.0883, 0.0565, 0.0468,
        0.0393, 0.0470, 0.1020, 0.0290, 0.0549, 0.0324, 0.0372],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,680][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0140, 0.0008, 0.0007, 0.0024, 0.0040, 0.0131, 0.0206, 0.0236, 0.0604,
        0.1255, 0.0313, 0.2929, 0.1002, 0.1380, 0.1375, 0.0349],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,681][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.0113, 0.0648, 0.0693, 0.0672, 0.0632, 0.0660, 0.0666, 0.0672, 0.0671,
        0.0664, 0.0659, 0.0665, 0.0638, 0.0641, 0.0649, 0.0657],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,683][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.0072, 0.0905, 0.0701, 0.0627, 0.0412, 0.0770, 0.0675, 0.0789, 0.0829,
        0.0501, 0.0760, 0.0615, 0.0515, 0.0661, 0.0500, 0.0668],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,685][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.0150, 0.0651, 0.0798, 0.0635, 0.0688, 0.0685, 0.0595, 0.0630, 0.0728,
        0.0625, 0.0676, 0.0531, 0.0698, 0.0574, 0.0656, 0.0679],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:27,687][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.5291, 0.0738, 0.0317, 0.0190, 0.0185, 0.0257, 0.0265, 0.0153, 0.0199,
        0.0231, 0.0251, 0.0555, 0.0371, 0.0255, 0.0199, 0.0296, 0.0245],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,688][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0058, 0.0285, 0.0386, 0.0817, 0.0910, 0.1053, 0.0557, 0.0351, 0.0599,
        0.0477, 0.0466, 0.0340, 0.2426, 0.0175, 0.0526, 0.0421, 0.0152],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,689][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1187, 0.0812, 0.0431, 0.0649, 0.0313, 0.0386, 0.1091, 0.0372, 0.0597,
        0.0632, 0.0497, 0.1011, 0.0394, 0.0231, 0.0327, 0.0826, 0.0246],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,690][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0076, 0.0723, 0.0722, 0.0671, 0.0613, 0.0632, 0.0592, 0.0641, 0.0660,
        0.0566, 0.0617, 0.0593, 0.0562, 0.0597, 0.0566, 0.0576, 0.0593],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,691][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0025, 0.0111, 0.0276, 0.0238, 0.0282, 0.0693, 0.0603, 0.0593, 0.0760,
        0.1003, 0.0735, 0.0743, 0.0770, 0.0748, 0.0722, 0.0863, 0.0835],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,693][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0215, 0.0209, 0.0469, 0.0402, 0.0683, 0.0482, 0.0495, 0.0495, 0.0466,
        0.1095, 0.0860, 0.0567, 0.0766, 0.0564, 0.0926, 0.0672, 0.0632],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,695][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3057, 0.3746, 0.0207, 0.0309, 0.0226, 0.0060, 0.0541, 0.0262, 0.0090,
        0.0076, 0.0147, 0.0140, 0.0063, 0.0460, 0.0082, 0.0215, 0.0318],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,696][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0235, 0.1056, 0.0626, 0.1638, 0.0330, 0.0421, 0.1121, 0.0541, 0.0495,
        0.0458, 0.0416, 0.0889, 0.0315, 0.0409, 0.0355, 0.0305, 0.0390],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,698][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([7.2830e-03, 3.1458e-04, 2.0819e-04, 1.1979e-03, 1.8064e-03, 9.6892e-03,
        2.6801e-02, 1.3152e-02, 4.9847e-02, 8.4089e-02, 2.8762e-02, 3.0437e-01,
        6.6287e-02, 6.7689e-02, 1.1573e-01, 1.2157e-01, 1.0121e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,699][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0103, 0.0608, 0.0653, 0.0631, 0.0594, 0.0620, 0.0626, 0.0633, 0.0632,
        0.0624, 0.0619, 0.0624, 0.0600, 0.0603, 0.0610, 0.0619, 0.0602],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,701][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0068, 0.0837, 0.0679, 0.0606, 0.0401, 0.0719, 0.0631, 0.0739, 0.0761,
        0.0478, 0.0694, 0.0574, 0.0491, 0.0614, 0.0474, 0.0616, 0.0618],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,703][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0125, 0.0605, 0.0800, 0.0613, 0.0668, 0.0655, 0.0554, 0.0604, 0.0664,
        0.0601, 0.0647, 0.0493, 0.0619, 0.0570, 0.0632, 0.0560, 0.0589],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:27,757][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:27,759][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,760][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,762][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,763][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,764][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,766][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,767][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,768][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,770][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,771][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,773][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,773][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:27,774][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.0145, 0.9855], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,775][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.0623, 0.9377], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,776][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.8976, 0.1024], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,777][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.4631, 0.5369], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,779][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.1929, 0.8071], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,780][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.9620, 0.0380], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,782][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.6189, 0.3811], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,783][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.6805, 0.3195], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,785][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.1286, 0.8714], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,787][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.2609, 0.7391], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,788][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.7319, 0.2681], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,790][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.3618, 0.6382], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:27,791][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0105, 0.5140, 0.4755], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,793][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0576, 0.5054, 0.4370], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,795][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.7468, 0.0008, 0.2524], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,796][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.4103, 0.2121, 0.3776], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,798][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1073, 0.3609, 0.5318], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,799][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9650, 0.0264, 0.0086], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,800][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0762, 0.0086, 0.9152], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,801][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.7123, 0.0016, 0.2861], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,801][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0743, 0.4650, 0.4607], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,802][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1582, 0.4026, 0.4392], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,804][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.5910, 0.1463, 0.2627], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,805][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1277, 0.1550, 0.7172], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:27,807][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Nathan] are: tensor([0.0074, 0.3052, 0.3009, 0.3864], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,808][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Nathan] are: tensor([0.0222, 0.2712, 0.2739, 0.4327], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,809][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Nathan] are: tensor([6.7370e-01, 4.7222e-04, 2.5572e-01, 7.0105e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,811][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Nathan] are: tensor([0.3175, 0.1743, 0.3065, 0.2017], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,813][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Nathan] are: tensor([0.0875, 0.2299, 0.3750, 0.3075], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,814][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Nathan] are: tensor([0.9139, 0.0300, 0.0534, 0.0028], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,816][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Nathan] are: tensor([0.0839, 0.0038, 0.8572, 0.0551], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,817][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Nathan] are: tensor([0.7619, 0.0014, 0.1954, 0.0414], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,819][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Nathan] are: tensor([0.0494, 0.2795, 0.4022, 0.2690], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,821][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Nathan] are: tensor([0.1056, 0.2860, 0.3047, 0.3037], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,822][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Nathan] are: tensor([0.6126, 0.0732, 0.1663, 0.1480], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,824][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Nathan] are: tensor([0.1858, 0.4474, 0.2199, 0.1468], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:27,825][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.0057, 0.2222, 0.2179, 0.2795, 0.2747], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,826][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.0275, 0.1737, 0.2052, 0.2890, 0.3046], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,827][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.3795, 0.0010, 0.3500, 0.1496, 0.1198], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,827][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.2260, 0.1723, 0.2727, 0.1890, 0.1400], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,829][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.0637, 0.1820, 0.3039, 0.2610, 0.1893], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,831][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.7442, 0.1365, 0.0576, 0.0400, 0.0217], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,832][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.0405, 0.0063, 0.5411, 0.2176, 0.1945], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,834][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([4.0195e-01, 3.5268e-04, 2.2653e-01, 7.2210e-02, 2.9896e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,835][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.0306, 0.2181, 0.2748, 0.2314, 0.2451], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,836][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.0824, 0.2137, 0.2286, 0.2381, 0.2373], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,838][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.3656, 0.1044, 0.2016, 0.1372, 0.1912], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,840][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.1226, 0.0537, 0.1124, 0.0493, 0.6621], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:27,841][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0048, 0.1793, 0.1820, 0.2277, 0.2261, 0.1801], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,843][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0213, 0.1430, 0.1615, 0.2298, 0.2923, 0.1520], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,844][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([7.4825e-01, 1.0886e-05, 4.4379e-04, 4.7591e-04, 4.7543e-04, 2.5034e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,846][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2344, 0.1422, 0.2005, 0.1397, 0.1140, 0.1692], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,847][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0455, 0.1486, 0.2256, 0.2271, 0.1789, 0.1742], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,849][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.9634, 0.0198, 0.0064, 0.0018, 0.0054, 0.0032], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,850][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1590, 0.0018, 0.0336, 0.0219, 0.0260, 0.7577], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,851][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([6.8398e-01, 3.7116e-05, 1.5036e-03, 1.0097e-03, 2.4979e-03, 3.1097e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,852][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0250, 0.1672, 0.2144, 0.1846, 0.2354, 0.1733], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,853][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0696, 0.1712, 0.1868, 0.1906, 0.1898, 0.1920], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,854][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.4164, 0.0700, 0.1361, 0.1074, 0.1532, 0.1168], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,855][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0864, 0.3516, 0.0907, 0.0274, 0.0708, 0.3732], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:27,856][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.0034, 0.1440, 0.1400, 0.1890, 0.1869, 0.1470, 0.1896],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,858][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0050, 0.0618, 0.0769, 0.1886, 0.2687, 0.1233, 0.2757],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,859][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([3.0659e-01, 7.1166e-05, 1.5842e-03, 2.5429e-03, 2.8508e-03, 5.4893e-01,
        1.3743e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,860][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.2305, 0.1317, 0.1665, 0.1137, 0.0946, 0.1439, 0.1191],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,862][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0500, 0.1219, 0.2161, 0.1800, 0.1483, 0.1712, 0.1125],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,864][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.8485, 0.0603, 0.0188, 0.0054, 0.0089, 0.0399, 0.0182],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,865][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([6.1892e-02, 4.2485e-04, 2.1598e-02, 1.1927e-02, 3.0857e-02, 3.6186e-01,
        5.1144e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,866][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([5.4266e-01, 1.2711e-04, 4.3994e-03, 1.6457e-03, 1.4003e-02, 2.8851e-01,
        1.4866e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,867][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.0260, 0.1246, 0.1691, 0.1490, 0.2086, 0.2010, 0.1217],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,869][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.0542, 0.1459, 0.1579, 0.1616, 0.1648, 0.1637, 0.1518],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,871][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.4907, 0.0450, 0.0769, 0.0665, 0.1006, 0.0678, 0.1525],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,872][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0736, 0.2467, 0.0508, 0.0192, 0.0118, 0.0378, 0.5600],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:27,874][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0029, 0.1257, 0.1231, 0.1619, 0.1681, 0.1298, 0.1675, 0.1210],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,876][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0107, 0.0778, 0.0766, 0.1775, 0.1880, 0.1030, 0.3046, 0.0618],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,877][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([4.7175e-01, 1.8238e-05, 3.3542e-04, 4.9812e-04, 4.2257e-04, 2.1141e-01,
        1.9630e-01, 1.1927e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,879][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.1686, 0.1248, 0.1582, 0.1135, 0.0925, 0.1247, 0.1031, 0.1146],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,880][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0347, 0.1075, 0.1696, 0.1715, 0.1348, 0.1548, 0.1109, 0.1161],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,881][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([9.7406e-01, 1.0709e-02, 2.0153e-03, 1.0393e-03, 1.9180e-03, 3.3195e-03,
        6.2063e-03, 7.2915e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,882][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([3.8053e-02, 4.6005e-04, 7.9467e-03, 6.0451e-03, 9.8010e-03, 1.7407e-01,
        5.4551e-01, 2.1812e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,883][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([6.6192e-01, 1.0212e-04, 9.0103e-04, 1.7376e-03, 2.9211e-03, 1.3646e-01,
        1.5701e-01, 3.8945e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,884][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0215, 0.1064, 0.1369, 0.1433, 0.1720, 0.1611, 0.1356, 0.1233],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,885][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0488, 0.1257, 0.1359, 0.1390, 0.1386, 0.1414, 0.1384, 0.1323],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,886][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.2464, 0.0601, 0.1002, 0.0828, 0.1189, 0.0911, 0.1230, 0.1775],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,887][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0792, 0.0982, 0.1058, 0.0077, 0.0405, 0.0896, 0.0584, 0.5205],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:27,889][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0025, 0.1149, 0.1135, 0.1437, 0.1420, 0.1162, 0.1494, 0.1131, 0.1046],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,891][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0101, 0.0694, 0.0839, 0.1420, 0.1788, 0.0946, 0.2726, 0.0976, 0.0509],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,892][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([6.7835e-01, 4.9646e-06, 5.2293e-05, 1.3953e-04, 1.0471e-04, 4.1634e-02,
        3.9356e-02, 4.4691e-02, 1.9566e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,893][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.1321, 0.1049, 0.1426, 0.1021, 0.0839, 0.1147, 0.0953, 0.1057, 0.1187],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,895][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0289, 0.0946, 0.1524, 0.1532, 0.1266, 0.1265, 0.0944, 0.1183, 0.1051],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,896][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([9.7470e-01, 1.2264e-02, 1.1173e-03, 7.4758e-04, 1.1816e-03, 1.7514e-03,
        3.5604e-03, 2.3334e-03, 2.3398e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,897][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([6.7736e-02, 1.6126e-04, 2.1412e-03, 1.7800e-03, 2.7373e-03, 6.1032e-02,
        2.1569e-01, 1.7316e-01, 4.7557e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,898][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([7.0173e-01, 1.8955e-05, 2.7472e-04, 3.5243e-04, 6.4791e-04, 5.0368e-02,
        4.6310e-02, 2.9714e-02, 1.7058e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,900][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0169, 0.0973, 0.1207, 0.1133, 0.1425, 0.1248, 0.1188, 0.1437, 0.1221],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,902][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0432, 0.1095, 0.1206, 0.1222, 0.1208, 0.1238, 0.1219, 0.1166, 0.1215],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,904][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.3196, 0.0462, 0.0776, 0.0677, 0.0975, 0.0707, 0.0945, 0.1357, 0.0905],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,905][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0622, 0.1069, 0.0581, 0.0067, 0.0293, 0.0952, 0.0690, 0.0457, 0.5268],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:27,907][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([0.0021, 0.0974, 0.0966, 0.1289, 0.1283, 0.1011, 0.1304, 0.0958, 0.0913,
        0.1281], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,908][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([0.0071, 0.0660, 0.0739, 0.1264, 0.1721, 0.0918, 0.2326, 0.0671, 0.0535,
        0.1095], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,909][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([8.6140e-01, 2.5699e-06, 1.6878e-05, 5.8284e-05, 5.0438e-05, 1.4042e-02,
        1.2279e-02, 1.0320e-02, 6.9217e-02, 3.2616e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,910][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([0.1483, 0.1059, 0.1145, 0.0823, 0.0730, 0.0998, 0.0798, 0.0962, 0.1061,
        0.0940], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,910][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([0.0319, 0.0867, 0.1455, 0.1301, 0.1034, 0.1227, 0.0824, 0.1057, 0.1038,
        0.0879], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,912][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([0.8406, 0.0257, 0.0094, 0.0104, 0.0161, 0.0250, 0.0282, 0.0090, 0.0285,
        0.0071], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,913][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([3.2781e-02, 1.3559e-04, 2.9100e-03, 1.5085e-03, 2.4861e-03, 5.3315e-02,
        1.1231e-01, 1.0431e-01, 5.0144e-01, 1.8881e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,914][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([9.0042e-01, 2.1440e-05, 1.5103e-04, 9.5851e-05, 2.0372e-04, 8.2766e-03,
        1.4863e-02, 1.0484e-02, 3.6786e-02, 2.8698e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,916][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([0.0154, 0.0780, 0.1069, 0.1063, 0.1364, 0.1223, 0.0905, 0.1247, 0.1327,
        0.0868], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,917][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([0.0357, 0.0998, 0.1085, 0.1113, 0.1105, 0.1132, 0.1084, 0.1049, 0.1098,
        0.0979], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,919][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([0.2709, 0.0388, 0.0822, 0.0567, 0.0936, 0.0627, 0.0698, 0.1177, 0.0771,
        0.1305], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,921][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([0.0911, 0.0795, 0.0454, 0.0151, 0.0174, 0.0114, 0.0236, 0.0233, 0.0593,
        0.6338], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:27,922][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0019, 0.0901, 0.0850, 0.1170, 0.1187, 0.0931, 0.1200, 0.0875, 0.0823,
        0.1179, 0.0864], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,924][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0087, 0.0563, 0.0534, 0.1276, 0.1513, 0.0786, 0.2387, 0.0600, 0.0464,
        0.1323, 0.0467], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,925][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([3.5432e-01, 1.0357e-06, 8.0699e-06, 3.0680e-05, 2.8362e-05, 7.0561e-03,
        5.8445e-03, 9.5953e-03, 5.5174e-02, 5.1421e-02, 5.1652e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,927][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0935, 0.0909, 0.1128, 0.0850, 0.0727, 0.0921, 0.0804, 0.0865, 0.0952,
        0.0881, 0.1030], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,929][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0294, 0.0751, 0.1181, 0.1272, 0.1000, 0.1118, 0.0747, 0.0915, 0.0936,
        0.0839, 0.0947], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,930][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([9.6707e-01, 9.2553e-03, 1.8506e-03, 8.1732e-04, 1.1511e-03, 1.8029e-03,
        3.4723e-03, 1.9332e-03, 3.4626e-03, 3.8691e-03, 5.3149e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,931][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([4.3700e-02, 1.2376e-04, 9.1889e-04, 5.9475e-04, 7.8802e-04, 2.5504e-02,
        5.3807e-02, 4.6127e-02, 1.9362e-01, 2.0385e-01, 4.3097e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,932][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([7.1196e-01, 1.0567e-05, 8.2623e-05, 8.7548e-05, 8.7753e-05, 1.3851e-02,
        1.4395e-02, 6.8564e-03, 3.7115e-02, 2.4174e-02, 1.9138e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,934][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0166, 0.0786, 0.0900, 0.0926, 0.1139, 0.1076, 0.0845, 0.1129, 0.1153,
        0.0998, 0.0882], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,935][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0351, 0.0882, 0.0969, 0.0988, 0.0982, 0.1001, 0.0974, 0.0940, 0.0979,
        0.0921, 0.1013], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,936][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2352, 0.0448, 0.0799, 0.0604, 0.0826, 0.0627, 0.0756, 0.1232, 0.0796,
        0.0715, 0.0846], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,937][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0674, 0.1106, 0.2074, 0.0078, 0.0345, 0.0325, 0.0541, 0.0317, 0.0522,
        0.2157, 0.1861], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:27,938][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.0016, 0.0803, 0.0775, 0.1037, 0.1041, 0.0823, 0.1038, 0.0783, 0.0749,
        0.1063, 0.0803, 0.1070], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,939][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.0037, 0.0470, 0.0487, 0.1366, 0.1579, 0.0785, 0.1650, 0.0617, 0.0462,
        0.1082, 0.0598, 0.0868], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,940][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([8.3099e-01, 1.0651e-06, 3.8022e-06, 1.3792e-05, 7.7878e-06, 1.1388e-03,
        1.6647e-03, 9.4735e-04, 5.8858e-03, 5.7218e-03, 4.7920e-02, 1.0571e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,942][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.1305, 0.0859, 0.0907, 0.0624, 0.0586, 0.0799, 0.0646, 0.0787, 0.0866,
        0.0756, 0.0977, 0.0889], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,944][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.0261, 0.0694, 0.1212, 0.1075, 0.0835, 0.0980, 0.0680, 0.0883, 0.0847,
        0.0732, 0.0951, 0.0850], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,945][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.9717, 0.0031, 0.0039, 0.0012, 0.0013, 0.0025, 0.0033, 0.0012, 0.0015,
        0.0021, 0.0048, 0.0032], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,946][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([7.6598e-02, 3.6630e-05, 4.8760e-04, 2.2234e-04, 4.7698e-04, 1.3048e-02,
        4.1337e-02, 2.4903e-02, 1.3254e-01, 1.5138e-01, 3.8302e-01, 1.7596e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,948][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([9.3623e-01, 4.7116e-06, 1.4700e-05, 3.2231e-05, 6.1188e-05, 9.4395e-04,
        2.0462e-03, 1.1009e-03, 3.2773e-03, 4.3768e-03, 1.5198e-02, 3.6718e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,949][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.0140, 0.0617, 0.0879, 0.0824, 0.1058, 0.1022, 0.0731, 0.1043, 0.1101,
        0.0814, 0.1011, 0.0759], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,951][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.0309, 0.0801, 0.0888, 0.0914, 0.0904, 0.0917, 0.0905, 0.0871, 0.0896,
        0.0838, 0.0924, 0.0836], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,953][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.2059, 0.0446, 0.0808, 0.0548, 0.0804, 0.0575, 0.0633, 0.1163, 0.0687,
        0.0795, 0.0776, 0.0708], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,955][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.0513, 0.0547, 0.0223, 0.0110, 0.0239, 0.0391, 0.0647, 0.0882, 0.1251,
        0.3655, 0.0614, 0.0928], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:27,956][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0022, 0.0737, 0.0722, 0.0923, 0.0929, 0.0743, 0.0959, 0.0716, 0.0686,
        0.0940, 0.0738, 0.0930, 0.0956], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,958][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0091, 0.0491, 0.0532, 0.0844, 0.1024, 0.0755, 0.2030, 0.0573, 0.0458,
        0.1258, 0.0528, 0.0697, 0.0721], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,959][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([5.9171e-02, 1.4436e-06, 2.0161e-05, 4.2919e-05, 3.0638e-05, 8.3908e-03,
        5.6167e-03, 7.5575e-03, 5.5387e-02, 2.8408e-02, 3.2225e-01, 4.7906e-01,
        3.4058e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,960][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0928, 0.0784, 0.0926, 0.0647, 0.0561, 0.0781, 0.0648, 0.0723, 0.0836,
        0.0713, 0.0922, 0.0844, 0.0687], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,961][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0315, 0.0678, 0.1129, 0.0987, 0.0751, 0.0957, 0.0590, 0.0846, 0.0798,
        0.0680, 0.0844, 0.0829, 0.0596], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,962][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([9.4146e-01, 1.7540e-02, 7.4533e-04, 4.9110e-04, 3.4502e-03, 1.4868e-03,
        7.7187e-03, 7.5928e-04, 1.6760e-03, 3.3247e-03, 2.3732e-03, 1.6487e-02,
        2.4897e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,963][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([1.0143e-02, 3.3221e-05, 8.5098e-04, 4.1303e-04, 9.0556e-04, 1.7723e-02,
        4.6907e-02, 2.7353e-02, 1.3123e-01, 1.3911e-01, 2.4043e-01, 2.4694e-01,
        1.3796e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,964][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([2.6414e-01, 6.6442e-06, 1.2840e-04, 2.0044e-04, 1.8598e-04, 1.1572e-02,
        1.9354e-02, 8.4796e-03, 4.1272e-02, 3.2281e-02, 1.8967e-01, 2.1625e-01,
        2.1646e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,965][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0088, 0.0633, 0.0811, 0.0703, 0.0909, 0.0869, 0.0800, 0.0912, 0.0960,
        0.0906, 0.0898, 0.0817, 0.0694], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,967][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0314, 0.0741, 0.0800, 0.0814, 0.0822, 0.0831, 0.0825, 0.0787, 0.0811,
        0.0769, 0.0847, 0.0785, 0.0855], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,969][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.1846, 0.0385, 0.0694, 0.0671, 0.0739, 0.0608, 0.0671, 0.1077, 0.0673,
        0.0522, 0.0746, 0.0637, 0.0731], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,971][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0309, 0.0253, 0.0767, 0.0156, 0.1845, 0.0652, 0.0380, 0.0688, 0.0754,
        0.0184, 0.0514, 0.0556, 0.2941], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:27,972][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0016, 0.0678, 0.0658, 0.0863, 0.0872, 0.0711, 0.0906, 0.0647, 0.0648,
        0.0894, 0.0678, 0.0867, 0.0900, 0.0663], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,974][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0090, 0.0468, 0.0473, 0.1060, 0.0921, 0.0701, 0.1686, 0.0488, 0.0473,
        0.0985, 0.0439, 0.0718, 0.1003, 0.0495], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,975][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([4.2903e-01, 9.8059e-07, 2.8164e-06, 6.5198e-06, 5.3699e-06, 1.8817e-03,
        2.8827e-03, 2.1050e-03, 1.4165e-02, 1.1893e-02, 1.2109e-01, 3.4357e-01,
        2.5019e-02, 4.8352e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,977][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0790, 0.0764, 0.0908, 0.0649, 0.0553, 0.0727, 0.0598, 0.0679, 0.0771,
        0.0676, 0.0834, 0.0778, 0.0652, 0.0620], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,979][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0188, 0.0588, 0.0917, 0.0992, 0.0769, 0.0824, 0.0614, 0.0711, 0.0728,
        0.0671, 0.0788, 0.0765, 0.0670, 0.0774], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,980][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.7310e-01, 7.9776e-03, 3.2956e-04, 2.6197e-04, 5.3786e-04, 5.4877e-04,
        2.5114e-03, 2.7107e-04, 8.6135e-04, 8.4619e-04, 1.2973e-03, 8.2835e-03,
        2.6927e-03, 4.7757e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,981][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.6632e-02, 6.0290e-05, 4.5713e-04, 3.4315e-04, 4.2817e-04, 9.0114e-03,
        3.4909e-02, 1.3996e-02, 6.4362e-02, 7.7815e-02, 1.6358e-01, 2.4747e-01,
        1.8779e-01, 1.7315e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,983][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([4.8268e-01, 7.8878e-06, 2.9260e-05, 8.0553e-05, 4.6980e-05, 3.6188e-03,
        4.8062e-03, 2.0655e-03, 1.2671e-02, 5.8099e-03, 7.6182e-02, 2.1749e-01,
        8.3886e-02, 1.1063e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,985][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0128, 0.0589, 0.0708, 0.0716, 0.0837, 0.0812, 0.0713, 0.0816, 0.0912,
        0.0772, 0.0802, 0.0738, 0.0752, 0.0703], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,986][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0275, 0.0682, 0.0747, 0.0759, 0.0756, 0.0766, 0.0756, 0.0731, 0.0754,
        0.0710, 0.0784, 0.0726, 0.0804, 0.0750], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,987][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2232, 0.0307, 0.0609, 0.0469, 0.0673, 0.0495, 0.0510, 0.0966, 0.0598,
        0.0504, 0.0642, 0.0509, 0.0624, 0.0861], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,988][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0399, 0.0193, 0.0887, 0.0024, 0.0578, 0.0262, 0.0113, 0.0367, 0.0352,
        0.0355, 0.0715, 0.0268, 0.0079, 0.5408], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:27,989][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0014, 0.0634, 0.0623, 0.0795, 0.0808, 0.0663, 0.0812, 0.0632, 0.0591,
        0.0816, 0.0650, 0.0826, 0.0816, 0.0630, 0.0690], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,990][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0075, 0.0543, 0.0558, 0.0735, 0.0932, 0.0733, 0.1225, 0.0591, 0.0427,
        0.1030, 0.0507, 0.0817, 0.0774, 0.0542, 0.0511], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,991][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([1.0164e-01, 2.2686e-06, 9.4638e-06, 2.6851e-05, 1.0258e-05, 5.0949e-03,
        4.3340e-03, 4.9118e-03, 2.8104e-02, 2.3139e-02, 1.5424e-01, 5.0411e-01,
        3.2565e-02, 9.6423e-02, 4.5388e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,993][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0771, 0.0705, 0.0807, 0.0581, 0.0507, 0.0669, 0.0552, 0.0633, 0.0714,
        0.0634, 0.0797, 0.0737, 0.0634, 0.0610, 0.0649], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,995][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0216, 0.0560, 0.0928, 0.0863, 0.0651, 0.0800, 0.0551, 0.0710, 0.0700,
        0.0608, 0.0746, 0.0721, 0.0588, 0.0773, 0.0584], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,996][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.7518, 0.0479, 0.0024, 0.0019, 0.0013, 0.0030, 0.0153, 0.0084, 0.0102,
        0.0174, 0.0150, 0.0837, 0.0267, 0.0091, 0.0059], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,998][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([8.1549e-03, 3.8408e-05, 4.3306e-04, 1.9982e-04, 2.0862e-04, 6.2854e-03,
        1.8174e-02, 1.4939e-02, 5.6189e-02, 1.1358e-01, 1.1711e-01, 2.6972e-01,
        1.0582e-01, 1.7832e-01, 1.1082e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:27,999][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([3.6786e-01, 4.9042e-06, 7.0680e-05, 1.1043e-04, 1.3899e-04, 7.1900e-03,
        9.2342e-03, 4.6017e-03, 1.8133e-02, 1.6319e-02, 1.1081e-01, 1.4624e-01,
        8.8264e-02, 1.9318e-01, 3.7850e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,001][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0111, 0.0662, 0.0638, 0.0678, 0.0731, 0.0703, 0.0659, 0.0842, 0.0792,
        0.0699, 0.0714, 0.0835, 0.0666, 0.0726, 0.0546], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,003][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0260, 0.0639, 0.0687, 0.0705, 0.0709, 0.0716, 0.0696, 0.0676, 0.0695,
        0.0657, 0.0724, 0.0675, 0.0760, 0.0700, 0.0702], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,004][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.1379, 0.0314, 0.0513, 0.0454, 0.0563, 0.0452, 0.0753, 0.0908, 0.0634,
        0.0715, 0.0653, 0.0647, 0.0516, 0.0729, 0.0771], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,006][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0329, 0.0275, 0.0732, 0.0026, 0.0419, 0.0576, 0.0563, 0.0268, 0.0761,
        0.1719, 0.0594, 0.0491, 0.0095, 0.0788, 0.2364], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,008][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.0014, 0.0600, 0.0590, 0.0757, 0.0755, 0.0614, 0.0776, 0.0593, 0.0540,
        0.0773, 0.0613, 0.0771, 0.0763, 0.0601, 0.0667, 0.0573],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,010][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.0070, 0.0351, 0.0491, 0.0710, 0.0936, 0.0569, 0.1708, 0.0576, 0.0282,
        0.0960, 0.0496, 0.0577, 0.0632, 0.0591, 0.0690, 0.0362],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,011][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([2.1399e-01, 1.4175e-06, 4.1383e-06, 1.2748e-05, 7.2614e-06, 2.6077e-03,
        2.5415e-03, 2.6758e-03, 1.3618e-02, 1.6956e-02, 1.2511e-01, 3.3514e-01,
        3.8510e-02, 1.2255e-01, 4.9691e-02, 7.6575e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,013][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([0.0704, 0.0642, 0.0756, 0.0544, 0.0474, 0.0639, 0.0516, 0.0596, 0.0674,
        0.0618, 0.0740, 0.0709, 0.0593, 0.0574, 0.0613, 0.0607],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,014][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.0199, 0.0539, 0.0859, 0.0820, 0.0676, 0.0715, 0.0503, 0.0673, 0.0596,
        0.0586, 0.0695, 0.0662, 0.0565, 0.0763, 0.0587, 0.0564],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,015][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.8178, 0.0111, 0.0034, 0.0015, 0.0026, 0.0054, 0.0068, 0.0064, 0.0090,
        0.0114, 0.0178, 0.0204, 0.0204, 0.0105, 0.0442, 0.0113],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,016][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([1.4990e-02, 3.1225e-05, 2.5276e-04, 2.1628e-04, 2.4097e-04, 4.0946e-03,
        1.3558e-02, 1.7373e-02, 3.1727e-02, 3.7276e-02, 1.0642e-01, 1.9610e-01,
        1.4403e-01, 1.4820e-01, 1.8437e-01, 1.0112e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,017][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([2.6116e-01, 6.5732e-06, 3.2626e-05, 5.2632e-05, 9.5419e-05, 3.2903e-03,
        4.4435e-03, 2.5920e-03, 1.5413e-02, 9.8771e-03, 9.0970e-02, 1.9656e-01,
        8.1776e-02, 1.8898e-01, 1.0375e-01, 4.1004e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,019][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.0092, 0.0490, 0.0660, 0.0553, 0.0774, 0.0666, 0.0597, 0.0775, 0.0723,
        0.0694, 0.0740, 0.0623, 0.0649, 0.0724, 0.0679, 0.0561],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,020][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.0236, 0.0588, 0.0649, 0.0664, 0.0658, 0.0667, 0.0665, 0.0629, 0.0652,
        0.0624, 0.0683, 0.0627, 0.0712, 0.0650, 0.0663, 0.0634],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,022][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.1035, 0.0209, 0.0415, 0.0326, 0.0520, 0.0409, 0.0747, 0.0892, 0.0685,
        0.0530, 0.0625, 0.0504, 0.0484, 0.0723, 0.0827, 0.1068],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,024][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.0411, 0.0838, 0.0169, 0.0126, 0.0137, 0.0106, 0.0329, 0.0182, 0.0905,
        0.0410, 0.0139, 0.1765, 0.0165, 0.0367, 0.0110, 0.3844],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,026][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0013, 0.0559, 0.0545, 0.0711, 0.0719, 0.0588, 0.0740, 0.0535, 0.0535,
        0.0735, 0.0560, 0.0712, 0.0740, 0.0549, 0.0640, 0.0569, 0.0549],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,028][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0080, 0.0395, 0.0401, 0.0902, 0.0779, 0.0611, 0.1365, 0.0418, 0.0414,
        0.0831, 0.0375, 0.0597, 0.0830, 0.0424, 0.0615, 0.0545, 0.0416],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,029][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([5.5783e-01, 1.0181e-06, 1.4846e-06, 5.0675e-06, 2.6422e-06, 9.7343e-04,
        1.5050e-03, 9.0704e-04, 7.1393e-03, 5.6348e-03, 5.2365e-02, 1.9826e-01,
        1.1862e-02, 2.3983e-02, 2.5430e-02, 6.3688e-02, 5.0410e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,031][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0590, 0.0649, 0.0754, 0.0550, 0.0469, 0.0612, 0.0504, 0.0570, 0.0642,
        0.0570, 0.0688, 0.0651, 0.0548, 0.0522, 0.0572, 0.0577, 0.0534],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,033][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0151, 0.0471, 0.0745, 0.0802, 0.0634, 0.0671, 0.0509, 0.0583, 0.0596,
        0.0558, 0.0650, 0.0617, 0.0558, 0.0637, 0.0579, 0.0622, 0.0616],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,034][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.2190e-01, 1.6618e-02, 8.8069e-04, 8.0808e-04, 1.1034e-03, 1.2155e-03,
        5.9184e-03, 7.8128e-04, 2.1084e-03, 1.9065e-03, 3.4243e-03, 2.0498e-02,
        7.5762e-03, 1.1547e-03, 5.4963e-03, 7.0565e-03, 1.5521e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,035][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([3.0377e-02, 4.7205e-05, 2.8196e-04, 2.0203e-04, 2.7040e-04, 5.6752e-03,
        1.5904e-02, 8.1670e-03, 3.6685e-02, 4.3806e-02, 9.3647e-02, 1.4102e-01,
        9.1103e-02, 8.4137e-02, 1.4948e-01, 1.8215e-01, 1.1704e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,037][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([6.4928e-01, 5.2209e-06, 1.4215e-05, 4.3715e-05, 3.2538e-05, 1.6256e-03,
        1.7288e-03, 1.0868e-03, 5.2362e-03, 2.1107e-03, 3.3786e-02, 9.1195e-02,
        2.9430e-02, 4.7601e-02, 2.5145e-02, 1.3673e-02, 9.8007e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,038][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0105, 0.0482, 0.0569, 0.0579, 0.0678, 0.0652, 0.0578, 0.0664, 0.0734,
        0.0621, 0.0647, 0.0602, 0.0609, 0.0569, 0.0638, 0.0698, 0.0574],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,039][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0221, 0.0556, 0.0610, 0.0620, 0.0618, 0.0625, 0.0620, 0.0597, 0.0614,
        0.0583, 0.0640, 0.0592, 0.0657, 0.0612, 0.0622, 0.0608, 0.0607],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,040][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1462, 0.0260, 0.0507, 0.0392, 0.0538, 0.0414, 0.0446, 0.0802, 0.0514,
        0.0443, 0.0541, 0.0434, 0.0473, 0.0678, 0.0644, 0.0744, 0.0709],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,041][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0262, 0.0109, 0.0595, 0.0014, 0.0375, 0.0177, 0.0084, 0.0252, 0.0245,
        0.0223, 0.0487, 0.0150, 0.0047, 0.3506, 0.0268, 0.0052, 0.3153],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,045][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:28,047][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[6727],
        [3917],
        [4929],
        [ 902],
        [6450],
        [1196],
        [ 958],
        [ 277],
        [ 862],
        [2941],
        [2264],
        [5854],
        [4649],
        [3481],
        [6066],
        [1765],
        [2489]], device='cuda:0')
[2024-07-24 10:31:28,048][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[7418],
        [6854],
        [5180],
        [2328],
        [7482],
        [1235],
        [1680],
        [ 577],
        [1631],
        [2643],
        [2595],
        [5240],
        [7345],
        [4011],
        [5301],
        [2899],
        [3229]], device='cuda:0')
[2024-07-24 10:31:28,050][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[28989],
        [17414],
        [18845],
        [22496],
        [21358],
        [20871],
        [22526],
        [21720],
        [22831],
        [22480],
        [22277],
        [22507],
        [22798],
        [22914],
        [23302],
        [22968],
        [23053]], device='cuda:0')
[2024-07-24 10:31:28,052][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[8760],
        [1104],
        [1936],
        [ 317],
        [ 177],
        [  61],
        [  39],
        [  55],
        [ 190],
        [ 159],
        [ 110],
        [ 114],
        [ 308],
        [  78],
        [ 331],
        [ 368],
        [ 102]], device='cuda:0')
[2024-07-24 10:31:28,054][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 7678],
        [16187],
        [24964],
        [30683],
        [28849],
        [34283],
        [34371],
        [33613],
        [33762],
        [34407],
        [35292],
        [34099],
        [34893],
        [34004],
        [34128],
        [34701],
        [34269]], device='cuda:0')
[2024-07-24 10:31:28,056][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[4749],
        [6081],
        [6622],
        [6601],
        [6834],
        [6819],
        [6870],
        [6888],
        [6879],
        [6994],
        [7014],
        [6967],
        [6920],
        [6908],
        [6907],
        [6957],
        [6967]], device='cuda:0')
[2024-07-24 10:31:28,057][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[17016],
        [15980],
        [15466],
        [16428],
        [16148],
        [14466],
        [13122],
        [13074],
        [12815],
        [13163],
        [13303],
        [13521],
        [13612],
        [13528],
        [13433],
        [13262],
        [13170]], device='cuda:0')
[2024-07-24 10:31:28,059][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[16792],
        [10449],
        [11824],
        [12578],
        [13213],
        [13414],
        [13034],
        [13184],
        [12900],
        [12912],
        [12900],
        [13020],
        [12975],
        [12723],
        [12629],
        [12542],
        [12404]], device='cuda:0')
[2024-07-24 10:31:28,061][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[44920],
        [42319],
        [41360],
        [41073],
        [40779],
        [39355],
        [39018],
        [33989],
        [35260],
        [35130],
        [38238],
        [35838],
        [37080],
        [39632],
        [32728],
        [37682],
        [35997]], device='cuda:0')
[2024-07-24 10:31:28,063][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[13330],
        [ 8228],
        [17243],
        [ 6358],
        [ 6992],
        [ 9706],
        [10557],
        [11561],
        [12656],
        [12829],
        [12118],
        [ 9538],
        [11671],
        [11379],
        [13871],
        [12887],
        [13080]], device='cuda:0')
[2024-07-24 10:31:28,065][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[46174],
        [31161],
        [20698],
        [24489],
        [27546],
        [31757],
        [31895],
        [29721],
        [27680],
        [27409],
        [26936],
        [29055],
        [29124],
        [30805],
        [30333],
        [32674],
        [31476]], device='cuda:0')
[2024-07-24 10:31:28,067][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 5459],
        [ 8103],
        [ 9648],
        [ 9692],
        [ 9637],
        [ 9777],
        [ 9978],
        [10114],
        [10265],
        [10288],
        [10370],
        [10384],
        [10372],
        [10415],
        [10490],
        [10554],
        [10574]], device='cuda:0')
[2024-07-24 10:31:28,068][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 900],
        [4065],
        [2934],
        [3161],
        [3176],
        [2643],
        [2592],
        [2290],
        [2083],
        [2015],
        [1938],
        [1983],
        [1945],
        [1931],
        [1896],
        [1825],
        [1810]], device='cuda:0')
[2024-07-24 10:31:28,070][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[24748],
        [38842],
        [32713],
        [41895],
        [39300],
        [36446],
        [38636],
        [36044],
        [34880],
        [34818],
        [33319],
        [34907],
        [34139],
        [33383],
        [33521],
        [32917],
        [32332]], device='cuda:0')
[2024-07-24 10:31:28,072][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[41761],
        [11501],
        [11677],
        [ 4431],
        [19663],
        [14578],
        [ 8820],
        [12630],
        [10880],
        [14784],
        [17209],
        [22444],
        [12743],
        [33073],
        [17353],
        [13734],
        [26136]], device='cuda:0')
[2024-07-24 10:31:28,073][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[1446],
        [1737],
        [1699],
        [1920],
        [2038],
        [1985],
        [2026],
        [2039],
        [1986],
        [2066],
        [2022],
        [1971],
        [1998],
        [1970],
        [1962],
        [1968],
        [1947]], device='cuda:0')
[2024-07-24 10:31:28,075][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[11469],
        [29024],
        [28839],
        [31847],
        [33082],
        [33689],
        [33985],
        [33379],
        [33045],
        [33349],
        [33329],
        [33216],
        [32987],
        [33008],
        [33288],
        [33648],
        [33726]], device='cuda:0')
[2024-07-24 10:31:28,077][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[32630],
        [33522],
        [33220],
        [24422],
        [11643],
        [ 4306],
        [ 2203],
        [ 3603],
        [12126],
        [25832],
        [ 5278],
        [17973],
        [ 1828],
        [ 1680],
        [ 1237],
        [ 1195],
        [ 2072]], device='cuda:0')
[2024-07-24 10:31:28,078][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[21840],
        [24331],
        [22710],
        [24028],
        [24751],
        [24022],
        [24241],
        [24496],
        [24140],
        [24440],
        [25090],
        [26185],
        [25944],
        [25600],
        [25520],
        [25235],
        [25036]], device='cuda:0')
[2024-07-24 10:31:28,080][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[32174],
        [41729],
        [38258],
        [42349],
        [42423],
        [41935],
        [41659],
        [41812],
        [41749],
        [41621],
        [41163],
        [41297],
        [41315],
        [41063],
        [41086],
        [40718],
        [40468]], device='cuda:0')
[2024-07-24 10:31:28,082][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[39000],
        [37144],
        [37347],
        [35073],
        [27841],
        [37495],
        [31815],
        [38011],
        [37954],
        [32015],
        [37705],
        [37945],
        [36752],
        [37924],
        [29614],
        [32297],
        [36069]], device='cuda:0')
[2024-07-24 10:31:28,084][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[37338],
        [10764],
        [18716],
        [18522],
        [18030],
        [22367],
        [17178],
        [18901],
        [18702],
        [19325],
        [16662],
        [12824],
        [11882],
        [11028],
        [12265],
        [12378],
        [12925]], device='cuda:0')
[2024-07-24 10:31:28,086][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[29146],
        [28044],
        [32610],
        [34016],
        [25345],
        [35327],
        [28836],
        [27579],
        [34272],
        [32767],
        [37866],
        [31007],
        [28731],
        [31801],
        [30336],
        [28312],
        [34823]], device='cuda:0')
[2024-07-24 10:31:28,088][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[22081],
        [20922],
        [20862],
        [19666],
        [24528],
        [27236],
        [26958],
        [27242],
        [28199],
        [28101],
        [27789],
        [27986],
        [28048],
        [28144],
        [28519],
        [29250],
        [29287]], device='cuda:0')
[2024-07-24 10:31:28,089][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[36091],
        [38913],
        [39533],
        [39863],
        [39902],
        [39956],
        [40150],
        [40090],
        [40154],
        [40299],
        [40304],
        [40339],
        [40431],
        [40403],
        [40414],
        [40425],
        [40384]], device='cuda:0')
[2024-07-24 10:31:28,091][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[48476],
        [40070],
        [28708],
        [36584],
        [27463],
        [30326],
        [30455],
        [23949],
        [26709],
        [24135],
        [23559],
        [22968],
        [23508],
        [24098],
        [21368],
        [21670],
        [22665]], device='cuda:0')
[2024-07-24 10:31:28,093][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[27342],
        [ 2828],
        [12697],
        [ 8839],
        [27886],
        [22802],
        [ 4783],
        [23335],
        [27464],
        [28948],
        [17838],
        [27102],
        [29281],
        [15527],
        [22400],
        [23448],
        [15888]], device='cuda:0')
[2024-07-24 10:31:28,095][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 4415],
        [11135],
        [ 9652],
        [ 9420],
        [12995],
        [10123],
        [19377],
        [14631],
        [ 9114],
        [ 7972],
        [12180],
        [10098],
        [15059],
        [16589],
        [18430],
        [17395],
        [15030]], device='cuda:0')
[2024-07-24 10:31:28,096][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 4366],
        [10601],
        [10733],
        [12762],
        [ 8050],
        [ 9237],
        [17140],
        [ 7743],
        [ 7583],
        [12992],
        [ 7631],
        [ 9740],
        [14169],
        [ 7244],
        [17603],
        [14584],
        [ 8572]], device='cuda:0')
[2024-07-24 10:31:28,098][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[39634],
        [39634],
        [39634],
        [39634],
        [39634],
        [39634],
        [39634],
        [39634],
        [39634],
        [39634],
        [39634],
        [39634],
        [39634],
        [39634],
        [39634],
        [39634],
        [39634]], device='cuda:0')
[2024-07-24 10:31:28,167][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:28,168][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,170][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,171][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,173][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,174][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,175][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,177][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,178][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,179][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,180][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,181][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,181][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,182][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.9894, 0.0106], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,184][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.3287, 0.6713], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,184][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.4454, 0.5546], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,185][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.4226, 0.5774], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,186][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.3394, 0.6606], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,187][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.8453, 0.1547], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,187][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.6517, 0.3483], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,188][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.4222, 0.5778], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,190][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.6686, 0.3314], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,191][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.6401, 0.3599], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,193][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.5197, 0.4803], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,194][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.2734, 0.7266], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,195][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.8777e-01, 3.0620e-04, 1.1922e-02], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,197][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0167, 0.7971, 0.1862], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,199][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2825, 0.3493, 0.3681], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,200][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2944, 0.2594, 0.4462], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,202][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1122, 0.3828, 0.5050], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,203][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.6615, 0.0882, 0.2504], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,205][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.4431, 0.2454, 0.3115], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,206][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2193, 0.3384, 0.4423], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,208][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2184, 0.6605, 0.1211], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,210][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0690, 0.4699, 0.4611], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,211][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.3829, 0.3339, 0.2833], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,211][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1963, 0.3890, 0.4146], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,212][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Nathan] are: tensor([9.8489e-01, 2.6858e-04, 1.1671e-02, 3.1670e-03], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,213][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Nathan] are: tensor([0.0252, 0.0056, 0.9547, 0.0146], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,213][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Nathan] are: tensor([0.2112, 0.2551, 0.2691, 0.2646], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,215][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Nathan] are: tensor([0.1833, 0.1756, 0.3270, 0.3141], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,216][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Nathan] are: tensor([0.1094, 0.2593, 0.3247, 0.3067], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,218][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Nathan] are: tensor([0.6673, 0.0250, 0.1046, 0.2031], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,220][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Nathan] are: tensor([0.3380, 0.1832, 0.2350, 0.2438], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,221][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Nathan] are: tensor([0.1784, 0.2546, 0.3358, 0.2312], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,223][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Nathan] are: tensor([0.0900, 0.0728, 0.7240, 0.1131], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,225][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Nathan] are: tensor([0.0551, 0.4211, 0.3943, 0.1296], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,226][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Nathan] are: tensor([0.2918, 0.2628, 0.2272, 0.2182], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,228][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Nathan] are: tensor([0.1197, 0.2506, 0.2850, 0.3447], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,230][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.9609, 0.0010, 0.0228, 0.0077, 0.0076], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,231][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.0276, 0.0301, 0.8373, 0.0744, 0.0306], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,233][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.1593, 0.2035, 0.2135, 0.2096, 0.2141], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,235][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.1389, 0.1398, 0.2421, 0.2321, 0.2470], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,236][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.0825, 0.1826, 0.2258, 0.2436, 0.2655], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,237][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.4312, 0.0236, 0.0843, 0.1954, 0.2654], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,238][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.2796, 0.1477, 0.1961, 0.1989, 0.1778], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,239][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.1294, 0.1920, 0.2467, 0.1727, 0.2591], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,239][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.0505, 0.1066, 0.6999, 0.1177, 0.0253], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,241][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.0402, 0.3671, 0.3289, 0.1342, 0.1296], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,242][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.2098, 0.2213, 0.1991, 0.1808, 0.1890], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,244][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.0838, 0.1944, 0.2267, 0.2847, 0.2104], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,245][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([9.9049e-01, 6.0870e-05, 4.8406e-04, 2.5967e-04, 3.4238e-04, 8.3654e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,246][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0499, 0.0300, 0.3292, 0.3715, 0.0505, 0.1689], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,248][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1323, 0.1696, 0.1780, 0.1751, 0.1783, 0.1666], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,250][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1494, 0.0995, 0.1596, 0.1586, 0.1684, 0.2645], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,251][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0517, 0.1497, 0.1870, 0.1861, 0.2039, 0.2216], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,253][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.5966, 0.0114, 0.0430, 0.0905, 0.1338, 0.1248], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,254][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2301, 0.1227, 0.1582, 0.1614, 0.1443, 0.1832], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,256][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0999, 0.1554, 0.2021, 0.1486, 0.2133, 0.1806], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,258][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0918, 0.1216, 0.3190, 0.3363, 0.0846, 0.0466], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,259][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2173, 0.1877, 0.2121, 0.0957, 0.1395, 0.1478], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,261][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2305, 0.1960, 0.1542, 0.1494, 0.1474, 0.1226], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,263][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0828, 0.1658, 0.1797, 0.2284, 0.1747, 0.1686], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,263][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([9.5420e-01, 2.8724e-04, 1.9109e-03, 1.3839e-03, 1.5469e-03, 2.4633e-02,
        1.6034e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,264][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.0075, 0.0050, 0.1119, 0.0225, 0.0373, 0.2401, 0.5757],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,265][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.1144, 0.1473, 0.1541, 0.1498, 0.1528, 0.1432, 0.1384],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,266][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.1279, 0.0812, 0.1287, 0.1261, 0.1373, 0.2227, 0.1760],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,267][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0745, 0.1117, 0.1580, 0.1610, 0.1712, 0.1921, 0.1314],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,269][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.3048, 0.0068, 0.0321, 0.0537, 0.1018, 0.1170, 0.3838],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,270][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.1914, 0.0981, 0.1271, 0.1303, 0.1136, 0.1433, 0.1963],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,272][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.1014, 0.1356, 0.1784, 0.1256, 0.1894, 0.1659, 0.1037],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,274][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.0781, 0.0143, 0.1562, 0.1591, 0.0910, 0.2449, 0.2564],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,275][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.2531, 0.1815, 0.1900, 0.0739, 0.1075, 0.1320, 0.0620],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,277][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.1707, 0.1644, 0.1360, 0.1372, 0.1434, 0.1225, 0.1258],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,279][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0593, 0.1412, 0.1567, 0.1987, 0.1535, 0.1505, 0.1401],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,280][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ at] are: tensor([9.7231e-01, 1.0572e-04, 5.8583e-04, 3.4156e-04, 4.0099e-04, 9.4199e-03,
        7.9685e-03, 8.8652e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,282][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0234, 0.0060, 0.0224, 0.0151, 0.0230, 0.0846, 0.8199, 0.0056],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,283][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0993, 0.1276, 0.1336, 0.1309, 0.1333, 0.1247, 0.1218, 0.1287],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,285][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.1040, 0.0693, 0.1059, 0.1077, 0.1128, 0.1723, 0.1471, 0.1808],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,286][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0418, 0.1000, 0.1263, 0.1331, 0.1412, 0.1548, 0.1323, 0.1706],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,288][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.2253, 0.0093, 0.0275, 0.0603, 0.0848, 0.1120, 0.3726, 0.1082],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,289][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1612, 0.0861, 0.1125, 0.1152, 0.0997, 0.1268, 0.1700, 0.1286],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,290][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0834, 0.1142, 0.1544, 0.1106, 0.1602, 0.1401, 0.0927, 0.1444],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,291][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0321, 0.0123, 0.0428, 0.0246, 0.0226, 0.0554, 0.7884, 0.0219],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,291][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.2585, 0.1470, 0.1856, 0.0662, 0.1039, 0.1247, 0.0530, 0.0610],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,292][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1649, 0.1620, 0.1262, 0.1202, 0.1241, 0.1005, 0.1038, 0.0984],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,294][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0581, 0.1230, 0.1288, 0.1783, 0.1326, 0.1275, 0.1322, 0.1196],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,295][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ the] are: tensor([9.8085e-01, 4.6989e-05, 2.0217e-04, 1.4011e-04, 1.6490e-04, 3.9010e-03,
        3.0931e-03, 4.1195e-03, 7.4865e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,297][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0102, 0.0013, 0.0041, 0.0127, 0.0020, 0.0396, 0.8400, 0.0272, 0.0628],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,298][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0899, 0.1134, 0.1191, 0.1165, 0.1186, 0.1110, 0.1086, 0.1148, 0.1080],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,300][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0939, 0.0561, 0.0854, 0.0871, 0.0904, 0.1400, 0.1235, 0.1506, 0.1729],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,301][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0330, 0.0878, 0.1132, 0.1113, 0.1189, 0.1312, 0.1051, 0.1424, 0.1573],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,303][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.2721, 0.0082, 0.0258, 0.0459, 0.0731, 0.0768, 0.2586, 0.0924, 0.1472],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,305][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1415, 0.0742, 0.0968, 0.0990, 0.0865, 0.1101, 0.1502, 0.1109, 0.1307],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,307][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0752, 0.1019, 0.1344, 0.0964, 0.1381, 0.1200, 0.0802, 0.1245, 0.1293],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,308][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0365, 0.0062, 0.0136, 0.0153, 0.0081, 0.0144, 0.7159, 0.1511, 0.0388],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,310][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.2424, 0.1282, 0.1991, 0.0643, 0.0946, 0.0966, 0.0555, 0.0646, 0.0547],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,312][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1415, 0.1442, 0.1130, 0.1094, 0.1124, 0.0933, 0.0982, 0.0913, 0.0966],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,313][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0477, 0.1108, 0.1165, 0.1552, 0.1163, 0.1091, 0.1152, 0.1153, 0.1140],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,315][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([9.7481e-01, 7.3296e-05, 2.5714e-04, 1.3372e-04, 1.8950e-04, 3.2604e-03,
        2.7818e-03, 3.6964e-03, 7.3051e-03, 7.4884e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,315][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([0.0078, 0.0018, 0.0084, 0.0067, 0.0457, 0.1076, 0.5118, 0.1274, 0.1745,
        0.0084], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,316][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([0.0788, 0.1031, 0.1075, 0.1051, 0.1069, 0.1002, 0.0972, 0.1038, 0.0978,
        0.0995], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,317][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([0.0916, 0.0521, 0.0730, 0.0700, 0.0778, 0.1189, 0.1044, 0.1285, 0.1471,
        0.1365], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,318][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([0.0557, 0.0706, 0.0861, 0.1077, 0.1093, 0.1137, 0.0825, 0.1222, 0.1320,
        0.1204], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,320][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([0.1878, 0.0064, 0.0136, 0.0232, 0.0397, 0.0529, 0.1206, 0.0500, 0.0891,
        0.4168], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,321][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.1287, 0.0642, 0.0823, 0.0847, 0.0741, 0.0948, 0.1314, 0.0951, 0.1135,
        0.1313], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,323][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([0.0700, 0.0883, 0.1123, 0.0814, 0.1218, 0.1039, 0.0696, 0.1081, 0.1150,
        0.1296], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,324][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.0779, 0.0047, 0.0212, 0.0480, 0.0177, 0.0696, 0.1892, 0.0966, 0.2670,
        0.2081], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,326][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([0.1792, 0.1490, 0.2035, 0.0623, 0.0887, 0.0872, 0.0563, 0.0558, 0.0467,
        0.0712], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,328][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([0.1420, 0.1270, 0.1038, 0.0967, 0.1045, 0.0923, 0.0933, 0.0849, 0.0905,
        0.0650], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,330][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([0.0477, 0.0965, 0.1048, 0.1363, 0.1040, 0.0999, 0.0991, 0.1077, 0.1077,
        0.0963], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,331][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.5906e-01, 5.6647e-05, 1.7176e-04, 1.0217e-04, 1.5229e-04, 2.8625e-03,
        2.8926e-03, 3.2738e-03, 6.2848e-03, 6.8294e-03, 1.8317e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,332][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.5121e-04, 1.4162e-03, 1.3050e-03, 3.3344e-03, 8.1596e-03, 3.0002e-02,
        8.6524e-02, 1.3352e-02, 2.1201e-01, 6.4092e-01, 2.8291e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,334][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0741, 0.0933, 0.0975, 0.0955, 0.0972, 0.0908, 0.0890, 0.0941, 0.0885,
        0.0908, 0.0892], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,336][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0707, 0.0453, 0.0657, 0.0669, 0.0702, 0.1046, 0.0923, 0.1107, 0.1278,
        0.1182, 0.1275], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,337][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0343, 0.0655, 0.0838, 0.0910, 0.0974, 0.1012, 0.0828, 0.1119, 0.1205,
        0.1176, 0.0939], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,339][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2214, 0.0051, 0.0135, 0.0191, 0.0325, 0.0329, 0.1070, 0.0363, 0.0681,
        0.3476, 0.1166], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,341][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1121, 0.0594, 0.0776, 0.0783, 0.0679, 0.0872, 0.1145, 0.0863, 0.1013,
        0.1129, 0.1024], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,341][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0533, 0.0799, 0.1046, 0.0760, 0.1087, 0.0941, 0.0645, 0.0984, 0.1030,
        0.1165, 0.1009], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,342][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0108, 0.0055, 0.0019, 0.0118, 0.0033, 0.0204, 0.2426, 0.0237, 0.0889,
        0.5870, 0.0043], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,343][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0570, 0.1553, 0.1765, 0.0719, 0.0876, 0.0977, 0.0549, 0.0621, 0.0616,
        0.1134, 0.0620], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,344][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1342, 0.1281, 0.1008, 0.0954, 0.0970, 0.0752, 0.0811, 0.0755, 0.0824,
        0.0667, 0.0638], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,346][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0479, 0.0873, 0.0906, 0.1292, 0.0951, 0.0924, 0.0910, 0.0913, 0.0982,
        0.0939, 0.0833], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,347][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([9.5301e-01, 7.2068e-05, 1.7533e-04, 1.2164e-04, 1.4848e-04, 2.1572e-03,
        3.0060e-03, 2.4355e-03, 5.2422e-03, 6.0687e-03, 1.3704e-02, 1.3857e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,349][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.0388, 0.0011, 0.0085, 0.0039, 0.0022, 0.1157, 0.3988, 0.0407, 0.1186,
        0.0894, 0.0411, 0.1412], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,350][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.0676, 0.0858, 0.0894, 0.0878, 0.0896, 0.0836, 0.0813, 0.0861, 0.0813,
        0.0832, 0.0818, 0.0826], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,352][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.0804, 0.0399, 0.0549, 0.0564, 0.0602, 0.0897, 0.0788, 0.0959, 0.1097,
        0.1053, 0.1128, 0.1159], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,354][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.0311, 0.0703, 0.0832, 0.0896, 0.0963, 0.1025, 0.0684, 0.1046, 0.1142,
        0.0959, 0.0836, 0.0603], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,356][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.1022, 0.0030, 0.0097, 0.0130, 0.0297, 0.0276, 0.0761, 0.0356, 0.0586,
        0.2838, 0.1037, 0.2570], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,357][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.1075, 0.0517, 0.0668, 0.0683, 0.0592, 0.0755, 0.1035, 0.0758, 0.0891,
        0.1004, 0.0897, 0.1125], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,359][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.0531, 0.0720, 0.0932, 0.0681, 0.1000, 0.0873, 0.0593, 0.0907, 0.0962,
        0.1091, 0.0934, 0.0775], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,361][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.1012, 0.0012, 0.0105, 0.0073, 0.0051, 0.0156, 0.1207, 0.0252, 0.0507,
        0.2972, 0.1861, 0.1791], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,363][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.2705, 0.0751, 0.1843, 0.0426, 0.0594, 0.0675, 0.0429, 0.0402, 0.0381,
        0.0643, 0.0619, 0.0532], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,364][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.1457, 0.1057, 0.0837, 0.0852, 0.0864, 0.0770, 0.0810, 0.0723, 0.0764,
        0.0587, 0.0619, 0.0660], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,366][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.0355, 0.0806, 0.0868, 0.1130, 0.0871, 0.0837, 0.0822, 0.0890, 0.0892,
        0.0857, 0.0798, 0.0874], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,367][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([8.5682e-01, 1.6764e-04, 6.0725e-04, 3.1309e-04, 4.6485e-04, 8.5497e-03,
        6.2226e-03, 8.9286e-03, 1.5141e-02, 1.5729e-02, 3.7648e-02, 3.5764e-02,
        1.3648e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,368][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([1.3393e-03, 3.8068e-04, 8.2560e-03, 1.7057e-03, 1.0929e-03, 9.1623e-03,
        1.5107e-01, 2.5511e-02, 1.1721e-01, 5.9746e-01, 2.5079e-02, 5.7807e-02,
        3.9256e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,369][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0634, 0.0791, 0.0828, 0.0809, 0.0827, 0.0771, 0.0753, 0.0798, 0.0752,
        0.0768, 0.0758, 0.0764, 0.0747], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,370][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0711, 0.0362, 0.0534, 0.0535, 0.0587, 0.0841, 0.0745, 0.0888, 0.1009,
        0.0940, 0.1008, 0.1002, 0.0838], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,371][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0342, 0.0552, 0.0710, 0.0797, 0.0916, 0.0947, 0.0658, 0.0970, 0.1033,
        0.0954, 0.0775, 0.0550, 0.0797], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,372][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0895, 0.0045, 0.0103, 0.0181, 0.0279, 0.0281, 0.0768, 0.0275, 0.0501,
        0.2206, 0.0839, 0.2132, 0.1494], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,374][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0914, 0.0465, 0.0610, 0.0624, 0.0551, 0.0697, 0.0949, 0.0702, 0.0829,
        0.0928, 0.0831, 0.1014, 0.0886], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,376][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0440, 0.0680, 0.0858, 0.0628, 0.0911, 0.0776, 0.0551, 0.0826, 0.0871,
        0.1013, 0.0834, 0.0706, 0.0906], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,378][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0060, 0.0024, 0.0207, 0.0071, 0.0101, 0.0149, 0.0478, 0.0399, 0.0319,
        0.2006, 0.1009, 0.5049, 0.0128], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,379][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0680, 0.1504, 0.1455, 0.0554, 0.0862, 0.0842, 0.0612, 0.0550, 0.0523,
        0.0906, 0.0511, 0.0641, 0.0361], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,381][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.1318, 0.1032, 0.0853, 0.0798, 0.0807, 0.0691, 0.0710, 0.0660, 0.0733,
        0.0509, 0.0562, 0.0605, 0.0721], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,383][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0324, 0.0717, 0.0801, 0.1036, 0.0790, 0.0783, 0.0749, 0.0817, 0.0826,
        0.0795, 0.0749, 0.0792, 0.0821], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,384][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.4596e-01, 6.1039e-05, 1.3113e-04, 8.9016e-05, 1.0158e-04, 1.7552e-03,
        2.1794e-03, 2.0516e-03, 3.8543e-03, 5.1533e-03, 1.0389e-02, 1.2179e-02,
        5.5842e-03, 1.0512e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,386][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.3054e-03, 3.6326e-04, 9.6487e-04, 1.4269e-03, 3.9234e-03, 1.9628e-02,
        1.5079e-01, 4.8027e-03, 2.1573e-01, 4.6638e-01, 2.3081e-02, 9.6692e-02,
        9.3600e-03, 5.5545e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,387][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0602, 0.0735, 0.0766, 0.0751, 0.0765, 0.0714, 0.0701, 0.0739, 0.0696,
        0.0714, 0.0701, 0.0710, 0.0694, 0.0712], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,389][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0572, 0.0342, 0.0486, 0.0503, 0.0528, 0.0748, 0.0685, 0.0801, 0.0908,
        0.0863, 0.0906, 0.0926, 0.0782, 0.0952], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,391][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0217, 0.0551, 0.0694, 0.0727, 0.0780, 0.0810, 0.0642, 0.0857, 0.0923,
        0.0928, 0.0737, 0.0526, 0.0704, 0.0903], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,393][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1192, 0.0023, 0.0071, 0.0111, 0.0176, 0.0158, 0.0550, 0.0211, 0.0355,
        0.2291, 0.0671, 0.1929, 0.1599, 0.0661], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,394][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0845, 0.0442, 0.0581, 0.0585, 0.0508, 0.0653, 0.0858, 0.0653, 0.0764,
        0.0851, 0.0770, 0.0915, 0.0798, 0.0778], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,395][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0422, 0.0616, 0.0799, 0.0582, 0.0839, 0.0734, 0.0504, 0.0771, 0.0813,
        0.0925, 0.0787, 0.0661, 0.0856, 0.0690], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,395][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([3.0509e-03, 6.9289e-04, 1.7629e-04, 1.3090e-03, 5.3961e-04, 2.7624e-03,
        1.6171e-01, 1.8007e-03, 1.2373e-02, 2.0034e-01, 3.0163e-03, 5.6168e-01,
        4.8973e-02, 1.5671e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,396][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0586, 0.1642, 0.1432, 0.0585, 0.0848, 0.0792, 0.0590, 0.0502, 0.0459,
        0.0776, 0.0505, 0.0632, 0.0338, 0.0313], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,398][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1149, 0.1036, 0.0833, 0.0754, 0.0757, 0.0611, 0.0663, 0.0623, 0.0676,
        0.0499, 0.0539, 0.0590, 0.0665, 0.0603], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,400][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0305, 0.0698, 0.0704, 0.0974, 0.0732, 0.0711, 0.0739, 0.0696, 0.0733,
        0.0737, 0.0655, 0.0755, 0.0786, 0.0775], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,401][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ give] are: tensor([8.3582e-01, 9.0976e-05, 2.9341e-04, 2.0002e-04, 2.5250e-04, 4.8861e-03,
        4.6126e-03, 4.9900e-03, 1.0314e-02, 1.3178e-02, 2.7139e-02, 2.6900e-02,
        1.4365e-02, 3.1723e-02, 2.5236e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,403][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0010, 0.0008, 0.0035, 0.0034, 0.0018, 0.0110, 0.3605, 0.0203, 0.2301,
        0.0810, 0.0499, 0.1787, 0.0184, 0.0213, 0.0186], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,404][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0558, 0.0688, 0.0715, 0.0699, 0.0712, 0.0668, 0.0649, 0.0692, 0.0651,
        0.0665, 0.0657, 0.0666, 0.0649, 0.0667, 0.0664], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,406][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0508, 0.0300, 0.0435, 0.0432, 0.0457, 0.0682, 0.0618, 0.0751, 0.0861,
        0.0797, 0.0840, 0.0863, 0.0712, 0.0908, 0.0836], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,408][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0259, 0.0475, 0.0596, 0.0641, 0.0704, 0.0754, 0.0572, 0.0809, 0.0876,
        0.0860, 0.0673, 0.0466, 0.0642, 0.0753, 0.0919], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,410][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0986, 0.0029, 0.0066, 0.0111, 0.0200, 0.0211, 0.0465, 0.0244, 0.0428,
        0.1757, 0.0672, 0.1617, 0.1308, 0.0662, 0.1244], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,411][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0806, 0.0401, 0.0522, 0.0534, 0.0464, 0.0588, 0.0816, 0.0595, 0.0709,
        0.0812, 0.0708, 0.0880, 0.0753, 0.0709, 0.0703], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,413][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0405, 0.0589, 0.0734, 0.0534, 0.0782, 0.0667, 0.0473, 0.0719, 0.0766,
        0.0888, 0.0717, 0.0606, 0.0799, 0.0620, 0.0701], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,415][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0065, 0.0010, 0.0034, 0.0017, 0.0007, 0.0075, 0.0779, 0.0209, 0.0287,
        0.4475, 0.0273, 0.2650, 0.0430, 0.0646, 0.0044], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,417][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0472, 0.1540, 0.1286, 0.0551, 0.0705, 0.0774, 0.0501, 0.0565, 0.0509,
        0.0948, 0.0470, 0.0717, 0.0314, 0.0307, 0.0340], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,419][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0996, 0.0969, 0.0779, 0.0716, 0.0764, 0.0625, 0.0652, 0.0606, 0.0640,
        0.0464, 0.0524, 0.0529, 0.0619, 0.0550, 0.0567], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,420][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0270, 0.0618, 0.0687, 0.0879, 0.0671, 0.0676, 0.0638, 0.0686, 0.0718,
        0.0662, 0.0638, 0.0672, 0.0715, 0.0782, 0.0689], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,421][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ it] are: tensor([8.9830e-01, 4.8571e-05, 1.1828e-04, 6.0603e-05, 8.3315e-05, 1.6870e-03,
        2.0379e-03, 2.4141e-03, 5.1285e-03, 4.9248e-03, 1.1806e-02, 1.3453e-02,
        6.2355e-03, 1.5714e-02, 1.3790e-02, 2.4195e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,422][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ it] are: tensor([2.8407e-03, 3.1305e-04, 1.0137e-03, 2.3489e-03, 1.2755e-03, 2.4995e-02,
        4.6489e-01, 3.8452e-02, 6.7827e-02, 1.3928e-01, 2.1001e-02, 8.2169e-02,
        1.9618e-02, 8.5971e-02, 2.0422e-02, 2.7584e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,422][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0535, 0.0644, 0.0672, 0.0657, 0.0670, 0.0627, 0.0611, 0.0649, 0.0611,
        0.0626, 0.0617, 0.0624, 0.0610, 0.0625, 0.0624, 0.0599],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,424][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.0534, 0.0272, 0.0400, 0.0394, 0.0416, 0.0630, 0.0552, 0.0687, 0.0794,
        0.0724, 0.0784, 0.0796, 0.0654, 0.0836, 0.0770, 0.0757],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,426][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.0199, 0.0449, 0.0575, 0.0601, 0.0630, 0.0675, 0.0567, 0.0743, 0.0794,
        0.0824, 0.0618, 0.0438, 0.0582, 0.0689, 0.0872, 0.0743],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,428][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.1698, 0.0022, 0.0066, 0.0096, 0.0181, 0.0142, 0.0378, 0.0179, 0.0296,
        0.1525, 0.0464, 0.1283, 0.1145, 0.0479, 0.0983, 0.1062],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,429][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.0745, 0.0385, 0.0501, 0.0505, 0.0439, 0.0560, 0.0749, 0.0556, 0.0664,
        0.0749, 0.0661, 0.0806, 0.0699, 0.0662, 0.0646, 0.0674],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,431][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0386, 0.0544, 0.0697, 0.0506, 0.0737, 0.0635, 0.0439, 0.0671, 0.0707,
        0.0821, 0.0676, 0.0570, 0.0746, 0.0589, 0.0652, 0.0623],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,432][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ it] are: tensor([1.8715e-03, 9.6085e-04, 2.0474e-03, 2.0387e-03, 5.2033e-04, 1.7310e-03,
        3.6984e-02, 3.5867e-02, 1.0270e-02, 1.2034e-01, 2.0762e-02, 5.3034e-01,
        2.7451e-02, 1.6284e-01, 4.1044e-02, 4.9357e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,434][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.0727, 0.1089, 0.1440, 0.0589, 0.0727, 0.0788, 0.0430, 0.0506, 0.0496,
        0.0977, 0.0464, 0.0599, 0.0317, 0.0259, 0.0353, 0.0239],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,436][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.1103, 0.0915, 0.0691, 0.0655, 0.0671, 0.0570, 0.0601, 0.0565, 0.0609,
        0.0435, 0.0473, 0.0520, 0.0588, 0.0523, 0.0535, 0.0544],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,438][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.0269, 0.0604, 0.0637, 0.0842, 0.0639, 0.0602, 0.0617, 0.0635, 0.0630,
        0.0627, 0.0577, 0.0639, 0.0679, 0.0726, 0.0666, 0.0614],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,439][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([8.9454e-01, 7.8622e-05, 1.3961e-04, 1.0271e-04, 1.2022e-04, 1.9315e-03,
        2.5068e-03, 2.2080e-03, 4.2468e-03, 6.2341e-03, 1.1299e-02, 1.4028e-02,
        6.4684e-03, 1.2590e-02, 1.0685e-02, 1.9744e-02, 1.3078e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,440][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.3469e-03, 3.1118e-04, 7.2976e-04, 1.3252e-03, 3.2487e-03, 1.4474e-02,
        1.2975e-01, 4.3971e-03, 1.4763e-01, 3.1873e-01, 2.0198e-02, 8.2928e-02,
        8.7689e-03, 4.4677e-03, 3.3568e-02, 2.2217e-01, 5.9500e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,442][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0497, 0.0609, 0.0633, 0.0620, 0.0632, 0.0590, 0.0578, 0.0609, 0.0574,
        0.0588, 0.0578, 0.0586, 0.0572, 0.0587, 0.0588, 0.0565, 0.0592],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,444][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0446, 0.0276, 0.0380, 0.0403, 0.0413, 0.0578, 0.0525, 0.0625, 0.0708,
        0.0672, 0.0702, 0.0729, 0.0608, 0.0754, 0.0707, 0.0702, 0.0772],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,446][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0174, 0.0449, 0.0565, 0.0539, 0.0593, 0.0627, 0.0476, 0.0655, 0.0707,
        0.0719, 0.0578, 0.0405, 0.0530, 0.0709, 0.0789, 0.0664, 0.0820],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,447][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0955, 0.0014, 0.0048, 0.0072, 0.0125, 0.0115, 0.0359, 0.0152, 0.0259,
        0.1642, 0.0495, 0.1371, 0.1186, 0.0479, 0.0970, 0.1133, 0.0626],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,447][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0691, 0.0357, 0.0473, 0.0471, 0.0409, 0.0531, 0.0699, 0.0530, 0.0624,
        0.0699, 0.0626, 0.0750, 0.0651, 0.0633, 0.0596, 0.0631, 0.0630],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,448][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0355, 0.0510, 0.0647, 0.0476, 0.0685, 0.0601, 0.0421, 0.0637, 0.0678,
        0.0767, 0.0647, 0.0540, 0.0707, 0.0567, 0.0619, 0.0605, 0.0538],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,449][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([3.3251e-03, 6.9820e-04, 1.9268e-04, 1.2305e-03, 4.7298e-04, 2.7942e-03,
        1.4370e-01, 1.6220e-03, 1.2817e-02, 1.8423e-01, 2.9825e-03, 5.1164e-01,
        3.8347e-02, 1.5855e-03, 2.3847e-02, 6.8356e-02, 2.1610e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,451][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0751, 0.1117, 0.1273, 0.0551, 0.0862, 0.0757, 0.0588, 0.0530, 0.0412,
        0.0609, 0.0506, 0.0495, 0.0337, 0.0296, 0.0343, 0.0280, 0.0292],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,453][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1052, 0.0866, 0.0671, 0.0639, 0.0641, 0.0528, 0.0581, 0.0529, 0.0572,
        0.0417, 0.0451, 0.0487, 0.0561, 0.0502, 0.0514, 0.0516, 0.0474],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,454][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0256, 0.0572, 0.0573, 0.0794, 0.0598, 0.0577, 0.0606, 0.0566, 0.0596,
        0.0603, 0.0530, 0.0614, 0.0637, 0.0633, 0.0621, 0.0607, 0.0616],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,518][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:28,519][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,520][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,522][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,523][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,525][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,525][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,526][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,527][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,527][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,528][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,529][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,530][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,530][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.8794, 0.1206], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,531][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.6575, 0.3425], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,532][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.3595, 0.6405], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,532][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.4547, 0.5453], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,533][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([9.9970e-01, 2.9559e-04], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,534][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.4163, 0.5837], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,534][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.9593, 0.0407], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,536][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.4960, 0.5040], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,538][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.9578, 0.0422], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,539][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.1616, 0.8384], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,541][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.4130, 0.5870], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,543][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.1356, 0.8644], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,544][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([5.2638e-01, 5.1220e-05, 4.7357e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,544][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([3.0923e-02, 2.7618e-04, 9.6880e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,545][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2145, 0.3827, 0.4028], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,546][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2174, 0.2355, 0.5472], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,547][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.9990e-01, 5.7905e-05, 4.0002e-05], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,547][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2738, 0.3519, 0.3743], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,549][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9216, 0.0319, 0.0465], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,550][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1115, 0.0018, 0.8868], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,551][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([1.7108e-01, 4.0335e-05, 8.2888e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,553][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0519, 0.4022, 0.5459], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,554][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2301, 0.3531, 0.4168], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,555][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([1.2219e-03, 3.5925e-05, 9.9874e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,556][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Nathan] are: tensor([4.6093e-01, 7.8177e-05, 4.8886e-01, 5.0131e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,557][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Nathan] are: tensor([1.1853e-01, 6.6379e-05, 8.4147e-01, 3.9933e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,559][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Nathan] are: tensor([0.1595, 0.2700, 0.2830, 0.2874], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,561][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Nathan] are: tensor([0.1495, 0.1356, 0.4075, 0.3074], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,562][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Nathan] are: tensor([9.9978e-01, 3.1022e-05, 9.2296e-06, 1.7918e-04], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,564][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Nathan] are: tensor([0.1768, 0.2411, 0.2928, 0.2892], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,565][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Nathan] are: tensor([0.9017, 0.0351, 0.0444, 0.0188], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,567][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Nathan] are: tensor([0.0615, 0.0011, 0.8112, 0.1262], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,568][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Nathan] are: tensor([1.8495e-01, 2.1152e-05, 7.3104e-01, 8.3989e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,570][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Nathan] are: tensor([0.0526, 0.2723, 0.3936, 0.2815], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,571][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Nathan] are: tensor([0.1659, 0.2334, 0.3146, 0.2861], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,571][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Nathan] are: tensor([1.5927e-03, 2.1978e-05, 9.6088e-01, 3.7502e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,572][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([2.7589e-01, 2.8790e-04, 5.6606e-01, 8.8985e-02, 6.8780e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,573][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([4.8419e-02, 7.4335e-05, 8.7812e-01, 2.5976e-02, 4.7408e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,574][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.1159, 0.2109, 0.2224, 0.2259, 0.2250], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,575][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.0862, 0.1277, 0.2774, 0.2171, 0.2916], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,576][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([9.9926e-01, 5.1660e-05, 3.3143e-05, 3.7988e-04, 2.7987e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,578][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.1574, 0.2021, 0.2178, 0.2392, 0.1835], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,580][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.8036, 0.0529, 0.0595, 0.0262, 0.0577], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,581][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.0446, 0.0008, 0.4647, 0.1003, 0.3897], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,582][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([9.5843e-02, 1.9919e-05, 6.5296e-01, 8.7389e-02, 1.6379e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,584][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.0515, 0.2207, 0.2959, 0.2543, 0.1775], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,586][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.1118, 0.1682, 0.2472, 0.2472, 0.2255], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,587][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([1.3829e-03, 2.0520e-05, 6.1976e-01, 4.2789e-02, 3.3605e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,588][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([2.9959e-01, 2.4208e-06, 3.5849e-03, 1.1340e-03, 1.6074e-03, 6.9409e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,589][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.1739e-02, 7.8819e-07, 3.0874e-04, 1.3537e-04, 8.1313e-05, 9.6773e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,591][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0958, 0.1728, 0.1817, 0.1846, 0.1834, 0.1817], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,592][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1127, 0.0896, 0.1808, 0.1578, 0.1947, 0.2645], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,594][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([9.9987e-01, 8.5843e-06, 2.6520e-06, 5.3858e-05, 3.7700e-05, 2.4827e-05],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,595][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1377, 0.1608, 0.1696, 0.1898, 0.1527, 0.1893], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,597][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.7749, 0.0433, 0.0542, 0.0218, 0.0450, 0.0609], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,598][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([1.1279e-01, 4.5309e-05, 3.8890e-03, 2.0026e-03, 6.5256e-03, 8.7475e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,598][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([7.8286e-02, 5.3008e-08, 5.6820e-05, 5.2393e-05, 4.7753e-05, 9.2156e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,599][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0248, 0.1677, 0.2395, 0.1899, 0.1455, 0.2325], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,600][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0898, 0.1477, 0.1827, 0.1888, 0.2160, 0.1750], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,601][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.0336e-03, 1.3050e-07, 1.5870e-04, 3.2030e-05, 1.3277e-04, 9.9864e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,602][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([2.5454e-01, 1.9413e-05, 9.2326e-03, 4.9389e-03, 5.9402e-03, 4.9756e-01,
        2.2777e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,603][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([9.5899e-03, 2.9560e-06, 6.4583e-04, 3.2669e-04, 3.0949e-04, 8.5685e-01,
        1.3227e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,605][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.0825, 0.1496, 0.1553, 0.1568, 0.1562, 0.1549, 0.1447],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,606][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.0749, 0.0726, 0.1557, 0.1393, 0.1815, 0.2324, 0.1435],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,607][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([9.9989e-01, 4.7968e-06, 2.7223e-06, 2.7786e-05, 1.3836e-05, 9.1346e-06,
        5.5810e-05], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,609][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.0945, 0.1327, 0.1533, 0.1605, 0.1390, 0.1604, 0.1596],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,611][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.8450, 0.0257, 0.0307, 0.0118, 0.0277, 0.0342, 0.0249],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,612][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([1.1289e-01, 1.4865e-04, 8.5844e-03, 6.0819e-03, 1.6358e-02, 6.8864e-01,
        1.6730e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,613][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([3.6725e-02, 4.0899e-07, 3.0891e-04, 2.5733e-04, 3.3084e-04, 7.9635e-01,
        1.6603e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,615][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.0414, 0.1614, 0.1991, 0.1598, 0.1250, 0.2238, 0.0895],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,616][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0902, 0.1259, 0.1829, 0.1609, 0.1649, 0.1618, 0.1134],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,617][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([1.4087e-03, 1.5778e-06, 1.0872e-03, 3.5441e-04, 1.7313e-03, 8.6700e-01,
        1.2841e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:28,618][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([2.8136e-01, 1.0580e-05, 3.6735e-03, 1.3491e-03, 1.7784e-03, 3.1188e-01,
        2.2167e-01, 1.7828e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,620][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([2.5667e-02, 9.6175e-07, 2.9690e-04, 1.5024e-04, 9.2070e-05, 6.8784e-01,
        1.8343e-01, 1.0253e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,621][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0742, 0.1276, 0.1334, 0.1351, 0.1341, 0.1329, 0.1259, 0.1368],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,623][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0835, 0.0682, 0.1194, 0.1132, 0.1304, 0.1718, 0.1272, 0.1863],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,624][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([9.9982e-01, 1.1124e-05, 2.0305e-06, 5.4408e-05, 1.8364e-05, 1.1832e-05,
        7.4203e-05, 5.0839e-06], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,625][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0882, 0.1229, 0.1251, 0.1399, 0.1136, 0.1336, 0.1455, 0.1312],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,625][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.7703, 0.0265, 0.0315, 0.0130, 0.0309, 0.0413, 0.0228, 0.0637],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,626][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([1.5236e-01, 6.1893e-05, 3.4623e-03, 2.0695e-03, 4.4618e-03, 4.8248e-01,
        1.3328e-01, 2.2182e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,628][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([3.4980e-02, 7.2434e-08, 4.0544e-05, 3.3966e-05, 4.2067e-05, 4.4051e-01,
        1.9577e-01, 3.2862e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,629][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0275, 0.1415, 0.1767, 0.1456, 0.1118, 0.1818, 0.0844, 0.1307],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,631][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0722, 0.1101, 0.1426, 0.1380, 0.1495, 0.1397, 0.1058, 0.1422],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,632][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([1.3296e-03, 3.3200e-07, 1.1823e-04, 5.2694e-05, 1.5223e-04, 5.6374e-01,
        8.4817e-02, 3.4979e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:28,633][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([2.0474e-01, 5.1989e-07, 2.8758e-04, 1.4507e-04, 2.0566e-04, 5.5903e-02,
        2.5724e-02, 4.6044e-02, 6.6695e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,634][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([9.2534e-02, 1.0444e-06, 7.5482e-05, 5.7358e-05, 2.3393e-05, 2.3783e-01,
        1.0000e-01, 1.0053e-01, 4.6895e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,636][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0649, 0.1130, 0.1183, 0.1198, 0.1189, 0.1176, 0.1115, 0.1212, 0.1149],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,638][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0744, 0.0547, 0.0970, 0.0932, 0.1037, 0.1452, 0.1053, 0.1664, 0.1602],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,639][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([9.9996e-01, 2.0140e-06, 4.7108e-07, 1.2250e-05, 5.9345e-06, 3.1481e-06,
        1.0258e-05, 9.7123e-07, 1.0033e-06], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,640][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0819, 0.1046, 0.1063, 0.1202, 0.0994, 0.1192, 0.1285, 0.1237, 0.1162],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,642][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.6898, 0.0284, 0.0316, 0.0150, 0.0330, 0.0404, 0.0235, 0.0621, 0.0761],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,643][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([2.1511e-01, 2.7272e-05, 9.0510e-04, 7.5921e-04, 1.7527e-03, 1.5314e-01,
        5.8270e-02, 1.0917e-01, 4.6087e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,644][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([1.1428e-01, 1.7346e-08, 3.7864e-06, 4.9303e-06, 4.3910e-06, 5.2734e-02,
        4.5816e-02, 7.3432e-02, 7.1372e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,646][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0216, 0.1124, 0.1469, 0.1215, 0.0961, 0.1545, 0.0719, 0.1295, 0.1457],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,648][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0626, 0.0925, 0.1204, 0.1166, 0.1377, 0.1161, 0.0987, 0.1301, 0.1252],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,649][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([1.7112e-03, 7.9906e-08, 1.5701e-05, 9.0981e-06, 2.6055e-05, 7.6963e-02,
        1.9860e-02, 1.1286e-01, 7.8855e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:28,650][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([2.7137e-01, 9.2474e-06, 1.2750e-03, 4.2949e-04, 7.7850e-04, 4.4206e-02,
        4.9759e-02, 3.6234e-02, 5.6250e-01, 3.3436e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,651][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([1.0438e-01, 4.3227e-07, 5.1474e-05, 3.0760e-05, 6.3305e-05, 1.5996e-01,
        6.8089e-02, 7.1785e-02, 3.3581e-01, 2.5983e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,651][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([0.0572, 0.1027, 0.1066, 0.1076, 0.1072, 0.1064, 0.0997, 0.1087, 0.1034,
        0.1005], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,652][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([0.0541, 0.0337, 0.0877, 0.0736, 0.1026, 0.1333, 0.0906, 0.1733, 0.1410,
        0.1102], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,654][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([9.9976e-01, 8.6658e-06, 1.8716e-06, 4.7449e-05, 1.5473e-05, 9.2179e-06,
        5.8224e-05, 6.8342e-06, 4.4787e-06, 9.2518e-05], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,655][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([0.0641, 0.0942, 0.1025, 0.1069, 0.0959, 0.1077, 0.1069, 0.1110, 0.1038,
        0.1070], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,657][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([0.5911, 0.0344, 0.0377, 0.0185, 0.0374, 0.0431, 0.0277, 0.0655, 0.0733,
        0.0713], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,658][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([3.4638e-01, 4.5014e-05, 4.9654e-04, 9.5186e-04, 1.2709e-03, 8.2869e-02,
        3.7917e-02, 4.2722e-02, 1.7093e-01, 3.1642e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,659][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([1.3752e-01, 3.2355e-08, 2.2962e-06, 6.9793e-06, 4.9030e-06, 1.8252e-02,
        1.7524e-02, 1.4182e-02, 2.0521e-01, 6.0730e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,661][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([0.0183, 0.0987, 0.1362, 0.1142, 0.0895, 0.1501, 0.0621, 0.1044, 0.1314,
        0.0950], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,663][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([0.0706, 0.0764, 0.1153, 0.1022, 0.1137, 0.1130, 0.0803, 0.1129, 0.1158,
        0.0998], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,664][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([6.5944e-03, 1.3155e-07, 1.8642e-05, 7.8462e-06, 4.4447e-05, 4.2730e-02,
        1.2148e-02, 3.7311e-02, 3.6130e-01, 5.3985e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:28,665][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([1.1148e-01, 3.0784e-07, 6.5279e-05, 2.5545e-05, 5.4187e-05, 9.2665e-03,
        6.8189e-03, 1.0418e-02, 1.4634e-01, 1.4949e-02, 7.0058e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,666][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.8263e-02, 1.4726e-07, 6.6463e-06, 5.4800e-06, 3.3778e-06, 2.0383e-02,
        1.5543e-02, 1.0346e-02, 6.7566e-02, 2.6343e-01, 6.0446e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,668][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0527, 0.0919, 0.0962, 0.0972, 0.0967, 0.0956, 0.0904, 0.0986, 0.0936,
        0.0912, 0.0957], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,670][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0423, 0.0473, 0.0734, 0.0729, 0.0825, 0.1102, 0.0775, 0.1214, 0.1187,
        0.1391, 0.1146], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,671][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.9992e-01, 2.2069e-06, 2.8958e-07, 1.7819e-05, 9.1781e-06, 2.1222e-06,
        1.4142e-05, 7.5748e-07, 6.5604e-07, 3.0410e-05, 1.6941e-06],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,673][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0785, 0.0828, 0.0850, 0.0941, 0.0784, 0.0957, 0.0983, 0.0978, 0.0944,
        0.1006, 0.0946], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,674][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.6443, 0.0229, 0.0300, 0.0117, 0.0256, 0.0335, 0.0195, 0.0502, 0.0563,
        0.0462, 0.0598], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,675][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([1.0442e-01, 1.0306e-05, 1.7487e-04, 2.0179e-04, 3.7935e-04, 2.8924e-02,
        1.8424e-02, 2.0587e-02, 8.7092e-02, 2.8742e-01, 4.5237e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,677][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([3.5991e-02, 2.8666e-09, 1.7546e-07, 3.6113e-07, 3.2127e-07, 2.3669e-03,
        3.2030e-03, 3.1927e-03, 3.9265e-02, 1.5147e-01, 7.6451e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,678][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0178, 0.0902, 0.1218, 0.1025, 0.0797, 0.1284, 0.0573, 0.1026, 0.1197,
        0.0879, 0.0922], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,680][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0485, 0.0766, 0.0997, 0.0960, 0.1058, 0.0992, 0.0756, 0.1054, 0.1092,
        0.0960, 0.0878], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,681][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([1.2351e-03, 1.2692e-08, 1.0829e-06, 4.4296e-07, 1.0641e-06, 4.0083e-03,
        2.8670e-03, 4.8446e-03, 6.1008e-02, 9.0751e-02, 8.3528e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:28,682][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([3.1556e-01, 1.6930e-06, 1.4506e-04, 7.2894e-05, 1.3280e-04, 6.5729e-03,
        1.9190e-02, 7.6938e-03, 1.1813e-01, 1.2364e-02, 4.1850e-01, 1.0164e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,683][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([2.7990e-01, 4.2705e-07, 1.5912e-05, 2.0630e-05, 1.3377e-05, 2.1796e-02,
        1.8687e-02, 8.9491e-03, 4.9426e-02, 1.1732e-01, 1.6021e-01, 3.4365e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,684][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.0487, 0.0852, 0.0880, 0.0889, 0.0886, 0.0879, 0.0827, 0.0897, 0.0855,
        0.0832, 0.0875, 0.0840], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,685][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.0590, 0.0256, 0.0669, 0.0619, 0.0797, 0.1009, 0.0681, 0.1207, 0.1011,
        0.0929, 0.1069, 0.1163], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,686][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([9.9982e-01, 2.0205e-06, 4.1354e-07, 3.3446e-05, 3.0615e-05, 6.3399e-06,
        2.6073e-05, 2.4594e-06, 1.5958e-06, 3.7582e-05, 4.4868e-06, 3.1434e-05],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,688][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.0614, 0.0752, 0.0783, 0.0885, 0.0754, 0.0873, 0.0906, 0.0911, 0.0872,
        0.0863, 0.0903, 0.0883], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,690][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.6461, 0.0210, 0.0237, 0.0113, 0.0227, 0.0270, 0.0165, 0.0390, 0.0453,
        0.0406, 0.0462, 0.0606], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,691][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([3.7663e-01, 2.8859e-05, 1.5647e-04, 3.3834e-04, 4.2055e-04, 1.2477e-02,
        1.5825e-02, 9.0773e-03, 3.8705e-02, 1.0222e-01, 1.3152e-01, 3.1260e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,692][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([2.4184e-01, 1.1743e-08, 4.1830e-07, 1.0488e-06, 8.2328e-07, 1.1904e-03,
        4.5979e-03, 1.2855e-03, 1.5788e-02, 9.3911e-02, 1.8571e-01, 4.5567e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,694][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.0166, 0.0790, 0.1263, 0.0978, 0.0739, 0.1245, 0.0515, 0.0924, 0.1129,
        0.0841, 0.0842, 0.0569], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,695][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.0571, 0.0648, 0.0942, 0.0825, 0.0998, 0.0915, 0.0663, 0.0975, 0.0966,
        0.0843, 0.0883, 0.0771], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,697][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([4.5695e-03, 3.5874e-08, 2.1526e-06, 1.3278e-06, 6.8654e-06, 2.5756e-03,
        1.9746e-03, 2.4346e-03, 3.2076e-02, 3.7462e-02, 2.8555e-01, 6.3335e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:28,698][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([3.4262e-02, 1.9454e-06, 3.5426e-04, 1.0570e-04, 2.1834e-04, 1.9480e-02,
        1.1851e-02, 1.5269e-02, 1.9607e-01, 1.2340e-02, 5.8486e-01, 1.0850e-01,
        1.6692e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,699][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([1.2576e-02, 1.3398e-07, 1.9509e-05, 6.9217e-06, 5.4249e-06, 1.9300e-02,
        1.8294e-02, 1.0250e-02, 5.9201e-02, 1.9912e-01, 3.1222e-01, 3.2205e-01,
        4.6948e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,701][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0455, 0.0782, 0.0816, 0.0820, 0.0819, 0.0811, 0.0765, 0.0831, 0.0789,
        0.0766, 0.0807, 0.0773, 0.0766], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,703][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0259, 0.0350, 0.0664, 0.0658, 0.0752, 0.0922, 0.0675, 0.0973, 0.0953,
        0.1087, 0.0874, 0.1231, 0.0602], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,704][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([9.9989e-01, 1.2910e-06, 5.4535e-07, 1.4849e-05, 2.0064e-05, 6.3273e-06,
        6.2401e-06, 1.4078e-06, 8.4800e-07, 2.0582e-05, 2.5949e-06, 1.1373e-05,
        1.9269e-05], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,706][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.0574, 0.0692, 0.0784, 0.0824, 0.0682, 0.0820, 0.0808, 0.0838, 0.0797,
        0.0823, 0.0871, 0.0789, 0.0697], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,707][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.4961, 0.0277, 0.0328, 0.0145, 0.0303, 0.0335, 0.0227, 0.0543, 0.0631,
        0.0566, 0.0619, 0.0766, 0.0301], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,707][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([2.1448e-02, 9.7933e-06, 3.3626e-04, 1.6286e-04, 4.5657e-04, 3.4843e-02,
        8.3356e-03, 1.8871e-02, 7.6558e-02, 8.5817e-02, 3.2750e-01, 2.6243e-01,
        1.6323e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,708][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([3.2274e-03, 3.5380e-09, 6.9684e-07, 8.9638e-07, 1.0127e-06, 3.0400e-03,
        2.1539e-03, 2.7462e-03, 2.3780e-02, 9.6589e-02, 3.9174e-01, 4.1218e-01,
        6.4541e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,710][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0172, 0.0788, 0.1115, 0.0929, 0.0776, 0.1174, 0.0536, 0.0913, 0.1035,
        0.0786, 0.0812, 0.0549, 0.0416], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,711][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0429, 0.0625, 0.0888, 0.0815, 0.0831, 0.0828, 0.0668, 0.0852, 0.0924,
        0.0779, 0.0860, 0.0738, 0.0764], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,712][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([2.6316e-04, 1.0323e-08, 1.7303e-06, 5.4681e-07, 1.6940e-06, 2.9125e-03,
        9.3244e-04, 2.7523e-03, 2.4454e-02, 2.6783e-02, 2.8780e-01, 6.2086e-01,
        3.3237e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:28,714][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.9030e-01, 7.5392e-07, 4.5242e-05, 2.9013e-05, 3.6086e-05, 3.3924e-03,
        5.4679e-03, 4.4048e-03, 4.7953e-02, 1.0066e-02, 1.9472e-01, 1.0560e-01,
        1.5470e-02, 3.2252e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,715][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.8739e-02, 1.2767e-07, 4.4649e-06, 2.5064e-06, 1.4513e-06, 7.5835e-03,
        8.5624e-03, 4.2240e-03, 3.3252e-02, 9.8043e-02, 2.3554e-01, 3.1244e-01,
        3.1069e-02, 2.2054e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,717][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0418, 0.0719, 0.0752, 0.0762, 0.0756, 0.0747, 0.0709, 0.0768, 0.0728,
        0.0711, 0.0744, 0.0718, 0.0712, 0.0756], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,718][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0415, 0.0325, 0.0554, 0.0527, 0.0599, 0.0738, 0.0553, 0.0809, 0.0824,
        0.1020, 0.0816, 0.1160, 0.0616, 0.1043], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,720][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.9993e-01, 1.7952e-06, 2.8589e-07, 1.4609e-05, 7.3235e-06, 2.2292e-06,
        7.3907e-06, 5.0047e-07, 4.6726e-07, 1.3642e-05, 1.2929e-06, 1.0520e-05,
        1.0273e-05, 1.9333e-06], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,721][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0565, 0.0653, 0.0669, 0.0756, 0.0611, 0.0744, 0.0781, 0.0753, 0.0715,
        0.0781, 0.0763, 0.0763, 0.0707, 0.0739], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,723][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.5183, 0.0239, 0.0286, 0.0117, 0.0253, 0.0328, 0.0182, 0.0468, 0.0534,
        0.0467, 0.0558, 0.0665, 0.0254, 0.0466], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,724][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([9.8562e-02, 5.4546e-06, 7.8078e-05, 7.5778e-05, 1.5562e-04, 8.0465e-03,
        5.1513e-03, 4.7491e-03, 2.5836e-02, 5.4661e-02, 1.4845e-01, 2.2680e-01,
        1.2778e-01, 2.9966e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,726][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([3.1135e-02, 2.5647e-09, 6.7922e-08, 1.4727e-07, 1.2264e-07, 5.7222e-04,
        1.4238e-03, 6.2665e-04, 9.1089e-03, 4.1135e-02, 1.4472e-01, 4.1054e-01,
        4.6384e-02, 3.1435e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,727][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0143, 0.0788, 0.1055, 0.0883, 0.0709, 0.1109, 0.0506, 0.0843, 0.0988,
        0.0711, 0.0762, 0.0519, 0.0404, 0.0579], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,729][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0404, 0.0614, 0.0751, 0.0773, 0.0846, 0.0717, 0.0608, 0.0797, 0.0798,
        0.0727, 0.0704, 0.0694, 0.0739, 0.0828], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,730][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.0170e-03, 8.3702e-09, 2.2310e-07, 2.5441e-07, 3.4329e-07, 5.4082e-04,
        5.0508e-04, 6.6817e-04, 6.3420e-03, 1.3035e-02, 1.2628e-01, 6.5590e-01,
        2.3821e-02, 1.7188e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:28,732][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([7.1608e-02, 1.7299e-06, 1.5242e-04, 8.5383e-05, 1.3385e-04, 7.4900e-03,
        1.0292e-02, 6.7310e-03, 9.2475e-02, 1.1032e-02, 2.8466e-01, 7.6063e-02,
        1.8500e-02, 3.4439e-01, 7.6389e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,733][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([9.2758e-03, 1.3055e-07, 6.4071e-06, 3.9464e-06, 1.5752e-06, 5.9292e-03,
        5.1644e-03, 4.0430e-03, 2.7758e-02, 5.5429e-02, 2.6359e-01, 2.7123e-01,
        3.9760e-02, 2.3361e-01, 8.4192e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,734][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0393, 0.0671, 0.0701, 0.0705, 0.0703, 0.0698, 0.0657, 0.0715, 0.0678,
        0.0661, 0.0695, 0.0667, 0.0661, 0.0704, 0.0691], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,734][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0343, 0.0292, 0.0497, 0.0460, 0.0541, 0.0674, 0.0547, 0.0779, 0.0750,
        0.0947, 0.0726, 0.1062, 0.0554, 0.0986, 0.0841], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,736][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([9.9972e-01, 3.7059e-06, 8.8437e-07, 2.7015e-05, 1.5817e-05, 7.6336e-06,
        3.2943e-05, 2.8820e-06, 2.4193e-06, 6.9841e-05, 5.8370e-06, 5.7368e-05,
        2.3249e-05, 4.7771e-06, 2.6634e-05], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,737][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0492, 0.0590, 0.0652, 0.0684, 0.0559, 0.0708, 0.0693, 0.0734, 0.0693,
        0.0744, 0.0737, 0.0691, 0.0641, 0.0733, 0.0648], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,739][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.5442, 0.0190, 0.0218, 0.0097, 0.0221, 0.0264, 0.0167, 0.0415, 0.0507,
        0.0435, 0.0491, 0.0621, 0.0218, 0.0372, 0.0343], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,740][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([2.8719e-02, 5.5424e-06, 6.7936e-05, 1.1438e-04, 1.6185e-04, 9.5157e-03,
        5.8116e-03, 6.1478e-03, 2.3288e-02, 7.6013e-02, 9.8388e-02, 2.6731e-01,
        1.2643e-01, 2.8040e-01, 7.7620e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,741][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([8.8566e-03, 3.5647e-09, 1.9664e-07, 2.3718e-07, 2.2102e-07, 9.5758e-04,
        8.4173e-04, 1.2987e-03, 8.9506e-03, 5.5807e-02, 1.3617e-01, 2.8031e-01,
        2.7212e-02, 4.0410e-01, 7.5493e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,743][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0195, 0.0719, 0.0949, 0.0781, 0.0615, 0.1019, 0.0466, 0.0833, 0.0979,
        0.0733, 0.0769, 0.0507, 0.0387, 0.0570, 0.0480], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,745][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0443, 0.0535, 0.0764, 0.0705, 0.0761, 0.0703, 0.0543, 0.0738, 0.0756,
        0.0663, 0.0663, 0.0595, 0.0686, 0.0777, 0.0669], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,746][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([1.6347e-04, 7.0666e-09, 5.3151e-07, 3.8817e-07, 8.6797e-07, 1.0342e-03,
        5.5585e-04, 7.5986e-04, 8.5759e-03, 1.9271e-02, 9.1949e-02, 5.6764e-01,
        1.7320e-02, 2.2729e-01, 6.5432e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:28,748][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([8.9244e-02, 2.8752e-07, 2.1815e-05, 8.3790e-06, 1.5529e-05, 1.5629e-03,
        2.9334e-03, 2.9181e-03, 3.9828e-02, 3.5626e-03, 1.1434e-01, 4.8278e-02,
        7.3564e-03, 2.7654e-01, 5.3721e-02, 3.5967e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,749][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([9.1077e-03, 1.1139e-07, 2.1931e-06, 2.2494e-06, 8.1629e-07, 5.0439e-03,
        4.5876e-03, 3.8446e-03, 1.9754e-02, 5.4441e-02, 1.6056e-01, 2.2578e-01,
        3.3449e-02, 2.3862e-01, 8.9237e-02, 1.5557e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,751][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.0370, 0.0628, 0.0657, 0.0663, 0.0659, 0.0653, 0.0616, 0.0669, 0.0635,
        0.0621, 0.0651, 0.0625, 0.0619, 0.0659, 0.0646, 0.0628],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,753][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([0.0298, 0.0269, 0.0468, 0.0446, 0.0517, 0.0641, 0.0475, 0.0715, 0.0717,
        0.0858, 0.0693, 0.0994, 0.0515, 0.0924, 0.0788, 0.0683],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,754][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([9.9985e-01, 1.6349e-06, 3.0083e-07, 1.1436e-05, 5.5480e-06, 2.5195e-06,
        1.8793e-05, 1.1430e-06, 1.1157e-06, 3.9498e-05, 2.0809e-06, 2.2773e-05,
        8.6749e-06, 1.7545e-06, 1.7471e-05, 1.9409e-05], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,756][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.0463, 0.0582, 0.0579, 0.0638, 0.0539, 0.0628, 0.0695, 0.0683, 0.0619,
        0.0707, 0.0664, 0.0667, 0.0622, 0.0670, 0.0616, 0.0628],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,758][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.5052, 0.0197, 0.0236, 0.0099, 0.0228, 0.0276, 0.0168, 0.0437, 0.0526,
        0.0436, 0.0504, 0.0604, 0.0232, 0.0417, 0.0336, 0.0251],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,759][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([2.4560e-02, 2.7345e-06, 4.4967e-05, 4.5445e-05, 9.3687e-05, 7.0138e-03,
        3.3488e-03, 3.7090e-03, 2.1607e-02, 3.8857e-02, 1.0665e-01, 1.4218e-01,
        1.1309e-01, 3.2395e-01, 9.7578e-02, 1.1727e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,759][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([5.9509e-03, 1.9307e-09, 7.4072e-08, 1.2133e-07, 1.0375e-07, 5.0323e-04,
        6.0000e-04, 1.0181e-03, 6.3941e-03, 3.0406e-02, 1.0627e-01, 2.1453e-01,
        2.9566e-02, 3.8945e-01, 8.3361e-02, 1.3194e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,760][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.0164, 0.0648, 0.0952, 0.0789, 0.0602, 0.1029, 0.0428, 0.0803, 0.0936,
        0.0701, 0.0702, 0.0453, 0.0345, 0.0526, 0.0467, 0.0452],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,762][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.0329, 0.0512, 0.0658, 0.0663, 0.0762, 0.0601, 0.0506, 0.0673, 0.0652,
        0.0660, 0.0656, 0.0594, 0.0634, 0.0770, 0.0651, 0.0679],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,763][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([1.4989e-04, 7.7785e-09, 2.3468e-07, 3.1725e-07, 6.8357e-07, 4.8428e-04,
        4.4771e-04, 8.1397e-04, 5.2652e-03, 1.3529e-02, 8.9130e-02, 4.7459e-01,
        1.8467e-02, 2.1724e-01, 1.1524e-01, 6.4642e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:28,765][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.6935e-01, 7.2611e-07, 2.0855e-05, 1.7161e-05, 2.1794e-05, 1.2846e-03,
        2.9425e-03, 1.7593e-03, 1.6367e-02, 4.8352e-03, 5.9675e-02, 4.3033e-02,
        6.0383e-03, 1.1933e-01, 3.0336e-02, 1.8498e-01, 2.6000e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,766][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.9696e-02, 9.0367e-08, 2.1103e-06, 1.2842e-06, 8.1559e-07, 2.8602e-03,
        3.2401e-03, 2.0912e-03, 1.2540e-02, 3.7255e-02, 9.7833e-02, 1.3620e-01,
        1.6392e-02, 1.2410e-01, 7.8043e-02, 1.8488e-01, 2.5487e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,768][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0349, 0.0588, 0.0615, 0.0623, 0.0619, 0.0611, 0.0580, 0.0627, 0.0595,
        0.0582, 0.0608, 0.0588, 0.0582, 0.0619, 0.0607, 0.0589, 0.0618],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,769][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0364, 0.0254, 0.0420, 0.0426, 0.0468, 0.0557, 0.0440, 0.0620, 0.0607,
        0.0789, 0.0622, 0.0911, 0.0487, 0.0827, 0.0724, 0.0638, 0.0846],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,771][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.9991e-01, 1.7293e-06, 3.2586e-07, 1.6434e-05, 6.3089e-06, 2.6195e-06,
        5.7715e-06, 5.9171e-07, 4.9830e-07, 1.3209e-05, 1.5052e-06, 1.1721e-05,
        8.6564e-06, 1.9995e-06, 5.4474e-06, 6.5840e-06, 3.0735e-06],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,772][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0491, 0.0536, 0.0545, 0.0617, 0.0498, 0.0606, 0.0635, 0.0618, 0.0587,
        0.0638, 0.0623, 0.0627, 0.0574, 0.0602, 0.0568, 0.0628, 0.0605],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,774][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.4657, 0.0225, 0.0249, 0.0110, 0.0241, 0.0296, 0.0155, 0.0420, 0.0475,
        0.0404, 0.0478, 0.0562, 0.0223, 0.0417, 0.0302, 0.0228, 0.0557],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,776][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([7.8563e-02, 4.9060e-06, 3.9325e-05, 5.1851e-05, 9.8377e-05, 3.6850e-03,
        2.3706e-03, 1.9859e-03, 1.0579e-02, 3.0239e-02, 6.7514e-02, 1.3999e-01,
        5.7274e-02, 1.4546e-01, 7.0930e-02, 1.0678e-01, 2.8444e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,777][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([4.3852e-02, 2.4579e-09, 4.0624e-08, 6.6956e-08, 4.8314e-08, 2.3834e-04,
        5.8421e-04, 2.4546e-04, 3.5721e-03, 1.6473e-02, 5.3988e-02, 1.5238e-01,
        1.5772e-02, 1.3577e-01, 6.3027e-02, 1.3837e-01, 3.7572e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,779][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0112, 0.0657, 0.0878, 0.0741, 0.0591, 0.0929, 0.0430, 0.0731, 0.0860,
        0.0610, 0.0655, 0.0443, 0.0346, 0.0494, 0.0436, 0.0457, 0.0630],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,781][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0317, 0.0486, 0.0599, 0.0613, 0.0672, 0.0573, 0.0492, 0.0649, 0.0645,
        0.0585, 0.0576, 0.0556, 0.0599, 0.0670, 0.0613, 0.0674, 0.0681],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,782][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.2754e-03, 8.4587e-09, 1.5908e-07, 2.1130e-07, 3.0534e-07, 3.7140e-04,
        2.3813e-04, 4.1656e-04, 3.4687e-03, 6.3874e-03, 6.8001e-02, 3.0757e-01,
        1.4526e-02, 1.0036e-01, 6.6949e-02, 8.9797e-02, 3.4063e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:28,785][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:28,787][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[5388],
        [ 141],
        [  64],
        [  46],
        [ 292],
        [  51],
        [  49],
        [  13],
        [  15],
        [  44],
        [ 149],
        [  49],
        [  38],
        [  69],
        [ 162],
        [  28],
        [ 115]], device='cuda:0')
[2024-07-24 10:31:28,788][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[6066],
        [1869],
        [1447],
        [1701],
        [2787],
        [ 466],
        [ 496],
        [ 134],
        [ 371],
        [ 487],
        [1053],
        [3696],
        [1572],
        [1318],
        [2832],
        [ 666],
        [1504]], device='cuda:0')
[2024-07-24 10:31:28,790][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[17282],
        [16383],
        [16756],
        [16679],
        [16080],
        [17132],
        [16475],
        [16452],
        [16625],
        [16682],
        [16284],
        [15646],
        [12616],
        [15115],
        [11423],
        [12670],
        [12544]], device='cuda:0')
[2024-07-24 10:31:28,792][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[19674],
        [10153],
        [10241],
        [20970],
        [24229],
        [46844],
        [21082],
        [15351],
        [15942],
        [24391],
        [22351],
        [19821],
        [18612],
        [21229],
        [21069],
        [21053],
        [30463]], device='cuda:0')
[2024-07-24 10:31:28,794][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[4837],
        [6867],
        [5900],
        [5111],
        [4607],
        [4217],
        [4298],
        [4071],
        [3960],
        [4101],
        [4089],
        [4208],
        [4218],
        [4176],
        [4176],
        [4149],
        [4096]], device='cuda:0')
[2024-07-24 10:31:28,795][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[1059],
        [1749],
        [2689],
        [2314],
        [2346],
        [2128],
        [1974],
        [1766],
        [1642],
        [1550],
        [1568],
        [1540],
        [1471],
        [1400],
        [1363],
        [1332],
        [1273]], device='cuda:0')
[2024-07-24 10:31:28,797][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 4002],
        [22970],
        [18805],
        [18376],
        [18694],
        [17889],
        [16762],
        [17334],
        [17115],
        [16300],
        [16606],
        [17060],
        [17643],
        [18101],
        [18415],
        [18408],
        [19112]], device='cuda:0')
[2024-07-24 10:31:28,799][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 4703],
        [ 4855],
        [ 6294],
        [ 5710],
        [ 7429],
        [ 6764],
        [ 7039],
        [ 7807],
        [ 8279],
        [12792],
        [12843],
        [14028],
        [14469],
        [14541],
        [15569],
        [15043],
        [16212]], device='cuda:0')
[2024-07-24 10:31:28,801][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[4597],
        [4830],
        [5683],
        [5467],
        [6030],
        [6210],
        [6475],
        [6775],
        [6647],
        [6537],
        [6893],
        [6789],
        [7024],
        [7354],
        [7606],
        [7729],
        [7851]], device='cuda:0')
[2024-07-24 10:31:28,802][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[9012],
        [9456],
        [9400],
        [9500],
        [9472],
        [9391],
        [9218],
        [9163],
        [9085],
        [9221],
        [9312],
        [9375],
        [9324],
        [9257],
        [9286],
        [9171],
        [9135]], device='cuda:0')
[2024-07-24 10:31:28,804][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[24470],
        [35058],
        [34678],
        [14098],
        [15082],
        [22974],
        [25357],
        [29889],
        [28852],
        [23772],
        [24959],
        [26090],
        [30532],
        [33281],
        [27287],
        [29809],
        [33233]], device='cuda:0')
[2024-07-24 10:31:28,806][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[37034],
        [21848],
        [ 9806],
        [11615],
        [11544],
        [12080],
        [11553],
        [10412],
        [ 8849],
        [ 7915],
        [ 6945],
        [ 7842],
        [ 7181],
        [ 7483],
        [ 7094],
        [ 6731],
        [ 6891]], device='cuda:0')
[2024-07-24 10:31:28,808][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[34093],
        [15764],
        [16037],
        [15573],
        [16853],
        [17298],
        [16867],
        [16945],
        [16453],
        [15582],
        [15495],
        [14872],
        [14339],
        [14068],
        [13691],
        [13032],
        [12731]], device='cuda:0')
[2024-07-24 10:31:28,810][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[29863],
        [19142],
        [20177],
        [17147],
        [16995],
        [16953],
        [17439],
        [17440],
        [17785],
        [18082],
        [18488],
        [18369],
        [18815],
        [18623],
        [19128],
        [19453],
        [19274]], device='cuda:0')
[2024-07-24 10:31:28,812][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[6346],
        [1188],
        [1009],
        [ 899],
        [3327],
        [ 959],
        [3632],
        [1684],
        [1034],
        [2333],
        [2316],
        [ 472],
        [ 498],
        [1117],
        [1059],
        [1078],
        [1605]], device='cuda:0')
[2024-07-24 10:31:28,813][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[30598],
        [41799],
        [44328],
        [43265],
        [40174],
        [32159],
        [33726],
        [35072],
        [34158],
        [34779],
        [29765],
        [32778],
        [29656],
        [32934],
        [31208],
        [33666],
        [34385]], device='cuda:0')
[2024-07-24 10:31:28,815][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[36725],
        [25535],
        [ 8726],
        [ 8536],
        [ 8413],
        [17071],
        [17147],
        [17615],
        [16034],
        [11205],
        [16066],
        [24418],
        [20942],
        [23771],
        [25264],
        [25135],
        [24255]], device='cuda:0')
[2024-07-24 10:31:28,816][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[29717],
        [29963],
        [32643],
        [33662],
        [34519],
        [35318],
        [35959],
        [36208],
        [36261],
        [36126],
        [36271],
        [36173],
        [36457],
        [36742],
        [36839],
        [36902],
        [36956]], device='cuda:0')
[2024-07-24 10:31:28,818][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 9705],
        [33018],
        [13278],
        [11231],
        [ 9771],
        [11203],
        [11860],
        [14137],
        [15887],
        [18101],
        [19434],
        [19449],
        [19632],
        [19263],
        [19372],
        [19198],
        [19039]], device='cuda:0')
[2024-07-24 10:31:28,820][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[10496],
        [10489],
        [10496],
        [10470],
        [10425],
        [10487],
        [10492],
        [10489],
        [10493],
        [10495],
        [10494],
        [10491],
        [10490],
        [10491],
        [10493],
        [10495],
        [10491]], device='cuda:0')
[2024-07-24 10:31:28,822][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 4694],
        [11211],
        [17457],
        [13776],
        [13182],
        [13982],
        [13904],
        [13482],
        [13420],
        [12653],
        [12965],
        [13072],
        [12574],
        [11806],
        [11969],
        [11565],
        [11249]], device='cuda:0')
[2024-07-24 10:31:28,823][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[15540],
        [14122],
        [12371],
        [11888],
        [10090],
        [ 9279],
        [ 9696],
        [ 8477],
        [ 7961],
        [ 7598],
        [ 7565],
        [ 7560],
        [ 7251],
        [ 7230],
        [ 7102],
        [ 7050],
        [ 7033]], device='cuda:0')
[2024-07-24 10:31:28,825][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[37249],
        [21367],
        [30011],
        [30569],
        [35754],
        [39418],
        [38602],
        [38704],
        [22069],
        [39944],
        [27974],
        [18875],
        [14590],
        [ 7914],
        [ 7921],
        [ 7965],
        [ 5180]], device='cuda:0')
[2024-07-24 10:31:28,827][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[12712],
        [13016],
        [42356],
        [42987],
        [46029],
        [42552],
        [42948],
        [42976],
        [35157],
        [43848],
        [44132],
        [44266],
        [45786],
        [46490],
        [46900],
        [46690],
        [46271]], device='cuda:0')
[2024-07-24 10:31:28,829][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[10278],
        [  305],
        [  441],
        [  399],
        [  431],
        [  499],
        [  585],
        [  641],
        [  729],
        [  744],
        [  779],
        [  737],
        [  743],
        [  756],
        [  791],
        [  821],
        [  830]], device='cuda:0')
[2024-07-24 10:31:28,831][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 8171],
        [10513],
        [18478],
        [21147],
        [22046],
        [23105],
        [22361],
        [23025],
        [24326],
        [22689],
        [23000],
        [21765],
        [22915],
        [23869],
        [24981],
        [25128],
        [26228]], device='cuda:0')
[2024-07-24 10:31:28,832][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[17934],
        [38805],
        [42329],
        [42381],
        [37554],
        [39019],
        [38285],
        [38504],
        [38062],
        [35452],
        [43275],
        [39002],
        [38769],
        [36658],
        [36085],
        [35459],
        [33970]], device='cuda:0')
[2024-07-24 10:31:28,834][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[25858],
        [22399],
        [15643],
        [15754],
        [16631],
        [17449],
        [16340],
        [16663],
        [20544],
        [18163],
        [17347],
        [16888],
        [18034],
        [17416],
        [17452],
        [17219],
        [18412]], device='cuda:0')
[2024-07-24 10:31:28,836][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[41520],
        [45980],
        [37078],
        [38809],
        [37743],
        [42153],
        [35798],
        [38711],
        [40160],
        [36637],
        [41637],
        [42235],
        [43150],
        [42208],
        [42218],
        [41132],
        [41783]], device='cuda:0')
[2024-07-24 10:31:28,838][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[36867],
        [36867],
        [36867],
        [36867],
        [36867],
        [36867],
        [36867],
        [36867],
        [36867],
        [36867],
        [36867],
        [36867],
        [36867],
        [36867],
        [36867],
        [36867],
        [36867]], device='cuda:0')
[2024-07-24 10:31:28,920][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:28,921][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,922][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,922][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,923][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,924][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,925][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,925][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,926][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,927][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,927][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,928][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,929][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:28,930][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.0510, 0.9490], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,930][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([9.9946e-01, 5.3731e-04], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,932][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.0026, 0.9974], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,934][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.2188, 0.7812], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,935][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.8905, 0.1095], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,936][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.8099, 0.1901], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,936][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.6313, 0.3687], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,937][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.9064, 0.0936], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,938][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.6501, 0.3499], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,939][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.0571, 0.9429], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,941][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.0315, 0.9685], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,943][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.0546, 0.9454], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:28,944][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0344, 0.4227, 0.5429], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,945][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([9.9958e-01, 2.8958e-04, 1.2762e-04], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,947][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0008, 0.4163, 0.5828], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,948][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([7.7706e-03, 6.1834e-04, 9.9161e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,949][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.7963, 0.0350, 0.1687], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,951][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.7186, 0.0446, 0.2368], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,952][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5130, 0.2585, 0.2284], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,954][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.8493, 0.0838, 0.0669], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,956][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.4742, 0.2190, 0.3068], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,957][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0249, 0.5110, 0.4641], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,959][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0108, 0.4478, 0.5414], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,961][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0217, 0.4594, 0.5188], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:28,961][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Nathan] are: tensor([0.0223, 0.2844, 0.3645, 0.3288], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,962][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Nathan] are: tensor([9.9976e-01, 1.4703e-04, 6.3794e-05, 2.6321e-05], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,963][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Nathan] are: tensor([3.2050e-04, 2.4544e-01, 3.6449e-01, 3.8974e-01], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,963][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Nathan] are: tensor([0.0164, 0.0009, 0.8132, 0.1696], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,965][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Nathan] are: tensor([0.7234, 0.0291, 0.1370, 0.1105], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,967][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Nathan] are: tensor([0.5647, 0.0520, 0.2983, 0.0850], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,968][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Nathan] are: tensor([0.4059, 0.2162, 0.1906, 0.1873], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,970][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Nathan] are: tensor([0.8033, 0.0768, 0.0667, 0.0533], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,972][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Nathan] are: tensor([0.3808, 0.1618, 0.2340, 0.2233], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,973][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Nathan] are: tensor([0.0177, 0.3752, 0.3466, 0.2606], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,975][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Nathan] are: tensor([0.0081, 0.2998, 0.3604, 0.3317], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,976][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Nathan] are: tensor([0.0136, 0.3045, 0.3436, 0.3382], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:28,978][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.0175, 0.2110, 0.2670, 0.2444, 0.2602], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,979][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ got] are: tensor([9.9966e-01, 1.7948e-04, 7.5545e-05, 3.0824e-05, 5.2851e-05],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,981][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.0004, 0.1788, 0.2628, 0.2925, 0.2656], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,982][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.0141, 0.0008, 0.5531, 0.1346, 0.2974], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,984][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.6981, 0.0270, 0.1119, 0.0904, 0.0726], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,986][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.5296, 0.0512, 0.2353, 0.0796, 0.1043], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,987][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.3367, 0.1846, 0.1644, 0.1580, 0.1563], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,988][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.7718, 0.0738, 0.0607, 0.0493, 0.0444], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,989][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.2902, 0.1372, 0.1980, 0.1949, 0.1797], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,989][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.0120, 0.3178, 0.2870, 0.2114, 0.1718], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,991][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.0066, 0.2216, 0.2632, 0.2449, 0.2637], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,993][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.0102, 0.2304, 0.2601, 0.2570, 0.2423], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:28,994][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0123, 0.1724, 0.2118, 0.1951, 0.2081, 0.2003], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,995][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([9.9942e-01, 2.4080e-04, 1.0546e-04, 4.3591e-05, 7.2996e-05, 1.2012e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,997][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0003, 0.1363, 0.1967, 0.2213, 0.2217, 0.2237], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:28,998][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.4993e-02, 2.4611e-05, 3.3715e-03, 1.0659e-03, 2.0781e-03, 9.7847e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,000][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.7168, 0.0152, 0.0530, 0.0432, 0.0374, 0.1343], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,001][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.7957, 0.0191, 0.0432, 0.0223, 0.0288, 0.0908], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,003][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2927, 0.1582, 0.1420, 0.1361, 0.1359, 0.1352], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,005][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.7029, 0.0813, 0.0665, 0.0537, 0.0469, 0.0486], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,006][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2827, 0.1094, 0.1447, 0.1451, 0.1357, 0.1824], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,008][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0113, 0.2563, 0.2315, 0.1773, 0.1456, 0.1780], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,010][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0085, 0.1816, 0.2073, 0.1935, 0.2050, 0.2041], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,011][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0080, 0.1853, 0.2093, 0.2036, 0.1940, 0.1996], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,013][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.0080, 0.1504, 0.1822, 0.1710, 0.1807, 0.1678, 0.1398],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,014][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([9.9994e-01, 3.0033e-05, 1.0683e-05, 3.8006e-06, 6.7544e-06, 1.2673e-05,
        6.7147e-07], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,014][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([1.9840e-04, 9.5988e-02, 1.4822e-01, 1.7013e-01, 1.7598e-01, 1.8444e-01,
        2.2505e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,015][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([1.7932e-02, 1.2901e-04, 1.1522e-02, 3.4203e-03, 5.0553e-03, 7.7945e-01,
        1.8249e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,016][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.4347, 0.0231, 0.0848, 0.0713, 0.0622, 0.1856, 0.1383],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,017][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.7450, 0.0225, 0.0423, 0.0258, 0.0269, 0.0816, 0.0558],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,019][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.2620, 0.1406, 0.1228, 0.1194, 0.1172, 0.1172, 0.1209],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,021][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.6742, 0.0738, 0.0618, 0.0503, 0.0443, 0.0466, 0.0490],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,022][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.2306, 0.0954, 0.1282, 0.1283, 0.1198, 0.1544, 0.1433],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,024][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0104, 0.2190, 0.2037, 0.1521, 0.1298, 0.1574, 0.1276],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,025][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0041, 0.1473, 0.1735, 0.1613, 0.1756, 0.1771, 0.1612],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,027][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0060, 0.1543, 0.1739, 0.1711, 0.1626, 0.1695, 0.1626],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,029][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0092, 0.1287, 0.1563, 0.1460, 0.1547, 0.1475, 0.1226, 0.1350],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,030][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ at] are: tensor([9.9992e-01, 3.3634e-05, 1.3687e-05, 4.8154e-06, 8.7800e-06, 1.5456e-05,
        8.3444e-07, 1.1714e-06], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,032][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0002, 0.0956, 0.1363, 0.1593, 0.1494, 0.1618, 0.1707, 0.1267],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,033][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ at] are: tensor([1.0102e-02, 1.5569e-05, 1.9263e-03, 6.8413e-04, 1.3360e-03, 4.7340e-01,
        8.8034e-02, 4.2450e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,035][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.4982, 0.0141, 0.0507, 0.0430, 0.0364, 0.1266, 0.0988, 0.1322],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,036][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.7004, 0.0190, 0.0398, 0.0177, 0.0211, 0.0827, 0.0551, 0.0643],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,038][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.2257, 0.1267, 0.1133, 0.1082, 0.1064, 0.1068, 0.1092, 0.1037],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,039][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.6885, 0.0650, 0.0522, 0.0411, 0.0366, 0.0382, 0.0400, 0.0384],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,040][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.1948, 0.0828, 0.1100, 0.1092, 0.1041, 0.1383, 0.1285, 0.1323],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,041][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0087, 0.1977, 0.1765, 0.1369, 0.1126, 0.1364, 0.1137, 0.1174],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,042][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0050, 0.1313, 0.1480, 0.1413, 0.1495, 0.1504, 0.1397, 0.1347],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,043][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0052, 0.1344, 0.1515, 0.1492, 0.1415, 0.1453, 0.1401, 0.1328],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,045][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0069, 0.1147, 0.1385, 0.1296, 0.1371, 0.1302, 0.1081, 0.1194, 0.1154],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,046][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ the] are: tensor([9.9994e-01, 2.5392e-05, 1.0189e-05, 3.5563e-06, 6.5516e-06, 1.2019e-05,
        5.9028e-07, 8.1545e-07, 4.9426e-07], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,048][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0002, 0.0840, 0.1166, 0.1351, 0.1270, 0.1337, 0.1398, 0.1147, 0.1489],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,049][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ the] are: tensor([2.2553e-02, 1.0100e-05, 5.0283e-04, 1.7652e-04, 3.0738e-04, 9.6005e-02,
        2.4160e-02, 1.2282e-01, 7.3347e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,050][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.4820, 0.0117, 0.0405, 0.0336, 0.0299, 0.0968, 0.0762, 0.1015, 0.1278],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,052][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.8572, 0.0082, 0.0126, 0.0085, 0.0086, 0.0329, 0.0239, 0.0294, 0.0189],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,054][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2158, 0.1147, 0.1005, 0.0967, 0.0953, 0.0944, 0.0969, 0.0920, 0.0937],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,055][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.6360, 0.0641, 0.0536, 0.0428, 0.0383, 0.0402, 0.0426, 0.0406, 0.0419],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,057][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1816, 0.0716, 0.0944, 0.0945, 0.0896, 0.1184, 0.1107, 0.1146, 0.1246],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,059][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0080, 0.1746, 0.1567, 0.1232, 0.1024, 0.1237, 0.1018, 0.1054, 0.1042],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,060][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0058, 0.1147, 0.1294, 0.1248, 0.1312, 0.1313, 0.1219, 0.1212, 0.1198],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,062][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0051, 0.1186, 0.1335, 0.1312, 0.1246, 0.1282, 0.1236, 0.1182, 0.1170],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,064][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([0.0069, 0.1036, 0.1238, 0.1159, 0.1224, 0.1155, 0.0973, 0.1058, 0.1028,
        0.1061], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,065][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([9.9983e-01, 6.5009e-05, 2.7970e-05, 1.0985e-05, 1.8833e-05, 3.1607e-05,
        2.0238e-06, 2.7041e-06, 1.7521e-06, 6.3145e-06], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,065][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([1.1084e-04, 6.1770e-02, 9.9734e-02, 1.2445e-01, 1.1637e-01, 1.3135e-01,
        1.3963e-01, 1.0363e-01, 1.4148e-01, 8.1481e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,066][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([2.3085e-02, 1.5227e-05, 4.5379e-04, 3.5482e-04, 4.7780e-04, 7.4631e-02,
        2.4322e-02, 8.3438e-02, 5.1409e-01, 2.7914e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,067][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([0.4013, 0.0127, 0.0407, 0.0343, 0.0300, 0.0913, 0.0750, 0.0969, 0.1257,
        0.0921], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,068][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([0.7733, 0.0115, 0.0140, 0.0074, 0.0103, 0.0285, 0.0307, 0.0418, 0.0223,
        0.0603], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,070][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.1986, 0.1050, 0.0899, 0.0883, 0.0859, 0.0860, 0.0900, 0.0847, 0.0863,
        0.0853], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,071][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([0.6487, 0.0582, 0.0466, 0.0377, 0.0337, 0.0357, 0.0368, 0.0362, 0.0373,
        0.0291], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,073][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.1655, 0.0657, 0.0840, 0.0846, 0.0803, 0.1030, 0.0975, 0.1015, 0.1097,
        0.1081], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,074][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([0.0076, 0.1599, 0.1422, 0.1116, 0.0939, 0.1127, 0.0923, 0.0957, 0.0956,
        0.0886], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,076][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([0.0026, 0.0998, 0.1121, 0.1111, 0.1195, 0.1186, 0.1113, 0.1073, 0.1061,
        0.1116], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,078][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([0.0040, 0.1053, 0.1182, 0.1165, 0.1100, 0.1148, 0.1116, 0.1049, 0.1049,
        0.1099], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,079][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0057, 0.0937, 0.1125, 0.1044, 0.1107, 0.1050, 0.0882, 0.0967, 0.0938,
        0.0980, 0.0913], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,081][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([9.9990e-01, 3.8949e-05, 1.7120e-05, 6.0662e-06, 1.1015e-05, 1.9132e-05,
        1.0516e-06, 1.4582e-06, 9.0020e-07, 3.2593e-06, 1.3895e-06],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,082][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0001, 0.0626, 0.0978, 0.1103, 0.1049, 0.1171, 0.1203, 0.0947, 0.1266,
        0.0727, 0.0929], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,083][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([1.2418e-02, 2.9355e-06, 7.2367e-05, 3.3767e-05, 4.8847e-05, 1.4306e-02,
        5.2965e-03, 1.7613e-02, 1.2912e-01, 5.1105e-02, 7.6998e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,085][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4185, 0.0088, 0.0284, 0.0244, 0.0224, 0.0689, 0.0591, 0.0762, 0.0985,
        0.0751, 0.1196], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,087][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8305, 0.0053, 0.0069, 0.0044, 0.0060, 0.0215, 0.0192, 0.0271, 0.0158,
        0.0414, 0.0220], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,088][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1844, 0.0977, 0.0843, 0.0823, 0.0807, 0.0788, 0.0822, 0.0765, 0.0782,
        0.0785, 0.0765], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,090][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5973, 0.0599, 0.0486, 0.0398, 0.0352, 0.0372, 0.0387, 0.0380, 0.0389,
        0.0307, 0.0358], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,091][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1491, 0.0588, 0.0743, 0.0768, 0.0724, 0.0921, 0.0885, 0.0913, 0.0975,
        0.1004, 0.0988], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,092][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0068, 0.1460, 0.1309, 0.1015, 0.0853, 0.1029, 0.0872, 0.0894, 0.0881,
        0.0817, 0.0801], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,093][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0040, 0.0898, 0.1049, 0.1014, 0.1063, 0.1058, 0.0976, 0.0974, 0.0958,
        0.0975, 0.0996], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,094][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0038, 0.0959, 0.1077, 0.1058, 0.1004, 0.1037, 0.0998, 0.0951, 0.0947,
        0.0984, 0.0949], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,095][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.0054, 0.0860, 0.1023, 0.0961, 0.1015, 0.0953, 0.0807, 0.0876, 0.0850,
        0.0881, 0.0822, 0.0896], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,096][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([9.9986e-01, 5.4411e-05, 2.1156e-05, 8.1591e-06, 1.4338e-05, 2.4520e-05,
        1.5628e-06, 2.0687e-06, 1.3132e-06, 4.7593e-06, 1.9085e-06, 3.5910e-06],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,098][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([6.5417e-05, 5.5047e-02, 8.6507e-02, 9.8113e-02, 9.0698e-02, 1.0434e-01,
        1.0568e-01, 8.2854e-02, 1.1352e-01, 6.6181e-02, 8.4259e-02, 1.1273e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,099][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([1.0184e-02, 5.7908e-06, 1.2083e-04, 6.2122e-05, 9.7929e-05, 1.2470e-02,
        5.6503e-03, 1.6402e-02, 9.8283e-02, 5.4524e-02, 4.8759e-01, 3.1461e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,101][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.3605, 0.0106, 0.0300, 0.0255, 0.0221, 0.0656, 0.0550, 0.0676, 0.0912,
        0.0675, 0.1049, 0.0996], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,102][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.7591, 0.0086, 0.0097, 0.0069, 0.0105, 0.0221, 0.0241, 0.0334, 0.0165,
        0.0372, 0.0229, 0.0489], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,104][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.1629, 0.0885, 0.0771, 0.0751, 0.0742, 0.0735, 0.0774, 0.0727, 0.0744,
        0.0738, 0.0721, 0.0784], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,106][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.6050, 0.0552, 0.0447, 0.0360, 0.0325, 0.0342, 0.0347, 0.0336, 0.0350,
        0.0272, 0.0330, 0.0290], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,107][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.1331, 0.0547, 0.0689, 0.0701, 0.0663, 0.0827, 0.0796, 0.0815, 0.0874,
        0.0891, 0.0876, 0.0990], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,109][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.0069, 0.1360, 0.1197, 0.0944, 0.0801, 0.0948, 0.0787, 0.0809, 0.0804,
        0.0752, 0.0740, 0.0789], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,111][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.0026, 0.0807, 0.0954, 0.0900, 0.0976, 0.0970, 0.0885, 0.0883, 0.0870,
        0.0899, 0.0912, 0.0921], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,113][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.0038, 0.0860, 0.0966, 0.0951, 0.0902, 0.0946, 0.0911, 0.0865, 0.0861,
        0.0907, 0.0870, 0.0924], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,115][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0057, 0.0784, 0.0938, 0.0876, 0.0926, 0.0876, 0.0740, 0.0806, 0.0783,
        0.0805, 0.0763, 0.0826, 0.0821], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,116][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([9.9988e-01, 4.9788e-05, 1.8032e-05, 6.6575e-06, 1.1763e-05, 2.0892e-05,
        1.1945e-06, 1.6068e-06, 1.0634e-06, 3.8542e-06, 1.5762e-06, 2.8451e-06,
        1.9645e-06], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,117][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([8.8020e-05, 5.3484e-02, 7.8453e-02, 9.4743e-02, 8.9807e-02, 9.5019e-02,
        1.0618e-01, 7.8962e-02, 1.0396e-01, 5.8284e-02, 7.9166e-02, 9.1955e-02,
        6.9896e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,117][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([1.5251e-03, 3.3770e-06, 1.6659e-04, 7.2470e-05, 1.0886e-04, 1.7690e-02,
        3.8612e-03, 1.7942e-02, 8.4601e-02, 4.7290e-02, 4.7836e-01, 3.0183e-01,
        4.6548e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,118][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.3066, 0.0089, 0.0281, 0.0240, 0.0217, 0.0648, 0.0529, 0.0669, 0.0882,
        0.0649, 0.1029, 0.0915, 0.0786], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,119][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.6444, 0.0077, 0.0136, 0.0113, 0.0132, 0.0350, 0.0297, 0.0338, 0.0229,
        0.0519, 0.0340, 0.0655, 0.0371], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,121][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.1409, 0.0842, 0.0751, 0.0728, 0.0706, 0.0698, 0.0724, 0.0674, 0.0691,
        0.0680, 0.0668, 0.0721, 0.0708], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,122][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.5806, 0.0557, 0.0450, 0.0365, 0.0322, 0.0335, 0.0348, 0.0335, 0.0347,
        0.0269, 0.0323, 0.0287, 0.0256], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,124][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.1148, 0.0487, 0.0636, 0.0641, 0.0608, 0.0787, 0.0734, 0.0773, 0.0830,
        0.0819, 0.0813, 0.0916, 0.0809], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,126][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0054, 0.1336, 0.1151, 0.0896, 0.0720, 0.0888, 0.0748, 0.0751, 0.0767,
        0.0699, 0.0697, 0.0759, 0.0533], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,127][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0028, 0.0755, 0.0870, 0.0864, 0.0924, 0.0892, 0.0832, 0.0816, 0.0788,
        0.0812, 0.0818, 0.0840, 0.0761], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,129][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0032, 0.0799, 0.0895, 0.0878, 0.0828, 0.0863, 0.0835, 0.0798, 0.0796,
        0.0831, 0.0800, 0.0849, 0.0794], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,131][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0044, 0.0735, 0.0870, 0.0818, 0.0860, 0.0815, 0.0687, 0.0747, 0.0728,
        0.0761, 0.0706, 0.0782, 0.0773, 0.0674], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,132][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([9.9989e-01, 4.2017e-05, 1.7126e-05, 6.0841e-06, 1.0791e-05, 1.8341e-05,
        9.6273e-07, 1.3841e-06, 8.5208e-07, 3.1658e-06, 1.3075e-06, 2.2761e-06,
        1.6201e-06, 1.5616e-06], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,133][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([8.9606e-05, 4.9323e-02, 7.1628e-02, 8.5873e-02, 8.2250e-02, 9.2485e-02,
        9.3508e-02, 7.1842e-02, 9.7838e-02, 5.3706e-02, 7.2394e-02, 8.6800e-02,
        6.4179e-02, 7.8083e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,135][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.7558e-02, 1.9527e-06, 3.6273e-05, 2.1856e-05, 2.5658e-05, 4.9401e-03,
        2.6747e-03, 5.9248e-03, 4.1273e-02, 1.6152e-02, 2.3662e-01, 1.4594e-01,
        3.5090e-02, 4.9375e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,136][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.3822, 0.0073, 0.0204, 0.0179, 0.0156, 0.0475, 0.0429, 0.0507, 0.0696,
        0.0517, 0.0786, 0.0772, 0.0621, 0.0764], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,138][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.8390, 0.0045, 0.0049, 0.0049, 0.0043, 0.0138, 0.0138, 0.0124, 0.0076,
        0.0243, 0.0101, 0.0235, 0.0165, 0.0206], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,140][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1505, 0.0781, 0.0678, 0.0663, 0.0649, 0.0635, 0.0670, 0.0617, 0.0628,
        0.0629, 0.0614, 0.0669, 0.0659, 0.0602], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,142][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.5730, 0.0508, 0.0421, 0.0341, 0.0302, 0.0316, 0.0331, 0.0318, 0.0333,
        0.0260, 0.0307, 0.0272, 0.0242, 0.0319], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,143][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1080, 0.0456, 0.0579, 0.0589, 0.0558, 0.0720, 0.0688, 0.0706, 0.0764,
        0.0772, 0.0762, 0.0853, 0.0757, 0.0717], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,143][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0058, 0.1196, 0.1051, 0.0824, 0.0683, 0.0823, 0.0704, 0.0718, 0.0713,
        0.0665, 0.0650, 0.0713, 0.0514, 0.0687], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,144][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0033, 0.0699, 0.0813, 0.0787, 0.0837, 0.0830, 0.0766, 0.0755, 0.0747,
        0.0760, 0.0771, 0.0785, 0.0716, 0.0701], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,146][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0031, 0.0743, 0.0838, 0.0824, 0.0777, 0.0808, 0.0772, 0.0739, 0.0735,
        0.0762, 0.0738, 0.0780, 0.0734, 0.0718], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,147][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0047, 0.0683, 0.0813, 0.0762, 0.0803, 0.0760, 0.0643, 0.0699, 0.0680,
        0.0704, 0.0661, 0.0721, 0.0718, 0.0628, 0.0677], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,149][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ give] are: tensor([9.9987e-01, 5.1489e-05, 1.8541e-05, 6.8082e-06, 1.1802e-05, 2.0836e-05,
        1.2178e-06, 1.6907e-06, 1.1145e-06, 4.0411e-06, 1.7039e-06, 3.0227e-06,
        2.0524e-06, 1.8913e-06, 2.2278e-06], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,151][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ give] are: tensor([9.1103e-05, 4.8588e-02, 6.6033e-02, 8.4105e-02, 7.5886e-02, 8.3593e-02,
        8.9883e-02, 7.0593e-02, 8.9670e-02, 5.5669e-02, 6.6314e-02, 8.8254e-02,
        5.7543e-02, 7.0626e-02, 5.3152e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,152][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ give] are: tensor([1.4873e-03, 2.2555e-06, 6.7888e-05, 4.0572e-05, 4.6741e-05, 9.2253e-03,
        2.3118e-03, 8.4194e-03, 4.7263e-02, 3.0073e-02, 2.3760e-01, 1.7897e-01,
        1.9751e-02, 3.9806e-01, 6.6682e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,153][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.3173, 0.0065, 0.0198, 0.0165, 0.0154, 0.0474, 0.0413, 0.0512, 0.0677,
        0.0511, 0.0784, 0.0743, 0.0612, 0.0749, 0.0770], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,155][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.6123, 0.0096, 0.0107, 0.0092, 0.0073, 0.0289, 0.0283, 0.0289, 0.0189,
        0.0564, 0.0235, 0.0562, 0.0267, 0.0454, 0.0378], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,157][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.1361, 0.0750, 0.0644, 0.0630, 0.0611, 0.0599, 0.0630, 0.0584, 0.0600,
        0.0602, 0.0583, 0.0641, 0.0626, 0.0577, 0.0562], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,159][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.5782, 0.0481, 0.0389, 0.0312, 0.0282, 0.0296, 0.0301, 0.0296, 0.0309,
        0.0237, 0.0287, 0.0249, 0.0222, 0.0297, 0.0260], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,161][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.1025, 0.0423, 0.0534, 0.0547, 0.0511, 0.0669, 0.0630, 0.0657, 0.0710,
        0.0704, 0.0697, 0.0791, 0.0698, 0.0658, 0.0747], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,163][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0054, 0.1163, 0.1010, 0.0790, 0.0642, 0.0797, 0.0661, 0.0674, 0.0684,
        0.0627, 0.0629, 0.0681, 0.0486, 0.0653, 0.0449], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,164][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0020, 0.0653, 0.0734, 0.0727, 0.0777, 0.0773, 0.0731, 0.0713, 0.0692,
        0.0721, 0.0716, 0.0763, 0.0653, 0.0660, 0.0667], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,166][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0028, 0.0686, 0.0770, 0.0762, 0.0719, 0.0746, 0.0721, 0.0690, 0.0686,
        0.0715, 0.0688, 0.0733, 0.0682, 0.0674, 0.0698], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,168][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.0038, 0.0636, 0.0747, 0.0704, 0.0745, 0.0706, 0.0605, 0.0654, 0.0636,
        0.0667, 0.0622, 0.0690, 0.0680, 0.0595, 0.0643, 0.0632],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,169][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ it] are: tensor([9.9992e-01, 3.3796e-05, 1.2251e-05, 4.3287e-06, 7.9141e-06, 1.4024e-05,
        7.1218e-07, 1.0136e-06, 6.2238e-07, 2.3853e-06, 9.3453e-07, 1.7429e-06,
        1.1717e-06, 1.0570e-06, 1.2223e-06, 8.6211e-07], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,170][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ it] are: tensor([8.3785e-05, 3.8687e-02, 6.3536e-02, 7.6251e-02, 7.5187e-02, 7.7909e-02,
        8.1994e-02, 6.9273e-02, 8.5731e-02, 4.9484e-02, 6.3579e-02, 7.3092e-02,
        5.5978e-02, 7.0216e-02, 5.2353e-02, 6.6644e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,170][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ it] are: tensor([3.6322e-03, 1.1436e-06, 2.7125e-05, 1.3673e-05, 2.2303e-05, 4.2063e-03,
        1.7496e-03, 5.7253e-03, 3.0926e-02, 1.7912e-02, 1.7287e-01, 1.2312e-01,
        1.6992e-02, 3.7450e-01, 6.1866e-02, 1.8644e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,172][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.2591, 0.0064, 0.0190, 0.0165, 0.0151, 0.0464, 0.0364, 0.0465, 0.0625,
        0.0492, 0.0758, 0.0724, 0.0606, 0.0758, 0.0749, 0.0834],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,174][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.7028, 0.0054, 0.0058, 0.0063, 0.0048, 0.0207, 0.0143, 0.0161, 0.0111,
        0.0374, 0.0147, 0.0356, 0.0222, 0.0354, 0.0322, 0.0352],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,176][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.1288, 0.0709, 0.0611, 0.0599, 0.0580, 0.0571, 0.0592, 0.0552, 0.0565,
        0.0566, 0.0550, 0.0606, 0.0590, 0.0543, 0.0530, 0.0548],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,177][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.5386, 0.0482, 0.0394, 0.0321, 0.0285, 0.0303, 0.0315, 0.0309, 0.0321,
        0.0250, 0.0299, 0.0260, 0.0233, 0.0309, 0.0269, 0.0266],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,179][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0974, 0.0380, 0.0489, 0.0496, 0.0475, 0.0621, 0.0589, 0.0612, 0.0666,
        0.0650, 0.0655, 0.0734, 0.0652, 0.0623, 0.0713, 0.0672],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,181][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.0052, 0.1083, 0.0948, 0.0744, 0.0611, 0.0752, 0.0629, 0.0645, 0.0647,
        0.0608, 0.0592, 0.0659, 0.0461, 0.0620, 0.0434, 0.0514],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,183][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.0027, 0.0613, 0.0700, 0.0690, 0.0720, 0.0716, 0.0671, 0.0665, 0.0646,
        0.0681, 0.0661, 0.0696, 0.0624, 0.0608, 0.0641, 0.0641],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,184][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.0026, 0.0642, 0.0721, 0.0711, 0.0673, 0.0697, 0.0677, 0.0643, 0.0639,
        0.0669, 0.0645, 0.0683, 0.0640, 0.0629, 0.0656, 0.0651],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,186][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0034, 0.0611, 0.0715, 0.0675, 0.0708, 0.0671, 0.0569, 0.0615, 0.0601,
        0.0629, 0.0583, 0.0649, 0.0640, 0.0558, 0.0605, 0.0597, 0.0540],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,188][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([9.9982e-01, 6.2230e-05, 2.7022e-05, 1.0259e-05, 1.7599e-05, 2.9832e-05,
        1.7618e-06, 2.5052e-06, 1.6047e-06, 5.6952e-06, 2.3593e-06, 4.0600e-06,
        2.9189e-06, 2.7962e-06, 3.1065e-06, 2.2100e-06, 4.3961e-06],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,189][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([8.4112e-05, 4.1809e-02, 5.8785e-02, 7.0451e-02, 6.8079e-02, 7.6446e-02,
        7.4801e-02, 5.9224e-02, 8.0888e-02, 4.4969e-02, 6.0969e-02, 7.5800e-02,
        5.3844e-02, 6.4451e-02, 4.5648e-02, 6.0667e-02, 6.3084e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,191][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.0324e-02, 9.0369e-07, 1.2286e-05, 7.6863e-06, 9.5535e-06, 1.9325e-03,
        1.0721e-03, 2.3833e-03, 1.7157e-02, 7.3011e-03, 9.3935e-02, 5.2096e-02,
        1.6339e-02, 2.0134e-01, 3.7488e-02, 1.2419e-01, 4.3442e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,193][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.3126, 0.0061, 0.0159, 0.0143, 0.0123, 0.0365, 0.0343, 0.0396, 0.0542,
        0.0411, 0.0603, 0.0613, 0.0486, 0.0584, 0.0609, 0.0710, 0.0727],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,194][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.8086, 0.0043, 0.0039, 0.0047, 0.0037, 0.0124, 0.0110, 0.0103, 0.0061,
        0.0217, 0.0076, 0.0193, 0.0134, 0.0161, 0.0171, 0.0183, 0.0216],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,195][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1255, 0.0659, 0.0573, 0.0562, 0.0552, 0.0543, 0.0564, 0.0526, 0.0534,
        0.0530, 0.0522, 0.0568, 0.0559, 0.0513, 0.0501, 0.0522, 0.0518],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,196][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.5207, 0.0474, 0.0391, 0.0317, 0.0280, 0.0292, 0.0307, 0.0295, 0.0308,
        0.0245, 0.0287, 0.0255, 0.0229, 0.0296, 0.0262, 0.0254, 0.0302],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,197][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0877, 0.0375, 0.0474, 0.0481, 0.0455, 0.0589, 0.0557, 0.0574, 0.0620,
        0.0626, 0.0617, 0.0693, 0.0612, 0.0582, 0.0663, 0.0624, 0.0582],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,199][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0048, 0.1026, 0.0894, 0.0707, 0.0580, 0.0700, 0.0593, 0.0606, 0.0601,
        0.0562, 0.0555, 0.0605, 0.0437, 0.0583, 0.0411, 0.0489, 0.0602],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,201][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0026, 0.0566, 0.0661, 0.0641, 0.0680, 0.0681, 0.0628, 0.0628, 0.0617,
        0.0635, 0.0635, 0.0652, 0.0592, 0.0577, 0.0601, 0.0608, 0.0573],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,202][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0026, 0.0606, 0.0683, 0.0673, 0.0637, 0.0662, 0.0632, 0.0606, 0.0601,
        0.0626, 0.0604, 0.0637, 0.0600, 0.0587, 0.0610, 0.0607, 0.0602],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,279][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:29,280][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,282][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,283][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,284][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,286][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,287][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,288][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,290][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,291][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,293][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,294][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,296][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,297][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.3258, 0.6742], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,299][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.3801, 0.6199], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,300][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.0097, 0.9903], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,301][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.3058, 0.6942], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,302][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.1016, 0.8984], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,303][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.8732, 0.1268], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,304][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.9061, 0.0939], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,306][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.7992, 0.2008], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,307][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.0547, 0.9453], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,309][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.0626, 0.9374], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,311][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.0079, 0.9921], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,312][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.9599, 0.0401], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,313][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([9.7076e-04, 1.0130e-06, 9.9903e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,315][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.3185, 0.2615, 0.4200], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,316][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([2.2233e-04, 1.0071e-01, 8.9906e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,317][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([9.9066e-03, 1.3585e-04, 9.8996e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,318][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([1.8336e-03, 3.0259e-05, 9.9814e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,320][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9085, 0.0040, 0.0876], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,322][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9706, 0.0177, 0.0116], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,323][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.8350, 0.0863, 0.0787], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,324][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([1.2474e-03, 3.2830e-05, 9.9872e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,325][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([6.5842e-04, 5.6657e-05, 9.9928e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,326][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([8.0580e-04, 8.6245e-02, 9.1295e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,327][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.9631, 0.0228, 0.0141], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,328][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Nathan] are: tensor([4.4982e-04, 4.7629e-07, 9.7081e-01, 2.8743e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,328][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Nathan] are: tensor([0.8687, 0.0537, 0.0273, 0.0502], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,329][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Nathan] are: tensor([2.5451e-05, 5.9981e-02, 8.7442e-01, 6.5569e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,330][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Nathan] are: tensor([3.6360e-02, 2.8087e-04, 7.3090e-01, 2.3246e-01], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,331][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Nathan] are: tensor([1.8246e-03, 6.7465e-05, 9.0727e-01, 9.0837e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,333][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Nathan] are: tensor([0.8902, 0.0047, 0.0960, 0.0091], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,334][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Nathan] are: tensor([0.9513, 0.0257, 0.0144, 0.0086], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,336][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Nathan] are: tensor([0.3857, 0.2540, 0.1538, 0.2065], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,337][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Nathan] are: tensor([1.7777e-03, 1.7756e-05, 9.7384e-01, 2.4367e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,338][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Nathan] are: tensor([6.1774e-04, 1.3411e-05, 9.2808e-01, 7.1287e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,339][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Nathan] are: tensor([2.6829e-04, 1.0619e-01, 8.2936e-01, 6.4185e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,341][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Nathan] are: tensor([0.4383, 0.0722, 0.1618, 0.3277], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,342][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([9.6299e-04, 5.7576e-07, 6.5447e-01, 7.9622e-02, 2.6494e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,344][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.4706, 0.2674, 0.0990, 0.0798, 0.0832], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,345][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([8.0256e-06, 4.3126e-02, 7.1530e-01, 8.3926e-02, 1.5764e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,346][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([1.2425e-02, 1.9060e-04, 5.6368e-01, 1.9335e-01, 2.3036e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,347][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([3.1094e-03, 6.4510e-05, 8.3900e-01, 6.6068e-02, 9.1755e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,349][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.8310, 0.0060, 0.1246, 0.0119, 0.0265], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,350][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.9489, 0.0237, 0.0156, 0.0056, 0.0062], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,352][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.4577, 0.1205, 0.0879, 0.1429, 0.1911], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,353][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([6.5797e-04, 1.2085e-05, 8.3870e-01, 4.7890e-02, 1.1274e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,353][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([2.8698e-04, 2.3277e-05, 8.8282e-01, 6.0676e-02, 5.6194e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,354][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([7.6554e-05, 6.9728e-02, 7.7027e-01, 6.0120e-02, 9.9801e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,355][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.6087, 0.0414, 0.0417, 0.1411, 0.1671], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,356][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([6.3776e-04, 9.5175e-10, 6.9189e-06, 2.8247e-06, 1.0279e-05, 9.9934e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,358][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.6211, 0.0727, 0.0773, 0.0500, 0.1165, 0.0625], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,359][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([6.4207e-05, 5.4436e-02, 4.3339e-01, 6.1064e-02, 3.0268e-01, 1.4837e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,360][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.7643e-02, 2.8173e-06, 8.8544e-04, 5.0730e-04, 4.0263e-04, 9.8056e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,361][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([5.9800e-03, 2.3912e-07, 2.3020e-04, 3.0630e-05, 6.6453e-05, 9.9369e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,362][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([9.8710e-01, 3.4145e-04, 1.2825e-03, 2.7768e-04, 6.4342e-04, 1.0352e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,364][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.9784, 0.0094, 0.0028, 0.0011, 0.0012, 0.0070], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,365][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.8222, 0.0412, 0.0134, 0.0247, 0.0525, 0.0460], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,367][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.9876e-03, 1.9086e-07, 2.4176e-04, 4.5034e-05, 1.2340e-04, 9.9760e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,368][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([9.2573e-04, 4.4127e-07, 3.9985e-04, 1.1071e-04, 6.3410e-05, 9.9850e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,369][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([2.8191e-04, 6.6986e-02, 4.1536e-01, 5.6835e-02, 2.1023e-01, 2.5031e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,371][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.8441, 0.0240, 0.0198, 0.0307, 0.0578, 0.0237], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,372][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([1.7500e-04, 1.6354e-08, 9.4234e-05, 1.4889e-04, 3.0834e-04, 9.0681e-01,
        9.2467e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,374][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.8026, 0.0246, 0.0114, 0.0278, 0.0566, 0.0247, 0.0523],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,375][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([8.8269e-06, 1.6135e-02, 3.0049e-01, 2.8851e-02, 2.1811e-01, 3.7956e-01,
        5.6847e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,376][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([2.9280e-02, 3.8365e-05, 6.1006e-03, 2.7051e-03, 1.9272e-03, 7.5913e-01,
        2.0082e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,377][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([8.1916e-04, 2.9162e-06, 1.7090e-03, 4.3788e-04, 6.7355e-04, 9.3270e-01,
        6.3659e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,378][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([9.7476e-01, 8.0004e-04, 1.9075e-03, 6.1506e-04, 8.3365e-04, 1.0316e-02,
        1.0769e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,379][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.9653, 0.0069, 0.0030, 0.0022, 0.0017, 0.0086, 0.0121],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,380][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.5970, 0.0519, 0.0106, 0.0224, 0.0407, 0.0736, 0.2038],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,381][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([1.9794e-03, 1.8248e-06, 1.7324e-03, 3.8251e-04, 1.1551e-03, 8.3931e-01,
        1.5544e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,381][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([6.4386e-04, 2.9396e-06, 2.1786e-03, 9.1415e-04, 9.5115e-04, 8.9098e-01,
        1.0433e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,382][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([1.5246e-04, 2.9849e-02, 1.2716e-01, 2.5649e-02, 1.2256e-01, 6.5665e-01,
        3.7975e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,384][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.2193, 0.0546, 0.0395, 0.1333, 0.2643, 0.1802, 0.1089],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,385][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([2.1986e-04, 1.0996e-09, 5.2682e-06, 5.9764e-06, 1.5695e-05, 5.5567e-01,
        4.3213e-02, 4.0087e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,387][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.5824, 0.0879, 0.0768, 0.0398, 0.0766, 0.0459, 0.0609, 0.0295],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,388][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([2.9370e-05, 3.7735e-02, 3.3861e-01, 7.2541e-02, 2.0749e-01, 2.9401e-01,
        2.6241e-02, 2.3336e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,389][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([1.7974e-02, 3.1165e-06, 5.9391e-04, 4.1201e-04, 3.3557e-04, 4.2482e-01,
        9.3350e-02, 4.6251e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,390][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([4.9370e-03, 5.1219e-07, 2.0999e-04, 6.5696e-05, 9.4463e-05, 4.8711e-01,
        5.3719e-02, 4.5386e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,391][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([9.3276e-01, 9.5983e-04, 3.0001e-03, 5.4473e-04, 8.6986e-04, 1.9742e-02,
        1.8796e-02, 2.3323e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,391][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([9.6151e-01, 5.6721e-03, 2.0673e-03, 1.0408e-03, 9.3783e-04, 6.0913e-03,
        1.4762e-02, 7.9222e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,393][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.6033, 0.0288, 0.0130, 0.0209, 0.0510, 0.0450, 0.1882, 0.0498],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,394][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([1.0427e-03, 2.1297e-07, 1.6388e-04, 3.9694e-05, 1.2884e-04, 5.0199e-01,
        1.1717e-01, 3.7946e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,395][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([1.2176e-03, 5.2962e-07, 3.1768e-04, 1.4942e-04, 1.4533e-04, 5.5778e-01,
        6.8080e-02, 3.7231e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,396][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([4.1404e-04, 8.8604e-02, 2.3149e-01, 6.9238e-02, 1.3804e-01, 4.1739e-01,
        3.6681e-02, 1.8140e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,398][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.6684, 0.0188, 0.0133, 0.0615, 0.1078, 0.0490, 0.0589, 0.0223],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,399][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([5.5314e-04, 4.1567e-10, 3.2559e-07, 7.7369e-07, 1.3730e-06, 3.6485e-02,
        8.2338e-03, 7.5279e-02, 8.7945e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,401][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.6950, 0.0575, 0.0367, 0.0389, 0.0804, 0.0234, 0.0181, 0.0202, 0.0298],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,402][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([1.0981e-04, 5.7916e-02, 3.4224e-01, 6.7415e-02, 1.8494e-01, 1.9127e-01,
        2.3709e-02, 6.7382e-02, 6.5018e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,403][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([3.3960e-02, 1.5253e-06, 1.4000e-04, 8.5028e-05, 5.6382e-05, 7.6675e-02,
        2.4988e-02, 1.3807e-01, 7.2602e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,405][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([7.3821e-03, 2.2227e-07, 4.4295e-05, 1.2806e-05, 2.0959e-05, 8.5878e-02,
        1.6748e-02, 1.5261e-01, 7.3730e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,406][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([9.9086e-01, 1.4488e-04, 1.8655e-04, 7.0513e-05, 8.0040e-05, 1.6332e-03,
        2.2665e-03, 2.6048e-03, 2.1545e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,407][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([9.7145e-01, 3.5826e-03, 1.2171e-03, 5.7052e-04, 5.7459e-04, 2.9622e-03,
        7.3460e-03, 4.0954e-03, 8.1969e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,408][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.7873, 0.0181, 0.0051, 0.0078, 0.0201, 0.0158, 0.0777, 0.0340, 0.0342],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,409][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([5.6918e-03, 1.1564e-07, 2.2789e-05, 1.2880e-05, 2.7383e-05, 5.1969e-02,
        2.7892e-02, 9.2474e-02, 8.2191e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,409][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([1.5205e-03, 1.5078e-07, 3.1368e-05, 1.8734e-05, 1.7635e-05, 5.7198e-02,
        1.4087e-02, 9.3250e-02, 8.3388e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,410][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0004, 0.0519, 0.1198, 0.0488, 0.1153, 0.3563, 0.0314, 0.0999, 0.1762],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,412][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.8845, 0.0112, 0.0057, 0.0144, 0.0232, 0.0122, 0.0187, 0.0128, 0.0175],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,413][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([3.3471e-04, 8.2398e-10, 5.0069e-07, 7.6779e-07, 1.7548e-06, 1.5735e-02,
        4.2819e-03, 2.1477e-02, 2.9820e-01, 6.5997e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,415][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([0.8750, 0.0311, 0.0046, 0.0160, 0.0205, 0.0065, 0.0162, 0.0032, 0.0054,
        0.0216], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,416][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([1.3507e-06, 4.3837e-03, 1.4939e-01, 3.7768e-02, 1.2590e-01, 4.5064e-01,
        1.9466e-02, 3.8195e-02, 9.1039e-02, 8.3210e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,417][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([6.3923e-02, 3.0327e-06, 9.7301e-05, 1.8420e-04, 1.0363e-04, 4.2564e-02,
        2.3945e-02, 6.8874e-02, 3.4814e-01, 4.5217e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,418][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([5.1761e-03, 3.0079e-07, 3.4574e-05, 1.3702e-05, 1.7124e-05, 5.3273e-02,
        9.8834e-03, 6.4315e-02, 4.5954e-01, 4.0774e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,419][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([9.8338e-01, 1.8826e-04, 1.7371e-04, 3.7850e-05, 8.6344e-05, 7.5211e-04,
        2.2967e-03, 3.7008e-03, 1.6630e-03, 7.7250e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,421][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([9.6611e-01, 4.8618e-03, 9.6836e-04, 5.9920e-04, 4.1985e-04, 1.9051e-03,
        1.0077e-02, 4.6134e-03, 5.5080e-03, 4.9387e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,422][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([0.4669, 0.0356, 0.0068, 0.0212, 0.0341, 0.0372, 0.1367, 0.0800, 0.0808,
        0.1008], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,424][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([1.2376e-02, 1.7617e-07, 1.6024e-05, 1.1776e-05, 2.9975e-05, 2.3780e-02,
        3.0315e-02, 5.2954e-02, 3.8484e-01, 4.9567e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,425][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([2.6993e-03, 1.9977e-07, 2.8678e-05, 2.1779e-05, 1.6479e-05, 2.5984e-02,
        1.2879e-02, 2.6470e-02, 3.4303e-01, 5.8887e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,426][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([3.9538e-05, 1.8854e-02, 1.0642e-01, 3.3708e-02, 1.1434e-01, 3.8431e-01,
        1.9036e-02, 5.1330e-02, 2.3509e-01, 3.6873e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,428][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([0.4753, 0.0119, 0.0098, 0.0327, 0.0538, 0.0703, 0.0778, 0.0657, 0.1132,
        0.0896], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,429][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([5.6132e-04, 6.1495e-11, 1.3739e-08, 3.7590e-08, 7.4535e-08, 8.8169e-04,
        7.0024e-04, 2.3452e-03, 2.9676e-02, 1.4802e-01, 8.1781e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,431][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.7510, 0.0435, 0.0270, 0.0227, 0.0653, 0.0136, 0.0093, 0.0099, 0.0143,
        0.0232, 0.0202], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,432][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([2.2377e-05, 1.8895e-02, 2.9497e-01, 4.4309e-02, 1.2888e-01, 2.5358e-01,
        1.9525e-02, 3.5777e-02, 5.3773e-02, 8.5342e-02, 6.4930e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,433][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([1.6679e-02, 4.4405e-07, 1.6384e-05, 1.5025e-05, 8.2308e-06, 8.1795e-03,
        4.9667e-03, 1.4324e-02, 8.7763e-02, 8.5271e-02, 7.8278e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,434][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([2.2511e-03, 4.3121e-08, 3.4589e-06, 1.4386e-06, 2.4957e-06, 5.4244e-03,
        1.5693e-03, 1.1361e-02, 6.1870e-02, 9.7697e-02, 8.1982e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,435][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([9.8065e-01, 7.2909e-05, 7.4829e-05, 2.7095e-05, 5.3266e-05, 7.3056e-04,
        2.2248e-03, 2.6829e-03, 1.8020e-03, 8.3215e-03, 3.3561e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,436][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([9.7170e-01, 3.1530e-03, 7.2932e-04, 3.6802e-04, 3.3395e-04, 1.4253e-03,
        6.5230e-03, 2.3897e-03, 4.3417e-03, 4.3943e-03, 4.6438e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,437][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.7041, 0.0103, 0.0051, 0.0065, 0.0122, 0.0082, 0.1060, 0.0297, 0.0380,
        0.0502, 0.0297], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,438][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([2.8599e-03, 3.1619e-08, 1.2615e-06, 1.0932e-06, 1.8646e-06, 1.8710e-03,
        4.5249e-03, 7.2879e-03, 4.8176e-02, 1.5159e-01, 7.8368e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,439][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.2223e-03, 5.8653e-08, 2.0630e-06, 3.9071e-06, 1.9198e-06, 3.3203e-03,
        2.3604e-03, 6.4928e-03, 7.1394e-02, 1.4493e-01, 7.7027e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,440][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.1311e-04, 2.0485e-02, 1.0537e-01, 4.8678e-02, 7.8333e-02, 2.8220e-01,
        1.1690e-02, 5.9729e-02, 1.3136e-01, 9.5823e-02, 1.6623e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,442][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.8071, 0.0108, 0.0043, 0.0160, 0.0210, 0.0150, 0.0306, 0.0111, 0.0231,
        0.0394, 0.0216], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,443][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([2.6160e-03, 1.1505e-09, 1.3518e-07, 5.6008e-07, 8.6333e-07, 1.5942e-03,
        1.5974e-03, 2.9812e-03, 2.4989e-02, 1.3664e-01, 4.0636e-01, 4.2323e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,445][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.5197, 0.0566, 0.0361, 0.0318, 0.0524, 0.0198, 0.0108, 0.0144, 0.0178,
        0.0252, 0.0492, 0.1663], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,446][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([5.0429e-06, 9.0448e-03, 2.4293e-01, 2.5419e-02, 6.5969e-02, 2.8182e-01,
        9.6440e-03, 4.2752e-02, 7.3209e-02, 8.0812e-02, 1.1125e-01, 5.7140e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,447][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([2.7172e-02, 1.9873e-06, 3.4810e-05, 4.0841e-05, 2.6744e-05, 5.7996e-03,
        5.2238e-03, 1.1016e-02, 4.9718e-02, 6.7127e-02, 3.0796e-01, 5.2588e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,449][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([9.0030e-03, 6.0199e-07, 1.4291e-05, 9.0556e-06, 6.8162e-06, 7.4597e-03,
        2.7597e-03, 1.0238e-02, 7.2067e-02, 7.5573e-02, 3.6222e-01, 4.6065e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,450][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([9.7029e-01, 1.6382e-04, 1.0358e-04, 4.6478e-05, 1.1731e-04, 6.1603e-04,
        1.9898e-03, 2.7688e-03, 1.3878e-03, 4.7874e-03, 2.6777e-03, 1.5055e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,451][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([9.3966e-01, 3.9077e-03, 1.4213e-03, 7.7754e-04, 1.0184e-03, 3.0412e-03,
        1.2161e-02, 6.0609e-03, 7.0555e-03, 6.9547e-03, 8.1001e-03, 9.8439e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,453][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.4139, 0.0179, 0.0058, 0.0122, 0.0331, 0.0118, 0.1600, 0.0438, 0.0547,
        0.0740, 0.0357, 0.1371], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,454][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([6.7969e-03, 1.7483e-07, 4.3147e-06, 4.1062e-06, 4.2767e-06, 1.4030e-03,
        4.4175e-03, 2.8149e-03, 2.2108e-02, 7.3917e-02, 2.1581e-01, 6.7272e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,455][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([4.3704e-03, 2.4671e-07, 1.1104e-05, 1.5811e-05, 1.5664e-05, 4.8356e-03,
        4.6318e-03, 1.0042e-02, 7.2152e-02, 1.6831e-01, 4.0641e-01, 3.2921e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,457][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([6.9623e-05, 1.1555e-02, 1.9436e-01, 4.5007e-02, 9.3159e-02, 2.1231e-01,
        1.2399e-02, 3.1630e-02, 9.0897e-02, 4.5195e-02, 1.5946e-01, 1.0397e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,458][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.5285, 0.0055, 0.0080, 0.0241, 0.0559, 0.0422, 0.0436, 0.0342, 0.0373,
        0.1312, 0.0403, 0.0494], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,460][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([4.1740e-05, 1.6410e-10, 9.0033e-08, 1.9234e-07, 3.0329e-07, 1.5630e-03,
        4.3717e-04, 2.3879e-03, 2.6106e-02, 6.1350e-02, 4.8852e-01, 3.8448e-01,
        3.5115e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,461][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.2106, 0.0354, 0.0534, 0.0601, 0.1051, 0.0751, 0.0213, 0.0318, 0.0323,
        0.0446, 0.0604, 0.2251, 0.0448], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,463][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([6.0186e-06, 1.0084e-02, 1.5725e-01, 3.5481e-02, 1.5332e-01, 2.7334e-01,
        2.5684e-02, 4.9970e-02, 6.3671e-02, 5.0709e-02, 1.0628e-01, 2.1482e-02,
        5.2730e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,464][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([1.9690e-03, 4.6070e-07, 3.3606e-05, 3.2005e-05, 1.9709e-05, 8.3311e-03,
        2.8150e-03, 1.0496e-02, 3.9543e-02, 5.9209e-02, 3.1163e-01, 5.3585e-01,
        3.0079e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,465][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([6.0987e-04, 1.0951e-07, 1.5650e-05, 6.1490e-06, 6.7188e-06, 1.1905e-02,
        2.1985e-03, 1.4296e-02, 7.7470e-02, 8.3801e-02, 5.2353e-01, 2.5785e-01,
        2.8312e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,466][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([9.0283e-01, 1.9011e-04, 3.8397e-04, 2.6028e-04, 3.4456e-04, 3.3906e-03,
        4.2495e-03, 5.2419e-03, 4.0272e-03, 1.1668e-02, 8.5949e-03, 4.9046e-02,
        9.7723e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,466][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.8989, 0.0049, 0.0019, 0.0015, 0.0015, 0.0058, 0.0175, 0.0073, 0.0122,
        0.0098, 0.0134, 0.0167, 0.0087], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,467][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.2480, 0.0237, 0.0155, 0.0113, 0.0340, 0.0396, 0.1202, 0.0618, 0.0704,
        0.0783, 0.0744, 0.1808, 0.0420], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,469][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([1.5692e-04, 1.9616e-08, 4.3248e-06, 1.9016e-06, 3.5641e-06, 5.1178e-03,
        1.6763e-03, 5.2200e-03, 4.6019e-02, 4.0097e-02, 3.3438e-01, 5.3959e-01,
        2.7732e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,470][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([1.1621e-04, 7.5595e-08, 7.2132e-06, 7.2144e-06, 2.9486e-06, 6.1005e-03,
        1.6625e-03, 4.6363e-03, 5.5706e-02, 1.1621e-01, 3.0746e-01, 4.7944e-01,
        2.8657e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,471][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([1.4085e-04, 1.0672e-02, 7.1883e-02, 5.6307e-02, 1.5968e-01, 2.6845e-01,
        2.3503e-02, 6.7526e-02, 1.1604e-01, 3.1688e-02, 1.2842e-01, 5.3457e-02,
        1.2231e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,473][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.5874, 0.0149, 0.0106, 0.0199, 0.0386, 0.0294, 0.0452, 0.0247, 0.0417,
        0.0893, 0.0438, 0.0349, 0.0197], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,474][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([4.9739e-04, 5.7505e-11, 3.5014e-09, 1.5486e-08, 2.1724e-08, 1.4308e-04,
        1.5327e-04, 2.9835e-04, 4.1272e-03, 2.2752e-02, 1.0563e-01, 2.1846e-01,
        1.7574e-02, 6.3036e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,476][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.6410, 0.0257, 0.0229, 0.0333, 0.0805, 0.0184, 0.0078, 0.0089, 0.0098,
        0.0132, 0.0130, 0.0755, 0.0160, 0.0342], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,477][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.2664e-05, 1.5430e-02, 1.2219e-01, 4.1164e-02, 1.3928e-01, 2.9710e-01,
        1.9981e-02, 2.7036e-02, 5.4495e-02, 5.8889e-02, 8.7551e-02, 3.8515e-02,
        6.0605e-02, 3.7755e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,478][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.7371e-02, 3.6503e-07, 9.0508e-06, 1.1873e-05, 5.1181e-06, 2.7186e-03,
        2.5645e-03, 4.4435e-03, 2.3369e-02, 2.2454e-02, 1.9485e-01, 3.5560e-01,
        3.0432e-02, 3.3617e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,479][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([8.9603e-03, 9.0514e-08, 1.9964e-06, 1.1770e-06, 9.3011e-07, 2.0410e-03,
        1.1670e-03, 3.3974e-03, 2.5505e-02, 3.2628e-02, 2.1264e-01, 2.3108e-01,
        1.3890e-02, 4.6869e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,481][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.8726e-01, 3.0807e-05, 2.3322e-05, 1.7557e-05, 1.5850e-05, 2.0443e-04,
        7.1417e-04, 4.4528e-04, 2.9079e-04, 1.8593e-03, 5.5616e-04, 5.0891e-03,
        1.2436e-03, 2.2519e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,482][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.6623e-01, 2.0152e-03, 4.6288e-04, 2.9385e-04, 2.9321e-04, 1.1698e-03,
        4.8611e-03, 1.8474e-03, 3.2258e-03, 2.5972e-03, 3.3217e-03, 5.9246e-03,
        4.5353e-03, 3.2239e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,484][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.6092, 0.0119, 0.0053, 0.0045, 0.0091, 0.0123, 0.0671, 0.0294, 0.0501,
        0.0354, 0.0357, 0.0647, 0.0387, 0.0266], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,485][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.1911e-03, 1.5882e-08, 3.3940e-07, 2.5770e-07, 4.9329e-07, 4.6695e-04,
        1.4067e-03, 1.0427e-03, 1.2559e-02, 3.3881e-02, 1.5304e-01, 5.0964e-01,
        2.0271e-02, 2.6550e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,486][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.1723e-03, 6.4750e-08, 1.0574e-06, 2.1734e-06, 7.9123e-07, 1.1299e-03,
        1.1260e-03, 1.8433e-03, 2.2308e-02, 3.4666e-02, 1.8082e-01, 4.3222e-01,
        3.2029e-02, 2.9268e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,487][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([8.4103e-05, 1.4373e-02, 6.8033e-02, 2.8141e-02, 8.1285e-02, 2.7735e-01,
        1.8718e-02, 3.5990e-02, 1.2384e-01, 4.6664e-02, 1.5744e-01, 9.3180e-02,
        1.2664e-02, 4.2244e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,489][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.8522, 0.0079, 0.0031, 0.0078, 0.0088, 0.0110, 0.0148, 0.0073, 0.0144,
        0.0206, 0.0158, 0.0158, 0.0081, 0.0123], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,490][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([3.3751e-05, 7.0180e-11, 1.5745e-08, 4.0784e-08, 5.0343e-08, 2.8051e-04,
        1.9883e-04, 7.6301e-04, 6.9564e-03, 2.9259e-02, 1.1613e-01, 1.3441e-01,
        1.8815e-02, 6.3971e-01, 5.3450e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,491][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.1776, 0.0822, 0.0255, 0.0354, 0.0534, 0.0146, 0.0387, 0.0308, 0.0501,
        0.0470, 0.0549, 0.1927, 0.0254, 0.0713, 0.1005], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,492][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([1.4589e-06, 1.2829e-02, 9.7586e-02, 3.1612e-02, 6.6530e-02, 2.1520e-01,
        1.6309e-02, 5.6305e-02, 6.4871e-02, 1.7234e-01, 8.7720e-02, 7.2874e-02,
        3.7339e-02, 4.4836e-02, 2.3650e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,493][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([2.9239e-03, 4.7897e-07, 1.4732e-05, 1.9810e-05, 8.8479e-06, 4.9452e-03,
        1.8382e-03, 5.9917e-03, 2.7581e-02, 4.0835e-02, 1.8471e-01, 3.8061e-01,
        1.3900e-02, 2.6123e-01, 7.5390e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,494][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([8.3691e-04, 5.9977e-08, 4.5606e-06, 1.5070e-06, 1.9603e-06, 3.2581e-03,
        1.0086e-03, 5.8338e-03, 3.2862e-02, 4.2972e-02, 2.2551e-01, 1.8347e-01,
        1.3735e-02, 4.1987e-01, 7.0643e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,495][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([8.5288e-01, 2.8273e-04, 2.5252e-04, 1.8762e-04, 1.3577e-04, 2.4173e-03,
        5.3656e-03, 4.5762e-03, 3.5496e-03, 2.4446e-02, 5.5951e-03, 5.2892e-02,
        5.5203e-03, 2.0849e-02, 2.1048e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,497][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.8341, 0.0077, 0.0025, 0.0016, 0.0012, 0.0046, 0.0184, 0.0079, 0.0156,
        0.0136, 0.0160, 0.0270, 0.0148, 0.0125, 0.0225], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,499][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.4186, 0.0163, 0.0060, 0.0080, 0.0142, 0.0204, 0.0547, 0.0416, 0.0483,
        0.0675, 0.0517, 0.0856, 0.0418, 0.0297, 0.0954], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,500][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([2.0063e-04, 1.9680e-08, 1.1771e-06, 1.3607e-06, 1.2314e-06, 1.2313e-03,
        1.0924e-03, 2.2159e-03, 1.7191e-02, 3.6603e-02, 1.2633e-01, 3.7255e-01,
        2.1524e-02, 2.7377e-01, 1.4729e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,501][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([2.0648e-04, 4.4891e-08, 2.7844e-06, 3.6959e-06, 2.4106e-06, 2.7420e-03,
        1.1159e-03, 2.8892e-03, 3.1849e-02, 4.1222e-02, 1.9886e-01, 2.1254e-01,
        2.9174e-02, 3.8585e-01, 9.3545e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,502][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([8.9871e-06, 7.5410e-03, 5.2917e-02, 1.2523e-02, 1.6683e-02, 1.5749e-01,
        1.1590e-02, 1.0760e-01, 1.9831e-01, 5.9420e-02, 1.7532e-01, 1.1456e-01,
        8.3816e-03, 5.9821e-02, 1.7835e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,504][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.5688, 0.0125, 0.0068, 0.0265, 0.0382, 0.0335, 0.0241, 0.0274, 0.0382,
        0.0750, 0.0347, 0.0314, 0.0147, 0.0358, 0.0326], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,505][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([8.1832e-05, 4.0788e-11, 3.4065e-09, 9.9189e-09, 2.2440e-08, 1.0807e-04,
        7.6579e-05, 2.9631e-04, 3.2868e-03, 1.7586e-02, 8.3128e-02, 1.1462e-01,
        1.0638e-02, 5.4918e-01, 6.8489e-02, 1.5252e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,507][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.2472, 0.0215, 0.0191, 0.0192, 0.0400, 0.0181, 0.0330, 0.0257, 0.0429,
        0.0274, 0.0411, 0.1732, 0.0315, 0.0794, 0.1315, 0.0493],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,508][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([3.6582e-06, 4.2735e-03, 1.1230e-01, 3.5288e-02, 1.4349e-01, 1.7887e-01,
        1.4411e-02, 7.5784e-02, 6.0491e-02, 7.6025e-02, 8.5254e-02, 2.1444e-02,
        3.9713e-02, 6.1179e-02, 3.5169e-02, 5.6312e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,510][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([6.5018e-03, 1.9724e-07, 5.3564e-06, 5.8540e-06, 3.6928e-06, 2.0070e-03,
        1.3232e-03, 4.0443e-03, 1.6668e-02, 2.5013e-02, 1.3082e-01, 2.8362e-01,
        1.2290e-02, 2.4875e-01, 7.8632e-02, 1.9032e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,511][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([9.4467e-04, 2.8701e-08, 1.2093e-06, 5.8840e-07, 9.7394e-07, 1.8533e-03,
        4.0551e-04, 2.4740e-03, 1.3681e-02, 2.6522e-02, 1.5173e-01, 1.3708e-01,
        1.1288e-02, 4.4954e-01, 5.8120e-02, 1.4635e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,512][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([9.4410e-01, 8.2511e-05, 6.7784e-05, 5.3421e-05, 3.8471e-05, 8.2759e-04,
        9.5958e-04, 9.4054e-04, 9.3933e-04, 6.0343e-03, 1.8390e-03, 1.3595e-02,
        2.9510e-03, 8.9255e-03, 1.0216e-02, 8.4276e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,514][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([8.9950e-01, 3.2616e-03, 1.0763e-03, 7.7424e-04, 6.1772e-04, 2.8616e-03,
        9.2303e-03, 4.0478e-03, 7.9443e-03, 7.3819e-03, 8.3963e-03, 1.6908e-02,
        7.9955e-03, 7.6614e-03, 1.1448e-02, 1.0898e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,515][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.4682, 0.0132, 0.0038, 0.0067, 0.0116, 0.0159, 0.0522, 0.0288, 0.0310,
        0.0466, 0.0372, 0.0750, 0.0370, 0.0291, 0.0885, 0.0552],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,517][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([1.5484e-04, 2.9656e-09, 2.4482e-07, 1.6913e-07, 3.8953e-07, 4.6646e-04,
        7.3897e-04, 1.0485e-03, 1.6097e-02, 1.2767e-02, 1.2041e-01, 1.4956e-01,
        1.2048e-02, 2.9142e-01, 2.1408e-01, 1.8121e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,518][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([2.7285e-04, 2.1202e-08, 8.6253e-07, 1.0866e-06, 8.2027e-07, 1.1969e-03,
        6.3570e-04, 1.5439e-03, 1.8951e-02, 3.7667e-02, 1.7999e-01, 1.7799e-01,
        2.4199e-02, 3.4738e-01, 6.3728e-02, 1.4644e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,519][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([4.6512e-05, 1.0217e-02, 6.5819e-02, 3.2288e-02, 5.1865e-02, 2.1899e-01,
        1.4292e-02, 6.2662e-02, 1.1586e-01, 6.6519e-02, 1.2085e-01, 9.8645e-02,
        8.6443e-03, 4.1665e-02, 5.1991e-02, 3.9641e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,519][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.6188, 0.0130, 0.0068, 0.0191, 0.0292, 0.0190, 0.0304, 0.0273, 0.0359,
        0.0379, 0.0340, 0.0205, 0.0108, 0.0348, 0.0318, 0.0307],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,520][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([3.7982e-04, 3.2588e-11, 8.4282e-10, 3.9353e-09, 5.9183e-09, 3.1098e-05,
        3.8955e-05, 5.8218e-05, 8.9143e-04, 4.2999e-03, 1.9097e-02, 4.0741e-02,
        4.1405e-03, 1.3269e-01, 1.9911e-02, 9.7039e-02, 6.8068e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,522][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.5711, 0.0192, 0.0284, 0.0252, 0.0527, 0.0195, 0.0095, 0.0097, 0.0126,
        0.0134, 0.0161, 0.0631, 0.0175, 0.0338, 0.0477, 0.0196, 0.0407],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,523][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([6.2759e-06, 1.3754e-02, 7.8402e-02, 3.1478e-02, 1.1007e-01, 2.4790e-01,
        1.1976e-02, 2.2280e-02, 4.8946e-02, 5.9288e-02, 8.8990e-02, 5.6304e-02,
        6.5611e-02, 3.5238e-02, 2.1095e-02, 5.7425e-02, 5.1240e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,525][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.8284e-02, 2.5504e-07, 3.9855e-06, 5.2255e-06, 2.4659e-06, 1.2322e-03,
        1.1628e-03, 2.0810e-03, 1.0918e-02, 1.1286e-02, 8.3603e-02, 1.3309e-01,
        1.6254e-02, 1.4814e-01, 5.0972e-02, 1.4907e-01, 3.7389e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,526][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([4.3529e-03, 4.8431e-08, 7.0964e-07, 4.9398e-07, 4.2901e-07, 6.6250e-04,
        5.0085e-04, 1.2239e-03, 8.2394e-03, 1.4851e-02, 7.2223e-02, 1.0068e-01,
        5.3186e-03, 1.6710e-01, 3.6522e-02, 1.0495e-01, 4.8338e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,527][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.8518e-01, 2.4325e-05, 1.3237e-05, 1.5331e-05, 1.0330e-05, 1.5489e-04,
        4.2647e-04, 3.0213e-04, 1.7813e-04, 1.4559e-03, 2.9569e-04, 3.2382e-03,
        7.9989e-04, 1.3452e-03, 1.9978e-03, 1.5555e-03, 3.0049e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,528][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.5593e-01, 2.2024e-03, 4.2175e-04, 2.7404e-04, 2.8364e-04, 1.1254e-03,
        3.7516e-03, 1.7389e-03, 2.9225e-03, 2.1892e-03, 2.9092e-03, 4.9687e-03,
        4.5232e-03, 3.0810e-03, 4.9502e-03, 5.8480e-03, 2.8777e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,530][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.3672, 0.0117, 0.0052, 0.0063, 0.0165, 0.0198, 0.0505, 0.0352, 0.0584,
        0.0421, 0.0372, 0.0760, 0.0412, 0.0331, 0.0631, 0.1085, 0.0281],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,531][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.5807e-03, 1.0386e-08, 1.5468e-07, 1.5167e-07, 2.7549e-07, 2.2783e-04,
        5.1797e-04, 3.5061e-04, 4.1457e-03, 1.2904e-02, 5.2888e-02, 1.9825e-01,
        6.0938e-03, 1.0488e-01, 9.5790e-02, 9.7548e-02, 4.2483e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,533][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.3986e-04, 5.6401e-08, 5.7799e-07, 1.2051e-06, 4.6844e-07, 6.0331e-04,
        5.2213e-04, 8.1440e-04, 1.0553e-02, 1.5930e-02, 7.5790e-02, 1.8026e-01,
        1.8325e-02, 1.6298e-01, 4.4335e-02, 1.2026e-01, 3.6868e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,534][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.4283e-05, 1.0009e-02, 4.9067e-02, 1.8892e-02, 5.9488e-02, 1.8573e-01,
        1.0583e-02, 3.3957e-02, 1.0795e-01, 3.8024e-02, 1.3656e-01, 9.3449e-02,
        9.7833e-03, 3.6018e-02, 3.1077e-02, 5.9930e-02, 1.1945e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,536][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.7659, 0.0073, 0.0034, 0.0087, 0.0106, 0.0133, 0.0147, 0.0104, 0.0175,
        0.0341, 0.0167, 0.0197, 0.0088, 0.0154, 0.0122, 0.0267, 0.0145],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,539][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:29,541][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[5616],
        [ 535],
        [ 235],
        [1567],
        [1564],
        [ 589],
        [1427],
        [ 207],
        [ 641],
        [ 485],
        [1473],
        [1003],
        [ 462],
        [ 566],
        [1597],
        [ 973],
        [1413]], device='cuda:0')
[2024-07-24 10:31:29,543][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[5580],
        [ 442],
        [ 236],
        [1581],
        [1230],
        [ 338],
        [ 683],
        [ 158],
        [ 337],
        [ 233],
        [ 788],
        [ 686],
        [ 201],
        [ 307],
        [ 770],
        [ 382],
        [ 817]], device='cuda:0')
[2024-07-24 10:31:29,545][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[34587],
        [11042],
        [ 8927],
        [10327],
        [10785],
        [ 9964],
        [10215],
        [ 9914],
        [ 9538],
        [ 9836],
        [ 9526],
        [ 9349],
        [ 9319],
        [ 9156],
        [ 9177],
        [ 9107],
        [ 9003]], device='cuda:0')
[2024-07-24 10:31:29,546][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[31131],
        [31118],
        [31124],
        [31129],
        [31130],
        [31126],
        [31133],
        [31133],
        [31133],
        [31131],
        [31133],
        [31132],
        [31132],
        [31133],
        [31132],
        [31133],
        [31131]], device='cuda:0')
[2024-07-24 10:31:29,548][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[31775],
        [17486],
        [20366],
        [47738],
        [46274],
        [43987],
        [39119],
        [38220],
        [34322],
        [33318],
        [31577],
        [31555],
        [30864],
        [30130],
        [29655],
        [27664],
        [27348]], device='cuda:0')
[2024-07-24 10:31:29,549][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[  540],
        [31186],
        [20597],
        [15253],
        [17646],
        [19464],
        [21886],
        [23818],
        [33176],
        [34955],
        [33715],
        [34818],
        [34905],
        [35794],
        [37506],
        [41509],
        [40210]], device='cuda:0')
[2024-07-24 10:31:29,551][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 4495],
        [12361],
        [18183],
        [27570],
        [30780],
        [29603],
        [38544],
        [36311],
        [34707],
        [36061],
        [33652],
        [35326],
        [35261],
        [34017],
        [34429],
        [34332],
        [34124]], device='cuda:0')
[2024-07-24 10:31:29,553][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[33839],
        [18437],
        [20724],
        [15600],
        [17564],
        [25854],
        [20194],
        [16876],
        [25443],
        [20630],
        [24594],
        [19658],
        [16088],
        [25985],
        [15526],
        [18605],
        [24467]], device='cuda:0')
[2024-07-24 10:31:29,555][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 1801],
        [13088],
        [17580],
        [19004],
        [19704],
        [20145],
        [22026],
        [21972],
        [22364],
        [21564],
        [21318],
        [22029],
        [22684],
        [22005],
        [21954],
        [21932],
        [21683]], device='cuda:0')
[2024-07-24 10:31:29,556][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[21372],
        [20412],
        [19683],
        [19601],
        [19053],
        [18299],
        [18383],
        [18540],
        [18005],
        [17902],
        [17426],
        [17542],
        [17175],
        [16854],
        [16710],
        [16338],
        [16114]], device='cuda:0')
[2024-07-24 10:31:29,558][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[23401],
        [33813],
        [41136],
        [43723],
        [43619],
        [43077],
        [42857],
        [43547],
        [43482],
        [43696],
        [43493],
        [43349],
        [43333],
        [43233],
        [43131],
        [43445],
        [43387]], device='cuda:0')
[2024-07-24 10:31:29,560][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[29776],
        [14549],
        [14178],
        [14911],
        [15203],
        [14196],
        [14381],
        [13843],
        [14053],
        [14005],
        [13924],
        [14235],
        [14280],
        [14146],
        [14123],
        [14077],
        [14175]], device='cuda:0')
[2024-07-24 10:31:29,562][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[13139],
        [22081],
        [15064],
        [27263],
        [22560],
        [21669],
        [19065],
        [18387],
        [17456],
        [15608],
        [15128],
        [14352],
        [14578],
        [14524],
        [13406],
        [13128],
        [13009]], device='cuda:0')
[2024-07-24 10:31:29,563][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[13509],
        [30243],
        [24147],
        [29970],
        [27703],
        [26960],
        [26014],
        [25202],
        [24800],
        [25131],
        [24821],
        [25672],
        [25526],
        [25194],
        [25267],
        [24982],
        [24577]], device='cuda:0')
[2024-07-24 10:31:29,565][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[21518],
        [ 7523],
        [ 4968],
        [ 3376],
        [ 5744],
        [ 8626],
        [13061],
        [ 6383],
        [ 9505],
        [ 9395],
        [10167],
        [ 8668],
        [15406],
        [11721],
        [17683],
        [17892],
        [11459]], device='cuda:0')
[2024-07-24 10:31:29,567][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 9323],
        [36148],
        [ 9309],
        [ 9276],
        [ 7661],
        [ 6820],
        [ 7899],
        [11662],
        [16438],
        [14543],
        [ 8901],
        [11335],
        [10818],
        [13154],
        [12717],
        [12074],
        [14780]], device='cuda:0')
[2024-07-24 10:31:29,569][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[13710],
        [30859],
        [13098],
        [10171],
        [14375],
        [10594],
        [12893],
        [ 8823],
        [11943],
        [11871],
        [11867],
        [11381],
        [ 7492],
        [ 9658],
        [ 7317],
        [ 8058],
        [ 7513]], device='cuda:0')
[2024-07-24 10:31:29,571][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 7560],
        [29137],
        [ 1570],
        [ 1182],
        [  325],
        [  150],
        [  358],
        [  333],
        [  449],
        [ 1387],
        [  779],
        [ 1955],
        [ 1163],
        [ 1407],
        [ 2516],
        [ 1118],
        [ 1871]], device='cuda:0')
[2024-07-24 10:31:29,573][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 7563],
        [12127],
        [30362],
        [32292],
        [30315],
        [34379],
        [40420],
        [31406],
        [20678],
        [29236],
        [21098],
        [26840],
        [26977],
        [28312],
        [28134],
        [26030],
        [26237]], device='cuda:0')
[2024-07-24 10:31:29,574][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[37547],
        [ 6678],
        [ 5592],
        [ 6250],
        [ 6656],
        [10294],
        [10424],
        [ 8571],
        [ 3620],
        [ 3935],
        [ 2837],
        [ 3603],
        [ 3280],
        [ 1640],
        [ 1615],
        [ 1540],
        [  925]], device='cuda:0')
[2024-07-24 10:31:29,576][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[25350],
        [27967],
        [23251],
        [24206],
        [26529],
        [25678],
        [26898],
        [28250],
        [25798],
        [25409],
        [25266],
        [24816],
        [23990],
        [25163],
        [27162],
        [25234],
        [25168]], device='cuda:0')
[2024-07-24 10:31:29,577][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[33490],
        [29946],
        [32454],
        [32278],
        [31998],
        [33513],
        [33339],
        [33468],
        [33375],
        [33201],
        [33311],
        [31986],
        [29130],
        [33402],
        [23281],
        [28804],
        [32839]], device='cuda:0')
[2024-07-24 10:31:29,579][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[19216],
        [15252],
        [16834],
        [ 4277],
        [ 9354],
        [13405],
        [ 7759],
        [ 8014],
        [ 9864],
        [ 5293],
        [ 7992],
        [ 4813],
        [ 3570],
        [ 4467],
        [ 3157],
        [ 2930],
        [ 2299]], device='cuda:0')
[2024-07-24 10:31:29,581][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[40386],
        [33590],
        [30513],
        [30649],
        [31950],
        [34172],
        [36643],
        [36431],
        [26636],
        [41120],
        [34663],
        [36684],
        [33553],
        [32702],
        [31745],
        [23998],
        [27003]], device='cuda:0')
[2024-07-24 10:31:29,583][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[37522],
        [ 2400],
        [12100],
        [11442],
        [11428],
        [20563],
        [21369],
        [24532],
        [22992],
        [21475],
        [24214],
        [14259],
        [ 9462],
        [12249],
        [19740],
        [20977],
        [17103]], device='cuda:0')
[2024-07-24 10:31:29,584][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[35229],
        [ 1263],
        [ 1897],
        [ 1934],
        [ 1751],
        [ 2883],
        [ 6239],
        [ 3617],
        [ 3222],
        [ 3565],
        [ 2259],
        [ 1832],
        [ 2451],
        [ 2402],
        [ 1599],
        [ 1738],
        [ 2012]], device='cuda:0')
[2024-07-24 10:31:29,586][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[26346],
        [23596],
        [23940],
        [ 7730],
        [12157],
        [16288],
        [ 7137],
        [10954],
        [17908],
        [ 5089],
        [14268],
        [ 7154],
        [ 8399],
        [16044],
        [ 8007],
        [ 8905],
        [12327]], device='cuda:0')
[2024-07-24 10:31:29,588][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[11896],
        [22323],
        [37948],
        [43721],
        [41804],
        [38909],
        [37098],
        [36787],
        [38580],
        [37746],
        [40589],
        [41589],
        [43436],
        [41699],
        [42155],
        [43653],
        [43092]], device='cuda:0')
[2024-07-24 10:31:29,590][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[22951],
        [39478],
        [44049],
        [46153],
        [44337],
        [40799],
        [39699],
        [43789],
        [42114],
        [45890],
        [42927],
        [45782],
        [47004],
        [44857],
        [46794],
        [47255],
        [47671]], device='cuda:0')
[2024-07-24 10:31:29,591][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[18011],
        [18011],
        [18011],
        [18011],
        [18011],
        [18011],
        [18011],
        [18011],
        [18011],
        [18011],
        [18011],
        [18011],
        [18011],
        [18011],
        [18011],
        [18011],
        [18011]], device='cuda:0')
[2024-07-24 10:31:29,670][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:29,672][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,673][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,674][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,675][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,676][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,677][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,677][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,678][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,679][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,679][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,680][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,681][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:29,681][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.9223, 0.0777], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,682][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.0024, 0.9976], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,683][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.3829, 0.6171], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,684][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.2029, 0.7971], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,684][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.0251, 0.9749], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,686][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.7392, 0.2608], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,687][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.9051, 0.0949], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,689][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.0310, 0.9690], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,691][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.9802, 0.0198], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,692][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.2531, 0.7469], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,694][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.3257, 0.6743], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,695][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.7542, 0.2458], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:29,697][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6170, 0.0777, 0.3054], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,699][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0010, 0.4668, 0.5322], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,700][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1959, 0.4062, 0.3979], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,701][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0915, 0.3006, 0.6079], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,702][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0138, 0.3123, 0.6739], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,703][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.4377, 0.0025, 0.5598], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,703][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.7753, 0.0257, 0.1989], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,704][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0278, 0.0022, 0.9700], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,706][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.9166, 0.0013, 0.0821], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,707][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1239, 0.3796, 0.4964], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,709][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0368, 0.0150, 0.9481], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,710][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([3.5458e-03, 3.0902e-04, 9.9615e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:29,712][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Nathan] are: tensor([0.5403, 0.0556, 0.2200, 0.1841], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,713][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Nathan] are: tensor([0.0008, 0.3124, 0.3494, 0.3374], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,715][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Nathan] are: tensor([0.1245, 0.2403, 0.2285, 0.4067], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,716][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Nathan] are: tensor([0.0850, 0.2003, 0.4426, 0.2721], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,718][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Nathan] are: tensor([0.0109, 0.2058, 0.4459, 0.3374], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,720][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Nathan] are: tensor([0.3051, 0.0021, 0.4930, 0.1998], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,721][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Nathan] are: tensor([0.4127, 0.0374, 0.2252, 0.3247], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,723][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Nathan] are: tensor([0.0200, 0.0009, 0.7231, 0.2560], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,724][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Nathan] are: tensor([9.6800e-01, 9.4575e-04, 2.6510e-02, 4.5416e-03], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,726][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Nathan] are: tensor([0.1026, 0.2589, 0.3370, 0.3015], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,727][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Nathan] are: tensor([0.0883, 0.0275, 0.7998, 0.0845], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,728][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Nathan] are: tensor([4.8221e-03, 1.6410e-04, 9.7120e-01, 2.3809e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:29,729][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.3578, 0.0381, 0.1523, 0.1109, 0.3409], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,730][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.0006, 0.2338, 0.2653, 0.2536, 0.2467], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,730][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.0962, 0.1982, 0.1908, 0.3284, 0.1864], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,732][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.0411, 0.2016, 0.3600, 0.1642, 0.2331], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,733][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.0069, 0.1486, 0.3266, 0.2500, 0.2680], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,735][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.0837, 0.0031, 0.5219, 0.2575, 0.1337], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,737][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.5097, 0.0249, 0.1414, 0.1653, 0.1587], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,738][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ got] are: tensor([4.4556e-03, 4.7406e-04, 5.7004e-01, 2.8506e-01, 1.3997e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,739][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ got] are: tensor([9.5528e-01, 5.3168e-04, 3.4453e-02, 2.9164e-03, 6.8166e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,741][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.0701, 0.2093, 0.2735, 0.2369, 0.2103], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,742][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.0812, 0.0231, 0.6842, 0.0514, 0.1602], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,744][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ got] are: tensor([8.9440e-03, 2.0593e-04, 8.7558e-01, 1.6396e-02, 9.8877e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:29,745][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1702, 0.0208, 0.0790, 0.0673, 0.1914, 0.4713], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,747][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0004, 0.1863, 0.2134, 0.2057, 0.2002, 0.1940], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,749][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0654, 0.1750, 0.1518, 0.2609, 0.1520, 0.1948], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,750][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0790, 0.1451, 0.2129, 0.0980, 0.1427, 0.3224], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,752][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0054, 0.1234, 0.2394, 0.1861, 0.2007, 0.2451], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,754][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1394, 0.0057, 0.3732, 0.1799, 0.1137, 0.1882], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,755][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.7341, 0.0129, 0.0588, 0.0464, 0.0295, 0.1184], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,755][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0020, 0.0009, 0.2439, 0.2497, 0.1322, 0.3713], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,756][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([9.8955e-01, 2.7441e-05, 1.0018e-04, 3.8714e-05, 7.6579e-05, 1.0211e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,757][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0631, 0.1615, 0.2032, 0.1861, 0.1573, 0.2288], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,758][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1197, 0.0057, 0.0608, 0.0059, 0.0182, 0.7898], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,759][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([2.8462e-03, 5.4850e-05, 1.9176e-02, 1.6756e-03, 3.7152e-03, 9.7253e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:29,761][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.2204, 0.0160, 0.0633, 0.0596, 0.1438, 0.4088, 0.0881],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,763][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.0003, 0.1605, 0.1803, 0.1758, 0.1698, 0.1652, 0.1480],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,764][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.0579, 0.1352, 0.1147, 0.2062, 0.1174, 0.1538, 0.2147],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,766][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0305, 0.1011, 0.1590, 0.0838, 0.1240, 0.2767, 0.2249],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,768][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0034, 0.1077, 0.2048, 0.1592, 0.1753, 0.2030, 0.1466],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,769][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.0242, 0.0059, 0.4198, 0.2059, 0.1414, 0.1731, 0.0296],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,771][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.1640, 0.0139, 0.1018, 0.0730, 0.0396, 0.2218, 0.3859],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,772][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([7.0682e-05, 4.6354e-04, 1.8802e-01, 3.7763e-01, 3.0671e-01, 1.1716e-01,
        9.9522e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,773][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([9.9090e-01, 4.2763e-05, 3.4702e-04, 9.6394e-05, 1.5940e-04, 5.7003e-03,
        2.7572e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,775][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0538, 0.1448, 0.1870, 0.1672, 0.1404, 0.1999, 0.1069],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,777][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0571, 0.0081, 0.0946, 0.0140, 0.0348, 0.6158, 0.1756],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,778][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([9.5470e-03, 1.1525e-04, 2.7099e-02, 4.0757e-03, 8.5753e-03, 8.7644e-01,
        7.4147e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:29,780][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.1633, 0.0131, 0.0487, 0.0428, 0.1160, 0.2937, 0.0644, 0.2579],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,780][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0004, 0.1358, 0.1538, 0.1508, 0.1460, 0.1429, 0.1256, 0.1446],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,781][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0404, 0.1145, 0.1087, 0.1835, 0.1052, 0.1319, 0.1829, 0.1328],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,782][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0696, 0.0908, 0.1358, 0.0683, 0.0969, 0.1967, 0.1730, 0.1690],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,783][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0039, 0.0898, 0.1697, 0.1332, 0.1463, 0.1726, 0.1256, 0.1589],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,785][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0320, 0.0084, 0.3693, 0.1975, 0.1211, 0.1647, 0.0448, 0.0622],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,786][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.3682, 0.0090, 0.0643, 0.0472, 0.0253, 0.2045, 0.1835, 0.0980],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,788][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0005, 0.0012, 0.1916, 0.2496, 0.1601, 0.2211, 0.0237, 0.1522],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,789][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ at] are: tensor([9.7807e-01, 2.6521e-05, 2.2524e-04, 5.3212e-05, 1.0183e-04, 1.5769e-02,
        2.7257e-03, 3.0299e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,791][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0446, 0.1269, 0.1587, 0.1433, 0.1211, 0.1713, 0.0941, 0.1399],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,792][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0778, 0.0034, 0.0507, 0.0055, 0.0117, 0.5092, 0.0867, 0.2550],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,793][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ at] are: tensor([4.6560e-03, 1.0043e-04, 1.7280e-02, 1.7729e-03, 2.2204e-03, 6.0174e-01,
        1.9327e-02, 3.5291e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:29,795][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1137, 0.0100, 0.0360, 0.0310, 0.0921, 0.2003, 0.0433, 0.1868, 0.2868],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,797][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0003, 0.1179, 0.1340, 0.1313, 0.1269, 0.1238, 0.1089, 0.1272, 0.1297],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,798][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0433, 0.0992, 0.0938, 0.1630, 0.0946, 0.1176, 0.1653, 0.1190, 0.1042],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,800][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0795, 0.0773, 0.1022, 0.0507, 0.0786, 0.1627, 0.1318, 0.1630, 0.1541],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,802][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0031, 0.0790, 0.1460, 0.1144, 0.1254, 0.1482, 0.1097, 0.1375, 0.1367],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,804][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0373, 0.0101, 0.3149, 0.2011, 0.1175, 0.1529, 0.0501, 0.0680, 0.0482],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,805][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.5049, 0.0092, 0.0457, 0.0364, 0.0182, 0.0982, 0.1332, 0.0594, 0.0949],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,806][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ the] are: tensor([1.9389e-04, 1.0574e-03, 1.3579e-01, 2.3653e-01, 1.5265e-01, 1.6940e-01,
        2.5243e-02, 1.7064e-01, 1.0850e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,807][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ the] are: tensor([9.9720e-01, 7.8373e-06, 1.4794e-05, 1.0384e-05, 1.4464e-05, 1.0858e-03,
        3.8856e-04, 2.5783e-04, 1.0174e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,808][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0470, 0.1108, 0.1378, 0.1226, 0.1050, 0.1476, 0.0792, 0.1211, 0.1290],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,809][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0955, 0.0018, 0.0135, 0.0018, 0.0049, 0.1312, 0.0305, 0.0875, 0.6333],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,810][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ the] are: tensor([5.5822e-03, 3.1730e-05, 2.9034e-03, 7.4479e-04, 1.3199e-03, 1.7999e-01,
        9.9207e-03, 1.4663e-01, 6.5288e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:29,811][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([0.1204, 0.0096, 0.0322, 0.0295, 0.0774, 0.1895, 0.0408, 0.1584, 0.2899,
        0.0523], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,813][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([0.0003, 0.1075, 0.1208, 0.1173, 0.1133, 0.1107, 0.0973, 0.1131, 0.1159,
        0.1039], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,815][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([0.0524, 0.0849, 0.0802, 0.1407, 0.0840, 0.1062, 0.1480, 0.1071, 0.0936,
        0.1031], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,816][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([0.0539, 0.0578, 0.0856, 0.0465, 0.0628, 0.1579, 0.0994, 0.1395, 0.1398,
        0.1568], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,818][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([0.0029, 0.0733, 0.1288, 0.1011, 0.1128, 0.1299, 0.0974, 0.1221, 0.1216,
        0.1100], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,819][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([0.0117, 0.0145, 0.3237, 0.1796, 0.1292, 0.1637, 0.0414, 0.0620, 0.0455,
        0.0288], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,821][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.2405, 0.0059, 0.0430, 0.0381, 0.0243, 0.1091, 0.1319, 0.0714, 0.1470,
        0.1887], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,822][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([1.1278e-04, 9.3200e-04, 2.1635e-01, 1.7166e-01, 1.7476e-01, 1.6205e-01,
        2.0757e-02, 1.1966e-01, 1.0998e-01, 2.3738e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,823][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([9.9247e-01, 1.1761e-05, 4.8222e-05, 3.1429e-05, 5.1423e-05, 2.1629e-03,
        1.2417e-03, 8.3857e-04, 2.2602e-03, 8.8034e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,825][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([0.0429, 0.1056, 0.1247, 0.1069, 0.0921, 0.1354, 0.0711, 0.1092, 0.1177,
        0.0943], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,827][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([0.0424, 0.0019, 0.0187, 0.0025, 0.0077, 0.1440, 0.0337, 0.0939, 0.4282,
        0.2269], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,828][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([9.3890e-03, 4.2094e-05, 2.5793e-03, 6.0244e-04, 1.3503e-03, 1.2562e-01,
        1.2337e-02, 1.2797e-01, 4.9385e-01, 2.2626e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:29,830][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1196, 0.0094, 0.0320, 0.0288, 0.0826, 0.1680, 0.0371, 0.1503, 0.2379,
        0.0370, 0.0974], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,831][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0003, 0.0946, 0.1079, 0.1056, 0.1017, 0.0995, 0.0875, 0.1023, 0.1043,
        0.0942, 0.1022], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,833][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0389, 0.0949, 0.0794, 0.1410, 0.0808, 0.0983, 0.1345, 0.1021, 0.0893,
        0.0910, 0.0498], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,833][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0809, 0.0581, 0.0674, 0.0337, 0.0527, 0.0921, 0.0870, 0.0951, 0.0978,
        0.1049, 0.2302], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,834][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0025, 0.0631, 0.1128, 0.0909, 0.0999, 0.1160, 0.0872, 0.1073, 0.1066,
        0.1005, 0.1130], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,835][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0250, 0.0139, 0.2888, 0.1864, 0.1178, 0.1398, 0.0529, 0.0633, 0.0450,
        0.0412, 0.0259], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,836][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3929, 0.0058, 0.0290, 0.0352, 0.0179, 0.0673, 0.1097, 0.0505, 0.0798,
        0.1255, 0.0866], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,837][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([1.5192e-04, 1.1840e-03, 1.1199e-01, 1.6832e-01, 1.8089e-01, 1.5008e-01,
        5.6905e-02, 1.3924e-01, 1.1421e-01, 5.1524e-02, 2.5500e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,838][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([9.9751e-01, 3.8207e-06, 4.3930e-06, 8.1546e-06, 1.0348e-05, 3.8884e-04,
        2.6760e-04, 9.8490e-05, 3.2984e-04, 3.2554e-04, 1.0525e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,840][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0392, 0.0941, 0.1144, 0.1010, 0.0857, 0.1229, 0.0624, 0.0981, 0.1049,
        0.0824, 0.0948], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,842][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0481, 0.0009, 0.0051, 0.0007, 0.0018, 0.0436, 0.0111, 0.0241, 0.1832,
        0.0667, 0.6147], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,843][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([2.5057e-03, 3.3527e-05, 1.6772e-03, 6.5365e-04, 8.2794e-04, 5.6560e-02,
        5.3154e-03, 3.9562e-02, 1.8701e-01, 1.3148e-01, 5.7437e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:29,845][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.0891, 0.0076, 0.0256, 0.0221, 0.0666, 0.1645, 0.0332, 0.1554, 0.2646,
        0.0414, 0.0980, 0.0319], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,847][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.0002, 0.0871, 0.0986, 0.0954, 0.0931, 0.0905, 0.0791, 0.0932, 0.0946,
        0.0854, 0.0928, 0.0901], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,848][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.0405, 0.0770, 0.0693, 0.1282, 0.0715, 0.0906, 0.1232, 0.0925, 0.0793,
        0.0896, 0.0446, 0.0938], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,850][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.0620, 0.0361, 0.0542, 0.0309, 0.0445, 0.1012, 0.0721, 0.1008, 0.0913,
        0.1077, 0.1711, 0.1281], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,852][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.0022, 0.0614, 0.1030, 0.0846, 0.0927, 0.1028, 0.0797, 0.0964, 0.0958,
        0.0893, 0.1005, 0.0915], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,854][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.0091, 0.0181, 0.2884, 0.1968, 0.1204, 0.1444, 0.0464, 0.0607, 0.0394,
        0.0330, 0.0230, 0.0203], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,855][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.1305, 0.0089, 0.0331, 0.0632, 0.0223, 0.0696, 0.1022, 0.0534, 0.0818,
        0.1230, 0.0929, 0.2193], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,857][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([2.9281e-05, 2.2690e-03, 1.5405e-01, 2.2636e-01, 2.4057e-01, 9.7045e-02,
        4.4666e-02, 1.0766e-01, 7.7427e-02, 3.5099e-02, 1.1822e-02, 3.0046e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,858][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([9.9784e-01, 3.7635e-06, 5.3701e-06, 1.0380e-05, 1.3457e-05, 2.1135e-04,
        2.1760e-04, 9.6552e-05, 2.2391e-04, 1.8283e-04, 4.9299e-04, 6.9764e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,859][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.0425, 0.0865, 0.0992, 0.0901, 0.0749, 0.1113, 0.0572, 0.0915, 0.0975,
        0.0762, 0.0866, 0.0865], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,860][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.0299, 0.0013, 0.0071, 0.0012, 0.0041, 0.0495, 0.0153, 0.0269, 0.1389,
        0.0768, 0.4114, 0.2377], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,861][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([1.0313e-01, 1.0809e-04, 4.2007e-03, 1.3264e-03, 1.6429e-03, 5.7326e-02,
        7.8923e-03, 4.5114e-02, 9.9092e-02, 1.0282e-01, 2.7072e-01, 3.0663e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:29,862][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0850, 0.0079, 0.0288, 0.0219, 0.0671, 0.1494, 0.0270, 0.1364, 0.2297,
        0.0320, 0.0952, 0.0264, 0.0932], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,865][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0003, 0.0793, 0.0904, 0.0883, 0.0855, 0.0828, 0.0735, 0.0852, 0.0866,
        0.0782, 0.0851, 0.0831, 0.0817], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,871][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0290, 0.0699, 0.0649, 0.1176, 0.0675, 0.0878, 0.1259, 0.0895, 0.0782,
        0.0805, 0.0430, 0.0857, 0.0606], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,872][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0152, 0.0338, 0.0626, 0.0335, 0.0506, 0.1067, 0.0680, 0.0809, 0.0819,
        0.0961, 0.1870, 0.1153, 0.0684], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,873][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0021, 0.0535, 0.0959, 0.0788, 0.0850, 0.0976, 0.0732, 0.0904, 0.0886,
        0.0832, 0.0926, 0.0845, 0.0747], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,874][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0181, 0.0125, 0.3078, 0.1961, 0.1369, 0.1283, 0.0437, 0.0531, 0.0332,
        0.0272, 0.0168, 0.0179, 0.0085], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,877][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.2789, 0.0067, 0.0310, 0.0392, 0.0176, 0.0681, 0.0783, 0.0376, 0.0575,
        0.1145, 0.0827, 0.1267, 0.0612], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,883][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0002, 0.0006, 0.1461, 0.2014, 0.1497, 0.1894, 0.0240, 0.1289, 0.0932,
        0.0317, 0.0144, 0.0027, 0.0177], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,884][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([9.8369e-01, 1.6031e-05, 4.0213e-05, 6.0914e-05, 6.4823e-05, 2.2416e-03,
        5.6334e-04, 5.0454e-04, 1.1960e-03, 1.0467e-03, 2.8354e-03, 6.6941e-03,
        1.0503e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,885][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0276, 0.0808, 0.1008, 0.0873, 0.0760, 0.1089, 0.0523, 0.0842, 0.0871,
        0.0715, 0.0785, 0.0782, 0.0669], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,886][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0141, 0.0007, 0.0071, 0.0010, 0.0024, 0.0519, 0.0093, 0.0274, 0.1536,
        0.0738, 0.4201, 0.1681, 0.0707], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,887][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([3.7897e-03, 1.7355e-05, 2.2955e-03, 5.1780e-04, 4.5778e-04, 6.0251e-02,
        3.4038e-03, 3.3237e-02, 9.0381e-02, 1.7560e-01, 3.6927e-01, 2.2164e-01,
        3.9147e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:29,892][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0578, 0.0060, 0.0210, 0.0173, 0.0535, 0.1132, 0.0238, 0.1068, 0.1546,
        0.0221, 0.0621, 0.0186, 0.0631, 0.2801], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,896][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0002, 0.0726, 0.0827, 0.0811, 0.0781, 0.0764, 0.0667, 0.0781, 0.0796,
        0.0722, 0.0784, 0.0763, 0.0755, 0.0821], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,897][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0344, 0.0754, 0.0645, 0.1144, 0.0665, 0.0803, 0.1095, 0.0812, 0.0717,
        0.0712, 0.0400, 0.0795, 0.0540, 0.0576], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,898][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0687, 0.0369, 0.0459, 0.0298, 0.0355, 0.0791, 0.0652, 0.0745, 0.0698,
        0.0658, 0.1391, 0.0930, 0.0549, 0.1418], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,899][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0020, 0.0509, 0.0870, 0.0714, 0.0783, 0.0892, 0.0675, 0.0824, 0.0814,
        0.0771, 0.0866, 0.0791, 0.0707, 0.0763], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,902][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0114, 0.0218, 0.2999, 0.1912, 0.1391, 0.1111, 0.0491, 0.0511, 0.0351,
        0.0313, 0.0191, 0.0192, 0.0109, 0.0098], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,908][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.4350, 0.0041, 0.0210, 0.0275, 0.0128, 0.0604, 0.0787, 0.0310, 0.0527,
        0.0583, 0.0541, 0.0823, 0.0499, 0.0322], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,909][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.6625e-04, 1.7441e-03, 1.1018e-01, 2.2482e-01, 1.2442e-01, 1.4108e-01,
        4.4340e-02, 1.4660e-01, 1.0134e-01, 4.0730e-02, 1.8735e-02, 7.3951e-03,
        2.3954e-02, 1.4485e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,910][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([9.9822e-01, 1.8245e-06, 1.5371e-06, 4.9551e-06, 3.7111e-06, 1.1568e-04,
        6.8947e-05, 2.2730e-05, 8.0984e-05, 1.0147e-04, 2.3855e-04, 7.5204e-04,
        7.4742e-05, 3.1204e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,911][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0288, 0.0756, 0.0899, 0.0801, 0.0691, 0.0972, 0.0489, 0.0771, 0.0822,
        0.0646, 0.0730, 0.0734, 0.0617, 0.0784], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,914][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0666, 0.0005, 0.0025, 0.0006, 0.0013, 0.0231, 0.0061, 0.0123, 0.0874,
        0.0292, 0.2445, 0.1140, 0.0361, 0.3758], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,918][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.2494e-03, 2.0004e-05, 9.6204e-04, 3.1344e-04, 5.8057e-04, 2.8528e-02,
        3.0513e-03, 1.4159e-02, 8.3546e-02, 7.1913e-02, 2.5378e-01, 2.1528e-01,
        5.8703e-02, 2.6692e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:29,920][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0618, 0.0062, 0.0197, 0.0152, 0.0456, 0.1005, 0.0187, 0.0921, 0.1546,
        0.0224, 0.0645, 0.0185, 0.0623, 0.2427, 0.0750], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,921][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0003, 0.0683, 0.0771, 0.0749, 0.0722, 0.0707, 0.0627, 0.0727, 0.0743,
        0.0669, 0.0730, 0.0710, 0.0696, 0.0762, 0.0701], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,922][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0273, 0.0608, 0.0581, 0.1037, 0.0585, 0.0771, 0.1102, 0.0781, 0.0693,
        0.0731, 0.0388, 0.0795, 0.0540, 0.0538, 0.0577], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,923][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0203, 0.0358, 0.0472, 0.0315, 0.0404, 0.0816, 0.0630, 0.0661, 0.0679,
        0.0807, 0.1407, 0.0879, 0.0535, 0.1263, 0.0571], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,927][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0018, 0.0462, 0.0818, 0.0669, 0.0726, 0.0832, 0.0621, 0.0770, 0.0769,
        0.0715, 0.0799, 0.0743, 0.0653, 0.0707, 0.0699], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,932][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0077, 0.0108, 0.3020, 0.1971, 0.1268, 0.1295, 0.0388, 0.0493, 0.0343,
        0.0271, 0.0185, 0.0176, 0.0100, 0.0096, 0.0208], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,933][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.4309, 0.0030, 0.0191, 0.0142, 0.0094, 0.0495, 0.0691, 0.0353, 0.0709,
        0.0751, 0.0588, 0.0637, 0.0378, 0.0252, 0.0380], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,934][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0003, 0.0010, 0.1301, 0.1860, 0.1246, 0.1536, 0.0285, 0.1398, 0.1054,
        0.0354, 0.0199, 0.0043, 0.0231, 0.0138, 0.0341], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,935][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ give] are: tensor([9.8600e-01, 5.4799e-06, 2.1277e-05, 2.9206e-05, 3.4275e-05, 1.4046e-03,
        5.1471e-04, 2.8961e-04, 8.7430e-04, 8.3137e-04, 2.0738e-03, 3.0100e-03,
        4.5040e-04, 3.2557e-03, 1.2053e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,939][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0255, 0.0685, 0.0861, 0.0732, 0.0654, 0.0912, 0.0470, 0.0722, 0.0768,
        0.0609, 0.0700, 0.0671, 0.0591, 0.0758, 0.0611], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,945][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0057, 0.0004, 0.0041, 0.0005, 0.0014, 0.0326, 0.0058, 0.0169, 0.0987,
        0.0438, 0.2772, 0.1080, 0.0263, 0.2924, 0.0864], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,945][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ give] are: tensor([2.2756e-03, 7.4190e-06, 4.4037e-04, 1.9097e-04, 2.8986e-04, 1.9494e-02,
        3.6624e-03, 3.1119e-02, 6.8674e-02, 1.0132e-01, 1.7354e-01, 1.9066e-01,
        6.2173e-02, 2.7725e-01, 6.8902e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:29,946][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.0523, 0.0047, 0.0155, 0.0124, 0.0376, 0.0849, 0.0159, 0.0793, 0.1324,
        0.0189, 0.0555, 0.0148, 0.0539, 0.2081, 0.0601, 0.1536],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,947][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.0002, 0.0631, 0.0716, 0.0697, 0.0678, 0.0659, 0.0582, 0.0677, 0.0691,
        0.0624, 0.0680, 0.0661, 0.0650, 0.0711, 0.0656, 0.0685],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,951][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0264, 0.0605, 0.0562, 0.0993, 0.0576, 0.0727, 0.1037, 0.0743, 0.0647,
        0.0667, 0.0361, 0.0726, 0.0488, 0.0510, 0.0524, 0.0570],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,957][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.0241, 0.0263, 0.0402, 0.0271, 0.0392, 0.0777, 0.0608, 0.0679, 0.0641,
        0.0721, 0.1347, 0.0815, 0.0491, 0.1168, 0.0506, 0.0679],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,958][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.0017, 0.0434, 0.0748, 0.0608, 0.0667, 0.0771, 0.0581, 0.0710, 0.0713,
        0.0672, 0.0756, 0.0694, 0.0620, 0.0664, 0.0649, 0.0693],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,959][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.0174, 0.0145, 0.2543, 0.1701, 0.1101, 0.1085, 0.0502, 0.0561, 0.0404,
        0.0419, 0.0279, 0.0272, 0.0169, 0.0154, 0.0299, 0.0192],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,960][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.2062, 0.0039, 0.0231, 0.0209, 0.0140, 0.0528, 0.1178, 0.0455, 0.0712,
        0.0826, 0.0688, 0.0809, 0.0497, 0.0362, 0.0449, 0.0814],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,963][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0002, 0.0008, 0.0969, 0.1499, 0.1405, 0.1273, 0.0273, 0.1446, 0.0976,
        0.0477, 0.0260, 0.0068, 0.0368, 0.0188, 0.0411, 0.0376],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,967][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ it] are: tensor([9.9351e-01, 1.8989e-06, 4.2168e-06, 6.1371e-06, 9.3518e-06, 4.1026e-04,
        1.3753e-04, 1.1013e-04, 3.2079e-04, 1.8049e-04, 9.4877e-04, 1.1533e-03,
        2.5951e-04, 1.5274e-03, 4.7112e-04, 9.4432e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,969][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.0245, 0.0604, 0.0789, 0.0686, 0.0627, 0.0865, 0.0438, 0.0692, 0.0727,
        0.0575, 0.0656, 0.0628, 0.0555, 0.0709, 0.0568, 0.0637],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,970][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ it] are: tensor([1.4567e-02, 2.5861e-04, 1.6653e-03, 3.7723e-04, 9.0754e-04, 2.0239e-02,
        5.2035e-03, 1.1158e-02, 7.3800e-02, 3.0579e-02, 2.1156e-01, 8.3282e-02,
        2.7016e-02, 2.9574e-01, 5.4209e-02, 1.6944e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,971][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ it] are: tensor([4.7193e-03, 4.4050e-06, 1.7070e-04, 4.0917e-05, 5.8239e-05, 9.9296e-03,
        1.2719e-03, 1.0312e-02, 3.3905e-02, 3.9404e-02, 1.6579e-01, 1.4933e-01,
        3.1742e-02, 2.5488e-01, 6.1618e-02, 2.3682e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:29,972][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0376, 0.0043, 0.0138, 0.0109, 0.0334, 0.0670, 0.0138, 0.0648, 0.1002,
        0.0154, 0.0431, 0.0123, 0.0421, 0.1703, 0.0471, 0.1179, 0.2059],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,975][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0002, 0.0590, 0.0670, 0.0653, 0.0631, 0.0617, 0.0540, 0.0632, 0.0645,
        0.0585, 0.0635, 0.0619, 0.0610, 0.0666, 0.0611, 0.0642, 0.0650],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,981][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0254, 0.0611, 0.0550, 0.0964, 0.0570, 0.0686, 0.0934, 0.0677, 0.0595,
        0.0611, 0.0318, 0.0658, 0.0457, 0.0468, 0.0493, 0.0519, 0.0635],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,982][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0638, 0.0263, 0.0367, 0.0262, 0.0284, 0.0659, 0.0510, 0.0547, 0.0504,
        0.0505, 0.0997, 0.0757, 0.0421, 0.1055, 0.0423, 0.0549, 0.1259],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,983][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0016, 0.0420, 0.0713, 0.0579, 0.0642, 0.0725, 0.0546, 0.0666, 0.0665,
        0.0628, 0.0706, 0.0645, 0.0577, 0.0622, 0.0605, 0.0648, 0.0597],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,984][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0049, 0.0215, 0.3117, 0.1760, 0.1289, 0.1038, 0.0434, 0.0502, 0.0325,
        0.0277, 0.0176, 0.0160, 0.0099, 0.0095, 0.0233, 0.0145, 0.0088],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,988][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3887, 0.0033, 0.0180, 0.0246, 0.0144, 0.0525, 0.0623, 0.0271, 0.0484,
        0.0483, 0.0391, 0.0607, 0.0467, 0.0308, 0.0278, 0.0726, 0.0348],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,992][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.3854e-04, 1.8041e-03, 1.0957e-01, 2.0550e-01, 1.3333e-01, 1.3170e-01,
        4.0372e-02, 1.1923e-01, 8.8434e-02, 3.7433e-02, 1.5538e-02, 5.4274e-03,
        2.2424e-02, 1.1711e-02, 3.0412e-02, 3.8093e-02, 8.8949e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,994][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([9.9835e-01, 1.3570e-06, 9.0909e-07, 3.6683e-06, 3.3465e-06, 8.4996e-05,
        4.3154e-05, 1.3957e-05, 4.7596e-05, 6.8159e-05, 1.1313e-04, 4.6105e-04,
        4.8741e-05, 1.9549e-04, 8.4259e-05, 1.6111e-04, 3.2103e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,995][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0241, 0.0620, 0.0729, 0.0636, 0.0565, 0.0782, 0.0409, 0.0634, 0.0674,
        0.0523, 0.0607, 0.0588, 0.0523, 0.0652, 0.0533, 0.0598, 0.0686],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,996][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0466, 0.0003, 0.0013, 0.0003, 0.0007, 0.0126, 0.0038, 0.0061, 0.0530,
        0.0144, 0.1433, 0.0605, 0.0214, 0.2093, 0.0428, 0.1413, 0.2422],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:29,996][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.7469e-03, 1.4498e-05, 4.2977e-04, 1.5743e-04, 2.7880e-04, 1.0896e-02,
        1.2004e-03, 7.4896e-03, 3.7678e-02, 2.8092e-02, 1.0123e-01, 1.1074e-01,
        2.7792e-02, 1.4142e-01, 4.4672e-02, 2.3686e-01, 2.4831e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,081][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:30,082][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,083][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,083][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,084][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,085][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,085][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,086][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,087][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,088][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,088][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,089][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,090][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,091][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.9990, 0.0010], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,091][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.3542, 0.6458], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,092][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.7736, 0.2264], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,095][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.3633, 0.6367], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,098][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.0364, 0.9636], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,102][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.8649, 0.1351], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,103][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.9909, 0.0091], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,104][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.0821, 0.9179], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,104][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.9843, 0.0157], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,106][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.9634, 0.0366], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,109][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.3612, 0.6388], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,113][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.6067, 0.3933], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,115][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([9.9837e-01, 9.3989e-05, 1.5315e-03], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,116][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1025, 0.3117, 0.5858], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,117][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.7315, 0.1487, 0.1198], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,117][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3208, 0.0637, 0.6156], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,118][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([6.5899e-04, 2.5030e-05, 9.9932e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,119][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([9.2756e-02, 3.5341e-05, 9.0721e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,122][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9912, 0.0022, 0.0066], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,125][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([1.6765e-03, 2.1603e-06, 9.9832e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,129][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.8783, 0.0012, 0.1205], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,129][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9788, 0.0033, 0.0180], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,130][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0397, 0.0032, 0.9572], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,131][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0062, 0.0013, 0.9926], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,132][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Nathan] are: tensor([9.9700e-01, 3.6695e-04, 1.7499e-03, 8.8470e-04], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,135][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Nathan] are: tensor([0.0481, 0.1284, 0.2647, 0.5588], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,139][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Nathan] are: tensor([0.5217, 0.2279, 0.1549, 0.0956], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,142][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Nathan] are: tensor([0.7557, 0.0293, 0.1479, 0.0672], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,142][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Nathan] are: tensor([2.5588e-04, 1.4571e-05, 9.8115e-01, 1.8578e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,143][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Nathan] are: tensor([1.0532e-02, 2.1662e-05, 9.5787e-01, 3.1576e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,144][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Nathan] are: tensor([0.9634, 0.0045, 0.0155, 0.0166], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,145][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Nathan] are: tensor([1.0995e-04, 9.3741e-07, 9.8182e-01, 1.8069e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,147][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Nathan] are: tensor([0.9544, 0.0011, 0.0376, 0.0069], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,150][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Nathan] are: tensor([0.9571, 0.0029, 0.0176, 0.0224], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,153][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Nathan] are: tensor([0.1165, 0.0083, 0.7918, 0.0834], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,155][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Nathan] are: tensor([4.5754e-03, 5.7012e-04, 9.4490e-01, 4.9950e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,156][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([9.9243e-01, 2.6302e-04, 2.9039e-03, 1.8294e-03, 2.5754e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,157][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.0528, 0.1034, 0.2748, 0.3874, 0.1816], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,158][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.5821, 0.1580, 0.1278, 0.0928, 0.0394], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,159][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.2014, 0.1153, 0.5785, 0.0504, 0.0544], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,161][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([1.6534e-04, 6.7368e-06, 9.0166e-01, 2.9195e-02, 6.8975e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,164][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([1.4468e-02, 3.9914e-05, 8.1757e-01, 7.3275e-02, 9.4643e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,168][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.9820, 0.0019, 0.0049, 0.0047, 0.0066], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,169][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([3.0368e-04, 1.3998e-06, 9.5410e-01, 2.7659e-02, 1.7937e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,170][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([9.3042e-01, 5.2392e-04, 5.2056e-02, 5.6073e-03, 1.1392e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,170][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.9410, 0.0032, 0.0267, 0.0164, 0.0127], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,171][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.0718, 0.0061, 0.7646, 0.0458, 0.1117], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,173][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.0072, 0.0009, 0.8706, 0.0454, 0.0759], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,175][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([8.6258e-01, 1.5244e-05, 1.0159e-04, 5.7512e-05, 7.2852e-05, 1.3718e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,179][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0743, 0.0877, 0.1241, 0.3427, 0.2762, 0.0950], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,182][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.7627, 0.1018, 0.0433, 0.0245, 0.0182, 0.0495], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,183][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.6788, 0.0261, 0.0442, 0.0054, 0.0080, 0.2376], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,183][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([6.6879e-04, 2.9506e-07, 1.8852e-04, 2.7091e-05, 3.4973e-05, 9.9908e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,184][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.4955e-01, 1.2223e-06, 3.6896e-04, 6.8281e-05, 9.5899e-05, 8.4992e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,186][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([9.9826e-01, 2.1619e-04, 2.7933e-04, 1.8527e-04, 2.7151e-04, 7.8661e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,188][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([8.3177e-04, 7.2007e-09, 1.2557e-05, 4.6959e-06, 2.8330e-06, 9.9915e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,190][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([9.5743e-01, 3.9004e-05, 2.8177e-04, 1.1372e-04, 2.1333e-04, 4.1920e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,193][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([9.7995e-01, 3.5207e-04, 5.9613e-04, 9.1138e-04, 5.7627e-04, 1.7612e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,195][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1243, 0.0010, 0.0246, 0.0021, 0.0049, 0.8430], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,195][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([3.1657e-03, 1.1990e-04, 1.0100e-02, 1.9718e-03, 1.6631e-03, 9.8298e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,196][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([7.3354e-01, 3.5296e-04, 1.0904e-03, 8.5122e-04, 6.2237e-04, 2.6300e-01,
        5.4004e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,197][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0134, 0.0948, 0.0794, 0.2579, 0.1949, 0.1533, 0.2063],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,199][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.5393, 0.2265, 0.0848, 0.0483, 0.0151, 0.0548, 0.0311],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,202][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.1680, 0.0241, 0.0861, 0.0192, 0.0181, 0.3702, 0.3143],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,204][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([3.7678e-05, 2.5740e-06, 2.4287e-03, 3.1284e-04, 5.1880e-04, 9.8202e-01,
        1.4683e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,208][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([2.5341e-02, 5.4981e-06, 2.9809e-03, 5.7879e-04, 7.9319e-04, 9.0786e-01,
        6.2444e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,209][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.9412, 0.0014, 0.0064, 0.0032, 0.0021, 0.0133, 0.0325],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,209][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([6.1352e-05, 8.1899e-08, 3.0432e-04, 2.3637e-04, 2.4389e-04, 9.8125e-01,
        1.7904e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,210][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([9.7131e-01, 5.5235e-05, 5.4291e-04, 1.6375e-04, 2.8727e-04, 1.4263e-02,
        1.3382e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,212][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([9.1733e-01, 6.2631e-04, 1.4404e-03, 1.8160e-03, 9.0749e-04, 1.2731e-02,
        6.5147e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,218][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0580, 0.0021, 0.0527, 0.0087, 0.0174, 0.6532, 0.2079],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,220][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([7.6356e-03, 2.1612e-04, 1.5273e-02, 4.6738e-03, 4.9830e-03, 8.5582e-01,
        1.1140e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,220][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([7.7181e-01, 6.6727e-05, 3.1082e-04, 2.1971e-04, 2.8734e-04, 2.2655e-01,
        2.4317e-04, 5.0574e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,221][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0479, 0.0464, 0.0591, 0.3517, 0.2164, 0.1757, 0.0894, 0.0134],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,222][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.5722, 0.1241, 0.0665, 0.0468, 0.0242, 0.0903, 0.0412, 0.0347],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,226][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.6355, 0.0075, 0.0272, 0.0041, 0.0063, 0.1550, 0.1182, 0.0462],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,230][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([3.1323e-04, 3.3371e-07, 1.4274e-04, 3.4240e-05, 8.8416e-05, 7.6354e-01,
        1.3038e-02, 2.2284e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,232][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([3.0497e-02, 1.3558e-06, 3.0623e-04, 7.6483e-05, 9.9440e-05, 4.6945e-01,
        7.3768e-02, 4.2580e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,232][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([9.8007e-01, 6.9764e-04, 1.8823e-03, 7.9247e-04, 8.7891e-04, 5.3339e-03,
        6.7882e-03, 3.5570e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,233][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([3.3190e-04, 1.2154e-08, 1.7286e-05, 9.6661e-06, 7.5936e-06, 5.8101e-01,
        1.0996e-02, 4.0763e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,234][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([9.3092e-01, 3.3414e-05, 4.0036e-04, 1.0118e-04, 1.9033e-04, 3.9631e-02,
        1.8299e-02, 1.0421e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,237][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([9.3195e-01, 3.5783e-04, 5.7819e-04, 8.6438e-04, 4.8588e-04, 9.2230e-03,
        4.2766e-02, 1.3771e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,241][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.1130, 0.0008, 0.0239, 0.0028, 0.0037, 0.5168, 0.1072, 0.2318],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,243][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([3.0070e-03, 1.7733e-04, 9.1123e-03, 1.8017e-03, 9.9642e-04, 6.0665e-01,
        3.3455e-02, 3.4480e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,244][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([9.0621e-01, 1.4727e-05, 8.0093e-05, 4.8445e-05, 6.0201e-05, 7.1719e-02,
        7.4664e-05, 1.0260e-04, 2.1692e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,245][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1601, 0.0618, 0.0466, 0.2806, 0.1390, 0.1078, 0.1187, 0.0452, 0.0402],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,246][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.6907, 0.1198, 0.0363, 0.0220, 0.0149, 0.0355, 0.0176, 0.0176, 0.0458],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,249][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.5430, 0.0137, 0.0143, 0.0036, 0.0064, 0.1249, 0.0998, 0.0733, 0.1208],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,252][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([3.6505e-04, 1.8810e-07, 1.2724e-05, 3.1834e-06, 6.2123e-06, 5.4083e-02,
        2.8291e-03, 2.8964e-02, 9.1374e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,255][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([2.6828e-01, 5.4592e-07, 2.2531e-05, 1.4136e-05, 1.2617e-05, 4.6606e-02,
        2.2525e-02, 6.7995e-02, 5.9455e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,256][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([9.9631e-01, 1.2663e-04, 1.8463e-04, 1.5111e-04, 1.4712e-04, 5.7424e-04,
        1.5210e-03, 4.8861e-04, 4.9223e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,257][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([1.1902e-03, 4.6910e-09, 6.3762e-07, 1.1139e-06, 7.1973e-07, 2.8717e-02,
        2.4028e-03, 5.6562e-02, 9.1113e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,258][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([9.8635e-01, 9.7395e-06, 2.4281e-05, 1.8884e-05, 2.6057e-05, 2.5603e-03,
        2.6111e-03, 9.0447e-04, 7.4961e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,259][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([9.8267e-01, 1.1982e-04, 9.0187e-05, 1.6003e-04, 8.7297e-05, 1.2384e-03,
        6.7424e-03, 1.9362e-03, 6.9516e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,263][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([1.3913e-01, 3.9049e-04, 5.1051e-03, 7.6307e-04, 1.3407e-03, 1.1788e-01,
        3.6481e-02, 7.7847e-02, 6.2106e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,266][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([4.6203e-03, 5.9122e-05, 1.4434e-03, 6.7869e-04, 4.8649e-04, 1.6016e-01,
        1.4324e-02, 1.1736e-01, 7.0087e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,268][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([8.0616e-01, 1.2040e-04, 2.8722e-04, 2.1973e-04, 1.1827e-04, 1.4826e-01,
        1.7157e-04, 2.5291e-04, 4.4037e-02, 3.7218e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,268][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([0.0134, 0.0704, 0.0722, 0.1916, 0.1097, 0.1245, 0.0885, 0.0527, 0.0951,
        0.1820], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,269][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([0.8535, 0.0338, 0.0129, 0.0097, 0.0063, 0.0159, 0.0125, 0.0074, 0.0145,
        0.0335], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,270][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([0.6378, 0.0073, 0.0105, 0.0024, 0.0016, 0.0561, 0.0228, 0.0225, 0.0447,
        0.1943], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,272][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([2.3172e-04, 1.5833e-07, 3.3783e-05, 7.1741e-06, 1.5003e-05, 6.5289e-02,
        2.4331e-03, 3.7984e-02, 7.1981e-01, 1.7419e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,275][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([6.7124e-02, 1.4958e-06, 6.7238e-05, 1.8699e-05, 2.6402e-05, 5.9171e-02,
        1.1480e-02, 5.7568e-02, 4.9509e-01, 3.0945e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,279][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([9.6702e-01, 5.9685e-04, 1.4795e-03, 1.1176e-03, 1.2010e-03, 5.1451e-03,
        6.1846e-03, 2.8616e-03, 4.4651e-03, 9.9317e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,280][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([1.6507e-04, 6.4262e-09, 3.9231e-06, 1.3970e-06, 2.2710e-06, 3.6882e-02,
        1.7877e-03, 3.5705e-02, 8.3881e-01, 8.6640e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,281][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([9.8066e-01, 8.8851e-06, 3.7140e-05, 3.3798e-05, 4.7709e-05, 2.7126e-03,
        4.1995e-03, 1.3738e-03, 7.4641e-03, 3.4656e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,282][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([9.7117e-01, 1.5624e-04, 1.1780e-04, 1.0648e-04, 6.3531e-05, 1.6711e-03,
        6.2565e-03, 2.0069e-03, 7.6303e-03, 1.0817e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,287][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([0.0886, 0.0005, 0.0068, 0.0010, 0.0023, 0.1200, 0.0376, 0.0753, 0.3404,
        0.3275], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,291][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([9.3040e-03, 7.2987e-05, 1.1259e-03, 6.2028e-04, 6.0391e-04, 1.1677e-01,
        1.7745e-02, 8.8024e-02, 5.0430e-01, 2.6143e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,292][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.6680e-01, 1.4353e-05, 4.9951e-05, 3.0624e-05, 2.6731e-05, 2.4451e-02,
        8.1305e-05, 4.5268e-05, 7.7749e-03, 2.0834e-04, 5.2079e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,293][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0686, 0.0231, 0.0385, 0.2307, 0.0701, 0.0711, 0.0744, 0.0391, 0.0382,
        0.2182, 0.1281], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,293][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7809, 0.0494, 0.0186, 0.0100, 0.0061, 0.0209, 0.0085, 0.0087, 0.0226,
        0.0341, 0.0403], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,297][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6138, 0.0051, 0.0058, 0.0013, 0.0024, 0.0314, 0.0244, 0.0143, 0.0300,
        0.0697, 0.2017], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,300][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([6.2084e-04, 3.8496e-08, 7.8561e-07, 5.8189e-07, 1.0536e-06, 2.7083e-03,
        5.7850e-04, 2.0173e-03, 4.4584e-02, 4.1723e-02, 9.0776e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,303][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([1.7010e-01, 1.6761e-07, 1.6221e-06, 1.6793e-06, 1.3083e-06, 3.0522e-03,
        3.2967e-03, 5.5616e-03, 4.2152e-02, 8.4836e-02, 6.9100e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,304][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([9.9427e-01, 1.3992e-04, 1.3484e-04, 2.0597e-04, 1.8189e-04, 3.9384e-04,
        1.5047e-03, 4.0777e-04, 3.9904e-04, 1.8958e-03, 4.7098e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,305][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([1.0165e-03, 6.0669e-10, 2.1446e-08, 4.2580e-08, 5.4061e-08, 8.3260e-04,
        3.8401e-04, 1.5137e-03, 3.5961e-02, 1.5169e-02, 9.4512e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,306][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([9.8649e-01, 4.2420e-06, 5.4512e-06, 1.0775e-05, 1.3772e-05, 6.6255e-04,
        1.3569e-03, 2.4014e-04, 1.7400e-03, 2.0990e-03, 7.3797e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,309][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([9.7422e-01, 1.5011e-04, 5.6565e-05, 9.9806e-05, 4.5775e-05, 8.9426e-04,
        3.4192e-03, 1.1480e-03, 4.8767e-03, 4.9509e-03, 1.0139e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,313][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([6.8491e-02, 2.1005e-04, 1.6730e-03, 2.6481e-04, 4.1020e-04, 3.2893e-02,
        1.1489e-02, 1.6496e-02, 1.4095e-01, 8.1952e-02, 6.4517e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,315][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([2.7689e-03, 3.3249e-05, 3.5430e-04, 2.7940e-04, 1.5701e-04, 2.9783e-02,
        5.0114e-03, 1.9856e-02, 1.3529e-01, 1.2656e-01, 6.7991e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,316][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([9.0594e-01, 6.6580e-05, 1.7922e-04, 1.4838e-04, 1.0601e-04, 6.5940e-02,
        1.7150e-04, 1.6145e-04, 1.8648e-02, 3.8740e-04, 1.1173e-03, 7.1357e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,317][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.0178, 0.0337, 0.0459, 0.0913, 0.0728, 0.0881, 0.0541, 0.0609, 0.0586,
        0.1627, 0.1478, 0.1664], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,317][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.7112, 0.0679, 0.0195, 0.0185, 0.0087, 0.0153, 0.0125, 0.0081, 0.0169,
        0.0465, 0.0284, 0.0465], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,321][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.5993, 0.0029, 0.0042, 0.0016, 0.0023, 0.0341, 0.0204, 0.0159, 0.0201,
        0.0802, 0.0688, 0.1501], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,325][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([5.8175e-04, 4.5434e-07, 8.2015e-06, 1.7089e-05, 1.1570e-05, 4.6741e-03,
        2.5125e-03, 4.5644e-03, 6.3723e-02, 5.3599e-02, 6.0685e-01, 2.6346e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,327][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([1.7973e-01, 1.9099e-06, 1.8336e-05, 1.9071e-05, 8.4415e-06, 7.6378e-03,
        4.9488e-03, 9.9828e-03, 4.8472e-02, 9.5017e-02, 4.0505e-01, 2.4911e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,328][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([9.4766e-01, 7.3714e-04, 8.2202e-04, 1.8817e-03, 1.3280e-03, 2.8061e-03,
        7.0315e-03, 3.2442e-03, 3.7624e-03, 9.1886e-03, 3.6905e-03, 1.7852e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,329][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([7.9739e-04, 1.9934e-08, 6.6388e-07, 8.2869e-07, 9.0270e-07, 2.0224e-03,
        8.8625e-04, 5.1711e-03, 6.2039e-02, 2.5721e-02, 6.8143e-01, 2.2193e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,330][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([9.9060e-01, 3.7464e-06, 4.9572e-06, 1.0891e-05, 1.3966e-05, 2.9360e-04,
        8.0942e-04, 1.7938e-04, 8.3386e-04, 7.7667e-04, 2.3909e-03, 4.0798e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,333][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([9.2985e-01, 1.4447e-04, 6.6367e-05, 1.8571e-04, 9.5057e-05, 1.4081e-03,
        5.2814e-03, 2.3438e-03, 6.6526e-03, 6.9551e-03, 8.8802e-03, 3.8136e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,338][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.0675, 0.0005, 0.0029, 0.0005, 0.0016, 0.0353, 0.0167, 0.0173, 0.0778,
        0.0883, 0.3143, 0.3771], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,339][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([4.8784e-02, 8.9485e-05, 1.0672e-03, 7.4839e-04, 6.0803e-04, 4.4679e-02,
        8.8657e-03, 3.1441e-02, 1.1346e-01, 1.1379e-01, 3.9118e-01, 2.4530e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,340][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([9.1339e-01, 2.5433e-05, 1.5292e-04, 1.1155e-04, 1.3898e-04, 6.0436e-02,
        1.5703e-04, 1.7044e-04, 1.5493e-02, 3.9580e-04, 1.0918e-03, 5.2061e-03,
        3.2294e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,341][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0182, 0.0137, 0.0679, 0.1845, 0.1094, 0.0896, 0.0463, 0.0381, 0.0272,
        0.1709, 0.0923, 0.1202, 0.0215], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,345][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.7656, 0.0486, 0.0188, 0.0186, 0.0101, 0.0199, 0.0114, 0.0067, 0.0168,
        0.0210, 0.0246, 0.0234, 0.0145], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,351][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.1607, 0.0030, 0.0095, 0.0031, 0.0032, 0.0710, 0.0212, 0.0175, 0.0249,
        0.1606, 0.1525, 0.3444, 0.0281], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,352][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([7.0290e-05, 4.8955e-08, 5.4867e-06, 4.6435e-06, 5.1069e-06, 1.4883e-02,
        9.1084e-04, 7.1965e-03, 7.1726e-02, 6.1785e-02, 5.5213e-01, 2.8101e-01,
        1.0276e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,352][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([1.0790e-02, 2.7570e-07, 1.7146e-05, 8.8392e-06, 1.0084e-05, 1.1684e-02,
        3.6445e-03, 1.2547e-02, 7.0791e-02, 7.2269e-02, 5.7260e-01, 2.3215e-01,
        1.3487e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,353][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([9.7264e-01, 5.2590e-04, 9.0115e-04, 8.6591e-04, 5.8918e-04, 2.0084e-03,
        2.5076e-03, 1.3377e-03, 1.2295e-03, 5.3590e-03, 2.4406e-03, 6.8600e-03,
        2.7326e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,356][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([3.3444e-05, 1.1877e-09, 4.7397e-07, 3.7804e-07, 3.2037e-07, 5.7520e-03,
        2.8211e-04, 4.9610e-03, 7.0445e-02, 1.4758e-02, 7.8454e-01, 1.1369e-01,
        5.5359e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,360][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([9.0116e-01, 1.6204e-05, 5.6955e-05, 9.9989e-05, 1.0240e-04, 4.8712e-03,
        2.9844e-03, 1.4333e-03, 6.6370e-03, 6.3687e-03, 2.1057e-02, 5.1411e-02,
        3.7975e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,362][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([8.7328e-01, 3.5245e-04, 3.5630e-04, 4.2574e-04, 3.6063e-04, 4.3407e-03,
        7.8986e-03, 4.7382e-03, 1.0750e-02, 1.6256e-02, 1.9202e-02, 5.3152e-02,
        8.8879e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,363][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([2.2746e-02, 1.8616e-04, 2.6367e-03, 5.2080e-04, 7.3232e-04, 4.0847e-02,
        9.6722e-03, 1.8667e-02, 1.0468e-01, 9.9224e-02, 3.4776e-01, 2.9637e-01,
        5.5955e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,364][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([1.5402e-03, 2.5083e-05, 8.5815e-04, 4.5879e-04, 2.2883e-04, 5.6005e-02,
        3.8508e-03, 2.2981e-02, 9.5716e-02, 1.5102e-01, 4.9451e-01, 1.4316e-01,
        2.9656e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,365][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.6238e-01, 1.4150e-05, 4.2003e-05, 5.1404e-05, 5.2692e-05, 2.3614e-02,
        7.1019e-05, 4.6277e-05, 6.1873e-03, 1.7124e-04, 4.2540e-04, 3.3524e-03,
        1.5712e-03, 2.0244e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,370][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0343, 0.0236, 0.0344, 0.2169, 0.0642, 0.0634, 0.0206, 0.0198, 0.0196,
        0.1481, 0.0949, 0.1631, 0.0385, 0.0584], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,374][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.8638, 0.0295, 0.0080, 0.0106, 0.0030, 0.0074, 0.0075, 0.0026, 0.0073,
        0.0128, 0.0142, 0.0199, 0.0078, 0.0055], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,375][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.6288, 0.0028, 0.0027, 0.0011, 0.0011, 0.0244, 0.0181, 0.0114, 0.0167,
        0.0369, 0.0592, 0.1453, 0.0162, 0.0354], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,376][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([2.1303e-03, 9.2849e-08, 3.2708e-07, 8.2333e-07, 7.0027e-07, 1.0804e-03,
        5.0933e-04, 9.3393e-04, 1.4470e-02, 1.5210e-02, 1.9254e-01, 2.4885e-01,
        4.7157e-03, 5.1956e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,377][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.2506e-01, 2.9704e-07, 7.7851e-07, 1.2679e-06, 8.5977e-07, 7.1944e-04,
        1.7226e-03, 1.4095e-03, 1.0762e-02, 2.3220e-02, 1.5287e-01, 1.5483e-01,
        6.6502e-03, 4.2275e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,380][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.9476e-01, 7.4258e-05, 8.8026e-05, 1.2618e-04, 9.7926e-05, 3.4285e-04,
        8.0937e-04, 2.2956e-04, 2.7186e-04, 8.9176e-04, 3.3293e-04, 1.1272e-03,
        4.9283e-04, 3.5920e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,384][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.7001e-03, 7.3847e-10, 6.1291e-09, 2.7793e-08, 1.0138e-08, 1.5780e-04,
        9.0025e-05, 4.5748e-04, 5.8391e-03, 2.4302e-03, 1.0001e-01, 7.7339e-02,
        1.3688e-03, 8.1061e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,386][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.8896e-01, 1.6242e-06, 1.3801e-06, 4.7470e-06, 3.7255e-06, 1.5830e-04,
        3.0911e-04, 4.6021e-05, 3.6231e-04, 5.2513e-04, 1.4694e-03, 5.2568e-03,
        2.3351e-04, 2.6661e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,387][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.7056e-01, 8.7436e-05, 2.5026e-05, 6.9763e-05, 3.8590e-05, 3.9240e-04,
        1.7529e-03, 5.2583e-04, 1.7907e-03, 1.5764e-03, 2.3995e-03, 1.4707e-02,
        1.6068e-03, 4.4683e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,387][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.0131e-01, 1.4259e-04, 8.7773e-04, 3.0917e-04, 4.0035e-04, 1.8875e-02,
        6.6953e-03, 8.9753e-03, 6.1896e-02, 3.3373e-02, 2.2147e-01, 2.2339e-01,
        3.2650e-02, 2.8964e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,388][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.8656e-03, 2.5121e-05, 2.0959e-04, 1.7154e-04, 1.3072e-04, 1.5035e-02,
        3.2830e-03, 7.2100e-03, 6.0479e-02, 6.6101e-02, 2.9866e-01, 1.3207e-01,
        2.9142e-02, 3.8462e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,390][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([7.9815e-01, 9.8124e-05, 3.1555e-04, 3.1781e-04, 3.0033e-04, 1.1142e-01,
        3.5008e-04, 4.8286e-04, 4.3179e-02, 1.3045e-03, 3.2364e-03, 1.4076e-02,
        8.6945e-03, 1.2677e-02, 5.3991e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,395][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0415, 0.0251, 0.0410, 0.1236, 0.0413, 0.0722, 0.0343, 0.0374, 0.0504,
        0.1206, 0.1234, 0.1338, 0.0298, 0.0589, 0.0668], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,398][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.6337, 0.0538, 0.0212, 0.0182, 0.0124, 0.0235, 0.0155, 0.0115, 0.0183,
        0.0362, 0.0300, 0.0425, 0.0302, 0.0128, 0.0401], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,399][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.1380, 0.0041, 0.0054, 0.0037, 0.0021, 0.0443, 0.0319, 0.0155, 0.0236,
        0.1503, 0.0943, 0.3136, 0.0186, 0.0601, 0.0945], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,400][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([3.0138e-05, 2.2561e-08, 1.2652e-06, 8.1175e-07, 1.2314e-06, 2.1891e-03,
        2.1835e-04, 1.1238e-03, 2.9601e-02, 1.6612e-02, 2.4254e-01, 1.1468e-01,
        5.5844e-03, 5.3793e-01, 4.9487e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,402][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([3.7285e-03, 9.6069e-08, 3.0195e-06, 1.9470e-06, 2.3273e-06, 3.0468e-03,
        8.8136e-04, 3.2762e-03, 2.4366e-02, 2.0128e-02, 2.1490e-01, 7.1079e-02,
        7.0955e-03, 6.0225e-01, 4.9245e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,404][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([9.8240e-01, 1.6111e-04, 4.6556e-04, 2.5520e-04, 2.8660e-04, 1.1483e-03,
        1.8021e-03, 1.0699e-03, 1.3358e-03, 3.4194e-03, 1.1943e-03, 1.9815e-03,
        1.2131e-03, 9.0382e-04, 2.3590e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,408][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([1.8850e-05, 4.0132e-10, 5.5543e-08, 7.1305e-08, 4.3892e-08, 5.7694e-04,
        6.0537e-05, 8.7570e-04, 1.1523e-02, 3.1975e-03, 1.5810e-01, 3.2204e-02,
        1.5186e-03, 7.6900e-01, 2.2929e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,410][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([9.1369e-01, 5.5228e-06, 2.4407e-05, 3.4894e-05, 4.1272e-05, 2.4081e-03,
        2.5295e-03, 6.6057e-04, 4.3283e-03, 4.4306e-03, 1.3395e-02, 2.0431e-02,
        1.4003e-03, 2.7230e-02, 9.3891e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,411][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([8.3567e-01, 2.5292e-04, 2.3063e-04, 1.9908e-04, 1.6171e-04, 2.1456e-03,
        1.0870e-02, 2.9275e-03, 1.2584e-02, 1.1866e-02, 2.0104e-02, 4.1952e-02,
        6.1938e-03, 3.0307e-02, 2.4536e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,412][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([1.1854e-02, 1.1864e-04, 1.5679e-03, 2.4601e-04, 4.1176e-04, 2.5781e-02,
        6.4639e-03, 1.2575e-02, 7.7357e-02, 5.8674e-02, 2.5404e-01, 2.0098e-01,
        2.1230e-02, 2.1367e-01, 1.1503e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,413][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([6.6075e-04, 1.1115e-05, 2.1104e-04, 1.9229e-04, 1.3680e-04, 1.8121e-02,
        3.6240e-03, 1.8421e-02, 6.2010e-02, 9.0164e-02, 2.3759e-01, 1.2788e-01,
        3.3038e-02, 3.6790e-01, 4.0038e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,414][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([9.4436e-01, 2.6047e-05, 8.0821e-05, 4.8091e-05, 4.6561e-05, 2.3813e-02,
        7.1359e-05, 5.6345e-05, 8.3335e-03, 1.8394e-04, 5.1775e-04, 3.5913e-03,
        1.7447e-03, 2.0834e-03, 7.6554e-04, 1.4276e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,420][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.0192, 0.0156, 0.0287, 0.1055, 0.0439, 0.0754, 0.0474, 0.0238, 0.0358,
        0.1385, 0.1177, 0.1440, 0.0325, 0.0582, 0.0779, 0.0359],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,424][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.7035, 0.0314, 0.0119, 0.0094, 0.0069, 0.0136, 0.0160, 0.0068, 0.0171,
        0.0209, 0.0269, 0.0355, 0.0198, 0.0127, 0.0359, 0.0317],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,425][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([0.1250, 0.0019, 0.0036, 0.0024, 0.0025, 0.0553, 0.0344, 0.0221, 0.0336,
        0.1193, 0.1238, 0.2225, 0.0245, 0.0672, 0.0876, 0.0743],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,426][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([6.3335e-05, 1.2437e-08, 2.6080e-07, 1.3616e-07, 2.7592e-07, 1.0221e-03,
        1.0913e-04, 5.0426e-04, 1.6710e-02, 7.7047e-03, 2.2169e-01, 8.0403e-02,
        4.2636e-03, 4.8819e-01, 2.7062e-02, 1.5228e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,427][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([2.3578e-02, 6.4361e-08, 5.7193e-07, 4.4607e-07, 4.0437e-07, 5.9403e-04,
        5.6562e-04, 1.0916e-03, 9.1536e-03, 1.5096e-02, 1.8010e-01, 8.0528e-02,
        7.2702e-03, 5.5572e-01, 3.7739e-02, 8.8567e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,428][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([9.5989e-01, 2.9919e-04, 6.1398e-04, 4.5368e-04, 4.5488e-04, 1.8174e-03,
        5.9150e-03, 1.6646e-03, 2.1076e-03, 5.8917e-03, 2.0400e-03, 5.6350e-03,
        1.6989e-03, 1.9723e-03, 4.5014e-03, 5.0482e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,432][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([7.6159e-05, 1.1373e-10, 4.3986e-09, 1.0130e-08, 1.1803e-08, 1.1320e-04,
        2.7625e-05, 2.8527e-04, 3.7340e-03, 2.3354e-03, 1.0435e-01, 3.2871e-02,
        1.6728e-03, 6.7457e-01, 1.4606e-02, 1.6536e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,436][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([9.5202e-01, 1.7720e-06, 4.1275e-06, 7.3905e-06, 1.0716e-05, 6.6838e-04,
        6.9852e-04, 2.5394e-04, 1.5831e-03, 1.0648e-03, 6.3434e-03, 9.0828e-03,
        8.8273e-04, 1.4329e-02, 4.3620e-03, 8.6909e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,437][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([8.8702e-01, 4.2203e-05, 5.8729e-05, 1.0454e-04, 1.2467e-04, 1.2149e-03,
        4.9855e-03, 2.0711e-03, 6.9433e-03, 5.4288e-03, 1.1281e-02, 2.1909e-02,
        4.2976e-03, 1.7552e-02, 1.1939e-02, 2.5029e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,438][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([2.9747e-02, 6.8066e-05, 5.1032e-04, 1.7590e-04, 2.7167e-04, 1.4286e-02,
        5.5969e-03, 7.9021e-03, 5.1952e-02, 3.5460e-02, 1.8197e-01, 1.5255e-01,
        2.4019e-02, 2.1274e-01, 6.8538e-02, 2.1421e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,439][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([1.0831e-03, 5.2709e-06, 7.4103e-05, 4.4749e-05, 2.9802e-05, 9.4952e-03,
        1.3996e-03, 6.7124e-03, 3.5556e-02, 4.3804e-02, 2.3731e-01, 8.6611e-02,
        1.7571e-02, 3.6204e-01, 3.7185e-02, 1.6108e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,440][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.4752e-01, 1.5573e-05, 5.2180e-05, 5.3872e-05, 6.2661e-05, 2.4200e-02,
        4.2244e-05, 5.2181e-05, 5.8448e-03, 1.2888e-04, 3.5449e-04, 2.5535e-03,
        1.3948e-03, 1.9646e-03, 7.3388e-04, 1.2010e-02, 3.0187e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,446][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0429, 0.0260, 0.0387, 0.1343, 0.0587, 0.0577, 0.0163, 0.0202, 0.0217,
        0.1261, 0.0832, 0.1420, 0.0285, 0.0511, 0.0393, 0.0527, 0.0607],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,448][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.7864, 0.0351, 0.0094, 0.0094, 0.0038, 0.0089, 0.0073, 0.0035, 0.0092,
        0.0165, 0.0199, 0.0246, 0.0128, 0.0083, 0.0174, 0.0168, 0.0109],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,449][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.6233, 0.0026, 0.0025, 0.0011, 0.0008, 0.0183, 0.0131, 0.0063, 0.0109,
        0.0229, 0.0367, 0.1072, 0.0102, 0.0236, 0.0370, 0.0283, 0.0551],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,450][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.4398e-04, 3.9099e-08, 1.1461e-07, 2.1420e-07, 2.4464e-07, 2.8606e-04,
        1.3526e-04, 2.2725e-04, 5.1709e-03, 4.6677e-03, 5.7276e-02, 6.6826e-02,
        1.8020e-03, 1.5206e-01, 1.7060e-02, 9.7594e-02, 5.9595e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,451][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.3623e-01, 2.1658e-07, 4.1345e-07, 6.5262e-07, 5.0943e-07, 3.7246e-04,
        8.7168e-04, 8.0802e-04, 5.0758e-03, 1.0399e-02, 5.9338e-02, 5.4846e-02,
        3.5578e-03, 2.2716e-01, 2.8287e-02, 6.8975e-02, 4.0408e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,454][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.8876e-01, 7.9786e-05, 1.3339e-04, 1.8310e-04, 1.6834e-04, 5.4479e-04,
        1.1447e-03, 3.4636e-04, 4.5278e-04, 1.2762e-03, 3.7295e-04, 1.3886e-03,
        6.6350e-04, 5.2653e-04, 1.1215e-03, 1.9823e-03, 8.5331e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,458][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.6748e-03, 4.8830e-10, 2.8857e-09, 1.2428e-08, 5.5274e-09, 5.7388e-05,
        3.5482e-05, 1.3261e-04, 1.8058e-03, 9.2209e-04, 2.6887e-02, 1.8158e-02,
        5.5588e-04, 2.1951e-01, 8.7966e-03, 1.6842e-01, 5.5304e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,460][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.8971e-01, 1.2047e-06, 7.6347e-07, 3.0416e-06, 2.8964e-06, 1.0190e-04,
        1.6900e-04, 2.4416e-05, 1.8135e-04, 3.0189e-04, 5.8496e-04, 2.6320e-03,
        1.3140e-04, 1.3826e-03, 6.1834e-04, 1.1645e-03, 2.9861e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,461][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.4411e-01, 1.1942e-04, 3.3443e-05, 5.7750e-05, 4.5202e-05, 4.0363e-04,
        2.1397e-03, 6.0664e-04, 2.2481e-03, 1.6706e-03, 3.0894e-03, 1.3981e-02,
        2.1270e-03, 5.0242e-03, 5.1207e-03, 1.1008e-02, 8.2155e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,462][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([7.0071e-02, 8.8832e-05, 4.8391e-04, 1.3683e-04, 2.3013e-04, 9.7012e-03,
        4.0690e-03, 4.2409e-03, 3.6328e-02, 1.4710e-02, 1.2442e-01, 1.0510e-01,
        1.8849e-02, 1.5184e-01, 5.4693e-02, 1.7921e-01, 2.2583e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,463][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.7344e-03, 1.5333e-05, 9.3634e-05, 8.5648e-05, 6.8149e-05, 6.6332e-03,
        1.4108e-03, 4.1203e-03, 3.0480e-02, 2.8670e-02, 1.3115e-01, 6.7788e-02,
        1.5222e-02, 2.0679e-01, 2.9159e-02, 1.3595e-01, 3.3963e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,466][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:30,470][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[5447],
        [ 511],
        [ 127],
        [3085],
        [ 771],
        [ 207],
        [ 646],
        [ 100],
        [ 238],
        [  94],
        [ 501],
        [ 867],
        [ 172],
        [ 176],
        [ 456],
        [ 189],
        [ 452]], device='cuda:0')
[2024-07-24 10:31:30,472][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[5353],
        [ 932],
        [ 361],
        [7643],
        [2208],
        [ 765],
        [1738],
        [ 291],
        [ 735],
        [ 520],
        [1882],
        [1782],
        [ 539],
        [ 573],
        [1460],
        [ 864],
        [1388]], device='cuda:0')
[2024-07-24 10:31:30,475][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[45643],
        [44490],
        [39570],
        [38917],
        [35860],
        [32250],
        [30864],
        [28761],
        [28343],
        [27997],
        [28266],
        [27721],
        [27269],
        [28655],
        [28283],
        [27451],
        [28452]], device='cuda:0')
[2024-07-24 10:31:30,476][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[25375],
        [30433],
        [27355],
        [35236],
        [33186],
        [32291],
        [31003],
        [29392],
        [28687],
        [28644],
        [28358],
        [28894],
        [28861],
        [28509],
        [27826],
        [27434],
        [27088]], device='cuda:0')
[2024-07-24 10:31:30,478][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 940],
        [1205],
        [1165],
        [1414],
        [1370],
        [1545],
        [1701],
        [1708],
        [1727],
        [1749],
        [1775],
        [1804],
        [1828],
        [1833],
        [1839],
        [1860],
        [1841]], device='cuda:0')
[2024-07-24 10:31:30,479][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[40614],
        [ 7625],
        [10049],
        [ 8001],
        [ 7364],
        [ 6261],
        [ 5970],
        [ 6835],
        [ 7468],
        [ 7257],
        [ 9151],
        [ 8836],
        [ 8973],
        [ 8099],
        [ 8027],
        [ 8274],
        [ 7216]], device='cuda:0')
[2024-07-24 10:31:30,482][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[20595],
        [14849],
        [12766],
        [12053],
        [12331],
        [11826],
        [11101],
        [11540],
        [11685],
        [11704],
        [11700],
        [11820],
        [11847],
        [11994],
        [12201],
        [12238],
        [12368]], device='cuda:0')
[2024-07-24 10:31:30,485][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[3406],
        [1363],
        [1170],
        [1290],
        [2070],
        [1608],
        [2154],
        [2105],
        [2093],
        [2152],
        [2176],
        [2184],
        [2244],
        [2344],
        [2247],
        [2389],
        [2356]], device='cuda:0')
[2024-07-24 10:31:30,487][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 2725],
        [ 9996],
        [13999],
        [41150],
        [35279],
        [18813],
        [25731],
        [25092],
        [22437],
        [28931],
        [27941],
        [38278],
        [35656],
        [31086],
        [29172],
        [31425],
        [29662]], device='cuda:0')
[2024-07-24 10:31:30,489][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[40832],
        [20960],
        [38197],
        [35646],
        [34549],
        [34449],
        [32145],
        [33353],
        [33127],
        [34299],
        [34082],
        [33428],
        [33887],
        [33453],
        [33614],
        [33588],
        [33249]], device='cuda:0')
[2024-07-24 10:31:30,491][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[19875],
        [20855],
        [23634],
        [21687],
        [21636],
        [20627],
        [20464],
        [21176],
        [20027],
        [20298],
        [20047],
        [20016],
        [20891],
        [19953],
        [20421],
        [20090],
        [19932]], device='cuda:0')
[2024-07-24 10:31:30,492][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[18949],
        [11767],
        [12715],
        [13821],
        [13944],
        [14509],
        [14691],
        [14544],
        [14199],
        [14379],
        [14153],
        [14181],
        [14565],
        [14482],
        [14283],
        [14131],
        [14002]], device='cuda:0')
[2024-07-24 10:31:30,494][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[36516],
        [16499],
        [28233],
        [26518],
        [27212],
        [32607],
        [32151],
        [33287],
        [32250],
        [31213],
        [20283],
        [21788],
        [19782],
        [20713],
        [20726],
        [21130],
        [21611]], device='cuda:0')
[2024-07-24 10:31:30,497][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[13599],
        [ 6920],
        [ 2537],
        [ 3412],
        [ 2848],
        [ 4990],
        [ 5086],
        [ 2582],
        [ 1439],
        [  331],
        [ 1004],
        [  637],
        [  588],
        [ 1758],
        [ 1151],
        [ 1629],
        [ 1908]], device='cuda:0')
[2024-07-24 10:31:30,499][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[14440],
        [ 9542],
        [10530],
        [ 6272],
        [ 7312],
        [ 7264],
        [ 8392],
        [ 8010],
        [ 9375],
        [ 9249],
        [ 9491],
        [11701],
        [10819],
        [10649],
        [12187],
        [ 9447],
        [10851]], device='cuda:0')
[2024-07-24 10:31:30,502][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[18549],
        [18400],
        [18415],
        [18288],
        [17895],
        [17755],
        [17189],
        [17361],
        [16787],
        [16922],
        [17423],
        [16108],
        [16048],
        [16708],
        [13501],
        [15697],
        [15801]], device='cuda:0')
[2024-07-24 10:31:30,504][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 5580],
        [22661],
        [21148],
        [ 4648],
        [ 3755],
        [ 2070],
        [ 2072],
        [ 1305],
        [ 1539],
        [ 2324],
        [ 2742],
        [12912],
        [ 7018],
        [11420],
        [14827],
        [14646],
        [13629]], device='cuda:0')
[2024-07-24 10:31:30,505][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[19870],
        [35551],
        [33920],
        [36641],
        [40084],
        [40163],
        [37405],
        [36686],
        [36942],
        [35011],
        [34501],
        [37462],
        [38353],
        [35784],
        [33604],
        [34697],
        [36507]], device='cuda:0')
[2024-07-24 10:31:30,507][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[11601],
        [32345],
        [36758],
        [24574],
        [37545],
        [36853],
        [43649],
        [39801],
        [41628],
        [31374],
        [34238],
        [33559],
        [38251],
        [34530],
        [39445],
        [40941],
        [39421]], device='cuda:0')
[2024-07-24 10:31:30,509][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[33021],
        [ 1160],
        [  927],
        [  966],
        [  827],
        [ 1754],
        [ 1791],
        [ 1588],
        [ 1810],
        [ 1356],
        [ 1266],
        [ 1042],
        [ 1035],
        [ 5892],
        [ 6133],
        [ 4453],
        [ 6604]], device='cuda:0')
[2024-07-24 10:31:30,511][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[38296],
        [35360],
        [36480],
        [35585],
        [34945],
        [31930],
        [30018],
        [26181],
        [28386],
        [19328],
        [18671],
        [20200],
        [17930],
        [19181],
        [14623],
        [15167],
        [20129]], device='cuda:0')
[2024-07-24 10:31:30,514][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[21300],
        [20994],
        [20391],
        [16079],
        [19191],
        [21124],
        [16161],
        [19382],
        [20934],
        [17824],
        [20613],
        [15950],
        [18388],
        [20684],
        [19530],
        [17412],
        [20155]], device='cuda:0')
[2024-07-24 10:31:30,516][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 2727],
        [34813],
        [11101],
        [11070],
        [11249],
        [25845],
        [25804],
        [34597],
        [27315],
        [26489],
        [20975],
        [22775],
        [21949],
        [11542],
        [12138],
        [12693],
        [17138]], device='cuda:0')
[2024-07-24 10:31:30,519][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 4581],
        [ 5682],
        [11751],
        [ 5957],
        [ 7041],
        [ 6467],
        [ 4931],
        [ 6561],
        [ 5089],
        [ 5243],
        [ 5320],
        [ 5060],
        [10766],
        [ 5128],
        [ 8297],
        [ 6452],
        [ 5053]], device='cuda:0')
[2024-07-24 10:31:30,520][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[35708],
        [32063],
        [34587],
        [34297],
        [33756],
        [33650],
        [30440],
        [31448],
        [34880],
        [35486],
        [34620],
        [31463],
        [26647],
        [33998],
        [22616],
        [24202],
        [31010]], device='cuda:0')
[2024-07-24 10:31:30,522][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 8365],
        [11214],
        [ 3455],
        [ 3287],
        [ 2818],
        [ 7783],
        [ 8436],
        [ 9925],
        [12613],
        [11045],
        [ 6136],
        [ 3889],
        [ 4148],
        [ 5083],
        [ 5852],
        [ 7877],
        [ 8729]], device='cuda:0')
[2024-07-24 10:31:30,523][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[16597],
        [19758],
        [21820],
        [21365],
        [18518],
        [21034],
        [17632],
        [19081],
        [23804],
        [21051],
        [23328],
        [16580],
        [19345],
        [24307],
        [24079],
        [25879],
        [32051]], device='cuda:0')
[2024-07-24 10:31:30,526][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[28554],
        [16995],
        [24813],
        [34875],
        [30850],
        [26637],
        [29584],
        [27262],
        [23354],
        [30642],
        [32453],
        [33577],
        [32596],
        [30259],
        [32024],
        [30718],
        [24101]], device='cuda:0')
[2024-07-24 10:31:30,528][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[31846],
        [38727],
        [36726],
        [42279],
        [40493],
        [36704],
        [32632],
        [37717],
        [37462],
        [39086],
        [38328],
        [36620],
        [33443],
        [38176],
        [33630],
        [35705],
        [34802]], device='cuda:0')
[2024-07-24 10:31:30,531][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[32093],
        [32093],
        [32093],
        [32093],
        [32093],
        [32093],
        [32093],
        [32093],
        [32093],
        [32093],
        [32093],
        [32093],
        [32093],
        [32093],
        [32093],
        [32093],
        [32093]], device='cuda:0')
[2024-07-24 10:31:30,626][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:30,630][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,630][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,631][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,632][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,633][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,634][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,635][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,635][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,636][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,637][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,637][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,638][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:30,639][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.9176, 0.0824], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,640][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.0488, 0.9512], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,640][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.6804, 0.3196], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,641][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.8763, 0.1237], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,642][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.9845, 0.0155], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,642][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.2363, 0.7637], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,645][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.0088, 0.9912], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,648][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.6123, 0.3877], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,652][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.1257, 0.8743], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,653][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.0132, 0.9868], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,654][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.1135, 0.8865], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,654][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.0171, 0.9829], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:30,655][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.9767, 0.0144, 0.0089], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,657][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0298, 0.8364, 0.1337], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,660][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.8151, 0.1372, 0.0477], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,662][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([9.2367e-01, 2.6160e-06, 7.6331e-02], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,666][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9771, 0.0198, 0.0031], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,667][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.6421, 0.2359, 0.1220], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,668][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0018, 0.4055, 0.5927], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,668][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4974, 0.2380, 0.2647], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,669][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0595, 0.2880, 0.6525], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,671][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0043, 0.3074, 0.6883], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,673][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([6.6449e-04, 1.2880e-02, 9.8646e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,677][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0436, 0.5878, 0.3687], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:30,680][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Nathan] are: tensor([0.9809, 0.0062, 0.0075, 0.0054], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,680][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Nathan] are: tensor([0.0684, 0.3981, 0.0775, 0.4560], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,681][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Nathan] are: tensor([0.9203, 0.0463, 0.0190, 0.0144], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,682][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Nathan] are: tensor([2.7871e-01, 4.7972e-06, 7.1726e-01, 4.0225e-03], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,683][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Nathan] are: tensor([0.9212, 0.0342, 0.0064, 0.0383], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,686][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Nathan] are: tensor([0.6691, 0.2074, 0.1129, 0.0106], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,690][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Nathan] are: tensor([0.0007, 0.2417, 0.4446, 0.3129], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,693][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Nathan] are: tensor([0.1720, 0.0608, 0.6975, 0.0697], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,693][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Nathan] are: tensor([0.0864, 0.2272, 0.6386, 0.0478], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,694][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Nathan] are: tensor([0.0033, 0.1891, 0.4151, 0.3924], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,695][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Nathan] are: tensor([6.9671e-05, 1.8724e-03, 9.4167e-01, 5.6392e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,696][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Nathan] are: tensor([0.0083, 0.2818, 0.2280, 0.4819], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:30,698][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.9459, 0.0082, 0.0372, 0.0067, 0.0021], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,701][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.0500, 0.3255, 0.0530, 0.4970, 0.0745], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,704][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.6593, 0.0772, 0.2021, 0.0316, 0.0300], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,706][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ got] are: tensor([2.1484e-01, 6.4098e-06, 7.5911e-01, 2.4264e-02, 1.7837e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,707][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.9258, 0.0269, 0.0053, 0.0322, 0.0097], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,708][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.6553, 0.1751, 0.1302, 0.0103, 0.0291], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,709][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.0003, 0.3103, 0.2658, 0.3145, 0.1091], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,710][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.0376, 0.0804, 0.8058, 0.0657, 0.0105], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,713][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.0242, 0.0888, 0.7057, 0.0901, 0.0911], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,717][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.0021, 0.1381, 0.3351, 0.2797, 0.2451], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,719][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ got] are: tensor([8.8299e-05, 2.6633e-03, 9.1069e-01, 5.9475e-02, 2.7082e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,720][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.0035, 0.1751, 0.1741, 0.2619, 0.3853], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:30,721][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([9.9386e-01, 2.2420e-03, 1.4129e-03, 6.4387e-04, 1.0378e-04, 1.7365e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,722][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0401, 0.3695, 0.0561, 0.3160, 0.0630, 0.1551], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,723][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.7513, 0.1584, 0.0284, 0.0183, 0.0089, 0.0347], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,725][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([9.1362e-01, 6.0733e-06, 8.5013e-03, 1.5128e-03, 9.0884e-05, 7.6265e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,729][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.8979, 0.0334, 0.0059, 0.0297, 0.0110, 0.0221], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,733][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.7892, 0.1032, 0.0193, 0.0024, 0.0038, 0.0820], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,733][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0007, 0.1037, 0.2118, 0.3224, 0.1921, 0.1694], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,734][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.5461, 0.1027, 0.1665, 0.0510, 0.0104, 0.1234], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,735][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0158, 0.2787, 0.4549, 0.1232, 0.0705, 0.0568], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,737][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0013, 0.0996, 0.2331, 0.1981, 0.1733, 0.2945], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,739][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([1.2054e-03, 6.6414e-04, 7.5850e-03, 2.9229e-03, 7.2853e-04, 9.8689e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,742][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0068, 0.2417, 0.1323, 0.2231, 0.2534, 0.1427], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:30,744][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([9.5551e-01, 6.4150e-03, 4.8337e-03, 3.1528e-03, 9.1953e-04, 1.1204e-02,
        1.7966e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,746][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.0166, 0.3048, 0.0323, 0.2543, 0.0208, 0.0749, 0.2963],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,747][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.6599, 0.0245, 0.0596, 0.0487, 0.0270, 0.1375, 0.0427],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,748][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([4.2328e-03, 3.1363e-05, 4.8257e-01, 4.8914e-02, 1.5279e-02, 4.4832e-01,
        6.5861e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,748][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.9078, 0.0221, 0.0043, 0.0241, 0.0074, 0.0157, 0.0186],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,750][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.4071, 0.0458, 0.0356, 0.0059, 0.0108, 0.1214, 0.3734],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,752][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([2.3733e-04, 9.6898e-02, 1.4693e-01, 2.0280e-01, 9.4125e-02, 1.7682e-01,
        2.8219e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,756][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.1727, 0.0657, 0.2583, 0.1195, 0.0243, 0.3433, 0.0162],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,760][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.0715, 0.0392, 0.3730, 0.1368, 0.1595, 0.1399, 0.0800],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,760][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0011, 0.0890, 0.2015, 0.1771, 0.1489, 0.2514, 0.1310],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,761][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([2.6161e-05, 7.9154e-04, 2.9089e-02, 2.2059e-02, 6.4785e-03, 9.1612e-01,
        2.5439e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,762][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0042, 0.1232, 0.1311, 0.1699, 0.2422, 0.1964, 0.1330],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:30,763][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ at] are: tensor([9.2902e-01, 1.1303e-02, 1.0674e-02, 2.4441e-03, 4.1156e-04, 1.1992e-02,
        2.1041e-02, 1.3118e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,766][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0120, 0.3679, 0.0511, 0.2286, 0.0295, 0.0653, 0.1479, 0.0977],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,770][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.6566, 0.1157, 0.0603, 0.0479, 0.0154, 0.0534, 0.0392, 0.0116],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,773][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ at] are: tensor([5.9545e-01, 4.7865e-05, 3.5717e-02, 6.9816e-03, 1.0149e-03, 2.9376e-01,
        2.4229e-03, 6.4605e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,774][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.9192, 0.0189, 0.0031, 0.0182, 0.0059, 0.0126, 0.0148, 0.0074],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,774][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.5086, 0.0912, 0.0199, 0.0046, 0.0069, 0.0834, 0.1586, 0.1268],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,775][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0009, 0.1117, 0.1597, 0.1997, 0.2036, 0.1230, 0.1443, 0.0571],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,776][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.6916, 0.0813, 0.0409, 0.0222, 0.0134, 0.0591, 0.0759, 0.0156],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,778][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0708, 0.2264, 0.2892, 0.1544, 0.0697, 0.0923, 0.0767, 0.0205],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,782][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0008, 0.0841, 0.1767, 0.1499, 0.1254, 0.2096, 0.1052, 0.1482],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,784][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ at] are: tensor([2.1857e-04, 5.7781e-04, 8.7940e-03, 6.6784e-03, 1.8575e-03, 8.3683e-01,
        2.6517e-02, 1.1853e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,787][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0026, 0.1544, 0.1009, 0.1491, 0.1651, 0.1701, 0.1874, 0.0704],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:30,787][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ the] are: tensor([9.9327e-01, 2.1474e-03, 6.4299e-04, 3.4088e-04, 4.7439e-05, 8.2146e-04,
        1.5896e-03, 6.7010e-04, 4.6732e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,788][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0344, 0.3114, 0.0335, 0.2558, 0.0362, 0.0473, 0.1767, 0.0631, 0.0414],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,789][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.7266, 0.0927, 0.0339, 0.0290, 0.0099, 0.0437, 0.0316, 0.0101, 0.0226],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,790][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ the] are: tensor([6.7968e-01, 1.3698e-05, 2.1317e-03, 8.3662e-04, 1.0645e-04, 3.1080e-02,
        1.1253e-03, 2.0492e-02, 2.6454e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,793][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.9123, 0.0168, 0.0033, 0.0173, 0.0060, 0.0114, 0.0148, 0.0073, 0.0109],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,798][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.6954, 0.0308, 0.0032, 0.0010, 0.0018, 0.0210, 0.0602, 0.0450, 0.1417],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,800][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0017, 0.0920, 0.1050, 0.2031, 0.1317, 0.0883, 0.1785, 0.0845, 0.1151],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,801][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.6033, 0.0878, 0.1115, 0.0362, 0.0075, 0.0744, 0.0148, 0.0396, 0.0248],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,801][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0905, 0.1814, 0.2969, 0.1115, 0.0926, 0.0847, 0.0590, 0.0265, 0.0570],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,802][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0008, 0.0681, 0.1488, 0.1269, 0.1096, 0.1840, 0.0913, 0.1284, 0.1422],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,804][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ the] are: tensor([1.3884e-03, 3.8196e-04, 8.1868e-04, 1.2893e-03, 2.1232e-04, 1.4894e-01,
        5.7746e-03, 3.9557e-02, 8.0164e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,807][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0055, 0.1699, 0.1192, 0.1214, 0.1533, 0.1156, 0.1747, 0.0824, 0.0581],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:30,809][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([9.8871e-01, 1.3990e-03, 6.2491e-04, 3.1818e-04, 6.1533e-05, 7.4593e-04,
        1.3035e-03, 1.5979e-03, 3.9941e-04, 4.8367e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,813][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([0.0210, 0.3345, 0.0199, 0.2325, 0.0228, 0.0456, 0.1733, 0.0526, 0.0191,
        0.0787], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,814][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([9.8251e-01, 3.2893e-03, 1.1201e-03, 1.5436e-03, 7.5329e-04, 1.9588e-03,
        1.9441e-03, 5.6736e-04, 1.1817e-03, 5.1281e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,815][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([4.9072e-02, 1.2892e-04, 8.2993e-02, 2.2833e-02, 6.1816e-03, 3.2843e-01,
        2.6271e-03, 7.4598e-02, 4.2860e-01, 4.5382e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,816][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([0.8984, 0.0172, 0.0036, 0.0193, 0.0061, 0.0116, 0.0145, 0.0070, 0.0110,
        0.0112], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,818][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([0.7374, 0.0239, 0.0044, 0.0013, 0.0029, 0.0173, 0.0524, 0.0424, 0.0771,
        0.0409], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,821][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.0009, 0.1125, 0.0707, 0.2566, 0.1093, 0.0827, 0.0875, 0.0732, 0.1196,
        0.0870], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,825][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([0.2934, 0.1022, 0.1260, 0.0267, 0.0069, 0.2030, 0.0271, 0.1092, 0.0986,
        0.0069], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,829][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.1373, 0.1210, 0.1968, 0.1270, 0.0359, 0.0607, 0.0916, 0.0213, 0.0307,
        0.1776], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,830][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([0.0007, 0.0597, 0.1273, 0.1157, 0.0944, 0.1618, 0.0828, 0.1214, 0.1332,
        0.1029], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,830][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([2.3750e-05, 1.0418e-04, 1.9249e-03, 6.5492e-04, 4.1157e-04, 2.0683e-01,
        1.9103e-03, 3.0149e-02, 7.0595e-01, 5.2044e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,831][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([0.0029, 0.0970, 0.0804, 0.1257, 0.2144, 0.1187, 0.1364, 0.0554, 0.0562,
        0.1128], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:30,833][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.9328e-01, 1.2124e-03, 2.4690e-04, 3.5731e-04, 3.6075e-05, 3.2458e-04,
        7.4181e-04, 3.6265e-04, 1.4888e-04, 2.3010e-03, 9.8673e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,836][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0251, 0.3992, 0.0275, 0.1558, 0.0174, 0.0337, 0.1497, 0.0288, 0.0224,
        0.0735, 0.0668], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,840][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9322, 0.0199, 0.0037, 0.0114, 0.0025, 0.0045, 0.0081, 0.0009, 0.0013,
        0.0089, 0.0065], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,842][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([8.0233e-01, 7.1418e-06, 2.3600e-04, 1.5011e-04, 2.9635e-05, 6.7564e-03,
        8.3478e-04, 4.0871e-03, 5.0471e-02, 1.5081e-03, 1.3359e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,843][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.8985, 0.0154, 0.0032, 0.0182, 0.0060, 0.0110, 0.0142, 0.0071, 0.0109,
        0.0097, 0.0059], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,844][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.6960, 0.0416, 0.0047, 0.0010, 0.0014, 0.0137, 0.0303, 0.0329, 0.0847,
        0.0244, 0.0693], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,845][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0009, 0.0781, 0.0984, 0.3019, 0.0989, 0.0653, 0.0919, 0.0458, 0.0784,
        0.0809, 0.0595], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,848][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.7890, 0.0379, 0.0201, 0.0038, 0.0063, 0.0597, 0.0141, 0.0113, 0.0254,
        0.0212, 0.0112], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,852][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1493, 0.1715, 0.0832, 0.1751, 0.0840, 0.0361, 0.0426, 0.0107, 0.0143,
        0.0786, 0.1546], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,855][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0006, 0.0553, 0.1202, 0.1057, 0.0892, 0.1482, 0.0733, 0.1073, 0.1168,
        0.0881, 0.0955], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,856][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([6.2349e-04, 4.8043e-05, 4.6122e-05, 8.8295e-05, 1.6023e-05, 1.4109e-02,
        5.5072e-04, 3.4295e-03, 6.8002e-02, 6.1187e-03, 9.0697e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,857][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0063, 0.1076, 0.0504, 0.0851, 0.2285, 0.1312, 0.1099, 0.0499, 0.0437,
        0.1646, 0.0230], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:30,858][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([9.6533e-01, 2.3180e-03, 7.3308e-04, 1.1015e-03, 2.3778e-04, 1.3150e-03,
        1.2122e-03, 2.0739e-03, 6.1627e-04, 1.0037e-02, 3.4123e-03, 1.1608e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,860][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.0061, 0.2289, 0.0298, 0.0917, 0.0214, 0.0415, 0.1201, 0.0423, 0.0195,
        0.0592, 0.0662, 0.2734], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,862][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([9.6715e-01, 4.5815e-03, 3.6367e-04, 2.5067e-03, 7.7608e-04, 1.8279e-03,
        3.1474e-03, 3.0490e-04, 5.5829e-04, 2.6300e-03, 1.8387e-03, 1.4318e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,864][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([1.6560e-01, 2.2920e-04, 5.3578e-02, 5.6363e-02, 9.3191e-03, 1.1172e-01,
        1.0428e-02, 9.2109e-02, 2.8969e-01, 1.1721e-02, 1.8149e-01, 1.7758e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,868][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.8988, 0.0160, 0.0030, 0.0171, 0.0054, 0.0112, 0.0138, 0.0064, 0.0101,
        0.0090, 0.0049, 0.0044], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,869][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.6548, 0.0419, 0.0036, 0.0014, 0.0024, 0.0116, 0.0369, 0.0398, 0.0607,
        0.0167, 0.0502, 0.0801], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,870][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.0006, 0.0488, 0.1105, 0.1356, 0.0864, 0.0674, 0.0731, 0.0415, 0.0716,
        0.0658, 0.0818, 0.2170], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,871][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.3971, 0.0599, 0.0268, 0.0262, 0.0057, 0.0869, 0.0160, 0.1152, 0.1335,
        0.0058, 0.0721, 0.0549], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,874][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.2142, 0.1619, 0.1353, 0.0838, 0.0249, 0.0235, 0.0608, 0.0163, 0.0119,
        0.0425, 0.1100, 0.1149], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,878][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.0005, 0.0491, 0.1078, 0.0935, 0.0764, 0.1344, 0.0659, 0.0975, 0.1063,
        0.0824, 0.0884, 0.0976], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,881][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([1.0522e-04, 3.4551e-05, 2.2490e-04, 2.1706e-04, 1.2448e-04, 2.2813e-02,
        1.0784e-03, 7.6569e-03, 1.0899e-01, 1.1726e-02, 7.9320e-01, 5.3828e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,882][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.0016, 0.0988, 0.0647, 0.1502, 0.1286, 0.0962, 0.1045, 0.0547, 0.0498,
        0.1041, 0.0577, 0.0892], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:30,883][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([9.7658e-01, 6.7933e-04, 7.4533e-04, 6.8301e-04, 1.5234e-04, 2.0958e-03,
        2.2687e-03, 2.2710e-03, 4.5902e-04, 3.9415e-03, 1.8710e-03, 6.1252e-03,
        2.1263e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,884][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0377, 0.2004, 0.0286, 0.1927, 0.0157, 0.0381, 0.1759, 0.0408, 0.0220,
        0.0721, 0.0474, 0.1174, 0.0112], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,886][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.7098, 0.0056, 0.0050, 0.0368, 0.0148, 0.0434, 0.0217, 0.0038, 0.0046,
        0.0516, 0.0137, 0.0730, 0.0160], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,888][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([5.8854e-02, 2.8519e-05, 3.8571e-02, 1.0511e-02, 3.4198e-03, 2.3076e-01,
        2.8367e-03, 6.2236e-02, 3.8050e-01, 3.9959e-03, 2.0162e-01, 6.3795e-03,
        2.8870e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,892][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.9235, 0.0123, 0.0019, 0.0117, 0.0043, 0.0084, 0.0099, 0.0052, 0.0078,
        0.0060, 0.0036, 0.0030, 0.0023], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,895][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.6449, 0.0188, 0.0029, 0.0011, 0.0040, 0.0202, 0.0281, 0.0324, 0.0555,
        0.0205, 0.0357, 0.0892, 0.0468], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,895][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0005, 0.0462, 0.1402, 0.1100, 0.0904, 0.0574, 0.0716, 0.0614, 0.0708,
        0.0787, 0.0785, 0.1612, 0.0331], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,896][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.3902, 0.0607, 0.0593, 0.0137, 0.0075, 0.0781, 0.0134, 0.0466, 0.0677,
        0.0238, 0.0575, 0.0627, 0.1187], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,898][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.2040, 0.0479, 0.1057, 0.0641, 0.0329, 0.0273, 0.0641, 0.0294, 0.0154,
        0.0485, 0.1321, 0.0519, 0.1765], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,901][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0004, 0.0443, 0.1024, 0.0894, 0.0745, 0.1323, 0.0602, 0.0932, 0.1002,
        0.0755, 0.0821, 0.0884, 0.0571], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,903][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([1.1472e-05, 1.1454e-05, 1.7138e-04, 9.6539e-05, 4.5335e-05, 2.1271e-02,
        3.0525e-04, 4.0881e-03, 7.3989e-02, 5.0505e-03, 8.3384e-01, 5.7216e-02,
        3.9011e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,908][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0032, 0.0978, 0.0540, 0.1131, 0.1326, 0.0900, 0.1023, 0.0425, 0.0323,
        0.0932, 0.0504, 0.0797, 0.1089], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:30,908][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.9432e-01, 5.1720e-04, 1.5429e-04, 1.6172e-04, 1.9521e-05, 1.5344e-04,
        2.9535e-04, 1.7464e-04, 5.5763e-05, 5.9916e-04, 4.0110e-04, 1.6277e-03,
        4.0061e-04, 1.1170e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,909][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0520, 0.1656, 0.0267, 0.2055, 0.0223, 0.0418, 0.1160, 0.0250, 0.0223,
        0.0833, 0.0475, 0.1461, 0.0139, 0.0319], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,910][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([9.6640e-01, 4.4436e-03, 6.7754e-04, 6.4950e-03, 1.9716e-03, 2.5436e-03,
        2.5624e-03, 3.9810e-04, 4.0008e-04, 3.3635e-03, 1.5761e-03, 5.7190e-03,
        1.1206e-03, 2.3243e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,912][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([9.3476e-01, 1.7672e-05, 1.1727e-04, 1.2018e-04, 1.5875e-05, 1.7320e-03,
        4.0612e-04, 1.1977e-03, 1.3663e-02, 4.7955e-04, 2.1426e-02, 3.3978e-03,
        1.2631e-04, 2.2541e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,915][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.8950, 0.0145, 0.0026, 0.0160, 0.0055, 0.0110, 0.0132, 0.0065, 0.0098,
        0.0083, 0.0050, 0.0039, 0.0029, 0.0058], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,917][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([8.7376e-01, 9.9624e-03, 1.1495e-03, 5.7355e-04, 8.3996e-04, 4.5698e-03,
        6.9237e-03, 7.2372e-03, 1.4247e-02, 5.2514e-03, 1.2950e-02, 3.1685e-02,
        1.2723e-02, 1.8132e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,921][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0015, 0.0714, 0.0823, 0.2772, 0.0884, 0.0494, 0.0781, 0.0291, 0.0542,
        0.0526, 0.0440, 0.1182, 0.0298, 0.0239], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,922][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.4938, 0.0543, 0.0114, 0.0053, 0.0064, 0.0427, 0.0247, 0.0160, 0.0225,
        0.0193, 0.0223, 0.1145, 0.0688, 0.0979], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,923][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1856, 0.1828, 0.0992, 0.0919, 0.0271, 0.0162, 0.0434, 0.0079, 0.0099,
        0.0461, 0.1090, 0.0681, 0.0540, 0.0589], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,925][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0004, 0.0425, 0.0961, 0.0815, 0.0717, 0.1206, 0.0554, 0.0831, 0.0906,
        0.0689, 0.0737, 0.0805, 0.0531, 0.0818], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,927][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([4.4271e-03, 2.9117e-05, 1.3902e-05, 3.4308e-05, 6.1308e-06, 3.2556e-03,
        2.2397e-04, 1.3881e-03, 2.0249e-02, 1.3351e-03, 2.0751e-01, 5.7996e-02,
        2.1698e-03, 7.0136e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,930][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0037, 0.0807, 0.0589, 0.0778, 0.1191, 0.0913, 0.1114, 0.0325, 0.0434,
        0.1143, 0.0410, 0.0668, 0.1092, 0.0499], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:30,932][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ give] are: tensor([9.1824e-01, 3.7491e-03, 1.5544e-03, 1.4168e-03, 2.3227e-04, 2.5348e-03,
        5.0793e-03, 1.7063e-03, 9.5974e-04, 1.7788e-02, 4.8051e-03, 2.9519e-02,
        2.2353e-03, 6.9272e-03, 3.2554e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,934][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0468, 0.1827, 0.0258, 0.1878, 0.0183, 0.0369, 0.0681, 0.0335, 0.0234,
        0.1043, 0.0575, 0.1605, 0.0074, 0.0205, 0.0265], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,935][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.8261, 0.0189, 0.0070, 0.0137, 0.0041, 0.0173, 0.0106, 0.0011, 0.0031,
        0.0168, 0.0122, 0.0299, 0.0079, 0.0161, 0.0153], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,936][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ give] are: tensor([1.2756e-01, 2.9067e-05, 1.1280e-02, 6.4784e-03, 9.6690e-04, 1.1871e-01,
        1.7986e-03, 3.1902e-02, 2.9418e-01, 3.9533e-03, 2.5984e-01, 1.1307e-02,
        3.5393e-04, 1.2358e-01, 8.0534e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,937][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.9055, 0.0129, 0.0023, 0.0131, 0.0046, 0.0100, 0.0114, 0.0057, 0.0084,
        0.0068, 0.0040, 0.0036, 0.0027, 0.0050, 0.0040], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,939][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.5335, 0.0165, 0.0045, 0.0010, 0.0019, 0.0160, 0.0242, 0.0271, 0.0703,
        0.0222, 0.0455, 0.0640, 0.0377, 0.0903, 0.0453], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,943][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0010, 0.0522, 0.0698, 0.1793, 0.0804, 0.0592, 0.0615, 0.0347, 0.0563,
        0.0558, 0.0923, 0.1498, 0.0169, 0.0252, 0.0655], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,946][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0647, 0.0765, 0.1031, 0.0127, 0.0049, 0.1746, 0.0164, 0.0627, 0.0946,
        0.0135, 0.0756, 0.0676, 0.0592, 0.1633, 0.0105], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,948][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0248, 0.0556, 0.1549, 0.1097, 0.0564, 0.0541, 0.0556, 0.0164, 0.0229,
        0.0763, 0.1490, 0.0665, 0.0645, 0.0818, 0.0116], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,949][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0004, 0.0406, 0.0927, 0.0809, 0.0708, 0.1122, 0.0531, 0.0786, 0.0858,
        0.0650, 0.0691, 0.0762, 0.0492, 0.0755, 0.0501], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,950][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ give] are: tensor([5.8594e-06, 4.9084e-06, 4.5471e-05, 3.0266e-05, 8.3232e-06, 1.1503e-02,
        1.5619e-04, 1.4842e-03, 3.1728e-02, 1.5328e-03, 2.6669e-01, 2.4517e-02,
        1.7877e-03, 6.5068e-01, 9.8209e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,952][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0017, 0.0798, 0.0463, 0.0893, 0.1071, 0.0850, 0.0726, 0.0407, 0.0429,
        0.1012, 0.0377, 0.0916, 0.0962, 0.0379, 0.0698], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:30,954][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ it] are: tensor([9.7894e-01, 3.7606e-04, 1.0903e-04, 3.8837e-04, 7.1309e-05, 8.5177e-04,
        1.5657e-03, 8.3439e-04, 2.5772e-04, 4.1615e-03, 8.6843e-04, 5.0739e-03,
        1.3794e-03, 2.6121e-03, 6.1441e-04, 1.9010e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,958][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.0355, 0.1092, 0.0154, 0.1718, 0.0152, 0.0374, 0.0823, 0.0385, 0.0291,
        0.0670, 0.0707, 0.1352, 0.0170, 0.0374, 0.0346, 0.1037],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,961][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ it] are: tensor([8.9891e-01, 1.8650e-03, 1.1624e-03, 1.5952e-02, 3.7633e-03, 1.4464e-02,
        7.7359e-03, 8.9699e-04, 1.0033e-03, 7.9986e-03, 3.1073e-03, 2.1476e-02,
        4.2913e-03, 5.2219e-03, 4.5911e-03, 7.5624e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,962][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ it] are: tensor([2.4058e-01, 1.8596e-05, 1.3624e-03, 5.3186e-04, 1.2127e-04, 2.2271e-02,
        1.2204e-03, 1.3048e-02, 1.5446e-01, 2.8563e-03, 2.9390e-01, 1.4046e-02,
        5.9082e-04, 1.7629e-01, 1.4019e-02, 6.4694e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,963][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.9138, 0.0110, 0.0020, 0.0118, 0.0042, 0.0089, 0.0100, 0.0052, 0.0075,
        0.0059, 0.0035, 0.0031, 0.0023, 0.0043, 0.0037, 0.0028],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,963][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ it] are: tensor([7.0983e-01, 6.9481e-03, 1.2139e-03, 8.0502e-04, 6.8797e-04, 9.0757e-03,
        1.2382e-02, 1.6885e-02, 3.4799e-02, 6.7649e-03, 1.7881e-02, 4.7023e-02,
        1.4903e-02, 2.8499e-02, 1.6625e-02, 7.5676e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,966][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.0005, 0.0176, 0.0456, 0.1029, 0.0604, 0.0760, 0.0595, 0.0461, 0.0829,
        0.0645, 0.0596, 0.1414, 0.0262, 0.0293, 0.1187, 0.0690],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,969][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.3691, 0.0780, 0.0501, 0.0236, 0.0051, 0.0703, 0.0139, 0.0391, 0.0308,
        0.0188, 0.0438, 0.0652, 0.0652, 0.0842, 0.0092, 0.0334],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,973][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0565, 0.0558, 0.0935, 0.1082, 0.0407, 0.0343, 0.0485, 0.0113, 0.0126,
        0.0833, 0.1668, 0.0775, 0.0782, 0.0878, 0.0153, 0.0299],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,974][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.0004, 0.0363, 0.0864, 0.0754, 0.0638, 0.1082, 0.0503, 0.0775, 0.0827,
        0.0621, 0.0661, 0.0711, 0.0462, 0.0727, 0.0466, 0.0542],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,975][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ it] are: tensor([3.2830e-05, 3.6126e-06, 8.8436e-06, 9.7616e-06, 2.8864e-06, 3.9157e-03,
        7.0056e-05, 6.0505e-04, 1.4985e-02, 6.4735e-04, 1.7029e-01, 1.9404e-02,
        9.1237e-04, 6.9975e-01, 7.7710e-03, 8.1596e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,976][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.0014, 0.0686, 0.0561, 0.0663, 0.1141, 0.0857, 0.0820, 0.0395, 0.0347,
        0.0964, 0.0387, 0.0607, 0.0982, 0.0411, 0.0660, 0.0505],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:30,978][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.9282e-01, 4.7697e-04, 1.2367e-04, 1.1631e-04, 1.8213e-05, 1.5995e-04,
        3.1426e-04, 1.6882e-04, 6.7550e-05, 6.6957e-04, 3.9566e-04, 1.7101e-03,
        2.9920e-04, 9.2694e-04, 1.7235e-04, 4.4953e-04, 1.1085e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,981][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0839, 0.1223, 0.0183, 0.1843, 0.0227, 0.0334, 0.0855, 0.0222, 0.0173,
        0.1033, 0.0411, 0.1053, 0.0106, 0.0209, 0.0290, 0.0787, 0.0212],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,983][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([9.5552e-01, 5.9663e-03, 9.6685e-04, 4.5661e-03, 1.7947e-03, 3.2229e-03,
        1.8922e-03, 3.6742e-04, 6.2113e-04, 2.0224e-03, 2.2112e-03, 5.4469e-03,
        1.4122e-03, 3.4518e-03, 2.1129e-03, 2.6900e-03, 5.7333e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,986][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([8.6968e-01, 1.5864e-05, 7.2559e-05, 7.7735e-05, 1.3206e-05, 1.0020e-03,
        4.4105e-04, 8.2252e-04, 8.7562e-03, 4.2412e-04, 1.2205e-02, 2.2539e-03,
        1.0076e-04, 1.5451e-02, 1.7588e-03, 1.4347e-02, 7.2582e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,987][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.8889, 0.0149, 0.0026, 0.0149, 0.0051, 0.0108, 0.0118, 0.0059, 0.0085,
        0.0074, 0.0045, 0.0037, 0.0027, 0.0053, 0.0043, 0.0034, 0.0054],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,988][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([7.5869e-01, 8.5461e-03, 1.2585e-03, 6.5768e-04, 7.7776e-04, 6.7767e-03,
        9.0258e-03, 1.0987e-02, 2.0720e-02, 5.4077e-03, 1.2791e-02, 2.8501e-02,
        1.3532e-02, 2.1268e-02, 1.0981e-02, 4.3433e-02, 4.6650e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,989][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0023, 0.0539, 0.0507, 0.1853, 0.0679, 0.0368, 0.0602, 0.0277, 0.0510,
        0.0576, 0.0479, 0.1107, 0.0205, 0.0246, 0.0994, 0.0482, 0.0554],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,990][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.4817, 0.0415, 0.0090, 0.0050, 0.0064, 0.0370, 0.0197, 0.0132, 0.0211,
        0.0159, 0.0199, 0.0940, 0.0468, 0.0647, 0.0096, 0.0286, 0.0858],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,993][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0663, 0.1400, 0.1136, 0.0753, 0.0290, 0.0194, 0.0234, 0.0078, 0.0142,
        0.0287, 0.1421, 0.0560, 0.0501, 0.0800, 0.0152, 0.0219, 0.1171],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,996][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0004, 0.0352, 0.0793, 0.0695, 0.0601, 0.1012, 0.0464, 0.0703, 0.0765,
        0.0585, 0.0617, 0.0673, 0.0444, 0.0678, 0.0436, 0.0510, 0.0667],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:30,998][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([2.6452e-03, 2.2691e-05, 9.6251e-06, 2.2460e-05, 4.4417e-06, 2.2557e-03,
        1.2727e-04, 7.5447e-04, 1.0220e-02, 8.8335e-04, 9.2414e-02, 2.9806e-02,
        9.9401e-04, 3.0308e-01, 4.7058e-03, 6.3386e-02, 4.8867e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:31,001][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0029, 0.0628, 0.0534, 0.0615, 0.1044, 0.0864, 0.0917, 0.0273, 0.0394,
        0.0945, 0.0341, 0.0510, 0.0871, 0.0438, 0.0732, 0.0518, 0.0348],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:31,107][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:31,108][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,109][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,109][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,110][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,111][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,112][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,112][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,113][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,114][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,114][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,115][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,116][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,118][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.9176, 0.0824], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,121][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.0488, 0.9512], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,124][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.8989, 0.1011], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,126][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.9284, 0.0716], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,127][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.5159, 0.4841], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,128][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.2363, 0.7637], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,128][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.0088, 0.9912], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,131][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.2872, 0.7128], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,132][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.5799, 0.4201], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,133][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.0014, 0.9986], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,136][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.1869, 0.8131], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,140][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.0860, 0.9140], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,141][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9767, 0.0144, 0.0089], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,142][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0298, 0.8364, 0.1337], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,142][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.9644, 0.0334, 0.0022], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,143][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([7.7881e-01, 9.7119e-05, 2.2110e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,146][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.6520, 0.3216, 0.0264], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,152][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.6421, 0.2359, 0.1220], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,153][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0018, 0.4055, 0.5927], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,154][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0021, 0.0030, 0.9950], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,154][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.5779, 0.2771, 0.1449], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,156][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([4.6973e-04, 1.4158e-01, 8.5795e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,160][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([8.6476e-04, 1.2884e-04, 9.9901e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,164][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0173, 0.2757, 0.7070], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,165][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Nathan] are: tensor([0.9809, 0.0062, 0.0075, 0.0054], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,165][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Nathan] are: tensor([0.0684, 0.3981, 0.0775, 0.4560], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,166][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Nathan] are: tensor([0.9853, 0.0122, 0.0012, 0.0013], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,167][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Nathan] are: tensor([4.2889e-02, 6.5060e-05, 9.5530e-01, 1.7482e-03], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,170][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Nathan] are: tensor([0.7684, 0.1377, 0.0492, 0.0447], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,176][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Nathan] are: tensor([0.6691, 0.2074, 0.1129, 0.0106], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,177][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Nathan] are: tensor([0.0007, 0.2417, 0.4446, 0.3129], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,177][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Nathan] are: tensor([0.0069, 0.0031, 0.9825, 0.0076], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,178][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Nathan] are: tensor([0.7849, 0.1131, 0.0690, 0.0330], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,182][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Nathan] are: tensor([0.0014, 0.1027, 0.2489, 0.6470], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,185][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Nathan] are: tensor([2.5532e-05, 1.1047e-05, 9.9158e-01, 8.3876e-03], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,187][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Nathan] are: tensor([0.0074, 0.0933, 0.8046, 0.0947], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,188][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.9459, 0.0082, 0.0372, 0.0067, 0.0021], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,189][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.0500, 0.3255, 0.0530, 0.4970, 0.0745], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,190][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.8996, 0.0537, 0.0315, 0.0074, 0.0077], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,191][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([1.5028e-01, 8.1547e-05, 8.3303e-01, 9.0404e-03, 7.5674e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,197][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.6157, 0.3249, 0.0225, 0.0290, 0.0079], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,199][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.6553, 0.1751, 0.1302, 0.0103, 0.0291], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,200][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.0003, 0.3103, 0.2658, 0.3145, 0.1091], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,201][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.0015, 0.0028, 0.9741, 0.0127, 0.0088], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,203][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.5674, 0.1087, 0.1535, 0.0939, 0.0765], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,208][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.0005, 0.0705, 0.3507, 0.4090, 0.1692], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,211][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([1.5795e-05, 1.2734e-05, 9.8761e-01, 8.6153e-03, 3.7438e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,211][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.0036, 0.1264, 0.3318, 0.1379, 0.4004], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,212][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([9.9386e-01, 2.2420e-03, 1.4129e-03, 6.4387e-04, 1.0378e-04, 1.7365e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,213][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0401, 0.3695, 0.0561, 0.3160, 0.0630, 0.1551], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,215][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([9.5424e-01, 3.8513e-02, 1.5343e-03, 1.6033e-03, 8.8886e-04, 3.2191e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,218][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([9.7580e-01, 1.5111e-06, 1.4940e-05, 2.1457e-06, 1.0684e-06, 2.4182e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,223][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.8115, 0.1230, 0.0252, 0.0115, 0.0052, 0.0237], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,225][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.7892, 0.1032, 0.0193, 0.0024, 0.0038, 0.0820], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,225][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0007, 0.1037, 0.2118, 0.3224, 0.1921, 0.1694], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,226][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0498, 0.0061, 0.1466, 0.0045, 0.0040, 0.7890], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,227][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.5155, 0.2175, 0.0747, 0.0919, 0.0461, 0.0543], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,228][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.5665e-04, 2.5052e-02, 1.8493e-01, 3.0562e-01, 1.4647e-01, 3.3777e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,231][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([6.0156e-04, 4.0188e-06, 7.8218e-04, 8.5475e-05, 2.3024e-05, 9.9850e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,237][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0142, 0.1102, 0.2222, 0.0813, 0.3465, 0.2255], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,237][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([9.5551e-01, 6.4150e-03, 4.8337e-03, 3.1528e-03, 9.1953e-04, 1.1204e-02,
        1.7966e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,238][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0166, 0.3048, 0.0323, 0.2543, 0.0208, 0.0749, 0.2963],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,239][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.9424, 0.0123, 0.0060, 0.0068, 0.0043, 0.0192, 0.0090],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,240][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([4.0709e-02, 4.2678e-05, 9.4822e-03, 5.7621e-04, 6.3414e-04, 9.4100e-01,
        7.5578e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,245][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.1670, 0.2503, 0.1569, 0.0348, 0.0277, 0.0659, 0.2974],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,249][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.4071, 0.0458, 0.0356, 0.0059, 0.0108, 0.1214, 0.3734],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,249][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([2.3733e-04, 9.6898e-02, 1.4693e-01, 2.0280e-01, 9.4125e-02, 1.7682e-01,
        2.8219e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,250][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0153, 0.0082, 0.3185, 0.0089, 0.0150, 0.5717, 0.0625],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,251][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.7165, 0.0288, 0.0387, 0.0602, 0.0407, 0.0379, 0.0773],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,252][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([6.3686e-05, 3.5016e-02, 1.4024e-01, 1.6602e-01, 6.0914e-02, 1.9904e-01,
        3.9871e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,255][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([1.1067e-05, 1.6130e-05, 1.1724e-02, 2.5138e-03, 9.1802e-04, 9.7729e-01,
        7.5230e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,261][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0034, 0.0737, 0.2727, 0.0493, 0.2329, 0.1716, 0.1964],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,262][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([9.2902e-01, 1.1303e-02, 1.0674e-02, 2.4441e-03, 4.1156e-04, 1.1992e-02,
        2.1041e-02, 1.3118e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,263][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0120, 0.3679, 0.0511, 0.2286, 0.0295, 0.0653, 0.1479, 0.0977],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,263][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.9123, 0.0508, 0.0066, 0.0067, 0.0026, 0.0095, 0.0093, 0.0022],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,265][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([6.4235e-01, 1.4952e-05, 2.5547e-04, 3.2991e-05, 3.3447e-05, 2.9070e-01,
        1.1245e-02, 5.5367e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,270][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.6639, 0.1098, 0.0697, 0.0241, 0.0106, 0.0231, 0.0921, 0.0066],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,273][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.5086, 0.0912, 0.0199, 0.0046, 0.0069, 0.0834, 0.1586, 0.1268],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,274][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0009, 0.1117, 0.1597, 0.1997, 0.2036, 0.1230, 0.1443, 0.0571],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,275][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0112, 0.0053, 0.1647, 0.0061, 0.0056, 0.6507, 0.0329, 0.1235],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,276][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.4629, 0.1553, 0.0559, 0.0912, 0.0326, 0.0619, 0.1239, 0.0165],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,277][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([7.7165e-05, 8.5897e-02, 2.3793e-01, 2.0069e-01, 4.8632e-02, 2.2998e-01,
        1.4912e-01, 4.7676e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,280][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([1.4768e-04, 4.6241e-06, 8.4526e-04, 2.4311e-04, 6.7784e-05, 7.7753e-01,
        8.0455e-03, 2.1312e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,286][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0053, 0.0956, 0.2323, 0.0781, 0.1801, 0.2006, 0.1405, 0.0676],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,286][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([9.9327e-01, 2.1474e-03, 6.4299e-04, 3.4088e-04, 4.7439e-05, 8.2146e-04,
        1.5896e-03, 6.7010e-04, 4.6732e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,287][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0344, 0.3114, 0.0335, 0.2558, 0.0362, 0.0473, 0.1767, 0.0631, 0.0414],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,288][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.9575, 0.0245, 0.0018, 0.0025, 0.0010, 0.0042, 0.0047, 0.0011, 0.0026],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,289][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([9.2552e-01, 1.6152e-06, 2.6717e-06, 8.0468e-07, 6.4990e-07, 5.3239e-03,
        1.0358e-03, 3.0251e-03, 6.5087e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,294][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.7198, 0.1716, 0.0311, 0.0100, 0.0058, 0.0123, 0.0346, 0.0069, 0.0079],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,298][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.6954, 0.0308, 0.0032, 0.0010, 0.0018, 0.0210, 0.0602, 0.0450, 0.1417],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,299][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0017, 0.0920, 0.1050, 0.2031, 0.1317, 0.0883, 0.1785, 0.0845, 0.1151],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,300][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0888, 0.0042, 0.0398, 0.0017, 0.0017, 0.1855, 0.0209, 0.0523, 0.6051],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,300][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.7724, 0.0610, 0.0195, 0.0285, 0.0154, 0.0208, 0.0500, 0.0086, 0.0238],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,302][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([2.1349e-04, 4.8135e-02, 1.0790e-01, 1.5511e-01, 7.7107e-02, 2.5483e-01,
        1.2245e-01, 6.8151e-02, 1.6610e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,305][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([8.0813e-04, 3.1968e-06, 4.6043e-05, 3.9748e-05, 5.0071e-06, 6.2391e-02,
        1.9385e-03, 4.0456e-02, 8.9431e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,310][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0128, 0.1011, 0.1907, 0.0456, 0.1322, 0.0919, 0.1641, 0.0553, 0.2063],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,311][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([9.8871e-01, 1.3990e-03, 6.2491e-04, 3.1818e-04, 6.1533e-05, 7.4593e-04,
        1.3035e-03, 1.5979e-03, 3.9941e-04, 4.8367e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,312][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([0.0210, 0.3345, 0.0199, 0.2325, 0.0228, 0.0456, 0.1733, 0.0526, 0.0191,
        0.0787], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,313][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([9.9591e-01, 1.5204e-03, 1.0684e-04, 1.9527e-04, 1.3387e-04, 2.8640e-04,
        4.0558e-04, 9.2640e-05, 2.2068e-04, 1.1294e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,314][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([2.2890e-01, 1.6809e-05, 1.9157e-04, 2.0398e-05, 2.8313e-05, 1.2680e-01,
        3.8986e-03, 3.4081e-02, 5.7906e-01, 2.7009e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,319][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([0.6680, 0.1354, 0.0167, 0.0130, 0.0074, 0.0112, 0.0538, 0.0087, 0.0091,
        0.0767], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,323][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([0.7374, 0.0239, 0.0044, 0.0013, 0.0029, 0.0173, 0.0524, 0.0424, 0.0771,
        0.0409], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,324][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([0.0009, 0.1125, 0.0707, 0.2566, 0.1093, 0.0827, 0.0875, 0.0732, 0.1196,
        0.0870], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,324][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([0.0405, 0.0050, 0.0424, 0.0020, 0.0036, 0.1336, 0.0189, 0.0831, 0.5938,
        0.0771], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,325][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([0.8969, 0.0142, 0.0048, 0.0146, 0.0027, 0.0051, 0.0175, 0.0042, 0.0050,
        0.0350], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,327][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([6.5102e-05, 4.6917e-02, 6.3384e-02, 1.8110e-01, 4.8540e-02, 1.1724e-01,
        1.4690e-01, 7.5535e-02, 1.7017e-01, 1.5015e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,331][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([1.8973e-05, 1.8148e-06, 2.6363e-04, 3.3150e-05, 2.5118e-05, 1.1810e-01,
        7.0464e-04, 4.2486e-02, 8.0734e-01, 3.1032e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,335][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([0.0068, 0.0474, 0.1546, 0.0286, 0.0958, 0.1129, 0.1189, 0.0912, 0.2245,
        0.1193], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,336][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.9328e-01, 1.2124e-03, 2.4690e-04, 3.5731e-04, 3.6075e-05, 3.2458e-04,
        7.4181e-04, 3.6265e-04, 1.4888e-04, 2.3010e-03, 9.8673e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,336][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0251, 0.3992, 0.0275, 0.1558, 0.0174, 0.0337, 0.1497, 0.0288, 0.0224,
        0.0735, 0.0668], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,337][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([9.9210e-01, 4.0489e-03, 1.1680e-04, 6.7780e-04, 1.7225e-04, 2.7057e-04,
        8.5504e-04, 6.8734e-05, 9.6965e-05, 1.1248e-03, 4.6802e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,339][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([9.3691e-01, 2.1184e-07, 3.8902e-08, 2.5760e-08, 2.0646e-08, 9.5151e-05,
        9.3332e-05, 7.4269e-05, 1.2695e-03, 1.9815e-04, 6.1356e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,345][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.7951, 0.1095, 0.0136, 0.0143, 0.0041, 0.0078, 0.0203, 0.0031, 0.0046,
        0.0120, 0.0156], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,347][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6960, 0.0416, 0.0047, 0.0010, 0.0014, 0.0137, 0.0303, 0.0329, 0.0847,
        0.0244, 0.0693], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,348][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0009, 0.0781, 0.0984, 0.3019, 0.0989, 0.0653, 0.0919, 0.0458, 0.0784,
        0.0809, 0.0595], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,349][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([4.9294e-02, 3.0067e-03, 8.8670e-03, 5.5764e-04, 4.6924e-04, 4.0332e-02,
        5.9528e-03, 1.3333e-02, 1.3590e-01, 2.1147e-02, 7.2114e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,350][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.7685, 0.0498, 0.0063, 0.0290, 0.0113, 0.0081, 0.0205, 0.0036, 0.0059,
        0.0435, 0.0535], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,351][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([7.9403e-05, 1.7272e-02, 1.0031e-01, 1.8838e-01, 6.1416e-02, 1.7059e-01,
        7.6481e-02, 5.9101e-02, 1.3009e-01, 8.7450e-02, 1.0882e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,355][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([5.9426e-04, 9.2763e-07, 2.4992e-06, 3.6013e-06, 6.1539e-07, 4.5317e-03,
        2.7067e-04, 2.9514e-03, 5.2975e-02, 4.1110e-03, 9.3456e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,359][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0247, 0.0921, 0.1769, 0.0596, 0.0789, 0.0918, 0.1695, 0.0394, 0.1284,
        0.0904, 0.0483], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,360][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([9.6533e-01, 2.3180e-03, 7.3308e-04, 1.1015e-03, 2.3778e-04, 1.3150e-03,
        1.2122e-03, 2.0739e-03, 6.1627e-04, 1.0037e-02, 3.4123e-03, 1.1608e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,361][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.0061, 0.2289, 0.0298, 0.0917, 0.0214, 0.0415, 0.1201, 0.0423, 0.0195,
        0.0592, 0.0662, 0.2734], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,362][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([9.9403e-01, 1.4806e-03, 2.8733e-05, 2.2110e-04, 8.5942e-05, 2.1176e-04,
        5.0961e-04, 4.2264e-05, 9.4338e-05, 5.3875e-04, 3.2118e-04, 2.4379e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,363][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([5.7758e-01, 1.3821e-05, 1.3230e-05, 9.6853e-06, 6.0809e-06, 2.6844e-03,
        1.9474e-03, 3.4079e-03, 2.0819e-02, 5.1792e-03, 2.8624e-01, 1.0210e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,369][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.5520, 0.1291, 0.0217, 0.0229, 0.0132, 0.0185, 0.0916, 0.0106, 0.0083,
        0.0615, 0.0362, 0.0344], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,371][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.6548, 0.0419, 0.0036, 0.0014, 0.0024, 0.0116, 0.0369, 0.0398, 0.0607,
        0.0167, 0.0502, 0.0801], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,372][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.0006, 0.0488, 0.1105, 0.1356, 0.0864, 0.0674, 0.0731, 0.0415, 0.0716,
        0.0658, 0.0818, 0.2170], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,373][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.3194, 0.0086, 0.0110, 0.0026, 0.0028, 0.0336, 0.0150, 0.0267, 0.0924,
        0.0583, 0.3504, 0.0792], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,374][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.8771, 0.0221, 0.0036, 0.0122, 0.0029, 0.0022, 0.0113, 0.0026, 0.0019,
        0.0100, 0.0155, 0.0384], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,375][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([5.5301e-05, 1.8525e-02, 1.0619e-01, 6.5496e-02, 3.1026e-02, 9.9695e-02,
        3.0306e-02, 3.1907e-02, 6.3075e-02, 5.5696e-02, 1.1278e-01, 3.8525e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,379][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([4.9679e-04, 2.8283e-06, 5.2002e-05, 2.3776e-05, 1.6813e-05, 1.1056e-02,
        1.0431e-03, 1.1282e-02, 1.0830e-01, 9.5610e-03, 8.1345e-01, 4.4718e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,383][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.0111, 0.0474, 0.1515, 0.0266, 0.0877, 0.0916, 0.1671, 0.0633, 0.1350,
        0.1154, 0.0652, 0.0379], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,384][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([9.7658e-01, 6.7933e-04, 7.4533e-04, 6.8301e-04, 1.5234e-04, 2.0958e-03,
        2.2687e-03, 2.2710e-03, 4.5902e-04, 3.9415e-03, 1.8710e-03, 6.1252e-03,
        2.1263e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,385][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0377, 0.2004, 0.0286, 0.1927, 0.0157, 0.0381, 0.1759, 0.0408, 0.0220,
        0.0721, 0.0474, 0.1174, 0.0112], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,386][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([9.2425e-01, 4.1904e-03, 7.7018e-04, 6.3927e-03, 3.4319e-03, 8.9825e-03,
        5.8366e-03, 1.0503e-03, 1.4633e-03, 1.4251e-02, 4.0912e-03, 2.1505e-02,
        3.7828e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,387][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([2.1554e-01, 1.2451e-06, 1.4784e-05, 2.4247e-06, 3.7705e-06, 7.5374e-03,
        9.1590e-04, 4.0442e-03, 4.2128e-02, 3.2914e-03, 6.3313e-01, 9.1378e-02,
        2.0107e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,393][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.8407, 0.1177, 0.0045, 0.0053, 0.0016, 0.0025, 0.0051, 0.0012, 0.0012,
        0.0057, 0.0042, 0.0076, 0.0026], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,395][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.6449, 0.0188, 0.0029, 0.0011, 0.0040, 0.0202, 0.0281, 0.0324, 0.0555,
        0.0205, 0.0357, 0.0892, 0.0468], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,396][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0005, 0.0462, 0.1402, 0.1100, 0.0904, 0.0574, 0.0716, 0.0614, 0.0708,
        0.0787, 0.0785, 0.1612, 0.0331], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,397][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0102, 0.0023, 0.0279, 0.0028, 0.0012, 0.0890, 0.0077, 0.0310, 0.1549,
        0.0258, 0.5500, 0.0759, 0.0213], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,398][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.8545, 0.0082, 0.0030, 0.0087, 0.0025, 0.0027, 0.0191, 0.0052, 0.0029,
        0.0173, 0.0221, 0.0302, 0.0237], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,399][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([4.1997e-05, 8.3595e-03, 5.8070e-02, 7.0680e-02, 2.0427e-02, 1.9760e-01,
        3.5839e-02, 6.2066e-02, 9.1370e-02, 5.9728e-02, 1.0405e-01, 2.4480e-01,
        4.6970e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,403][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([1.7773e-05, 4.1526e-07, 3.9712e-05, 1.2801e-05, 5.5968e-06, 1.1962e-02,
        1.7172e-04, 6.5386e-03, 7.8721e-02, 3.4493e-03, 8.5680e-01, 4.0909e-02,
        1.3717e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,407][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0082, 0.0543, 0.1336, 0.0475, 0.0586, 0.1056, 0.1334, 0.0622, 0.1837,
        0.0804, 0.0538, 0.0313, 0.0475], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,408][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.9432e-01, 5.1720e-04, 1.5429e-04, 1.6172e-04, 1.9521e-05, 1.5344e-04,
        2.9535e-04, 1.7464e-04, 5.5763e-05, 5.9916e-04, 4.0110e-04, 1.6277e-03,
        4.0061e-04, 1.1170e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:31,409][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0520, 0.1656, 0.0267, 0.2055, 0.0223, 0.0418, 0.1160, 0.0250, 0.0223,
        0.0833, 0.0475, 0.1461, 0.0139, 0.0319], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:31,410][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([9.9707e-01, 9.0663e-04, 1.8390e-05, 2.9755e-04, 1.1003e-04, 1.1876e-04,
        2.1996e-04, 2.2741e-05, 2.6013e-05, 3.1929e-04, 9.9326e-05, 5.4992e-04,
        7.4358e-05, 1.6231e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:31,412][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.8358e-01, 1.0814e-07, 5.6043e-09, 6.1737e-09, 3.2531e-09, 7.3053e-06,
        1.1545e-05, 7.9338e-06, 1.4084e-04, 1.5284e-05, 3.8967e-03, 3.3271e-03,
        3.4074e-05, 8.9801e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:31,415][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.3843e-01, 2.5760e-02, 3.4695e-03, 7.5923e-03, 8.3797e-04, 2.3442e-03,
        3.4832e-03, 1.0923e-03, 1.1382e-03, 2.5065e-03, 2.3110e-03, 4.7770e-03,
        2.5825e-03, 3.6768e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:31,419][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([8.7376e-01, 9.9624e-03, 1.1495e-03, 5.7355e-04, 8.3996e-04, 4.5698e-03,
        6.9237e-03, 7.2372e-03, 1.4247e-02, 5.2514e-03, 1.2950e-02, 3.1685e-02,
        1.2723e-02, 1.8132e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:31,420][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0015, 0.0714, 0.0823, 0.2772, 0.0884, 0.0494, 0.0781, 0.0291, 0.0542,
        0.0526, 0.0440, 0.1182, 0.0298, 0.0239], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:31,421][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([6.5971e-02, 2.2064e-03, 5.4600e-03, 6.1210e-04, 2.9228e-04, 1.8756e-02,
        3.7112e-03, 8.9843e-03, 5.2719e-02, 1.0072e-02, 3.1219e-01, 6.2702e-02,
        1.7161e-02, 4.3916e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:31,422][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.8618, 0.0226, 0.0025, 0.0097, 0.0021, 0.0017, 0.0106, 0.0012, 0.0020,
        0.0128, 0.0201, 0.0251, 0.0113, 0.0166], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:31,424][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([4.0305e-05, 9.5044e-03, 6.7780e-02, 6.6008e-02, 5.3277e-02, 1.6860e-01,
        2.2830e-02, 3.3331e-02, 8.1340e-02, 4.9000e-02, 7.7973e-02, 2.1704e-01,
        5.9678e-02, 9.3600e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:31,427][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([7.1056e-03, 1.0720e-06, 8.1098e-07, 1.6392e-06, 2.5592e-07, 1.0463e-03,
        1.2286e-04, 1.0005e-03, 1.3958e-02, 8.5890e-04, 1.8931e-01, 6.0880e-02,
        8.1894e-04, 7.2490e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:31,431][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0625, 0.0887, 0.1481, 0.0527, 0.0825, 0.0830, 0.1245, 0.0346, 0.0910,
        0.0722, 0.0418, 0.0357, 0.0368, 0.0459], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:31,432][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([9.1824e-01, 3.7491e-03, 1.5544e-03, 1.4168e-03, 2.3227e-04, 2.5348e-03,
        5.0793e-03, 1.7063e-03, 9.5974e-04, 1.7788e-02, 4.8051e-03, 2.9519e-02,
        2.2353e-03, 6.9272e-03, 3.2554e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:31,433][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0468, 0.1827, 0.0258, 0.1878, 0.0183, 0.0369, 0.0681, 0.0335, 0.0234,
        0.1043, 0.0575, 0.1605, 0.0074, 0.0205, 0.0265], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:31,434][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([9.4984e-01, 1.0842e-02, 1.0083e-03, 2.6461e-03, 9.9091e-04, 3.4128e-03,
        2.9176e-03, 2.3290e-04, 7.8897e-04, 5.3098e-03, 3.0855e-03, 9.4906e-03,
        1.7330e-03, 3.8873e-03, 3.8184e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:31,436][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([5.9969e-02, 4.7832e-07, 1.7939e-06, 4.9059e-07, 5.1634e-07, 2.5083e-03,
        2.8442e-04, 1.1204e-03, 1.6183e-02, 1.1037e-03, 3.4024e-01, 5.9681e-02,
        1.0109e-03, 5.0925e-01, 8.6495e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:31,441][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.9001, 0.0485, 0.0028, 0.0040, 0.0010, 0.0027, 0.0102, 0.0013, 0.0014,
        0.0077, 0.0030, 0.0080, 0.0031, 0.0033, 0.0030], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:31,444][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.5335, 0.0165, 0.0045, 0.0010, 0.0019, 0.0160, 0.0242, 0.0271, 0.0703,
        0.0222, 0.0455, 0.0640, 0.0377, 0.0903, 0.0453], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:31,445][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0010, 0.0522, 0.0698, 0.1793, 0.0804, 0.0592, 0.0615, 0.0347, 0.0563,
        0.0558, 0.0923, 0.1498, 0.0169, 0.0252, 0.0655], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:31,445][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0088, 0.0013, 0.0119, 0.0011, 0.0007, 0.0361, 0.0034, 0.0145, 0.0833,
        0.0144, 0.3842, 0.0459, 0.0149, 0.3555, 0.0241], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:31,447][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.4774, 0.0248, 0.0104, 0.0495, 0.0130, 0.0134, 0.0549, 0.0071, 0.0116,
        0.0681, 0.0675, 0.1063, 0.0315, 0.0518, 0.0128], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:31,449][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([6.4447e-05, 5.8277e-03, 6.7620e-02, 8.1109e-02, 7.9134e-02, 1.3175e-01,
        3.7756e-02, 4.0935e-02, 8.2432e-02, 7.2175e-02, 8.2634e-02, 1.5151e-01,
        4.3324e-02, 7.3250e-02, 5.0485e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:31,453][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([1.9145e-05, 1.8042e-07, 5.7265e-06, 2.5682e-06, 5.7053e-07, 5.3748e-03,
        9.1051e-05, 2.1051e-03, 3.3697e-02, 9.6067e-04, 2.5726e-01, 1.8257e-02,
        5.8123e-04, 6.7281e-01, 8.8349e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:31,455][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0063, 0.0485, 0.1069, 0.0219, 0.0632, 0.0890, 0.0728, 0.0520, 0.1673,
        0.0668, 0.0518, 0.0323, 0.0348, 0.0633, 0.1231], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:31,456][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([9.7894e-01, 3.7606e-04, 1.0903e-04, 3.8837e-04, 7.1309e-05, 8.5177e-04,
        1.5657e-03, 8.3439e-04, 2.5772e-04, 4.1615e-03, 8.6843e-04, 5.0739e-03,
        1.3794e-03, 2.6121e-03, 6.1441e-04, 1.9010e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:31,457][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.0355, 0.1092, 0.0154, 0.1718, 0.0152, 0.0374, 0.0823, 0.0385, 0.0291,
        0.0670, 0.0707, 0.1352, 0.0170, 0.0374, 0.0346, 0.1037],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:31,458][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([9.7603e-01, 1.0248e-03, 1.4405e-04, 2.1522e-03, 7.2246e-04, 2.9249e-03,
        1.8900e-03, 2.1479e-04, 2.8691e-04, 2.4097e-03, 8.9253e-04, 5.9367e-03,
        9.2174e-04, 1.6152e-03, 1.1995e-03, 1.6311e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:31,459][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([4.1654e-01, 1.9514e-07, 9.8900e-08, 2.5802e-08, 3.3846e-08, 2.4836e-04,
        7.9721e-05, 1.8829e-04, 4.3226e-03, 2.4619e-04, 1.7428e-01, 3.2128e-02,
        4.6526e-04, 3.2431e-01, 5.0844e-03, 4.2103e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:31,465][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.7270, 0.0629, 0.0109, 0.0191, 0.0034, 0.0127, 0.0290, 0.0050, 0.0076,
        0.0213, 0.0174, 0.0291, 0.0092, 0.0202, 0.0125, 0.0126],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:31,467][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([7.0983e-01, 6.9481e-03, 1.2139e-03, 8.0502e-04, 6.8797e-04, 9.0757e-03,
        1.2382e-02, 1.6885e-02, 3.4799e-02, 6.7649e-03, 1.7881e-02, 4.7023e-02,
        1.4903e-02, 2.8499e-02, 1.6625e-02, 7.5676e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:31,468][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.0005, 0.0176, 0.0456, 0.1029, 0.0604, 0.0760, 0.0595, 0.0461, 0.0829,
        0.0645, 0.0596, 0.1414, 0.0262, 0.0293, 0.1187, 0.0690],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:31,469][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([1.4767e-02, 3.5360e-04, 2.1725e-03, 2.6113e-04, 1.5241e-04, 1.2868e-02,
        1.5249e-03, 4.9511e-03, 3.9420e-02, 1.1050e-02, 2.9283e-01, 3.8152e-02,
        1.1380e-02, 4.3048e-01, 1.7774e-02, 1.2186e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:31,470][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.6714, 0.0145, 0.0038, 0.0220, 0.0043, 0.0059, 0.0277, 0.0026, 0.0041,
        0.0420, 0.0415, 0.0693, 0.0201, 0.0377, 0.0093, 0.0237],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:31,471][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([4.8989e-05, 2.9353e-03, 5.7125e-02, 6.0079e-02, 3.9476e-02, 1.5890e-01,
        4.9234e-02, 5.3777e-02, 8.3782e-02, 6.9034e-02, 8.6390e-02, 1.2937e-01,
        3.5141e-02, 9.2217e-02, 3.1689e-02, 5.0792e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:31,475][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([4.0365e-05, 6.4113e-08, 3.9001e-07, 3.3293e-07, 9.1019e-08, 1.1494e-03,
        2.8403e-05, 4.4121e-04, 1.0560e-02, 2.9893e-04, 1.4815e-01, 1.5907e-02,
        2.6961e-04, 6.9596e-01, 7.6966e-03, 1.1950e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:31,479][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.0105, 0.0255, 0.0834, 0.0233, 0.0672, 0.0972, 0.0678, 0.0467, 0.1462,
        0.0615, 0.0522, 0.0256, 0.0279, 0.0652, 0.1002, 0.0997],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:31,480][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.9282e-01, 4.7697e-04, 1.2367e-04, 1.1631e-04, 1.8213e-05, 1.5995e-04,
        3.1426e-04, 1.6882e-04, 6.7550e-05, 6.6957e-04, 3.9566e-04, 1.7101e-03,
        2.9920e-04, 9.2694e-04, 1.7235e-04, 4.4953e-04, 1.1085e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:31,481][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0839, 0.1223, 0.0183, 0.1843, 0.0227, 0.0334, 0.0855, 0.0222, 0.0173,
        0.1033, 0.0411, 0.1053, 0.0106, 0.0209, 0.0290, 0.0787, 0.0212],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:31,482][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([9.9570e-01, 1.2420e-03, 2.9320e-05, 2.3785e-04, 1.0877e-04, 1.7178e-04,
        1.8701e-04, 2.3110e-05, 4.5975e-05, 2.3056e-04, 1.6199e-04, 5.9922e-04,
        1.0828e-04, 2.6694e-04, 1.9523e-04, 1.9177e-04, 5.0236e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:31,483][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.6341e-01, 1.2166e-07, 5.3723e-09, 5.8382e-09, 3.9978e-09, 6.5344e-06,
        1.4359e-05, 7.2955e-06, 1.3195e-04, 1.6051e-05, 2.4753e-03, 2.3744e-03,
        2.9801e-05, 6.2542e-03, 2.6169e-04, 2.2309e-03, 2.2783e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:31,487][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.4151e-01, 1.7880e-02, 3.0487e-03, 5.9674e-03, 1.0422e-03, 2.5825e-03,
        4.6809e-03, 7.5138e-04, 8.5211e-04, 2.1628e-03, 1.9296e-03, 4.7407e-03,
        2.1683e-03, 2.8489e-03, 1.9465e-03, 1.6784e-03, 4.2057e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:31,491][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([7.5869e-01, 8.5461e-03, 1.2585e-03, 6.5768e-04, 7.7776e-04, 6.7767e-03,
        9.0258e-03, 1.0987e-02, 2.0720e-02, 5.4077e-03, 1.2791e-02, 2.8501e-02,
        1.3532e-02, 2.1268e-02, 1.0981e-02, 4.3433e-02, 4.6650e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:31,492][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0023, 0.0539, 0.0507, 0.1853, 0.0679, 0.0368, 0.0602, 0.0277, 0.0510,
        0.0576, 0.0479, 0.1107, 0.0205, 0.0246, 0.0994, 0.0482, 0.0554],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:31,493][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([8.9199e-02, 1.7379e-03, 2.9641e-03, 4.2666e-04, 2.5299e-04, 9.7976e-03,
        2.6460e-03, 4.9924e-03, 2.9244e-02, 8.6362e-03, 1.5614e-01, 4.6486e-02,
        1.2541e-02, 2.2989e-01, 1.6209e-02, 1.1030e-01, 2.7855e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:31,494][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.7044, 0.0306, 0.0040, 0.0163, 0.0045, 0.0029, 0.0135, 0.0018, 0.0039,
        0.0159, 0.0388, 0.0386, 0.0186, 0.0296, 0.0110, 0.0131, 0.0525],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:31,495][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([6.5364e-05, 8.0676e-03, 4.6374e-02, 7.0530e-02, 5.0497e-02, 1.2744e-01,
        2.6758e-02, 3.2838e-02, 7.4302e-02, 6.5446e-02, 7.1741e-02, 1.9078e-01,
        5.2472e-02, 6.2783e-02, 2.5849e-02, 4.0603e-02, 5.3450e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:31,499][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([4.6697e-03, 9.7507e-07, 5.6166e-07, 1.0238e-06, 2.0092e-07, 6.6101e-04,
        7.4992e-05, 5.0704e-04, 6.1840e-03, 5.6005e-04, 7.5132e-02, 2.8474e-02,
        3.6552e-04, 2.6465e-01, 4.8567e-03, 1.0678e-01, 5.0708e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:31,503][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0392, 0.0604, 0.1174, 0.0411, 0.0852, 0.0832, 0.0992, 0.0335, 0.0761,
        0.0729, 0.0308, 0.0372, 0.0342, 0.0394, 0.0611, 0.0500, 0.0391],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:31,506][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:31,510][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[6122],
        [  26],
        [   6],
        [2355],
        [ 188],
        [  61],
        [  53],
        [  51],
        [  24],
        [  29],
        [  74],
        [  71],
        [  16],
        [  37],
        [  25],
        [   5],
        [  26]], device='cuda:0')
[2024-07-24 10:31:31,513][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[4232],
        [ 483],
        [  82],
        [7476],
        [ 765],
        [ 425],
        [ 525],
        [ 537],
        [ 504],
        [ 380],
        [ 703],
        [1376],
        [ 145],
        [ 167],
        [ 130],
        [  44],
        [ 184]], device='cuda:0')
[2024-07-24 10:31:31,515][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[17864],
        [26508],
        [20957],
        [22874],
        [29693],
        [18987],
        [26143],
        [31994],
        [19041],
        [19109],
        [18636],
        [20532],
        [20199],
        [18397],
        [23259],
        [19773],
        [18656]], device='cuda:0')
[2024-07-24 10:31:31,517][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[30600],
        [ 5359],
        [ 5169],
        [17439],
        [19120],
        [13199],
        [11075],
        [10313],
        [11557],
        [11428],
        [ 8519],
        [ 5483],
        [ 9417],
        [ 9755],
        [ 9771],
        [12491],
        [13304]], device='cuda:0')
[2024-07-24 10:31:31,519][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[22071],
        [ 2041],
        [ 2594],
        [ 7101],
        [ 3151],
        [ 2176],
        [ 3047],
        [ 2239],
        [ 2218],
        [17150],
        [ 7992],
        [11930],
        [ 1539],
        [14077],
        [ 2553],
        [ 5481],
        [11997]], device='cuda:0')
[2024-07-24 10:31:31,520][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[33294],
        [33808],
        [35854],
        [40074],
        [39927],
        [33989],
        [34095],
        [32764],
        [31110],
        [27130],
        [34125],
        [28655],
        [26772],
        [34329],
        [28978],
        [31799],
        [34881]], device='cuda:0')
[2024-07-24 10:31:31,522][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[23066],
        [22542],
        [22320],
        [20260],
        [20511],
        [20353],
        [20701],
        [21212],
        [21109],
        [20895],
        [20974],
        [20751],
        [21266],
        [20798],
        [20936],
        [21122],
        [20802]], device='cuda:0')
[2024-07-24 10:31:31,525][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[28059],
        [23264],
        [16600],
        [16019],
        [14868],
        [20610],
        [12077],
        [10994],
        [ 9208],
        [13338],
        [ 9209],
        [10682],
        [12475],
        [17633],
        [ 9725],
        [10253],
        [12614]], device='cuda:0')
[2024-07-24 10:31:31,527][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[42754],
        [29178],
        [33922],
        [48466],
        [47891],
        [47946],
        [43869],
        [43136],
        [44102],
        [45577],
        [47320],
        [39425],
        [37456],
        [46870],
        [41676],
        [34553],
        [42085]], device='cuda:0')
[2024-07-24 10:31:31,530][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[12203],
        [15852],
        [25191],
        [33883],
        [33610],
        [29399],
        [32943],
        [22302],
        [27904],
        [28470],
        [19809],
        [29501],
        [30673],
        [24379],
        [29598],
        [29732],
        [25985]], device='cuda:0')
[2024-07-24 10:31:31,532][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 7426],
        [25518],
        [12529],
        [14471],
        [14192],
        [21179],
        [20508],
        [27168],
        [23149],
        [19851],
        [30558],
        [29559],
        [30673],
        [32041],
        [29364],
        [32522],
        [32169]], device='cuda:0')
[2024-07-24 10:31:31,533][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[20737],
        [20225],
        [13916],
        [49545],
        [46377],
        [41711],
        [41059],
        [37966],
        [35307],
        [32340],
        [30863],
        [26772],
        [25187],
        [23567],
        [22252],
        [21106],
        [19900]], device='cuda:0')
[2024-07-24 10:31:31,535][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[16595],
        [14455],
        [13978],
        [14482],
        [14777],
        [12087],
        [12486],
        [14164],
        [13499],
        [13326],
        [14351],
        [13888],
        [13822],
        [15807],
        [16005],
        [16349],
        [20306]], device='cuda:0')
[2024-07-24 10:31:31,537][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[15083],
        [  276],
        [  827],
        [  291],
        [  785],
        [  820],
        [ 1899],
        [ 1849],
        [ 1859],
        [ 2135],
        [ 2315],
        [ 1349],
        [ 1666],
        [ 2275],
        [ 1875],
        [ 2451],
        [ 2853]], device='cuda:0')
[2024-07-24 10:31:31,539][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[41084],
        [ 5049],
        [ 1489],
        [ 2218],
        [ 2539],
        [ 1597],
        [ 2031],
        [ 2042],
        [ 1159],
        [ 1467],
        [ 1391],
        [ 1334],
        [ 3399],
        [ 2719],
        [ 3492],
        [ 2888],
        [ 2636]], device='cuda:0')
[2024-07-24 10:31:31,542][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[14004],
        [28839],
        [18715],
        [15642],
        [18644],
        [14815],
        [17685],
        [20433],
        [14674],
        [14487],
        [14382],
        [15670],
        [14926],
        [14268],
        [15792],
        [14466],
        [14236]], device='cuda:0')
[2024-07-24 10:31:31,544][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[4523],
        [6217],
        [5285],
        [3172],
        [2749],
        [2225],
        [6704],
        [5002],
        [5249],
        [4625],
        [4186],
        [7792],
        [5975],
        [5149],
        [4499],
        [3994],
        [3483]], device='cuda:0')
[2024-07-24 10:31:31,547][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[13001],
        [ 8449],
        [11999],
        [13085],
        [15293],
        [11723],
        [17585],
        [14135],
        [14473],
        [13114],
        [13262],
        [13412],
        [17985],
        [13153],
        [16031],
        [14804],
        [13246]], device='cuda:0')
[2024-07-24 10:31:31,548][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[   17],
        [   16],
        [    5],
        [ 7276],
        [ 4461],
        [    9],
        [ 9585],
        [   54],
        [    9],
        [ 3700],
        [    2],
        [  942],
        [20683],
        [   14],
        [23442],
        [ 2738],
        [    8]], device='cuda:0')
[2024-07-24 10:31:31,550][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 8751],
        [ 4764],
        [ 5063],
        [ 6403],
        [ 5468],
        [ 7243],
        [ 7668],
        [ 8056],
        [ 7116],
        [ 9750],
        [ 8275],
        [ 8576],
        [ 7678],
        [10309],
        [ 9380],
        [ 8054],
        [ 9988]], device='cuda:0')
[2024-07-24 10:31:31,551][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 2070],
        [ 1861],
        [ 3927],
        [ 4393],
        [ 5414],
        [ 5230],
        [18016],
        [12182],
        [13281],
        [12924],
        [13607],
        [15110],
        [19154],
        [12187],
        [23705],
        [19021],
        [18390]], device='cuda:0')
[2024-07-24 10:31:31,554][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 3575],
        [14692],
        [35300],
        [25140],
        [23795],
        [30669],
        [38180],
        [37438],
        [37346],
        [35729],
        [33801],
        [35232],
        [38343],
        [31674],
        [33600],
        [35128],
        [31249]], device='cuda:0')
[2024-07-24 10:31:31,556][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 3982],
        [26351],
        [11934],
        [11906],
        [11872],
        [21414],
        [17901],
        [17384],
        [11606],
        [11788],
        [ 4465],
        [ 5466],
        [ 6190],
        [ 7147],
        [ 6872],
        [ 7900],
        [10101]], device='cuda:0')
[2024-07-24 10:31:31,559][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 4585],
        [30137],
        [24996],
        [24785],
        [26018],
        [28753],
        [28827],
        [28418],
        [27609],
        [11668],
        [29087],
        [24684],
        [23387],
        [23702],
        [26758],
        [26494],
        [22270]], device='cuda:0')
[2024-07-24 10:31:31,561][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[10892],
        [27167],
        [27369],
        [34559],
        [33504],
        [38652],
        [46577],
        [42267],
        [42794],
        [43082],
        [41481],
        [38181],
        [39510],
        [38770],
        [38674],
        [39262],
        [38119]], device='cuda:0')
[2024-07-24 10:31:31,563][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 1924],
        [17008],
        [ 3748],
        [ 3808],
        [ 3826],
        [ 3427],
        [ 3475],
        [ 3930],
        [19450],
        [18382],
        [18282],
        [17358],
        [17266],
        [11035],
        [11980],
        [11927],
        [12148]], device='cuda:0')
[2024-07-24 10:31:31,564][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[4849],
        [2820],
        [4472],
        [5363],
        [3659],
        [3658],
        [3637],
        [3130],
        [3077],
        [4920],
        [3674],
        [4336],
        [3591],
        [3416],
        [4487],
        [4344],
        [3861]], device='cuda:0')
[2024-07-24 10:31:31,566][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[50071],
        [47653],
        [48764],
        [44065],
        [43660],
        [47288],
        [32756],
        [42670],
        [42725],
        [38545],
        [44405],
        [40036],
        [30349],
        [45749],
        [27949],
        [38298],
        [44538]], device='cuda:0')
[2024-07-24 10:31:31,568][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 8521],
        [40749],
        [47156],
        [46664],
        [48806],
        [46692],
        [47067],
        [46728],
        [44404],
        [43790],
        [46389],
        [47609],
        [42177],
        [45106],
        [42874],
        [43324],
        [46077]], device='cuda:0')
[2024-07-24 10:31:31,571][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[23917],
        [23917],
        [23917],
        [23917],
        [23917],
        [23917],
        [23917],
        [23917],
        [23917],
        [23917],
        [23917],
        [23917],
        [23917],
        [23917],
        [23917],
        [23917],
        [23917]], device='cuda:0')
[2024-07-24 10:31:31,687][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:31,688][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,689][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,690][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,691][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,692][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,693][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,693][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,694][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,694][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,695][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,696][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,698][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:31,701][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.1859, 0.8141], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,701][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.0013, 0.9987], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,702][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.6896, 0.3104], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,703][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.6935, 0.3065], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,706][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.9771, 0.0229], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,708][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.2926, 0.7074], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,708][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.0224, 0.9776], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,709][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.3074, 0.6926], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,710][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.7264, 0.2736], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,711][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.0694, 0.9306], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,716][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.0380, 0.9620], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,719][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.9851, 0.0149], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:31,720][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0177, 0.2471, 0.7352], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,721][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.7077e-04, 8.3403e-01, 1.6570e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,722][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4029, 0.3812, 0.2159], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,725][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3768, 0.2431, 0.3801], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,729][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([9.9620e-01, 9.7096e-04, 2.8306e-03], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,731][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([8.9183e-04, 4.6324e-03, 9.9448e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,731][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0284, 0.4476, 0.5240], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,732][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.5546, 0.4062, 0.0392], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,733][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7587, 0.0976, 0.1437], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,734][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([5.3048e-04, 1.6190e-03, 9.9785e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,737][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([7.4642e-03, 9.9242e-01, 1.1611e-04], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,740][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([9.9960e-01, 3.2470e-04, 7.9853e-05], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:31,743][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Nathan] are: tensor([0.0141, 0.0544, 0.8004, 0.1311], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,743][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Nathan] are: tensor([7.3703e-04, 8.8966e-01, 9.0000e-02, 1.9608e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,744][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Nathan] are: tensor([0.3191, 0.4057, 0.2157, 0.0595], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,745][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Nathan] are: tensor([0.1850, 0.2379, 0.5274, 0.0496], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,746][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Nathan] are: tensor([9.9287e-01, 2.0236e-03, 4.5349e-03, 5.7056e-04], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,750][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Nathan] are: tensor([7.6828e-06, 3.8182e-04, 9.9130e-01, 8.3063e-03], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,754][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Nathan] are: tensor([0.0211, 0.3473, 0.4935, 0.1382], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,755][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Nathan] are: tensor([0.5476, 0.3960, 0.0419, 0.0146], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,755][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Nathan] are: tensor([0.7284, 0.1319, 0.0694, 0.0703], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,756][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Nathan] are: tensor([6.8848e-06, 1.4741e-04, 9.9902e-01, 8.2206e-04], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,758][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Nathan] are: tensor([0.0421, 0.4889, 0.0008, 0.4682], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,764][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Nathan] are: tensor([0.0117, 0.2043, 0.5926, 0.1915], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:31,766][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.0023, 0.0305, 0.7715, 0.0491, 0.1466], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,767][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ got] are: tensor([2.8407e-04, 7.5191e-01, 2.0352e-01, 3.6047e-02, 8.2391e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,767][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.1938, 0.1929, 0.1815, 0.1415, 0.2903], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,768][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.1391, 0.2410, 0.4536, 0.0442, 0.1221], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,770][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ got] are: tensor([9.8802e-01, 1.0850e-03, 7.7238e-03, 5.3918e-04, 2.6365e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,773][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ got] are: tensor([6.3517e-06, 2.0818e-04, 9.8702e-01, 8.2034e-03, 4.5618e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,777][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.0093, 0.1722, 0.5239, 0.1600, 0.1346], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,778][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.4786, 0.4466, 0.0648, 0.0057, 0.0042], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,779][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.5627, 0.1095, 0.1178, 0.1172, 0.0928], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,780][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ got] are: tensor([5.7852e-07, 4.1979e-05, 9.9889e-01, 7.5168e-04, 3.1420e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,781][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ got] are: tensor([1.4931e-02, 7.5554e-01, 2.2383e-04, 2.2835e-01, 9.5568e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,785][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.0595, 0.1563, 0.3614, 0.2006, 0.2222], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:31,789][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0155, 0.1466, 0.2820, 0.0495, 0.1634, 0.3431], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,790][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.3830e-04, 6.4289e-01, 1.5433e-01, 3.6226e-02, 1.5925e-02, 1.5049e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,791][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1331, 0.1734, 0.1049, 0.1531, 0.1945, 0.2409], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,791][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2919, 0.1677, 0.2204, 0.0457, 0.0489, 0.2255], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,793][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([9.9417e-01, 8.6933e-04, 2.0774e-03, 2.5768e-04, 6.9160e-04, 1.9381e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,796][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([2.5839e-03, 2.8489e-03, 2.6569e-02, 1.7907e-03, 5.6378e-04, 9.6564e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,801][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0057, 0.2940, 0.3071, 0.1162, 0.0771, 0.1999], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,801][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([6.8557e-01, 2.7352e-01, 2.9330e-02, 3.5593e-03, 4.7723e-04, 7.5421e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,802][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.8019, 0.0508, 0.0287, 0.0747, 0.0225, 0.0214], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,803][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([6.3085e-03, 1.6791e-03, 1.5641e-02, 1.9588e-04, 4.4619e-05, 9.7613e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,804][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([2.8705e-02, 7.0835e-01, 3.3237e-05, 2.6235e-01, 5.2687e-04, 3.1487e-05],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,807][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([9.9853e-01, 2.8358e-04, 1.1051e-05, 1.0948e-03, 1.9022e-05, 5.9150e-05],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:31,812][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.0077, 0.0508, 0.2132, 0.0449, 0.2135, 0.2151, 0.2547],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,813][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([1.2463e-04, 4.7690e-01, 2.4109e-01, 4.1639e-02, 1.4070e-02, 1.0821e-01,
        1.1797e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,814][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.0183, 0.0776, 0.1143, 0.0211, 0.1177, 0.2137, 0.4373],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,815][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0507, 0.0728, 0.2591, 0.0236, 0.0730, 0.1694, 0.3515],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,818][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.9643, 0.0017, 0.0111, 0.0018, 0.0035, 0.0111, 0.0064],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,822][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([2.5228e-05, 3.8284e-04, 2.0746e-01, 7.7796e-03, 3.9066e-03, 7.7808e-01,
        2.3679e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,824][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.0011, 0.1608, 0.3388, 0.0791, 0.0901, 0.2007, 0.1293],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,825][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.1916, 0.6327, 0.1008, 0.0053, 0.0025, 0.0327, 0.0342],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,825][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.7900, 0.0439, 0.0190, 0.0251, 0.0125, 0.0088, 0.1007],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,826][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([6.8374e-06, 2.0879e-04, 1.8044e-01, 1.5993e-03, 1.6017e-03, 8.1508e-01,
        1.0609e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,828][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([1.5492e-01, 4.5732e-01, 4.8793e-05, 2.9446e-02, 3.7607e-04, 2.8404e-05,
        3.5786e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,830][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([3.5879e-05, 5.9724e-03, 2.7113e-02, 2.1235e-03, 9.6453e-03, 9.5156e-01,
        3.5450e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:31,836][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0046, 0.0743, 0.2552, 0.0687, 0.1130, 0.2120, 0.1660, 0.1062],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,837][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ at] are: tensor([1.7034e-04, 5.6153e-01, 2.0175e-01, 3.0205e-02, 8.2869e-03, 1.0623e-01,
        5.3516e-02, 3.8318e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,837][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0522, 0.0642, 0.1043, 0.0610, 0.1144, 0.1583, 0.2605, 0.1850],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,838][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.1252, 0.1106, 0.2393, 0.0362, 0.0630, 0.1513, 0.1535, 0.1208],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,842][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.9141, 0.0062, 0.0137, 0.0036, 0.0067, 0.0192, 0.0158, 0.0207],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,846][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ at] are: tensor([7.9521e-04, 1.7450e-03, 5.3453e-02, 2.9455e-03, 1.3045e-03, 7.9825e-01,
        1.1713e-02, 1.2980e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,848][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0037, 0.1462, 0.2801, 0.1692, 0.0899, 0.1770, 0.1069, 0.0269],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,849][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.2449, 0.5287, 0.1334, 0.0176, 0.0031, 0.0333, 0.0222, 0.0168],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,849][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.6771, 0.0503, 0.0249, 0.0506, 0.0222, 0.0243, 0.1214, 0.0292],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,850][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ at] are: tensor([1.1029e-03, 1.6625e-03, 3.3215e-02, 6.3965e-04, 2.4098e-04, 7.9407e-01,
        3.1912e-03, 1.6588e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,852][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ at] are: tensor([1.8513e-02, 3.0639e-01, 3.8445e-05, 1.4400e-01, 4.8165e-04, 3.6298e-05,
        5.3044e-01, 1.0393e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,855][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ at] are: tensor([9.9646e-01, 5.8756e-04, 8.6541e-05, 1.2808e-03, 8.4463e-05, 3.0856e-04,
        4.2595e-04, 7.6467e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:31,860][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0548, 0.1063, 0.1078, 0.0460, 0.0934, 0.1110, 0.1410, 0.1027, 0.2369],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,861][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0008, 0.5549, 0.1044, 0.0233, 0.0079, 0.0616, 0.0542, 0.0424, 0.1505],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,861][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2923, 0.1096, 0.0405, 0.0518, 0.0864, 0.0685, 0.2030, 0.1097, 0.0383],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,862][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.4223, 0.1006, 0.1075, 0.0134, 0.0315, 0.0947, 0.0686, 0.0787, 0.0826],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,865][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ the] are: tensor([9.5252e-01, 1.9804e-03, 3.9878e-03, 5.9015e-04, 1.6669e-03, 5.0425e-03,
        4.2000e-03, 1.0311e-02, 1.9703e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,868][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ the] are: tensor([4.1755e-03, 1.0869e-03, 1.9462e-03, 2.6686e-04, 6.8655e-05, 6.4799e-02,
        2.6213e-03, 1.7518e-02, 9.0752e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,871][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0347, 0.2087, 0.1623, 0.1153, 0.0528, 0.1674, 0.1035, 0.0250, 0.1303],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,872][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ the] are: tensor([8.7273e-01, 1.0191e-01, 8.8938e-03, 1.0998e-03, 2.3269e-04, 3.1367e-03,
        2.5743e-03, 2.3306e-03, 7.0878e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,873][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.8516, 0.0206, 0.0075, 0.0123, 0.0075, 0.0040, 0.0497, 0.0107, 0.0362],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,874][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ the] are: tensor([7.0725e-03, 1.5949e-03, 2.0673e-03, 4.0037e-05, 1.4702e-05, 5.2844e-02,
        9.0547e-04, 3.4978e-02, 9.0048e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,875][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ the] are: tensor([4.5511e-02, 5.1336e-01, 7.9348e-06, 8.3238e-02, 1.3768e-04, 5.7666e-06,
        3.5769e-01, 3.0924e-05, 1.5321e-05], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,878][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ the] are: tensor([9.9890e-01, 1.5692e-04, 8.2916e-06, 6.5511e-04, 1.5017e-05, 4.4862e-05,
        1.5248e-04, 2.4853e-05, 4.5819e-05], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:31,884][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([0.0089, 0.0745, 0.0727, 0.0515, 0.1800, 0.1188, 0.0586, 0.1161, 0.2095,
        0.1093], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,884][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([1.4705e-04, 5.8234e-01, 6.7925e-02, 4.3740e-02, 2.4476e-02, 5.9119e-02,
        2.5964e-02, 3.2128e-02, 7.0543e-02, 9.3620e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,885][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([0.0238, 0.0894, 0.0608, 0.0300, 0.0572, 0.1042, 0.1437, 0.0903, 0.0421,
        0.3584], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,886][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([0.2367, 0.1013, 0.0982, 0.0220, 0.0282, 0.0846, 0.0497, 0.0613, 0.0728,
        0.2453], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,891][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([0.8253, 0.0067, 0.0155, 0.0029, 0.0058, 0.0226, 0.0119, 0.0375, 0.0518,
        0.0199], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,895][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([5.2730e-05, 1.7970e-04, 1.7690e-02, 4.1123e-04, 4.0417e-04, 2.1523e-01,
        8.5738e-04, 2.7758e-02, 7.3305e-01, 4.3621e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,896][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.0059, 0.1214, 0.1204, 0.1754, 0.0853, 0.1005, 0.0619, 0.0383, 0.0952,
        0.1957], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,897][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([0.2504, 0.6200, 0.0313, 0.0081, 0.0010, 0.0141, 0.0065, 0.0097, 0.0260,
        0.0327], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,898][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.6760, 0.0429, 0.0268, 0.0279, 0.0093, 0.0079, 0.0432, 0.0227, 0.0533,
        0.0899], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,899][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([2.8617e-05, 2.0679e-04, 1.8907e-02, 9.2252e-05, 1.8327e-04, 1.4734e-01,
        3.3634e-04, 6.2189e-02, 7.6484e-01, 5.8732e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,903][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([1.6914e-01, 1.6835e-01, 5.7332e-06, 9.1744e-02, 3.2769e-04, 1.3509e-05,
        2.5403e-01, 4.4429e-05, 1.7425e-05, 3.1632e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,907][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([0.0372, 0.0393, 0.0314, 0.0338, 0.0237, 0.2834, 0.0126, 0.1923, 0.3247,
        0.0215], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:31,908][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0302, 0.0634, 0.0602, 0.0982, 0.1314, 0.0692, 0.0560, 0.0559, 0.0986,
        0.1126, 0.2243], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,909][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0007, 0.5171, 0.1022, 0.0630, 0.0102, 0.0412, 0.0333, 0.0221, 0.0516,
        0.0735, 0.0850], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,910][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1720, 0.1223, 0.0318, 0.0724, 0.0497, 0.0428, 0.1668, 0.0405, 0.0230,
        0.2141, 0.0645], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,915][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3158, 0.0617, 0.0719, 0.0197, 0.0219, 0.0550, 0.0440, 0.0490, 0.0445,
        0.1633, 0.1532], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,919][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([9.7090e-01, 3.7338e-03, 1.4120e-03, 7.3691e-04, 6.2367e-04, 1.2219e-03,
        2.9860e-03, 3.3353e-03, 3.4699e-03, 5.0451e-03, 6.5363e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,920][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([1.1790e-02, 8.1595e-04, 1.8547e-04, 3.6042e-05, 1.3031e-05, 7.7659e-03,
        1.3599e-03, 3.5866e-03, 1.2972e-01, 2.1871e-03, 8.4254e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,921][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0350, 0.1544, 0.1044, 0.3042, 0.0545, 0.0838, 0.0529, 0.0131, 0.0378,
        0.0981, 0.0618], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,921][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([5.2083e-01, 4.3468e-01, 1.3101e-02, 2.5762e-03, 2.4189e-04, 2.2988e-03,
        2.4423e-03, 1.7374e-03, 5.3071e-03, 2.7965e-03, 1.3993e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,925][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.8646, 0.0101, 0.0045, 0.0157, 0.0065, 0.0029, 0.0337, 0.0072, 0.0186,
        0.0301, 0.0060], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,928][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([4.3298e-03, 1.2826e-04, 2.0329e-05, 1.4707e-06, 1.1614e-06, 1.0634e-03,
        1.0910e-04, 1.2589e-03, 1.8829e-02, 5.3979e-04, 9.7372e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,931][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([3.4392e-02, 2.5257e-01, 9.9668e-06, 1.6939e-01, 2.3483e-04, 1.2130e-05,
        2.7011e-01, 4.3878e-05, 1.8621e-05, 2.7297e-01, 2.6001e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,932][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([9.9906e-01, 6.7487e-05, 2.4997e-06, 7.1291e-04, 1.2275e-05, 1.4807e-05,
        5.3215e-05, 6.4684e-06, 1.0115e-05, 5.2268e-05, 3.2515e-06],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:31,933][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.0086, 0.0282, 0.0301, 0.0469, 0.1058, 0.0721, 0.0519, 0.0490, 0.1401,
        0.0685, 0.2309, 0.1680], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,934][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([1.8334e-04, 2.1474e-01, 6.7901e-02, 2.8571e-02, 2.0489e-02, 6.0801e-02,
        2.0573e-02, 3.0663e-02, 6.3415e-02, 4.6869e-02, 1.3970e-01, 3.0609e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,939][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.0470, 0.0618, 0.0307, 0.0235, 0.0699, 0.0814, 0.1867, 0.0404, 0.0244,
        0.1403, 0.1055, 0.1882], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,943][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.2956, 0.0717, 0.0290, 0.0148, 0.0233, 0.0349, 0.0358, 0.0443, 0.0459,
        0.1226, 0.1237, 0.1584], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,944][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([9.6471e-01, 3.0431e-03, 1.5011e-03, 8.8959e-04, 1.1058e-03, 1.7756e-03,
        2.7989e-03, 3.2064e-03, 3.8393e-03, 3.4269e-03, 5.4077e-03, 8.2933e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,944][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.0031, 0.0016, 0.0057, 0.0021, 0.0006, 0.0512, 0.0049, 0.0240, 0.2048,
        0.0122, 0.5783, 0.1115], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,945][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.0039, 0.1924, 0.0639, 0.1546, 0.0519, 0.0535, 0.0362, 0.0136, 0.0395,
        0.0429, 0.1142, 0.2334], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,949][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.5076, 0.2560, 0.0119, 0.0058, 0.0011, 0.0081, 0.0116, 0.0066, 0.0143,
        0.0179, 0.0321, 0.1270], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,955][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.7118, 0.0600, 0.0081, 0.0443, 0.0059, 0.0052, 0.0256, 0.0066, 0.0339,
        0.0533, 0.0171, 0.0282], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,957][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([8.4133e-04, 5.1520e-04, 1.9934e-03, 1.8300e-04, 1.5302e-04, 1.9640e-02,
        1.8025e-03, 1.8303e-02, 9.4250e-02, 7.9047e-03, 8.2950e-01, 2.4915e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,958][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([1.9781e-01, 1.0936e-01, 1.1888e-05, 6.2891e-02, 3.2740e-04, 1.7272e-05,
        1.2294e-01, 4.7272e-05, 1.9096e-05, 1.1631e-01, 2.2922e-04, 3.9004e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,959][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.8709, 0.0085, 0.0012, 0.0322, 0.0058, 0.0175, 0.0081, 0.0145, 0.0150,
        0.0105, 0.0078, 0.0080], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:31,959][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0074, 0.0088, 0.0164, 0.0332, 0.0514, 0.0631, 0.1037, 0.0623, 0.0726,
        0.1866, 0.1210, 0.1979, 0.0757], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,963][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0005, 0.1789, 0.0700, 0.0291, 0.0097, 0.0414, 0.0321, 0.0274, 0.0491,
        0.0783, 0.0988, 0.3540, 0.0306], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,969][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0961, 0.0870, 0.0280, 0.0315, 0.0421, 0.0528, 0.0901, 0.0342, 0.0204,
        0.1656, 0.0427, 0.2584, 0.0512], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,970][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.3701, 0.0344, 0.0338, 0.0117, 0.0190, 0.0287, 0.0272, 0.0350, 0.0276,
        0.1399, 0.0871, 0.1678, 0.0178], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,971][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.8964, 0.0041, 0.0045, 0.0022, 0.0011, 0.0050, 0.0039, 0.0112, 0.0128,
        0.0153, 0.0207, 0.0177, 0.0049], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,972][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([1.5435e-04, 1.4492e-04, 2.1944e-03, 2.3528e-04, 7.4986e-05, 2.1414e-02,
        1.1017e-03, 9.1044e-03, 1.7259e-01, 2.3987e-03, 7.3743e-01, 5.2147e-02,
        1.0160e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,975][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0111, 0.0809, 0.1084, 0.1016, 0.0381, 0.0947, 0.0443, 0.0113, 0.0429,
        0.1005, 0.0989, 0.2441, 0.0235], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,981][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.5635, 0.3235, 0.0175, 0.0037, 0.0014, 0.0041, 0.0040, 0.0052, 0.0114,
        0.0043, 0.0219, 0.0271, 0.0124], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,982][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.6490, 0.0424, 0.0191, 0.0303, 0.0134, 0.0086, 0.0482, 0.0156, 0.0435,
        0.0539, 0.0262, 0.0249, 0.0250], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,983][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([9.9678e-06, 2.5485e-05, 1.6554e-03, 1.5578e-05, 7.8163e-06, 8.2560e-03,
        9.8930e-05, 2.8007e-03, 4.5807e-02, 7.6307e-04, 9.3616e-01, 3.9067e-03,
        4.9212e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,984][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([6.1538e-02, 6.8246e-02, 1.6522e-05, 5.8283e-02, 2.3492e-04, 4.7291e-05,
        1.5907e-01, 8.8716e-05, 5.3402e-05, 1.5236e-01, 4.3181e-04, 4.5627e-01,
        4.3349e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,987][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.4993, 0.0366, 0.0112, 0.1230, 0.0105, 0.0812, 0.0094, 0.0473, 0.0492,
        0.0368, 0.0172, 0.0365, 0.0417], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:31,993][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0332, 0.0404, 0.0240, 0.0468, 0.0632, 0.0731, 0.0365, 0.0532, 0.0806,
        0.0700, 0.1398, 0.0586, 0.1040, 0.1765], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:31,994][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0006, 0.2238, 0.0528, 0.0270, 0.0071, 0.0444, 0.0258, 0.0222, 0.0689,
        0.0500, 0.0938, 0.2921, 0.0303, 0.0610], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:31,995][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.3239, 0.0338, 0.0166, 0.0279, 0.0412, 0.0281, 0.0575, 0.0382, 0.0180,
        0.1506, 0.0401, 0.1456, 0.0515, 0.0269], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:31,996][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.6159, 0.0311, 0.0285, 0.0084, 0.0135, 0.0221, 0.0092, 0.0143, 0.0147,
        0.0600, 0.0548, 0.0682, 0.0197, 0.0396], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:31,998][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([9.9007e-01, 1.4181e-03, 2.3594e-04, 1.9027e-04, 1.3138e-04, 2.2807e-04,
        6.8171e-04, 8.0799e-04, 7.8775e-04, 9.3768e-04, 1.0443e-03, 2.2378e-03,
        4.5506e-04, 7.7567e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:32,001][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([5.3010e-02, 8.2419e-04, 4.8911e-05, 2.6720e-05, 4.7508e-06, 2.1952e-03,
        1.0571e-03, 1.3394e-03, 4.2003e-02, 1.3766e-03, 3.1888e-01, 1.1673e-01,
        8.3215e-04, 4.6168e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:32,005][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0264, 0.0569, 0.0990, 0.1983, 0.0337, 0.0904, 0.0398, 0.0100, 0.0475,
        0.0667, 0.0991, 0.1462, 0.0218, 0.0642], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:32,006][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([8.8328e-01, 8.3327e-02, 4.2624e-03, 1.7886e-03, 1.4423e-04, 7.7899e-04,
        4.0828e-04, 5.3670e-04, 1.6733e-03, 3.5753e-04, 4.1672e-03, 1.1199e-02,
        1.1207e-03, 6.9541e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:32,007][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.8134, 0.0120, 0.0054, 0.0150, 0.0071, 0.0046, 0.0377, 0.0078, 0.0258,
        0.0259, 0.0081, 0.0086, 0.0115, 0.0171], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:32,008][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.5905e-02, 8.9868e-05, 5.9203e-06, 7.4066e-07, 2.3857e-07, 2.2542e-04,
        5.5289e-05, 4.4266e-04, 4.9257e-03, 2.4838e-04, 2.6939e-01, 1.3085e-02,
        3.5246e-04, 6.9528e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:32,010][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([4.6696e-02, 1.2116e-01, 7.7387e-06, 1.1350e-01, 1.7359e-04, 1.4415e-05,
        1.8046e-01, 3.9739e-05, 2.1999e-05, 1.5377e-01, 1.9963e-04, 3.4513e-01,
        3.8146e-02, 6.9158e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:32,013][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([9.9988e-01, 6.7709e-06, 2.5332e-07, 9.4763e-05, 5.8964e-07, 5.6475e-07,
        4.3120e-06, 3.8297e-07, 4.7669e-07, 4.8950e-06, 1.7655e-07, 1.7408e-06,
        5.1996e-06, 2.1608e-06], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:32,017][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0027, 0.0122, 0.0368, 0.0232, 0.0549, 0.0600, 0.0368, 0.0369, 0.1003,
        0.0593, 0.1623, 0.1014, 0.0363, 0.1576, 0.1194], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,018][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0004, 0.2618, 0.0874, 0.0611, 0.0134, 0.0485, 0.0194, 0.0160, 0.0431,
        0.0460, 0.0573, 0.2740, 0.0167, 0.0403, 0.0146], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,019][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0753, 0.0470, 0.0203, 0.0379, 0.0366, 0.0324, 0.0820, 0.0402, 0.0159,
        0.1593, 0.0602, 0.1785, 0.0354, 0.0275, 0.1517], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,020][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.1538, 0.0250, 0.0548, 0.0162, 0.0135, 0.0421, 0.0272, 0.0143, 0.0225,
        0.0978, 0.0916, 0.2998, 0.0075, 0.0603, 0.0736], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,024][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.7351, 0.0174, 0.0089, 0.0043, 0.0028, 0.0063, 0.0130, 0.0137, 0.0199,
        0.0248, 0.0371, 0.0518, 0.0044, 0.0172, 0.0432], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,028][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ give] are: tensor([1.2033e-04, 5.5024e-05, 6.8017e-04, 5.8774e-05, 2.5720e-05, 1.5658e-02,
        2.2823e-04, 1.9163e-03, 7.9728e-02, 1.3582e-03, 3.9851e-01, 2.5974e-02,
        5.1220e-04, 4.6498e-01, 1.0190e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,030][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0119, 0.0610, 0.0944, 0.1686, 0.0433, 0.1040, 0.0452, 0.0071, 0.0380,
        0.0835, 0.0842, 0.1978, 0.0111, 0.0356, 0.0144], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,031][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.3209, 0.4267, 0.0241, 0.0032, 0.0006, 0.0086, 0.0047, 0.0053, 0.0123,
        0.0134, 0.0359, 0.0794, 0.0058, 0.0252, 0.0339], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,032][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.5719, 0.0209, 0.0165, 0.0400, 0.0142, 0.0070, 0.0632, 0.0133, 0.0375,
        0.0549, 0.0164, 0.0109, 0.0073, 0.0159, 0.1102], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,033][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ give] are: tensor([6.0165e-06, 8.6755e-06, 1.5017e-04, 1.6006e-06, 1.2059e-06, 1.2425e-03,
        9.7697e-06, 8.0687e-04, 1.1105e-02, 3.0117e-04, 3.5925e-01, 1.7799e-03,
        1.7571e-04, 6.2333e-01, 1.8377e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,034][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ give] are: tensor([4.0251e-02, 6.2130e-02, 9.1706e-06, 2.7894e-02, 9.1748e-05, 2.1151e-05,
        2.0076e-01, 8.4343e-05, 5.7617e-05, 1.4483e-01, 4.5005e-04, 4.7290e-01,
        2.6138e-02, 9.1111e-04, 2.3466e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,040][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0422, 0.0298, 0.0293, 0.0737, 0.0134, 0.0950, 0.0061, 0.1225, 0.1628,
        0.0226, 0.0599, 0.0176, 0.0320, 0.1936, 0.0996], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,042][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.0289, 0.0095, 0.0168, 0.0340, 0.0711, 0.0497, 0.0508, 0.0482, 0.0596,
        0.0777, 0.1418, 0.0827, 0.0519, 0.1247, 0.0904, 0.0624],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,043][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.0007, 0.0971, 0.0577, 0.0240, 0.0083, 0.0500, 0.0360, 0.0230, 0.0659,
        0.0863, 0.1136, 0.2742, 0.0165, 0.0493, 0.0292, 0.0683],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,044][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.1147, 0.0203, 0.0198, 0.0214, 0.0445, 0.0472, 0.0758, 0.0303, 0.0182,
        0.1419, 0.0442, 0.1374, 0.0480, 0.0314, 0.1490, 0.0559],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,045][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.5169, 0.0161, 0.0127, 0.0043, 0.0084, 0.0233, 0.0187, 0.0122, 0.0202,
        0.0655, 0.0547, 0.1163, 0.0117, 0.0465, 0.0370, 0.0355],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,048][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ it] are: tensor([9.6902e-01, 5.6001e-04, 4.4586e-04, 3.3569e-04, 3.6557e-04, 1.3310e-03,
        7.9836e-04, 2.0358e-03, 2.7884e-03, 1.8947e-03, 3.5050e-03, 5.8303e-03,
        6.9414e-04, 2.6444e-03, 3.6961e-03, 4.0499e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,052][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ it] are: tensor([1.8759e-04, 5.6337e-05, 3.1815e-05, 4.7721e-06, 1.4991e-06, 2.4453e-03,
        1.3185e-04, 6.0168e-04, 3.8722e-02, 2.2408e-04, 2.9868e-01, 2.4560e-02,
        1.9773e-04, 5.1753e-01, 6.4970e-03, 1.1013e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,054][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.0223, 0.0254, 0.0615, 0.1197, 0.0446, 0.1179, 0.0631, 0.0102, 0.0504,
        0.1060, 0.0806, 0.1232, 0.0197, 0.0439, 0.0179, 0.0935],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,055][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ it] are: tensor([8.9538e-01, 5.9519e-02, 2.3333e-03, 1.0868e-03, 9.7644e-05, 1.4986e-03,
        8.9123e-04, 1.3089e-03, 2.4626e-03, 9.7840e-04, 6.3389e-03, 1.5256e-02,
        9.4871e-04, 6.4049e-03, 2.5700e-03, 2.9198e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,056][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.5608, 0.0132, 0.0095, 0.0135, 0.0089, 0.0086, 0.0382, 0.0146, 0.0552,
        0.0304, 0.0216, 0.0067, 0.0176, 0.0275, 0.1139, 0.0600],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,056][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ it] are: tensor([2.4645e-04, 3.6014e-06, 3.2922e-06, 9.4380e-08, 5.4713e-08, 2.7902e-04,
        8.1396e-06, 1.4676e-04, 4.3738e-03, 1.0439e-04, 2.3789e-01, 2.7330e-03,
        9.5784e-05, 6.8815e-01, 1.2668e-03, 6.4704e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,058][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ it] are: tensor([7.2745e-02, 3.5132e-02, 6.6881e-06, 3.4768e-02, 1.7584e-04, 1.5480e-05,
        1.7943e-01, 7.0265e-05, 4.3959e-05, 1.8956e-01, 3.0726e-04, 4.0334e-01,
        4.1085e-02, 1.2850e-03, 3.6266e-02, 5.7649e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,061][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ it] are: tensor([9.9216e-01, 5.0535e-04, 7.3596e-05, 1.5547e-03, 1.2303e-04, 5.3047e-04,
        2.7192e-04, 3.8786e-04, 6.0840e-04, 3.9723e-04, 2.0700e-04, 1.7436e-04,
        5.2129e-04, 8.2965e-04, 1.3000e-03, 3.5385e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,065][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0140, 0.0216, 0.0154, 0.0216, 0.0336, 0.0500, 0.0217, 0.0497, 0.0706,
        0.0352, 0.0998, 0.0445, 0.0405, 0.1509, 0.0817, 0.0646, 0.1846],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,066][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0008, 0.2125, 0.0432, 0.0224, 0.0081, 0.0402, 0.0282, 0.0198, 0.0551,
        0.0556, 0.0758, 0.2698, 0.0225, 0.0426, 0.0155, 0.0335, 0.0543],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,067][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.3403, 0.0247, 0.0139, 0.0208, 0.0276, 0.0211, 0.0511, 0.0225, 0.0114,
        0.0932, 0.0259, 0.1052, 0.0305, 0.0171, 0.1137, 0.0312, 0.0498],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,068][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.5257, 0.0273, 0.0242, 0.0084, 0.0142, 0.0286, 0.0116, 0.0154, 0.0206,
        0.0404, 0.0468, 0.0680, 0.0141, 0.0426, 0.0320, 0.0285, 0.0517],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,070][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([9.8246e-01, 1.0771e-03, 2.7538e-04, 2.1300e-04, 2.2399e-04, 2.8572e-04,
        7.4584e-04, 1.3437e-03, 1.0108e-03, 8.7925e-04, 1.2604e-03, 1.7249e-03,
        3.5669e-04, 9.5688e-04, 3.2279e-03, 1.9849e-03, 1.9701e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,073][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.4363e-02, 5.0888e-04, 3.8772e-05, 1.5471e-05, 4.0908e-06, 1.3059e-03,
        4.5484e-04, 6.3012e-04, 1.8251e-02, 7.5485e-04, 1.0842e-01, 4.9113e-02,
        5.1252e-04, 1.9295e-01, 5.1170e-03, 7.6919e-02, 5.2065e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,077][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0336, 0.0395, 0.0620, 0.1615, 0.0307, 0.0825, 0.0457, 0.0076, 0.0418,
        0.0683, 0.0775, 0.1293, 0.0151, 0.0505, 0.0141, 0.0599, 0.0805],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,078][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([8.1671e-01, 8.7054e-02, 7.7389e-03, 1.8750e-03, 2.5002e-04, 2.8641e-03,
        1.3780e-03, 1.1497e-03, 3.3741e-03, 9.2923e-04, 7.7746e-03, 2.5264e-02,
        1.8245e-03, 1.2852e-02, 3.6920e-03, 2.5020e-03, 2.2768e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,079][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.7829, 0.0066, 0.0041, 0.0095, 0.0048, 0.0037, 0.0279, 0.0068, 0.0229,
        0.0179, 0.0053, 0.0044, 0.0066, 0.0116, 0.0478, 0.0145, 0.0227],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,080][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.6701e-02, 7.1606e-05, 6.2891e-06, 6.7121e-07, 4.2370e-07, 2.6827e-04,
        5.2739e-05, 4.3137e-04, 3.8652e-03, 3.2446e-04, 1.4955e-01, 7.9159e-03,
        3.1184e-04, 4.1072e-01, 2.6878e-03, 8.5937e-02, 3.2116e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,082][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.3478e-01, 1.5668e-01, 6.5799e-06, 8.4622e-02, 1.2633e-04, 8.3221e-06,
        1.6895e-01, 3.2063e-05, 1.7807e-05, 1.1470e-01, 1.5642e-04, 2.8498e-01,
        3.1244e-02, 5.2874e-04, 1.8760e-02, 2.4154e-03, 1.9964e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,085][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([9.9990e-01, 3.1956e-06, 1.0218e-07, 8.1769e-05, 4.5727e-07, 4.6494e-07,
        4.0007e-06, 2.2782e-07, 2.8889e-07, 3.2671e-06, 9.5392e-08, 1.2087e-06,
        2.9198e-06, 1.0897e-06, 2.1711e-06, 5.5631e-07, 6.7152e-07],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,203][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:32,207][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,208][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,209][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,209][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,210][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,211][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,214][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,216][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,219][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,221][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,222][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,222][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,223][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.1859, 0.8141], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,224][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.0013, 0.9987], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,225][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.6896, 0.3104], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,229][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.6935, 0.3065], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,234][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.9771, 0.0229], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,234][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.2926, 0.7074], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,235][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.0224, 0.9776], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,236][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.3074, 0.6926], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,237][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.7264, 0.2736], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,240][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.0694, 0.9306], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,246][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.0094, 0.9906], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,247][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.2287, 0.7713], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,247][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0177, 0.2471, 0.7352], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,248][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.7077e-04, 8.3403e-01, 1.6570e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,249][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4029, 0.3812, 0.2159], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,252][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3768, 0.2431, 0.3801], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,256][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.9620e-01, 9.7096e-04, 2.8306e-03], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,258][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([8.9183e-04, 4.6324e-03, 9.9448e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,259][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0284, 0.4476, 0.5240], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,260][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.5546, 0.4062, 0.0392], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,260][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.7587, 0.0976, 0.1437], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,262][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([5.3048e-04, 1.6190e-03, 9.9785e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,264][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([1.1901e-03, 9.9829e-01, 5.2020e-04], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,270][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.8717, 0.0933, 0.0350], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,271][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Nathan] are: tensor([0.0141, 0.0544, 0.8004, 0.1311], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,271][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Nathan] are: tensor([7.3703e-04, 8.8966e-01, 9.0000e-02, 1.9608e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,272][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Nathan] are: tensor([0.3191, 0.4057, 0.2157, 0.0595], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,273][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Nathan] are: tensor([0.1850, 0.2379, 0.5274, 0.0496], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,274][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Nathan] are: tensor([9.9287e-01, 2.0236e-03, 4.5349e-03, 5.7056e-04], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,278][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Nathan] are: tensor([7.6828e-06, 3.8182e-04, 9.9130e-01, 8.3063e-03], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,282][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Nathan] are: tensor([0.0211, 0.3473, 0.4935, 0.1382], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,283][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Nathan] are: tensor([0.5476, 0.3960, 0.0419, 0.0146], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,284][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Nathan] are: tensor([0.7284, 0.1319, 0.0694, 0.0703], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,284][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Nathan] are: tensor([6.8848e-06, 1.4741e-04, 9.9902e-01, 8.2206e-04], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,285][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Nathan] are: tensor([0.0088, 0.7745, 0.0049, 0.2118], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,289][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Nathan] are: tensor([0.3671, 0.3766, 0.1773, 0.0790], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,294][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.0023, 0.0305, 0.7715, 0.0491, 0.1466], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,295][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([2.8407e-04, 7.5191e-01, 2.0352e-01, 3.6047e-02, 8.2391e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,296][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.1938, 0.1929, 0.1815, 0.1415, 0.2903], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,297][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.1391, 0.2410, 0.4536, 0.0442, 0.1221], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,297][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([9.8802e-01, 1.0850e-03, 7.7238e-03, 5.3918e-04, 2.6365e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,299][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([6.3517e-06, 2.0818e-04, 9.8702e-01, 8.2034e-03, 4.5618e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,304][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.0093, 0.1722, 0.5239, 0.1600, 0.1346], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,307][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.4786, 0.4466, 0.0648, 0.0057, 0.0042], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,308][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.5627, 0.1095, 0.1178, 0.1172, 0.0928], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,308][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([5.7852e-07, 4.1979e-05, 9.9889e-01, 7.5168e-04, 3.1420e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,309][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.0009, 0.8520, 0.0021, 0.1355, 0.0095], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,312][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.6911, 0.1796, 0.0844, 0.0360, 0.0089], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,317][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0155, 0.1466, 0.2820, 0.0495, 0.1634, 0.3431], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,321][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.3830e-04, 6.4289e-01, 1.5433e-01, 3.6226e-02, 1.5925e-02, 1.5049e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,322][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1331, 0.1734, 0.1049, 0.1531, 0.1945, 0.2409], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,322][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2919, 0.1677, 0.2204, 0.0457, 0.0489, 0.2255], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,323][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([9.9417e-01, 8.6933e-04, 2.0774e-03, 2.5768e-04, 6.9160e-04, 1.9381e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,324][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([2.5839e-03, 2.8489e-03, 2.6569e-02, 1.7907e-03, 5.6378e-04, 9.6564e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,327][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0057, 0.2940, 0.3071, 0.1162, 0.0771, 0.1999], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,331][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([6.8557e-01, 2.7352e-01, 2.9330e-02, 3.5593e-03, 4.7723e-04, 7.5421e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,333][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.8019, 0.0508, 0.0287, 0.0747, 0.0225, 0.0214], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,334][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([6.3085e-03, 1.6791e-03, 1.5641e-02, 1.9588e-04, 4.4619e-05, 9.7613e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,335][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0015, 0.8101, 0.0009, 0.1758, 0.0099, 0.0018], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,336][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.7575, 0.1889, 0.0120, 0.0129, 0.0015, 0.0272], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,339][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.0077, 0.0508, 0.2132, 0.0449, 0.2135, 0.2151, 0.2547],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,343][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([1.2463e-04, 4.7690e-01, 2.4109e-01, 4.1639e-02, 1.4070e-02, 1.0821e-01,
        1.1797e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,345][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.0183, 0.0776, 0.1143, 0.0211, 0.1177, 0.2137, 0.4373],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,346][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.0507, 0.0728, 0.2591, 0.0236, 0.0730, 0.1694, 0.3515],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,347][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.9643, 0.0017, 0.0111, 0.0018, 0.0035, 0.0111, 0.0064],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,347][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([2.5228e-05, 3.8284e-04, 2.0746e-01, 7.7796e-03, 3.9066e-03, 7.7808e-01,
        2.3679e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,351][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.0011, 0.1608, 0.3388, 0.0791, 0.0901, 0.2007, 0.1293],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,356][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.1916, 0.6327, 0.1008, 0.0053, 0.0025, 0.0327, 0.0342],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,357][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.7900, 0.0439, 0.0190, 0.0251, 0.0125, 0.0088, 0.1007],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,358][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([6.8374e-06, 2.0879e-04, 1.8044e-01, 1.5993e-03, 1.6017e-03, 8.1508e-01,
        1.0609e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,359][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0018, 0.8366, 0.0035, 0.0861, 0.0221, 0.0029, 0.0470],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,360][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0034, 0.0800, 0.1144, 0.0222, 0.0298, 0.7020, 0.0483],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,365][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0046, 0.0743, 0.2552, 0.0687, 0.1130, 0.2120, 0.1660, 0.1062],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,367][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([1.7034e-04, 5.6153e-01, 2.0175e-01, 3.0205e-02, 8.2869e-03, 1.0623e-01,
        5.3516e-02, 3.8318e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,369][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0522, 0.0642, 0.1043, 0.0610, 0.1144, 0.1583, 0.2605, 0.1850],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,370][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.1252, 0.1106, 0.2393, 0.0362, 0.0630, 0.1513, 0.1535, 0.1208],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,371][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.9141, 0.0062, 0.0137, 0.0036, 0.0067, 0.0192, 0.0158, 0.0207],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,372][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([7.9521e-04, 1.7450e-03, 5.3453e-02, 2.9455e-03, 1.3045e-03, 7.9825e-01,
        1.1713e-02, 1.2980e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,375][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0037, 0.1462, 0.2801, 0.1692, 0.0899, 0.1770, 0.1069, 0.0269],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,380][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.2449, 0.5287, 0.1334, 0.0176, 0.0031, 0.0333, 0.0222, 0.0168],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,382][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.6771, 0.0503, 0.0249, 0.0506, 0.0222, 0.0243, 0.1214, 0.0292],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,382][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([1.1029e-03, 1.6625e-03, 3.3215e-02, 6.3965e-04, 2.4098e-04, 7.9407e-01,
        3.1912e-03, 1.6588e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,383][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0015, 0.6771, 0.0029, 0.2515, 0.0226, 0.0030, 0.0388, 0.0027],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,385][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.8179, 0.0514, 0.0094, 0.0092, 0.0017, 0.0248, 0.0081, 0.0774],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,391][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0548, 0.1063, 0.1078, 0.0460, 0.0934, 0.1110, 0.1410, 0.1027, 0.2369],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:32,393][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0008, 0.5549, 0.1044, 0.0233, 0.0079, 0.0616, 0.0542, 0.0424, 0.1505],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:32,394][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2923, 0.1096, 0.0405, 0.0518, 0.0864, 0.0685, 0.2030, 0.1097, 0.0383],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:32,395][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.4223, 0.1006, 0.1075, 0.0134, 0.0315, 0.0947, 0.0686, 0.0787, 0.0826],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:32,396][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([9.5252e-01, 1.9804e-03, 3.9878e-03, 5.9015e-04, 1.6669e-03, 5.0425e-03,
        4.2000e-03, 1.0311e-02, 1.9703e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:32,397][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([4.1755e-03, 1.0869e-03, 1.9462e-03, 2.6686e-04, 6.8655e-05, 6.4799e-02,
        2.6213e-03, 1.7518e-02, 9.0752e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:32,402][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0347, 0.2087, 0.1623, 0.1153, 0.0528, 0.1674, 0.1035, 0.0250, 0.1303],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:32,405][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([8.7273e-01, 1.0191e-01, 8.8938e-03, 1.0998e-03, 2.3269e-04, 3.1367e-03,
        2.5743e-03, 2.3306e-03, 7.0878e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:32,406][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.8516, 0.0206, 0.0075, 0.0123, 0.0075, 0.0040, 0.0497, 0.0107, 0.0362],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:32,407][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([7.0725e-03, 1.5949e-03, 2.0673e-03, 4.0037e-05, 1.4702e-05, 5.2844e-02,
        9.0547e-04, 3.4978e-02, 9.0048e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:32,408][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([4.4438e-03, 8.4656e-01, 6.0492e-04, 1.1244e-01, 8.1812e-03, 1.0578e-03,
        2.4034e-02, 1.2105e-03, 1.4713e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:32,411][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.7246, 0.1206, 0.0116, 0.0131, 0.0025, 0.0293, 0.0149, 0.0324, 0.0509],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:32,417][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([0.0089, 0.0745, 0.0727, 0.0515, 0.1800, 0.1188, 0.0586, 0.1161, 0.2095,
        0.1093], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:32,418][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([1.4705e-04, 5.8234e-01, 6.7925e-02, 4.3740e-02, 2.4476e-02, 5.9119e-02,
        2.5964e-02, 3.2128e-02, 7.0543e-02, 9.3620e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:32,419][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([0.0238, 0.0894, 0.0608, 0.0300, 0.0572, 0.1042, 0.1437, 0.0903, 0.0421,
        0.3584], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:32,420][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([0.2367, 0.1013, 0.0982, 0.0220, 0.0282, 0.0846, 0.0497, 0.0613, 0.0728,
        0.2453], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:32,423][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([0.8253, 0.0067, 0.0155, 0.0029, 0.0058, 0.0226, 0.0119, 0.0375, 0.0518,
        0.0199], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:32,426][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([5.2730e-05, 1.7970e-04, 1.7690e-02, 4.1123e-04, 4.0417e-04, 2.1523e-01,
        8.5738e-04, 2.7758e-02, 7.3305e-01, 4.3621e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:32,430][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([0.0059, 0.1214, 0.1204, 0.1754, 0.0853, 0.1005, 0.0619, 0.0383, 0.0952,
        0.1957], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:32,430][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([0.2504, 0.6200, 0.0313, 0.0081, 0.0010, 0.0141, 0.0065, 0.0097, 0.0260,
        0.0327], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:32,431][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([0.6760, 0.0429, 0.0268, 0.0279, 0.0093, 0.0079, 0.0432, 0.0227, 0.0533,
        0.0899], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:32,432][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([2.8617e-05, 2.0679e-04, 1.8907e-02, 9.2252e-05, 1.8327e-04, 1.4734e-01,
        3.3634e-04, 6.2189e-02, 7.6484e-01, 5.8732e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:32,436][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([0.0021, 0.6145, 0.0014, 0.2060, 0.0245, 0.0032, 0.0276, 0.0034, 0.0027,
        0.1146], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:32,441][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([0.0339, 0.1843, 0.0640, 0.0227, 0.0146, 0.1588, 0.0237, 0.2105, 0.2382,
        0.0494], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:32,442][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0302, 0.0634, 0.0602, 0.0982, 0.1314, 0.0692, 0.0560, 0.0559, 0.0986,
        0.1126, 0.2243], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:32,443][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0007, 0.5171, 0.1022, 0.0630, 0.0102, 0.0412, 0.0333, 0.0221, 0.0516,
        0.0735, 0.0850], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:32,444][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1720, 0.1223, 0.0318, 0.0724, 0.0497, 0.0428, 0.1668, 0.0405, 0.0230,
        0.2141, 0.0645], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:32,447][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3158, 0.0617, 0.0719, 0.0197, 0.0219, 0.0550, 0.0440, 0.0490, 0.0445,
        0.1633, 0.1532], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:32,451][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.7090e-01, 3.7338e-03, 1.4120e-03, 7.3691e-04, 6.2367e-04, 1.2219e-03,
        2.9860e-03, 3.3353e-03, 3.4699e-03, 5.0451e-03, 6.5363e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:32,453][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([1.1790e-02, 8.1595e-04, 1.8547e-04, 3.6042e-05, 1.3031e-05, 7.7659e-03,
        1.3599e-03, 3.5866e-03, 1.2972e-01, 2.1871e-03, 8.4254e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:32,454][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0350, 0.1544, 0.1044, 0.3042, 0.0545, 0.0838, 0.0529, 0.0131, 0.0378,
        0.0981, 0.0618], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:32,455][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([5.2083e-01, 4.3468e-01, 1.3101e-02, 2.5762e-03, 2.4189e-04, 2.2988e-03,
        2.4423e-03, 1.7374e-03, 5.3071e-03, 2.7965e-03, 1.3993e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:32,457][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8646, 0.0101, 0.0045, 0.0157, 0.0065, 0.0029, 0.0337, 0.0072, 0.0186,
        0.0301, 0.0060], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:32,461][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([4.3298e-03, 1.2826e-04, 2.0329e-05, 1.4707e-06, 1.1614e-06, 1.0634e-03,
        1.0910e-04, 1.2589e-03, 1.8829e-02, 5.3979e-04, 9.7372e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:32,465][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([2.8701e-03, 7.7805e-01, 7.2655e-04, 1.6093e-01, 6.5096e-03, 9.8528e-04,
        1.4279e-02, 9.5469e-04, 9.1504e-04, 3.2184e-02, 1.6017e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:32,466][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.8362, 0.0659, 0.0051, 0.0212, 0.0029, 0.0140, 0.0070, 0.0103, 0.0160,
        0.0140, 0.0074], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:32,467][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.0086, 0.0282, 0.0301, 0.0469, 0.1058, 0.0721, 0.0519, 0.0490, 0.1401,
        0.0685, 0.2309, 0.1680], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:32,467][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([1.8334e-04, 2.1474e-01, 6.7901e-02, 2.8571e-02, 2.0489e-02, 6.0801e-02,
        2.0573e-02, 3.0663e-02, 6.3415e-02, 4.6869e-02, 1.3970e-01, 3.0609e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:32,469][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.0470, 0.0618, 0.0307, 0.0235, 0.0699, 0.0814, 0.1867, 0.0404, 0.0244,
        0.1403, 0.1055, 0.1882], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:32,475][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.2956, 0.0717, 0.0290, 0.0148, 0.0233, 0.0349, 0.0358, 0.0443, 0.0459,
        0.1226, 0.1237, 0.1584], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:32,477][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([9.6471e-01, 3.0431e-03, 1.5011e-03, 8.8959e-04, 1.1058e-03, 1.7756e-03,
        2.7989e-03, 3.2064e-03, 3.8393e-03, 3.4269e-03, 5.4077e-03, 8.2933e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:32,478][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.0031, 0.0016, 0.0057, 0.0021, 0.0006, 0.0512, 0.0049, 0.0240, 0.2048,
        0.0122, 0.5783, 0.1115], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:32,479][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.0039, 0.1924, 0.0639, 0.1546, 0.0519, 0.0535, 0.0362, 0.0136, 0.0395,
        0.0429, 0.1142, 0.2334], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:32,483][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.5076, 0.2560, 0.0119, 0.0058, 0.0011, 0.0081, 0.0116, 0.0066, 0.0143,
        0.0179, 0.0321, 0.1270], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:32,488][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.7118, 0.0600, 0.0081, 0.0443, 0.0059, 0.0052, 0.0256, 0.0066, 0.0339,
        0.0533, 0.0171, 0.0282], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:32,489][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([8.4133e-04, 5.1520e-04, 1.9934e-03, 1.8300e-04, 1.5302e-04, 1.9640e-02,
        1.8025e-03, 1.8303e-02, 9.4250e-02, 7.9047e-03, 8.2950e-01, 2.4915e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:32,490][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.0066, 0.5576, 0.0015, 0.2946, 0.0237, 0.0024, 0.0330, 0.0019, 0.0013,
        0.0579, 0.0030, 0.0165], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:32,491][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.0448, 0.1071, 0.0218, 0.0340, 0.0203, 0.1464, 0.0263, 0.2367, 0.1445,
        0.0473, 0.1029, 0.0679], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:32,495][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0074, 0.0088, 0.0164, 0.0332, 0.0514, 0.0631, 0.1037, 0.0623, 0.0726,
        0.1866, 0.1210, 0.1979, 0.0757], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:32,500][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0005, 0.1789, 0.0700, 0.0291, 0.0097, 0.0414, 0.0321, 0.0274, 0.0491,
        0.0783, 0.0988, 0.3540, 0.0306], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:32,501][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0961, 0.0870, 0.0280, 0.0315, 0.0421, 0.0528, 0.0901, 0.0342, 0.0204,
        0.1656, 0.0427, 0.2584, 0.0512], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:32,502][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.3701, 0.0344, 0.0338, 0.0117, 0.0190, 0.0287, 0.0272, 0.0350, 0.0276,
        0.1399, 0.0871, 0.1678, 0.0178], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:32,504][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.8964, 0.0041, 0.0045, 0.0022, 0.0011, 0.0050, 0.0039, 0.0112, 0.0128,
        0.0153, 0.0207, 0.0177, 0.0049], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:32,507][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([1.5435e-04, 1.4492e-04, 2.1944e-03, 2.3528e-04, 7.4986e-05, 2.1414e-02,
        1.1017e-03, 9.1044e-03, 1.7259e-01, 2.3987e-03, 7.3743e-01, 5.2147e-02,
        1.0160e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:32,512][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0111, 0.0809, 0.1084, 0.1016, 0.0381, 0.0947, 0.0443, 0.0113, 0.0429,
        0.1005, 0.0989, 0.2441, 0.0235], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:32,513][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.5635, 0.3235, 0.0175, 0.0037, 0.0014, 0.0041, 0.0040, 0.0052, 0.0114,
        0.0043, 0.0219, 0.0271, 0.0124], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:32,514][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.6490, 0.0424, 0.0191, 0.0303, 0.0134, 0.0086, 0.0482, 0.0156, 0.0435,
        0.0539, 0.0262, 0.0249, 0.0250], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:32,515][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([9.9678e-06, 2.5485e-05, 1.6554e-03, 1.5578e-05, 7.8163e-06, 8.2560e-03,
        9.8930e-05, 2.8007e-03, 4.5807e-02, 7.6307e-04, 9.3616e-01, 3.9067e-03,
        4.9212e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:32,517][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0026, 0.5252, 0.0040, 0.2294, 0.0190, 0.0071, 0.0296, 0.0039, 0.0041,
        0.1157, 0.0093, 0.0176, 0.0324], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:32,523][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.6114, 0.1068, 0.0138, 0.0394, 0.0026, 0.0310, 0.0076, 0.0309, 0.0227,
        0.0391, 0.0148, 0.0583, 0.0214], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:32,525][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0332, 0.0404, 0.0240, 0.0468, 0.0632, 0.0731, 0.0365, 0.0532, 0.0806,
        0.0700, 0.1398, 0.0586, 0.1040, 0.1765], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:32,526][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0006, 0.2238, 0.0528, 0.0270, 0.0071, 0.0444, 0.0258, 0.0222, 0.0689,
        0.0500, 0.0938, 0.2921, 0.0303, 0.0610], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:32,527][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3239, 0.0338, 0.0166, 0.0279, 0.0412, 0.0281, 0.0575, 0.0382, 0.0180,
        0.1506, 0.0401, 0.1456, 0.0515, 0.0269], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:32,530][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.6159, 0.0311, 0.0285, 0.0084, 0.0135, 0.0221, 0.0092, 0.0143, 0.0147,
        0.0600, 0.0548, 0.0682, 0.0197, 0.0396], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:32,534][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.9007e-01, 1.4181e-03, 2.3594e-04, 1.9027e-04, 1.3138e-04, 2.2807e-04,
        6.8171e-04, 8.0799e-04, 7.8775e-04, 9.3768e-04, 1.0443e-03, 2.2378e-03,
        4.5506e-04, 7.7567e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:32,536][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([5.3010e-02, 8.2419e-04, 4.8911e-05, 2.6720e-05, 4.7508e-06, 2.1952e-03,
        1.0571e-03, 1.3394e-03, 4.2003e-02, 1.3766e-03, 3.1888e-01, 1.1673e-01,
        8.3215e-04, 4.6168e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:32,537][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0264, 0.0569, 0.0990, 0.1983, 0.0337, 0.0904, 0.0398, 0.0100, 0.0475,
        0.0667, 0.0991, 0.1462, 0.0218, 0.0642], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:32,538][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([8.8328e-01, 8.3327e-02, 4.2624e-03, 1.7886e-03, 1.4423e-04, 7.7899e-04,
        4.0828e-04, 5.3670e-04, 1.6733e-03, 3.5753e-04, 4.1672e-03, 1.1199e-02,
        1.1207e-03, 6.9541e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:32,539][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.8134, 0.0120, 0.0054, 0.0150, 0.0071, 0.0046, 0.0377, 0.0078, 0.0258,
        0.0259, 0.0081, 0.0086, 0.0115, 0.0171], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:32,540][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.5905e-02, 8.9868e-05, 5.9203e-06, 7.4066e-07, 2.3857e-07, 2.2542e-04,
        5.5289e-05, 4.4266e-04, 4.9257e-03, 2.4838e-04, 2.6939e-01, 1.3085e-02,
        3.5246e-04, 6.9528e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:32,546][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0048, 0.6517, 0.0016, 0.2225, 0.0096, 0.0026, 0.0207, 0.0022, 0.0029,
        0.0440, 0.0034, 0.0076, 0.0163, 0.0101], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:32,548][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([9.7512e-01, 8.8257e-03, 6.7546e-04, 2.4520e-03, 1.3454e-04, 7.0702e-04,
        4.4568e-04, 8.1319e-04, 1.0828e-03, 1.2749e-03, 5.8776e-04, 1.1929e-03,
        9.5642e-04, 5.7343e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:32,549][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0027, 0.0122, 0.0368, 0.0232, 0.0549, 0.0600, 0.0368, 0.0369, 0.1003,
        0.0593, 0.1623, 0.1014, 0.0363, 0.1576, 0.1194], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,550][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0004, 0.2618, 0.0874, 0.0611, 0.0134, 0.0485, 0.0194, 0.0160, 0.0431,
        0.0460, 0.0573, 0.2740, 0.0167, 0.0403, 0.0146], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,554][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0753, 0.0470, 0.0203, 0.0379, 0.0366, 0.0324, 0.0820, 0.0402, 0.0159,
        0.1593, 0.0602, 0.1785, 0.0354, 0.0275, 0.1517], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,560][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.1538, 0.0250, 0.0548, 0.0162, 0.0135, 0.0421, 0.0272, 0.0143, 0.0225,
        0.0978, 0.0916, 0.2998, 0.0075, 0.0603, 0.0736], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,560][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.7351, 0.0174, 0.0089, 0.0043, 0.0028, 0.0063, 0.0130, 0.0137, 0.0199,
        0.0248, 0.0371, 0.0518, 0.0044, 0.0172, 0.0432], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,561][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([1.2033e-04, 5.5024e-05, 6.8017e-04, 5.8774e-05, 2.5720e-05, 1.5658e-02,
        2.2823e-04, 1.9163e-03, 7.9728e-02, 1.3582e-03, 3.9851e-01, 2.5974e-02,
        5.1220e-04, 4.6498e-01, 1.0190e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,562][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0119, 0.0610, 0.0944, 0.1686, 0.0433, 0.1040, 0.0452, 0.0071, 0.0380,
        0.0835, 0.0842, 0.1978, 0.0111, 0.0356, 0.0144], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,566][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.3209, 0.4267, 0.0241, 0.0032, 0.0006, 0.0086, 0.0047, 0.0053, 0.0123,
        0.0134, 0.0359, 0.0794, 0.0058, 0.0252, 0.0339], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,572][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.5719, 0.0209, 0.0165, 0.0400, 0.0142, 0.0070, 0.0632, 0.0133, 0.0375,
        0.0549, 0.0164, 0.0109, 0.0073, 0.0159, 0.1102], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,573][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([6.0165e-06, 8.6755e-06, 1.5017e-04, 1.6006e-06, 1.2059e-06, 1.2425e-03,
        9.7697e-06, 8.0687e-04, 1.1105e-02, 3.0117e-04, 3.5925e-01, 1.7799e-03,
        1.7571e-04, 6.2333e-01, 1.8377e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,574][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0018, 0.4615, 0.0021, 0.2641, 0.0106, 0.0029, 0.0435, 0.0028, 0.0031,
        0.1279, 0.0054, 0.0163, 0.0140, 0.0067, 0.0371], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,576][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.7815, 0.0329, 0.0085, 0.0333, 0.0014, 0.0082, 0.0038, 0.0152, 0.0142,
        0.0206, 0.0108, 0.0148, 0.0109, 0.0304, 0.0134], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:32,581][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.0289, 0.0095, 0.0168, 0.0340, 0.0711, 0.0497, 0.0508, 0.0482, 0.0596,
        0.0777, 0.1418, 0.0827, 0.0519, 0.1247, 0.0904, 0.0624],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,583][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.0007, 0.0971, 0.0577, 0.0240, 0.0083, 0.0500, 0.0360, 0.0230, 0.0659,
        0.0863, 0.1136, 0.2742, 0.0165, 0.0493, 0.0292, 0.0683],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,584][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.1147, 0.0203, 0.0198, 0.0214, 0.0445, 0.0472, 0.0758, 0.0303, 0.0182,
        0.1419, 0.0442, 0.1374, 0.0480, 0.0314, 0.1490, 0.0559],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,585][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([0.5169, 0.0161, 0.0127, 0.0043, 0.0084, 0.0233, 0.0187, 0.0122, 0.0202,
        0.0655, 0.0547, 0.1163, 0.0117, 0.0465, 0.0370, 0.0355],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,586][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([9.6902e-01, 5.6001e-04, 4.4586e-04, 3.3569e-04, 3.6557e-04, 1.3310e-03,
        7.9836e-04, 2.0358e-03, 2.7884e-03, 1.8947e-03, 3.5050e-03, 5.8303e-03,
        6.9414e-04, 2.6444e-03, 3.6961e-03, 4.0499e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,588][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([1.8759e-04, 5.6337e-05, 3.1815e-05, 4.7721e-06, 1.4991e-06, 2.4453e-03,
        1.3185e-04, 6.0168e-04, 3.8722e-02, 2.2408e-04, 2.9868e-01, 2.4560e-02,
        1.9773e-04, 5.1753e-01, 6.4970e-03, 1.1013e-01], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,593][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.0223, 0.0254, 0.0615, 0.1197, 0.0446, 0.1179, 0.0631, 0.0102, 0.0504,
        0.1060, 0.0806, 0.1232, 0.0197, 0.0439, 0.0179, 0.0935],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,595][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([8.9538e-01, 5.9519e-02, 2.3333e-03, 1.0868e-03, 9.7644e-05, 1.4986e-03,
        8.9123e-04, 1.3089e-03, 2.4626e-03, 9.7840e-04, 6.3389e-03, 1.5256e-02,
        9.4871e-04, 6.4049e-03, 2.5700e-03, 2.9198e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,596][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.5608, 0.0132, 0.0095, 0.0135, 0.0089, 0.0086, 0.0382, 0.0146, 0.0552,
        0.0304, 0.0216, 0.0067, 0.0176, 0.0275, 0.1139, 0.0600],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,597][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([2.4645e-04, 3.6014e-06, 3.2922e-06, 9.4380e-08, 5.4713e-08, 2.7902e-04,
        8.1396e-06, 1.4676e-04, 4.3738e-03, 1.0439e-04, 2.3789e-01, 2.7330e-03,
        9.5784e-05, 6.8815e-01, 1.2668e-03, 6.4704e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,601][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.0098, 0.3712, 0.0016, 0.2113, 0.0201, 0.0030, 0.0444, 0.0041, 0.0042,
        0.1349, 0.0061, 0.0133, 0.0291, 0.0144, 0.0640, 0.0686],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,603][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([9.1175e-01, 1.3595e-02, 1.9496e-03, 4.9344e-03, 5.5976e-04, 5.7557e-03,
        2.2253e-03, 6.6378e-03, 7.9745e-03, 6.1930e-03, 4.0370e-03, 4.0318e-03,
        3.7513e-03, 1.3401e-02, 6.3834e-03, 6.8166e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:32,607][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0140, 0.0216, 0.0154, 0.0216, 0.0336, 0.0500, 0.0217, 0.0497, 0.0706,
        0.0352, 0.0998, 0.0445, 0.0405, 0.1509, 0.0817, 0.0646, 0.1846],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,608][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0008, 0.2125, 0.0432, 0.0224, 0.0081, 0.0402, 0.0282, 0.0198, 0.0551,
        0.0556, 0.0758, 0.2698, 0.0225, 0.0426, 0.0155, 0.0335, 0.0543],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,609][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3403, 0.0247, 0.0139, 0.0208, 0.0276, 0.0211, 0.0511, 0.0225, 0.0114,
        0.0932, 0.0259, 0.1052, 0.0305, 0.0171, 0.1137, 0.0312, 0.0498],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,610][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.5257, 0.0273, 0.0242, 0.0084, 0.0142, 0.0286, 0.0116, 0.0154, 0.0206,
        0.0404, 0.0468, 0.0680, 0.0141, 0.0426, 0.0320, 0.0285, 0.0517],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,612][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.8246e-01, 1.0771e-03, 2.7538e-04, 2.1300e-04, 2.2399e-04, 2.8572e-04,
        7.4584e-04, 1.3437e-03, 1.0108e-03, 8.7925e-04, 1.2604e-03, 1.7249e-03,
        3.5669e-04, 9.5688e-04, 3.2279e-03, 1.9849e-03, 1.9701e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,615][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.4363e-02, 5.0888e-04, 3.8772e-05, 1.5471e-05, 4.0908e-06, 1.3059e-03,
        4.5484e-04, 6.3012e-04, 1.8251e-02, 7.5485e-04, 1.0842e-01, 4.9113e-02,
        5.1252e-04, 1.9295e-01, 5.1170e-03, 7.6919e-02, 5.2065e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,619][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0336, 0.0395, 0.0620, 0.1615, 0.0307, 0.0825, 0.0457, 0.0076, 0.0418,
        0.0683, 0.0775, 0.1293, 0.0151, 0.0505, 0.0141, 0.0599, 0.0805],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,620][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([8.1671e-01, 8.7054e-02, 7.7389e-03, 1.8750e-03, 2.5002e-04, 2.8641e-03,
        1.3780e-03, 1.1497e-03, 3.3741e-03, 9.2923e-04, 7.7746e-03, 2.5264e-02,
        1.8245e-03, 1.2852e-02, 3.6920e-03, 2.5020e-03, 2.2768e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,621][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.7829, 0.0066, 0.0041, 0.0095, 0.0048, 0.0037, 0.0279, 0.0068, 0.0229,
        0.0179, 0.0053, 0.0044, 0.0066, 0.0116, 0.0478, 0.0145, 0.0227],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,623][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.6701e-02, 7.1606e-05, 6.2891e-06, 6.7121e-07, 4.2370e-07, 2.6827e-04,
        5.2739e-05, 4.3137e-04, 3.8652e-03, 3.2446e-04, 1.4955e-01, 7.9159e-03,
        3.1184e-04, 4.1072e-01, 2.6878e-03, 8.5937e-02, 3.2116e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,627][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0047, 0.6423, 0.0010, 0.1656, 0.0073, 0.0019, 0.0194, 0.0021, 0.0026,
        0.0367, 0.0034, 0.0068, 0.0115, 0.0085, 0.0279, 0.0339, 0.0244],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,631][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([9.7848e-01, 4.4724e-03, 3.0222e-04, 2.1657e-03, 1.0307e-04, 7.5079e-04,
        4.7369e-04, 5.6646e-04, 8.2289e-04, 1.0510e-03, 3.8764e-04, 1.0981e-03,
        5.9575e-04, 3.6395e-03, 4.4649e-04, 8.3610e-04, 3.8101e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:32,635][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:32,637][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[11578],
        [   27],
        [   10],
        [  287],
        [   23],
        [   15],
        [    4],
        [    9],
        [    4],
        [    3],
        [    5],
        [    2],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1]], device='cuda:0')
[2024-07-24 10:31:32,639][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[9294],
        [  17],
        [   3],
        [  48],
        [   2],
        [   1],
        [   1],
        [   3],
        [   1],
        [   1],
        [   2],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1]], device='cuda:0')
[2024-07-24 10:31:32,642][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[37299],
        [39201],
        [34401],
        [41997],
        [36946],
        [42031],
        [43853],
        [43759],
        [42887],
        [42122],
        [41708],
        [37353],
        [39871],
        [36145],
        [29359],
        [32530],
        [27310]], device='cuda:0')
[2024-07-24 10:31:32,644][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[26782],
        [ 4766],
        [ 4601],
        [ 5063],
        [ 5377],
        [ 6186],
        [ 5364],
        [ 5331],
        [ 4266],
        [ 4367],
        [ 4584],
        [ 3899],
        [ 3569],
        [ 3594],
        [ 4690],
        [ 3146],
        [ 3350]], device='cuda:0')
[2024-07-24 10:31:32,647][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[21226],
        [49890],
        [49655],
        [50051],
        [50172],
        [50173],
        [48701],
        [49833],
        [50024],
        [47641],
        [49718],
        [48808],
        [49188],
        [48871],
        [47677],
        [45749],
        [46320]], device='cuda:0')
[2024-07-24 10:31:32,648][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[10379],
        [ 8642],
        [13917],
        [16605],
        [17200],
        [12160],
        [19089],
        [17671],
        [16572],
        [11754],
        [13058],
        [ 9327],
        [ 8444],
        [10686],
        [ 9517],
        [11568],
        [15441]], device='cuda:0')
[2024-07-24 10:31:32,650][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[26176],
        [31512],
        [26822],
        [27377],
        [27730],
        [26926],
        [30847],
        [38662],
        [33955],
        [45285],
        [31722],
        [32808],
        [42177],
        [28046],
        [46669],
        [31069],
        [28988]], device='cuda:0')
[2024-07-24 10:31:32,653][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[24924],
        [16613],
        [ 7720],
        [ 7747],
        [ 7779],
        [22833],
        [19611],
        [21816],
        [22168],
        [22022],
        [12732],
        [14159],
        [13284],
        [16365],
        [16611],
        [17767],
        [20467]], device='cuda:0')
[2024-07-24 10:31:32,655][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 7656],
        [38303],
        [32707],
        [39551],
        [37639],
        [37364],
        [31417],
        [37090],
        [34725],
        [35531],
        [44015],
        [37741],
        [32389],
        [39066],
        [36527],
        [33340],
        [37276]], device='cuda:0')
[2024-07-24 10:31:32,658][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[35968],
        [ 5914],
        [ 6366],
        [ 4803],
        [ 5373],
        [ 6576],
        [ 4946],
        [ 4128],
        [14290],
        [ 5255],
        [ 5978],
        [ 9779],
        [ 6645],
        [17242],
        [ 7270],
        [22284],
        [14283]], device='cuda:0')
[2024-07-24 10:31:32,660][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[40836],
        [20091],
        [22362],
        [20422],
        [21255],
        [28974],
        [28278],
        [27207],
        [36796],
        [35500],
        [39456],
        [34755],
        [36269],
        [40247],
        [36725],
        [41402],
        [42324]], device='cuda:0')
[2024-07-24 10:31:32,662][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[34729],
        [21110],
        [39178],
        [39190],
        [39189],
        [43653],
        [43218],
        [44767],
        [46211],
        [46204],
        [40789],
        [41604],
        [41049],
        [41952],
        [42018],
        [42229],
        [41140]], device='cuda:0')
[2024-07-24 10:31:32,663][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 6636],
        [46725],
        [46753],
        [50190],
        [49813],
        [49911],
        [49571],
        [50124],
        [49843],
        [48175],
        [49821],
        [49360],
        [49248],
        [49791],
        [48794],
        [48408],
        [49714]], device='cuda:0')
[2024-07-24 10:31:32,665][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[32335],
        [33633],
        [32374],
        [45738],
        [46958],
        [32513],
        [42765],
        [32667],
        [32468],
        [40755],
        [32454],
        [42725],
        [47497],
        [32355],
        [39692],
        [32973],
        [32351]], device='cuda:0')
[2024-07-24 10:31:32,667][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[21640],
        [ 8248],
        [14766],
        [ 7500],
        [14956],
        [12554],
        [11805],
        [ 4944],
        [15847],
        [34724],
        [10243],
        [22989],
        [ 7808],
        [10555],
        [ 9900],
        [15816],
        [ 8714]], device='cuda:0')
[2024-07-24 10:31:32,670][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[11396],
        [17639],
        [31930],
        [34800],
        [31672],
        [30713],
        [26100],
        [29315],
        [28011],
        [28469],
        [31133],
        [30603],
        [27255],
        [29043],
        [31202],
        [29580],
        [30894]], device='cuda:0')
[2024-07-24 10:31:32,672][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[40253],
        [40313],
        [41582],
        [41211],
        [42174],
        [44231],
        [44330],
        [44283],
        [45076],
        [44962],
        [45180],
        [44756],
        [44408],
        [44815],
        [44469],
        [45049],
        [44853]], device='cuda:0')
[2024-07-24 10:31:32,675][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[31180],
        [34257],
        [35729],
        [35100],
        [36137],
        [33629],
        [39598],
        [35874],
        [37321],
        [37307],
        [38611],
        [38144],
        [37178],
        [35503],
        [33803],
        [32447],
        [32464]], device='cuda:0')
[2024-07-24 10:31:32,677][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[36728],
        [33344],
        [13102],
        [10511],
        [12651],
        [16141],
        [15578],
        [14514],
        [17000],
        [22347],
        [20491],
        [25633],
        [25473],
        [25028],
        [23243],
        [25208],
        [22584]], device='cuda:0')
[2024-07-24 10:31:32,679][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[27388],
        [28264],
        [27401],
        [27469],
        [27130],
        [27288],
        [25461],
        [19757],
        [24107],
        [13569],
        [26070],
        [26446],
        [20746],
        [27446],
        [10895],
        [26750],
        [26908]], device='cuda:0')
[2024-07-24 10:31:32,680][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[27912],
        [27868],
        [20344],
        [20318],
        [20294],
        [16844],
        [17659],
        [17421],
        [10848],
        [11767],
        [20964],
        [18094],
        [19521],
        [21197],
        [21366],
        [21396],
        [20181]], device='cuda:0')
[2024-07-24 10:31:32,682][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[14119],
        [15566],
        [12065],
        [11571],
        [11109],
        [13487],
        [14680],
        [14245],
        [17066],
        [17771],
        [15908],
        [21314],
        [22842],
        [19711],
        [20919],
        [22854],
        [22262]], device='cuda:0')
[2024-07-24 10:31:32,684][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[22693],
        [34093],
        [32222],
        [32077],
        [32833],
        [29968],
        [33775],
        [33584],
        [25343],
        [34102],
        [32577],
        [33257],
        [32017],
        [24854],
        [33971],
        [24220],
        [25181]], device='cuda:0')
[2024-07-24 10:31:32,687][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 9923],
        [14882],
        [15499],
        [15080],
        [17866],
        [13807],
        [12876],
        [15189],
        [10939],
        [12692],
        [10642],
        [13101],
        [14101],
        [11193],
        [15747],
        [15454],
        [13033]], device='cuda:0')
[2024-07-24 10:31:32,690][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[32465],
        [ 8619],
        [15632],
        [15646],
        [15645],
        [ 9967],
        [10907],
        [ 7486],
        [ 3512],
        [ 3807],
        [ 5254],
        [ 4933],
        [ 5138],
        [ 5120],
        [ 5040],
        [ 4819],
        [ 5407]], device='cuda:0')
[2024-07-24 10:31:32,692][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[26358],
        [25754],
        [25779],
        [24127],
        [24331],
        [24053],
        [24379],
        [23536],
        [24582],
        [22375],
        [23954],
        [22880],
        [21456],
        [22991],
        [21322],
        [18994],
        [22123]], device='cuda:0')
[2024-07-24 10:31:32,693][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 8505],
        [ 8786],
        [ 7797],
        [ 7872],
        [ 6682],
        [ 7448],
        [14424],
        [11726],
        [ 8433],
        [10430],
        [ 8479],
        [10429],
        [ 7274],
        [ 8611],
        [ 9103],
        [ 9176],
        [ 8605]], device='cuda:0')
[2024-07-24 10:31:32,695][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 7272],
        [ 7201],
        [ 8013],
        [ 8750],
        [ 8027],
        [ 9019],
        [ 8293],
        [ 8800],
        [10743],
        [12463],
        [ 8303],
        [ 8437],
        [ 9658],
        [ 8916],
        [11267],
        [ 9118],
        [ 9287]], device='cuda:0')
[2024-07-24 10:31:32,698][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[17063],
        [18522],
        [12696],
        [16950],
        [16620],
        [22640],
        [18535],
        [25924],
        [19598],
        [ 7714],
        [10305],
        [ 3226],
        [ 8552],
        [ 7874],
        [ 7685],
        [ 6025],
        [ 9789]], device='cuda:0')
[2024-07-24 10:31:32,701][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[21547],
        [21547],
        [21547],
        [21547],
        [21547],
        [21547],
        [21547],
        [21547],
        [21547],
        [21547],
        [21547],
        [21547],
        [21547],
        [21547],
        [21547],
        [21547],
        [21547]], device='cuda:0')
[2024-07-24 10:31:32,820][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:32,822][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,825][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,826][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,826][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,827][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,828][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,828][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,829][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,830][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,830][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,831][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,832][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:32,832][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.9170, 0.0830], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,833][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.9937, 0.0063], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,834][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.0853, 0.9147], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,835][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.8160, 0.1840], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,838][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.0133, 0.9867], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,840][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.2115, 0.7885], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,840][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.1402, 0.8598], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,841][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.9007, 0.0993], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,842][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.9888, 0.0112], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,843][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.9805, 0.0195], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,844][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([9.9988e-01, 1.1992e-04], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,846][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.7137, 0.2863], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:32,849][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4323, 0.5411, 0.0267], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,853][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([9.1136e-01, 8.8451e-02, 1.9059e-04], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,854][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0016, 0.0340, 0.9644], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,855][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0043, 0.7723, 0.2234], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,855][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0239, 0.4112, 0.5648], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,856][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0768, 0.8815, 0.0417], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,860][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0041, 0.9945, 0.0014], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,865][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3272, 0.6674, 0.0054], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,866][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.9492, 0.0153, 0.0355], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,867][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.8932, 0.1031, 0.0037], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,868][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([9.9991e-01, 9.3812e-05, 6.4473e-07], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,869][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.8462, 0.1524, 0.0014], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:32,872][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Nathan] are: tensor([0.7866, 0.1767, 0.0158, 0.0208], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,876][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Nathan] are: tensor([8.9966e-01, 1.0015e-01, 1.6894e-04, 1.9980e-05], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,878][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Nathan] are: tensor([8.3670e-04, 2.2186e-02, 9.4031e-01, 3.6667e-02], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,879][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Nathan] are: tensor([0.0206, 0.1446, 0.8317, 0.0030], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,879][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Nathan] are: tensor([0.0034, 0.1097, 0.8312, 0.0557], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,880][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Nathan] are: tensor([0.1164, 0.8063, 0.0679, 0.0094], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,881][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Nathan] are: tensor([0.0289, 0.9633, 0.0055, 0.0023], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,884][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Nathan] are: tensor([1.5048e-01, 8.4412e-01, 4.8598e-03, 5.4288e-04], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,889][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Nathan] are: tensor([0.9307, 0.0129, 0.0316, 0.0248], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,890][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Nathan] are: tensor([9.6566e-01, 3.3177e-02, 1.1260e-03, 3.9922e-05], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,891][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Nathan] are: tensor([9.9999e-01, 1.1855e-05, 5.1724e-07, 9.5430e-08], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,892][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Nathan] are: tensor([0.9658, 0.0279, 0.0043, 0.0020], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:32,893][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.7552, 0.1325, 0.0490, 0.0365, 0.0268], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,894][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ got] are: tensor([7.4748e-01, 2.5167e-01, 5.5751e-04, 9.0296e-05, 2.0128e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,896][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ got] are: tensor([2.1788e-04, 1.8219e-02, 9.2501e-01, 3.1967e-02, 2.4588e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,899][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ got] are: tensor([4.2656e-04, 1.1986e-01, 8.7726e-01, 2.0161e-03, 4.3854e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,903][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.0019, 0.1182, 0.4830, 0.0692, 0.3277], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,904][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.0626, 0.8745, 0.0453, 0.0161, 0.0014], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,904][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ got] are: tensor([3.5512e-03, 9.9285e-01, 2.6242e-03, 4.0034e-04, 5.7430e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,905][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ got] are: tensor([8.4836e-02, 9.0409e-01, 9.1904e-03, 1.0714e-03, 8.1690e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,906][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.9257, 0.0109, 0.0274, 0.0211, 0.0149], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,907][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ got] are: tensor([9.4288e-01, 5.3545e-02, 3.3845e-03, 3.0255e-05, 1.6389e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,911][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ got] are: tensor([9.9996e-01, 2.6716e-05, 8.1668e-06, 2.5755e-07, 5.0471e-07],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,915][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.6398, 0.3196, 0.0237, 0.0140, 0.0029], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:32,916][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4940, 0.3540, 0.0459, 0.0195, 0.0079, 0.0789], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,917][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.6063e-01, 1.3917e-01, 7.6223e-05, 1.4612e-05, 2.8806e-05, 8.0417e-05],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,917][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0016, 0.0412, 0.7179, 0.0273, 0.0234, 0.1885], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,918][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.7373e-02, 8.6855e-01, 1.1133e-01, 1.2690e-03, 1.8661e-04, 1.2873e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,922][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0200, 0.2390, 0.3441, 0.0617, 0.2001, 0.1351], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,927][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2238, 0.6803, 0.0608, 0.0107, 0.0031, 0.0213], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,928][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([3.8125e-03, 9.9277e-01, 2.2350e-03, 3.8380e-04, 4.9063e-04, 3.0305e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,929][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([5.4299e-02, 9.3490e-01, 9.1747e-03, 5.8060e-04, 2.8315e-04, 7.6312e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,930][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.8891, 0.0137, 0.0330, 0.0261, 0.0190, 0.0190], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,931][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([9.0488e-01, 8.5442e-02, 8.2158e-03, 1.6187e-04, 4.7891e-04, 8.2462e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,932][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.9998e-01, 1.5452e-05, 1.1034e-06, 1.2868e-07, 1.5277e-08, 2.4153e-06],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,936][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([5.2662e-01, 4.6485e-01, 2.9448e-03, 4.6842e-03, 1.3300e-04, 7.7036e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:32,940][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.5794, 0.1999, 0.0232, 0.0712, 0.0304, 0.0852, 0.0106],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,941][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([3.4298e-01, 6.4587e-01, 3.7612e-03, 2.5837e-04, 2.0759e-03, 3.8371e-03,
        1.2264e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,941][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([4.7186e-04, 1.1347e-02, 6.5633e-01, 4.0187e-02, 3.7859e-02, 2.3985e-01,
        1.3954e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,942][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([5.9351e-04, 1.5087e-02, 9.0647e-01, 2.0260e-02, 1.2700e-02, 4.4202e-02,
        6.8449e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,944][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0028, 0.0314, 0.4963, 0.0259, 0.2291, 0.1066, 0.1080],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,948][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.0129, 0.5412, 0.3431, 0.0088, 0.0072, 0.0601, 0.0267],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,952][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([8.1878e-04, 9.6268e-01, 2.4365e-02, 2.0091e-03, 5.4438e-03, 2.5244e-03,
        2.1598e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,953][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([1.2040e-02, 9.7361e-01, 9.0096e-03, 5.9672e-04, 5.7716e-04, 1.3883e-03,
        2.7755e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,954][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.8579, 0.0153, 0.0357, 0.0279, 0.0206, 0.0204, 0.0222],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,955][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.3360, 0.3278, 0.3230, 0.0004, 0.0027, 0.0096, 0.0006],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,956][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([9.9745e-01, 3.9022e-04, 2.6646e-04, 3.8082e-05, 6.9153e-05, 1.7649e-03,
        1.7101e-05], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,961][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.3645, 0.2257, 0.0762, 0.0702, 0.0368, 0.1313, 0.0953],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:32,964][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.4107, 0.1987, 0.0405, 0.1512, 0.0356, 0.0948, 0.0108, 0.0576],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,965][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ at] are: tensor([6.4005e-01, 3.5892e-01, 4.7739e-04, 5.2790e-05, 1.0618e-04, 2.0058e-04,
        1.1770e-04, 7.2856e-05], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,966][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ at] are: tensor([3.3680e-04, 2.2289e-02, 7.0644e-01, 2.7929e-02, 2.8848e-02, 1.2788e-01,
        1.2989e-02, 7.3290e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,967][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0204, 0.3166, 0.6346, 0.0095, 0.0021, 0.0152, 0.0008, 0.0008],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,970][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0031, 0.0858, 0.4031, 0.0315, 0.1750, 0.0647, 0.1577, 0.0791],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,975][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0787, 0.6331, 0.1699, 0.0328, 0.0056, 0.0226, 0.0170, 0.0404],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,977][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ at] are: tensor([4.2785e-03, 9.7811e-01, 1.0307e-02, 3.2051e-03, 1.2475e-03, 9.9006e-04,
        1.2947e-03, 5.7249e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,978][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ at] are: tensor([4.3859e-02, 9.3815e-01, 1.3388e-02, 1.2601e-03, 6.5739e-04, 7.8736e-04,
        9.1835e-04, 9.7912e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,979][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.8189, 0.0160, 0.0385, 0.0298, 0.0224, 0.0220, 0.0249, 0.0274],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,979][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ at] are: tensor([7.9916e-01, 1.7901e-01, 1.7329e-02, 4.5533e-04, 8.3229e-04, 5.3587e-04,
        2.4315e-04, 2.4359e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,981][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ at] are: tensor([9.9982e-01, 1.3469e-04, 1.8398e-05, 4.6227e-06, 8.2573e-07, 2.0968e-05,
        1.0585e-06, 2.0440e-06], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,983][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ at] are: tensor([5.2986e-01, 4.3948e-01, 1.2777e-02, 1.0199e-02, 4.0526e-04, 2.2282e-03,
        3.0482e-03, 2.0019e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:32,989][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.8375, 0.0994, 0.0045, 0.0101, 0.0029, 0.0132, 0.0017, 0.0100, 0.0208],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:32,990][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ the] are: tensor([8.8164e-01, 1.1794e-01, 5.1716e-05, 1.3634e-05, 2.4435e-05, 5.2978e-05,
        5.0456e-05, 2.9063e-05, 1.9610e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:32,991][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0031, 0.0799, 0.4996, 0.0360, 0.0299, 0.1015, 0.0181, 0.0583, 0.1737],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:32,992][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.2172, 0.5439, 0.1932, 0.0050, 0.0011, 0.0054, 0.0012, 0.0011, 0.0319],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:32,995][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0143, 0.1168, 0.2356, 0.0255, 0.1388, 0.0611, 0.2143, 0.0485, 0.1451],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:33,000][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.3760, 0.5115, 0.0323, 0.0087, 0.0022, 0.0114, 0.0050, 0.0214, 0.0315],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:33,002][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ the] are: tensor([9.1620e-03, 9.8443e-01, 2.2170e-03, 6.5009e-04, 8.9314e-04, 3.7233e-04,
        6.6134e-04, 3.7989e-04, 1.2360e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:33,002][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ the] are: tensor([1.4268e-01, 8.5326e-01, 2.3861e-03, 2.8774e-04, 1.7518e-04, 2.8103e-04,
        3.8901e-04, 2.8201e-04, 2.6221e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:33,003][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.8150, 0.0146, 0.0346, 0.0260, 0.0202, 0.0203, 0.0220, 0.0250, 0.0224],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:33,004][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ the] are: tensor([9.8066e-01, 1.5718e-02, 1.1661e-03, 3.1948e-05, 7.4009e-05, 1.3672e-04,
        4.1566e-05, 3.4945e-04, 1.8257e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:33,006][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ the] are: tensor([9.9998e-01, 1.3808e-05, 7.0476e-07, 1.0074e-07, 3.4251e-08, 1.6608e-06,
        2.8633e-08, 9.1181e-08, 1.1104e-06], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:33,009][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ the] are: tensor([7.5527e-01, 2.1083e-01, 1.2540e-03, 1.9204e-03, 2.3535e-04, 5.8266e-04,
        2.1899e-03, 7.7801e-04, 2.6938e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:33,013][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([0.3007, 0.3912, 0.0452, 0.0886, 0.0186, 0.0398, 0.0046, 0.0429, 0.0588,
        0.0096], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,014][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([7.9219e-01, 2.0500e-01, 2.7112e-04, 4.1838e-05, 1.1205e-04, 1.4080e-04,
        7.9792e-05, 7.3247e-05, 9.7575e-04, 1.1194e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,015][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([0.0025, 0.0237, 0.4368, 0.0494, 0.0346, 0.1726, 0.0141, 0.0551, 0.1283,
        0.0829], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,016][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([6.6928e-03, 9.4578e-02, 8.1409e-01, 1.3786e-02, 3.6989e-03, 1.8931e-02,
        5.5814e-04, 2.2671e-03, 4.2370e-02, 3.0308e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,019][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([0.0048, 0.0746, 0.2625, 0.0155, 0.1018, 0.0521, 0.0367, 0.0285, 0.0701,
        0.3533], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,025][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([0.0115, 0.6382, 0.1297, 0.0069, 0.0049, 0.0246, 0.0063, 0.0305, 0.0494,
        0.0980], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,026][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([4.1701e-03, 9.7496e-01, 1.1449e-02, 1.6039e-03, 2.7150e-03, 9.1750e-04,
        7.8297e-04, 7.1148e-04, 2.3680e-03, 3.2127e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,027][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([8.0486e-02, 9.0382e-01, 9.6474e-03, 4.8554e-04, 6.5685e-04, 5.6001e-04,
        7.8076e-04, 6.3657e-04, 5.6062e-04, 2.3699e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,028][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.7791, 0.0155, 0.0371, 0.0283, 0.0211, 0.0224, 0.0242, 0.0273, 0.0245,
        0.0206], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,030][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([6.7680e-01, 2.8314e-01, 2.2513e-02, 2.7398e-04, 2.5320e-03, 9.8543e-04,
        1.2373e-04, 4.1894e-03, 8.7706e-03, 6.6532e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,033][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([9.9875e-01, 7.7737e-04, 7.3571e-05, 1.2203e-05, 6.6684e-06, 1.2820e-04,
        1.2385e-06, 3.4876e-06, 4.7279e-05, 1.9658e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,037][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([0.5452, 0.1256, 0.0174, 0.0163, 0.0073, 0.0105, 0.0088, 0.0206, 0.2345,
        0.0138], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,038][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.7293, 0.2053, 0.0038, 0.0117, 0.0018, 0.0065, 0.0012, 0.0109, 0.0208,
        0.0013, 0.0076], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,039][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([9.3519e-01, 6.3978e-02, 4.0339e-05, 2.1740e-05, 2.4526e-05, 2.2105e-05,
        2.8214e-05, 1.8001e-05, 1.1514e-04, 3.9407e-04, 1.7113e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,040][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0025, 0.0339, 0.2720, 0.0253, 0.0172, 0.0530, 0.0072, 0.0262, 0.0761,
        0.0372, 0.4494], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,044][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3581, 0.4312, 0.0751, 0.0074, 0.0011, 0.0024, 0.0016, 0.0008, 0.0090,
        0.0018, 0.1115], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,050][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0045, 0.0770, 0.2004, 0.0172, 0.0875, 0.0271, 0.1016, 0.0165, 0.0437,
        0.2458, 0.1787], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,050][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1218, 0.5754, 0.0733, 0.0102, 0.0012, 0.0074, 0.0053, 0.0155, 0.0239,
        0.0599, 0.1061], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,051][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([1.3555e-02, 9.7181e-01, 5.7463e-03, 2.9016e-03, 1.9384e-03, 5.0847e-04,
        6.8006e-04, 4.9515e-04, 1.3135e-03, 4.0543e-04, 6.4503e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,052][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([3.1117e-01, 6.7946e-01, 4.6628e-03, 5.9297e-04, 4.2673e-04, 2.7334e-04,
        4.7709e-04, 2.7874e-04, 3.1757e-04, 1.1582e-03, 1.1822e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,056][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.7324, 0.0157, 0.0368, 0.0294, 0.0218, 0.0216, 0.0241, 0.0264, 0.0231,
        0.0210, 0.0476], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,060][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([9.4595e-01, 4.9276e-02, 2.2942e-03, 5.6414e-05, 1.7568e-04, 7.2547e-05,
        1.9194e-05, 3.5485e-04, 6.1512e-04, 1.3720e-04, 1.0450e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,064][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([9.9978e-01, 1.8278e-04, 1.6461e-06, 8.4985e-07, 1.8139e-07, 4.1521e-06,
        1.7085e-07, 3.4134e-07, 2.3627e-06, 1.7276e-05, 7.9586e-06],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,064][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([9.0551e-01, 7.3706e-02, 2.7598e-04, 9.8709e-04, 2.0195e-04, 1.6005e-04,
        1.5862e-03, 3.9940e-04, 7.7215e-03, 1.1952e-03, 8.2607e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,065][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.2128, 0.3088, 0.0344, 0.0349, 0.0110, 0.0578, 0.0045, 0.0303, 0.0477,
        0.0092, 0.0362, 0.2124], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,066][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([8.8764e-01, 1.0856e-01, 1.5734e-04, 5.3391e-05, 8.8048e-05, 1.6897e-04,
        1.0526e-04, 8.6722e-05, 6.6316e-04, 8.0446e-04, 7.5393e-04, 9.2200e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,070][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.0036, 0.0134, 0.2077, 0.0248, 0.0320, 0.1033, 0.0090, 0.0342, 0.0927,
        0.0421, 0.3818, 0.0555], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,076][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.0445, 0.3402, 0.1992, 0.0171, 0.0101, 0.0045, 0.0023, 0.0045, 0.0385,
        0.0141, 0.2921, 0.0328], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,077][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.0067, 0.2138, 0.1139, 0.0126, 0.0746, 0.0282, 0.0179, 0.0271, 0.0630,
        0.1219, 0.1318, 0.1885], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,077][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.0301, 0.6620, 0.0267, 0.0046, 0.0019, 0.0091, 0.0281, 0.0169, 0.0242,
        0.0564, 0.0512, 0.0889], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,079][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([8.6367e-03, 9.8066e-01, 3.9222e-03, 8.6096e-04, 1.6384e-03, 3.0893e-04,
        7.7770e-04, 2.6073e-04, 8.5942e-04, 1.8415e-04, 1.1003e-03, 7.9320e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,082][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([1.5264e-01, 8.2324e-01, 8.9568e-03, 8.3670e-04, 7.8490e-04, 9.6387e-04,
        1.9128e-03, 6.0224e-04, 6.2438e-04, 2.2672e-03, 1.9356e-03, 5.2405e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,087][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.7801, 0.0118, 0.0282, 0.0220, 0.0159, 0.0166, 0.0179, 0.0204, 0.0178,
        0.0156, 0.0369, 0.0170], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,088][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([9.1822e-01, 5.9524e-02, 8.6686e-03, 1.4492e-04, 8.6722e-04, 3.1490e-04,
        2.1273e-04, 1.3451e-03, 3.6046e-03, 3.1088e-04, 6.4946e-03, 2.9724e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,089][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([9.9699e-01, 1.3106e-04, 1.1932e-05, 3.9587e-06, 1.0827e-06, 2.2400e-05,
        3.3873e-07, 8.5076e-07, 9.2285e-06, 1.7814e-04, 2.6708e-05, 2.6249e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,090][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.3419, 0.4223, 0.0016, 0.0198, 0.0013, 0.0017, 0.0102, 0.0144, 0.0545,
        0.0103, 0.0256, 0.0963], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,094][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.6305, 0.1861, 0.0148, 0.0373, 0.0052, 0.0152, 0.0023, 0.0247, 0.0327,
        0.0031, 0.0181, 0.0243, 0.0057], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,098][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([7.4249e-01, 2.5004e-01, 8.0281e-04, 6.8199e-05, 2.3798e-04, 1.8776e-04,
        7.4588e-05, 9.7980e-05, 5.4206e-04, 1.6382e-03, 1.8586e-03, 1.8182e-03,
        1.4978e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,100][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0005, 0.0165, 0.2454, 0.0242, 0.0166, 0.0846, 0.0180, 0.0532, 0.1032,
        0.0507, 0.3175, 0.0529, 0.0166], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,101][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([6.9538e-03, 8.8640e-02, 2.7018e-01, 5.8772e-03, 1.5740e-03, 9.9449e-03,
        1.5203e-03, 5.4118e-03, 5.1653e-02, 6.0846e-03, 5.1754e-01, 3.4444e-02,
        1.7904e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,102][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0009, 0.0119, 0.3148, 0.0138, 0.1415, 0.0473, 0.0148, 0.0334, 0.0347,
        0.1073, 0.1416, 0.0666, 0.0713], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,105][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0074, 0.5900, 0.1021, 0.0103, 0.0028, 0.0117, 0.0044, 0.0170, 0.0267,
        0.0449, 0.0880, 0.0659, 0.0289], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,109][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([3.3568e-03, 9.7634e-01, 9.4360e-03, 2.4029e-03, 2.1514e-03, 6.6672e-04,
        7.4879e-04, 6.1414e-04, 1.4482e-03, 3.3590e-04, 1.2393e-03, 8.5996e-04,
        3.9532e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,111][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([9.1095e-02, 8.9097e-01, 7.2173e-03, 1.4343e-03, 2.7324e-04, 5.9309e-04,
        4.9339e-04, 4.4496e-04, 4.5262e-04, 1.4252e-03, 1.9765e-03, 2.3590e-03,
        1.2701e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,112][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.7124, 0.0139, 0.0320, 0.0256, 0.0188, 0.0191, 0.0213, 0.0240, 0.0209,
        0.0185, 0.0419, 0.0194, 0.0323], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,113][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([9.3693e-01, 5.0359e-02, 6.4299e-03, 1.5917e-04, 1.8603e-04, 1.7500e-04,
        1.8520e-04, 5.0400e-04, 1.6468e-03, 4.6853e-04, 2.4875e-03, 2.5050e-04,
        2.1984e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,114][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([9.9638e-01, 7.3239e-04, 1.7640e-04, 9.8593e-06, 6.6939e-06, 1.0531e-04,
        7.9455e-07, 1.9479e-05, 9.0430e-05, 2.2457e-04, 2.9715e-04, 1.8616e-03,
        9.1055e-05], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,117][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.3381, 0.4505, 0.0079, 0.0034, 0.0011, 0.0035, 0.0063, 0.0027, 0.0762,
        0.0059, 0.0462, 0.0457, 0.0126], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,123][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.7775, 0.0952, 0.0060, 0.0092, 0.0041, 0.0073, 0.0018, 0.0159, 0.0237,
        0.0034, 0.0149, 0.0113, 0.0039, 0.0258], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,124][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([8.5322e-01, 1.4388e-01, 1.2704e-04, 3.6072e-05, 5.8367e-05, 9.7639e-05,
        5.4366e-05, 2.7329e-05, 4.0413e-04, 5.6397e-04, 4.8756e-04, 7.6762e-04,
        3.0262e-05, 2.4200e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,125][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0024, 0.0292, 0.1940, 0.0275, 0.0189, 0.0656, 0.0124, 0.0422, 0.0927,
        0.0424, 0.3078, 0.0384, 0.0203, 0.1061], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,127][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([4.6160e-01, 2.2848e-01, 2.6539e-02, 1.5805e-03, 5.5795e-04, 7.9456e-04,
        1.0785e-03, 1.3150e-03, 1.6290e-02, 3.5856e-03, 1.5261e-01, 3.1550e-02,
        1.6998e-04, 7.3854e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,131][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0020, 0.0332, 0.1233, 0.0068, 0.0556, 0.0275, 0.0440, 0.0190, 0.0464,
        0.1611, 0.1290, 0.1830, 0.0815, 0.0876], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,135][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1017, 0.3741, 0.0980, 0.0142, 0.0037, 0.0106, 0.0068, 0.0274, 0.0357,
        0.0844, 0.1392, 0.0601, 0.0249, 0.0190], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,136][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([2.7335e-02, 9.4793e-01, 9.0651e-03, 2.1005e-03, 1.5080e-03, 9.2493e-04,
        1.2489e-03, 8.5114e-04, 3.2822e-03, 6.9466e-04, 1.6583e-03, 6.7434e-04,
        4.0248e-04, 2.3263e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,137][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([5.2793e-01, 4.6083e-01, 3.4335e-03, 6.3725e-04, 6.9809e-04, 3.0011e-04,
        6.1692e-04, 3.6007e-04, 3.6209e-04, 1.5908e-03, 1.1458e-03, 1.0318e-03,
        7.2779e-04, 3.3318e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,138][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.7200, 0.0124, 0.0288, 0.0228, 0.0170, 0.0170, 0.0191, 0.0211, 0.0189,
        0.0164, 0.0384, 0.0174, 0.0297, 0.0211], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,139][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.6703e-01, 2.6965e-02, 1.8577e-03, 4.2887e-05, 1.0310e-04, 6.5457e-05,
        2.1240e-05, 2.8240e-04, 1.3755e-03, 1.1150e-04, 8.9319e-04, 3.0778e-05,
        9.6812e-05, 1.1231e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,143][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.9976e-01, 8.3675e-05, 2.0321e-06, 4.9994e-07, 6.9992e-08, 1.1953e-06,
        3.7769e-08, 3.1924e-07, 2.0820e-06, 4.1381e-06, 5.2382e-06, 6.2772e-05,
        6.4629e-06, 7.2748e-05], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,147][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([6.5027e-01, 2.8220e-01, 5.6159e-04, 6.5801e-04, 5.1040e-05, 9.0968e-05,
        8.8965e-04, 1.6283e-04, 7.9214e-03, 1.4710e-03, 1.0635e-02, 2.9697e-02,
        3.9032e-03, 1.1490e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,148][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.5985, 0.1242, 0.0087, 0.0185, 0.0147, 0.0120, 0.0054, 0.0290, 0.0417,
        0.0062, 0.0247, 0.0358, 0.0058, 0.0399, 0.0353], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,149][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ give] are: tensor([7.4019e-01, 2.5415e-01, 3.9184e-04, 8.1563e-05, 1.5261e-04, 1.4080e-04,
        1.0797e-04, 3.9216e-05, 6.5605e-04, 8.3847e-04, 1.1621e-03, 1.3168e-03,
        3.3462e-05, 3.3110e-04, 4.0343e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,153][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0004, 0.0134, 0.2676, 0.0193, 0.0191, 0.0644, 0.0072, 0.0347, 0.0687,
        0.0416, 0.3195, 0.0315, 0.0126, 0.0847, 0.0154], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,157][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ give] are: tensor([6.8027e-03, 6.6347e-02, 2.8086e-01, 1.6876e-03, 1.4070e-03, 7.8169e-03,
        1.5904e-03, 1.7530e-03, 3.8618e-02, 7.1469e-03, 4.3719e-01, 2.7095e-02,
        9.2264e-05, 1.1974e-01, 1.8563e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,159][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0007, 0.0275, 0.1640, 0.0080, 0.0448, 0.0248, 0.0264, 0.0144, 0.0446,
        0.1314, 0.1268, 0.1992, 0.0723, 0.0727, 0.0425], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,160][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0133, 0.7142, 0.0690, 0.0068, 0.0014, 0.0057, 0.0013, 0.0058, 0.0156,
        0.0171, 0.0638, 0.0468, 0.0114, 0.0073, 0.0204], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,161][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ give] are: tensor([5.0206e-03, 9.8032e-01, 6.8907e-03, 7.3560e-04, 1.7473e-03, 3.6529e-04,
        2.7513e-04, 2.4581e-04, 1.2753e-03, 1.4292e-04, 1.0835e-03, 3.2144e-04,
        9.3868e-05, 6.4500e-04, 8.3679e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,162][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ give] are: tensor([1.3749e-01, 8.1785e-01, 2.6611e-02, 1.5303e-03, 1.2045e-03, 7.4568e-04,
        8.2560e-04, 1.0953e-03, 1.0757e-03, 4.0163e-03, 3.7841e-03, 2.1896e-03,
        5.5626e-04, 8.4853e-04, 1.7197e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,165][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.7101, 0.0122, 0.0276, 0.0214, 0.0160, 0.0164, 0.0183, 0.0205, 0.0180,
        0.0161, 0.0360, 0.0169, 0.0285, 0.0203, 0.0219], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,169][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ give] are: tensor([8.1785e-01, 1.4656e-01, 1.8825e-02, 3.1337e-04, 9.5962e-04, 4.0376e-04,
        5.6931e-05, 1.2099e-03, 3.6289e-03, 5.3740e-04, 6.2221e-03, 1.2182e-04,
        1.4859e-04, 2.5915e-03, 5.8048e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,171][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ give] are: tensor([9.9454e-01, 2.2968e-03, 7.9257e-05, 1.0149e-05, 2.0458e-06, 5.6414e-05,
        3.3524e-07, 2.7579e-06, 5.6552e-05, 8.6627e-05, 2.0276e-04, 1.8923e-03,
        6.4382e-05, 7.0270e-04, 7.1918e-06], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,172][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ give] are: tensor([7.6074e-01, 1.9862e-01, 6.5733e-04, 4.0982e-04, 5.8782e-05, 1.6620e-04,
        7.9202e-04, 2.5078e-04, 7.3561e-03, 1.9472e-03, 6.4514e-03, 1.4601e-02,
        1.5732e-03, 6.1165e-03, 2.5961e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,173][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.7311, 0.0482, 0.0053, 0.0188, 0.0084, 0.0170, 0.0034, 0.0199, 0.0337,
        0.0036, 0.0140, 0.0182, 0.0060, 0.0391, 0.0197, 0.0135],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,175][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ it] are: tensor([9.3064e-01, 6.5584e-02, 1.0325e-04, 5.0469e-05, 6.2930e-05, 1.3100e-04,
        9.8124e-05, 4.5501e-05, 5.2727e-04, 3.7443e-04, 5.9850e-04, 5.9774e-04,
        3.2650e-05, 2.6859e-04, 3.4960e-04, 5.3930e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,180][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0010, 0.0163, 0.1607, 0.0156, 0.0145, 0.0559, 0.0149, 0.0382, 0.0740,
        0.0548, 0.3228, 0.0410, 0.0172, 0.1098, 0.0207, 0.0427],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,182][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ it] are: tensor([3.0752e-01, 1.6827e-02, 3.2944e-02, 1.8660e-03, 5.0062e-04, 7.6993e-03,
        1.7086e-03, 1.1258e-03, 1.9983e-02, 4.4496e-03, 2.9116e-01, 5.5749e-02,
        1.9772e-04, 2.3429e-01, 3.8262e-03, 2.0162e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,183][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.0023, 0.0047, 0.0705, 0.0060, 0.0371, 0.0307, 0.0388, 0.0111, 0.0275,
        0.1786, 0.0949, 0.2329, 0.1042, 0.0922, 0.0390, 0.0296],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,184][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.1415, 0.3327, 0.0917, 0.0153, 0.0033, 0.0117, 0.0065, 0.0255, 0.0321,
        0.0586, 0.0865, 0.0641, 0.0261, 0.0239, 0.0395, 0.0409],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,185][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ it] are: tensor([2.3771e-02, 9.2020e-01, 1.1596e-02, 3.6210e-03, 3.2291e-03, 2.3791e-03,
        1.6213e-03, 1.7617e-03, 6.4581e-03, 6.1688e-04, 3.6505e-03, 1.4341e-03,
        1.7846e-03, 4.7518e-03, 7.7360e-03, 5.3921e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,187][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ it] are: tensor([4.6262e-01, 5.1039e-01, 7.5957e-03, 7.8870e-04, 6.9176e-04, 9.9897e-04,
        2.2094e-03, 1.1081e-03, 1.1599e-03, 4.0529e-03, 2.8942e-03, 2.0754e-03,
        8.8161e-04, 7.5529e-04, 1.4805e-04, 1.6361e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,192][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.6627, 0.0128, 0.0286, 0.0229, 0.0171, 0.0176, 0.0201, 0.0222, 0.0197,
        0.0177, 0.0387, 0.0183, 0.0304, 0.0221, 0.0236, 0.0256],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,195][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ it] are: tensor([9.6628e-01, 2.2202e-02, 3.5092e-03, 5.6647e-05, 2.5079e-04, 1.6192e-04,
        3.3980e-05, 5.4693e-04, 2.0507e-03, 2.2116e-04, 1.7208e-03, 4.5248e-05,
        1.2677e-04, 1.4503e-03, 9.9893e-04, 3.4122e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,196][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ it] are: tensor([9.9981e-01, 1.7926e-05, 1.1565e-06, 3.5207e-07, 1.5913e-07, 2.6781e-06,
        2.8402e-08, 1.7606e-07, 2.1555e-06, 3.9772e-06, 4.2197e-06, 1.2486e-04,
        1.3931e-06, 3.2339e-05, 1.0183e-07, 2.0060e-06], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,196][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ it] are: tensor([8.0898e-01, 5.2916e-02, 7.0192e-04, 1.0914e-03, 2.1375e-04, 5.8420e-04,
        1.8255e-03, 5.9169e-04, 1.4157e-02, 2.8096e-03, 1.4429e-02, 6.3821e-02,
        2.7418e-03, 1.8125e-02, 5.1432e-04, 1.6498e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,200][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.8259, 0.0534, 0.0028, 0.0076, 0.0032, 0.0049, 0.0013, 0.0089, 0.0132,
        0.0020, 0.0086, 0.0068, 0.0027, 0.0152, 0.0163, 0.0064, 0.0208],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,204][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([8.8467e-01, 1.1238e-01, 5.3681e-05, 2.7270e-05, 4.0954e-05, 6.7114e-05,
        3.2282e-05, 2.2746e-05, 3.1805e-04, 2.8807e-04, 2.6478e-04, 4.6403e-04,
        1.1857e-05, 1.6553e-04, 1.1278e-04, 1.8752e-04, 8.9673e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,206][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0017, 0.0361, 0.1343, 0.0181, 0.0121, 0.0438, 0.0096, 0.0339, 0.0731,
        0.0350, 0.2474, 0.0367, 0.0130, 0.1041, 0.0217, 0.0503, 0.1292],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,207][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([6.5910e-01, 8.8528e-02, 2.0121e-02, 8.2479e-04, 6.0145e-04, 8.1884e-04,
        1.2544e-03, 9.2151e-04, 1.0803e-02, 2.1570e-03, 8.6411e-02, 2.7191e-02,
        1.5559e-04, 7.3375e-02, 2.2344e-03, 4.7772e-03, 2.0727e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,208][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0016, 0.0409, 0.0870, 0.0051, 0.0333, 0.0171, 0.0428, 0.0144, 0.0354,
        0.1133, 0.0941, 0.2555, 0.0615, 0.0731, 0.0297, 0.0130, 0.0824],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,210][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.3639, 0.2609, 0.0493, 0.0115, 0.0021, 0.0105, 0.0058, 0.0242, 0.0303,
        0.0361, 0.0746, 0.0268, 0.0128, 0.0137, 0.0248, 0.0188, 0.0340],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,214][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([2.9988e-02, 9.4388e-01, 5.1474e-03, 1.7541e-03, 8.8666e-04, 9.2471e-04,
        7.2957e-04, 7.3932e-04, 3.5894e-03, 3.1036e-04, 1.9283e-03, 4.0756e-04,
        1.9880e-04, 1.9397e-03, 1.1595e-03, 1.5135e-03, 4.9067e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,218][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([7.0608e-01, 2.8323e-01, 2.7997e-03, 5.2798e-04, 6.7169e-04, 3.2890e-04,
        5.1423e-04, 3.8609e-04, 4.2590e-04, 1.3172e-03, 1.1180e-03, 5.7365e-04,
        3.6993e-04, 2.8071e-04, 8.5267e-05, 4.4707e-04, 8.3840e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,219][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.6411, 0.0124, 0.0287, 0.0228, 0.0170, 0.0175, 0.0198, 0.0217, 0.0194,
        0.0169, 0.0392, 0.0181, 0.0304, 0.0217, 0.0233, 0.0252, 0.0247],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,220][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.7453e-01, 1.8510e-02, 1.1408e-03, 2.7778e-05, 8.7878e-05, 8.7717e-05,
        2.7949e-05, 4.2710e-04, 1.2826e-03, 1.0754e-04, 9.3987e-04, 2.5047e-05,
        5.9226e-05, 8.1322e-04, 2.0534e-04, 1.0298e-04, 1.6246e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,222][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.9989e-01, 2.4332e-05, 6.0180e-07, 3.6618e-07, 5.3880e-08, 1.6938e-06,
        4.7064e-08, 1.5796e-07, 1.1774e-06, 3.0789e-06, 2.3888e-06, 3.0982e-05,
        1.5337e-06, 2.3391e-05, 1.4134e-07, 7.3438e-07, 1.4902e-05],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,225][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([8.0055e-01, 1.6146e-01, 2.5258e-04, 4.3916e-04, 5.7096e-05, 9.1753e-05,
        8.5920e-04, 1.1103e-04, 5.0080e-03, 6.8516e-04, 4.6415e-03, 1.4949e-02,
        9.5217e-04, 5.1920e-03, 1.0092e-04, 2.1289e-03, 2.5230e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,351][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:33,352][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:33,353][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:33,354][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:33,355][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:33,356][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:33,356][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:33,357][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:33,358][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:33,359][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:33,359][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:33,361][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:33,363][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:31:33,365][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.9170, 0.0830], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:33,366][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.9937, 0.0063], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:33,367][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.5463, 0.4537], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:33,370][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.8160, 0.1840], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:33,372][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.0133, 0.9867], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:33,372][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.2115, 0.7885], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:33,373][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.1402, 0.8598], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:33,374][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.7963, 0.2037], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:33,376][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.0936, 0.9064], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:33,382][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.9805, 0.0195], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:33,384][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([9.9988e-01, 1.1992e-04], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:33,384][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.7137, 0.2863], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:31:33,385][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.4323, 0.5411, 0.0267], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:33,386][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([9.1136e-01, 8.8451e-02, 1.9059e-04], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:33,389][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0057, 0.7398, 0.2545], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:33,395][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0043, 0.7723, 0.2234], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:33,396][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0239, 0.4112, 0.5648], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:33,397][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0768, 0.8815, 0.0417], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:33,397][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0041, 0.9945, 0.0014], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:33,399][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1697, 0.8227, 0.0075], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:33,404][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0438, 0.8464, 0.1098], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:33,407][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.8932, 0.1031, 0.0037], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:33,408][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([9.9991e-01, 9.3812e-05, 6.4473e-07], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:33,409][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.8462, 0.1524, 0.0014], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:31:33,410][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Nathan] are: tensor([0.7866, 0.1767, 0.0158, 0.0208], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:33,411][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Nathan] are: tensor([8.9966e-01, 1.0015e-01, 1.6894e-04, 1.9980e-05], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:33,417][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Nathan] are: tensor([0.0285, 0.6788, 0.2891, 0.0036], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:33,419][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Nathan] are: tensor([0.0206, 0.1446, 0.8317, 0.0030], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:33,420][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Nathan] are: tensor([0.0034, 0.1097, 0.8312, 0.0557], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:33,420][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Nathan] are: tensor([0.1164, 0.8063, 0.0679, 0.0094], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:33,421][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Nathan] are: tensor([0.0289, 0.9633, 0.0055, 0.0023], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:33,423][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Nathan] are: tensor([4.8181e-02, 9.4470e-01, 6.3927e-03, 7.2167e-04], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:33,427][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Nathan] are: tensor([0.0284, 0.7351, 0.2340, 0.0025], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:33,431][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Nathan] are: tensor([9.6566e-01, 3.3177e-02, 1.1260e-03, 3.9922e-05], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:33,433][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Nathan] are: tensor([9.9999e-01, 1.1855e-05, 5.1724e-07, 9.5430e-08], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:33,434][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Nathan] are: tensor([0.9658, 0.0279, 0.0043, 0.0020], device='cuda:0') for source tokens [When Katherine and Nathan]
[2024-07-24 10:31:33,434][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.7552, 0.1325, 0.0490, 0.0365, 0.0268], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:33,435][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([7.4748e-01, 2.5167e-01, 5.5751e-04, 9.0296e-05, 2.0128e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:33,437][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.0009, 0.5760, 0.4165, 0.0058, 0.0007], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:33,441][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([4.2656e-04, 1.1986e-01, 8.7726e-01, 2.0161e-03, 4.3854e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:33,445][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.0019, 0.1182, 0.4830, 0.0692, 0.3277], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:33,446][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.0626, 0.8745, 0.0453, 0.0161, 0.0014], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:33,447][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([3.5512e-03, 9.9285e-01, 2.6242e-03, 4.0034e-04, 5.7430e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:33,447][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.0253, 0.9604, 0.0119, 0.0014, 0.0010], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:33,449][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.0475, 0.2649, 0.6780, 0.0041, 0.0055], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:33,453][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([9.4288e-01, 5.3545e-02, 3.3845e-03, 3.0255e-05, 1.6389e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:33,456][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([9.9996e-01, 2.6716e-05, 8.1668e-06, 2.5755e-07, 5.0471e-07],
       device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:33,458][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.6398, 0.3196, 0.0237, 0.0140, 0.0029], device='cuda:0') for source tokens [When Katherine and Nathan got]
[2024-07-24 10:31:33,458][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4940, 0.3540, 0.0459, 0.0195, 0.0079, 0.0789], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:33,459][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([8.6063e-01, 1.3917e-01, 7.6223e-05, 1.4612e-05, 2.8806e-05, 8.0417e-05],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:33,460][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.1798e-03, 8.0365e-01, 1.9057e-01, 2.5929e-03, 4.3670e-04, 1.5780e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:33,461][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.7373e-02, 8.6855e-01, 1.1133e-01, 1.2690e-03, 1.8661e-04, 1.2873e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:33,466][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0200, 0.2390, 0.3441, 0.0617, 0.2001, 0.1351], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:33,470][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2238, 0.6803, 0.0608, 0.0107, 0.0031, 0.0213], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:33,471][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([3.8125e-03, 9.9277e-01, 2.2350e-03, 3.8380e-04, 4.9063e-04, 3.0305e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:33,471][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([1.7098e-02, 9.7221e-01, 9.3613e-03, 6.1840e-04, 2.3453e-04, 4.7930e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:33,472][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.3913, 0.5136, 0.0592, 0.0012, 0.0018, 0.0328], device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:33,474][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([9.0488e-01, 8.5442e-02, 8.2158e-03, 1.6187e-04, 4.7891e-04, 8.2462e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:33,476][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([9.9998e-01, 1.5452e-05, 1.1034e-06, 1.2868e-07, 1.5277e-08, 2.4153e-06],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:33,479][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([5.2662e-01, 4.6485e-01, 2.9448e-03, 4.6842e-03, 1.3300e-04, 7.7036e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a]
[2024-07-24 10:31:33,482][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.5794, 0.1999, 0.0232, 0.0712, 0.0304, 0.0852, 0.0106],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:33,483][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([3.4298e-01, 6.4587e-01, 3.7612e-03, 2.5837e-04, 2.0759e-03, 3.8371e-03,
        1.2264e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:33,484][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([1.3854e-04, 1.3026e-01, 8.4657e-01, 5.3484e-03, 5.4855e-03, 1.1502e-02,
        6.9718e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:33,485][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([5.9351e-04, 1.5087e-02, 9.0647e-01, 2.0260e-02, 1.2700e-02, 4.4202e-02,
        6.8449e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:33,487][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0028, 0.0314, 0.4963, 0.0259, 0.2291, 0.1066, 0.1080],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:33,493][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.0129, 0.5412, 0.3431, 0.0088, 0.0072, 0.0601, 0.0267],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:33,495][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([8.1878e-04, 9.6268e-01, 2.4365e-02, 2.0091e-03, 5.4438e-03, 2.5244e-03,
        2.1598e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:33,496][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([2.2134e-03, 9.8306e-01, 1.0092e-02, 6.5921e-04, 4.8310e-04, 1.0980e-03,
        2.3989e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:33,496][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.0858, 0.3990, 0.3742, 0.0062, 0.0033, 0.1270, 0.0046],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:33,497][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.3360, 0.3278, 0.3230, 0.0004, 0.0027, 0.0096, 0.0006],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:33,499][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([9.9745e-01, 3.9022e-04, 2.6646e-04, 3.8082e-05, 6.9153e-05, 1.7649e-03,
        1.7101e-05], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:33,503][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.3645, 0.2257, 0.0762, 0.0702, 0.0368, 0.1313, 0.0953],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace]
[2024-07-24 10:31:33,507][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.4107, 0.1987, 0.0405, 0.1512, 0.0356, 0.0948, 0.0108, 0.0576],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:33,508][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([6.4005e-01, 3.5892e-01, 4.7739e-04, 5.2790e-05, 1.0618e-04, 2.0058e-04,
        1.1770e-04, 7.2856e-05], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:33,509][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([4.4621e-04, 4.7383e-01, 5.0053e-01, 9.6119e-03, 2.5609e-03, 4.0651e-03,
        1.0355e-03, 7.9271e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:33,510][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0204, 0.3166, 0.6346, 0.0095, 0.0021, 0.0152, 0.0008, 0.0008],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:33,513][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0031, 0.0858, 0.4031, 0.0315, 0.1750, 0.0647, 0.1577, 0.0791],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:33,519][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0787, 0.6331, 0.1699, 0.0328, 0.0056, 0.0226, 0.0170, 0.0404],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:33,520][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([4.2785e-03, 9.7811e-01, 1.0307e-02, 3.2051e-03, 1.2475e-03, 9.9006e-04,
        1.2947e-03, 5.7249e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:33,521][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([1.5207e-02, 9.6463e-01, 1.5638e-02, 1.7216e-03, 6.3157e-04, 5.5084e-04,
        8.5982e-04, 7.6289e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:33,522][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.2154, 0.5428, 0.1375, 0.0016, 0.0027, 0.0600, 0.0025, 0.0376],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:33,523][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([7.9916e-01, 1.7901e-01, 1.7329e-02, 4.5533e-04, 8.3229e-04, 5.3587e-04,
        2.4315e-04, 2.4359e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:33,526][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([9.9982e-01, 1.3469e-04, 1.8398e-05, 4.6227e-06, 8.2573e-07, 2.0968e-05,
        1.0585e-06, 2.0440e-06], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:33,529][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([5.2986e-01, 4.3948e-01, 1.2777e-02, 1.0199e-02, 4.0526e-04, 2.2282e-03,
        3.0482e-03, 2.0019e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at]
[2024-07-24 10:31:33,532][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.8375, 0.0994, 0.0045, 0.0101, 0.0029, 0.0132, 0.0017, 0.0100, 0.0208],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:33,532][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([8.8164e-01, 1.1794e-01, 5.1716e-05, 1.3634e-05, 2.4435e-05, 5.2978e-05,
        5.0456e-05, 2.9063e-05, 1.9610e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:33,533][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0019, 0.8395, 0.1330, 0.0054, 0.0014, 0.0024, 0.0009, 0.0031, 0.0125],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:33,534][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.2172, 0.5439, 0.1932, 0.0050, 0.0011, 0.0054, 0.0012, 0.0011, 0.0319],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:33,538][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0143, 0.1168, 0.2356, 0.0255, 0.1388, 0.0611, 0.2143, 0.0485, 0.1451],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:33,544][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.3760, 0.5115, 0.0323, 0.0087, 0.0022, 0.0114, 0.0050, 0.0214, 0.0315],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:33,544][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([9.1620e-03, 9.8443e-01, 2.2170e-03, 6.5009e-04, 8.9314e-04, 3.7233e-04,
        6.6134e-04, 3.7989e-04, 1.2360e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:33,545][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([5.6914e-02, 9.3976e-01, 2.2394e-03, 2.9413e-04, 1.1667e-04, 1.4311e-04,
        2.3679e-04, 1.4177e-04, 1.4967e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:33,546][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([7.3337e-01, 2.1945e-01, 1.9141e-02, 1.1060e-04, 2.0396e-04, 5.5157e-03,
        6.1885e-04, 5.0347e-03, 1.6558e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:33,547][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([9.8066e-01, 1.5718e-02, 1.1661e-03, 3.1948e-05, 7.4009e-05, 1.3672e-04,
        4.1566e-05, 3.4945e-04, 1.8257e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:33,550][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([9.9998e-01, 1.3808e-05, 7.0476e-07, 1.0074e-07, 3.4251e-08, 1.6608e-06,
        2.8633e-08, 9.1181e-08, 1.1104e-06], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:33,554][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([7.5527e-01, 2.1083e-01, 1.2540e-03, 1.9204e-03, 2.3535e-04, 5.8266e-04,
        2.1899e-03, 7.7801e-04, 2.6938e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the]
[2024-07-24 10:31:33,556][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([0.3007, 0.3912, 0.0452, 0.0886, 0.0186, 0.0398, 0.0046, 0.0429, 0.0588,
        0.0096], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,557][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([7.9219e-01, 2.0500e-01, 2.7112e-04, 4.1838e-05, 1.1205e-04, 1.4080e-04,
        7.9792e-05, 7.3247e-05, 9.7575e-04, 1.1194e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,558][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([1.4392e-03, 6.3299e-01, 3.1413e-01, 8.9060e-03, 1.1524e-03, 3.6513e-03,
        3.7559e-04, 2.4963e-03, 2.0552e-02, 1.4300e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,558][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([6.6928e-03, 9.4578e-02, 8.1409e-01, 1.3786e-02, 3.6989e-03, 1.8931e-02,
        5.5814e-04, 2.2671e-03, 4.2370e-02, 3.0308e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,562][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([0.0048, 0.0746, 0.2625, 0.0155, 0.1018, 0.0521, 0.0367, 0.0285, 0.0701,
        0.3533], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,568][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([0.0115, 0.6382, 0.1297, 0.0069, 0.0049, 0.0246, 0.0063, 0.0305, 0.0494,
        0.0980], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,569][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([4.1701e-03, 9.7496e-01, 1.1449e-02, 1.6039e-03, 2.7150e-03, 9.1750e-04,
        7.8297e-04, 7.1148e-04, 2.3680e-03, 3.2127e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,570][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([4.4858e-02, 9.3894e-01, 1.1096e-02, 5.5159e-04, 5.8508e-04, 3.6033e-04,
        5.4843e-04, 3.8502e-04, 4.0229e-04, 2.2774e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,570][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([0.0561, 0.3111, 0.3919, 0.0012, 0.0021, 0.0826, 0.0022, 0.0453, 0.0913,
        0.0164], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,572][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([6.7680e-01, 2.8314e-01, 2.2513e-02, 2.7398e-04, 2.5320e-03, 9.8543e-04,
        1.2373e-04, 4.1894e-03, 8.7706e-03, 6.6532e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,576][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([9.9875e-01, 7.7737e-04, 7.3571e-05, 1.2203e-05, 6.6684e-06, 1.2820e-04,
        1.2385e-06, 3.4876e-06, 4.7279e-05, 1.9658e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,580][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([0.5452, 0.1256, 0.0174, 0.0163, 0.0073, 0.0105, 0.0088, 0.0206, 0.2345,
        0.0138], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital]
[2024-07-24 10:31:33,581][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.7293, 0.2053, 0.0038, 0.0117, 0.0018, 0.0065, 0.0012, 0.0109, 0.0208,
        0.0013, 0.0076], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,582][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([9.3519e-01, 6.3978e-02, 4.0339e-05, 2.1740e-05, 2.4526e-05, 2.2105e-05,
        2.8214e-05, 1.8001e-05, 1.1514e-04, 3.9407e-04, 1.7113e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,583][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([2.9889e-03, 7.9655e-01, 1.0305e-01, 5.0748e-03, 7.4741e-04, 1.6779e-03,
        5.8375e-04, 4.1134e-03, 1.1754e-02, 1.9971e-02, 5.3483e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,586][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3581, 0.4312, 0.0751, 0.0074, 0.0011, 0.0024, 0.0016, 0.0008, 0.0090,
        0.0018, 0.1115], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,592][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0045, 0.0770, 0.2004, 0.0172, 0.0875, 0.0271, 0.1016, 0.0165, 0.0437,
        0.2458, 0.1787], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,593][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1218, 0.5754, 0.0733, 0.0102, 0.0012, 0.0074, 0.0053, 0.0155, 0.0239,
        0.0599, 0.1061], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,594][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([1.3555e-02, 9.7181e-01, 5.7463e-03, 2.9016e-03, 1.9384e-03, 5.0847e-04,
        6.8006e-04, 4.9515e-04, 1.3135e-03, 4.0543e-04, 6.4503e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,595][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([1.5207e-01, 8.3805e-01, 5.6158e-03, 8.2471e-04, 4.1382e-04, 1.8292e-04,
        4.0187e-04, 1.7860e-04, 2.2745e-04, 1.1153e-03, 9.1658e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,596][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([4.3366e-01, 3.8691e-01, 2.0755e-02, 1.8974e-04, 3.8650e-04, 9.0112e-03,
        6.5936e-04, 1.3673e-02, 3.1731e-02, 2.7428e-03, 1.0028e-01],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,600][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([9.4595e-01, 4.9276e-02, 2.2942e-03, 5.6414e-05, 1.7568e-04, 7.2547e-05,
        1.9194e-05, 3.5485e-04, 6.1512e-04, 1.3720e-04, 1.0450e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,604][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([9.9978e-01, 1.8278e-04, 1.6461e-06, 8.4985e-07, 1.8139e-07, 4.1521e-06,
        1.7085e-07, 3.4134e-07, 2.3627e-06, 1.7276e-05, 7.9586e-06],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,605][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([9.0551e-01, 7.3706e-02, 2.7598e-04, 9.8709e-04, 2.0195e-04, 1.6005e-04,
        1.5862e-03, 3.9940e-04, 7.7215e-03, 1.1952e-03, 8.2607e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital,]
[2024-07-24 10:31:33,606][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.2128, 0.3088, 0.0344, 0.0349, 0.0110, 0.0578, 0.0045, 0.0303, 0.0477,
        0.0092, 0.0362, 0.2124], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,607][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([8.8764e-01, 1.0856e-01, 1.5734e-04, 5.3391e-05, 8.8048e-05, 1.6897e-04,
        1.0526e-04, 8.6722e-05, 6.6316e-04, 8.0446e-04, 7.5393e-04, 9.2200e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,611][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.0154, 0.5451, 0.2528, 0.0094, 0.0025, 0.0062, 0.0009, 0.0035, 0.0290,
        0.0110, 0.0958, 0.0285], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,616][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.0445, 0.3402, 0.1992, 0.0171, 0.0101, 0.0045, 0.0023, 0.0045, 0.0385,
        0.0141, 0.2921, 0.0328], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,617][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.0067, 0.2138, 0.1139, 0.0126, 0.0746, 0.0282, 0.0179, 0.0271, 0.0630,
        0.1219, 0.1318, 0.1885], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,618][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.0301, 0.6620, 0.0267, 0.0046, 0.0019, 0.0091, 0.0281, 0.0169, 0.0242,
        0.0564, 0.0512, 0.0889], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,619][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([8.6367e-03, 9.8066e-01, 3.9222e-03, 8.6096e-04, 1.6384e-03, 3.0893e-04,
        7.7770e-04, 2.6073e-04, 8.5942e-04, 1.8415e-04, 1.1003e-03, 7.9320e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,621][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([1.0361e-01, 8.7170e-01, 9.3274e-03, 1.0554e-03, 6.8417e-04, 6.7067e-04,
        1.6223e-03, 4.0694e-04, 4.7448e-04, 2.1340e-03, 1.6397e-03, 6.6727e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,626][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.0201, 0.3614, 0.0950, 0.0021, 0.0036, 0.0524, 0.0025, 0.0342, 0.0564,
        0.0122, 0.2621, 0.0979], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,629][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([9.1822e-01, 5.9524e-02, 8.6686e-03, 1.4492e-04, 8.6722e-04, 3.1490e-04,
        2.1273e-04, 1.3451e-03, 3.6046e-03, 3.1088e-04, 6.4946e-03, 2.9724e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,629][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([9.9699e-01, 1.3106e-04, 1.1932e-05, 3.9587e-06, 1.0827e-06, 2.2400e-05,
        3.3873e-07, 8.5076e-07, 9.2285e-06, 1.7814e-04, 2.6708e-05, 2.6249e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,630][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.3419, 0.4223, 0.0016, 0.0198, 0.0013, 0.0017, 0.0102, 0.0144, 0.0545,
        0.0103, 0.0256, 0.0963], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine]
[2024-07-24 10:31:33,631][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.6305, 0.1861, 0.0148, 0.0373, 0.0052, 0.0152, 0.0023, 0.0247, 0.0327,
        0.0031, 0.0181, 0.0243, 0.0057], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,633][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([7.4249e-01, 2.5004e-01, 8.0281e-04, 6.8199e-05, 2.3798e-04, 1.8776e-04,
        7.4588e-05, 9.7980e-05, 5.4206e-04, 1.6382e-03, 1.8586e-03, 1.8182e-03,
        1.4978e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,638][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0010, 0.5337, 0.2246, 0.0084, 0.0008, 0.0032, 0.0024, 0.0044, 0.0292,
        0.0348, 0.1024, 0.0532, 0.0018], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,641][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([6.9538e-03, 8.8640e-02, 2.7018e-01, 5.8772e-03, 1.5740e-03, 9.9449e-03,
        1.5203e-03, 5.4118e-03, 5.1653e-02, 6.0846e-03, 5.1754e-01, 3.4444e-02,
        1.7904e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,641][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0009, 0.0119, 0.3148, 0.0138, 0.1415, 0.0473, 0.0148, 0.0334, 0.0347,
        0.1073, 0.1416, 0.0666, 0.0713], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,642][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.0074, 0.5900, 0.1021, 0.0103, 0.0028, 0.0117, 0.0044, 0.0170, 0.0267,
        0.0449, 0.0880, 0.0659, 0.0289], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,643][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([3.3568e-03, 9.7634e-01, 9.4360e-03, 2.4029e-03, 2.1514e-03, 6.6672e-04,
        7.4879e-04, 6.1414e-04, 1.4482e-03, 3.3590e-04, 1.2393e-03, 8.5996e-04,
        3.9532e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,645][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([3.8879e-02, 9.4624e-01, 6.8060e-03, 1.5135e-03, 1.7234e-04, 2.9735e-04,
        2.6878e-04, 1.9689e-04, 2.3739e-04, 1.0533e-03, 1.2981e-03, 2.2930e-03,
        7.4178e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,650][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.3953, 0.1815, 0.0710, 0.0009, 0.0019, 0.0191, 0.0019, 0.0228, 0.0851,
        0.0047, 0.1700, 0.0379, 0.0079], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,652][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([9.3693e-01, 5.0359e-02, 6.4299e-03, 1.5917e-04, 1.8603e-04, 1.7500e-04,
        1.8520e-04, 5.0400e-04, 1.6468e-03, 4.6853e-04, 2.4875e-03, 2.5050e-04,
        2.1984e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,653][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([9.9638e-01, 7.3239e-04, 1.7640e-04, 9.8593e-06, 6.6939e-06, 1.0531e-04,
        7.9455e-07, 1.9479e-05, 9.0430e-05, 2.2457e-04, 2.9715e-04, 1.8616e-03,
        9.1055e-05], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,654][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.3381, 0.4505, 0.0079, 0.0034, 0.0011, 0.0035, 0.0063, 0.0027, 0.0762,
        0.0059, 0.0462, 0.0457, 0.0126], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided]
[2024-07-24 10:31:33,655][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.7775, 0.0952, 0.0060, 0.0092, 0.0041, 0.0073, 0.0018, 0.0159, 0.0237,
        0.0034, 0.0149, 0.0113, 0.0039, 0.0258], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,657][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([8.5322e-01, 1.4388e-01, 1.2704e-04, 3.6072e-05, 5.8367e-05, 9.7639e-05,
        5.4366e-05, 2.7329e-05, 4.0413e-04, 5.6397e-04, 4.8756e-04, 7.6762e-04,
        3.0262e-05, 2.4200e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,662][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0018, 0.7507, 0.0920, 0.0086, 0.0009, 0.0024, 0.0008, 0.0050, 0.0221,
        0.0155, 0.0493, 0.0233, 0.0015, 0.0259], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,664][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([4.6160e-01, 2.2848e-01, 2.6539e-02, 1.5805e-03, 5.5795e-04, 7.9456e-04,
        1.0785e-03, 1.3150e-03, 1.6290e-02, 3.5856e-03, 1.5261e-01, 3.1550e-02,
        1.6998e-04, 7.3854e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,665][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0020, 0.0332, 0.1233, 0.0068, 0.0556, 0.0275, 0.0440, 0.0190, 0.0464,
        0.1611, 0.1290, 0.1830, 0.0815, 0.0876], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,666][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1017, 0.3741, 0.0980, 0.0142, 0.0037, 0.0106, 0.0068, 0.0274, 0.0357,
        0.0844, 0.1392, 0.0601, 0.0249, 0.0190], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,667][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.7335e-02, 9.4793e-01, 9.0651e-03, 2.1005e-03, 1.5080e-03, 9.2493e-04,
        1.2489e-03, 8.5114e-04, 3.2822e-03, 6.9466e-04, 1.6583e-03, 6.7434e-04,
        4.0248e-04, 2.3263e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,669][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([3.6920e-01, 6.1988e-01, 4.1496e-03, 8.8118e-04, 6.5379e-04, 1.8746e-04,
        5.3139e-04, 2.0949e-04, 2.4234e-04, 1.4990e-03, 8.1307e-04, 1.0492e-03,
        4.8771e-04, 2.1595e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,672][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([8.1706e-01, 1.0811e-01, 1.8195e-03, 4.0997e-05, 3.3058e-05, 6.8879e-04,
        1.9586e-04, 1.2183e-03, 5.0915e-03, 7.8932e-04, 1.0859e-02, 9.0408e-03,
        7.6716e-04, 4.4286e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,676][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.6703e-01, 2.6965e-02, 1.8577e-03, 4.2887e-05, 1.0310e-04, 6.5457e-05,
        2.1240e-05, 2.8240e-04, 1.3755e-03, 1.1150e-04, 8.9319e-04, 3.0778e-05,
        9.6812e-05, 1.1231e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,677][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.9976e-01, 8.3675e-05, 2.0321e-06, 4.9994e-07, 6.9992e-08, 1.1953e-06,
        3.7769e-08, 3.1924e-07, 2.0820e-06, 4.1381e-06, 5.2382e-06, 6.2772e-05,
        6.4629e-06, 7.2748e-05], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,678][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([6.5027e-01, 2.8220e-01, 5.6159e-04, 6.5801e-04, 5.1040e-05, 9.0968e-05,
        8.8965e-04, 1.6283e-04, 7.9214e-03, 1.4710e-03, 1.0635e-02, 2.9697e-02,
        3.9032e-03, 1.1490e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to]
[2024-07-24 10:31:33,679][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.5985, 0.1242, 0.0087, 0.0185, 0.0147, 0.0120, 0.0054, 0.0290, 0.0417,
        0.0062, 0.0247, 0.0358, 0.0058, 0.0399, 0.0353], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,680][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([7.4019e-01, 2.5415e-01, 3.9184e-04, 8.1563e-05, 1.5261e-04, 1.4080e-04,
        1.0797e-04, 3.9216e-05, 6.5605e-04, 8.3847e-04, 1.1621e-03, 1.3168e-03,
        3.3462e-05, 3.3110e-04, 4.0343e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,684][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([3.4148e-04, 6.4182e-01, 1.8997e-01, 8.3770e-03, 9.3203e-04, 1.4202e-03,
        7.7915e-04, 2.4061e-03, 9.0415e-03, 2.0504e-02, 6.7530e-02, 3.1046e-02,
        6.0634e-04, 1.8365e-02, 6.8671e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,688][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([6.8027e-03, 6.6347e-02, 2.8086e-01, 1.6876e-03, 1.4070e-03, 7.8169e-03,
        1.5904e-03, 1.7530e-03, 3.8618e-02, 7.1469e-03, 4.3719e-01, 2.7095e-02,
        9.2264e-05, 1.1974e-01, 1.8563e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,689][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0007, 0.0275, 0.1640, 0.0080, 0.0448, 0.0248, 0.0264, 0.0144, 0.0446,
        0.1314, 0.1268, 0.1992, 0.0723, 0.0727, 0.0425], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,690][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0133, 0.7142, 0.0690, 0.0068, 0.0014, 0.0057, 0.0013, 0.0058, 0.0156,
        0.0171, 0.0638, 0.0468, 0.0114, 0.0073, 0.0204], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,691][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([5.0206e-03, 9.8032e-01, 6.8907e-03, 7.3560e-04, 1.7473e-03, 3.6529e-04,
        2.7513e-04, 2.4581e-04, 1.2753e-03, 1.4292e-04, 1.0835e-03, 3.2144e-04,
        9.3868e-05, 6.4500e-04, 8.3679e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,692][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([5.8109e-02, 8.7994e-01, 4.2639e-02, 2.6080e-03, 1.5054e-03, 6.0162e-04,
        7.8757e-04, 7.9813e-04, 9.5601e-04, 4.3024e-03, 3.6699e-03, 2.7872e-03,
        4.0978e-04, 7.0553e-04, 1.7818e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,696][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([3.4305e-02, 2.0627e-01, 5.2721e-02, 1.2560e-04, 1.5041e-04, 9.1169e-03,
        2.5506e-04, 5.3756e-03, 1.7077e-02, 4.8632e-03, 1.2468e-01, 2.8680e-02,
        2.3868e-03, 4.8854e-01, 2.5446e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,700][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([8.1785e-01, 1.4656e-01, 1.8825e-02, 3.1337e-04, 9.5962e-04, 4.0376e-04,
        5.6931e-05, 1.2099e-03, 3.6289e-03, 5.3740e-04, 6.2221e-03, 1.2182e-04,
        1.4859e-04, 2.5915e-03, 5.8048e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,701][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([9.9454e-01, 2.2968e-03, 7.9257e-05, 1.0149e-05, 2.0458e-06, 5.6414e-05,
        3.3524e-07, 2.7579e-06, 5.6552e-05, 8.6627e-05, 2.0276e-04, 1.8923e-03,
        6.4382e-05, 7.0270e-04, 7.1918e-06], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,702][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([7.6074e-01, 1.9862e-01, 6.5733e-04, 4.0982e-04, 5.8782e-05, 1.6620e-04,
        7.9202e-04, 2.5078e-04, 7.3561e-03, 1.9472e-03, 6.4514e-03, 1.4601e-02,
        1.5732e-03, 6.1165e-03, 2.5961e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give]
[2024-07-24 10:31:33,703][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.7311, 0.0482, 0.0053, 0.0188, 0.0084, 0.0170, 0.0034, 0.0199, 0.0337,
        0.0036, 0.0140, 0.0182, 0.0060, 0.0391, 0.0197, 0.0135],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,704][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([9.3064e-01, 6.5584e-02, 1.0325e-04, 5.0469e-05, 6.2930e-05, 1.3100e-04,
        9.8124e-05, 4.5501e-05, 5.2727e-04, 3.7443e-04, 5.9850e-04, 5.9774e-04,
        3.2650e-05, 2.6859e-04, 3.4960e-04, 5.3930e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,710][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.0016, 0.4704, 0.1778, 0.0107, 0.0025, 0.0039, 0.0027, 0.0052, 0.0222,
        0.0382, 0.1611, 0.0324, 0.0019, 0.0394, 0.0159, 0.0141],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,712][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([3.0752e-01, 1.6827e-02, 3.2944e-02, 1.8660e-03, 5.0062e-04, 7.6993e-03,
        1.7086e-03, 1.1258e-03, 1.9983e-02, 4.4496e-03, 2.9116e-01, 5.5749e-02,
        1.9772e-04, 2.3429e-01, 3.8262e-03, 2.0162e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,713][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.0023, 0.0047, 0.0705, 0.0060, 0.0371, 0.0307, 0.0388, 0.0111, 0.0275,
        0.1786, 0.0949, 0.2329, 0.1042, 0.0922, 0.0390, 0.0296],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,714][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.1415, 0.3327, 0.0917, 0.0153, 0.0033, 0.0117, 0.0065, 0.0255, 0.0321,
        0.0586, 0.0865, 0.0641, 0.0261, 0.0239, 0.0395, 0.0409],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,716][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([2.3771e-02, 9.2020e-01, 1.1596e-02, 3.6210e-03, 3.2291e-03, 2.3791e-03,
        1.6213e-03, 1.7617e-03, 6.4581e-03, 6.1688e-04, 3.6505e-03, 1.4341e-03,
        1.7846e-03, 4.7518e-03, 7.7360e-03, 5.3921e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,718][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([3.1485e-01, 6.5539e-01, 1.1033e-02, 1.2930e-03, 7.5141e-04, 7.9075e-04,
        2.1557e-03, 7.4959e-04, 9.3425e-04, 4.1556e-03, 2.5835e-03, 2.5772e-03,
        6.4306e-04, 5.9781e-04, 1.4330e-04, 1.3506e-03], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,722][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([2.8793e-01, 1.5755e-01, 6.4340e-03, 7.7835e-05, 4.1963e-05, 1.5909e-03,
        1.4768e-04, 1.9571e-03, 7.3128e-03, 1.8446e-03, 3.6341e-02, 2.4157e-02,
        1.1618e-03, 4.4441e-01, 5.5936e-03, 2.3453e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,724][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([9.6628e-01, 2.2202e-02, 3.5092e-03, 5.6647e-05, 2.5079e-04, 1.6192e-04,
        3.3980e-05, 5.4693e-04, 2.0507e-03, 2.2116e-04, 1.7208e-03, 4.5248e-05,
        1.2677e-04, 1.4503e-03, 9.9893e-04, 3.4122e-04], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,725][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([9.9981e-01, 1.7926e-05, 1.1565e-06, 3.5207e-07, 1.5913e-07, 2.6781e-06,
        2.8402e-08, 1.7606e-07, 2.1555e-06, 3.9772e-06, 4.2197e-06, 1.2486e-04,
        1.3931e-06, 3.2339e-05, 1.0183e-07, 2.0060e-06], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,726][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([8.0898e-01, 5.2916e-02, 7.0192e-04, 1.0914e-03, 2.1375e-04, 5.8420e-04,
        1.8255e-03, 5.9169e-04, 1.4157e-02, 2.8096e-03, 1.4429e-02, 6.3821e-02,
        2.7418e-03, 1.8125e-02, 5.1432e-04, 1.6498e-02], device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it]
[2024-07-24 10:31:33,727][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.8259, 0.0534, 0.0028, 0.0076, 0.0032, 0.0049, 0.0013, 0.0089, 0.0132,
        0.0020, 0.0086, 0.0068, 0.0027, 0.0152, 0.0163, 0.0064, 0.0208],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,730][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([8.8467e-01, 1.1238e-01, 5.3681e-05, 2.7270e-05, 4.0954e-05, 6.7114e-05,
        3.2282e-05, 2.2746e-05, 3.1805e-04, 2.8807e-04, 2.6478e-04, 4.6403e-04,
        1.1857e-05, 1.6553e-04, 1.1278e-04, 1.8752e-04, 8.9673e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,734][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([9.5838e-04, 8.6983e-01, 2.2951e-02, 2.5711e-03, 2.1117e-04, 1.1401e-03,
        3.7475e-04, 2.7340e-03, 1.2627e-02, 6.9262e-03, 2.5987e-02, 1.0654e-02,
        3.7034e-04, 1.5286e-02, 4.5065e-03, 5.7491e-03, 1.7118e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,736][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([6.5910e-01, 8.8528e-02, 2.0121e-02, 8.2479e-04, 6.0145e-04, 8.1884e-04,
        1.2544e-03, 9.2151e-04, 1.0803e-02, 2.1570e-03, 8.6411e-02, 2.7191e-02,
        1.5559e-04, 7.3375e-02, 2.2344e-03, 4.7772e-03, 2.0727e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,737][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0016, 0.0409, 0.0870, 0.0051, 0.0333, 0.0171, 0.0428, 0.0144, 0.0354,
        0.1133, 0.0941, 0.2555, 0.0615, 0.0731, 0.0297, 0.0130, 0.0824],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,738][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.3639, 0.2609, 0.0493, 0.0115, 0.0021, 0.0105, 0.0058, 0.0242, 0.0303,
        0.0361, 0.0746, 0.0268, 0.0128, 0.0137, 0.0248, 0.0188, 0.0340],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,739][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.9988e-02, 9.4388e-01, 5.1474e-03, 1.7541e-03, 8.8666e-04, 9.2471e-04,
        7.2957e-04, 7.3932e-04, 3.5894e-03, 3.1036e-04, 1.9283e-03, 4.0756e-04,
        1.9880e-04, 1.9397e-03, 1.1595e-03, 1.5135e-03, 4.9067e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,742][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([5.0977e-01, 4.7854e-01, 3.9929e-03, 8.8693e-04, 7.7104e-04, 2.5360e-04,
        5.1647e-04, 2.8334e-04, 3.3922e-04, 1.4266e-03, 9.6370e-04, 6.9057e-04,
        2.7175e-04, 2.1435e-04, 8.1282e-05, 3.5273e-04, 6.3647e-04],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,746][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([6.3942e-01, 1.2977e-01, 3.0167e-03, 5.6326e-05, 4.9471e-05, 1.2489e-03,
        2.4004e-04, 2.1130e-03, 7.3535e-03, 1.0293e-03, 2.5315e-02, 1.4936e-02,
        1.3704e-03, 1.2998e-01, 4.3930e-03, 7.5123e-03, 3.2194e-02],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,748][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.7453e-01, 1.8510e-02, 1.1408e-03, 2.7778e-05, 8.7878e-05, 8.7717e-05,
        2.7949e-05, 4.2710e-04, 1.2826e-03, 1.0754e-04, 9.3987e-04, 2.5047e-05,
        5.9226e-05, 8.1322e-04, 2.0534e-04, 1.0298e-04, 1.6246e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,749][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.9989e-01, 2.4332e-05, 6.0180e-07, 3.6618e-07, 5.3880e-08, 1.6938e-06,
        4.7064e-08, 1.5796e-07, 1.1774e-06, 3.0789e-06, 2.3888e-06, 3.0982e-05,
        1.5337e-06, 2.3391e-05, 1.4134e-07, 7.3438e-07, 1.4902e-05],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,750][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([8.0055e-01, 1.6146e-01, 2.5258e-04, 4.3916e-04, 5.7096e-05, 9.1753e-05,
        8.5920e-04, 1.1103e-04, 5.0080e-03, 6.8516e-04, 4.6415e-03, 1.4949e-02,
        9.5217e-04, 5.1920e-03, 1.0092e-04, 2.1289e-03, 2.5230e-03],
       device='cuda:0') for source tokens [When Katherine and Nathan got a necklace at the hospital, Katherine decided to give it to]
[2024-07-24 10:31:33,753][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:33,756][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[3506],
        [   3],
        [   3],
        [   1],
        [  52],
        [  14],
        [ 180],
        [   4],
        [  34],
        [ 219],
        [   1],
        [   1],
        [  10],
        [   1],
        [   7],
        [   5],
        [   1]], device='cuda:0')
[2024-07-24 10:31:33,758][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[3405],
        [   1],
        [   1],
        [   1],
        [  29],
        [  14],
        [  70],
        [   1],
        [  32],
        [ 202],
        [   1],
        [   1],
        [   8],
        [   1],
        [   4],
        [   5],
        [   1]], device='cuda:0')
[2024-07-24 10:31:33,761][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[11056],
        [15097],
        [32378],
        [22460],
        [24009],
        [29146],
        [25624],
        [27224],
        [17694],
        [29452],
        [23451],
        [28470],
        [24295],
        [18905],
        [22476],
        [18404],
        [16295]], device='cuda:0')
[2024-07-24 10:31:33,763][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 1368],
        [ 1563],
        [11910],
        [15192],
        [43813],
        [26683],
        [49103],
        [47389],
        [20474],
        [39527],
        [ 6558],
        [17646],
        [43565],
        [27889],
        [43869],
        [ 6893],
        [18679]], device='cuda:0')
[2024-07-24 10:31:33,765][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 6228],
        [47720],
        [43226],
        [45184],
        [44464],
        [44177],
        [44038],
        [42234],
        [41755],
        [38877],
        [34806],
        [33376],
        [33698],
        [35819],
        [35059],
        [33759],
        [37680]], device='cuda:0')
[2024-07-24 10:31:33,766][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[21033],
        [35027],
        [36400],
        [34554],
        [34388],
        [36481],
        [34799],
        [35617],
        [36903],
        [35300],
        [38018],
        [39549],
        [39912],
        [40494],
        [40188],
        [42547],
        [41163]], device='cuda:0')
[2024-07-24 10:31:33,768][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 9109],
        [ 2645],
        [ 6142],
        [ 9633],
        [10280],
        [ 8424],
        [11534],
        [11815],
        [12785],
        [11145],
        [12518],
        [ 8024],
        [11954],
        [10946],
        [10705],
        [11070],
        [10252]], device='cuda:0')
[2024-07-24 10:31:33,770][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[17616],
        [ 2433],
        [ 2479],
        [ 2574],
        [ 2516],
        [ 2711],
        [ 3987],
        [ 3136],
        [ 2813],
        [ 3665],
        [ 3740],
        [ 3562],
        [ 3950],
        [ 5761],
        [ 3262],
        [ 6064],
        [ 5906]], device='cuda:0')
[2024-07-24 10:31:33,773][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[16538],
        [23341],
        [23391],
        [23448],
        [23389],
        [23393],
        [23034],
        [23398],
        [23404],
        [23293],
        [23448],
        [23374],
        [23367],
        [23346],
        [23333],
        [23477],
        [23387]], device='cuda:0')
[2024-07-24 10:31:33,776][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[48943],
        [49594],
        [49025],
        [48827],
        [48754],
        [48735],
        [48697],
        [48715],
        [48816],
        [48743],
        [48996],
        [48797],
        [48730],
        [49250],
        [48763],
        [49141],
        [49508]], device='cuda:0')
[2024-07-24 10:31:33,778][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[8683],
        [8681],
        [8636],
        [8611],
        [8594],
        [8531],
        [8449],
        [8352],
        [8340],
        [8249],
        [7974],
        [8208],
        [7644],
        [7773],
        [7499],
        [5531],
        [4854]], device='cuda:0')
[2024-07-24 10:31:33,779][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[15210],
        [14714],
        [14472],
        [14560],
        [14529],
        [14825],
        [21618],
        [15180],
        [14757],
        [15279],
        [14371],
        [14534],
        [14605],
        [14528],
        [14971],
        [14477],
        [14362]], device='cuda:0')
[2024-07-24 10:31:33,781][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[32977],
        [32939],
        [32947],
        [32970],
        [32966],
        [32969],
        [32736],
        [32937],
        [32969],
        [32735],
        [32930],
        [32677],
        [32622],
        [32951],
        [32139],
        [32959],
        [32967]], device='cuda:0')
[2024-07-24 10:31:33,782][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[33186],
        [27666],
        [29558],
        [33550],
        [28621],
        [26803],
        [39837],
        [27649],
        [29691],
        [34966],
        [32249],
        [29352],
        [27892],
        [27842],
        [28953],
        [31004],
        [29502]], device='cuda:0')
[2024-07-24 10:31:33,785][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[12560],
        [10823],
        [ 8463],
        [10854],
        [11331],
        [12629],
        [13739],
        [ 9473],
        [ 9941],
        [11033],
        [ 6494],
        [ 9954],
        [10743],
        [ 8782],
        [ 8957],
        [ 9423],
        [ 7465]], device='cuda:0')
[2024-07-24 10:31:33,787][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[16048],
        [14200],
        [11769],
        [13301],
        [13451],
        [12452],
        [12629],
        [12364],
        [13777],
        [12044],
        [12985],
        [11725],
        [12771],
        [13519],
        [12748],
        [13547],
        [14018]], device='cuda:0')
[2024-07-24 10:31:33,790][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[10891],
        [10335],
        [ 6464],
        [ 6427],
        [ 7113],
        [ 6493],
        [ 8523],
        [ 7762],
        [ 6476],
        [ 6764],
        [ 6750],
        [ 6509],
        [ 7154],
        [ 6534],
        [ 7169],
        [ 6801],
        [ 6501]], device='cuda:0')
[2024-07-24 10:31:33,793][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[21527],
        [28310],
        [28143],
        [27851],
        [26669],
        [28310],
        [21311],
        [25396],
        [28395],
        [27608],
        [28578],
        [27368],
        [27572],
        [28592],
        [28122],
        [27435],
        [28677]], device='cuda:0')
[2024-07-24 10:31:33,795][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[2892],
        [2832],
        [3857],
        [6355],
        [6481],
        [3604],
        [6914],
        [5554],
        [4004],
        [6449],
        [3761],
        [4417],
        [4624],
        [3822],
        [4722],
        [4377],
        [3771]], device='cuda:0')
[2024-07-24 10:31:33,796][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[16919],
        [ 2449],
        [ 3839],
        [ 6485],
        [ 8591],
        [ 6684],
        [10761],
        [10554],
        [11164],
        [10362],
        [11597],
        [ 8316],
        [11270],
        [12120],
        [11331],
        [13401],
        [11453]], device='cuda:0')
[2024-07-24 10:31:33,798][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[12844],
        [18099],
        [17667],
        [17079],
        [17480],
        [16412],
        [11346],
        [13854],
        [15484],
        [15170],
        [16194],
        [16167],
        [14954],
        [14105],
        [16051],
        [12320],
        [12331]], device='cuda:0')
[2024-07-24 10:31:33,800][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[12376],
        [ 6689],
        [ 6678],
        [ 6719],
        [ 6696],
        [ 6695],
        [ 6929],
        [ 6779],
        [ 6715],
        [ 6816],
        [ 6767],
        [ 6744],
        [ 6814],
        [ 6847],
        [ 6769],
        [ 7084],
        [ 6852]], device='cuda:0')
[2024-07-24 10:31:33,802][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[18124],
        [10737],
        [ 6695],
        [ 6545],
        [ 6546],
        [ 6537],
        [ 6530],
        [ 6546],
        [ 6544],
        [ 6575],
        [ 6667],
        [ 6605],
        [ 6537],
        [ 7113],
        [ 6686],
        [ 6993],
        [ 7675]], device='cuda:0')
[2024-07-24 10:31:33,805][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[15719],
        [15642],
        [15102],
        [14858],
        [14346],
        [15862],
        [14597],
        [16319],
        [15731],
        [14295],
        [15621],
        [14148],
        [14608],
        [15706],
        [13927],
        [31060],
        [15545]], device='cuda:0')
[2024-07-24 10:31:33,807][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[10309],
        [15956],
        [24092],
        [19380],
        [22505],
        [24251],
        [23252],
        [23520],
        [15625],
        [22733],
        [22226],
        [24530],
        [23110],
        [19010],
        [24653],
        [19213],
        [17354]], device='cuda:0')
[2024-07-24 10:31:33,810][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[8905],
        [8898],
        [8899],
        [8904],
        [8901],
        [8904],
        [8755],
        [8893],
        [8904],
        [8829],
        [8893],
        [8712],
        [8663],
        [8888],
        [8535],
        [8890],
        [8896]], device='cuda:0')
[2024-07-24 10:31:33,811][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 8540],
        [15018],
        [14150],
        [10265],
        [14853],
        [15184],
        [13533],
        [15171],
        [15779],
        [19618],
        [13308],
        [17356],
        [18125],
        [16238],
        [15677],
        [17159],
        [15412]], device='cuda:0')
[2024-07-24 10:31:33,813][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[32387],
        [33887],
        [34537],
        [33880],
        [31703],
        [33572],
        [33231],
        [32497],
        [33914],
        [31668],
        [34039],
        [33255],
        [32286],
        [33518],
        [32532],
        [31957],
        [34239]], device='cuda:0')
[2024-07-24 10:31:33,815][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[35321],
        [33608],
        [36895],
        [36123],
        [36060],
        [35250],
        [33570],
        [37046],
        [35844],
        [34385],
        [38222],
        [35322],
        [36911],
        [36055],
        [37373],
        [35842],
        [37512]], device='cuda:0')
[2024-07-24 10:31:33,818][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[11256],
        [11256],
        [11256],
        [11256],
        [11256],
        [11256],
        [11256],
        [11256],
        [11256],
        [11256],
        [11256],
        [11256],
        [11256],
        [11256],
        [11256],
        [11256],
        [11256]], device='cuda:0')
