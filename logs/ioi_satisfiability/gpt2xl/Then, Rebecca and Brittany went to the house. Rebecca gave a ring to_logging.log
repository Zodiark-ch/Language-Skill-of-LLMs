[2024-07-24 10:21:46,880][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isThen, Rebecca and Brittany went to the house. Rebecca gave a ring to
[2024-07-24 10:21:46,881][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Brittany
[2024-07-24 10:21:46,881][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:21:46,881][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:21:46,881][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:21:46,881][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit5', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,881][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:21:46,881][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,881][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:21:46,882][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,882][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:21:46,882][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,882][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:21:46,882][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit26']
[2024-07-24 10:21:46,882][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:21:46,883][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,883][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:21:46,883][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,883][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:21:46,883][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,883][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:21:46,883][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit4', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,884][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:21:46,884][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,884][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:21:46,884][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,884][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:21:46,884][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,884][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:21:46,885][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,885][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:21:46,885][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,885][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:21:46,885][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,885][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:21:46,885][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:21:46,886][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:21:46,886][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit20', 'circuit27']
[2024-07-24 10:21:46,886][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:21:46,886][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,886][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:21:46,886][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,886][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:21:46,887][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,887][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:21:46,887][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19']
[2024-07-24 10:21:46,887][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:21:46,887][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,887][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:21:46,887][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit6', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,888][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:21:46,888][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit22', 'circuit24']
[2024-07-24 10:21:46,888][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:21:46,888][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:46,888][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:21:46,888][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit26']
[2024-07-24 10:21:46,888][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:21:46,888][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,889][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:21:46,889][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,889][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:21:46,889][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,889][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:21:46,889][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,889][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,890][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:21:46,890][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,890][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,890][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:21:46,890][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,890][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18']
[2024-07-24 10:21:46,890][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:21:46,891][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit25']
[2024-07-24 10:21:46,891][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,891][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:21:46,891][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit22']
[2024-07-24 10:21:46,891][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit20', 'circuit23', 'circuit25']
[2024-07-24 10:21:46,891][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:21:46,891][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,892][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit12', 'circuit13', 'circuit16', 'circuit18', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:46,892][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:21:46,892][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit25']
[2024-07-24 10:21:46,892][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,892][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:21:46,892][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,892][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21']
[2024-07-24 10:21:46,893][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:21:46,893][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,893][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,893][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:21:46,893][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,893][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:21:46,893][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:21:46,894][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:21:46,894][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,894][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:21:46,894][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,894][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,894][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:21:46,894][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22']
[2024-07-24 10:21:46,895][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17']
[2024-07-24 10:21:46,895][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:21:46,895][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,895][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,895][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:21:46,895][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:21:46,895][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:21:46,896][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:21:46,896][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit20', 'circuit24']
[2024-07-24 10:21:46,896][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit26']
[2024-07-24 10:21:46,896][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:21:46,896][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,896][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,896][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:21:46,897][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21', 'circuit23']
[2024-07-24 10:21:46,897][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit24']
[2024-07-24 10:21:46,897][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:21:46,897][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,897][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,897][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:21:46,897][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,897][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16']
[2024-07-24 10:21:46,898][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:21:46,898][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,898][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,898][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:21:46,898][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,898][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,898][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:21:46,899][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,899][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,899][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:21:46,899][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:21:46,899][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:21:46,899][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:21:46,899][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:46,900][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16']
[2024-07-24 10:21:46,900][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:21:46,900][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,900][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17']
[2024-07-24 10:21:46,900][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:21:46,900][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,900][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,901][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:21:46,901][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,901][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,901][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:21:46,901][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,901][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,901][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:21:46,902][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,902][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,902][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,902][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:21:46,902][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,902][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit13', 'circuit21']
[2024-07-24 10:21:46,903][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit23', 'circuit26']
[2024-07-24 10:21:46,903][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:21:46,903][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:21:46,903][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:21:46,903][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,903][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:21:46,903][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:21:46,904][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:21:46,904][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:46,904][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:21:46,904][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,904][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,904][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,904][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:21:46,905][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,905][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:21:46,905][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,905][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:21:46,905][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:21:46,905][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit5', 'circuit13', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:21:46,905][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,906][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:21:46,906][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,906][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit25']
[2024-07-24 10:21:46,906][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,906][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:21:46,906][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:21:46,906][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:46,907][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,907][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:21:46,907][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:21:46,907][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,907][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,907][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:21:46,907][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,908][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,908][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,908][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:21:46,908][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:21:46,908][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:21:46,908][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:21:46,908][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:21:46,909][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,909][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,909][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,909][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:21:46,909][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,909][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,909][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,910][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:21:46,910][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit24']
[2024-07-24 10:21:46,910][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,910][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:21:46,910][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:21:46,910][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:21:46,910][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,911][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:21:46,911][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:21:46,911][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:46,911][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,911][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,911][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:21:46,911][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,912][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:21:46,912][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,912][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:21:46,912][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,912][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:21:46,912][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:21:46,912][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:21:46,913][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,913][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit26']
[2024-07-24 10:21:46,913][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,913][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:21:46,913][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,913][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,913][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,914][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:21:46,914][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,914][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,914][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,914][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:21:46,914][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:21:46,914][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit17', 'circuit20']
[2024-07-24 10:21:46,915][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:21:46,915][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:21:46,915][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,915][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,915][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,915][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:21:46,915][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit24']
[2024-07-24 10:21:46,916][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,916][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:21:46,916][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:21:46,916][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,916][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,916][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,916][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:21:46,917][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,917][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,917][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,917][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:21:46,917][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,917][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,917][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,918][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:21:46,918][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,918][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,918][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,918][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:21:46,918][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,918][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit6', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,919][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit7', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,919][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,919][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:21:46,919][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit25']
[2024-07-24 10:21:46,919][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21']
[2024-07-24 10:21:46,919][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,919][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,920][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:21:46,920][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:21:46,920][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,920][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,920][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,920][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:21:46,920][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,921][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:21:46,921][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,921][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14']
[2024-07-24 10:21:46,921][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:21:46,921][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,921][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,921][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,921][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,922][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:21:46,922][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,922][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit19', 'circuit27']
[2024-07-24 10:21:46,922][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit10']
[2024-07-24 10:21:46,922][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,922][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:21:46,922][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,923][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:21:46,923][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,923][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,923][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:21:46,923][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit27']
[2024-07-24 10:21:46,923][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,923][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,924][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:21:46,924][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:21:46,924][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,924][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,924][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,924][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:21:46,924][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:21:46,925][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:21:46,925][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit26']
[2024-07-24 10:21:46,925][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,925][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,925][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:21:46,925][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,925][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,926][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,926][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,926][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:21:46,926][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,926][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit14', 'circuit15']
[2024-07-24 10:21:46,926][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,926][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,927][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:21:46,927][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,927][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,927][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:21:46,927][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:21:46,927][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:21:46,927][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,928][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,928][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,928][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,928][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:21:46,928][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,928][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,929][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,929][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,929][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:21:46,929][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,929][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,929][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,929][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,929][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:21:46,930][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,930][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,930][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,930][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,930][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:21:46,930][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,930][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,931][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,931][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,931][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:21:46,931][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:21:46,931][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,931][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,932][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,932][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:21:46,932][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,932][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,932][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,932][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,932][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:21:46,933][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:21:46,933][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,933][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,933][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,933][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:21:46,933][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,933][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,934][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,934][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,934][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:21:46,934][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,934][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,934][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit7', 'circuit8']
[2024-07-24 10:21:46,934][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,935][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:21:46,935][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,935][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,935][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,935][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,935][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:21:46,935][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,936][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:21:46,936][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,936][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,936][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:21:46,936][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,936][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,936][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,937][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,937][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:21:46,937][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,937][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,937][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,937][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,937][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:21:46,938][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,938][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,938][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,938][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,938][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:21:46,938][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,938][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,939][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,939][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,939][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:21:46,939][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,939][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,939][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,940][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,940][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,940][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:21:46,940][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,940][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit6', 'circuit12', 'circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,940][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,940][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,941][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,941][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:21:46,941][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,941][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,941][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,941][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,941][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,942][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:21:46,942][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit27']
[2024-07-24 10:21:46,942][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,942][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,942][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:21:46,942][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,942][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:21:46,943][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit27']
[2024-07-24 10:21:46,943][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,943][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,943][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:21:46,943][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,943][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:21:46,943][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17']
[2024-07-24 10:21:46,944][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,944][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,944][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,944][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,944][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:21:46,944][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,944][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,945][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,945][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,945][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,945][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:21:46,945][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,945][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit9', 'circuit11', 'circuit13']
[2024-07-24 10:21:46,946][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,946][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:46,946][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit18', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,946][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:21:46,946][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit24', 'circuit27']
[2024-07-24 10:21:46,946][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:21:46,946][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit18']
[2024-07-24 10:21:46,947][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20']
[2024-07-24 10:21:46,947][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,947][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:21:46,947][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,947][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:46,947][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,947][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,948][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,948][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:21:46,948][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,948][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,948][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,948][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit8', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,948][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,949][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:21:46,949][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,949][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:21:46,949][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,949][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,949][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:21:46,949][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:21:46,950][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:46,950][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,950][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,950][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,950][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,950][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:21:46,950][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,951][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,951][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,951][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,951][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,951][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:21:46,951][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,952][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,952][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,952][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,952][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit8', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,952][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:21:46,952][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,952][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,953][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,953][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,953][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,953][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:21:46,953][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,953][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,953][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,954][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,954][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,954][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:21:46,954][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,954][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,954][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,954][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,955][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,955][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:21:46,955][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,955][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit12']
[2024-07-24 10:21:46,955][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,955][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,955][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,956][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:21:46,956][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,956][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:46,956][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:46,956][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,956][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:46,956][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:21:46,957][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:21:46,957][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,957][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,957][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,957][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:21:46,957][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:21:46,957][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit27']
[2024-07-24 10:21:46,958][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,958][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,958][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,958][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,958][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:21:46,958][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,958][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,959][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,959][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,959][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,959][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:21:46,959][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,959][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,959][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,960][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,960][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,960][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:21:46,960][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,960][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,960][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit24', 'circuit25']
[2024-07-24 10:21:46,960][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:46,961][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,961][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:21:46,961][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,961][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,961][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,961][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,961][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,962][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:21:46,962][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,962][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,962][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,962][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,962][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,962][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:21:46,963][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,963][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,963][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,963][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,963][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,963][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:21:46,963][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,964][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,964][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,964][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,964][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,964][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:21:46,964][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,965][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,965][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,965][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,965][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,965][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,965][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:21:46,965][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12']
[2024-07-24 10:21:46,966][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit8', 'circuit15']
[2024-07-24 10:21:46,966][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:21:46,966][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:21:46,966][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,966][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit3']
[2024-07-24 10:21:46,966][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:21:46,966][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit27']
[2024-07-24 10:21:46,967][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit18']
[2024-07-24 10:21:46,967][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit27']
[2024-07-24 10:21:46,967][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit25']
[2024-07-24 10:21:46,967][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:21:46,967][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit8', 'circuit11', 'circuit14', 'circuit17', 'circuit20', 'circuit24']
[2024-07-24 10:21:46,967][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:21:46,967][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:46,968][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,968][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:21:46,968][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:46,968][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:21:46,968][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:21:46,968][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:21:46,968][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,969][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,969][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,969][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24']
[2024-07-24 10:21:46,969][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,969][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,969][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:21:46,969][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:21:46,970][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:21:46,970][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit19']
[2024-07-24 10:21:46,970][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,970][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,970][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20', 'circuit24']
[2024-07-24 10:21:46,970][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:21:46,970][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:46,971][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit26']
[2024-07-24 10:21:46,971][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,971][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,971][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit18']
[2024-07-24 10:21:46,971][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:21:46,971][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:21:46,972][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,972][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,972][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,972][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:46,972][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit3', 'circuit13', 'circuit24', 'circuit26']
[2024-07-24 10:21:46,972][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,972][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:21:46,973][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit10', 'circuit12']
[2024-07-24 10:21:46,973][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit14', 'circuit15']
[2024-07-24 10:21:46,973][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,973][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,973][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,973][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:46,973][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:21:46,974][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit20']
[2024-07-24 10:21:46,974][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,974][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,974][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,974][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,974][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:46,974][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:21:46,975][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,975][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22']
[2024-07-24 10:21:46,975][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,975][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,975][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:21:46,975][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit6', 'circuit10', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:21:46,975][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:21:46,976][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit22', 'circuit26']
[2024-07-24 10:21:46,976][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,976][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19']
[2024-07-24 10:21:46,976][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,976][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:46,976][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit7', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,976][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:21:46,977][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,977][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit15', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,977][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit26']
[2024-07-24 10:21:46,977][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:21:46,977][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit25']
[2024-07-24 10:21:46,977][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:21:46,977][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:21:46,977][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,978][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,978][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19']
[2024-07-24 10:21:46,978][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:21:46,978][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit3']
[2024-07-24 10:21:46,978][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit2', 'circuit24', 'circuit27']
[2024-07-24 10:21:46,978][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:21:46,978][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,979][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,979][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,979][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,979][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,979][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:46,979][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:21:46,979][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,980][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,980][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,980][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,980][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,980][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:46,980][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:21:46,980][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,981][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,981][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,981][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,981][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,981][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:46,981][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:21:46,981][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,982][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,982][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,982][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,982][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,982][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:46,982][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:21:46,982][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,983][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,983][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,983][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,983][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,983][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:46,983][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:21:46,983][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,984][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,984][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,984][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,984][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,984][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:46,984][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:21:46,985][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,985][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,985][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,985][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,985][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,985][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:46,985][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:21:46,986][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,986][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,986][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,986][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,986][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,986][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:46,986][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:21:46,987][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,987][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,987][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,987][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,987][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,987][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:46,987][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:21:46,988][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,988][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,988][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,988][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,988][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,988][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:46,988][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:21:46,989][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,989][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,989][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,989][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,989][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,989][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:46,989][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:21:46,990][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,990][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,990][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,990][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,990][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,990][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:46,990][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:21:46,991][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,991][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,991][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,991][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,991][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,991][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,991][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:21:46,992][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,992][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,992][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,992][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,992][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,992][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,992][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:21:46,993][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,993][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,993][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,993][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,993][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,993][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,994][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:21:46,994][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,994][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,994][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,994][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,994][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,994][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit6', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,995][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:46,995][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:21:46,995][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,995][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit19', 'circuit21']
[2024-07-24 10:21:46,995][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit26']
[2024-07-24 10:21:46,995][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,995][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:46,996][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:46,996][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24']
[2024-07-24 10:21:46,996][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:21:46,996][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit28']
[2024-07-24 10:21:46,996][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit8', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:21:46,996][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,996][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,997][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,997][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:46,997][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:46,997][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:21:46,997][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit13', 'circuit15', 'circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:46,997][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,997][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,998][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:46,998][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit24']
[2024-07-24 10:21:46,998][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:46,998][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:46,998][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:21:46,998][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:46,998][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:46,999][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:46,999][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:46,999][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:46,999][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:46,999][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:21:46,999][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:21:46,999][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit20', 'circuit24']
[2024-07-24 10:21:47,000][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,000][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,000][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,000][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,000][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,000][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,000][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:21:47,001][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:21:47,001][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit8', 'circuit12', 'circuit13', 'circuit26']
[2024-07-24 10:21:47,001][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,001][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,001][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,001][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,002][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,002][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:21:47,002][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:21:47,002][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:47,002][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:47,002][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,002][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:47,003][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,003][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,003][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:21:47,003][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,003][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,003][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,003][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,004][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,004][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,004][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit3', 'circuit6', 'circuit7', 'circuit24']
[2024-07-24 10:21:47,004][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:21:47,004][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit24']
[2024-07-24 10:21:47,004][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:21:47,004][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit22', 'circuit23']
[2024-07-24 10:21:47,005][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,005][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit24']
[2024-07-24 10:21:47,005][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:21:47,005][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,005][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:21:47,005][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit10', 'circuit11', 'circuit16', 'circuit18', 'circuit20']
[2024-07-24 10:21:47,005][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,006][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,006][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,006][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,006][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,006][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,006][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:21:47,006][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,007][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,007][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,007][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,007][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,007][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,007][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit17']
[2024-07-24 10:21:47,007][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:21:47,008][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:21:47,008][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,008][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,008][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,008][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,008][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,008][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit13']
[2024-07-24 10:21:47,009][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:21:47,009][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,009][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit16', 'circuit19', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,009][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit26']
[2024-07-24 10:21:47,009][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,009][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:47,010][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:47,010][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24']
[2024-07-24 10:21:47,010][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:21:47,010][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,010][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,010][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,010][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,011][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,011][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,011][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,011][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:21:47,011][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,011][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,011][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,012][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,012][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,012][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,012][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,012][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:21:47,012][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,012][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,013][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,013][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,013][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,013][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,013][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,013][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:21:47,013][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,014][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,014][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,014][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,014][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,014][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,014][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,014][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:21:47,015][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,015][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,015][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,015][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,015][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,015][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,015][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,016][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:21:47,016][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,016][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,016][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,016][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,016][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,016][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,017][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,017][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:21:47,017][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,017][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,017][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,017][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,017][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,018][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,018][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,018][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:21:47,018][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,018][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,018][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,018][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,019][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,019][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,019][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,019][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:21:47,019][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,019][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,019][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,020][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,020][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,020][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,020][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,020][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:21:47,020][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,020][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,021][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,021][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,021][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,021][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,021][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,021][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:21:47,021][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,022][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,022][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,022][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,022][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,022][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,022][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,022][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:21:47,023][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,023][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,023][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,023][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,023][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,023][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,023][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,024][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:21:47,024][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,024][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,024][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,024][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,024][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,024][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,025][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,025][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:21:47,025][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,025][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,025][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,025][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,026][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,026][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,026][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,026][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:21:47,026][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,026][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,026][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,027][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,027][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,027][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,027][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,027][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:21:47,027][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,027][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,028][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,028][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,028][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,028][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:47,028][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,028][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit28']
[2024-07-24 10:21:47,028][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:21:47,029][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit10', 'circuit13', 'circuit14']
[2024-07-24 10:21:47,029][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,029][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,029][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,029][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,029][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,030][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,030][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,030][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:21:47,030][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,030][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,030][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,030][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,031][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,031][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,031][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,031][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,031][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:21:47,031][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22', 'circuit26']
[2024-07-24 10:21:47,031][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,032][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:21:47,032][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:21:47,032][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:21:47,032][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,032][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit7']
[2024-07-24 10:21:47,032][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,032][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:21:47,033][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit26']
[2024-07-24 10:21:47,033][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,033][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:21:47,033][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,033][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,033][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,033][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,033][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,034][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:21:47,034][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,034][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,034][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,034][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,034][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,034][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,035][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,035][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,035][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:21:47,035][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12']
[2024-07-24 10:21:47,035][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit26']
[2024-07-24 10:21:47,035][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,035][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,036][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,036][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,036][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,036][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,036][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:21:47,036][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:21:47,036][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,037][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,037][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,037][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,037][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,037][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,037][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,037][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:21:47,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:21:47,038][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit20', 'circuit23']
[2024-07-24 10:21:47,038][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,038][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,038][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,038][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,038][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit25']
[2024-07-24 10:21:47,039][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit18']
[2024-07-24 10:21:47,039][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:21:47,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,039][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18']
[2024-07-24 10:21:47,039][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,039][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,039][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:21:47,040][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,040][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,040][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,040][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:21:47,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,040][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:21:47,040][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,041][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,041][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,041][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,041][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,041][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,041][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:21:47,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:21:47,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,042][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,042][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,042][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,042][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,042][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,042][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,043][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:21:47,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,043][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,043][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,043][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,043][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,044][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,044][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,044][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:21:47,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit23']
[2024-07-24 10:21:47,044][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,044][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,045][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,045][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:21:47,045][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,045][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,045][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:21:47,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,046][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,046][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,046][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,046][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,046][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,046][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,046][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:21:47,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,047][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,047][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,047][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,047][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,048][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,048][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,048][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:21:47,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,048][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,048][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,048][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,049][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,049][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,049][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,049][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,049][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:21:47,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,050][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,050][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,050][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,050][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,050][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,050][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:21:47,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,051][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,051][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,051][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,051][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,051][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,052][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,052][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:21:47,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,052][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,052][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,052][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,053][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,053][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,053][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,053][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:21:47,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,053][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,054][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,054][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,054][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,054][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,054][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,054][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:21:47,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,055][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,055][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,055][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,055][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,055][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,055][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,056][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:21:47,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,056][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,056][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,056][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,056][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,057][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,057][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,057][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:21:47,057][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,057][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,057][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,058][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,058][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,058][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,058][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,058][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:21:47,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,059][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,059][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,059][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,059][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,059][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,059][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:21:47,060][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,060][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,060][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,060][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,060][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,060][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,060][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,061][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,061][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:21:47,061][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,061][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,061][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,061][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,061][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,062][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,062][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,062][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,062][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:21:47,062][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,062][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,062][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,063][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,063][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,063][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,063][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,063][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,063][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:21:47,064][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,064][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,064][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,064][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,064][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,064][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,064][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,065][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,065][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:21:47,065][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:47,065][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,065][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,065][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,065][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,066][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:21:47,066][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,066][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,066][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,066][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:21:47,066][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,067][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,067][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,067][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,067][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,067][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,067][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,067][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,068][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,068][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:21:47,068][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,068][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,068][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,068][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,068][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,069][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,069][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,069][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,069][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,069][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:21:47,069][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,069][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,070][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,070][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,070][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,070][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,070][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,070][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,070][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,071][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:21:47,071][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,071][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,071][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,071][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,071][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,071][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,072][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,072][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,072][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,072][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:21:47,072][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,072][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,072][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,073][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,073][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,073][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,073][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,073][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,073][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,073][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:21:47,074][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:47,074][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,074][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit21', 'circuit22']
[2024-07-24 10:21:47,074][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:21:47,074][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,074][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,074][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,075][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,075][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,075][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:21:47,075][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,075][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,075][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,075][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,076][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,076][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,076][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,076][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,076][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,076][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:21:47,076][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22', 'circuit24']
[2024-07-24 10:21:47,077][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,077][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,077][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,077][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,077][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,077][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,077][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,078][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,078][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:21:47,078][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,078][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,078][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,078][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit17']
[2024-07-24 10:21:47,078][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,079][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,079][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,079][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,079][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,079][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:21:47,079][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,079][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit15']
[2024-07-24 10:21:47,080][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:21:47,080][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,080][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,080][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,080][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,080][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,080][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,081][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:21:47,081][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,081][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:21:47,081][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,081][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,081][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,081][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,082][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,082][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,082][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:21:47,082][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:21:47,082][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:21:47,082][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,082][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,083][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,083][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,083][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,083][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,083][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,083][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13']
[2024-07-24 10:21:47,083][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:21:47,084][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,084][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,084][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,084][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,084][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,084][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:47,084][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,085][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:21:47,085][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,085][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:21:47,085][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,085][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,085][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,085][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,086][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,086][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,086][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,086][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,086][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,086][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:21:47,086][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,087][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,087][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,087][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,087][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,087][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,087][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,087][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,088][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,088][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:21:47,088][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,088][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,088][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,088][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,088][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,089][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,089][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,089][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,089][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,089][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:21:47,089][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,089][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,090][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,090][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,090][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,090][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,090][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,090][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,090][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,091][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:21:47,091][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,091][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,091][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,091][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,091][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,091][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,091][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,092][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,092][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,092][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:21:47,092][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,092][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,092][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,092][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,093][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,093][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,093][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,093][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,093][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,093][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:21:47,093][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,094][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,094][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,094][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,094][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,094][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,094][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,094][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,095][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,095][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:21:47,095][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,095][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,095][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,095][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,095][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,096][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,096][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,096][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,096][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,096][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:21:47,096][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,096][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,097][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,097][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,097][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,097][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,097][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,097][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,097][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,098][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:21:47,098][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,098][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,098][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,098][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,098][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,098][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,099][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,099][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,099][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,099][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:21:47,099][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,099][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,099][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,100][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,100][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,100][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,100][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,100][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,100][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,100][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:21:47,101][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,101][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,101][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,101][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,101][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,101][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,101][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,102][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,102][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,102][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:21:47,102][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,102][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,102][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,102][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,103][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,103][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,103][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,103][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,103][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,103][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:21:47,104][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,104][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,104][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,104][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,104][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,104][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,104][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,105][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,105][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,105][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:21:47,105][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,105][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,105][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,106][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,106][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,106][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,106][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,106][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,106][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,106][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:21:47,107][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,107][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,107][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,107][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,107][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,107][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,107][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,108][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,108][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:47,108][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,108][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:21:47,108][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:21:47,108][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,108][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,109][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,109][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,109][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,109][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,109][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit14', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:21:47,109][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,109][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,110][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:21:47,110][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,110][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,110][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,110][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,110][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,111][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,111][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,111][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,111][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,111][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,111][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:21:47,111][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:21:47,111][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,112][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:21:47,112][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:47,112][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,112][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,112][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,112][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,113][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,113][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit19']
[2024-07-24 10:21:47,113][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:21:47,113][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,113][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit14', 'circuit19', 'circuit21']
[2024-07-24 10:21:47,113][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,113][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13']
[2024-07-24 10:21:47,114][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,114][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit16']
[2024-07-24 10:21:47,114][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,114][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15']
[2024-07-24 10:21:47,114][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,114][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,114][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:21:47,115][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:21:47,115][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,115][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit23', 'circuit25']
[2024-07-24 10:21:47,115][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,115][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,115][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit25']
[2024-07-24 10:21:47,115][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit25']
[2024-07-24 10:21:47,116][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,116][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,116][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,116][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:21:47,116][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,116][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit24']
[2024-07-24 10:21:47,116][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,117][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,117][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,117][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,117][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,117][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,117][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,117][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,118][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:21:47,118][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit25']
[2024-07-24 10:21:47,118][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,118][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:21:47,118][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,118][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit1', 'circuit3', 'circuit7', 'circuit11', 'circuit27']
[2024-07-24 10:21:47,118][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,119][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,119][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,119][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit21', 'circuit23']
[2024-07-24 10:21:47,119][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit16', 'circuit19', 'circuit22', 'circuit24']
[2024-07-24 10:21:47,119][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:21:47,119][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,119][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,120][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,120][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,120][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,120][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,120][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,120][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,120][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,121][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,121][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:21:47,121][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,121][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,121][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,121][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,121][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,122][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,122][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,122][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,122][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,122][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,122][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:21:47,122][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:47,123][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,123][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit23']
[2024-07-24 10:21:47,123][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:21:47,123][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,123][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,123][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,123][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,124][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,124][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit24']
[2024-07-24 10:21:47,124][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:21:47,124][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:47,124][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,124][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:21:47,124][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit18', 'circuit19']
[2024-07-24 10:21:47,125][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,125][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit17', 'circuit19', 'circuit23', 'circuit24']
[2024-07-24 10:21:47,125][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,125][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,125][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:21:47,125][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,125][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:21:47,126][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:21:47,126][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,126][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:21:47,126][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:21:47,126][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:21:47,126][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,126][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:21:47,127][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,127][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16']
[2024-07-24 10:21:47,127][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit18', 'circuit19']
[2024-07-24 10:21:47,127][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:21:47,127][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,127][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,127][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,128][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,128][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit17', 'circuit19', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:21:47,128][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:21:47,128][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,128][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,128][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,128][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit14', 'circuit20', 'circuit22']
[2024-07-24 10:21:47,129][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:21:47,129][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,129][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,129][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,129][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,129][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,129][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,130][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,130][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,130][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,130][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,130][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:21:47,130][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,130][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,131][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,131][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,131][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,131][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,131][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,131][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,131][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,132][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,132][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:21:47,132][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,132][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,132][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,132][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,132][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,133][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,133][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,133][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,133][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,133][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,133][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:21:47,133][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,134][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,134][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,134][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,134][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,134][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,134][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,134][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,135][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,135][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,135][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:21:47,135][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,135][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,135][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,135][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,136][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,136][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,136][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,136][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,136][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,136][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,136][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:21:47,137][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,137][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,137][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,137][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,137][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,137][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,137][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,138][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,138][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,138][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,138][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:21:47,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,138][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,138][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,139][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,139][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,139][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,139][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,139][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,139][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,139][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,140][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:21:47,140][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,140][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,140][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,140][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,140][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,140][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,141][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,141][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,141][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,141][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,141][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:21:47,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,141][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,142][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,142][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,142][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,142][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,142][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,142][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,142][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,143][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,143][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:21:47,143][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22', 'circuit24']
[2024-07-24 10:21:47,143][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,143][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,143][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:21:47,143][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,144][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,144][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,144][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,144][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,144][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,144][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:21:47,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,145][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,145][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,145][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,145][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,145][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,145][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,146][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,146][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,146][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,146][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:21:47,146][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,146][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,146][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,147][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,147][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,147][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,147][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,147][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,147][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,147][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:21:47,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,148][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,148][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,148][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,148][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,148][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,149][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,149][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,149][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,149][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:21:47,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,149][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,150][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,150][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,150][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,150][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,150][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,150][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,151][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,151][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:21:47,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,151][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,151][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,151][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,152][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,152][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,152][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,152][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,152][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,152][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:21:47,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,153][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit11', 'circuit14', 'circuit15', 'circuit17', 'circuit20']
[2024-07-24 10:21:47,153][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:21:47,153][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:21:47,153][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:47,153][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,153][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit26']
[2024-07-24 10:21:47,153][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit14', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:21:47,154][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit6', 'circuit16']
[2024-07-24 10:21:47,154][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit17', 'circuit19', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,154][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit11', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:21:47,154][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:21:47,154][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,154][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,154][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,155][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,155][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,155][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,155][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,155][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,155][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,156][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,156][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:47,156][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:21:47,156][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,156][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,156][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,156][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,157][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,157][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,157][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,157][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,157][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,157][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,157][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:47,158][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:21:47,158][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,158][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,158][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,158][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,158][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:47,158][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:21:47,159][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,159][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:21:47,159][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit26']
[2024-07-24 10:21:47,159][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,159][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,159][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:21:47,159][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,160][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,160][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,160][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,160][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,160][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,160][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,160][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,161][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,161][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,161][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:47,161][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:21:47,161][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:21:47,161][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,161][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,162][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,162][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,162][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,162][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,162][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,162][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,162][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,163][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:47,163][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:21:47,163][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,163][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,163][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,163][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,163][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,164][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,164][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,164][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,164][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,164][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,164][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:47,164][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:21:47,165][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:47,165][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,165][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,165][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,165][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:21:47,165][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,165][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,166][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,166][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,166][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:21:47,166][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit13', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,166][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:21:47,166][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,167][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,167][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,167][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,167][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,167][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,167][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,167][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,168][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,168][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,168][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:21:47,168][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:21:47,168][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit27']
[2024-07-24 10:21:47,168][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,168][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:47,169][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,169][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,169][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,169][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,169][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,169][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,169][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit19', 'circuit25']
[2024-07-24 10:21:47,170][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:21:47,170][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:21:47,170][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,170][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit26']
[2024-07-24 10:21:47,170][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,170][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,170][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,171][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,171][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit27']
[2024-07-24 10:21:47,171][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit3', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit19', 'circuit27']
[2024-07-24 10:21:47,171][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,171][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit19', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,171][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit2', 'circuit11', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:21:47,171][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:21:47,172][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit25']
[2024-07-24 10:21:47,172][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:21:47,172][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit23']
[2024-07-24 10:21:47,172][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,172][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,172][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,172][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,173][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,173][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,173][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,173][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,173][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:21:47,173][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:21:47,173][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,174][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,174][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,174][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:47,174][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,174][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,174][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,174][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,175][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit15', 'circuit17']
[2024-07-24 10:21:47,175][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:47,175][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:21:47,175][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,175][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit11', 'circuit12', 'circuit13', 'circuit16', 'circuit17', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:47,175][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,175][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,176][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,176][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,176][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,176][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,176][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:21:47,176][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit18', 'circuit19', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:21:47,177][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:21:47,177][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:21:47,177][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,177][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,177][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,177][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,177][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,177][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,178][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,178][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,178][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,178][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,178][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:47,178][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:21:47,178][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,179][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,179][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,179][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,179][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,179][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,179][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,179][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,180][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,180][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,180][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:47,180][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:21:47,180][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,180][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,181][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,181][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,181][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,181][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,181][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,181][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,181][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,182][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,182][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:47,182][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:21:47,182][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,182][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,182][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,182][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,183][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,183][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,183][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,183][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,183][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,183][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,183][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:47,184][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:21:47,184][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,184][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,184][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,184][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,184][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,184][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,185][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,185][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,185][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,185][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,185][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:47,185][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:21:47,185][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,186][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,186][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,186][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,186][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,186][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,186][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,186][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,187][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,187][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,187][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:47,187][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:21:47,187][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,187][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,187][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,188][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,188][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,188][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,188][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,188][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,188][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,188][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,189][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:47,189][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:21:47,189][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,189][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,189][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,189][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,189][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,190][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,190][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,190][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,190][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,190][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,190][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:47,190][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:21:47,191][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,191][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,191][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,191][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,191][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,191][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,191][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,192][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,192][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,192][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,192][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:47,192][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:21:47,192][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,192][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,193][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,193][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,193][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,193][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,193][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,193][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,194][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,194][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,194][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:47,194][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:21:47,194][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,194][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,194][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,195][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,195][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,195][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,195][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,195][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,195][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,195][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,196][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:47,196][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:21:47,196][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:47,196][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:47,196][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:47,196][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:47,196][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:47,197][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:47,197][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:47,197][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:47,197][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:47,197][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:47,197][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:47,197][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:21:47,198][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,198][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,198][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,198][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,198][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,198][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,198][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,199][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,199][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,199][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,199][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,199][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:21:47,199][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,200][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,200][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,200][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,200][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,200][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,200][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,200][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,201][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,201][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,201][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,201][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:21:47,201][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,201][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,202][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,202][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,202][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,202][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,202][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,202][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,202][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,203][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:47,203][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:48,233][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:48,233][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,234][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,234][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,235][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,235][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,235][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,235][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,236][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,236][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,236][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,237][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,237][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,237][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,238][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,238][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,238][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,244][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,245][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,246][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,248][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,249][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,251][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,252][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,253][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,255][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.4348, 0.3769, 0.1883], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,256][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([2.3077e-05, 1.3542e-04, 9.9984e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,257][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.4792, 0.1952, 0.3255], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,258][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([1.3082e-02, 1.8136e-04, 9.8674e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,259][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.0381, 0.0065, 0.9554], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,260][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([1.0075e-02, 8.0458e-06, 9.8992e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,262][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.3950, 0.3896, 0.2154], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,263][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.4950, 0.3862, 0.1187], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,265][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.5077, 0.3550, 0.1373], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,266][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.5865, 0.3476, 0.0659], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,267][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.3970, 0.3012, 0.3018], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,269][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.4242, 0.3456, 0.2302], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,270][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7392, 0.0837, 0.1117, 0.0653], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,271][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.3031e-03, 3.9258e-02, 2.2587e-04, 9.5821e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,272][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2344, 0.1755, 0.0502, 0.5400], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,274][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1139, 0.3892, 0.0209, 0.4761], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,275][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3681, 0.1668, 0.1631, 0.3020], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,277][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1231, 0.1971, 0.0067, 0.6731], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,278][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6443, 0.0308, 0.3015, 0.0234], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,280][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2330, 0.1772, 0.3229, 0.2668], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,281][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0670, 0.4695, 0.0232, 0.4402], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,283][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4215, 0.2354, 0.1245, 0.2186], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,283][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4179, 0.3113, 0.0655, 0.2054], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,283][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4457, 0.1947, 0.1053, 0.2544], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,284][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.2552, 0.2097, 0.2197, 0.2621, 0.0533], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,284][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([1.3127e-05, 1.0247e-04, 2.0749e-03, 1.0608e-04, 9.9770e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,284][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.4007, 0.2602, 0.0856, 0.1384, 0.1151], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,285][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([1.3974e-02, 1.8102e-04, 2.0140e-02, 4.0368e-04, 9.6530e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,285][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([5.4647e-03, 4.2625e-04, 1.2183e-02, 4.8635e-04, 9.8144e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,285][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([8.7052e-03, 2.3754e-06, 1.2927e-03, 1.4976e-06, 9.9000e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,287][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.2424, 0.2759, 0.1077, 0.1835, 0.1905], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,288][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.2903, 0.1732, 0.0298, 0.4263, 0.0804], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,289][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.3463, 0.2662, 0.0971, 0.2283, 0.0620], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,291][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.3766, 0.2434, 0.1550, 0.1966, 0.0283], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,292][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.2447, 0.1913, 0.1015, 0.1312, 0.3312], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,293][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.1608, 0.2539, 0.1265, 0.2871, 0.1717], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,295][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.3180, 0.0767, 0.0606, 0.0764, 0.1753, 0.2931], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,296][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0015, 0.0018, 0.0019, 0.0014, 0.0015, 0.9919], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,297][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.4628, 0.1331, 0.0668, 0.1887, 0.0539, 0.0947], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,298][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ went] are: tensor([1.4930e-02, 7.5074e-04, 7.0675e-04, 1.2512e-03, 8.3161e-04, 9.8153e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,300][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.3411, 0.0513, 0.0315, 0.0691, 0.0284, 0.4786], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,301][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ went] are: tensor([5.7752e-02, 1.8508e-04, 2.9914e-05, 3.0794e-05, 1.4025e-05, 9.4199e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,302][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.2841, 0.0543, 0.2941, 0.0425, 0.2750, 0.0500], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,304][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.1377, 0.0907, 0.1186, 0.2191, 0.2255, 0.2084], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,305][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.2160, 0.2801, 0.0890, 0.3178, 0.0440, 0.0532], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,306][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.3030, 0.1761, 0.1138, 0.1731, 0.1304, 0.1036], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,308][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.2936, 0.1910, 0.0657, 0.1470, 0.0434, 0.2594], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,309][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.3768, 0.1437, 0.0794, 0.1924, 0.1065, 0.1012], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,311][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.3968, 0.0531, 0.0603, 0.0433, 0.2087, 0.2125, 0.0254],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,312][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.2437e-03, 2.1519e-02, 2.3099e-04, 5.3075e-02, 1.0500e-04, 6.8604e-04,
        9.2014e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,313][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2779, 0.1460, 0.0536, 0.1623, 0.0324, 0.0787, 0.2492],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,314][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0196, 0.0109, 0.0031, 0.0181, 0.0029, 0.4600, 0.4854],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,316][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1063, 0.0120, 0.0347, 0.0243, 0.0416, 0.6433, 0.1379],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,317][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0922, 0.0991, 0.0021, 0.1078, 0.0016, 0.0137, 0.6835],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,319][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2744, 0.0178, 0.0887, 0.0137, 0.1459, 0.0801, 0.3795],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,320][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1004, 0.0542, 0.0628, 0.1174, 0.1103, 0.2946, 0.2603],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,321][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0252, 0.1973, 0.0091, 0.2948, 0.0130, 0.0540, 0.4065],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,323][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2519, 0.1613, 0.0870, 0.1658, 0.0777, 0.0837, 0.1727],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,324][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.2425, 0.2111, 0.0612, 0.1875, 0.0391, 0.0822, 0.1765],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,326][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.2893, 0.1201, 0.0891, 0.1369, 0.1277, 0.0970, 0.1400],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,327][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.4027, 0.0407, 0.1446, 0.0264, 0.2536, 0.0932, 0.0152, 0.0236],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,328][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ the] are: tensor([3.1839e-03, 2.6303e-02, 4.1503e-04, 5.2410e-02, 1.1884e-04, 1.4415e-04,
        7.6565e-02, 8.4086e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,330][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2402, 0.1311, 0.0504, 0.1287, 0.0437, 0.1059, 0.2630, 0.0369],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,331][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0287, 0.0115, 0.0057, 0.0204, 0.0088, 0.0835, 0.1760, 0.6654],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,333][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1988, 0.0306, 0.0339, 0.0457, 0.0624, 0.3265, 0.1420, 0.1600],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,334][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1121, 0.1533, 0.0117, 0.1134, 0.0098, 0.0381, 0.1204, 0.4413],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,335][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2832, 0.0058, 0.3187, 0.0052, 0.2972, 0.0768, 0.0096, 0.0034],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,337][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0834, 0.0354, 0.0349, 0.0804, 0.0980, 0.1481, 0.2189, 0.3010],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,338][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0145, 0.1255, 0.0068, 0.1861, 0.0099, 0.0461, 0.1835, 0.4275],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,340][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.2360, 0.1352, 0.0896, 0.1358, 0.0703, 0.0738, 0.1412, 0.1182],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,340][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.2626, 0.1668, 0.0597, 0.1424, 0.0325, 0.0429, 0.1102, 0.1828],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,341][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2419, 0.1004, 0.0896, 0.1134, 0.1471, 0.0826, 0.1078, 0.1172],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,341][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ house] are: tensor([0.1714, 0.0687, 0.0544, 0.0745, 0.2453, 0.0405, 0.0544, 0.0795, 0.2113],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,341][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ house] are: tensor([8.8244e-05, 1.8030e-03, 6.3473e-04, 1.2356e-03, 5.3401e-04, 3.7052e-04,
        5.3847e-04, 3.1566e-04, 9.9448e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,342][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.2287, 0.0665, 0.1512, 0.1248, 0.1244, 0.0726, 0.0910, 0.1117, 0.0291],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,342][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ house] are: tensor([8.5234e-03, 1.7947e-04, 9.9234e-04, 5.0301e-04, 2.7961e-03, 5.8475e-03,
        4.9552e-03, 4.5799e-03, 9.7162e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,343][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ house] are: tensor([0.0986, 0.0047, 0.0224, 0.0066, 0.0319, 0.0429, 0.0105, 0.0229, 0.7595],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,343][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ house] are: tensor([4.6909e-03, 3.5968e-05, 2.4225e-04, 7.4538e-06, 3.6582e-05, 1.8752e-05,
        1.4077e-06, 1.1785e-05, 9.9495e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,344][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ house] are: tensor([0.1473, 0.0286, 0.3163, 0.0185, 0.3099, 0.0140, 0.0101, 0.0141, 0.1412],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,346][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ house] are: tensor([0.0829, 0.0300, 0.0037, 0.0908, 0.0172, 0.1844, 0.1774, 0.3445, 0.0690],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,347][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.1844, 0.0975, 0.1018, 0.1129, 0.1599, 0.0539, 0.0951, 0.1347, 0.0599],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,348][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ house] are: tensor([0.2242, 0.1308, 0.1052, 0.1203, 0.1175, 0.0691, 0.1044, 0.1116, 0.0169],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,350][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.1388, 0.1221, 0.0775, 0.1240, 0.0519, 0.0544, 0.0951, 0.0845, 0.2516],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,351][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ house] are: tensor([0.3425, 0.1083, 0.0866, 0.0745, 0.1131, 0.0471, 0.0916, 0.0363, 0.1001],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,352][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.4880, 0.0178, 0.0611, 0.0146, 0.1868, 0.1193, 0.0105, 0.0394, 0.0517,
        0.0108], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,353][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [.] are: tensor([3.4794e-03, 4.5744e-02, 3.3231e-04, 8.3743e-03, 2.2970e-03, 4.5617e-04,
        5.8340e-03, 4.1349e-04, 4.1040e-04, 9.3266e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,355][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.4319, 0.0624, 0.0395, 0.0483, 0.0290, 0.2336, 0.0566, 0.0264, 0.0169,
        0.0554], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,356][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0304, 0.0077, 0.0023, 0.0112, 0.0066, 0.0615, 0.0756, 0.1831, 0.0989,
        0.5227], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,358][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0644, 0.0262, 0.0186, 0.0555, 0.0236, 0.0935, 0.1134, 0.1177, 0.1432,
        0.3440], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,359][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1404, 0.2031, 0.0187, 0.1236, 0.0062, 0.0480, 0.0808, 0.0841, 0.0191,
        0.2760], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,360][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.3329, 0.0099, 0.2377, 0.0070, 0.2552, 0.0412, 0.0116, 0.0059, 0.0945,
        0.0041], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,362][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0393, 0.0148, 0.0302, 0.0322, 0.0449, 0.0643, 0.0711, 0.1478, 0.1463,
        0.4090], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,363][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0184, 0.1691, 0.0066, 0.1294, 0.0074, 0.0108, 0.1060, 0.1481, 0.0124,
        0.3919], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,365][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1913, 0.1105, 0.0885, 0.1116, 0.0629, 0.0762, 0.1059, 0.0909, 0.0579,
        0.1042], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,366][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1586, 0.1409, 0.0665, 0.1359, 0.0508, 0.0744, 0.1121, 0.0762, 0.0438,
        0.1408], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,368][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.2606, 0.0927, 0.0678, 0.0928, 0.1016, 0.0716, 0.0830, 0.0454, 0.0527,
        0.1318], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,369][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.1534, 0.1249, 0.0984, 0.1130, 0.0442, 0.0185, 0.1207, 0.0650, 0.0473,
        0.1170, 0.0976], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,370][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([5.5982e-06, 2.0949e-05, 4.7572e-01, 7.8889e-06, 2.2339e-04, 3.7606e-05,
        3.1070e-06, 4.0395e-06, 6.7130e-06, 9.5778e-07, 5.2397e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,372][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.1543, 0.0647, 0.2263, 0.0594, 0.0367, 0.0389, 0.0513, 0.0854, 0.0259,
        0.0599, 0.1973], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,372][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([4.5395e-04, 5.7083e-07, 4.0257e-03, 9.1518e-07, 2.0270e-04, 3.0564e-05,
        5.8523e-06, 1.3720e-05, 1.0421e-04, 4.0605e-05, 9.9512e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,373][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([2.4642e-03, 3.9795e-04, 5.4809e-02, 2.7955e-04, 1.0339e-02, 6.4376e-04,
        6.0844e-04, 1.1188e-03, 2.0062e-03, 3.0706e-03, 9.2426e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,374][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([1.2692e-03, 7.0794e-07, 6.6652e-01, 2.3618e-07, 6.9549e-05, 4.0814e-07,
        1.1846e-08, 2.7645e-08, 7.4214e-07, 2.4788e-08, 3.3214e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,376][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.0917, 0.1261, 0.1221, 0.0909, 0.1793, 0.0178, 0.0196, 0.1125, 0.0670,
        0.0718, 0.1012], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,377][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.0650, 0.0222, 0.0115, 0.0456, 0.0098, 0.0546, 0.0990, 0.1686, 0.0324,
        0.3440, 0.1471], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,379][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.1684, 0.1380, 0.0686, 0.1075, 0.0421, 0.0544, 0.0791, 0.1249, 0.0420,
        0.1110, 0.0640], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,380][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.1886, 0.1331, 0.0283, 0.1114, 0.0928, 0.0588, 0.0953, 0.1060, 0.0557,
        0.1064, 0.0236], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,382][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.0727, 0.0800, 0.2577, 0.0808, 0.0712, 0.0358, 0.0673, 0.0555, 0.0291,
        0.0559, 0.1940], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,383][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.0971, 0.0736, 0.0716, 0.0715, 0.0810, 0.1103, 0.0687, 0.0414, 0.1669,
        0.1123, 0.1057], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,384][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.2286, 0.0256, 0.0270, 0.0300, 0.0923, 0.2400, 0.0209, 0.0207, 0.0537,
        0.0188, 0.0286, 0.2139], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,385][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([4.4725e-04, 9.0725e-04, 2.9272e-03, 1.9194e-03, 3.1629e-04, 7.7018e-03,
        9.7552e-04, 2.7284e-04, 2.1821e-04, 7.4691e-05, 1.7451e-03, 9.8249e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,387][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.2421, 0.0658, 0.0295, 0.0748, 0.0495, 0.0882, 0.1187, 0.0749, 0.0384,
        0.0996, 0.0248, 0.0936], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,388][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([2.0179e-03, 2.1988e-05, 1.8120e-05, 2.8828e-05, 3.8414e-05, 1.1545e-03,
        1.2827e-04, 2.0786e-04, 6.8704e-04, 6.9686e-04, 2.7160e-03, 9.9228e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,389][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1223, 0.0117, 0.0108, 0.0132, 0.0078, 0.0387, 0.0311, 0.0211, 0.0772,
        0.0433, 0.0695, 0.5532], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,390][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([4.3205e-02, 2.6894e-05, 2.8344e-04, 2.5130e-05, 4.5599e-05, 9.5717e-03,
        3.0519e-06, 1.1468e-05, 7.5367e-06, 1.9245e-06, 7.0925e-05, 9.4675e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,392][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1403, 0.0189, 0.1577, 0.0180, 0.1851, 0.0312, 0.0141, 0.0183, 0.1595,
        0.0163, 0.2047, 0.0358], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,393][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0313, 0.0100, 0.0110, 0.0180, 0.0163, 0.0200, 0.0441, 0.0751, 0.0595,
        0.2883, 0.2080, 0.2182], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,394][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0905, 0.0964, 0.0316, 0.1179, 0.0176, 0.0372, 0.1050, 0.1396, 0.1776,
        0.1090, 0.0399, 0.0377], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,396][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1471, 0.0839, 0.0645, 0.0868, 0.0842, 0.0745, 0.0880, 0.0721, 0.0611,
        0.1019, 0.0691, 0.0668], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,397][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.1075, 0.0806, 0.0753, 0.0830, 0.0335, 0.0957, 0.0832, 0.0587, 0.0383,
        0.0717, 0.0632, 0.2092], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,398][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.2557, 0.0910, 0.0416, 0.1120, 0.0620, 0.0456, 0.0970, 0.0421, 0.0333,
        0.1110, 0.0395, 0.0692], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,398][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2562, 0.0227, 0.0864, 0.0174, 0.1565, 0.0527, 0.0132, 0.0241, 0.1121,
        0.0175, 0.1120, 0.1091, 0.0199], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,399][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.0815e-04, 2.6693e-03, 1.3718e-03, 2.9472e-03, 2.0885e-04, 9.5592e-05,
        9.1471e-03, 3.0419e-02, 4.7715e-04, 5.9979e-04, 7.2708e-04, 2.2080e-04,
        9.5031e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,399][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1285, 0.0702, 0.0387, 0.0986, 0.0296, 0.0713, 0.1644, 0.0225, 0.0233,
        0.1975, 0.0393, 0.0952, 0.0208], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,400][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([7.1798e-03, 1.0022e-03, 3.9365e-04, 9.2096e-04, 3.2544e-04, 2.0897e-03,
        4.1377e-03, 1.7339e-02, 7.8428e-03, 2.7320e-02, 3.3567e-02, 1.3687e-01,
        7.6102e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,400][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0348, 0.0049, 0.0093, 0.0058, 0.0120, 0.0608, 0.0155, 0.0167, 0.0308,
        0.0210, 0.0824, 0.5227, 0.1834], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,400][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0309, 0.0942, 0.0063, 0.0771, 0.0011, 0.0098, 0.0841, 0.2041, 0.0182,
        0.0291, 0.0018, 0.0070, 0.4363], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,402][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1586, 0.0041, 0.1410, 0.0038, 0.1794, 0.0637, 0.0080, 0.0031, 0.1282,
        0.0030, 0.2207, 0.0808, 0.0055], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,403][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0235, 0.0061, 0.0052, 0.0111, 0.0140, 0.0208, 0.0206, 0.0350, 0.0374,
        0.1882, 0.1065, 0.2668, 0.2650], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,405][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0101, 0.0524, 0.0038, 0.0887, 0.0048, 0.0220, 0.0930, 0.2233, 0.0180,
        0.1197, 0.0063, 0.0274, 0.3306], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,406][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1410, 0.0891, 0.0549, 0.0953, 0.0440, 0.0507, 0.0968, 0.0830, 0.0553,
        0.0827, 0.0534, 0.0691, 0.0847], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,408][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1108, 0.0917, 0.0599, 0.0994, 0.0290, 0.0361, 0.0981, 0.1077, 0.0487,
        0.0673, 0.0466, 0.0405, 0.1641], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,409][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1939, 0.0758, 0.0606, 0.0721, 0.0876, 0.0569, 0.0806, 0.0431, 0.0402,
        0.0902, 0.0630, 0.0784, 0.0578], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,410][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0936, 0.0520, 0.0629, 0.0378, 0.1164, 0.0432, 0.0284, 0.0408, 0.2059,
        0.0313, 0.0619, 0.0561, 0.0332, 0.1363], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,411][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([8.3081e-05, 1.4525e-04, 3.7304e-04, 2.3564e-04, 1.0049e-03, 2.5856e-04,
        3.7986e-05, 1.3760e-04, 6.5413e-04, 3.7042e-06, 1.8041e-04, 1.1393e-04,
        1.1909e-05, 9.9676e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,413][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.1342, 0.0578, 0.0629, 0.0968, 0.0428, 0.0422, 0.1046, 0.0708, 0.0973,
        0.0581, 0.0537, 0.0634, 0.0710, 0.0443], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,414][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([8.3602e-04, 4.4986e-06, 4.7199e-06, 5.3906e-06, 2.5993e-05, 1.0345e-04,
        3.8363e-05, 1.2582e-04, 1.1784e-03, 2.0782e-04, 6.2063e-04, 3.0944e-03,
        3.3560e-03, 9.9040e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,415][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0365, 0.0039, 0.0086, 0.0033, 0.0188, 0.0201, 0.0037, 0.0095, 0.0426,
        0.0138, 0.0445, 0.0318, 0.0305, 0.7324], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,416][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([2.7211e-03, 8.2096e-06, 5.4935e-05, 2.5764e-06, 3.5809e-05, 1.1708e-05,
        3.8496e-07, 9.9196e-07, 9.3944e-05, 1.7800e-07, 9.4457e-06, 3.4140e-07,
        6.9792e-07, 9.9706e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,418][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.1083, 0.0433, 0.1548, 0.0266, 0.1929, 0.0276, 0.0147, 0.0132, 0.1299,
        0.0313, 0.1425, 0.0250, 0.0153, 0.0746], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,419][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0399, 0.0217, 0.0040, 0.0214, 0.0135, 0.0194, 0.0376, 0.0450, 0.0195,
        0.1349, 0.0471, 0.2446, 0.2763, 0.0752], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,420][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.1506, 0.0862, 0.0253, 0.1034, 0.0479, 0.0562, 0.0864, 0.0709, 0.0158,
        0.0784, 0.0244, 0.0690, 0.1091, 0.0765], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,422][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.1079, 0.0842, 0.0785, 0.0788, 0.0985, 0.0447, 0.0760, 0.0704, 0.0787,
        0.0720, 0.0762, 0.0509, 0.0785, 0.0047], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,424][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.0958, 0.0696, 0.0317, 0.0709, 0.0617, 0.0558, 0.0748, 0.0613, 0.0586,
        0.0559, 0.0275, 0.0348, 0.0590, 0.2425], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,425][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.1591, 0.0791, 0.0646, 0.0557, 0.0779, 0.0667, 0.0583, 0.0294, 0.0672,
        0.0540, 0.0649, 0.0886, 0.0422, 0.0924], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,427][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2338, 0.0227, 0.0317, 0.0190, 0.1145, 0.1210, 0.0108, 0.0266, 0.0520,
        0.0180, 0.0404, 0.1296, 0.0271, 0.1380, 0.0150], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,428][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.3318e-03, 6.6646e-03, 6.6938e-05, 1.9416e-02, 2.1098e-05, 2.4622e-04,
        4.5088e-01, 1.0429e-03, 4.7417e-05, 4.1259e-03, 3.3110e-05, 3.8134e-04,
        6.5953e-04, 1.0639e-05, 5.1407e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,429][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1297, 0.0570, 0.0274, 0.0782, 0.0184, 0.0439, 0.1213, 0.0226, 0.0248,
        0.2172, 0.0257, 0.0578, 0.0205, 0.0154, 0.1400], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,430][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([2.5111e-03, 2.2669e-04, 3.8276e-05, 1.5534e-04, 2.9015e-05, 2.6029e-03,
        1.8415e-03, 2.4849e-03, 1.0165e-03, 4.0759e-03, 2.1219e-03, 2.2916e-01,
        6.7670e-02, 1.2292e-01, 5.6315e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,432][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0337, 0.0022, 0.0042, 0.0036, 0.0037, 0.0710, 0.0131, 0.0080, 0.0179,
        0.0131, 0.0368, 0.3828, 0.0880, 0.0610, 0.2610], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,433][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.6365e-02, 3.7246e-02, 9.2120e-04, 4.7687e-02, 7.8464e-04, 7.7860e-03,
        3.6341e-01, 1.3185e-01, 6.9851e-03, 1.6711e-02, 2.4146e-04, 4.0850e-03,
        9.8190e-02, 2.2914e-03, 2.5545e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,434][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1115, 0.0054, 0.0415, 0.0046, 0.0730, 0.0357, 0.1654, 0.0032, 0.0775,
        0.0052, 0.0641, 0.0555, 0.0058, 0.0555, 0.2959], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,436][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0239, 0.0045, 0.0041, 0.0074, 0.0074, 0.0135, 0.0088, 0.0204, 0.0181,
        0.0933, 0.0600, 0.1312, 0.1734, 0.1381, 0.2959], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,437][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0070, 0.0518, 0.0026, 0.0903, 0.0042, 0.0184, 0.1158, 0.1525, 0.0161,
        0.1194, 0.0037, 0.0181, 0.1785, 0.0152, 0.2065], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,439][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1179, 0.0731, 0.0482, 0.0804, 0.0430, 0.0450, 0.0805, 0.0721, 0.0457,
        0.0724, 0.0479, 0.0624, 0.0777, 0.0365, 0.0972], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,440][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0966, 0.0794, 0.0385, 0.0950, 0.0304, 0.0614, 0.1099, 0.0770, 0.0380,
        0.0756, 0.0315, 0.0573, 0.0788, 0.0231, 0.1074], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,442][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1757, 0.0694, 0.0538, 0.0713, 0.0744, 0.0572, 0.0705, 0.0338, 0.0326,
        0.0764, 0.0533, 0.0762, 0.0444, 0.0393, 0.0717], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,464][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:48,465][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,467][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,468][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,469][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,470][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,471][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,472][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,473][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,474][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,476][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,477][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,478][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,479][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,481][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,482][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,484][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,485][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,486][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,488][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,489][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,490][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,492][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,493][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,495][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,496][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.4348, 0.3769, 0.1883], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,497][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([2.3077e-05, 1.3542e-04, 9.9984e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,498][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.4792, 0.1952, 0.3255], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,499][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([1.3082e-02, 1.8136e-04, 9.8674e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,501][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.0381, 0.0065, 0.9554], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,501][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([1.0075e-02, 8.0458e-06, 9.8992e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,503][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.3950, 0.3896, 0.2154], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,504][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.4950, 0.3862, 0.1187], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,506][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.5077, 0.3550, 0.1373], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,507][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.5865, 0.3476, 0.0659], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,509][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.3970, 0.3012, 0.3018], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,510][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.4242, 0.3456, 0.2302], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,511][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.7392, 0.0837, 0.1117, 0.0653], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,512][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.3031e-03, 3.9258e-02, 2.2587e-04, 9.5821e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,514][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2344, 0.1755, 0.0502, 0.5400], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,515][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1139, 0.3892, 0.0209, 0.4761], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,516][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3681, 0.1668, 0.1631, 0.3020], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,516][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1231, 0.1971, 0.0067, 0.6731], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,516][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6443, 0.0308, 0.3015, 0.0234], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,517][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2330, 0.1772, 0.3229, 0.2668], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,517][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0670, 0.4695, 0.0232, 0.4402], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,517][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4215, 0.2354, 0.1245, 0.2186], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,518][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4179, 0.3113, 0.0655, 0.2054], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,518][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4457, 0.1947, 0.1053, 0.2544], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,519][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.2552, 0.2097, 0.2197, 0.2621, 0.0533], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,520][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([1.3127e-05, 1.0247e-04, 2.0749e-03, 1.0608e-04, 9.9770e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,521][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.4007, 0.2602, 0.0856, 0.1384, 0.1151], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,522][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([1.3974e-02, 1.8102e-04, 2.0140e-02, 4.0368e-04, 9.6530e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,523][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([5.4647e-03, 4.2625e-04, 1.2183e-02, 4.8635e-04, 9.8144e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,524][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([8.7052e-03, 2.3754e-06, 1.2927e-03, 1.4976e-06, 9.9000e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,525][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.2424, 0.2759, 0.1077, 0.1835, 0.1905], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,527][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.2903, 0.1732, 0.0298, 0.4263, 0.0804], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,528][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.3463, 0.2662, 0.0971, 0.2283, 0.0620], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,529][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.3766, 0.2434, 0.1550, 0.1966, 0.0283], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,531][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.2447, 0.1913, 0.1015, 0.1312, 0.3312], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,532][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.1608, 0.2539, 0.1265, 0.2871, 0.1717], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,533][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.3180, 0.0767, 0.0606, 0.0764, 0.1753, 0.2931], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,535][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0015, 0.0018, 0.0019, 0.0014, 0.0015, 0.9919], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,536][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.4628, 0.1331, 0.0668, 0.1887, 0.0539, 0.0947], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,537][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([1.4930e-02, 7.5074e-04, 7.0675e-04, 1.2512e-03, 8.3161e-04, 9.8153e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,538][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.3411, 0.0513, 0.0315, 0.0691, 0.0284, 0.4786], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,539][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([5.7752e-02, 1.8508e-04, 2.9914e-05, 3.0794e-05, 1.4025e-05, 9.4199e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,541][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.2841, 0.0543, 0.2941, 0.0425, 0.2750, 0.0500], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,542][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.1377, 0.0907, 0.1186, 0.2191, 0.2255, 0.2084], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,544][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.2160, 0.2801, 0.0890, 0.3178, 0.0440, 0.0532], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,545][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.3030, 0.1761, 0.1138, 0.1731, 0.1304, 0.1036], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,547][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.2936, 0.1910, 0.0657, 0.1470, 0.0434, 0.2594], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,548][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.3768, 0.1437, 0.0794, 0.1924, 0.1065, 0.1012], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,549][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3968, 0.0531, 0.0603, 0.0433, 0.2087, 0.2125, 0.0254],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,550][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.2437e-03, 2.1519e-02, 2.3099e-04, 5.3075e-02, 1.0500e-04, 6.8604e-04,
        9.2014e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,552][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2779, 0.1460, 0.0536, 0.1623, 0.0324, 0.0787, 0.2492],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,553][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0196, 0.0109, 0.0031, 0.0181, 0.0029, 0.4600, 0.4854],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,554][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1063, 0.0120, 0.0347, 0.0243, 0.0416, 0.6433, 0.1379],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,556][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0922, 0.0991, 0.0021, 0.1078, 0.0016, 0.0137, 0.6835],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,557][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2744, 0.0178, 0.0887, 0.0137, 0.1459, 0.0801, 0.3795],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,559][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1004, 0.0542, 0.0628, 0.1174, 0.1103, 0.2946, 0.2603],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,560][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0252, 0.1973, 0.0091, 0.2948, 0.0130, 0.0540, 0.4065],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,562][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.2519, 0.1613, 0.0870, 0.1658, 0.0777, 0.0837, 0.1727],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,563][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2425, 0.2111, 0.0612, 0.1875, 0.0391, 0.0822, 0.1765],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,565][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.2893, 0.1201, 0.0891, 0.1369, 0.1277, 0.0970, 0.1400],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,566][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.4027, 0.0407, 0.1446, 0.0264, 0.2536, 0.0932, 0.0152, 0.0236],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,567][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([3.1839e-03, 2.6303e-02, 4.1503e-04, 5.2410e-02, 1.1884e-04, 1.4415e-04,
        7.6565e-02, 8.4086e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,568][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2402, 0.1311, 0.0504, 0.1287, 0.0437, 0.1059, 0.2630, 0.0369],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,570][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0287, 0.0115, 0.0057, 0.0204, 0.0088, 0.0835, 0.1760, 0.6654],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,571][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1988, 0.0306, 0.0339, 0.0457, 0.0624, 0.3265, 0.1420, 0.1600],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,573][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1121, 0.1533, 0.0117, 0.1134, 0.0098, 0.0381, 0.1204, 0.4413],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,573][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2832, 0.0058, 0.3187, 0.0052, 0.2972, 0.0768, 0.0096, 0.0034],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,574][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0834, 0.0354, 0.0349, 0.0804, 0.0980, 0.1481, 0.2189, 0.3010],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,574][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0145, 0.1255, 0.0068, 0.1861, 0.0099, 0.0461, 0.1835, 0.4275],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,574][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.2360, 0.1352, 0.0896, 0.1358, 0.0703, 0.0738, 0.1412, 0.1182],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,575][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.2626, 0.1668, 0.0597, 0.1424, 0.0325, 0.0429, 0.1102, 0.1828],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,575][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2419, 0.1004, 0.0896, 0.1134, 0.1471, 0.0826, 0.1078, 0.1172],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,576][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([0.1714, 0.0687, 0.0544, 0.0745, 0.2453, 0.0405, 0.0544, 0.0795, 0.2113],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,576][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([8.8244e-05, 1.8030e-03, 6.3473e-04, 1.2356e-03, 5.3401e-04, 3.7052e-04,
        5.3847e-04, 3.1566e-04, 9.9448e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,576][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([0.2287, 0.0665, 0.1512, 0.1248, 0.1244, 0.0726, 0.0910, 0.1117, 0.0291],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,577][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([8.5234e-03, 1.7947e-04, 9.9234e-04, 5.0301e-04, 2.7961e-03, 5.8475e-03,
        4.9552e-03, 4.5799e-03, 9.7162e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,578][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([0.0986, 0.0047, 0.0224, 0.0066, 0.0319, 0.0429, 0.0105, 0.0229, 0.7595],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,579][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([4.6909e-03, 3.5968e-05, 2.4225e-04, 7.4538e-06, 3.6582e-05, 1.8752e-05,
        1.4077e-06, 1.1785e-05, 9.9495e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,581][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([0.1473, 0.0286, 0.3163, 0.0185, 0.3099, 0.0140, 0.0101, 0.0141, 0.1412],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,582][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([0.0829, 0.0300, 0.0037, 0.0908, 0.0172, 0.1844, 0.1774, 0.3445, 0.0690],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,583][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([0.1844, 0.0975, 0.1018, 0.1129, 0.1599, 0.0539, 0.0951, 0.1347, 0.0599],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,585][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([0.2242, 0.1308, 0.1052, 0.1203, 0.1175, 0.0691, 0.1044, 0.1116, 0.0169],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,586][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([0.1388, 0.1221, 0.0775, 0.1240, 0.0519, 0.0544, 0.0951, 0.0845, 0.2516],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,588][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([0.3425, 0.1083, 0.0866, 0.0745, 0.1131, 0.0471, 0.0916, 0.0363, 0.1001],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,589][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.4880, 0.0178, 0.0611, 0.0146, 0.1868, 0.1193, 0.0105, 0.0394, 0.0517,
        0.0108], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,590][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([3.4794e-03, 4.5744e-02, 3.3231e-04, 8.3743e-03, 2.2970e-03, 4.5617e-04,
        5.8340e-03, 4.1349e-04, 4.1040e-04, 9.3266e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,591][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.4319, 0.0624, 0.0395, 0.0483, 0.0290, 0.2336, 0.0566, 0.0264, 0.0169,
        0.0554], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,593][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0304, 0.0077, 0.0023, 0.0112, 0.0066, 0.0615, 0.0756, 0.1831, 0.0989,
        0.5227], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,594][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0644, 0.0262, 0.0186, 0.0555, 0.0236, 0.0935, 0.1134, 0.1177, 0.1432,
        0.3440], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,596][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1404, 0.2031, 0.0187, 0.1236, 0.0062, 0.0480, 0.0808, 0.0841, 0.0191,
        0.2760], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,597][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.3329, 0.0099, 0.2377, 0.0070, 0.2552, 0.0412, 0.0116, 0.0059, 0.0945,
        0.0041], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,599][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0393, 0.0148, 0.0302, 0.0322, 0.0449, 0.0643, 0.0711, 0.1478, 0.1463,
        0.4090], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,600][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0184, 0.1691, 0.0066, 0.1294, 0.0074, 0.0108, 0.1060, 0.1481, 0.0124,
        0.3919], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,601][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.1913, 0.1105, 0.0885, 0.1116, 0.0629, 0.0762, 0.1059, 0.0909, 0.0579,
        0.1042], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,603][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1586, 0.1409, 0.0665, 0.1359, 0.0508, 0.0744, 0.1121, 0.0762, 0.0438,
        0.1408], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,604][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.2606, 0.0927, 0.0678, 0.0928, 0.1016, 0.0716, 0.0830, 0.0454, 0.0527,
        0.1318], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,606][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.1534, 0.1249, 0.0984, 0.1130, 0.0442, 0.0185, 0.1207, 0.0650, 0.0473,
        0.1170, 0.0976], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,607][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([5.5982e-06, 2.0949e-05, 4.7572e-01, 7.8889e-06, 2.2339e-04, 3.7606e-05,
        3.1070e-06, 4.0395e-06, 6.7130e-06, 9.5778e-07, 5.2397e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,608][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.1543, 0.0647, 0.2263, 0.0594, 0.0367, 0.0389, 0.0513, 0.0854, 0.0259,
        0.0599, 0.1973], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,609][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([4.5395e-04, 5.7083e-07, 4.0257e-03, 9.1518e-07, 2.0270e-04, 3.0564e-05,
        5.8523e-06, 1.3720e-05, 1.0421e-04, 4.0605e-05, 9.9512e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,610][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([2.4642e-03, 3.9795e-04, 5.4809e-02, 2.7955e-04, 1.0339e-02, 6.4376e-04,
        6.0844e-04, 1.1188e-03, 2.0062e-03, 3.0706e-03, 9.2426e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,611][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([1.2692e-03, 7.0794e-07, 6.6652e-01, 2.3618e-07, 6.9549e-05, 4.0814e-07,
        1.1846e-08, 2.7645e-08, 7.4214e-07, 2.4788e-08, 3.3214e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,612][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.0917, 0.1261, 0.1221, 0.0909, 0.1793, 0.0178, 0.0196, 0.1125, 0.0670,
        0.0718, 0.1012], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,614][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.0650, 0.0222, 0.0115, 0.0456, 0.0098, 0.0546, 0.0990, 0.1686, 0.0324,
        0.3440, 0.1471], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,615][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.1684, 0.1380, 0.0686, 0.1075, 0.0421, 0.0544, 0.0791, 0.1249, 0.0420,
        0.1110, 0.0640], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,617][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.1886, 0.1331, 0.0283, 0.1114, 0.0928, 0.0588, 0.0953, 0.1060, 0.0557,
        0.1064, 0.0236], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,618][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.0727, 0.0800, 0.2577, 0.0808, 0.0712, 0.0358, 0.0673, 0.0555, 0.0291,
        0.0559, 0.1940], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,620][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.0971, 0.0736, 0.0716, 0.0715, 0.0810, 0.1103, 0.0687, 0.0414, 0.1669,
        0.1123, 0.1057], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,621][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.2286, 0.0256, 0.0270, 0.0300, 0.0923, 0.2400, 0.0209, 0.0207, 0.0537,
        0.0188, 0.0286, 0.2139], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,622][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([4.4725e-04, 9.0725e-04, 2.9272e-03, 1.9194e-03, 3.1629e-04, 7.7018e-03,
        9.7552e-04, 2.7284e-04, 2.1821e-04, 7.4691e-05, 1.7451e-03, 9.8249e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,624][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.2421, 0.0658, 0.0295, 0.0748, 0.0495, 0.0882, 0.1187, 0.0749, 0.0384,
        0.0996, 0.0248, 0.0936], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,625][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([2.0179e-03, 2.1988e-05, 1.8120e-05, 2.8828e-05, 3.8414e-05, 1.1545e-03,
        1.2827e-04, 2.0786e-04, 6.8704e-04, 6.9686e-04, 2.7160e-03, 9.9228e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,626][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1223, 0.0117, 0.0108, 0.0132, 0.0078, 0.0387, 0.0311, 0.0211, 0.0772,
        0.0433, 0.0695, 0.5532], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,627][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([4.3205e-02, 2.6894e-05, 2.8344e-04, 2.5130e-05, 4.5599e-05, 9.5717e-03,
        3.0519e-06, 1.1468e-05, 7.5367e-06, 1.9245e-06, 7.0925e-05, 9.4675e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,629][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.1403, 0.0189, 0.1577, 0.0180, 0.1851, 0.0312, 0.0141, 0.0183, 0.1595,
        0.0163, 0.2047, 0.0358], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,630][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0313, 0.0100, 0.0110, 0.0180, 0.0163, 0.0200, 0.0441, 0.0751, 0.0595,
        0.2883, 0.2080, 0.2182], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,631][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0905, 0.0964, 0.0316, 0.1179, 0.0176, 0.0372, 0.1050, 0.1396, 0.1776,
        0.1090, 0.0399, 0.0377], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,631][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1471, 0.0839, 0.0645, 0.0868, 0.0842, 0.0745, 0.0880, 0.0721, 0.0611,
        0.1019, 0.0691, 0.0668], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,632][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.1075, 0.0806, 0.0753, 0.0830, 0.0335, 0.0957, 0.0832, 0.0587, 0.0383,
        0.0717, 0.0632, 0.2092], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,632][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.2557, 0.0910, 0.0416, 0.1120, 0.0620, 0.0456, 0.0970, 0.0421, 0.0333,
        0.1110, 0.0395, 0.0692], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,633][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2562, 0.0227, 0.0864, 0.0174, 0.1565, 0.0527, 0.0132, 0.0241, 0.1121,
        0.0175, 0.1120, 0.1091, 0.0199], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,633][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([8.0815e-04, 2.6693e-03, 1.3718e-03, 2.9472e-03, 2.0885e-04, 9.5592e-05,
        9.1471e-03, 3.0419e-02, 4.7715e-04, 5.9979e-04, 7.2708e-04, 2.2080e-04,
        9.5031e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,633][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1285, 0.0702, 0.0387, 0.0986, 0.0296, 0.0713, 0.1644, 0.0225, 0.0233,
        0.1975, 0.0393, 0.0952, 0.0208], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,634][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([7.1798e-03, 1.0022e-03, 3.9365e-04, 9.2096e-04, 3.2544e-04, 2.0897e-03,
        4.1377e-03, 1.7339e-02, 7.8428e-03, 2.7320e-02, 3.3567e-02, 1.3687e-01,
        7.6102e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,636][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0348, 0.0049, 0.0093, 0.0058, 0.0120, 0.0608, 0.0155, 0.0167, 0.0308,
        0.0210, 0.0824, 0.5227, 0.1834], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,637][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0309, 0.0942, 0.0063, 0.0771, 0.0011, 0.0098, 0.0841, 0.2041, 0.0182,
        0.0291, 0.0018, 0.0070, 0.4363], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,638][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1586, 0.0041, 0.1410, 0.0038, 0.1794, 0.0637, 0.0080, 0.0031, 0.1282,
        0.0030, 0.2207, 0.0808, 0.0055], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,640][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0235, 0.0061, 0.0052, 0.0111, 0.0140, 0.0208, 0.0206, 0.0350, 0.0374,
        0.1882, 0.1065, 0.2668, 0.2650], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,641][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0101, 0.0524, 0.0038, 0.0887, 0.0048, 0.0220, 0.0930, 0.2233, 0.0180,
        0.1197, 0.0063, 0.0274, 0.3306], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,643][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1410, 0.0891, 0.0549, 0.0953, 0.0440, 0.0507, 0.0968, 0.0830, 0.0553,
        0.0827, 0.0534, 0.0691, 0.0847], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,644][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1108, 0.0917, 0.0599, 0.0994, 0.0290, 0.0361, 0.0981, 0.1077, 0.0487,
        0.0673, 0.0466, 0.0405, 0.1641], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,646][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1939, 0.0758, 0.0606, 0.0721, 0.0876, 0.0569, 0.0806, 0.0431, 0.0402,
        0.0902, 0.0630, 0.0784, 0.0578], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,647][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.0936, 0.0520, 0.0629, 0.0378, 0.1164, 0.0432, 0.0284, 0.0408, 0.2059,
        0.0313, 0.0619, 0.0561, 0.0332, 0.1363], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,648][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([8.3081e-05, 1.4525e-04, 3.7304e-04, 2.3564e-04, 1.0049e-03, 2.5856e-04,
        3.7986e-05, 1.3760e-04, 6.5413e-04, 3.7042e-06, 1.8041e-04, 1.1393e-04,
        1.1909e-05, 9.9676e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,650][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.1342, 0.0578, 0.0629, 0.0968, 0.0428, 0.0422, 0.1046, 0.0708, 0.0973,
        0.0581, 0.0537, 0.0634, 0.0710, 0.0443], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,651][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([8.3602e-04, 4.4986e-06, 4.7199e-06, 5.3906e-06, 2.5993e-05, 1.0345e-04,
        3.8363e-05, 1.2582e-04, 1.1784e-03, 2.0782e-04, 6.2063e-04, 3.0944e-03,
        3.3560e-03, 9.9040e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,652][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0365, 0.0039, 0.0086, 0.0033, 0.0188, 0.0201, 0.0037, 0.0095, 0.0426,
        0.0138, 0.0445, 0.0318, 0.0305, 0.7324], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,653][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([2.7211e-03, 8.2096e-06, 5.4935e-05, 2.5764e-06, 3.5809e-05, 1.1708e-05,
        3.8496e-07, 9.9196e-07, 9.3944e-05, 1.7800e-07, 9.4457e-06, 3.4140e-07,
        6.9792e-07, 9.9706e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,654][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.1083, 0.0433, 0.1548, 0.0266, 0.1929, 0.0276, 0.0147, 0.0132, 0.1299,
        0.0313, 0.1425, 0.0250, 0.0153, 0.0746], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,656][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.0399, 0.0217, 0.0040, 0.0214, 0.0135, 0.0194, 0.0376, 0.0450, 0.0195,
        0.1349, 0.0471, 0.2446, 0.2763, 0.0752], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,657][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.1506, 0.0862, 0.0253, 0.1034, 0.0479, 0.0562, 0.0864, 0.0709, 0.0158,
        0.0784, 0.0244, 0.0690, 0.1091, 0.0765], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,659][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.1079, 0.0842, 0.0785, 0.0788, 0.0985, 0.0447, 0.0760, 0.0704, 0.0787,
        0.0720, 0.0762, 0.0509, 0.0785, 0.0047], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,660][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.0958, 0.0696, 0.0317, 0.0709, 0.0617, 0.0558, 0.0748, 0.0613, 0.0586,
        0.0559, 0.0275, 0.0348, 0.0590, 0.2425], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,662][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([0.1591, 0.0791, 0.0646, 0.0557, 0.0779, 0.0667, 0.0583, 0.0294, 0.0672,
        0.0540, 0.0649, 0.0886, 0.0422, 0.0924], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,663][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2338, 0.0227, 0.0317, 0.0190, 0.1145, 0.1210, 0.0108, 0.0266, 0.0520,
        0.0180, 0.0404, 0.1296, 0.0271, 0.1380, 0.0150], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,664][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.3318e-03, 6.6646e-03, 6.6938e-05, 1.9416e-02, 2.1098e-05, 2.4622e-04,
        4.5088e-01, 1.0429e-03, 4.7417e-05, 4.1259e-03, 3.3110e-05, 3.8134e-04,
        6.5953e-04, 1.0639e-05, 5.1407e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,666][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1297, 0.0570, 0.0274, 0.0782, 0.0184, 0.0439, 0.1213, 0.0226, 0.0248,
        0.2172, 0.0257, 0.0578, 0.0205, 0.0154, 0.1400], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,667][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.5111e-03, 2.2669e-04, 3.8276e-05, 1.5534e-04, 2.9015e-05, 2.6029e-03,
        1.8415e-03, 2.4849e-03, 1.0165e-03, 4.0759e-03, 2.1219e-03, 2.2916e-01,
        6.7670e-02, 1.2292e-01, 5.6315e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,668][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0337, 0.0022, 0.0042, 0.0036, 0.0037, 0.0710, 0.0131, 0.0080, 0.0179,
        0.0131, 0.0368, 0.3828, 0.0880, 0.0610, 0.2610], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,669][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.6365e-02, 3.7246e-02, 9.2120e-04, 4.7687e-02, 7.8464e-04, 7.7860e-03,
        3.6341e-01, 1.3185e-01, 6.9851e-03, 1.6711e-02, 2.4146e-04, 4.0850e-03,
        9.8190e-02, 2.2914e-03, 2.5545e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,671][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1115, 0.0054, 0.0415, 0.0046, 0.0730, 0.0357, 0.1654, 0.0032, 0.0775,
        0.0052, 0.0641, 0.0555, 0.0058, 0.0555, 0.2959], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,672][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0239, 0.0045, 0.0041, 0.0074, 0.0074, 0.0135, 0.0088, 0.0204, 0.0181,
        0.0933, 0.0600, 0.1312, 0.1734, 0.1381, 0.2959], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,674][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0070, 0.0518, 0.0026, 0.0903, 0.0042, 0.0184, 0.1158, 0.1525, 0.0161,
        0.1194, 0.0037, 0.0181, 0.1785, 0.0152, 0.2065], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,675][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1179, 0.0731, 0.0482, 0.0804, 0.0430, 0.0450, 0.0805, 0.0721, 0.0457,
        0.0724, 0.0479, 0.0624, 0.0777, 0.0365, 0.0972], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,677][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0966, 0.0794, 0.0385, 0.0950, 0.0304, 0.0614, 0.1099, 0.0770, 0.0380,
        0.0756, 0.0315, 0.0573, 0.0788, 0.0231, 0.1074], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,678][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1757, 0.0694, 0.0538, 0.0713, 0.0744, 0.0572, 0.0705, 0.0338, 0.0326,
        0.0764, 0.0533, 0.0762, 0.0444, 0.0393, 0.0717], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,680][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:48,681][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[29545],
        [26044],
        [23380],
        [29884],
        [    1],
        [20542],
        [27990],
        [42300],
        [44803],
        [20946],
        [23390],
        [ 9327],
        [41604],
        [22992],
        [34585]], device='cuda:0')
[2024-07-24 10:21:48,683][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[34830],
        [34000],
        [  129],
        [20124],
        [    1],
        [18268],
        [19344],
        [ 7673],
        [13542],
        [18374],
        [   96],
        [16356],
        [ 6432],
        [19004],
        [11117]], device='cuda:0')
[2024-07-24 10:21:48,684][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 2887],
        [ 3027],
        [10027],
        [ 4358],
        [12261],
        [ 2360],
        [ 2759],
        [ 4509],
        [13852],
        [ 3115],
        [20119],
        [ 1994],
        [ 5972],
        [13576],
        [ 3719]], device='cuda:0')
[2024-07-24 10:21:48,685][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 5826],
        [12057],
        [42034],
        [ 9720],
        [31737],
        [31565],
        [18503],
        [48954],
        [37477],
        [ 6139],
        [41042],
        [33158],
        [48155],
        [33490],
        [17665]], device='cuda:0')
[2024-07-24 10:21:48,687][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 4020],
        [ 5991],
        [ 7980],
        [30099],
        [ 9895],
        [12904],
        [12956],
        [11089],
        [ 9074],
        [ 9507],
        [10949],
        [ 8827],
        [11902],
        [11180],
        [10737]], device='cuda:0')
[2024-07-24 10:21:48,688][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[40495],
        [42067],
        [ 5974],
        [40068],
        [ 4662],
        [21315],
        [33114],
        [28995],
        [14100],
        [36494],
        [ 6776],
        [21623],
        [20940],
        [18916],
        [35248]], device='cuda:0')
[2024-07-24 10:21:48,690][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 4537],
        [ 4352],
        [13931],
        [ 3322],
        [ 1129],
        [ 3980],
        [ 4878],
        [ 2986],
        [22073],
        [ 3983],
        [15543],
        [17892],
        [14479],
        [22335],
        [11587]], device='cuda:0')
[2024-07-24 10:21:48,690][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[19613],
        [29653],
        [36016],
        [35351],
        [ 2825],
        [38768],
        [35551],
        [26278],
        [42494],
        [30863],
        [36507],
        [35775],
        [27311],
        [38109],
        [33189]], device='cuda:0')
[2024-07-24 10:21:48,691][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[23345],
        [23918],
        [29557],
        [ 8655],
        [12274],
        [  162],
        [10646],
        [   76],
        [  113],
        [  217],
        [ 6438],
        [  369],
        [  320],
        [  717],
        [16548]], device='cuda:0')
[2024-07-24 10:21:48,693][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[38884],
        [38523],
        [33499],
        [32680],
        [39392],
        [21488],
        [19422],
        [28589],
        [35829],
        [38776],
        [33359],
        [29702],
        [42082],
        [45022],
        [42707]], device='cuda:0')
[2024-07-24 10:21:48,694][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[41835],
        [37812],
        [41538],
        [30927],
        [40089],
        [39116],
        [34522],
        [34467],
        [42634],
        [28515],
        [39512],
        [39840],
        [37696],
        [45675],
        [36078]], device='cuda:0')
[2024-07-24 10:21:48,695][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[41965],
        [44764],
        [44178],
        [43222],
        [41696],
        [38273],
        [41072],
        [39724],
        [36437],
        [39501],
        [39540],
        [36064],
        [37830],
        [29795],
        [37741]], device='cuda:0')
[2024-07-24 10:21:48,697][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[13094],
        [17455],
        [46151],
        [20947],
        [45295],
        [18859],
        [21417],
        [34394],
        [24736],
        [24555],
        [49570],
        [28661],
        [42917],
        [35030],
        [31031]], device='cuda:0')
[2024-07-24 10:21:48,698][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[18238],
        [28995],
        [39941],
        [39087],
        [45669],
        [43670],
        [45232],
        [48229],
        [44832],
        [47105],
        [47653],
        [46924],
        [48242],
        [47402],
        [47844]], device='cuda:0')
[2024-07-24 10:21:48,699][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 9814],
        [ 1369],
        [10777],
        [ 2595],
        [    1],
        [24730],
        [14105],
        [38353],
        [41325],
        [ 7613],
        [12076],
        [ 7604],
        [26710],
        [13206],
        [15841]], device='cuda:0')
[2024-07-24 10:21:48,701][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[6108],
        [5846],
        [5170],
        [5573],
        [6100],
        [5573],
        [5563],
        [5986],
        [9703],
        [5823],
        [6437],
        [6241],
        [7988],
        [9635],
        [6877]], device='cuda:0')
[2024-07-24 10:21:48,702][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[38842],
        [20070],
        [ 9826],
        [14870],
        [ 8036],
        [10782],
        [15801],
        [14084],
        [22055],
        [31807],
        [10929],
        [11236],
        [12300],
        [26129],
        [16104]], device='cuda:0')
[2024-07-24 10:21:48,704][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[27070],
        [27183],
        [15777],
        [36489],
        [17890],
        [24337],
        [14954],
        [12817],
        [10185],
        [20830],
        [ 5780],
        [13940],
        [10643],
        [ 9518],
        [ 7391]], device='cuda:0')
[2024-07-24 10:21:48,705][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[22179],
        [25219],
        [36543],
        [15652],
        [21144],
        [26683],
        [17033],
        [16776],
        [31509],
        [16253],
        [29939],
        [21682],
        [19125],
        [35546],
        [17735]], device='cuda:0')
[2024-07-24 10:21:48,706][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[31121],
        [31303],
        [37480],
        [33698],
        [20191],
        [44678],
        [45271],
        [38030],
        [39677],
        [32073],
        [34738],
        [42084],
        [42268],
        [42582],
        [41466]], device='cuda:0')
[2024-07-24 10:21:48,708][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[44003],
        [30011],
        [19296],
        [17957],
        [26776],
        [16509],
        [16757],
        [20962],
        [12870],
        [21816],
        [18565],
        [11666],
        [17774],
        [ 9380],
        [15563]], device='cuda:0')
[2024-07-24 10:21:48,709][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[27633],
        [27281],
        [25847],
        [18347],
        [ 8080],
        [ 3535],
        [13550],
        [ 4337],
        [ 4164],
        [ 4671],
        [ 9022],
        [ 7770],
        [ 8447],
        [ 7128],
        [25783]], device='cuda:0')
[2024-07-24 10:21:48,711][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[3639],
        [4092],
        [4842],
        [2058],
        [1949],
        [1490],
        [ 787],
        [1175],
        [1174],
        [4242],
        [5018],
        [6293],
        [2842],
        [2249],
        [1263]], device='cuda:0')
[2024-07-24 10:21:48,712][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[38759],
        [10672],
        [21468],
        [ 8306],
        [14115],
        [10748],
        [ 9480],
        [ 7913],
        [12516],
        [ 6720],
        [ 8586],
        [ 9795],
        [ 8184],
        [ 8760],
        [ 8769]], device='cuda:0')
[2024-07-24 10:21:48,714][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[5436],
        [3951],
        [3660],
        [4478],
        [4245],
        [3833],
        [4497],
        [5792],
        [5226],
        [4215],
        [4344],
        [3900],
        [5338],
        [4802],
        [4766]], device='cuda:0')
[2024-07-24 10:21:48,715][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[17546],
        [25597],
        [16532],
        [27833],
        [19770],
        [25018],
        [30008],
        [26582],
        [22369],
        [27164],
        [14030],
        [24394],
        [24480],
        [19913],
        [28051]], device='cuda:0')
[2024-07-24 10:21:48,717][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[45746],
        [36104],
        [14161],
        [ 5596],
        [ 8417],
        [10763],
        [10769],
        [11411],
        [14701],
        [ 8361],
        [14448],
        [ 7096],
        [ 9872],
        [11093],
        [ 9275]], device='cuda:0')
[2024-07-24 10:21:48,718][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[26006],
        [31929],
        [36649],
        [36543],
        [39808],
        [40133],
        [39801],
        [42669],
        [38632],
        [40032],
        [42328],
        [40058],
        [40914],
        [39088],
        [40383]], device='cuda:0')
[2024-07-24 10:21:48,719][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[37705],
        [47684],
        [36471],
        [46282],
        [50257],
        [23639],
        [33732],
        [10361],
        [ 9673],
        [40468],
        [35420],
        [39904],
        [21772],
        [34552],
        [32113]], device='cuda:0')
[2024-07-24 10:21:48,721][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[46060],
        [46060],
        [46060],
        [46060],
        [46060],
        [46060],
        [46060],
        [46060],
        [46060],
        [46060],
        [46060],
        [46060],
        [46060],
        [46060],
        [46060]], device='cuda:0')
[2024-07-24 10:21:48,746][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:48,748][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,749][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,750][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,751][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,752][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,754][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,755][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,755][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,756][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,756][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,756][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,756][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,757][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0275, 0.9725], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,757][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9031, 0.0969], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,757][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.5279, 0.4721], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,758][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4128, 0.5872], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,758][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([2.5485e-04, 9.9975e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,760][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3364, 0.6636], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,761][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9682, 0.0318], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,762][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9527, 0.0473], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,764][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9483, 0.0517], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,765][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0014, 0.9986], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,766][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0345, 0.9655], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,767][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4129, 0.5871], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,769][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.3320, 0.6433, 0.0248], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,770][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.4165, 0.5724, 0.0111], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,772][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.3394, 0.3486, 0.3120], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,773][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.3045, 0.4349, 0.2605], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,774][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.0560, 0.8942, 0.0498], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,775][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.2967, 0.5831, 0.1203], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,777][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.1228, 0.0049, 0.8723], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,778][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.5373, 0.1801, 0.2826], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,780][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.7210, 0.2550, 0.0241], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,781][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([5.5467e-04, 3.0518e-01, 6.9427e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,782][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.0394, 0.4739, 0.4867], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,783][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.0288, 0.0249, 0.9463], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:48,785][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0723, 0.4890, 0.0244, 0.4143], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,786][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.8391, 0.1098, 0.0141, 0.0369], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,787][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1960, 0.1963, 0.2048, 0.4030], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,789][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2049, 0.2848, 0.1760, 0.3344], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,790][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0059, 0.7347, 0.0214, 0.2381], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,791][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0801, 0.1133, 0.0052, 0.8015], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,793][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.7104, 0.0927, 0.1520, 0.0450], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,794][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3980, 0.0835, 0.2059, 0.3126], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,796][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.8001, 0.0656, 0.0493, 0.0850], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,796][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([1.9724e-05, 2.3597e-02, 6.0014e-01, 3.7624e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,798][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0277, 0.3171, 0.4125, 0.2427], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,799][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1672, 0.4537, 0.0041, 0.3750], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:48,801][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.3696, 0.2804, 0.0196, 0.3266, 0.0038], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,802][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0880, 0.2692, 0.0092, 0.6236, 0.0101], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,803][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.1461, 0.1577, 0.1520, 0.3247, 0.2195], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,805][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.1694, 0.2400, 0.1448, 0.2840, 0.1617], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,806][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.1838, 0.5286, 0.0254, 0.2382, 0.0239], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,807][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0419, 0.1675, 0.0219, 0.7177, 0.0510], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,809][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.1976, 0.0184, 0.1720, 0.0090, 0.6030], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,810][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.1828, 0.0828, 0.3646, 0.2695, 0.1003], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,812][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.5523, 0.3100, 0.0217, 0.0996, 0.0165], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,813][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([1.6883e-04, 1.1444e-01, 2.8506e-01, 5.9836e-01, 1.9687e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,813][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.0234, 0.2362, 0.2521, 0.1819, 0.3065], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,813][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.0039, 0.0055, 0.0077, 0.0010, 0.9820], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:48,814][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0351, 0.4802, 0.0133, 0.4022, 0.0029, 0.0664], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,814][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.4687, 0.2322, 0.0103, 0.2508, 0.0176, 0.0204], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,815][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0957, 0.1275, 0.1316, 0.2459, 0.1790, 0.2202], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,815][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.1502, 0.2104, 0.1261, 0.2482, 0.1402, 0.1249], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,815][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0031, 0.3664, 0.0142, 0.1455, 0.0026, 0.4681], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,816][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0880, 0.1243, 0.0085, 0.6002, 0.0214, 0.1576], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,816][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.4720, 0.0687, 0.0212, 0.0188, 0.4136, 0.0057], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,817][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.3102, 0.1595, 0.1525, 0.1656, 0.1543, 0.0579], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,819][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.6572, 0.1172, 0.0309, 0.0796, 0.0339, 0.0813], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,819][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ went] are: tensor([2.2478e-04, 1.4544e-01, 5.8894e-01, 2.6114e-01, 3.1162e-03, 1.1344e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,821][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0138, 0.1777, 0.2032, 0.1196, 0.2452, 0.2405], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,822][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ went] are: tensor([3.8099e-03, 3.2433e-02, 7.8500e-04, 1.8321e-02, 8.0257e-04, 9.4385e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:48,823][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0696, 0.3996, 0.0150, 0.3588, 0.0032, 0.0898, 0.0640],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,824][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.7455, 0.1037, 0.0098, 0.0762, 0.0219, 0.0206, 0.0223],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,826][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0977, 0.1009, 0.1103, 0.1804, 0.1380, 0.1579, 0.2148],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,827][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1226, 0.1691, 0.1051, 0.1988, 0.1169, 0.1024, 0.1851],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,828][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0016, 0.2162, 0.0075, 0.0680, 0.0014, 0.2569, 0.4485],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,830][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0977, 0.0898, 0.0082, 0.5954, 0.0312, 0.0511, 0.1265],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,831][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2913, 0.0822, 0.0852, 0.0336, 0.4909, 0.0113, 0.0055],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,832][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.2417, 0.0863, 0.0922, 0.1498, 0.1099, 0.0484, 0.2716],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,834][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.5875, 0.0895, 0.0510, 0.0647, 0.0364, 0.0503, 0.1207],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,835][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([6.4675e-05, 1.0038e-01, 5.7562e-01, 3.1492e-01, 3.2742e-03, 2.1216e-03,
        3.6251e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,836][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0126, 0.1478, 0.1908, 0.1009, 0.2335, 0.2195, 0.0950],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,838][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.2360, 0.3838, 0.0074, 0.1533, 0.0153, 0.0123, 0.1921],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:48,839][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0750, 0.4072, 0.0134, 0.3478, 0.0026, 0.0608, 0.0646, 0.0286],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,840][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.7591, 0.1066, 0.0072, 0.0634, 0.0194, 0.0136, 0.0222, 0.0086],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,842][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0794, 0.0826, 0.0906, 0.1489, 0.1138, 0.1308, 0.1767, 0.1771],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,843][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1048, 0.1435, 0.0887, 0.1679, 0.0986, 0.0864, 0.1564, 0.1537],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,845][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0014, 0.1714, 0.0058, 0.0523, 0.0011, 0.1834, 0.3046, 0.2800],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,846][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0502, 0.0680, 0.0061, 0.3421, 0.0079, 0.0215, 0.0157, 0.4887],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,847][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2092, 0.0157, 0.1572, 0.0055, 0.6032, 0.0027, 0.0023, 0.0041],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,849][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1836, 0.0422, 0.1023, 0.1065, 0.1081, 0.0702, 0.1497, 0.2375],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,850][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.4589, 0.0738, 0.0445, 0.0613, 0.0331, 0.0386, 0.1156, 0.1742],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,851][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ the] are: tensor([6.6681e-06, 1.3734e-02, 8.1587e-01, 1.4019e-01, 2.6846e-03, 1.0703e-03,
        1.0463e-03, 2.5393e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,853][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0145, 0.1302, 0.1732, 0.0970, 0.2136, 0.1889, 0.0797, 0.1028],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,854][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0186, 0.0655, 0.0292, 0.0168, 0.0610, 0.0433, 0.0186, 0.7471],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:48,855][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ house] are: tensor([0.0272, 0.4211, 0.0188, 0.3358, 0.0032, 0.0621, 0.0707, 0.0395, 0.0216],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,857][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ house] are: tensor([0.2094, 0.1350, 0.0210, 0.1668, 0.0505, 0.0584, 0.1355, 0.1741, 0.0493],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,858][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.0516, 0.0689, 0.0728, 0.1320, 0.0993, 0.1206, 0.1695, 0.1667, 0.1186],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,860][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ house] are: tensor([0.0973, 0.1355, 0.0800, 0.1595, 0.0887, 0.0795, 0.1491, 0.1449, 0.0654],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,861][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ house] are: tensor([0.0008, 0.0944, 0.0061, 0.0479, 0.0013, 0.1624, 0.2556, 0.2108, 0.2207],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,863][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ house] are: tensor([0.0191, 0.0579, 0.0019, 0.2575, 0.0095, 0.0240, 0.0068, 0.6099, 0.0133],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,864][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ house] are: tensor([0.0401, 0.0050, 0.0983, 0.0045, 0.7401, 0.0035, 0.0022, 0.0017, 0.1047],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,866][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ house] are: tensor([0.2415, 0.0532, 0.1582, 0.0843, 0.0918, 0.1056, 0.1211, 0.1373, 0.0070],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,867][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.3264, 0.0925, 0.0348, 0.0528, 0.0368, 0.0902, 0.0975, 0.2112, 0.0578],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,868][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ house] are: tensor([6.2409e-05, 4.0067e-02, 6.5160e-01, 2.5501e-01, 3.0776e-03, 1.4462e-03,
        2.6977e-03, 4.5684e-02, 3.5192e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,869][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.0110, 0.1270, 0.1520, 0.0936, 0.1844, 0.1684, 0.0698, 0.0765, 0.1173],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,870][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ house] are: tensor([3.3883e-03, 2.4406e-02, 4.4918e-04, 2.6221e-02, 7.5365e-04, 1.1563e-02,
        1.8949e-02, 4.5501e-03, 9.0972e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:48,871][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.1281, 0.3594, 0.0100, 0.3476, 0.0022, 0.0538, 0.0519, 0.0250, 0.0201,
        0.0021], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,871][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.5918, 0.1135, 0.0113, 0.0756, 0.0259, 0.0147, 0.0290, 0.0246, 0.0187,
        0.0949], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,872][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0499, 0.0593, 0.0670, 0.1082, 0.0857, 0.1008, 0.1344, 0.1333, 0.0985,
        0.1629], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,872][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0880, 0.1201, 0.0735, 0.1401, 0.0818, 0.0717, 0.1305, 0.1285, 0.0597,
        0.1061], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,872][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0051, 0.1507, 0.0038, 0.0352, 0.0010, 0.1190, 0.1908, 0.2187, 0.2434,
        0.0323], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,873][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0397, 0.0520, 0.0046, 0.2135, 0.0087, 0.0160, 0.0182, 0.3717, 0.0134,
        0.2622], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,873][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0655, 0.0185, 0.0492, 0.0112, 0.3716, 0.0069, 0.0067, 0.0081, 0.4381,
        0.0243], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,875][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.1354, 0.0256, 0.1300, 0.1118, 0.1680, 0.0578, 0.1453, 0.1053, 0.0445,
        0.0764], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,876][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.4281, 0.0666, 0.0471, 0.0421, 0.0379, 0.0444, 0.0655, 0.1082, 0.0620,
        0.0981], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,877][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [.] are: tensor([1.0802e-05, 2.7637e-02, 6.5965e-01, 2.3239e-01, 3.1035e-03, 1.8853e-03,
        1.8747e-03, 4.8169e-02, 2.4001e-04, 2.5033e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,878][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0108, 0.1147, 0.1442, 0.0837, 0.1729, 0.1686, 0.0704, 0.0698, 0.1170,
        0.0479], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,880][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0830, 0.1833, 0.0186, 0.0837, 0.0258, 0.0260, 0.0489, 0.0782, 0.2671,
        0.1855], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:48,881][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([2.4655e-01, 3.5730e-01, 1.0557e-02, 2.5927e-01, 2.8793e-03, 3.9452e-02,
        4.4116e-02, 2.3603e-02, 1.2524e-02, 3.3977e-03, 3.4872e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,882][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.0746, 0.1371, 0.0034, 0.1905, 0.0132, 0.0162, 0.0821, 0.0858, 0.0179,
        0.3758, 0.0034], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,883][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.0397, 0.0528, 0.0556, 0.0993, 0.0737, 0.0885, 0.1228, 0.1216, 0.0868,
        0.1485, 0.1107], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,885][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.0810, 0.1123, 0.0672, 0.1317, 0.0748, 0.0669, 0.1236, 0.1210, 0.0557,
        0.1003, 0.0655], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,886][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.1257, 0.1017, 0.0061, 0.0400, 0.0081, 0.0731, 0.1374, 0.2430, 0.1369,
        0.1098, 0.0182], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,888][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.0108, 0.0228, 0.0051, 0.1446, 0.0258, 0.0132, 0.0078, 0.4642, 0.0024,
        0.2999, 0.0035], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,889][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.0230, 0.0141, 0.1752, 0.0152, 0.1635, 0.0304, 0.0521, 0.0362, 0.0567,
        0.3500, 0.0835], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,891][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.0823, 0.0523, 0.0639, 0.0759, 0.1123, 0.0604, 0.0936, 0.1845, 0.0698,
        0.1670, 0.0381], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,892][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.2073, 0.2007, 0.0078, 0.0400, 0.0066, 0.0506, 0.0852, 0.1585, 0.0139,
        0.2190, 0.0105], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,893][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([5.1703e-05, 4.8010e-02, 6.0391e-01, 2.3319e-01, 3.0070e-03, 1.1272e-03,
        3.6317e-03, 4.7274e-02, 3.9534e-04, 3.6221e-02, 2.3183e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,895][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.0126, 0.1041, 0.1168, 0.0818, 0.1388, 0.1451, 0.0694, 0.0720, 0.1040,
        0.0473, 0.1082], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,895][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([6.8320e-05, 3.8404e-04, 9.9017e-02, 6.9164e-05, 1.5867e-02, 4.7224e-04,
        3.0591e-04, 1.7201e-03, 9.0669e-04, 6.0918e-03, 8.7510e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:48,896][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([1.0607e-01, 3.9462e-01, 1.1801e-02, 3.2469e-01, 3.1263e-03, 5.3487e-02,
        4.7871e-02, 3.0900e-02, 2.0954e-02, 3.9208e-03, 3.0861e-04, 2.2509e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,898][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.1031, 0.1544, 0.0063, 0.2196, 0.0115, 0.0127, 0.0730, 0.0745, 0.0235,
        0.3129, 0.0054, 0.0030], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,899][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0312, 0.0459, 0.0502, 0.0843, 0.0670, 0.0801, 0.1085, 0.1052, 0.0787,
        0.1314, 0.1002, 0.1174], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,901][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0757, 0.1052, 0.0631, 0.1239, 0.0702, 0.0627, 0.1164, 0.1138, 0.0519,
        0.0938, 0.0612, 0.0621], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,902][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0106, 0.1387, 0.0043, 0.0439, 0.0019, 0.1104, 0.1938, 0.2373, 0.1813,
        0.0528, 0.0021, 0.0229], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,904][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0250, 0.0393, 0.0046, 0.1699, 0.0083, 0.0378, 0.0095, 0.3118, 0.0046,
        0.3648, 0.0031, 0.0213], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,905][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1791, 0.2789, 0.0046, 0.0644, 0.1747, 0.0205, 0.0095, 0.0372, 0.0299,
        0.1723, 0.0137, 0.0154], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,907][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1334, 0.0734, 0.0587, 0.0912, 0.0927, 0.0320, 0.1195, 0.0955, 0.0767,
        0.1825, 0.0264, 0.0180], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,908][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.3705, 0.0786, 0.0180, 0.0471, 0.0169, 0.0648, 0.0662, 0.1300, 0.0334,
        0.1106, 0.0202, 0.0438], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,909][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([8.2566e-06, 1.3077e-02, 8.6508e-01, 7.1056e-02, 2.4038e-03, 4.2518e-04,
        5.9223e-04, 1.2499e-02, 1.1366e-04, 6.5346e-03, 2.8093e-02, 1.1600e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,911][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0079, 0.0927, 0.1090, 0.0648, 0.1300, 0.1402, 0.0604, 0.0554, 0.0883,
        0.0382, 0.0997, 0.1133], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,912][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([3.7242e-04, 1.0035e-02, 2.7435e-04, 5.0605e-03, 1.1049e-03, 3.1369e-02,
        6.8448e-03, 4.3193e-03, 2.7062e-03, 6.3523e-02, 3.4203e-04, 8.7405e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:48,913][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([1.3655e-01, 3.7372e-01, 1.2311e-02, 3.1823e-01, 2.9938e-03, 5.0742e-02,
        5.2106e-02, 2.6895e-02, 1.8950e-02, 3.1732e-03, 3.7140e-04, 2.7458e-03,
        1.2131e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,914][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.5093, 0.1325, 0.0079, 0.0947, 0.0166, 0.0141, 0.0303, 0.0216, 0.0247,
        0.1291, 0.0042, 0.0058, 0.0093], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,916][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0335, 0.0422, 0.0479, 0.0741, 0.0608, 0.0691, 0.0921, 0.0906, 0.0686,
        0.1109, 0.0869, 0.1013, 0.1220], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,917][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0707, 0.0968, 0.0592, 0.1135, 0.0659, 0.0581, 0.1061, 0.1042, 0.0485,
        0.0863, 0.0578, 0.0578, 0.0752], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,918][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0209, 0.1161, 0.0045, 0.0424, 0.0029, 0.0936, 0.1727, 0.2372, 0.1513,
        0.0743, 0.0046, 0.0358, 0.0438], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,920][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0235, 0.0403, 0.0048, 0.2341, 0.0058, 0.0140, 0.0102, 0.3089, 0.0058,
        0.2214, 0.0031, 0.0098, 0.1182], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,921][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1363, 0.0648, 0.0520, 0.0109, 0.5959, 0.0050, 0.0041, 0.0108, 0.0195,
        0.0387, 0.0566, 0.0029, 0.0026], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,923][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1112, 0.0502, 0.0546, 0.0760, 0.0824, 0.0359, 0.1158, 0.1259, 0.0303,
        0.0966, 0.0176, 0.0296, 0.1740], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,924][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.3348, 0.0631, 0.0331, 0.0440, 0.0214, 0.0335, 0.0710, 0.0962, 0.0371,
        0.0962, 0.0331, 0.0273, 0.1091], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,925][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.5193e-06, 4.8525e-03, 8.7829e-01, 6.3693e-02, 2.0490e-03, 4.6984e-04,
        4.0484e-04, 1.0115e-02, 1.1104e-04, 5.4715e-03, 3.0697e-02, 1.2912e-04,
        3.7139e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,927][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0087, 0.0773, 0.1045, 0.0601, 0.1322, 0.1178, 0.0495, 0.0576, 0.0947,
        0.0347, 0.0985, 0.1091, 0.0554], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,928][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0040, 0.0104, 0.0060, 0.0017, 0.0286, 0.0281, 0.0040, 0.0397, 0.0729,
        0.0272, 0.0268, 0.0315, 0.7193], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:48,928][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([2.3718e-01, 3.6017e-01, 9.5410e-03, 2.6966e-01, 1.8844e-03, 4.2570e-02,
        3.6877e-02, 2.0963e-02, 1.4375e-02, 3.1881e-03, 3.2250e-04, 1.8677e-03,
        1.1111e-03, 2.9368e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,928][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0520, 0.0805, 0.0094, 0.1209, 0.0163, 0.0289, 0.0901, 0.1170, 0.0244,
        0.3379, 0.0074, 0.0128, 0.0961, 0.0060], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,929][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.0240, 0.0368, 0.0409, 0.0664, 0.0536, 0.0617, 0.0848, 0.0822, 0.0622,
        0.1027, 0.0800, 0.0936, 0.1123, 0.0988], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,929][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.0682, 0.0945, 0.0555, 0.1108, 0.0615, 0.0555, 0.1037, 0.1009, 0.0458,
        0.0840, 0.0538, 0.0551, 0.0719, 0.0390], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,930][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0901, 0.0994, 0.0048, 0.0348, 0.0048, 0.0689, 0.1313, 0.2217, 0.1403,
        0.0791, 0.0108, 0.0402, 0.0593, 0.0144], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,930][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.0188, 0.0343, 0.0012, 0.1916, 0.0049, 0.0292, 0.0059, 0.3150, 0.0045,
        0.2938, 0.0006, 0.0067, 0.0907, 0.0029], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,931][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.0479, 0.0155, 0.0452, 0.0198, 0.3352, 0.0280, 0.0082, 0.0065, 0.1661,
        0.0305, 0.0303, 0.0399, 0.0148, 0.2123], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,932][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0540, 0.0424, 0.0904, 0.0679, 0.0475, 0.0597, 0.0584, 0.1371, 0.0552,
        0.1559, 0.0332, 0.0528, 0.1398, 0.0057], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,933][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.2069, 0.0514, 0.0205, 0.0511, 0.0236, 0.0705, 0.0508, 0.1914, 0.0364,
        0.0667, 0.0262, 0.0396, 0.1245, 0.0403], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,934][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([1.6422e-06, 4.5656e-03, 9.1350e-01, 4.5864e-02, 1.5312e-03, 4.4184e-04,
        2.8601e-04, 6.3905e-03, 1.1171e-04, 3.7714e-03, 2.0055e-02, 1.2554e-04,
        2.3857e-03, 9.6953e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,936][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.0068, 0.0835, 0.0971, 0.0654, 0.1179, 0.1076, 0.0553, 0.0492, 0.0805,
        0.0367, 0.0883, 0.0998, 0.0490, 0.0628], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,937][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([7.5236e-04, 2.6539e-02, 4.7331e-04, 1.5878e-02, 1.6959e-03, 3.3249e-02,
        2.4319e-02, 4.7741e-03, 1.7840e-02, 5.8832e-02, 2.2512e-04, 8.5798e-03,
        1.2062e-02, 7.9478e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:48,937][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([2.0930e-01, 3.2410e-01, 1.1299e-02, 2.9830e-01, 2.8364e-03, 5.8409e-02,
        4.3515e-02, 2.5161e-02, 1.8313e-02, 3.2478e-03, 3.4092e-04, 2.9125e-03,
        1.2845e-03, 3.0132e-04, 6.8695e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,939][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.5024, 0.1170, 0.0083, 0.0860, 0.0212, 0.0184, 0.0207, 0.0253, 0.0256,
        0.1208, 0.0037, 0.0063, 0.0213, 0.0094, 0.0136], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,940][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0273, 0.0348, 0.0407, 0.0595, 0.0508, 0.0564, 0.0733, 0.0715, 0.0548,
        0.0875, 0.0688, 0.0818, 0.0950, 0.0840, 0.1136], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,942][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0625, 0.0854, 0.0525, 0.1001, 0.0584, 0.0513, 0.0930, 0.0921, 0.0430,
        0.0764, 0.0515, 0.0512, 0.0668, 0.0373, 0.0785], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,943][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0451, 0.1246, 0.0045, 0.0400, 0.0036, 0.0813, 0.1467, 0.2177, 0.1244,
        0.0737, 0.0060, 0.0362, 0.0456, 0.0096, 0.0408], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,945][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0350, 0.0309, 0.0027, 0.2234, 0.0113, 0.0172, 0.0380, 0.2742, 0.0070,
        0.2248, 0.0019, 0.0100, 0.0929, 0.0026, 0.0284], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,946][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2383, 0.2820, 0.0141, 0.0466, 0.1418, 0.0207, 0.0072, 0.0325, 0.0312,
        0.1178, 0.0203, 0.0096, 0.0072, 0.0247, 0.0060], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,948][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0780, 0.0449, 0.0467, 0.0666, 0.0576, 0.0240, 0.1012, 0.0756, 0.0210,
        0.0776, 0.0126, 0.0211, 0.1395, 0.1223, 0.1114], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,949][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3252, 0.0588, 0.0288, 0.0335, 0.0191, 0.0320, 0.0605, 0.0728, 0.0278,
        0.0877, 0.0255, 0.0265, 0.1053, 0.0465, 0.0498], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,950][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([7.1386e-07, 4.0340e-03, 9.1596e-01, 4.4256e-02, 1.7939e-03, 3.3153e-04,
        2.3460e-04, 6.0939e-03, 7.5327e-05, 3.2235e-03, 2.0481e-02, 8.7851e-05,
        2.2434e-03, 7.1934e-04, 4.6656e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,952][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0077, 0.0724, 0.0964, 0.0515, 0.1172, 0.1104, 0.0488, 0.0474, 0.0765,
        0.0310, 0.0898, 0.0962, 0.0451, 0.0653, 0.0443], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,953][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0552, 0.1642, 0.0066, 0.0478, 0.0174, 0.0149, 0.0863, 0.0653, 0.0419,
        0.2312, 0.0135, 0.0095, 0.0394, 0.0061, 0.2006], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:48,979][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:48,980][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,982][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,983][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,984][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,985][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,986][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,987][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,988][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,989][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,991][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,992][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,992][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:48,993][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5006, 0.4994], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,993][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2439, 0.7561], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,993][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6312, 0.3688], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,994][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5000, 0.5000], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,994][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5004, 0.4996], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,994][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7952, 0.2048], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,995][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9449, 0.0551], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,995][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9821, 0.0179], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,997][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8926, 0.1074], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,998][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0656, 0.9344], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:48,999][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2261, 0.7739], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,001][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9789, 0.0211], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,002][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.3338, 0.3331, 0.3331], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,003][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.1077, 0.5359, 0.3564], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,004][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.2969, 0.4754, 0.2276], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,006][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.3334, 0.3334, 0.3331], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,007][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.3337, 0.3331, 0.3331], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,008][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.2182, 0.0751, 0.7066], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,010][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.7109, 0.2214, 0.0677], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,011][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.6320, 0.1159, 0.2521], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,013][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.8244, 0.1713, 0.0042], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,014][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.0294, 0.6859, 0.2847], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,015][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.1347, 0.4012, 0.4641], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,016][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([8.3346e-09, 1.3171e-06, 1.0000e+00], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,018][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2503, 0.2497, 0.2498, 0.2502], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,019][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0650, 0.2843, 0.3219, 0.3289], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,020][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2780, 0.2695, 0.2444, 0.2081], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,022][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2501, 0.2501, 0.2498, 0.2500], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,023][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2503, 0.2498, 0.2498, 0.2500], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,025][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.5925, 0.0523, 0.0555, 0.2996], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,026][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.7872, 0.0669, 0.0545, 0.0914], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,027][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.5335, 0.0610, 0.2131, 0.1924], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,029][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.8576, 0.1323, 0.0051, 0.0051], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,030][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0270, 0.4904, 0.3904, 0.0921], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,032][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0955, 0.2913, 0.3652, 0.2481], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,033][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([2.2180e-01, 8.6447e-03, 2.8582e-05, 7.6952e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,034][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.2002, 0.1998, 0.1998, 0.2001, 0.2000], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,035][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0411, 0.2027, 0.2239, 0.3863, 0.1459], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,037][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.2059, 0.3305, 0.1628, 0.1814, 0.1195], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,038][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.2000, 0.2001, 0.1999, 0.2000, 0.2000], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,040][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.2002, 0.1999, 0.1999, 0.2000, 0.1999], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,041][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.0314, 0.0439, 0.1647, 0.0369, 0.7231], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,043][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.4097, 0.1190, 0.0040, 0.4043, 0.0630], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,044][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.2217, 0.0524, 0.3967, 0.2335, 0.0958], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,045][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.7727, 0.2116, 0.0045, 0.0073, 0.0039], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,047][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.0332, 0.5177, 0.2429, 0.0884, 0.1179], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,048][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0761, 0.2190, 0.2548, 0.1849, 0.2653], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,049][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([2.0320e-09, 2.7615e-08, 2.8827e-05, 5.6079e-09, 9.9997e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,050][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.1669, 0.1665, 0.1665, 0.1668, 0.1667, 0.1667], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,050][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0286, 0.1376, 0.1864, 0.2600, 0.1572, 0.2302], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,050][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.1337, 0.2774, 0.1472, 0.1394, 0.1173, 0.1850], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,051][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.1667, 0.1667, 0.1666, 0.1667, 0.1667, 0.1667], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,051][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.1669, 0.1666, 0.1666, 0.1667, 0.1666, 0.1667], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,052][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.1608, 0.0247, 0.0517, 0.0462, 0.2982, 0.4184], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,052][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.8740, 0.0217, 0.0012, 0.0787, 0.0195, 0.0049], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,052][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.4164, 0.1072, 0.1378, 0.1208, 0.1631, 0.0547], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,053][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.8741, 0.1133, 0.0025, 0.0034, 0.0026, 0.0041], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,054][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0150, 0.4209, 0.2684, 0.0469, 0.1058, 0.1430], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,056][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0552, 0.1717, 0.2050, 0.1425, 0.2139, 0.2117], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,056][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([7.4995e-08, 1.2403e-06, 2.9113e-07, 2.7361e-08, 1.7601e-07, 1.0000e+00],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,058][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1430, 0.1427, 0.1427, 0.1429, 0.1428, 0.1429, 0.1429],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,059][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0317, 0.1129, 0.1153, 0.2110, 0.1042, 0.2314, 0.1936],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,061][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1618, 0.1961, 0.1451, 0.1060, 0.1090, 0.1703, 0.1115],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,062][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1429, 0.1429, 0.1427, 0.1429, 0.1429, 0.1428, 0.1429],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,063][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1430, 0.1428, 0.1428, 0.1429, 0.1428, 0.1428, 0.1429],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,065][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1718, 0.0102, 0.0515, 0.0585, 0.6196, 0.0514, 0.0370],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,066][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.8337, 0.0143, 0.0045, 0.0420, 0.0063, 0.0737, 0.0254],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,067][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.3547, 0.0777, 0.0964, 0.1156, 0.1227, 0.0584, 0.1744],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,069][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.8506, 0.1268, 0.0042, 0.0047, 0.0034, 0.0059, 0.0045],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,070][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0188, 0.3434, 0.2651, 0.0544, 0.1252, 0.1091, 0.0840],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,072][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0477, 0.1459, 0.1834, 0.1216, 0.1902, 0.1850, 0.1261],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,073][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([6.4422e-05, 1.0595e-03, 8.3507e-05, 1.7063e-03, 3.1191e-04, 9.5366e-05,
        9.9668e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,074][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1251, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,075][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0233, 0.0897, 0.0905, 0.1583, 0.0822, 0.2032, 0.2074, 0.1453],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,077][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1326, 0.1657, 0.1234, 0.0961, 0.0952, 0.1542, 0.0806, 0.1522],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,078][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,080][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1252, 0.1249, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,081][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.2234, 0.0232, 0.0663, 0.0658, 0.1324, 0.0301, 0.0034, 0.4554],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,083][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.3998, 0.0164, 0.0129, 0.0400, 0.0229, 0.0108, 0.0254, 0.4718],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,084][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.2510, 0.0342, 0.0905, 0.0851, 0.1258, 0.0855, 0.1152, 0.2127],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,086][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.8042, 0.1453, 0.0043, 0.0060, 0.0037, 0.0062, 0.0054, 0.0250],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,087][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0170, 0.2823, 0.2836, 0.0462, 0.1193, 0.1154, 0.0612, 0.0750],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,088][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0441, 0.1289, 0.1624, 0.1095, 0.1695, 0.1633, 0.1098, 0.1124],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,089][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([9.1398e-05, 7.3718e-05, 2.3265e-05, 4.9349e-05, 1.0425e-04, 1.4136e-05,
        4.9394e-06, 9.9964e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,091][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([0.1113, 0.1110, 0.1110, 0.1112, 0.1111, 0.1111, 0.1112, 0.1110, 0.1110],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,092][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([0.0141, 0.0714, 0.0771, 0.1211, 0.0689, 0.1937, 0.1670, 0.1969, 0.0899],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,094][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([0.1200, 0.1886, 0.1105, 0.0988, 0.0770, 0.1079, 0.0786, 0.1035, 0.1151],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,095][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([0.1111, 0.1111, 0.1110, 0.1111, 0.1111, 0.1111, 0.1112, 0.1111, 0.1110],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,096][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([0.1113, 0.1111, 0.1111, 0.1112, 0.1111, 0.1111, 0.1112, 0.1110, 0.1110],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,098][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([0.0333, 0.0420, 0.0157, 0.0270, 0.3350, 0.0318, 0.0021, 0.4195, 0.0936],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,099][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([0.1529, 0.0269, 0.0057, 0.1808, 0.0289, 0.0019, 0.0384, 0.5617, 0.0028],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,101][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([0.3526, 0.0335, 0.1024, 0.0622, 0.0688, 0.1318, 0.1038, 0.1363, 0.0085],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,102][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([0.7957, 0.1591, 0.0029, 0.0051, 0.0020, 0.0045, 0.0049, 0.0209, 0.0049],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,104][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([0.0138, 0.3164, 0.1995, 0.0426, 0.0868, 0.1079, 0.1054, 0.1192, 0.0083],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,105][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([0.0383, 0.1157, 0.1391, 0.0964, 0.1440, 0.1414, 0.0950, 0.0967, 0.1333],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,106][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([4.7851e-08, 1.3015e-06, 6.2870e-05, 3.2887e-07, 7.8305e-04, 9.8221e-05,
        5.4470e-07, 2.2772e-07, 9.9905e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,107][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.1001, 0.0999, 0.0999, 0.1001, 0.1000, 0.1000, 0.1001, 0.0999, 0.0999,
        0.1002], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,107][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0215, 0.0684, 0.0702, 0.0996, 0.0683, 0.1575, 0.1332, 0.1354, 0.1200,
        0.1260], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,108][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1003, 0.1098, 0.1108, 0.0735, 0.0794, 0.1110, 0.0637, 0.1016, 0.1255,
        0.1245], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,108][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.1000, 0.1000, 0.0999, 0.1000, 0.1000, 0.1000, 0.1001, 0.0999, 0.0999,
        0.1000], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,109][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.1001, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1001, 0.0999, 0.0999,
        0.1001], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,109][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1834, 0.0221, 0.0446, 0.0445, 0.1568, 0.0207, 0.0067, 0.3956, 0.0355,
        0.0901], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,109][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.1448, 0.0344, 0.0459, 0.0496, 0.0624, 0.0111, 0.0275, 0.5785, 0.0065,
        0.0393], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,111][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.1871, 0.0198, 0.1046, 0.0754, 0.1656, 0.0715, 0.0911, 0.1022, 0.0744,
        0.1084], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,112][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.8103, 0.1280, 0.0043, 0.0053, 0.0036, 0.0064, 0.0050, 0.0245, 0.0072,
        0.0053], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,113][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0191, 0.2544, 0.2410, 0.0497, 0.1145, 0.0812, 0.0455, 0.0435, 0.0112,
        0.1399], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,115][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0338, 0.1038, 0.1296, 0.0876, 0.1349, 0.1320, 0.0884, 0.0870, 0.1262,
        0.0767], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,116][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([7.9940e-03, 3.7806e-04, 6.1451e-01, 9.8218e-04, 2.0236e-01, 9.9822e-02,
        6.1575e-03, 2.1287e-02, 4.6316e-02, 1.8899e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,117][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.0910, 0.0908, 0.0908, 0.0909, 0.0909, 0.0909, 0.0910, 0.0908, 0.0908,
        0.0911, 0.0910], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,119][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.0115, 0.0605, 0.0391, 0.1083, 0.0426, 0.1506, 0.1319, 0.1654, 0.0914,
        0.1648, 0.0339], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,120][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.0853, 0.1606, 0.0756, 0.0797, 0.0506, 0.0994, 0.0615, 0.0889, 0.1010,
        0.1306, 0.0667], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,122][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.0909, 0.0909, 0.0908, 0.0909, 0.0909, 0.0909, 0.0910, 0.0909, 0.0908,
        0.0910, 0.0909], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,123][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.0910, 0.0909, 0.0909, 0.0909, 0.0909, 0.0909, 0.0910, 0.0908, 0.0908,
        0.0910, 0.0910], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,124][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.0134, 0.0053, 0.0534, 0.0081, 0.5598, 0.0133, 0.0019, 0.2335, 0.0029,
        0.0440, 0.0642], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,126][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.1724, 0.0514, 0.0144, 0.1568, 0.0612, 0.0036, 0.0347, 0.4132, 0.0027,
        0.0764, 0.0134], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,127][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.0846, 0.0290, 0.0383, 0.0650, 0.0874, 0.0595, 0.0973, 0.1730, 0.0960,
        0.2428, 0.0270], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,128][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([7.3395e-01, 2.1117e-01, 2.8826e-03, 6.0481e-03, 2.1476e-03, 4.2222e-03,
        5.1421e-03, 2.4575e-02, 3.6408e-03, 5.8093e-03, 4.0924e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,130][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.0109, 0.2369, 0.1016, 0.0308, 0.0517, 0.0767, 0.1103, 0.1061, 0.0064,
        0.1737, 0.0951], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,131][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.0335, 0.0953, 0.1122, 0.0804, 0.1170, 0.1166, 0.0798, 0.0795, 0.1111,
        0.0691, 0.1055], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,132][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([6.5314e-09, 5.9853e-07, 5.6981e-01, 2.2442e-08, 1.6732e-03, 7.9795e-07,
        1.9607e-07, 4.5483e-10, 7.0601e-08, 1.9362e-07, 4.2852e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,134][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0834, 0.0832, 0.0832, 0.0834, 0.0833, 0.0833, 0.0834, 0.0833, 0.0832,
        0.0835, 0.0834, 0.0833], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,135][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0102, 0.0462, 0.0655, 0.0814, 0.0549, 0.0991, 0.1091, 0.1542, 0.0915,
        0.1356, 0.0617, 0.0906], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,137][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0793, 0.1411, 0.0816, 0.0701, 0.0594, 0.0996, 0.0585, 0.0722, 0.0946,
        0.1069, 0.0735, 0.0633], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,138][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0833, 0.0834, 0.0833, 0.0833, 0.0833, 0.0833, 0.0834, 0.0833, 0.0833,
        0.0834, 0.0834, 0.0834], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,139][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0834, 0.0833, 0.0833, 0.0834, 0.0833, 0.0833, 0.0834, 0.0833, 0.0832,
        0.0834, 0.0834, 0.0833], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,141][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0729, 0.0153, 0.0693, 0.0230, 0.2080, 0.1255, 0.0024, 0.2174, 0.0087,
        0.1268, 0.0770, 0.0537], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,142][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.5138, 0.0175, 0.0052, 0.1521, 0.0619, 0.0197, 0.0350, 0.1268, 0.0024,
        0.0357, 0.0050, 0.0249], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,144][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.1525, 0.0490, 0.0387, 0.0709, 0.0753, 0.0309, 0.0959, 0.0898, 0.1238,
        0.2291, 0.0245, 0.0197], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,145][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([8.2775e-01, 1.1711e-01, 2.9128e-03, 3.9995e-03, 3.3722e-03, 5.1533e-03,
        3.5483e-03, 2.2230e-02, 7.8308e-03, 4.7760e-03, 6.1690e-04, 7.0611e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,146][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0082, 0.2268, 0.1410, 0.0285, 0.0537, 0.0680, 0.0735, 0.0983, 0.0050,
        0.1244, 0.1355, 0.0371], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,148][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0271, 0.0843, 0.1029, 0.0704, 0.1071, 0.1075, 0.0718, 0.0703, 0.1008,
        0.0621, 0.0968, 0.0989], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,149][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([1.4794e-08, 6.3982e-07, 8.9565e-07, 6.5961e-08, 1.0051e-05, 8.2439e-07,
        1.8089e-07, 1.2625e-11, 2.4939e-08, 9.0973e-08, 1.7288e-06, 9.9999e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,150][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0770, 0.0768, 0.0768, 0.0770, 0.0769, 0.0769, 0.0770, 0.0769, 0.0768,
        0.0771, 0.0770, 0.0769, 0.0769], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,152][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0114, 0.0451, 0.0444, 0.0724, 0.0424, 0.0980, 0.1085, 0.1205, 0.0793,
        0.1328, 0.0432, 0.1168, 0.0850], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,153][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0788, 0.1053, 0.0721, 0.0626, 0.0568, 0.0806, 0.0532, 0.0846, 0.1084,
        0.1042, 0.0685, 0.0531, 0.0718], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,155][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0770, 0.0769, 0.0769,
        0.0770, 0.0769, 0.0769, 0.0769], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,156][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0770, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0770, 0.0769, 0.0768,
        0.0770, 0.0770, 0.0769, 0.0769], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,158][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0783, 0.0148, 0.0850, 0.0488, 0.1693, 0.0296, 0.0024, 0.2912, 0.0177,
        0.0719, 0.0973, 0.0167, 0.0770], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,159][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2891, 0.0154, 0.0083, 0.0287, 0.0390, 0.0104, 0.0209, 0.3638, 0.0025,
        0.0260, 0.0081, 0.0087, 0.1791], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,160][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1646, 0.0368, 0.0415, 0.0583, 0.0865, 0.0417, 0.0815, 0.1073, 0.0621,
        0.1482, 0.0164, 0.0390, 0.1163], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,161][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([8.0405e-01, 1.3642e-01, 3.8258e-03, 4.9692e-03, 3.9624e-03, 5.6930e-03,
        3.8873e-03, 2.1039e-02, 6.0862e-03, 5.6088e-03, 5.2340e-04, 8.8892e-04,
        3.0497e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,163][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0099, 0.1962, 0.1579, 0.0274, 0.0633, 0.0732, 0.0475, 0.0498, 0.0057,
        0.1059, 0.1566, 0.0334, 0.0732], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,164][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0262, 0.0769, 0.0961, 0.0653, 0.1006, 0.0977, 0.0653, 0.0660, 0.0951,
        0.0573, 0.0912, 0.0932, 0.0689], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,165][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([3.5540e-08, 1.6019e-06, 1.0230e-05, 4.4622e-07, 7.2274e-06, 1.2346e-06,
        1.7949e-06, 3.4676e-07, 4.4614e-07, 1.0504e-06, 1.2466e-05, 1.5911e-05,
        9.9995e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,165][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.0715, 0.0713, 0.0714, 0.0715, 0.0714, 0.0714, 0.0715, 0.0714, 0.0713,
        0.0716, 0.0715, 0.0714, 0.0714, 0.0714], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,165][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.0058, 0.0351, 0.0454, 0.0631, 0.0319, 0.1091, 0.1043, 0.1083, 0.0606,
        0.1071, 0.0437, 0.1082, 0.1285, 0.0489], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,166][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.0705, 0.1240, 0.0715, 0.0701, 0.0546, 0.0713, 0.0607, 0.0636, 0.0813,
        0.0980, 0.0643, 0.0549, 0.0564, 0.0587], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,166][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0715, 0.0714, 0.0714,
        0.0715, 0.0714, 0.0714, 0.0714, 0.0714], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,167][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0715, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0715, 0.0714, 0.0714,
        0.0715, 0.0715, 0.0714, 0.0714, 0.0714], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,167][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([0.0378, 0.0172, 0.0188, 0.0249, 0.2417, 0.1273, 0.0031, 0.2645, 0.0270,
        0.1152, 0.0242, 0.0123, 0.0684, 0.0178], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,168][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.1276, 0.0402, 0.0162, 0.0532, 0.1094, 0.0062, 0.0323, 0.1674, 0.0014,
        0.0293, 0.0158, 0.0084, 0.1673, 0.2252], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,169][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.0797, 0.0347, 0.0567, 0.0603, 0.0385, 0.0912, 0.0578, 0.1299, 0.0683,
        0.1778, 0.0256, 0.0647, 0.1116, 0.0033], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,170][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([8.0121e-01, 1.5065e-01, 2.9960e-03, 4.2668e-03, 3.5427e-03, 4.3539e-03,
        2.8324e-03, 1.7342e-02, 4.5361e-03, 4.5609e-03, 4.7852e-04, 7.0044e-04,
        2.2701e-03, 2.6255e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,172][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.0069, 0.1971, 0.1065, 0.0237, 0.0412, 0.0605, 0.0633, 0.0678, 0.0047,
        0.1138, 0.1044, 0.0377, 0.1461, 0.0261], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,173][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.0240, 0.0737, 0.0877, 0.0616, 0.0906, 0.0886, 0.0614, 0.0606, 0.0851,
        0.0533, 0.0823, 0.0844, 0.0625, 0.0843], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,174][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([2.8390e-06, 1.1636e-05, 4.8911e-03, 7.1090e-06, 7.7923e-03, 1.5297e-02,
        3.1002e-05, 2.8393e-06, 1.1173e-02, 4.3374e-06, 3.7145e-03, 1.3521e-02,
        7.9973e-05, 9.4347e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,175][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0667, 0.0666, 0.0666, 0.0667, 0.0667, 0.0667, 0.0667, 0.0666, 0.0666,
        0.0668, 0.0667, 0.0666, 0.0666, 0.0667, 0.0667], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,177][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0105, 0.0389, 0.0406, 0.0720, 0.0364, 0.0843, 0.0650, 0.0930, 0.0754,
        0.0868, 0.0389, 0.0887, 0.1145, 0.0934, 0.0616], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,178][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0702, 0.0887, 0.0698, 0.0463, 0.0518, 0.0829, 0.0501, 0.0705, 0.0812,
        0.0848, 0.0665, 0.0586, 0.0588, 0.0674, 0.0525], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,180][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0667, 0.0667, 0.0666, 0.0667, 0.0667, 0.0667, 0.0667, 0.0666, 0.0666,
        0.0667, 0.0667, 0.0667, 0.0666, 0.0667, 0.0667], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,181][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0667, 0.0666, 0.0666, 0.0667, 0.0666, 0.0667, 0.0667, 0.0666, 0.0666,
        0.0667, 0.0667, 0.0667, 0.0667, 0.0667, 0.0667], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,183][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0906, 0.0061, 0.0289, 0.0374, 0.4004, 0.0274, 0.0139, 0.2061, 0.0201,
        0.0655, 0.0408, 0.0117, 0.0412, 0.0036, 0.0061], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,184][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([5.0335e-01, 6.5208e-03, 1.8482e-03, 2.0315e-02, 2.6807e-03, 2.8448e-02,
        1.1337e-02, 2.0460e-01, 2.4991e-04, 9.0330e-03, 1.7919e-03, 2.6359e-02,
        1.7211e-01, 6.1462e-03, 5.2137e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,185][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1163, 0.0353, 0.0402, 0.0503, 0.0584, 0.0313, 0.0668, 0.0761, 0.0456,
        0.1239, 0.0133, 0.0331, 0.0945, 0.1456, 0.0691], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,186][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([8.0998e-01, 1.3245e-01, 3.8448e-03, 4.4094e-03, 4.0430e-03, 5.5498e-03,
        3.4667e-03, 2.0484e-02, 5.7796e-03, 5.0375e-03, 5.4087e-04, 8.2575e-04,
        2.8403e-03, 3.1311e-04, 4.3135e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,188][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0100, 0.1737, 0.1388, 0.0276, 0.0646, 0.0596, 0.0453, 0.0496, 0.0062,
        0.0979, 0.1356, 0.0303, 0.0804, 0.0431, 0.0373], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,189][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0221, 0.0664, 0.0839, 0.0554, 0.0872, 0.0844, 0.0572, 0.0560, 0.0806,
        0.0490, 0.0793, 0.0804, 0.0585, 0.0820, 0.0576], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,190][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([3.1367e-05, 1.0929e-03, 1.6442e-04, 9.6309e-04, 4.1158e-04, 2.5043e-04,
        6.5044e-01, 7.4268e-07, 1.3874e-05, 3.5423e-04, 1.8595e-04, 1.4889e-03,
        3.1052e-05, 5.9106e-05, 3.4451e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,192][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:49,193][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[28063],
        [31354],
        [40207],
        [32320],
        [14748],
        [37267],
        [39683],
        [41378],
        [46796],
        [36173],
        [47144],
        [38658],
        [43944],
        [43475],
        [45628]], device='cuda:0')
[2024-07-24 10:21:49,195][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[30363],
        [24410],
        [27972],
        [32024],
        [    2],
        [24915],
        [33568],
        [43751],
        [46863],
        [30694],
        [30994],
        [ 8621],
        [42193],
        [18231],
        [37340]], device='cuda:0')
[2024-07-24 10:21:49,196][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[25526],
        [ 8714],
        [12798],
        [10067],
        [14274],
        [ 9409],
        [ 9898],
        [ 9972],
        [ 9330],
        [10515],
        [11973],
        [10162],
        [10569],
        [11786],
        [11507]], device='cuda:0')
[2024-07-24 10:21:49,197][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[36372],
        [40003],
        [46997],
        [40827],
        [43258],
        [44522],
        [41347],
        [41201],
        [40739],
        [42440],
        [41620],
        [42131],
        [43506],
        [42474],
        [43542]], device='cuda:0')
[2024-07-24 10:21:49,199][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[14194],
        [26192],
        [28486],
        [36071],
        [37114],
        [39995],
        [41684],
        [42736],
        [43224],
        [44124],
        [44467],
        [44884],
        [45401],
        [45755],
        [46045]], device='cuda:0')
[2024-07-24 10:21:49,200][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[11951],
        [11132],
        [10496],
        [ 9797],
        [ 9874],
        [ 9719],
        [ 9675],
        [ 9747],
        [ 9689],
        [ 9661],
        [ 9757],
        [ 9755],
        [ 9808],
        [ 9782],
        [ 9868]], device='cuda:0')
[2024-07-24 10:21:49,202][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[32836],
        [33016],
        [33094],
        [34578],
        [34824],
        [30828],
        [31964],
        [31441],
        [26075],
        [25562],
        [28310],
        [27108],
        [27674],
        [27965],
        [28887]], device='cuda:0')
[2024-07-24 10:21:49,203][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[31666],
        [35126],
        [34735],
        [37794],
        [38127],
        [34906],
        [37848],
        [38091],
        [38179],
        [38384],
        [38601],
        [37693],
        [38224],
        [38053],
        [38557]], device='cuda:0')
[2024-07-24 10:21:49,204][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[14935],
        [14795],
        [ 4709],
        [ 8741],
        [  139],
        [  172],
        [  113],
        [  136],
        [  202],
        [ 1027],
        [10825],
        [ 6633],
        [  201],
        [  319],
        [ 5576]], device='cuda:0')
[2024-07-24 10:21:49,206][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[31250],
        [31573],
        [14840],
        [24464],
        [ 8033],
        [ 4095],
        [ 8179],
        [11476],
        [ 8084],
        [ 3146],
        [ 5865],
        [ 5784],
        [11118],
        [10233],
        [ 9148]], device='cuda:0')
[2024-07-24 10:21:49,207][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[13768],
        [13843],
        [15576],
        [15363],
        [19095],
        [17231],
        [18908],
        [22817],
        [27683],
        [26952],
        [19464],
        [20631],
        [21298],
        [23789],
        [21198]], device='cuda:0')
[2024-07-24 10:21:49,209][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[18804],
        [17344],
        [38837],
        [38881],
        [33743],
        [38578],
        [38454],
        [39926],
        [38497],
        [38059],
        [37024],
        [39958],
        [39970],
        [40247],
        [40268]], device='cuda:0')
[2024-07-24 10:21:49,210][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[651],
        [276],
        [235],
        [287],
        [368],
        [367],
        [376],
        [531],
        [466],
        [471],
        [463],
        [471],
        [514],
        [477],
        [471]], device='cuda:0')
[2024-07-24 10:21:49,212][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[22538],
        [28210],
        [42152],
        [33006],
        [41431],
        [41110],
        [32592],
        [37467],
        [41947],
        [37155],
        [36860],
        [41201],
        [35839],
        [40455],
        [34096]], device='cuda:0')
[2024-07-24 10:21:49,213][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[23209],
        [48408],
        [47083],
        [47298],
        [47964],
        [41354],
        [49315],
        [47267],
        [49299],
        [45503],
        [49466],
        [43075],
        [48465],
        [42222],
        [47518]], device='cuda:0')
[2024-07-24 10:21:49,214][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[3553],
        [3556],
        [3554],
        [3553],
        [3549],
        [3547],
        [3551],
        [3554],
        [3550],
        [3551],
        [3554],
        [3553],
        [3554],
        [3555],
        [3553]], device='cuda:0')
[2024-07-24 10:21:49,216][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[2271],
        [3343],
        [2825],
        [3084],
        [3218],
        [3688],
        [5755],
        [7300],
        [7398],
        [6402],
        [6689],
        [6350],
        [6789],
        [6841],
        [6740]], device='cuda:0')
[2024-07-24 10:21:49,217][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[15209],
        [15084],
        [16189],
        [16514],
        [16903],
        [17732],
        [18279],
        [17951],
        [17516],
        [17802],
        [17802],
        [17761],
        [17663],
        [17627],
        [17897]], device='cuda:0')
[2024-07-24 10:21:49,219][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[29130],
        [29141],
        [29130],
        [29133],
        [29130],
        [29134],
        [29136],
        [29145],
        [29139],
        [29135],
        [29134],
        [29133],
        [29134],
        [29134],
        [29132]], device='cuda:0')
[2024-07-24 10:21:49,220][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[16492],
        [16443],
        [16422],
        [16435],
        [16440],
        [16435],
        [16434],
        [16444],
        [16435],
        [16440],
        [16444],
        [16449],
        [16444],
        [16443],
        [16443]], device='cuda:0')
[2024-07-24 10:21:49,221][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[  424],
        [  342],
        [ 9080],
        [  437],
        [16109],
        [10260],
        [ 9456],
        [ 5742],
        [ 7625],
        [ 5132],
        [10526],
        [ 6243],
        [ 6260],
        [ 6502],
        [ 6190]], device='cuda:0')
[2024-07-24 10:21:49,223][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 6879],
        [ 7571],
        [11444],
        [ 8866],
        [15309],
        [ 7853],
        [ 6765],
        [10208],
        [13659],
        [15611],
        [17296],
        [11215],
        [12432],
        [22551],
        [ 9446]], device='cuda:0')
[2024-07-24 10:21:49,224][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[32972],
        [32452],
        [41382],
        [34842],
        [46813],
        [47319],
        [41774],
        [44295],
        [45559],
        [48265],
        [45288],
        [45691],
        [46336],
        [47891],
        [47554]], device='cuda:0')
[2024-07-24 10:21:49,226][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[35608],
        [35896],
        [36114],
        [36034],
        [36355],
        [35991],
        [36115],
        [36355],
        [36329],
        [36371],
        [36659],
        [36281],
        [36398],
        [36363],
        [36372]], device='cuda:0')
[2024-07-24 10:21:49,227][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[25536],
        [36693],
        [35736],
        [34874],
        [34177],
        [33196],
        [32416],
        [31147],
        [30825],
        [32113],
        [31705],
        [31478],
        [30877],
        [29918],
        [30368]], device='cuda:0')
[2024-07-24 10:21:49,227][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[38264],
        [37866],
        [37482],
        [37515],
        [37107],
        [37404],
        [37334],
        [36930],
        [37155],
        [37021],
        [36984],
        [37055],
        [36953],
        [37063],
        [37052]], device='cuda:0')
[2024-07-24 10:21:49,229][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[29405],
        [29737],
        [29152],
        [31226],
        [33767],
        [40447],
        [39027],
        [21841],
        [45504],
        [31645],
        [32816],
        [45367],
        [27289],
        [46698],
        [39736]], device='cuda:0')
[2024-07-24 10:21:49,230][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[44161],
        [45499],
        [36077],
        [43303],
        [31182],
        [32002],
        [35302],
        [35059],
        [29627],
        [30001],
        [28802],
        [31945],
        [33316],
        [27167],
        [31964]], device='cuda:0')
[2024-07-24 10:21:49,232][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[12084],
        [ 1447],
        [ 3056],
        [  732],
        [10138],
        [ 1846],
        [  411],
        [ 1279],
        [  654],
        [ 1597],
        [ 2206],
        [ 4038],
        [  743],
        [ 6477],
        [ 1192]], device='cuda:0')
[2024-07-24 10:21:49,233][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[28562],
        [28562],
        [28562],
        [28562],
        [28562],
        [28562],
        [28562],
        [28562],
        [28562],
        [28562],
        [28562],
        [28562],
        [28562],
        [28562],
        [28562]], device='cuda:0')
[2024-07-24 10:21:49,259][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:49,260][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,261][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,262][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,264][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,265][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,266][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,267][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,268][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,269][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,270][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,271][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,273][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,274][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4212, 0.5788], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,276][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.7380, 0.2620], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,277][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1004, 0.8996], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,278][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5574, 0.4426], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,280][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9923, 0.0077], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,281][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2117, 0.7883], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,283][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3476, 0.6524], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,283][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2481, 0.7519], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,283][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2684, 0.7316], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,284][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2602, 0.7398], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,284][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.3161, 0.6839], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,284][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6086, 0.3914], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,285][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.2813, 0.4897, 0.2290], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,285][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.4853, 0.2549, 0.2598], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,285][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.4876, 0.0184, 0.4940], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,286][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.2813, 0.3941, 0.3246], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,287][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.9724, 0.0134, 0.0142], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,288][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.0729, 0.7568, 0.1703], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,289][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.1562, 0.3087, 0.5352], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,290][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.0178, 0.0761, 0.9060], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,292][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.0865, 0.3379, 0.5756], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,293][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.0265, 0.2309, 0.7426], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,294][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.0945, 0.2931, 0.6123], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,296][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.2988, 0.2415, 0.4598], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,297][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1862, 0.3129, 0.2561, 0.2448], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,299][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.3506, 0.1542, 0.3012, 0.1940], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,300][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0308, 0.0051, 0.8521, 0.1121], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,301][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1786, 0.2164, 0.4326, 0.1724], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,303][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9778, 0.0070, 0.0078, 0.0074], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,304][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0558, 0.3322, 0.5064, 0.1056], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,305][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1518, 0.2863, 0.3710, 0.1909], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,306][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0032, 0.0060, 0.1131, 0.8777], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,308][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0793, 0.2204, 0.4436, 0.2567], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,309][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0273, 0.0625, 0.8159, 0.0943], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,311][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0936, 0.2046, 0.4774, 0.2243], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,312][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2305, 0.2174, 0.3373, 0.2149], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,313][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.1502, 0.2159, 0.2044, 0.2419, 0.1876], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,315][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.1994, 0.1436, 0.2721, 0.1385, 0.2463], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,315][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([6.1805e-03, 2.0900e-05, 8.3588e-03, 2.5420e-03, 9.8290e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,317][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.1228, 0.2049, 0.2618, 0.2138, 0.1968], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,318][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.9696, 0.0079, 0.0087, 0.0083, 0.0055], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,320][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0248, 0.2964, 0.2433, 0.3339, 0.1016], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,321][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.1029, 0.2025, 0.3272, 0.1288, 0.2386], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,322][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.0019, 0.0062, 0.0691, 0.6044, 0.3183], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,324][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.0401, 0.1665, 0.2945, 0.2207, 0.2781], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,325][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0039, 0.0390, 0.2840, 0.1158, 0.5574], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,326][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.0417, 0.1528, 0.3252, 0.1546, 0.3258], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,328][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.1980, 0.1176, 0.2977, 0.1322, 0.2545], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,329][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.1022, 0.2002, 0.1594, 0.2208, 0.2120, 0.1054], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,331][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.2754, 0.1344, 0.1739, 0.1264, 0.1735, 0.1165], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,332][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0250, 0.0016, 0.0398, 0.0136, 0.8558, 0.0642], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,334][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.1642, 0.1340, 0.2064, 0.2031, 0.2332, 0.0591], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,335][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.8926, 0.0150, 0.0157, 0.0154, 0.0111, 0.0503], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,337][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0204, 0.2007, 0.2392, 0.2351, 0.2776, 0.0270], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,338][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0857, 0.1506, 0.2442, 0.1008, 0.1912, 0.2275], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,340][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0010, 0.0031, 0.0372, 0.3216, 0.1725, 0.4646], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,341][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0401, 0.1329, 0.2193, 0.1766, 0.2156, 0.2154], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,341][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0051, 0.0189, 0.2949, 0.0262, 0.6089, 0.0459], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,342][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0351, 0.1123, 0.2542, 0.1104, 0.2291, 0.2588], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,342][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.1254, 0.1312, 0.2354, 0.1272, 0.2193, 0.1615], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,342][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1073, 0.1583, 0.1363, 0.1766, 0.1340, 0.1055, 0.1820],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,343][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.2114, 0.1036, 0.1799, 0.1307, 0.1410, 0.0864, 0.1469],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,343][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0182, 0.0008, 0.0266, 0.0092, 0.7591, 0.0688, 0.1173],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,344][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1584, 0.1547, 0.1834, 0.1861, 0.1697, 0.0922, 0.0555],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,345][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.9318, 0.0065, 0.0074, 0.0068, 0.0046, 0.0317, 0.0112],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,346][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0255, 0.1353, 0.2897, 0.2278, 0.2729, 0.0365, 0.0121],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,347][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0947, 0.1512, 0.1914, 0.1173, 0.1518, 0.1928, 0.1007],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,348][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([2.6581e-04, 4.9204e-04, 6.9548e-03, 6.2188e-02, 3.3537e-02, 9.7162e-02,
        7.9940e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,350][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0448, 0.1062, 0.1969, 0.1261, 0.1776, 0.1975, 0.1508],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,350][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([3.8948e-04, 4.7712e-03, 1.4768e-01, 1.4397e-02, 7.2947e-01, 9.6479e-02,
        6.8130e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,352][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0428, 0.1000, 0.2132, 0.1127, 0.1861, 0.2176, 0.1275],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,353][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1164, 0.1235, 0.1582, 0.1554, 0.1514, 0.1619, 0.1331],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,355][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0786, 0.1271, 0.1156, 0.1486, 0.1276, 0.1093, 0.2063, 0.0871],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,356][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1744, 0.0755, 0.1546, 0.1224, 0.1330, 0.0731, 0.1014, 0.1656],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,357][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ the] are: tensor([1.0660e-02, 2.2995e-04, 1.8025e-02, 4.5557e-03, 5.4661e-01, 4.7465e-02,
        1.2485e-01, 2.4761e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,358][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1207, 0.1240, 0.1385, 0.1638, 0.1532, 0.1030, 0.1070, 0.0899],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,360][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.8731, 0.0098, 0.0111, 0.0104, 0.0072, 0.0407, 0.0166, 0.0312],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,361][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0241, 0.1791, 0.1353, 0.2602, 0.2561, 0.0637, 0.0637, 0.0178],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,363][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0778, 0.1340, 0.1748, 0.0993, 0.1360, 0.1910, 0.0863, 0.1008],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,363][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ the] are: tensor([1.5966e-04, 2.8977e-04, 3.8992e-03, 3.7349e-02, 1.8996e-02, 5.8786e-02,
        4.5025e-01, 4.3027e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,365][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0393, 0.0890, 0.1646, 0.1071, 0.1459, 0.1682, 0.1323, 0.1536],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,366][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0041, 0.0187, 0.2886, 0.0225, 0.5648, 0.0409, 0.0129, 0.0475],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,368][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0401, 0.0899, 0.1887, 0.0985, 0.1660, 0.1928, 0.1087, 0.1154],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,369][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1138, 0.1099, 0.1454, 0.1540, 0.1175, 0.1447, 0.1289, 0.0857],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,371][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ house] are: tensor([0.0653, 0.1068, 0.0832, 0.1113, 0.1027, 0.0953, 0.1601, 0.0892, 0.1861],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,372][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ house] are: tensor([0.1502, 0.1089, 0.1102, 0.0910, 0.1501, 0.0991, 0.0422, 0.1698, 0.0786],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,373][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.0681, 0.0014, 0.0173, 0.0110, 0.4051, 0.0697, 0.0900, 0.1769, 0.1605],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,375][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ house] are: tensor([0.0549, 0.0947, 0.1900, 0.1595, 0.1680, 0.1181, 0.0486, 0.1095, 0.0567],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,376][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ house] are: tensor([0.8138, 0.0122, 0.0131, 0.0123, 0.0091, 0.0429, 0.0187, 0.0341, 0.0438],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,378][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ house] are: tensor([0.0121, 0.1365, 0.2708, 0.1849, 0.2328, 0.0406, 0.0597, 0.0507, 0.0119],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,379][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ house] are: tensor([0.0508, 0.0995, 0.1791, 0.0705, 0.1166, 0.1841, 0.0589, 0.0814, 0.1590],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,380][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ house] are: tensor([8.8662e-05, 3.3404e-04, 3.5979e-03, 3.5765e-02, 1.8563e-02, 4.9512e-02,
        4.1640e-01, 3.3022e-01, 1.4552e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,382][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.0186, 0.0748, 0.1201, 0.1066, 0.1117, 0.1136, 0.1259, 0.1215, 0.2070],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,383][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ house] are: tensor([0.0047, 0.0202, 0.2870, 0.0192, 0.5271, 0.0288, 0.0117, 0.0433, 0.0581],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,384][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.0225, 0.0665, 0.1464, 0.0684, 0.1404, 0.1590, 0.0718, 0.0801, 0.2449],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,386][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ house] are: tensor([0.0974, 0.0740, 0.1721, 0.0819, 0.1736, 0.1215, 0.0650, 0.0736, 0.1409],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,387][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0589, 0.0913, 0.0787, 0.0928, 0.0937, 0.0832, 0.1328, 0.0818, 0.1797,
        0.1073], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,389][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0986, 0.0546, 0.1355, 0.1035, 0.1149, 0.0406, 0.1320, 0.1614, 0.0550,
        0.1038], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,390][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [.] are: tensor([1.3285e-03, 2.2751e-05, 4.9206e-03, 1.2529e-03, 2.1295e-01, 1.4829e-02,
        3.7031e-02, 1.0119e-01, 1.4394e-01, 4.8253e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,391][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0881, 0.1017, 0.1426, 0.1253, 0.1218, 0.1010, 0.0989, 0.0844, 0.1029,
        0.0334], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,393][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.7131, 0.0108, 0.0118, 0.0104, 0.0077, 0.0353, 0.0156, 0.0284, 0.0368,
        0.1301], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,394][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0266, 0.1370, 0.1295, 0.1663, 0.1510, 0.0579, 0.0809, 0.0533, 0.1349,
        0.0625], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,395][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0536, 0.1009, 0.1356, 0.0741, 0.1024, 0.1231, 0.0660, 0.0837, 0.1414,
        0.1193], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,396][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [.] are: tensor([6.6766e-05, 1.5129e-04, 2.0651e-03, 1.7372e-02, 9.8926e-03, 2.8856e-02,
        1.8751e-01, 1.7760e-01, 8.5812e-02, 4.9067e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,398][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0284, 0.0629, 0.1087, 0.0792, 0.1011, 0.1071, 0.0933, 0.1057, 0.1785,
        0.1351], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,398][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0045, 0.0144, 0.2430, 0.0189, 0.4578, 0.0342, 0.0220, 0.0575, 0.0991,
        0.0486], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,399][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0257, 0.0611, 0.1461, 0.0690, 0.1265, 0.1263, 0.0780, 0.0871, 0.2138,
        0.0664], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,399][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0913, 0.0698, 0.1242, 0.1187, 0.1034, 0.1033, 0.1112, 0.0910, 0.1212,
        0.0658], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,399][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.0501, 0.0899, 0.0401, 0.0859, 0.0916, 0.0754, 0.1373, 0.0763, 0.2022,
        0.1156, 0.0357], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,400][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.1799, 0.1006, 0.0956, 0.0597, 0.1376, 0.1193, 0.0220, 0.0700, 0.0748,
        0.0778, 0.0627], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,400][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([6.5970e-07, 4.3119e-10, 9.9525e-07, 8.4835e-07, 7.4121e-04, 3.7068e-05,
        1.9565e-04, 8.9080e-04, 1.5599e-04, 1.1430e-02, 9.8655e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,401][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.0672, 0.0909, 0.0784, 0.1015, 0.1368, 0.0987, 0.0705, 0.1455, 0.1170,
        0.0352, 0.0583], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,401][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.6773, 0.0107, 0.0112, 0.0098, 0.0074, 0.0323, 0.0142, 0.0256, 0.0328,
        0.1216, 0.0571], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,402][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.0138, 0.1322, 0.0313, 0.1280, 0.1358, 0.0584, 0.0451, 0.0826, 0.1957,
        0.1421, 0.0350], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,403][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.0427, 0.0822, 0.1408, 0.0499, 0.1074, 0.1541, 0.0466, 0.0539, 0.1238,
        0.0787, 0.1198], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,404][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([6.7373e-05, 2.8904e-04, 2.3865e-03, 1.9862e-02, 9.6738e-03, 2.5969e-02,
        1.7571e-01, 1.5843e-01, 6.8924e-02, 3.9249e-01, 1.4620e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,406][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.0141, 0.0517, 0.0852, 0.0697, 0.0839, 0.0862, 0.0893, 0.0883, 0.1721,
        0.1266, 0.1329], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,407][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([5.4513e-04, 4.2945e-03, 1.3703e-02, 1.1359e-02, 7.0012e-02, 2.1633e-02,
        1.7847e-03, 4.9137e-02, 1.5018e-01, 9.9989e-02, 5.7736e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,408][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.0174, 0.0553, 0.1199, 0.0545, 0.1232, 0.1499, 0.0575, 0.0646, 0.2134,
        0.0533, 0.0911], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,409][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.0799, 0.0658, 0.1203, 0.0696, 0.1273, 0.1190, 0.0553, 0.0691, 0.1252,
        0.0525, 0.1160], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,411][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0448, 0.0861, 0.0570, 0.0821, 0.0774, 0.0850, 0.1354, 0.0684, 0.1671,
        0.1108, 0.0503, 0.0356], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,412][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.1657, 0.0969, 0.0830, 0.0760, 0.0798, 0.0735, 0.0337, 0.0836, 0.0573,
        0.1082, 0.0574, 0.0849], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,413][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([2.6604e-06, 2.2361e-08, 1.3856e-05, 3.1556e-06, 1.3440e-03, 5.9785e-05,
        2.2615e-04, 8.2701e-04, 9.9634e-04, 5.9119e-03, 9.8207e-01, 8.5415e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,415][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0760, 0.0836, 0.1065, 0.0978, 0.1228, 0.0560, 0.0686, 0.1263, 0.1086,
        0.0442, 0.0806, 0.0290], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,416][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.6357, 0.0094, 0.0099, 0.0096, 0.0069, 0.0324, 0.0145, 0.0263, 0.0334,
        0.1324, 0.0567, 0.0328], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,418][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0163, 0.1356, 0.0849, 0.1076, 0.2083, 0.0287, 0.0386, 0.0687, 0.1128,
        0.0888, 0.0977, 0.0121], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,419][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0434, 0.0768, 0.1196, 0.0504, 0.0894, 0.1251, 0.0447, 0.0575, 0.1207,
        0.0761, 0.1031, 0.0931], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,420][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([5.5047e-05, 1.6012e-04, 1.2985e-03, 1.2349e-02, 5.6175e-03, 1.5827e-02,
        1.3949e-01, 1.0758e-01, 4.0215e-02, 3.3725e-01, 9.3550e-02, 2.4661e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,421][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0122, 0.0435, 0.0762, 0.0615, 0.0744, 0.0758, 0.0770, 0.0788, 0.1599,
        0.1174, 0.1244, 0.0989], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,423][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0017, 0.0045, 0.0497, 0.0043, 0.0700, 0.0056, 0.0014, 0.0090, 0.0163,
        0.0122, 0.8017, 0.0237], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,424][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0175, 0.0509, 0.1096, 0.0515, 0.1033, 0.1263, 0.0569, 0.0584, 0.1764,
        0.0475, 0.0856, 0.1161], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,426][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0733, 0.0679, 0.1081, 0.0645, 0.1259, 0.0829, 0.0675, 0.0739, 0.1138,
        0.0449, 0.1089, 0.0685], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,427][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0415, 0.0718, 0.0530, 0.0942, 0.0700, 0.0580, 0.1260, 0.0653, 0.1641,
        0.1122, 0.0491, 0.0473, 0.0475], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,429][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1374, 0.0604, 0.0995, 0.0831, 0.0800, 0.0436, 0.0632, 0.0927, 0.0450,
        0.0842, 0.0736, 0.0567, 0.0804], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,429][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([2.4893e-06, 1.8224e-08, 1.4189e-05, 3.1997e-06, 1.4795e-03, 5.4228e-05,
        2.1082e-04, 6.2608e-04, 4.3969e-04, 4.4697e-03, 8.2465e-01, 1.0470e-02,
        1.5758e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,431][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0703, 0.0770, 0.0917, 0.1012, 0.1051, 0.0691, 0.0647, 0.1017, 0.0884,
        0.0418, 0.0731, 0.0705, 0.0454], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,432][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.6380, 0.0076, 0.0083, 0.0075, 0.0054, 0.0283, 0.0117, 0.0218, 0.0286,
        0.1143, 0.0498, 0.0285, 0.0503], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,434][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0140, 0.1040, 0.0844, 0.0926, 0.1812, 0.0447, 0.0408, 0.0312, 0.0736,
        0.1247, 0.1108, 0.0884, 0.0096], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,435][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0417, 0.0779, 0.1001, 0.0545, 0.0786, 0.1104, 0.0484, 0.0578, 0.1139,
        0.0773, 0.0882, 0.0935, 0.0579], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,436][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([3.9261e-05, 6.9802e-05, 6.6138e-04, 6.3386e-03, 2.8176e-03, 7.9491e-03,
        6.5090e-02, 5.8133e-02, 2.2470e-02, 1.6029e-01, 4.5694e-02, 1.2360e-01,
        5.0685e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,438][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0164, 0.0375, 0.0735, 0.0466, 0.0652, 0.0756, 0.0602, 0.0704, 0.1365,
        0.1000, 0.1268, 0.0959, 0.0953], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,439][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0013, 0.0040, 0.0433, 0.0038, 0.0661, 0.0049, 0.0009, 0.0053, 0.0128,
        0.0090, 0.7891, 0.0280, 0.0317], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,441][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0223, 0.0471, 0.0986, 0.0512, 0.0922, 0.1027, 0.0576, 0.0605, 0.1749,
        0.0489, 0.0798, 0.1039, 0.0602], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,442][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0762, 0.0676, 0.0882, 0.0862, 0.0792, 0.0865, 0.0767, 0.0612, 0.1046,
        0.0490, 0.0917, 0.0886, 0.0442], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,444][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0349, 0.0628, 0.0536, 0.0712, 0.0672, 0.0625, 0.1095, 0.0502, 0.1707,
        0.0937, 0.0476, 0.0556, 0.0379, 0.0824], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,445][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0998, 0.0712, 0.0771, 0.0730, 0.1057, 0.0541, 0.0293, 0.1030, 0.0516,
        0.1090, 0.0557, 0.0673, 0.0632, 0.0401], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,446][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([2.6687e-06, 1.0028e-08, 6.3653e-06, 2.2435e-06, 9.6339e-04, 3.7347e-05,
        1.6011e-04, 4.1949e-04, 1.6668e-04, 3.7293e-03, 3.0978e-01, 7.0278e-03,
        1.3240e-01, 5.4530e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,448][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.0442, 0.0719, 0.1030, 0.0777, 0.1084, 0.0858, 0.0301, 0.0880, 0.0984,
        0.0287, 0.0705, 0.0620, 0.0882, 0.0430], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,449][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.6315, 0.0075, 0.0081, 0.0070, 0.0052, 0.0258, 0.0105, 0.0196, 0.0268,
        0.1095, 0.0476, 0.0261, 0.0466, 0.0281], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,451][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.0102, 0.0945, 0.1585, 0.0703, 0.0883, 0.0494, 0.0339, 0.0301, 0.0353,
        0.0686, 0.1752, 0.1176, 0.0598, 0.0083], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,452][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.0315, 0.0575, 0.1006, 0.0401, 0.0741, 0.1135, 0.0378, 0.0472, 0.1006,
        0.0599, 0.0861, 0.0866, 0.0454, 0.1191], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,453][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([2.8906e-05, 1.0105e-04, 6.8858e-04, 6.4641e-03, 2.7751e-03, 6.9816e-03,
        6.0940e-02, 4.6922e-02, 1.9017e-02, 1.4147e-01, 3.9815e-02, 1.0981e-01,
        3.8956e-01, 1.7542e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,454][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.0092, 0.0370, 0.0639, 0.0521, 0.0583, 0.0604, 0.0659, 0.0635, 0.1172,
        0.0954, 0.0939, 0.0782, 0.0866, 0.1183], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,456][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.0019, 0.0050, 0.0397, 0.0063, 0.0582, 0.0075, 0.0013, 0.0126, 0.0255,
        0.0180, 0.6128, 0.0485, 0.0762, 0.0864], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,456][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.0141, 0.0419, 0.0906, 0.0405, 0.0845, 0.1062, 0.0428, 0.0484, 0.1518,
        0.0399, 0.0690, 0.0920, 0.0485, 0.1297], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,457][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.0653, 0.0473, 0.1050, 0.0485, 0.1132, 0.0854, 0.0436, 0.0427, 0.1035,
        0.0350, 0.1032, 0.0636, 0.0357, 0.1079], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,457][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0417, 0.0663, 0.0569, 0.0741, 0.0569, 0.0441, 0.0737, 0.0476, 0.1401,
        0.0837, 0.0506, 0.0411, 0.0462, 0.1104, 0.0665], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,458][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1094, 0.0524, 0.0790, 0.0698, 0.0625, 0.0402, 0.0741, 0.1071, 0.0375,
        0.0712, 0.0578, 0.0564, 0.0826, 0.0369, 0.0631], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,458][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.0111e-06, 3.8528e-09, 3.4590e-06, 9.9250e-07, 5.3797e-04, 1.8427e-05,
        6.4602e-05, 2.4226e-04, 1.4910e-04, 1.9278e-03, 2.7117e-01, 4.2902e-03,
        8.1137e-02, 4.3416e-01, 2.0630e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,459][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0733, 0.0720, 0.0833, 0.0820, 0.0749, 0.0429, 0.0264, 0.0911, 0.0673,
        0.0420, 0.0637, 0.0859, 0.1050, 0.0666, 0.0235], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,460][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.6389, 0.0057, 0.0062, 0.0055, 0.0038, 0.0231, 0.0086, 0.0175, 0.0238,
        0.1003, 0.0423, 0.0236, 0.0428, 0.0253, 0.0326], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,461][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0097, 0.0608, 0.1323, 0.0922, 0.1216, 0.0161, 0.0046, 0.0237, 0.0728,
        0.0471, 0.1519, 0.1196, 0.0259, 0.1149, 0.0069], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,462][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0380, 0.0625, 0.0801, 0.0497, 0.0625, 0.0830, 0.0419, 0.0539, 0.0947,
        0.0695, 0.0704, 0.0756, 0.0560, 0.1223, 0.0399], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,463][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.4681e-05, 2.5718e-05, 2.1087e-04, 2.0016e-03, 8.6998e-04, 2.4145e-03,
        1.9936e-02, 1.6238e-02, 5.7373e-03, 5.0109e-02, 1.2618e-02, 3.4743e-02,
        1.3249e-01, 5.3715e-02, 6.6888e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,465][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0142, 0.0317, 0.0587, 0.0382, 0.0520, 0.0604, 0.0444, 0.0574, 0.1087,
        0.0823, 0.1008, 0.0796, 0.0778, 0.1209, 0.0730], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,466][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([3.3412e-05, 2.3969e-04, 4.7837e-03, 5.9572e-04, 2.1722e-02, 3.0134e-03,
        4.4368e-05, 4.5059e-03, 1.1387e-02, 8.3931e-03, 7.1901e-01, 3.5402e-02,
        6.6672e-02, 1.0857e-01, 1.5619e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,467][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0173, 0.0415, 0.0867, 0.0460, 0.0753, 0.0877, 0.0509, 0.0527, 0.1272,
        0.0414, 0.0703, 0.0893, 0.0527, 0.1160, 0.0450], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,468][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0556, 0.0625, 0.0746, 0.0791, 0.0730, 0.0796, 0.0641, 0.0625, 0.0646,
        0.0461, 0.0750, 0.0673, 0.0443, 0.0879, 0.0638], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,487][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:49,488][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,489][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,490][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,491][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,492][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,494][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,495][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,496][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,497][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,498][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,499][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,500][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,502][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.6286, 0.3714], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,503][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9687, 0.0313], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,505][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,506][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6633, 0.3367], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,507][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0670, 0.9330], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,508][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0110, 0.9890], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,510][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3996, 0.6004], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,511][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3134, 0.6866], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,513][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2409, 0.7591], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,514][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2187, 0.7813], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,515][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9783, 0.0217], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,517][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0034, 0.9966], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,518][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.5415, 0.3842, 0.0742], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,519][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.6848, 0.3035, 0.0118], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,520][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([7.1599e-06, 1.8779e-01, 8.1220e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,522][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.3770, 0.2153, 0.4077], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,523][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.0009, 0.2121, 0.7870], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,524][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.0008, 0.5111, 0.4880], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,524][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.1690, 0.2712, 0.5598], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,524][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.2060, 0.4754, 0.3186], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,525][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.0815, 0.3029, 0.6157], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,525][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.0616, 0.4633, 0.4751], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,525][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.9237, 0.0420, 0.0343], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,526][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.0056, 0.8313, 0.1631], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,526][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1542, 0.3088, 0.4946, 0.0424], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,526][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.9489, 0.0276, 0.0143, 0.0092], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,527][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([5.9576e-07, 5.7743e-03, 6.0793e-01, 3.8629e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,528][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2851, 0.1603, 0.3069, 0.2477], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,529][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0009, 0.0684, 0.6021, 0.3286], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,531][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0012, 0.2783, 0.3384, 0.3820], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,532][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1677, 0.2695, 0.3855, 0.1774], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,533][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1631, 0.3478, 0.2522, 0.2370], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,535][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0761, 0.2217, 0.4758, 0.2263], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,536][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0582, 0.2239, 0.3755, 0.3424], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,537][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9099, 0.0228, 0.0198, 0.0474], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,539][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0027, 0.6871, 0.0958, 0.2144], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,540][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.1628, 0.1379, 0.4267, 0.1507, 0.1219], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,542][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.6476, 0.3090, 0.0099, 0.0267, 0.0068], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,543][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([1.0444e-07, 7.7663e-04, 2.4617e-02, 1.2722e-01, 8.4739e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,544][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.1781, 0.0987, 0.1980, 0.1780, 0.3473], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,545][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([3.4728e-05, 3.9013e-03, 1.3063e-01, 8.4091e-02, 7.8135e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,546][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([2.4944e-04, 1.5972e-01, 2.0193e-01, 2.7006e-01, 3.6805e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,547][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.1129, 0.1831, 0.3527, 0.1183, 0.2330], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,549][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.1304, 0.2977, 0.1959, 0.2149, 0.1610], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,550][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.0448, 0.1681, 0.3403, 0.1738, 0.2730], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,551][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.0291, 0.2171, 0.2206, 0.3453, 0.1879], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,553][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.8689, 0.0281, 0.0228, 0.0557, 0.0245], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,554][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.0041, 0.5044, 0.0897, 0.2188, 0.1829], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,556][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0957, 0.1473, 0.1744, 0.1344, 0.4216, 0.0265], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,557][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.6249, 0.2635, 0.0247, 0.0438, 0.0199, 0.0231], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,558][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([1.8642e-08, 8.4946e-05, 5.3675e-03, 4.4030e-02, 7.6700e-01, 1.8352e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,560][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.0413, 0.0174, 0.0322, 0.0272, 0.0542, 0.8277], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,561][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([5.5873e-05, 8.8659e-03, 1.8463e-02, 1.7312e-01, 5.3324e-01, 2.6626e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,562][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.0005, 0.1114, 0.1441, 0.1823, 0.3164, 0.2453], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,563][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.0951, 0.1305, 0.2567, 0.0859, 0.1904, 0.2414], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,565][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0997, 0.2438, 0.1617, 0.1747, 0.1298, 0.1902], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,566][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0331, 0.1168, 0.2354, 0.1293, 0.1927, 0.2928], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,568][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0242, 0.1353, 0.1670, 0.2049, 0.1495, 0.3192], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,569][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.8287, 0.0296, 0.0242, 0.0575, 0.0263, 0.0337], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,571][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0029, 0.4886, 0.0673, 0.1680, 0.1276, 0.1456], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,572][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1044, 0.1450, 0.2940, 0.1399, 0.2340, 0.0694, 0.0131],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,574][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.7370, 0.1681, 0.0192, 0.0266, 0.0161, 0.0138, 0.0192],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,574][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([8.4795e-09, 6.1463e-06, 1.8987e-04, 3.7554e-03, 6.8114e-02, 4.0771e-01,
        5.2022e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,576][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0177, 0.0091, 0.0159, 0.0140, 0.0272, 0.4209, 0.4952],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,577][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([5.6921e-06, 5.0311e-04, 9.0900e-03, 6.6164e-03, 7.1767e-02, 7.9961e-01,
        1.1241e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,578][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0007, 0.0833, 0.1031, 0.1423, 0.2150, 0.1805, 0.2751],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,580][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1012, 0.1392, 0.1997, 0.1087, 0.1530, 0.2164, 0.0819],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,581][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0943, 0.2007, 0.1434, 0.1404, 0.1166, 0.1690, 0.1356],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,582][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0338, 0.0954, 0.1954, 0.1028, 0.1572, 0.2400, 0.1755],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,582][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0375, 0.0923, 0.1472, 0.1363, 0.1576, 0.2889, 0.1402],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,582][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.8443, 0.0229, 0.0179, 0.0454, 0.0195, 0.0247, 0.0253],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,583][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0022, 0.4073, 0.0496, 0.1351, 0.0986, 0.1154, 0.1920],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,583][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0933, 0.0884, 0.1715, 0.1135, 0.2359, 0.0787, 0.0903, 0.1284],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,583][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.7441, 0.0700, 0.0313, 0.0265, 0.0323, 0.0230, 0.0299, 0.0429],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,584][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([4.1254e-10, 3.8705e-07, 5.9931e-05, 3.8255e-04, 1.0159e-02, 2.5575e-02,
        8.6550e-01, 9.8323e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,585][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0106, 0.0049, 0.0090, 0.0084, 0.0162, 0.2179, 0.2643, 0.4687],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,586][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([1.0113e-05, 8.3535e-04, 1.6715e-02, 1.2155e-02, 1.3360e-01, 2.2519e-01,
        3.5083e-01, 2.6067e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,587][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0005, 0.0588, 0.0696, 0.0995, 0.1492, 0.1442, 0.2367, 0.2414],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,589][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0887, 0.1253, 0.1833, 0.0932, 0.1363, 0.2197, 0.0752, 0.0783],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,590][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0814, 0.1765, 0.1234, 0.1259, 0.0977, 0.1453, 0.1191, 0.1306],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,592][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0279, 0.0785, 0.1648, 0.0852, 0.1296, 0.2053, 0.1538, 0.1550],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,593][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0332, 0.0819, 0.1285, 0.1204, 0.1375, 0.2434, 0.1249, 0.1303],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,594][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.8154, 0.0238, 0.0189, 0.0480, 0.0204, 0.0269, 0.0269, 0.0197],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,596][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0021, 0.3186, 0.0449, 0.1045, 0.0855, 0.0987, 0.1541, 0.1915],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,597][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([0.0329, 0.0636, 0.1183, 0.0650, 0.2901, 0.0600, 0.0478, 0.2217, 0.1005],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,599][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([0.2763, 0.3816, 0.0235, 0.0634, 0.0162, 0.0314, 0.0378, 0.1510, 0.0188],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,600][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([3.1745e-11, 1.0598e-07, 1.4798e-05, 8.4613e-05, 1.6038e-02, 2.1609e-02,
        4.0885e-01, 4.0462e-01, 1.4879e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,601][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([0.0058, 0.0026, 0.0048, 0.0046, 0.0087, 0.1122, 0.1324, 0.2517, 0.4771],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,602][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([7.6534e-07, 2.0951e-04, 2.0573e-03, 3.5195e-03, 8.1018e-02, 9.8411e-02,
        1.4690e-01, 2.4351e-01, 4.2438e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,603][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([0.0004, 0.0391, 0.0494, 0.0635, 0.0957, 0.0901, 0.1543, 0.1887, 0.3189],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,605][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([0.0546, 0.0891, 0.2009, 0.0640, 0.1167, 0.2097, 0.0498, 0.0630, 0.1522],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,606][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([0.0672, 0.1515, 0.1077, 0.1148, 0.0857, 0.1309, 0.1092, 0.1152, 0.1178],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,608][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([0.0174, 0.0612, 0.1141, 0.0689, 0.0875, 0.1355, 0.1394, 0.1210, 0.2550],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,609][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([0.0157, 0.0923, 0.0834, 0.1345, 0.0724, 0.1709, 0.1260, 0.1188, 0.1860],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,611][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([0.7990, 0.0208, 0.0171, 0.0426, 0.0186, 0.0243, 0.0247, 0.0173, 0.0356],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,612][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([0.0022, 0.2602, 0.0336, 0.1005, 0.0710, 0.0702, 0.1455, 0.1672, 0.1496],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,613][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0606, 0.0361, 0.0859, 0.0424, 0.1453, 0.0851, 0.0313, 0.3296, 0.1235,
        0.0602], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,615][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.6957, 0.0583, 0.0308, 0.0253, 0.0342, 0.0223, 0.0308, 0.0416, 0.0243,
        0.0367], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,616][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([2.6022e-10, 2.0681e-08, 6.9123e-06, 2.3097e-05, 1.7845e-03, 1.7761e-03,
        1.7418e-02, 5.8856e-02, 1.4187e-01, 7.7826e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,618][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0061, 0.0019, 0.0037, 0.0033, 0.0061, 0.0604, 0.0736, 0.1414, 0.2718,
        0.4316], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,618][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([5.8683e-06, 1.9844e-04, 6.1745e-03, 5.8674e-03, 4.5935e-02, 4.6878e-02,
        7.3379e-02, 2.4089e-01, 1.4772e-01, 4.3295e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,620][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0007, 0.0300, 0.0322, 0.0487, 0.0582, 0.0677, 0.1059, 0.1254, 0.2327,
        0.2985], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,621][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0574, 0.0979, 0.1528, 0.0706, 0.1068, 0.1353, 0.0588, 0.0694, 0.1421,
        0.1089], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,623][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0657, 0.1400, 0.1029, 0.0999, 0.0820, 0.1159, 0.0947, 0.1050, 0.1054,
        0.0887], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,624][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0181, 0.0504, 0.1024, 0.0584, 0.0819, 0.1230, 0.1012, 0.1005, 0.2391,
        0.1248], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,626][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0226, 0.0539, 0.0776, 0.0809, 0.0806, 0.1417, 0.0833, 0.0872, 0.2541,
        0.1180], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,627][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.7355, 0.0230, 0.0193, 0.0443, 0.0207, 0.0274, 0.0262, 0.0194, 0.0383,
        0.0458], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,629][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0020, 0.2412, 0.0360, 0.0788, 0.0684, 0.0685, 0.1001, 0.1322, 0.1516,
        0.1211], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,630][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.0734, 0.0343, 0.0119, 0.0337, 0.1315, 0.0547, 0.0407, 0.1813, 0.1294,
        0.2443, 0.0649], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,632][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.5228, 0.2616, 0.0145, 0.0358, 0.0104, 0.0140, 0.0239, 0.0579, 0.0083,
        0.0391, 0.0117], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,633][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([5.6008e-11, 8.3192e-09, 1.1173e-07, 2.6114e-06, 7.3329e-05, 1.7891e-04,
        1.3350e-03, 4.2817e-03, 6.3153e-03, 2.0321e-01, 7.8460e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,634][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.0018, 0.0006, 0.0011, 0.0011, 0.0020, 0.0242, 0.0309, 0.0570, 0.1141,
        0.2298, 0.5376], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,635][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([1.1459e-06, 3.8722e-05, 1.9839e-04, 7.5469e-04, 7.8207e-03, 1.9107e-03,
        1.4862e-02, 3.4018e-02, 1.2515e-02, 1.8168e-01, 7.4620e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,636][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([1.3655e-04, 1.6330e-02, 1.4519e-02, 2.6560e-02, 3.3699e-02, 4.2289e-02,
        6.6377e-02, 8.7175e-02, 1.7450e-01, 2.8718e-01, 2.5123e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,637][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.0489, 0.0777, 0.1586, 0.0453, 0.1142, 0.1785, 0.0390, 0.0386, 0.1124,
        0.0659, 0.1209], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,638][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.0580, 0.1268, 0.0903, 0.0927, 0.0746, 0.1123, 0.0881, 0.0992, 0.1044,
        0.0856, 0.0679], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,639][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.0109, 0.0392, 0.0787, 0.0428, 0.0641, 0.0998, 0.0913, 0.0813, 0.2345,
        0.1116, 0.1458], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,639][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.0089, 0.0630, 0.0579, 0.0985, 0.0509, 0.1438, 0.0840, 0.0851, 0.1990,
        0.1223, 0.0866], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,640][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.6954, 0.0224, 0.0197, 0.0413, 0.0209, 0.0261, 0.0244, 0.0188, 0.0356,
        0.0433, 0.0520], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,640][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.0017, 0.1933, 0.0276, 0.0843, 0.0554, 0.0647, 0.1079, 0.1400, 0.1072,
        0.1378, 0.0801], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,640][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0289, 0.0211, 0.0481, 0.0219, 0.1214, 0.0874, 0.0198, 0.0824, 0.1125,
        0.1903, 0.2501, 0.0161], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,641][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.4551, 0.1716, 0.0243, 0.0439, 0.0206, 0.0242, 0.0312, 0.0867, 0.0207,
        0.0730, 0.0245, 0.0243], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,641][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([4.6510e-12, 4.0362e-10, 2.9453e-08, 1.9986e-07, 4.2668e-06, 3.1181e-06,
        9.0726e-05, 2.9456e-04, 1.3601e-03, 3.7369e-02, 4.2253e-01, 5.3835e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,642][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([7.8432e-04, 2.2039e-04, 4.5825e-04, 4.1030e-04, 8.2069e-04, 1.1369e-02,
        1.4036e-02, 2.6066e-02, 5.6235e-02, 1.3016e-01, 3.1132e-01, 4.4812e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,643][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([5.4804e-07, 2.1410e-05, 1.0592e-04, 3.5019e-04, 8.9805e-04, 7.8330e-04,
        5.1686e-03, 8.6508e-03, 7.3661e-03, 8.7842e-02, 3.1654e-01, 5.7227e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,644][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([2.0191e-04, 1.4321e-02, 1.7056e-02, 2.3740e-02, 3.5711e-02, 3.3297e-02,
        5.3055e-02, 7.0904e-02, 1.3879e-01, 2.2578e-01, 2.4904e-01, 1.3810e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,645][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0499, 0.0706, 0.1331, 0.0455, 0.0924, 0.1425, 0.0384, 0.0440, 0.1181,
        0.0647, 0.1041, 0.0968], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,647][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0536, 0.1225, 0.0843, 0.0871, 0.0687, 0.1036, 0.0849, 0.0888, 0.0895,
        0.0772, 0.0629, 0.0771], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,648][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0094, 0.0327, 0.0694, 0.0384, 0.0557, 0.0870, 0.0809, 0.0740, 0.2073,
        0.1044, 0.1332, 0.1078], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,649][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0101, 0.0507, 0.0577, 0.0772, 0.0521, 0.1141, 0.0704, 0.0708, 0.1738,
        0.1004, 0.0958, 0.1267], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,651][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.6984, 0.0191, 0.0168, 0.0377, 0.0177, 0.0231, 0.0229, 0.0164, 0.0320,
        0.0390, 0.0444, 0.0325], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,652][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0018, 0.2403, 0.0218, 0.0701, 0.0416, 0.0517, 0.0986, 0.1093, 0.0905,
        0.1255, 0.0528, 0.0962], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,654][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0358, 0.0339, 0.0347, 0.0476, 0.0681, 0.0176, 0.0235, 0.0915, 0.0907,
        0.2651, 0.1875, 0.0656, 0.0384], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,655][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.6423, 0.0555, 0.0268, 0.0237, 0.0288, 0.0192, 0.0251, 0.0386, 0.0211,
        0.0346, 0.0280, 0.0187, 0.0375], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,656][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.1136e-12, 3.3950e-11, 3.1353e-09, 2.2102e-08, 6.8597e-07, 1.1723e-06,
        2.7373e-05, 2.2859e-05, 1.0468e-04, 1.2005e-03, 2.7431e-02, 6.9538e-01,
        2.7584e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,657][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([5.0318e-04, 1.7713e-04, 3.6433e-04, 3.4260e-04, 6.7012e-04, 8.8292e-03,
        1.1183e-02, 2.0485e-02, 4.1827e-02, 9.9933e-02, 2.3111e-01, 3.4142e-01,
        2.4315e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,658][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([2.8580e-07, 4.4503e-06, 4.7165e-05, 5.4201e-05, 8.9157e-04, 4.9878e-04,
        9.1952e-04, 1.0881e-03, 1.9068e-03, 1.6234e-02, 8.3836e-02, 6.8948e-01,
        2.0504e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,660][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0004, 0.0148, 0.0155, 0.0231, 0.0294, 0.0313, 0.0512, 0.0613, 0.1164,
        0.1851, 0.1793, 0.1317, 0.1604], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,661][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0465, 0.0738, 0.1087, 0.0514, 0.0821, 0.1287, 0.0423, 0.0470, 0.1185,
        0.0671, 0.0874, 0.1006, 0.0458], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,663][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0524, 0.1116, 0.0796, 0.0794, 0.0642, 0.0915, 0.0751, 0.0832, 0.0849,
        0.0711, 0.0603, 0.0699, 0.0768], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,664][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0108, 0.0312, 0.0683, 0.0355, 0.0537, 0.0842, 0.0652, 0.0663, 0.1795,
        0.0864, 0.1258, 0.1035, 0.0896], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,665][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0146, 0.0350, 0.0512, 0.0513, 0.0552, 0.1005, 0.0502, 0.0525, 0.1972,
        0.0845, 0.1175, 0.1282, 0.0620], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,667][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.7217, 0.0144, 0.0127, 0.0301, 0.0135, 0.0182, 0.0177, 0.0125, 0.0255,
        0.0330, 0.0364, 0.0263, 0.0379], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,668][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0019, 0.1981, 0.0222, 0.0611, 0.0394, 0.0451, 0.0807, 0.0949, 0.0913,
        0.1002, 0.0484, 0.0896, 0.1271], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,670][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.0194, 0.0214, 0.0573, 0.0248, 0.0709, 0.0364, 0.0230, 0.0581, 0.1399,
        0.0942, 0.2452, 0.1098, 0.0375, 0.0620], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,671][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.3229, 0.1426, 0.0255, 0.0462, 0.0218, 0.0287, 0.0386, 0.0950, 0.0249,
        0.0827, 0.0264, 0.0310, 0.0900, 0.0237], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,672][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([2.4556e-14, 1.1252e-12, 4.7877e-11, 5.4924e-10, 2.4887e-08, 2.1397e-08,
        1.5945e-06, 7.6741e-07, 4.0733e-06, 1.7136e-04, 1.6599e-03, 3.4894e-02,
        1.9630e-01, 7.6696e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,673][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([3.0466e-04, 1.0498e-04, 2.1358e-04, 2.1696e-04, 4.1365e-04, 5.8792e-03,
        7.1086e-03, 1.3697e-02, 2.6983e-02, 6.3266e-02, 1.3475e-01, 2.1117e-01,
        1.5637e-01, 3.7952e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,674][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([4.2781e-08, 1.0548e-06, 3.2517e-06, 1.8721e-05, 1.6033e-04, 4.8227e-05,
        5.5203e-04, 7.9009e-04, 6.8935e-04, 1.1875e-02, 1.0993e-02, 2.0552e-01,
        3.3446e-01, 4.3489e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,676][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([0.0002, 0.0105, 0.0124, 0.0158, 0.0203, 0.0251, 0.0381, 0.0457, 0.0924,
        0.1489, 0.1605, 0.1152, 0.1559, 0.1590], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,677][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.0334, 0.0495, 0.1128, 0.0344, 0.0757, 0.1300, 0.0318, 0.0363, 0.0986,
        0.0492, 0.0872, 0.0917, 0.0344, 0.1349], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,679][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.0437, 0.1015, 0.0708, 0.0762, 0.0566, 0.0873, 0.0721, 0.0772, 0.0800,
        0.0680, 0.0524, 0.0660, 0.0724, 0.0756], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,680][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.0085, 0.0302, 0.0596, 0.0340, 0.0451, 0.0699, 0.0733, 0.0629, 0.1401,
        0.0826, 0.0960, 0.0803, 0.0844, 0.1330], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,682][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.0095, 0.0517, 0.0482, 0.0765, 0.0418, 0.0991, 0.0683, 0.0668, 0.1187,
        0.0860, 0.0629, 0.0978, 0.0679, 0.1048], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,683][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.6910, 0.0131, 0.0120, 0.0270, 0.0127, 0.0170, 0.0159, 0.0115, 0.0231,
        0.0307, 0.0349, 0.0250, 0.0353, 0.0506], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,685][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([0.0020, 0.1520, 0.0194, 0.0533, 0.0358, 0.0368, 0.0679, 0.0745, 0.0756,
        0.0859, 0.0418, 0.0712, 0.1114, 0.1724], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,686][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0215, 0.0239, 0.0485, 0.0288, 0.0325, 0.0128, 0.0029, 0.0561, 0.0732,
        0.1365, 0.3003, 0.0670, 0.0583, 0.1264, 0.0113], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,688][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.6545, 0.0979, 0.0186, 0.0226, 0.0174, 0.0121, 0.0178, 0.0323, 0.0112,
        0.0234, 0.0166, 0.0098, 0.0268, 0.0098, 0.0293], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,689][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.1072e-13, 3.3943e-13, 1.2963e-11, 1.3274e-10, 3.6283e-09, 1.0258e-08,
        9.3575e-09, 2.9715e-07, 1.1879e-06, 6.1327e-06, 1.0348e-04, 7.6654e-03,
        2.3611e-02, 4.1399e-01, 5.5462e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,690][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.7384e-04, 6.3734e-05, 1.2600e-04, 1.2899e-04, 2.3795e-04, 3.4165e-03,
        4.0565e-03, 8.3960e-03, 1.6116e-02, 3.8718e-02, 8.2462e-02, 1.3115e-01,
        1.0107e-01, 2.4869e-01, 3.6519e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,691][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([3.9985e-08, 3.1787e-07, 4.3202e-06, 2.5102e-06, 2.3450e-05, 2.1415e-04,
        3.0528e-05, 9.5705e-05, 4.9006e-04, 6.1172e-04, 8.8433e-03, 1.1013e-01,
        3.0906e-02, 6.4865e-01, 2.0000e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,692][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0003, 0.0111, 0.0113, 0.0169, 0.0196, 0.0199, 0.0294, 0.0422, 0.0799,
        0.1281, 0.1158, 0.0895, 0.1266, 0.1537, 0.1556], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,693][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0428, 0.0611, 0.0884, 0.0481, 0.0662, 0.0966, 0.0358, 0.0443, 0.0968,
        0.0608, 0.0705, 0.0819, 0.0444, 0.1312, 0.0313], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,695][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0460, 0.0953, 0.0700, 0.0687, 0.0581, 0.0814, 0.0662, 0.0718, 0.0735,
        0.0615, 0.0534, 0.0626, 0.0671, 0.0733, 0.0511], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,696][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0095, 0.0260, 0.0527, 0.0288, 0.0415, 0.0655, 0.0470, 0.0530, 0.1395,
        0.0711, 0.0959, 0.0842, 0.0710, 0.1492, 0.0652], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,697][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0132, 0.0255, 0.0380, 0.0372, 0.0419, 0.0762, 0.0354, 0.0413, 0.1613,
        0.0684, 0.0976, 0.1032, 0.0493, 0.1672, 0.0444], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,697][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.6682, 0.0132, 0.0114, 0.0266, 0.0121, 0.0155, 0.0149, 0.0111, 0.0219,
        0.0291, 0.0333, 0.0232, 0.0340, 0.0482, 0.0373], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,698][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0016, 0.1807, 0.0162, 0.0486, 0.0294, 0.0348, 0.0561, 0.0722, 0.0584,
        0.0766, 0.0291, 0.0606, 0.0878, 0.1242, 0.1237], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,699][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:49,700][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[21468],
        [45726],
        [45577],
        [46582],
        [41021],
        [45992],
        [43383],
        [44779],
        [44339],
        [39408],
        [46222],
        [45484],
        [44204],
        [41207],
        [42961]], device='cuda:0')
[2024-07-24 10:21:49,702][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[28903],
        [36211],
        [46084],
        [33510],
        [42031],
        [40297],
        [41527],
        [42633],
        [46900],
        [35954],
        [49226],
        [38031],
        [43269],
        [41404],
        [44266]], device='cuda:0')
[2024-07-24 10:21:49,703][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[40739],
        [42577],
        [43153],
        [44194],
        [42155],
        [41495],
        [41777],
        [41822],
        [41336],
        [41282],
        [41166],
        [41352],
        [41764],
        [41508],
        [41861]], device='cuda:0')
[2024-07-24 10:21:49,705][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[32319],
        [30700],
        [15158],
        [11109],
        [ 1286],
        [ 3403],
        [ 4041],
        [ 3898],
        [ 2504],
        [ 2616],
        [ 1784],
        [ 2731],
        [ 2585],
        [ 1736],
        [ 3262]], device='cuda:0')
[2024-07-24 10:21:49,706][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 9101],
        [ 8452],
        [ 3622],
        [ 3232],
        [ 6492],
        [ 6411],
        [ 6637],
        [ 6803],
        [ 7881],
        [ 8581],
        [18828],
        [18868],
        [17038],
        [19335],
        [20038]], device='cuda:0')
[2024-07-24 10:21:49,708][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[1761],
        [1500],
        [2085],
        [2128],
        [1962],
        [2262],
        [2434],
        [2517],
        [3032],
        [2923],
        [3027],
        [2824],
        [3054],
        [3848],
        [3404]], device='cuda:0')
[2024-07-24 10:21:49,709][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[26979],
        [27121],
        [27239],
        [27234],
        [27316],
        [27961],
        [27614],
        [28096],
        [28653],
        [29426],
        [29440],
        [29835],
        [29946],
        [30305],
        [30283]], device='cuda:0')
[2024-07-24 10:21:49,710][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[23125],
        [40043],
        [39709],
        [33296],
        [34633],
        [29481],
        [28200],
        [29742],
        [29152],
        [33151],
        [36274],
        [32247],
        [32336],
        [31729],
        [30208]], device='cuda:0')
[2024-07-24 10:21:49,712][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[9250],
        [6072],
        [6400],
        [5724],
        [7429],
        [8822],
        [8024],
        [7908],
        [8961],
        [8401],
        [8624],
        [9315],
        [8873],
        [8986],
        [8441]], device='cuda:0')
[2024-07-24 10:21:49,713][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[47261],
        [ 8092],
        [15959],
        [43781],
        [30089],
        [29704],
        [40479],
        [36864],
        [35013],
        [41250],
        [37296],
        [36692],
        [25243],
        [26013],
        [35822]], device='cuda:0')
[2024-07-24 10:21:49,715][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[24819],
        [30061],
        [27880],
        [28915],
        [28652],
        [28703],
        [29392],
        [29057],
        [29343],
        [29028],
        [28647],
        [28652],
        [28414],
        [28632],
        [28724]], device='cuda:0')
[2024-07-24 10:21:49,716][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[10259],
        [14500],
        [22018],
        [19481],
        [23258],
        [24922],
        [23503],
        [22307],
        [20102],
        [13827],
        [ 6688],
        [15941],
        [14789],
        [ 8367],
        [ 9292]], device='cuda:0')
[2024-07-24 10:21:49,718][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[41534],
        [29140],
        [27402],
        [29869],
        [29630],
        [30822],
        [30246],
        [30221],
        [27960],
        [27239],
        [27266],
        [26622],
        [26852],
        [25523],
        [25550]], device='cuda:0')
[2024-07-24 10:21:49,719][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[33059],
        [29099],
        [16362],
        [16372],
        [15901],
        [13891],
        [13182],
        [14572],
        [12373],
        [12475],
        [10967],
        [11054],
        [10722],
        [10052],
        [10384]], device='cuda:0')
[2024-07-24 10:21:49,720][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[17613],
        [48490],
        [48733],
        [49673],
        [48516],
        [49890],
        [48975],
        [49787],
        [48776],
        [49557],
        [48409],
        [49981],
        [49505],
        [49790],
        [49178]], device='cuda:0')
[2024-07-24 10:21:49,722][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[21051],
        [36060],
        [35779],
        [32164],
        [29747],
        [31430],
        [31927],
        [32401],
        [30015],
        [31130],
        [34249],
        [33696],
        [31946],
        [32683],
        [32063]], device='cuda:0')
[2024-07-24 10:21:49,723][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[29699],
        [29549],
        [28419],
        [29529],
        [28283],
        [28495],
        [28826],
        [29159],
        [28488],
        [29402],
        [28529],
        [29260],
        [29549],
        [29986],
        [29174]], device='cuda:0')
[2024-07-24 10:21:49,725][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[10115],
        [ 9018],
        [24384],
        [24662],
        [26118],
        [30543],
        [43383],
        [46931],
        [24842],
        [12406],
        [32191],
        [22583],
        [15644],
        [12046],
        [44203]], device='cuda:0')
[2024-07-24 10:21:49,726][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[16259],
        [15653],
        [14141],
        [13645],
        [12849],
        [11364],
        [11801],
        [12507],
        [12525],
        [12832],
        [12144],
        [11484],
        [11777],
        [11846],
        [11680]], device='cuda:0')
[2024-07-24 10:21:49,728][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 7787],
        [ 8600],
        [28739],
        [21454],
        [34432],
        [27204],
        [17754],
        [ 9953],
        [15432],
        [ 8699],
        [28648],
        [22396],
        [15787],
        [ 8998],
        [ 8111]], device='cuda:0')
[2024-07-24 10:21:49,729][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[12809],
        [12427],
        [ 9631],
        [10391],
        [ 9977],
        [ 9599],
        [ 9763],
        [10326],
        [11079],
        [11760],
        [10798],
        [10463],
        [10672],
        [10908],
        [11037]], device='cuda:0')
[2024-07-24 10:21:49,730][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[16801],
        [10700],
        [ 8149],
        [ 7164],
        [ 6857],
        [ 7264],
        [ 6754],
        [ 6320],
        [ 6433],
        [ 5601],
        [ 6294],
        [ 6296],
        [ 5968],
        [ 6368],
        [ 5857]], device='cuda:0')
[2024-07-24 10:21:49,732][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[39305],
        [37294],
        [38831],
        [39335],
        [38974],
        [38771],
        [39043],
        [38776],
        [37929],
        [37524],
        [37738],
        [37794],
        [37856],
        [37656],
        [37884]], device='cuda:0')
[2024-07-24 10:21:49,733][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[28566],
        [28514],
        [25060],
        [25360],
        [23762],
        [23503],
        [23454],
        [23027],
        [21414],
        [21444],
        [21428],
        [21490],
        [21508],
        [21020],
        [20863]], device='cuda:0')
[2024-07-24 10:21:49,735][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[13553],
        [11502],
        [ 9839],
        [10108],
        [ 9595],
        [ 9718],
        [ 9396],
        [ 9175],
        [ 9041],
        [ 8969],
        [ 9026],
        [ 8957],
        [ 8807],
        [ 8887],
        [ 8658]], device='cuda:0')
[2024-07-24 10:21:49,736][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[37081],
        [36609],
        [35568],
        [35110],
        [34541],
        [34458],
        [34874],
        [34821],
        [35529],
        [36191],
        [35723],
        [36025],
        [36347],
        [36397],
        [36459]], device='cuda:0')
[2024-07-24 10:21:49,737][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[41813],
        [16356],
        [16546],
        [17882],
        [19513],
        [20346],
        [20732],
        [22066],
        [21038],
        [20446],
        [20821],
        [21172],
        [21291],
        [20072],
        [20611]], device='cuda:0')
[2024-07-24 10:21:49,739][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[29869],
        [32411],
        [26911],
        [28216],
        [27856],
        [28604],
        [27902],
        [28809],
        [31398],
        [36453],
        [27798],
        [30298],
        [33076],
        [34614],
        [29537]], device='cuda:0')
[2024-07-24 10:21:49,740][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[18821],
        [ 7218],
        [ 3230],
        [ 6541],
        [ 5515],
        [ 6344],
        [ 5489],
        [ 3482],
        [ 4457],
        [ 4608],
        [ 2733],
        [ 4538],
        [ 3284],
        [ 4576],
        [ 4256]], device='cuda:0')
[2024-07-24 10:21:49,742][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[19423],
        [19423],
        [19423],
        [19423],
        [19423],
        [19423],
        [19423],
        [19423],
        [19423],
        [19423],
        [19423],
        [19423],
        [19423],
        [19423],
        [19423]], device='cuda:0')
[2024-07-24 10:21:49,774][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:49,775][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,776][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,777][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,779][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,780][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,781][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,782][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,783][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,784][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,785][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,787][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,788][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:49,789][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8536, 0.1464], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,790][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.4021, 0.5979], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,792][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4380, 0.5620], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,793][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0274, 0.9726], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,794][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0344, 0.9656], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,796][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9686, 0.0314], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,797][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4594, 0.5406], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,798][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2790, 0.7210], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,800][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0660, 0.9340], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,801][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2215, 0.7785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,802][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4334, 0.5666], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,804][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.8621, 0.1379], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:49,805][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.8288, 0.0493, 0.1219], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,807][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.2545, 0.3857, 0.3598], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,808][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.2993, 0.3768, 0.3239], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,809][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.0130, 0.8059, 0.1811], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,811][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.0517, 0.4073, 0.5410], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,812][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.8143, 0.0675, 0.1182], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,813][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.2881, 0.3398, 0.3721], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,813][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.1910, 0.4416, 0.3674], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,814][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.0574, 0.8797, 0.0629], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,814][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.1141, 0.6631, 0.2228], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,814][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.2819, 0.3722, 0.3459], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,815][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.7347, 0.1148, 0.1505], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:49,815][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7045, 0.1165, 0.0207, 0.1583], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,815][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1866, 0.2749, 0.2611, 0.2775], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,816][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2108, 0.2704, 0.2509, 0.2679], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,817][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0129, 0.4999, 0.1193, 0.3680], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,818][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0205, 0.4557, 0.3171, 0.2066], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,820][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.8574, 0.0195, 0.0694, 0.0536], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,821][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2127, 0.2499, 0.2736, 0.2639], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,823][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1189, 0.3209, 0.2985, 0.2617], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,824][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0269, 0.6401, 0.1659, 0.1671], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,825][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0723, 0.3877, 0.1277, 0.4123], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,827][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2219, 0.2819, 0.2444, 0.2517], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,828][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.5810, 0.1323, 0.1361, 0.1506], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:49,829][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.7267, 0.0636, 0.0224, 0.0640, 0.1233], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,831][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.1442, 0.2233, 0.2064, 0.2209, 0.2054], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,832][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.1738, 0.2218, 0.1949, 0.2229, 0.1866], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,834][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0085, 0.4463, 0.1025, 0.4096, 0.0332], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,835][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.0448, 0.3489, 0.3294, 0.1047, 0.1722], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,837][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.6938, 0.0488, 0.0760, 0.0998, 0.0816], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,838][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.1666, 0.1978, 0.2168, 0.2091, 0.2096], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,839][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.1020, 0.2580, 0.2280, 0.2192, 0.1928], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,841][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.0284, 0.5569, 0.0730, 0.3200, 0.0217], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,842][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0368, 0.3616, 0.0903, 0.4546, 0.0567], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,843][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.1688, 0.2187, 0.2013, 0.2045, 0.2068], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,845][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.8150, 0.0069, 0.0179, 0.0134, 0.1468], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:49,846][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.8733, 0.0348, 0.0082, 0.0350, 0.0164, 0.0324], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,848][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.1192, 0.1813, 0.1691, 0.1814, 0.1665, 0.1826], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,849][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.1437, 0.1829, 0.1630, 0.1857, 0.1623, 0.1624], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,850][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0159, 0.3356, 0.0839, 0.2704, 0.0285, 0.2655], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,852][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0569, 0.1924, 0.3109, 0.0896, 0.2319, 0.1183], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,853][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.6209, 0.0391, 0.0781, 0.0810, 0.0865, 0.0944], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,855][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.1385, 0.1626, 0.1790, 0.1726, 0.1736, 0.1737], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,856][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0844, 0.2131, 0.1861, 0.1809, 0.1845, 0.1510], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,858][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0263, 0.4556, 0.0906, 0.3042, 0.0609, 0.0623], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,859][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0437, 0.3159, 0.0505, 0.3735, 0.0579, 0.1585], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,860][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.1406, 0.1879, 0.1800, 0.1685, 0.1775, 0.1456], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,862][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.7618, 0.0142, 0.0059, 0.0291, 0.1019, 0.0871], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:49,863][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.5713, 0.0794, 0.0217, 0.0861, 0.0452, 0.0340, 0.1623],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,865][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0984, 0.1509, 0.1443, 0.1549, 0.1395, 0.1555, 0.1565],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,866][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1196, 0.1544, 0.1449, 0.1572, 0.1400, 0.1493, 0.1346],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,868][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0192, 0.1449, 0.0429, 0.1075, 0.0141, 0.1703, 0.5010],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,869][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0117, 0.2579, 0.1279, 0.1239, 0.2964, 0.1069, 0.0754],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,870][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.6622, 0.0235, 0.0568, 0.0494, 0.0670, 0.0605, 0.0806],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,872][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1173, 0.1387, 0.1527, 0.1469, 0.1480, 0.1484, 0.1480],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,873][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0663, 0.1840, 0.1765, 0.1532, 0.1647, 0.1498, 0.1055],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,875][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0106, 0.4896, 0.0773, 0.1998, 0.0264, 0.0921, 0.1043],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,875][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0483, 0.2279, 0.0452, 0.2793, 0.0267, 0.2613, 0.1113],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,875][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1241, 0.1648, 0.1493, 0.1505, 0.1566, 0.1212, 0.1336],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,876][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.7595, 0.0014, 0.0029, 0.0039, 0.0551, 0.0195, 0.1577],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:49,876][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.5077, 0.0763, 0.0149, 0.0940, 0.0380, 0.0273, 0.1077, 0.1342],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,877][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0875, 0.1281, 0.1236, 0.1310, 0.1207, 0.1323, 0.1337, 0.1431],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,877][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1038, 0.1326, 0.1218, 0.1345, 0.1194, 0.1279, 0.1209, 0.1391],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,877][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0047, 0.0815, 0.0244, 0.0756, 0.0084, 0.0975, 0.3606, 0.3473],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,878][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0174, 0.2205, 0.1596, 0.0869, 0.2910, 0.1056, 0.0633, 0.0557],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,879][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.6130, 0.0196, 0.0575, 0.0452, 0.0712, 0.0656, 0.0793, 0.0485],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,880][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1038, 0.1210, 0.1335, 0.1290, 0.1294, 0.1296, 0.1294, 0.1244],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,881][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0632, 0.1584, 0.1510, 0.1343, 0.1455, 0.1326, 0.0977, 0.1173],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,883][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0156, 0.4017, 0.0723, 0.1753, 0.0397, 0.0853, 0.1818, 0.0282],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,884][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0468, 0.1843, 0.0567, 0.2528, 0.0483, 0.1622, 0.2018, 0.0472],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,886][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1113, 0.1387, 0.1301, 0.1265, 0.1385, 0.1100, 0.1071, 0.1378],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,887][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ the] are: tensor([9.1147e-01, 1.3117e-04, 5.3827e-04, 2.4054e-04, 7.6239e-03, 9.9279e-04,
        2.4279e-02, 5.4726e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:49,888][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ house] are: tensor([0.4483, 0.0752, 0.0203, 0.0952, 0.0454, 0.0190, 0.1116, 0.0805, 0.1046],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,890][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ house] are: tensor([0.0743, 0.1124, 0.1050, 0.1132, 0.1032, 0.1144, 0.1165, 0.1264, 0.1345],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,891][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.0921, 0.1167, 0.1058, 0.1179, 0.1038, 0.1124, 0.1068, 0.1303, 0.1142],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,892][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ house] are: tensor([0.0033, 0.1201, 0.0279, 0.1013, 0.0086, 0.0898, 0.3007, 0.3125, 0.0358],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,894][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ house] are: tensor([0.0348, 0.1114, 0.2704, 0.0353, 0.2230, 0.1453, 0.0380, 0.0425, 0.0993],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,895][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ house] are: tensor([0.4309, 0.0347, 0.0627, 0.0813, 0.0693, 0.0749, 0.0948, 0.0786, 0.0727],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,897][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ house] are: tensor([0.0918, 0.1071, 0.1185, 0.1144, 0.1148, 0.1151, 0.1151, 0.1105, 0.1126],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,898][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ house] are: tensor([0.0565, 0.1417, 0.1289, 0.1223, 0.1267, 0.1237, 0.0881, 0.1095, 0.1026],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,900][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.0138, 0.3681, 0.0526, 0.2217, 0.0254, 0.0573, 0.1813, 0.0371, 0.0425],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,901][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ house] are: tensor([0.0218, 0.2200, 0.0563, 0.2190, 0.0284, 0.1579, 0.1703, 0.0672, 0.0592],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,902][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.0968, 0.1228, 0.1175, 0.1138, 0.1276, 0.1021, 0.1003, 0.1193, 0.0999],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,903][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ house] are: tensor([2.5288e-01, 3.7065e-04, 6.8755e-04, 5.2782e-04, 1.6899e-02, 3.9091e-03,
        1.0693e-01, 5.2636e-01, 9.1446e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:49,905][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.2926, 0.0810, 0.0259, 0.0983, 0.0618, 0.0296, 0.1303, 0.1053, 0.0447,
        0.1304], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,907][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0684, 0.0984, 0.0947, 0.1016, 0.0932, 0.1023, 0.1068, 0.1137, 0.1190,
        0.1020], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,908][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0829, 0.1048, 0.0953, 0.1069, 0.0938, 0.0997, 0.0973, 0.1169, 0.1101,
        0.0922], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,909][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0072, 0.0451, 0.0133, 0.0401, 0.0048, 0.0551, 0.2118, 0.2099, 0.0374,
        0.3751], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,911][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0030, 0.1477, 0.1713, 0.0362, 0.2995, 0.1169, 0.0322, 0.0365, 0.1181,
        0.0386], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,912][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.5260, 0.0174, 0.0489, 0.0455, 0.0621, 0.0558, 0.0691, 0.0483, 0.0520,
        0.0748], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,914][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0829, 0.0965, 0.1069, 0.1031, 0.1034, 0.1036, 0.1035, 0.0995, 0.1015,
        0.0989], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,915][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0515, 0.1232, 0.1218, 0.1048, 0.1156, 0.1078, 0.0779, 0.0986, 0.0967,
        0.1019], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,917][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0137, 0.2938, 0.0676, 0.1090, 0.0198, 0.0586, 0.1048, 0.0414, 0.1214,
        0.1699], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,918][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0342, 0.1493, 0.0524, 0.2266, 0.0346, 0.1081, 0.1088, 0.0958, 0.0896,
        0.1006], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,919][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0931, 0.1159, 0.1021, 0.1053, 0.1084, 0.0817, 0.0890, 0.1082, 0.0823,
        0.1141], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,920][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [.] are: tensor([8.0621e-01, 5.0545e-05, 3.5728e-04, 1.5350e-04, 5.3878e-03, 4.2766e-04,
        8.2646e-03, 4.4506e-02, 6.8030e-03, 1.2784e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:49,922][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.6142, 0.0303, 0.0748, 0.0294, 0.0205, 0.0104, 0.0379, 0.0249, 0.0137,
        0.0506, 0.0933], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,923][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.0608, 0.0931, 0.0863, 0.0922, 0.0867, 0.0944, 0.0983, 0.1032, 0.1130,
        0.0907, 0.0813], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,924][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.0786, 0.0985, 0.0849, 0.0995, 0.0845, 0.0891, 0.0897, 0.1117, 0.0964,
        0.0860, 0.0811], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,926][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.0027, 0.0642, 0.0144, 0.0592, 0.0047, 0.0534, 0.1964, 0.2032, 0.0243,
        0.3600, 0.0176], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,927][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.0171, 0.1273, 0.1610, 0.0587, 0.2040, 0.0728, 0.0519, 0.0623, 0.1065,
        0.0486, 0.0896], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,929][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.3670, 0.0341, 0.0536, 0.0662, 0.0601, 0.0661, 0.0817, 0.0659, 0.0623,
        0.0927, 0.0504], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,930][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.0749, 0.0876, 0.0963, 0.0927, 0.0933, 0.0939, 0.0940, 0.0904, 0.0920,
        0.0898, 0.0951], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,932][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.0524, 0.1141, 0.0961, 0.0994, 0.0982, 0.1013, 0.0761, 0.0946, 0.0924,
        0.0937, 0.0817], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,933][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.0169, 0.2303, 0.0184, 0.1236, 0.0221, 0.0884, 0.1341, 0.0263, 0.1190,
        0.2133, 0.0077], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,933][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.0291, 0.1492, 0.0508, 0.1581, 0.0457, 0.1175, 0.2004, 0.0541, 0.0709,
        0.0895, 0.0346], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,933][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.0762, 0.1007, 0.0941, 0.0941, 0.1004, 0.0795, 0.0825, 0.1019, 0.0769,
        0.1000, 0.0936], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,934][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([8.5070e-01, 6.0907e-06, 2.8372e-05, 1.7280e-05, 1.0790e-03, 4.9697e-05,
        1.1422e-03, 2.1304e-03, 1.0963e-03, 1.1744e-02, 1.3200e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:49,934][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.5644, 0.0431, 0.0130, 0.0516, 0.0230, 0.0164, 0.0806, 0.0350, 0.0281,
        0.0742, 0.0172, 0.0535], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,935][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0563, 0.0853, 0.0796, 0.0855, 0.0792, 0.0866, 0.0897, 0.0955, 0.1029,
        0.0852, 0.0749, 0.0793], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,935][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0696, 0.0896, 0.0804, 0.0906, 0.0784, 0.0830, 0.0836, 0.1034, 0.0886,
        0.0804, 0.0770, 0.0754], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,936][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0059, 0.0609, 0.0142, 0.0474, 0.0043, 0.0472, 0.1790, 0.1705, 0.0256,
        0.3037, 0.0185, 0.1227], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,937][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0223, 0.1261, 0.1157, 0.0722, 0.1969, 0.0650, 0.0763, 0.0632, 0.1211,
        0.0559, 0.0662, 0.0190], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,938][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.3657, 0.0255, 0.0515, 0.0545, 0.0571, 0.0605, 0.0740, 0.0597, 0.0585,
        0.0908, 0.0517, 0.0505], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,940][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0688, 0.0799, 0.0880, 0.0850, 0.0855, 0.0857, 0.0857, 0.0824, 0.0839,
        0.0819, 0.0870, 0.0863], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,941][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0442, 0.1045, 0.0946, 0.0896, 0.0919, 0.0888, 0.0686, 0.0839, 0.0848,
        0.0867, 0.0811, 0.0813], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,942][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0161, 0.2672, 0.0366, 0.1255, 0.0200, 0.0735, 0.1081, 0.0270, 0.0946,
        0.1910, 0.0136, 0.0268], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,944][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0248, 0.2013, 0.0228, 0.1776, 0.0229, 0.0856, 0.1594, 0.0636, 0.0595,
        0.1111, 0.0151, 0.0562], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,945][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0716, 0.0968, 0.0854, 0.0884, 0.0904, 0.0762, 0.0773, 0.0924, 0.0709,
        0.0930, 0.0854, 0.0722], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,946][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([3.5613e-01, 2.6497e-05, 2.2931e-05, 6.0523e-05, 4.5800e-04, 8.9558e-05,
        3.2666e-03, 5.5393e-03, 1.1955e-03, 1.1821e-01, 4.4818e-01, 6.6813e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:49,948][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.3893, 0.0494, 0.0169, 0.0613, 0.0344, 0.0232, 0.0835, 0.0658, 0.0465,
        0.0846, 0.0210, 0.0215, 0.1026], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,949][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0535, 0.0775, 0.0745, 0.0792, 0.0733, 0.0799, 0.0819, 0.0872, 0.0920,
        0.0793, 0.0704, 0.0738, 0.0774], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,950][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0639, 0.0810, 0.0753, 0.0822, 0.0740, 0.0777, 0.0739, 0.0876, 0.0820,
        0.0739, 0.0718, 0.0742, 0.0824], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,952][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0046, 0.0364, 0.0099, 0.0281, 0.0029, 0.0345, 0.1335, 0.1154, 0.0221,
        0.2395, 0.0123, 0.0958, 0.2651], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,953][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0106, 0.1459, 0.1147, 0.0546, 0.2073, 0.0716, 0.0482, 0.0524, 0.1175,
        0.0347, 0.0634, 0.0420, 0.0370], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,955][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.4015, 0.0167, 0.0470, 0.0433, 0.0570, 0.0538, 0.0669, 0.0459, 0.0560,
        0.0751, 0.0469, 0.0456, 0.0441], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,956][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0635, 0.0735, 0.0812, 0.0784, 0.0788, 0.0789, 0.0790, 0.0758, 0.0773,
        0.0752, 0.0802, 0.0795, 0.0789], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,958][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0400, 0.0977, 0.0880, 0.0836, 0.0871, 0.0817, 0.0628, 0.0752, 0.0776,
        0.0819, 0.0759, 0.0807, 0.0678], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,959][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0137, 0.2419, 0.0325, 0.1255, 0.0249, 0.0587, 0.1287, 0.0205, 0.0969,
        0.1899, 0.0148, 0.0416, 0.0104], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,961][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0407, 0.1407, 0.0417, 0.1694, 0.0228, 0.1144, 0.1160, 0.0310, 0.0565,
        0.0734, 0.0301, 0.1359, 0.0272], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,962][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0680, 0.0864, 0.0813, 0.0808, 0.0865, 0.0671, 0.0685, 0.0856, 0.0651,
        0.0850, 0.0809, 0.0655, 0.0794], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,963][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([9.2277e-01, 5.3431e-07, 1.9267e-06, 1.1069e-06, 7.4630e-05, 3.5374e-06,
        5.0262e-05, 1.1471e-04, 4.5032e-05, 2.0477e-03, 4.4152e-02, 4.0142e-03,
        2.6720e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:49,965][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.3665, 0.0479, 0.0145, 0.0634, 0.0389, 0.0184, 0.0842, 0.0513, 0.0364,
        0.0852, 0.0193, 0.0233, 0.0592, 0.0914], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,966][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0480, 0.0729, 0.0679, 0.0732, 0.0666, 0.0738, 0.0754, 0.0813, 0.0870,
        0.0728, 0.0631, 0.0671, 0.0712, 0.0797], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,968][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.0597, 0.0768, 0.0678, 0.0764, 0.0667, 0.0710, 0.0699, 0.0834, 0.0758,
        0.0666, 0.0649, 0.0676, 0.0816, 0.0718], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,969][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.0029, 0.0569, 0.0135, 0.0439, 0.0039, 0.0351, 0.1240, 0.1269, 0.0170,
        0.2149, 0.0138, 0.0831, 0.2491, 0.0149], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,970][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0295, 0.1155, 0.1072, 0.0712, 0.1586, 0.1125, 0.0473, 0.0505, 0.1406,
        0.0347, 0.0607, 0.0306, 0.0271, 0.0140], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,972][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.2806, 0.0234, 0.0453, 0.0580, 0.0496, 0.0563, 0.0685, 0.0570, 0.0601,
        0.0869, 0.0434, 0.0496, 0.0554, 0.0659], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,974][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.0586, 0.0681, 0.0755, 0.0727, 0.0731, 0.0733, 0.0732, 0.0703, 0.0717,
        0.0698, 0.0744, 0.0738, 0.0733, 0.0721], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,975][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0381, 0.0923, 0.0828, 0.0776, 0.0790, 0.0757, 0.0578, 0.0710, 0.0699,
        0.0754, 0.0699, 0.0744, 0.0670, 0.0691], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,976][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.0127, 0.2419, 0.0316, 0.1552, 0.0133, 0.0573, 0.1338, 0.0215, 0.0566,
        0.1686, 0.0106, 0.0734, 0.0169, 0.0064], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,978][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.0200, 0.1219, 0.0507, 0.1355, 0.0256, 0.1317, 0.1572, 0.0384, 0.0459,
        0.0607, 0.0316, 0.0777, 0.0377, 0.0655], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,980][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.0600, 0.0792, 0.0751, 0.0733, 0.0795, 0.0663, 0.0651, 0.0784, 0.0640,
        0.0784, 0.0754, 0.0639, 0.0733, 0.0681], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,980][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([9.0672e-01, 1.3267e-07, 6.0214e-07, 2.9743e-07, 1.8795e-05, 4.7361e-07,
        7.1531e-06, 1.1008e-05, 5.0962e-06, 1.6421e-04, 6.1829e-03, 5.6039e-04,
        4.7348e-03, 8.1595e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:49,982][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.3646, 0.0486, 0.0118, 0.0527, 0.0254, 0.0206, 0.0963, 0.0515, 0.0262,
        0.0771, 0.0145, 0.0234, 0.0502, 0.0304, 0.1067], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,984][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0449, 0.0660, 0.0640, 0.0682, 0.0619, 0.0685, 0.0689, 0.0747, 0.0784,
        0.0680, 0.0602, 0.0636, 0.0665, 0.0724, 0.0738], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,985][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0544, 0.0692, 0.0652, 0.0712, 0.0632, 0.0675, 0.0609, 0.0769, 0.0713,
        0.0624, 0.0622, 0.0649, 0.0765, 0.0701, 0.0641], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,986][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0085, 0.0262, 0.0075, 0.0173, 0.0023, 0.0261, 0.0820, 0.0779, 0.0193,
        0.1503, 0.0099, 0.0673, 0.1793, 0.0161, 0.3100], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,988][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0104, 0.1798, 0.0611, 0.1041, 0.2127, 0.0500, 0.0628, 0.0552, 0.0990,
        0.0403, 0.0324, 0.0211, 0.0295, 0.0165, 0.0252], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,989][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.4724, 0.0168, 0.0379, 0.0357, 0.0435, 0.0409, 0.0512, 0.0357, 0.0348,
        0.0522, 0.0364, 0.0307, 0.0331, 0.0377, 0.0410], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,990][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0543, 0.0637, 0.0701, 0.0676, 0.0679, 0.0683, 0.0682, 0.0656, 0.0669,
        0.0652, 0.0691, 0.0687, 0.0683, 0.0671, 0.0690], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,991][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0335, 0.0843, 0.0819, 0.0720, 0.0778, 0.0706, 0.0512, 0.0659, 0.0665,
        0.0691, 0.0698, 0.0706, 0.0633, 0.0724, 0.0510], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,991][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0062, 0.2684, 0.0422, 0.1202, 0.0146, 0.0423, 0.0598, 0.0323, 0.1167,
        0.1639, 0.0164, 0.0443, 0.0165, 0.0198, 0.0364], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,992][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0260, 0.1288, 0.0254, 0.1655, 0.0130, 0.1275, 0.0589, 0.0524, 0.0386,
        0.0758, 0.0168, 0.0992, 0.0506, 0.0750, 0.0465], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,992][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0588, 0.0780, 0.0715, 0.0721, 0.0750, 0.0584, 0.0642, 0.0740, 0.0572,
        0.0754, 0.0703, 0.0599, 0.0665, 0.0579, 0.0610], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:49,993][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([4.7053e-01, 8.6322e-08, 3.0873e-07, 2.3447e-07, 1.3608e-05, 3.5215e-07,
        3.0580e-06, 2.3684e-05, 8.8949e-06, 3.5992e-04, 7.8039e-03, 6.8214e-04,
        1.1592e-02, 4.4189e-01, 6.7099e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,026][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:50,027][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,028][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,029][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,030][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,031][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,032][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,034][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,035][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,036][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,037][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,038][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,039][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,041][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9900, 0.0100], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,042][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.4105, 0.5895], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,043][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0868, 0.9132], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,045][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0113, 0.9887], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,046][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5058, 0.4942], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,047][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.5148, 0.4852], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,048][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9090, 0.0910], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,048][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0586, 0.9414], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,048][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4742, 0.5258], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,049][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.8919, 0.1081], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,049][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3349, 0.6651], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,049][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.8621, 0.1379], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,050][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.9641, 0.0053, 0.0306], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,050][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.2545, 0.3822, 0.3633], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,050][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.0420, 0.2253, 0.7327], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,052][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.0452, 0.4456, 0.5092], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,053][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.3413, 0.3281, 0.3306], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,054][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.4235, 0.3511, 0.2255], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,056][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.6322, 0.1135, 0.2543], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,057][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.0408, 0.8240, 0.1352], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,058][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.3475, 0.3832, 0.2693], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,059][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.3647, 0.0889, 0.5464], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,061][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.2094, 0.4492, 0.3414], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,062][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.7347, 0.1148, 0.1505], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,064][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.8702, 0.0176, 0.0040, 0.1083], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,065][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1916, 0.2792, 0.2673, 0.2620], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,067][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0217, 0.1399, 0.5536, 0.2848], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,068][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0106, 0.3330, 0.5037, 0.1527], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,069][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2565, 0.2514, 0.2470, 0.2450], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,071][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3463, 0.2276, 0.1488, 0.2773], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,072][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3683, 0.0445, 0.5305, 0.0568], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,074][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0343, 0.1756, 0.4734, 0.3167], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,075][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2454, 0.2700, 0.2283, 0.2564], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,076][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2654, 0.2474, 0.2289, 0.2583], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,078][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1609, 0.3061, 0.2274, 0.3055], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,079][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.5810, 0.1323, 0.1361, 0.1506], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,080][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.9721, 0.0026, 0.0013, 0.0129, 0.0111], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,081][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.1479, 0.2262, 0.2257, 0.2244, 0.1759], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,083][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.0274, 0.1181, 0.3892, 0.2775, 0.1879], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,084][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.3850, 0.0195, 0.0545, 0.0200, 0.5210], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,086][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.2107, 0.2028, 0.2037, 0.1983, 0.1846], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,087][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.2652, 0.1984, 0.1267, 0.2283, 0.1814], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,089][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.7470, 0.0036, 0.0163, 0.0082, 0.2250], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,090][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.4277, 0.0275, 0.0130, 0.0391, 0.4926], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,091][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.2042, 0.2254, 0.1757, 0.2300, 0.1647], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,093][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.4472, 0.0066, 0.0219, 0.0159, 0.5084], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,094][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.1142, 0.2409, 0.1931, 0.2542, 0.1976], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,096][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.8150, 0.0069, 0.0179, 0.0134, 0.1468], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,097][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([9.8566e-01, 1.9822e-03, 3.4789e-04, 9.4554e-03, 3.6286e-04, 2.1878e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,098][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.1330, 0.1915, 0.1774, 0.1901, 0.1437, 0.1643], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,099][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0188, 0.0817, 0.2642, 0.1758, 0.1467, 0.3126], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,101][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.0357, 0.0112, 0.0054, 0.0109, 0.4155, 0.5213], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,102][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.1771, 0.1737, 0.1685, 0.1689, 0.1555, 0.1563], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,104][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.1739, 0.1843, 0.1145, 0.2222, 0.1627, 0.1424], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,105][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.2072, 0.0028, 0.0185, 0.0069, 0.6185, 0.1462], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,106][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([6.9339e-03, 4.5571e-04, 9.4996e-04, 1.0996e-03, 5.2552e-01, 4.6504e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,106][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.1658, 0.1875, 0.1506, 0.1912, 0.1630, 0.1419], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,106][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.4684, 0.0177, 0.0062, 0.0185, 0.1860, 0.3032], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,107][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0967, 0.2126, 0.1775, 0.2130, 0.1718, 0.1284], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,107][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.7618, 0.0142, 0.0059, 0.0291, 0.1019, 0.0871], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,107][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.9049, 0.0066, 0.0014, 0.0351, 0.0021, 0.0020, 0.0480],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,108][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1120, 0.1583, 0.1522, 0.1586, 0.1277, 0.1448, 0.1464],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,108][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0174, 0.0625, 0.2351, 0.1221, 0.1294, 0.2599, 0.1737],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,109][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0393, 0.0030, 0.0031, 0.0022, 0.1209, 0.4107, 0.4208],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,110][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1523, 0.1484, 0.1454, 0.1441, 0.1351, 0.1349, 0.1398],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,112][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1680, 0.1477, 0.0906, 0.1774, 0.1350, 0.1177, 0.1635],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,113][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([5.3850e-01, 3.0486e-04, 3.9763e-03, 1.1239e-03, 1.8699e-01, 4.3039e-02,
        2.2606e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,113][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.9824e-02, 3.0398e-05, 1.6139e-04, 6.1341e-05, 4.5542e-02, 3.2045e-02,
        9.0234e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,115][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1414, 0.1683, 0.1326, 0.1648, 0.1334, 0.1292, 0.1302],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,116][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.4775, 0.0029, 0.0037, 0.0081, 0.0856, 0.2424, 0.1798],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,117][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0901, 0.1761, 0.1436, 0.1753, 0.1465, 0.1064, 0.1619],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,119][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.7595, 0.0014, 0.0029, 0.0039, 0.0551, 0.0195, 0.1577],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,120][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.8802, 0.0067, 0.0014, 0.0423, 0.0024, 0.0020, 0.0178, 0.0473],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,122][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0944, 0.1333, 0.1337, 0.1320, 0.1092, 0.1219, 0.1228, 0.1527],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,123][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0206, 0.0617, 0.2009, 0.1121, 0.1074, 0.2171, 0.1580, 0.1222],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,125][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0423, 0.0020, 0.0048, 0.0018, 0.1653, 0.1244, 0.4070, 0.2524],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,126][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1353, 0.1312, 0.1278, 0.1285, 0.1190, 0.1183, 0.1229, 0.1169],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,127][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1389, 0.1229, 0.0804, 0.1506, 0.1232, 0.1027, 0.1424, 0.1389],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,128][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([8.1534e-01, 4.0561e-05, 6.6007e-04, 1.2921e-04, 3.6492e-02, 3.7522e-03,
        5.7565e-02, 8.6021e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,129][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([3.7499e-02, 2.2160e-06, 7.4568e-06, 5.0460e-06, 5.1191e-03, 2.5007e-03,
        1.5633e-01, 7.9853e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,131][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1277, 0.1453, 0.1140, 0.1428, 0.1254, 0.1178, 0.1258, 0.1013],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,132][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([4.9388e-01, 3.2059e-04, 2.3650e-03, 7.5887e-04, 3.9101e-02, 1.4991e-02,
        7.7142e-02, 3.7144e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,133][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0797, 0.1465, 0.1189, 0.1464, 0.1240, 0.0977, 0.1250, 0.1618],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,134][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([9.1147e-01, 1.3117e-04, 5.3827e-04, 2.4054e-04, 7.6239e-03, 9.9279e-04,
        2.4279e-02, 5.4726e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,135][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([9.2319e-01, 3.8803e-03, 7.3050e-04, 3.8018e-02, 1.1017e-03, 4.0449e-04,
        1.5562e-02, 1.2753e-02, 4.3601e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,136][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([0.0777, 0.1179, 0.1177, 0.1198, 0.0925, 0.1080, 0.1105, 0.1417, 0.1141],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,138][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([0.0235, 0.0631, 0.1645, 0.1197, 0.0779, 0.1892, 0.1407, 0.1070, 0.1144],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,139][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([0.0114, 0.0009, 0.0012, 0.0013, 0.0753, 0.0764, 0.4450, 0.2691, 0.1194],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,141][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([0.1230, 0.1177, 0.1159, 0.1152, 0.1060, 0.1044, 0.1089, 0.1038, 0.1049],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,142][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([0.1240, 0.1121, 0.0732, 0.1351, 0.1065, 0.0915, 0.1248, 0.1252, 0.1078],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,143][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([2.0157e-01, 1.0403e-04, 9.5782e-04, 2.9409e-04, 3.3835e-02, 6.9131e-03,
        1.6865e-01, 5.0905e-01, 7.8625e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,144][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([3.7670e-04, 8.2445e-07, 1.2719e-06, 2.1409e-06, 1.0232e-03, 1.2268e-03,
        7.7812e-02, 9.1664e-01, 2.9145e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,145][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([0.1165, 0.1273, 0.1031, 0.1315, 0.1052, 0.1013, 0.1188, 0.0950, 0.1014],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,146][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([8.5963e-02, 2.5506e-04, 1.3065e-03, 7.2070e-04, 2.3791e-02, 2.8291e-02,
        1.4451e-01, 6.5117e-01, 6.3993e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,148][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([0.0664, 0.1338, 0.1044, 0.1370, 0.1120, 0.0813, 0.1181, 0.1414, 0.1056],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,149][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([2.5288e-01, 3.7065e-04, 6.8755e-04, 5.2782e-04, 1.6899e-02, 3.9091e-03,
        1.0693e-01, 5.2636e-01, 9.1446e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,150][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.6896, 0.0127, 0.0053, 0.0758, 0.0115, 0.0040, 0.0587, 0.0447, 0.0039,
        0.0938], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,152][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0744, 0.1048, 0.1011, 0.1053, 0.0827, 0.0951, 0.1004, 0.1268, 0.1033,
        0.1063], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,153][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0250, 0.0497, 0.1366, 0.0861, 0.0769, 0.1576, 0.1060, 0.0903, 0.1271,
        0.1448], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,154][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([2.8842e-02, 9.2297e-05, 3.3985e-04, 1.0269e-04, 1.4818e-02, 7.3339e-03,
        3.1938e-02, 3.9442e-02, 4.6415e-02, 8.3068e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,155][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.1104, 0.1056, 0.1041, 0.1040, 0.0966, 0.0942, 0.0992, 0.0942, 0.0956,
        0.0961], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,157][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1047, 0.1008, 0.0673, 0.1235, 0.0993, 0.0842, 0.1158, 0.1143, 0.0994,
        0.0906], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,158][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([7.6985e-01, 8.4415e-06, 4.1085e-04, 5.3907e-05, 1.0928e-02, 8.5630e-04,
        9.4010e-03, 3.3535e-02, 1.0686e-02, 1.6427e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,159][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([1.8932e-02, 8.9596e-08, 1.1529e-06, 3.6400e-07, 4.0930e-04, 1.5673e-04,
        3.9199e-03, 3.7006e-02, 1.6618e-03, 9.3791e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,160][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.1005, 0.1133, 0.0930, 0.1116, 0.0931, 0.0953, 0.0974, 0.0854, 0.1040,
        0.1064], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,161][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([5.0056e-01, 1.2817e-04, 8.5368e-04, 3.5980e-04, 2.3077e-02, 4.8371e-03,
        1.0694e-02, 5.9742e-02, 5.8585e-03, 3.9389e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,162][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0663, 0.1200, 0.0887, 0.1199, 0.0931, 0.0676, 0.1016, 0.1216, 0.0836,
        0.1377], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,163][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([8.0621e-01, 5.0545e-05, 3.5728e-04, 1.5350e-04, 5.3878e-03, 4.2766e-04,
        8.2646e-03, 4.4506e-02, 6.8030e-03, 1.2784e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,164][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([9.0011e-01, 2.8791e-03, 2.5230e-02, 1.3065e-02, 1.7899e-03, 4.8487e-04,
        4.7529e-03, 4.0569e-03, 4.1007e-04, 2.4597e-02, 2.2622e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,164][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.0652, 0.0976, 0.0937, 0.0956, 0.0765, 0.0888, 0.0897, 0.1158, 0.0969,
        0.0935, 0.0868], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,165][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.0126, 0.0357, 0.1006, 0.0831, 0.0582, 0.1458, 0.1199, 0.0943, 0.0998,
        0.1567, 0.0933], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,165][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([6.5524e-02, 4.7273e-06, 1.1077e-05, 6.0669e-06, 7.1845e-04, 2.8119e-04,
        1.7266e-03, 1.2649e-03, 1.0689e-03, 7.2555e-02, 8.5684e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,166][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.0996, 0.0959, 0.0947, 0.0934, 0.0877, 0.0839, 0.0893, 0.0854, 0.0857,
        0.0867, 0.0975], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,166][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.1048, 0.0924, 0.0611, 0.1082, 0.0864, 0.0755, 0.1028, 0.1020, 0.0889,
        0.0840, 0.0939], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,166][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([6.3057e-01, 1.2490e-06, 1.6849e-05, 3.7148e-06, 1.0732e-03, 2.1661e-05,
        3.0659e-04, 4.2410e-04, 4.3581e-04, 1.1318e-02, 3.5583e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,167][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([1.1716e-01, 1.1857e-07, 2.1486e-07, 1.8113e-07, 1.8259e-04, 3.7423e-05,
        7.5290e-04, 2.1266e-03, 2.5834e-04, 1.9432e-01, 6.8517e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,169][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.0963, 0.1037, 0.0744, 0.1045, 0.0879, 0.0961, 0.0927, 0.0742, 0.0975,
        0.1012, 0.0715], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,169][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([3.9498e-01, 1.5995e-05, 1.3807e-04, 6.5660e-05, 4.7849e-03, 2.0131e-04,
        1.3163e-03, 5.1000e-03, 9.9789e-04, 3.0273e-02, 5.6213e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,171][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.0509, 0.1063, 0.0834, 0.1090, 0.0897, 0.0646, 0.0922, 0.1191, 0.0801,
        0.1215, 0.0831], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,172][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([8.5070e-01, 6.0907e-06, 2.8372e-05, 1.7280e-05, 1.0790e-03, 4.9697e-05,
        1.1422e-03, 2.1304e-03, 1.0963e-03, 1.1744e-02, 1.3200e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,173][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.8866, 0.0047, 0.0017, 0.0279, 0.0017, 0.0012, 0.0195, 0.0078, 0.0016,
        0.0350, 0.0012, 0.0110], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,175][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0617, 0.0903, 0.0848, 0.0898, 0.0704, 0.0810, 0.0838, 0.1099, 0.0863,
        0.0893, 0.0787, 0.0742], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,176][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0128, 0.0381, 0.1036, 0.0708, 0.0527, 0.1134, 0.0846, 0.0682, 0.0856,
        0.1297, 0.1012, 0.1392], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,177][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([1.2543e-02, 7.0955e-06, 4.4425e-06, 6.3252e-06, 5.4432e-04, 3.5013e-04,
        3.2431e-03, 2.4108e-03, 3.2496e-03, 1.2234e-01, 7.1498e-01, 1.4032e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,178][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0890, 0.0880, 0.0866, 0.0859, 0.0791, 0.0780, 0.0821, 0.0789, 0.0795,
        0.0803, 0.0896, 0.0830], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,180][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0962, 0.0849, 0.0541, 0.1020, 0.0787, 0.0685, 0.0955, 0.0947, 0.0825,
        0.0764, 0.0851, 0.0813], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,181][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([7.7256e-03, 1.8868e-07, 3.2834e-06, 5.5806e-07, 1.3845e-04, 1.5161e-05,
        3.4072e-04, 9.0053e-04, 2.2162e-04, 2.7201e-02, 9.5418e-01, 9.2712e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,182][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([4.9691e-04, 3.5051e-09, 8.4288e-09, 5.3928e-09, 1.1152e-05, 2.2520e-06,
        8.6224e-05, 4.2566e-04, 3.4693e-05, 9.9276e-02, 8.6029e-01, 3.9381e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,183][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0897, 0.0973, 0.0757, 0.0968, 0.0807, 0.0858, 0.0846, 0.0694, 0.0873,
        0.0924, 0.0725, 0.0677], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,184][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([2.3470e-01, 5.0100e-05, 2.0620e-05, 4.5974e-05, 9.5995e-04, 5.6644e-04,
        3.4336e-03, 1.7334e-02, 1.1153e-03, 2.9122e-01, 3.6074e-01, 8.9807e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,186][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0477, 0.1025, 0.0748, 0.1023, 0.0779, 0.0626, 0.0907, 0.1045, 0.0757,
        0.1147, 0.0751, 0.0715], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,187][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([3.5613e-01, 2.6497e-05, 2.2931e-05, 6.0523e-05, 4.5800e-04, 8.9558e-05,
        3.2666e-03, 5.5393e-03, 1.1955e-03, 1.1821e-01, 4.4818e-01, 6.6813e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,188][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.7148, 0.0077, 0.0033, 0.0395, 0.0041, 0.0029, 0.0290, 0.0341, 0.0055,
        0.0613, 0.0021, 0.0046, 0.0912], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,190][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0605, 0.0817, 0.0799, 0.0809, 0.0659, 0.0740, 0.0765, 0.0945, 0.0801,
        0.0819, 0.0751, 0.0718, 0.0773], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,191][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0109, 0.0333, 0.1007, 0.0597, 0.0515, 0.1069, 0.0775, 0.0598, 0.0842,
        0.1061, 0.0928, 0.1328, 0.0838], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,192][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([5.1416e-02, 4.0060e-06, 8.7451e-06, 2.4667e-06, 3.1811e-04, 2.4445e-04,
        9.9521e-04, 1.0046e-03, 1.1791e-03, 3.0323e-02, 5.8256e-01, 1.6381e-01,
        1.6813e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,194][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0814, 0.0806, 0.0790, 0.0784, 0.0736, 0.0729, 0.0758, 0.0732, 0.0732,
        0.0737, 0.0814, 0.0766, 0.0801], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,195][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0892, 0.0712, 0.0488, 0.0879, 0.0748, 0.0630, 0.0849, 0.0839, 0.0741,
        0.0692, 0.0788, 0.0736, 0.1006], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,196][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([6.6097e-01, 4.5012e-08, 1.5042e-06, 1.5026e-07, 1.3656e-04, 2.4924e-06,
        3.4778e-05, 2.4725e-05, 2.9638e-05, 1.6036e-03, 2.2701e-01, 2.3161e-03,
        1.0787e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,197][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([2.8446e-02, 1.1525e-10, 1.2746e-09, 4.0942e-10, 1.5997e-06, 1.1177e-07,
        4.8864e-06, 1.5804e-05, 2.9834e-06, 4.1906e-03, 2.2622e-01, 1.5932e-02,
        7.2518e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,199][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0827, 0.0913, 0.0707, 0.0897, 0.0789, 0.0764, 0.0789, 0.0635, 0.0816,
        0.0880, 0.0693, 0.0689, 0.0600], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,200][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.3683e-01, 9.9408e-07, 1.1138e-05, 3.2551e-06, 1.7854e-04, 4.3071e-05,
        2.2095e-04, 5.3229e-04, 1.8254e-04, 8.7648e-03, 2.4708e-01, 1.6610e-01,
        3.4005e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,201][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0470, 0.0882, 0.0717, 0.0909, 0.0742, 0.0573, 0.0776, 0.0969, 0.0675,
        0.1010, 0.0714, 0.0661, 0.0902], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,202][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([9.2277e-01, 5.3431e-07, 1.9267e-06, 1.1069e-06, 7.4630e-05, 3.5374e-06,
        5.0262e-05, 1.1471e-04, 4.5032e-05, 2.0477e-03, 4.4152e-02, 4.0142e-03,
        2.6720e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,203][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([8.9528e-01, 2.8966e-03, 8.2187e-04, 2.8240e-02, 1.2127e-03, 5.8917e-04,
        1.2929e-02, 8.2543e-03, 9.5781e-04, 3.1354e-02, 5.6212e-04, 1.6158e-03,
        1.2054e-02, 3.2275e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,204][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.0529, 0.0770, 0.0747, 0.0776, 0.0609, 0.0700, 0.0701, 0.0895, 0.0741,
        0.0759, 0.0686, 0.0665, 0.0710, 0.0713], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,206][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.0212, 0.0415, 0.0917, 0.0712, 0.0418, 0.1012, 0.0729, 0.0591, 0.0662,
        0.0972, 0.0728, 0.1218, 0.0850, 0.0565], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,207][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([2.0570e-01, 1.7304e-06, 2.4641e-06, 1.1818e-06, 1.8903e-04, 5.0510e-05,
        4.4932e-04, 3.9335e-04, 2.6875e-04, 1.2748e-02, 1.5760e-01, 4.1114e-02,
        1.2004e-01, 4.6144e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,208][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0758, 0.0748, 0.0743, 0.0728, 0.0681, 0.0663, 0.0699, 0.0670, 0.0680,
        0.0681, 0.0771, 0.0712, 0.0745, 0.0721], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,210][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([0.0865, 0.0628, 0.0454, 0.0756, 0.0671, 0.0572, 0.0731, 0.0738, 0.0667,
        0.0631, 0.0728, 0.0669, 0.0895, 0.0995], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,211][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([7.6406e-01, 1.3823e-08, 3.3833e-07, 4.1082e-08, 2.9338e-05, 3.5664e-07,
        7.4795e-06, 6.8797e-06, 3.8254e-06, 1.9727e-04, 3.6905e-02, 4.1111e-04,
        3.9076e-02, 1.5930e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,212][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([7.0825e-02, 3.7981e-11, 4.5392e-10, 8.2473e-11, 3.7382e-07, 7.2837e-09,
        3.1425e-07, 6.8574e-07, 8.8087e-08, 1.9458e-04, 2.9075e-02, 3.8349e-04,
        8.6469e-02, 8.1305e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,213][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.0781, 0.0841, 0.0665, 0.0855, 0.0679, 0.0721, 0.0789, 0.0613, 0.0727,
        0.0802, 0.0648, 0.0689, 0.0612, 0.0578], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,214][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([6.4198e-01, 4.2172e-07, 2.5893e-06, 1.1527e-06, 1.3284e-04, 2.6672e-05,
        1.0819e-04, 8.1011e-05, 1.5094e-05, 1.2243e-03, 2.7431e-02, 1.2312e-02,
        3.9756e-02, 2.7693e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,216][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.0418, 0.0856, 0.0637, 0.0870, 0.0686, 0.0518, 0.0747, 0.0908, 0.0666,
        0.0964, 0.0637, 0.0625, 0.0820, 0.0649], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,217][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([9.0672e-01, 1.3267e-07, 6.0214e-07, 2.9743e-07, 1.8795e-05, 4.7361e-07,
        7.1531e-06, 1.1008e-05, 5.0962e-06, 1.6421e-04, 6.1829e-03, 5.6039e-04,
        4.7348e-03, 8.1595e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,218][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.6962, 0.0088, 0.0018, 0.0368, 0.0031, 0.0027, 0.0523, 0.0196, 0.0023,
        0.0645, 0.0013, 0.0053, 0.0203, 0.0025, 0.0826], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,220][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0512, 0.0699, 0.0681, 0.0707, 0.0574, 0.0639, 0.0649, 0.0826, 0.0695,
        0.0711, 0.0639, 0.0625, 0.0681, 0.0682, 0.0680], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,221][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0105, 0.0248, 0.0779, 0.0456, 0.0406, 0.0902, 0.0602, 0.0565, 0.0653,
        0.1015, 0.0858, 0.1117, 0.0731, 0.0582, 0.0982], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,222][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([4.8893e-02, 9.4802e-07, 1.3339e-06, 6.3729e-07, 5.5176e-05, 4.5178e-05,
        1.1250e-04, 3.2713e-04, 5.4242e-04, 7.7658e-03, 8.8047e-02, 2.8733e-02,
        7.6694e-02, 4.9226e-01, 2.5653e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,222][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0709, 0.0699, 0.0685, 0.0677, 0.0631, 0.0625, 0.0653, 0.0630, 0.0632,
        0.0639, 0.0708, 0.0662, 0.0693, 0.0674, 0.0682], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,222][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0751, 0.0602, 0.0389, 0.0733, 0.0588, 0.0506, 0.0692, 0.0694, 0.0612,
        0.0562, 0.0640, 0.0603, 0.0844, 0.0935, 0.0848], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,223][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.6074e-01, 3.3821e-09, 1.6315e-07, 1.6924e-08, 2.0995e-05, 2.4961e-07,
        1.5433e-06, 5.8004e-06, 5.8486e-06, 1.7443e-04, 3.8616e-02, 1.4117e-04,
        3.8878e-02, 4.4739e-01, 2.1403e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,223][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([3.1332e-03, 3.5404e-13, 1.2928e-11, 1.3322e-12, 1.9318e-08, 1.5808e-10,
        4.7499e-09, 4.4859e-08, 8.2338e-09, 9.5054e-06, 2.0082e-03, 4.5921e-05,
        7.6804e-03, 6.7065e-01, 3.1647e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,224][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0693, 0.0804, 0.0645, 0.0793, 0.0653, 0.0630, 0.0647, 0.0585, 0.0720,
        0.0760, 0.0624, 0.0604, 0.0565, 0.0604, 0.0674], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,224][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.3642e-01, 1.6084e-07, 4.3013e-07, 5.1555e-07, 1.5513e-05, 6.3343e-06,
        4.8320e-06, 1.0494e-04, 1.1890e-05, 1.9455e-03, 1.6350e-02, 1.0978e-02,
        7.9118e-02, 6.9810e-01, 5.6949e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,226][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0404, 0.0781, 0.0639, 0.0781, 0.0657, 0.0475, 0.0718, 0.0800, 0.0608,
        0.0877, 0.0639, 0.0586, 0.0726, 0.0596, 0.0715], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,227][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([4.7053e-01, 8.6322e-08, 3.0873e-07, 2.3447e-07, 1.3608e-05, 3.5215e-07,
        3.0580e-06, 2.3684e-05, 8.8949e-06, 3.5992e-04, 7.8039e-03, 6.8214e-04,
        1.1592e-02, 4.4189e-01, 6.7099e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,228][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:50,229][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[22701],
        [41151],
        [48103],
        [46291],
        [48926],
        [45144],
        [43883],
        [41186],
        [45969],
        [37934],
        [48688],
        [45328],
        [44434],
        [42857],
        [41931]], device='cuda:0')
[2024-07-24 10:21:50,231][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[23234],
        [48365],
        [48900],
        [48187],
        [49600],
        [48220],
        [46720],
        [47694],
        [47267],
        [44852],
        [49237],
        [47875],
        [47674],
        [45202],
        [46774]], device='cuda:0')
[2024-07-24 10:21:50,232][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[18578],
        [18311],
        [16203],
        [16726],
        [15410],
        [17588],
        [14907],
        [14582],
        [13610],
        [12187],
        [13588],
        [14968],
        [12600],
        [12451],
        [12633]], device='cuda:0')
[2024-07-24 10:21:50,233][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[13369],
        [10263],
        [ 9965],
        [ 9647],
        [ 9299],
        [ 9114],
        [ 9093],
        [ 9326],
        [ 9536],
        [ 9700],
        [ 9620],
        [ 9380],
        [ 9414],
        [ 9628],
        [ 9683]], device='cuda:0')
[2024-07-24 10:21:50,235][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[9937],
        [8063],
        [8088],
        [7229],
        [7007],
        [7282],
        [7265],
        [7202],
        [7170],
        [7195],
        [7302],
        [7387],
        [7335],
        [7670],
        [7618]], device='cuda:0')
[2024-07-24 10:21:50,236][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 8313],
        [13183],
        [12072],
        [12621],
        [12628],
        [13822],
        [16443],
        [17024],
        [16748],
        [18415],
        [18023],
        [18797],
        [19809],
        [19336],
        [20278]], device='cuda:0')
[2024-07-24 10:21:50,238][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[14746],
        [20221],
        [38622],
        [33462],
        [36063],
        [38818],
        [35226],
        [36174],
        [40166],
        [38497],
        [39526],
        [38584],
        [38728],
        [38946],
        [36304]], device='cuda:0')
[2024-07-24 10:21:50,239][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[40942],
        [40783],
        [38270],
        [38208],
        [36132],
        [34369],
        [34332],
        [32840],
        [29696],
        [30464],
        [28955],
        [28802],
        [28867],
        [27548],
        [29896]], device='cuda:0')
[2024-07-24 10:21:50,240][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[27703],
        [29440],
        [31647],
        [32322],
        [32856],
        [32898],
        [33044],
        [32576],
        [32453],
        [32076],
        [32263],
        [32317],
        [32266],
        [32124],
        [32135]], device='cuda:0')
[2024-07-24 10:21:50,242][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[39789],
        [38312],
        [38877],
        [36918],
        [37697],
        [38254],
        [38185],
        [37968],
        [37568],
        [37477],
        [37513],
        [37582],
        [37581],
        [37511],
        [37464]], device='cuda:0')
[2024-07-24 10:21:50,243][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[10120],
        [12143],
        [12934],
        [14346],
        [13325],
        [14148],
        [13715],
        [13832],
        [14109],
        [16445],
        [16000],
        [15756],
        [15858],
        [15250],
        [16596]], device='cuda:0')
[2024-07-24 10:21:50,245][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[28897],
        [35063],
        [39900],
        [35000],
        [34511],
        [32721],
        [30819],
        [31703],
        [32480],
        [32886],
        [33100],
        [33017],
        [35067],
        [34891],
        [34545]], device='cuda:0')
[2024-07-24 10:21:50,246][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[26622],
        [26984],
        [34455],
        [35430],
        [39154],
        [37125],
        [36618],
        [36256],
        [36909],
        [36028],
        [36850],
        [36475],
        [36427],
        [36026],
        [35761]], device='cuda:0')
[2024-07-24 10:21:50,248][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[29137],
        [28263],
        [26294],
        [24999],
        [32509],
        [29152],
        [30622],
        [30141],
        [31651],
        [29614],
        [25074],
        [17868],
        [26691],
        [26012],
        [16542]], device='cuda:0')
[2024-07-24 10:21:50,249][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[14783],
        [  598],
        [ 1905],
        [ 1637],
        [  586],
        [ 6586],
        [ 1685],
        [ 4259],
        [ 2077],
        [ 2038],
        [ 6217],
        [ 4375],
        [ 9217],
        [ 8179],
        [ 6084]], device='cuda:0')
[2024-07-24 10:21:50,250][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[31444],
        [31589],
        [31557],
        [33141],
        [31725],
        [31673],
        [32409],
        [32736],
        [32364],
        [34275],
        [32215],
        [32849],
        [34389],
        [32818],
        [34045]], device='cuda:0')
[2024-07-24 10:21:50,252][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[3839],
        [6104],
        [8050],
        [7347],
        [8056],
        [7527],
        [7593],
        [7730],
        [7985],
        [8057],
        [8531],
        [8129],
        [8339],
        [8697],
        [8761]], device='cuda:0')
[2024-07-24 10:21:50,253][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[43354],
        [39903],
        [35835],
        [37236],
        [37045],
        [36955],
        [37728],
        [38337],
        [38274],
        [38216],
        [38733],
        [38660],
        [38490],
        [38662],
        [39150]], device='cuda:0')
[2024-07-24 10:21:50,255][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[5439],
        [ 668],
        [3500],
        [2461],
        [3169],
        [ 843],
        [1097],
        [ 583],
        [ 474],
        [ 665],
        [7574],
        [5197],
        [3832],
        [1992],
        [1325]], device='cuda:0')
[2024-07-24 10:21:50,256][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[35433],
        [34259],
        [34507],
        [32789],
        [33384],
        [32860],
        [32584],
        [32485],
        [33075],
        [33656],
        [33785],
        [33548],
        [33043],
        [32866],
        [32671]], device='cuda:0')
[2024-07-24 10:21:50,257][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[34809],
        [36116],
        [35046],
        [35893],
        [33563],
        [32655],
        [31783],
        [31636],
        [32237],
        [32299],
        [32113],
        [31695],
        [31780],
        [32583],
        [32622]], device='cuda:0')
[2024-07-24 10:21:50,259][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[34458],
        [30470],
        [27286],
        [27836],
        [28604],
        [25340],
        [25862],
        [30697],
        [14763],
        [29062],
        [26578],
        [15262],
        [29200],
        [34693],
        [30826]], device='cuda:0')
[2024-07-24 10:21:50,260][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[32568],
        [42190],
        [40368],
        [34243],
        [34187],
        [38390],
        [37639],
        [39419],
        [38834],
        [43796],
        [41950],
        [40608],
        [38140],
        [42948],
        [43461]], device='cuda:0')
[2024-07-24 10:21:50,262][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[5172],
        [5219],
        [5609],
        [5923],
        [5607],
        [5532],
        [5749],
        [5692],
        [5593],
        [5492],
        [5532],
        [5692],
        [5494],
        [5404],
        [5447]], device='cuda:0')
[2024-07-24 10:21:50,263][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 271],
        [ 176],
        [3209],
        [ 285],
        [1746],
        [ 793],
        [ 671],
        [ 545],
        [ 941],
        [ 349],
        [1750],
        [ 480],
        [ 450],
        [1913],
        [8118]], device='cuda:0')
[2024-07-24 10:21:50,265][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[33880],
        [25555],
        [31659],
        [31221],
        [32259],
        [32511],
        [32712],
        [32017],
        [31963],
        [31508],
        [32522],
        [32061],
        [32165],
        [32215],
        [32399]], device='cuda:0')
[2024-07-24 10:21:50,266][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 993],
        [ 990],
        [ 845],
        [ 845],
        [ 936],
        [1085],
        [1036],
        [1107],
        [1293],
        [ 952],
        [ 979],
        [ 981],
        [ 874],
        [1178],
        [2580]], device='cuda:0')
[2024-07-24 10:21:50,267][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[40599],
        [41429],
        [37557],
        [40641],
        [38478],
        [42430],
        [40654],
        [38986],
        [39812],
        [39377],
        [36998],
        [40168],
        [39587],
        [37189],
        [32992]], device='cuda:0')
[2024-07-24 10:21:50,269][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[14282],
        [20592],
        [17182],
        [25640],
        [26382],
        [ 9943],
        [24910],
        [25081],
        [31652],
        [25309],
        [18680],
        [21473],
        [16888],
        [15297],
        [17950]], device='cuda:0')
[2024-07-24 10:21:50,270][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[19696],
        [19696],
        [19696],
        [19696],
        [19696],
        [19696],
        [19696],
        [19696],
        [19696],
        [19696],
        [19696],
        [19696],
        [19696],
        [19696],
        [19696]], device='cuda:0')
[2024-07-24 10:21:50,308][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:50,309][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,310][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,311][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,312][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,314][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,315][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,316][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,317][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,318][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,319][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,320][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,321][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,323][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8071, 0.1929], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,324][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2221, 0.7779], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,326][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1384, 0.8616], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,327][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4427, 0.5573], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,328][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9979, 0.0021], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,330][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1206, 0.8794], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,331][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5810, 0.4190], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,332][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.7979, 0.2021], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,333][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4109, 0.5891], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,335][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7386, 0.2614], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,336][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.5846, 0.4154], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,337][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.2683e-06, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,338][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.1165, 0.7247, 0.1588], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,340][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.1486, 0.2593, 0.5921], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,341][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.0954, 0.2081, 0.6965], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,343][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.3368, 0.0588, 0.6044], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,343][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([9.9818e-01, 8.0248e-04, 1.0149e-03], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,345][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.0711, 0.0569, 0.8720], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,346][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.4467, 0.3086, 0.2446], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,347][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.8610, 0.0673, 0.0717], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,347][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.3196, 0.3747, 0.3057], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,348][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.7995, 0.0245, 0.1760], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,348][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.9025, 0.0341, 0.0635], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,348][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([5.8181e-07, 3.2282e-01, 6.7718e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,349][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4424, 0.1860, 0.3393, 0.0322], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,349][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0936, 0.1016, 0.2453, 0.5594], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,349][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0960, 0.1468, 0.2492, 0.5080], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,350][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1381, 0.0075, 0.4993, 0.3551], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,350][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9566, 0.0072, 0.0046, 0.0315], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,351][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.8351, 0.0051, 0.0541, 0.1058], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,352][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2441, 0.1504, 0.4131, 0.1924], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,353][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.6197, 0.0999, 0.1241, 0.1563], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,355][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3740, 0.2301, 0.1771, 0.2189], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,356][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.7001, 0.0206, 0.1662, 0.1131], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,358][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.7068, 0.1338, 0.0638, 0.0956], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,358][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([1.1155e-06, 6.9903e-02, 2.1611e-01, 7.1399e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,360][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.0449, 0.3990, 0.1139, 0.3975, 0.0447], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,361][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0761, 0.0792, 0.1975, 0.4809, 0.1663], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,362][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.0657, 0.0916, 0.2049, 0.3687, 0.2692], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,364][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.2895, 0.0051, 0.0708, 0.1315, 0.5030], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,364][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([9.9468e-01, 6.7470e-04, 5.5667e-04, 3.4986e-03, 5.8624e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,366][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0476, 0.0041, 0.0874, 0.2213, 0.6395], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,367][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.1928, 0.1540, 0.2475, 0.2812, 0.1244], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,369][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.5229, 0.0443, 0.0538, 0.0687, 0.3103], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,370][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.2353, 0.1943, 0.1665, 0.2090, 0.1949], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,372][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.6812, 0.0065, 0.0572, 0.0428, 0.2123], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,373][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.8029, 0.0240, 0.0481, 0.0529, 0.0721], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,374][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([1.2512e-07, 4.6837e-02, 1.0310e-01, 5.7160e-01, 2.7846e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,375][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0237, 0.2065, 0.1318, 0.3928, 0.1889, 0.0564], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,377][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0836, 0.0586, 0.1294, 0.2778, 0.1298, 0.3208], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,378][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0788, 0.0880, 0.1390, 0.2621, 0.1192, 0.3130], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,379][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ went] are: tensor([2.7252e-02, 2.8925e-04, 1.8733e-02, 2.4568e-02, 1.0597e-01, 8.2319e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,380][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ went] are: tensor([9.9736e-01, 2.1190e-04, 2.8078e-04, 1.4101e-03, 2.7307e-04, 4.6207e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,381][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ went] are: tensor([3.8949e-02, 2.3177e-04, 2.8691e-03, 3.2006e-02, 4.6746e-02, 8.7920e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,382][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.1096, 0.0916, 0.2823, 0.1753, 0.2148, 0.1264], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,383][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.3520, 0.0662, 0.0614, 0.0664, 0.2009, 0.2531], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,385][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.1094, 0.1722, 0.1540, 0.2089, 0.1762, 0.1793], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,386][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.5379, 0.0014, 0.0105, 0.0071, 0.0962, 0.3470], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,388][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.5317, 0.0923, 0.0690, 0.0951, 0.0298, 0.1821], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,388][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ went] are: tensor([4.9126e-07, 2.9419e-02, 7.6094e-02, 5.2830e-01, 2.3788e-01, 1.2831e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,390][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1736, 0.0290, 0.3096, 0.0122, 0.0482, 0.4249, 0.0025],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,391][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0548, 0.0270, 0.0809, 0.1460, 0.0739, 0.2262, 0.3912],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,393][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0458, 0.0552, 0.0887, 0.1747, 0.0968, 0.2579, 0.2810],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,394][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([7.2566e-02, 4.6859e-05, 3.3464e-03, 2.9499e-03, 3.3021e-02, 1.4540e-01,
        7.4267e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,395][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([9.9210e-01, 4.5205e-04, 4.3277e-04, 2.5795e-03, 4.0970e-04, 6.3554e-04,
        3.3901e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,395][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.1265e-01, 4.5771e-05, 1.2294e-03, 7.5561e-03, 1.4837e-02, 2.1628e-01,
        6.4740e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,397][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1113, 0.0809, 0.2040, 0.1496, 0.1644, 0.1736, 0.1162],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,398][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0577, 0.0155, 0.0106, 0.0112, 0.0450, 0.0529, 0.8071],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,400][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1378, 0.1436, 0.1182, 0.1551, 0.1351, 0.1483, 0.1618],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,401][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([4.7491e-01, 3.3191e-04, 3.1003e-03, 2.5718e-03, 3.2213e-02, 1.1575e-01,
        3.7113e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,402][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.3371, 0.0905, 0.0773, 0.1081, 0.0559, 0.1848, 0.1464],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,403][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([6.0593e-07, 3.6730e-02, 1.2163e-01, 3.3351e-01, 2.6033e-01, 8.9373e-02,
        1.5842e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,405][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.2533, 0.0908, 0.1818, 0.0265, 0.2105, 0.1583, 0.0495, 0.0294],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,405][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0486, 0.0282, 0.0675, 0.1217, 0.0649, 0.1497, 0.2866, 0.2328],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,405][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0536, 0.0476, 0.0735, 0.1265, 0.0712, 0.1863, 0.2022, 0.2392],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,406][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ the] are: tensor([2.1283e-01, 3.2543e-06, 4.7887e-04, 3.2297e-04, 5.6713e-03, 1.0303e-02,
        8.8663e-02, 6.8173e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,406][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ the] are: tensor([9.8487e-01, 5.3698e-04, 7.1197e-04, 2.9141e-03, 8.0961e-04, 9.5774e-04,
        3.6803e-03, 5.5208e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,406][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ the] are: tensor([1.9120e-02, 5.6042e-06, 9.4707e-05, 3.1976e-04, 1.2039e-03, 1.5329e-02,
        8.3345e-02, 8.8058e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,407][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1073, 0.0579, 0.1657, 0.1120, 0.1582, 0.1800, 0.1023, 0.1166],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,407][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0695, 0.0286, 0.0138, 0.0123, 0.0468, 0.0550, 0.6240, 0.1500],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,408][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0831, 0.1177, 0.1056, 0.1445, 0.1242, 0.1235, 0.1459, 0.1555],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,408][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ the] are: tensor([6.5363e-01, 4.0918e-05, 5.0604e-04, 2.6725e-04, 4.6500e-03, 1.3027e-02,
        4.8811e-02, 2.7906e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,410][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1899, 0.0669, 0.0819, 0.0884, 0.0615, 0.1501, 0.1190, 0.2422],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,410][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.7139e-06, 3.8130e-02, 1.0118e-01, 3.7113e-01, 1.9988e-01, 7.0294e-02,
        1.4777e-01, 7.1613e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,412][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ house] are: tensor([0.0609, 0.0897, 0.2250, 0.0794, 0.1244, 0.0800, 0.0735, 0.1570, 0.1102],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,413][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ house] are: tensor([0.0327, 0.0320, 0.0661, 0.1218, 0.0573, 0.1339, 0.2817, 0.2111, 0.0635],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,414][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.0373, 0.0288, 0.0482, 0.0907, 0.0379, 0.1536, 0.1591, 0.2071, 0.2373],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,415][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ house] are: tensor([6.8148e-03, 1.7487e-06, 1.4702e-04, 1.6585e-04, 1.8465e-03, 8.9577e-03,
        5.5801e-02, 8.7895e-01, 4.7313e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,416][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ house] are: tensor([9.7903e-01, 6.3127e-04, 6.0783e-04, 3.7435e-03, 6.6642e-04, 8.3489e-04,
        3.7174e-03, 7.2085e-03, 3.5561e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,417][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ house] are: tensor([1.5311e-02, 1.0047e-06, 2.6196e-05, 2.1245e-04, 9.3774e-04, 5.0950e-03,
        3.6090e-02, 6.7092e-01, 2.7141e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,419][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ house] are: tensor([0.0920, 0.0612, 0.1395, 0.1174, 0.1107, 0.1450, 0.1141, 0.1415, 0.0785],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,420][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ house] are: tensor([0.0511, 0.0271, 0.0157, 0.0169, 0.0395, 0.0499, 0.4460, 0.1221, 0.2318],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,421][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.0720, 0.1018, 0.0949, 0.1272, 0.1115, 0.1074, 0.1273, 0.1357, 0.1223],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,422][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ house] are: tensor([6.7762e-02, 5.0923e-05, 8.0056e-04, 4.2213e-04, 4.9868e-03, 2.1216e-02,
        8.0541e-02, 7.4311e-01, 8.1115e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,424][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.2544, 0.0288, 0.0399, 0.0535, 0.0344, 0.0873, 0.0874, 0.1971, 0.2173],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,425][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ house] are: tensor([1.5325e-06, 3.3760e-02, 8.5805e-02, 3.0013e-01, 2.0373e-01, 8.8458e-02,
        1.3707e-01, 7.7348e-02, 7.3694e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,426][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.1320, 0.0195, 0.2393, 0.0061, 0.1288, 0.0739, 0.0085, 0.1314, 0.2471,
        0.0135], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,427][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0718, 0.0251, 0.0507, 0.0895, 0.0421, 0.1143, 0.2009, 0.1921, 0.0528,
        0.1607], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,429][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0598, 0.0277, 0.0457, 0.0773, 0.0497, 0.1215, 0.1223, 0.1580, 0.1869,
        0.1510], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,430][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [.] are: tensor([8.6096e-02, 1.4016e-06, 2.1625e-04, 1.4368e-04, 2.8143e-03, 5.6034e-03,
        3.0939e-02, 3.5552e-01, 2.4077e-02, 4.9459e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,431][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [.] are: tensor([9.7689e-01, 6.0351e-04, 5.5077e-04, 3.4214e-03, 6.6602e-04, 7.1973e-04,
        2.8049e-03, 4.0514e-03, 2.2754e-03, 8.0164e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,432][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [.] are: tensor([3.3530e-01, 7.4397e-07, 2.2123e-05, 9.6556e-05, 6.4349e-04, 1.0527e-03,
        7.7123e-03, 5.4464e-02, 2.4556e-02, 5.7615e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,433][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0832, 0.0463, 0.1311, 0.0779, 0.1234, 0.1437, 0.0952, 0.1220, 0.1196,
        0.0578], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,435][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0575, 0.0403, 0.0270, 0.0199, 0.0449, 0.0379, 0.2907, 0.1012, 0.1677,
        0.2130], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,436][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0568, 0.0942, 0.0854, 0.1162, 0.0976, 0.0966, 0.1154, 0.1210, 0.1086,
        0.1082], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,437][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [.] are: tensor([4.4057e-01, 3.3385e-05, 4.8975e-04, 2.1295e-04, 4.4825e-03, 1.2186e-02,
        3.8336e-02, 2.3737e-01, 4.9650e-02, 2.1667e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,438][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.2683, 0.0415, 0.0462, 0.0533, 0.0266, 0.0957, 0.0667, 0.1493, 0.1366,
        0.1159], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,439][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [.] are: tensor([1.3437e-07, 2.2559e-02, 9.2981e-02, 3.0956e-01, 1.7461e-01, 5.6273e-02,
        1.3473e-01, 6.1896e-02, 7.0981e-02, 7.6416e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,441][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.0378, 0.1710, 0.0528, 0.2312, 0.0446, 0.0379, 0.1168, 0.1182, 0.1035,
        0.0433, 0.0429], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,442][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.0287, 0.0288, 0.0482, 0.1020, 0.0483, 0.1064, 0.2404, 0.1648, 0.0485,
        0.1520, 0.0318], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,444][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.0432, 0.0148, 0.0399, 0.0546, 0.0426, 0.0838, 0.0863, 0.1151, 0.1568,
        0.1230, 0.2399], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,445][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([1.2654e-01, 1.4668e-06, 4.2473e-05, 6.8749e-05, 7.1014e-04, 5.8946e-04,
        4.1919e-03, 1.0850e-02, 1.8729e-03, 6.4658e-02, 7.9048e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,446][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([9.8626e-01, 2.9272e-04, 3.3588e-04, 1.7804e-03, 2.7200e-04, 3.3147e-04,
        1.3513e-03, 2.9242e-03, 1.3894e-03, 4.1814e-03, 8.8205e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,447][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([1.6988e-02, 4.9148e-07, 6.0375e-06, 6.0987e-05, 1.7817e-04, 1.7869e-04,
        1.3022e-03, 1.5312e-02, 7.7491e-03, 2.7967e-01, 6.7855e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,448][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.0880, 0.0468, 0.0369, 0.0803, 0.0856, 0.1268, 0.0913, 0.1247, 0.1404,
        0.0887, 0.0904], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,450][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.0692, 0.0075, 0.0089, 0.0118, 0.0345, 0.0404, 0.3602, 0.0465, 0.1181,
        0.1173, 0.1855], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,451][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.0565, 0.0844, 0.0781, 0.1021, 0.0888, 0.0877, 0.1012, 0.1059, 0.0979,
        0.0964, 0.1009], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,452][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([5.7138e-01, 2.2956e-05, 2.2836e-04, 1.0964e-04, 1.8031e-03, 2.0931e-03,
        8.2307e-03, 2.1013e-02, 7.7220e-03, 4.1984e-02, 3.4542e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,453][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.7428, 0.0113, 0.0098, 0.0137, 0.0065, 0.0309, 0.0236, 0.0581, 0.0439,
        0.0332, 0.0264], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,454][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([2.4654e-07, 1.0629e-02, 1.9142e-02, 1.3318e-01, 5.9348e-02, 1.5967e-02,
        5.7126e-02, 2.8201e-02, 2.3450e-02, 4.3631e-02, 6.0932e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,456][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0038, 0.0723, 0.0229, 0.1006, 0.1104, 0.0332, 0.1551, 0.1845, 0.1962,
        0.0782, 0.0315, 0.0113], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,457][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0286, 0.0215, 0.0439, 0.0923, 0.0376, 0.0899, 0.2195, 0.1653, 0.0480,
        0.1657, 0.0318, 0.0559], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,459][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0335, 0.0175, 0.0328, 0.0504, 0.0284, 0.0644, 0.0777, 0.1069, 0.1175,
        0.1078, 0.2349, 0.1283], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,460][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([2.5412e-04, 1.5020e-08, 3.8789e-06, 1.6672e-06, 3.0594e-05, 3.1305e-05,
        5.5137e-04, 3.9195e-03, 2.8435e-04, 1.6209e-02, 9.5167e-01, 2.7042e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,461][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([9.7792e-01, 3.9113e-04, 3.7125e-04, 2.3202e-03, 3.3660e-04, 5.4938e-04,
        2.2045e-03, 4.6234e-03, 1.7452e-03, 6.6871e-03, 9.7264e-04, 1.8816e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,462][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([1.0832e-03, 2.1530e-08, 5.8082e-07, 5.6492e-06, 1.0755e-05, 2.1159e-05,
        2.9193e-04, 8.4311e-03, 3.1761e-03, 1.2213e-01, 7.2215e-01, 1.4270e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,462][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0543, 0.0352, 0.1071, 0.0611, 0.0919, 0.0779, 0.0632, 0.0839, 0.0844,
        0.0529, 0.2272, 0.0608], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,463][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0634, 0.0195, 0.0149, 0.0187, 0.0300, 0.0365, 0.2551, 0.0678, 0.0891,
        0.1590, 0.1642, 0.0817], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,463][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0605, 0.0751, 0.0683, 0.0886, 0.0791, 0.0803, 0.0887, 0.0960, 0.0882,
        0.0891, 0.0925, 0.0935], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,463][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([8.4673e-02, 6.3935e-06, 5.1978e-05, 3.2065e-05, 6.3785e-04, 1.7266e-03,
        6.7108e-03, 4.4217e-02, 6.0921e-03, 5.9645e-02, 3.9282e-01, 4.0338e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,464][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.4078, 0.0287, 0.0193, 0.0318, 0.0097, 0.0611, 0.0434, 0.0942, 0.0653,
        0.0645, 0.0418, 0.1325], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,464][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([9.8193e-07, 4.6509e-03, 9.5476e-03, 6.5113e-02, 2.7973e-02, 1.2045e-02,
        3.3371e-02, 1.9855e-02, 1.6834e-02, 2.6514e-02, 3.1762e-01, 4.6647e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,465][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1878, 0.0682, 0.0649, 0.0217, 0.0796, 0.0561, 0.0298, 0.0373, 0.2096,
        0.0341, 0.0878, 0.1029, 0.0200], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,465][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0289, 0.0211, 0.0485, 0.0859, 0.0434, 0.0881, 0.1867, 0.1375, 0.0530,
        0.1446, 0.0383, 0.0589, 0.0653], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,466][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0525, 0.0150, 0.0239, 0.0372, 0.0211, 0.0593, 0.0636, 0.0854, 0.0911,
        0.0833, 0.1423, 0.1237, 0.2018], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,467][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([4.9924e-02, 8.5033e-09, 1.8358e-06, 9.7854e-07, 3.6268e-05, 1.6271e-05,
        1.6934e-04, 4.7174e-04, 8.6221e-05, 4.0576e-03, 4.2990e-01, 1.3694e-02,
        5.0164e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,468][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([9.5027e-01, 6.1776e-04, 8.6577e-04, 3.3924e-03, 8.3440e-04, 1.1753e-03,
        5.5249e-03, 8.0939e-03, 3.4127e-03, 9.0067e-03, 1.7429e-03, 2.2551e-03,
        1.2808e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,469][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([7.7275e-02, 6.3719e-09, 2.7663e-07, 6.0765e-07, 7.1716e-06, 3.3772e-06,
        3.6186e-05, 3.2912e-04, 2.4088e-04, 1.1121e-02, 3.7421e-01, 1.6986e-02,
        5.1979e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,471][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0685, 0.0352, 0.0705, 0.0663, 0.0799, 0.0903, 0.0591, 0.0856, 0.0796,
        0.0551, 0.1411, 0.1111, 0.0576], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,472][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0660, 0.0168, 0.0101, 0.0111, 0.0278, 0.0373, 0.2803, 0.0644, 0.0861,
        0.1453, 0.1412, 0.0558, 0.0578], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,473][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0445, 0.0653, 0.0623, 0.0832, 0.0737, 0.0702, 0.0832, 0.0882, 0.0799,
        0.0803, 0.0841, 0.0839, 0.1012], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,474][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([3.5196e-01, 7.1192e-07, 1.1949e-05, 4.0550e-06, 1.4739e-04, 1.3643e-04,
        5.2116e-04, 1.9665e-03, 4.9877e-04, 3.9872e-03, 1.0090e-01, 6.4598e-02,
        4.7526e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,476][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1289, 0.0262, 0.0314, 0.0363, 0.0248, 0.0617, 0.0542, 0.1028, 0.1172,
        0.0844, 0.0842, 0.1025, 0.1454], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,477][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([8.0291e-07, 4.3604e-03, 1.0352e-02, 4.2305e-02, 2.2469e-02, 4.8726e-03,
        1.9798e-02, 1.0092e-02, 8.1414e-03, 1.4178e-02, 1.9431e-01, 2.0991e-01,
        4.5921e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,478][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0397, 0.0620, 0.0976, 0.0570, 0.0263, 0.0249, 0.0807, 0.0953, 0.0714,
        0.0305, 0.0945, 0.0773, 0.1636, 0.0793], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,479][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0250, 0.0285, 0.0499, 0.0949, 0.0434, 0.0867, 0.2024, 0.1327, 0.0416,
        0.1129, 0.0312, 0.0537, 0.0672, 0.0299], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,481][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.0650, 0.0101, 0.0181, 0.0258, 0.0158, 0.0444, 0.0428, 0.0593, 0.0624,
        0.0520, 0.1158, 0.1001, 0.1525, 0.2357], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,482][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([4.0650e-02, 2.5397e-09, 3.6587e-07, 1.8365e-07, 5.8582e-06, 1.5631e-06,
        1.2024e-05, 2.9605e-05, 6.9694e-06, 2.1406e-04, 3.9612e-02, 8.0853e-04,
        3.5482e-02, 8.8318e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,483][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([9.8601e-01, 2.2551e-04, 2.0333e-04, 1.4160e-03, 2.2478e-04, 2.6574e-04,
        7.8952e-04, 1.6814e-03, 6.9317e-04, 2.4737e-03, 4.5425e-04, 5.7618e-04,
        2.4060e-03, 2.5772e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,484][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([1.0379e-02, 9.2739e-11, 2.1999e-09, 9.3322e-09, 5.3219e-08, 1.2454e-08,
        1.3419e-07, 1.6023e-06, 8.9760e-07, 3.4543e-05, 1.5497e-03, 6.0436e-05,
        4.3744e-03, 9.8360e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,485][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.0428, 0.0350, 0.0695, 0.0551, 0.0507, 0.0836, 0.0647, 0.0776, 0.0810,
        0.0525, 0.1341, 0.1307, 0.0820, 0.0408], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,487][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0725, 0.0145, 0.0118, 0.0116, 0.0291, 0.0322, 0.2547, 0.0507, 0.1021,
        0.1246, 0.1506, 0.0619, 0.0437, 0.0401], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,488][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.0430, 0.0608, 0.0590, 0.0755, 0.0685, 0.0639, 0.0742, 0.0785, 0.0718,
        0.0729, 0.0767, 0.0759, 0.0893, 0.0899], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,489][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([1.8928e-01, 2.8688e-07, 5.9132e-06, 1.5143e-06, 5.9702e-05, 3.5762e-05,
        1.1892e-04, 3.8046e-04, 1.0038e-04, 5.9217e-04, 2.7277e-02, 1.1143e-02,
        9.0011e-02, 6.8099e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,490][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.4099, 0.0200, 0.0183, 0.0236, 0.0078, 0.0292, 0.0266, 0.0678, 0.0546,
        0.0492, 0.0384, 0.0730, 0.1077, 0.0739], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,492][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([9.3481e-08, 2.3564e-03, 6.2789e-03, 3.0198e-02, 1.3560e-02, 3.0877e-03,
        1.2219e-02, 6.2867e-03, 5.9880e-03, 8.5815e-03, 1.7741e-01, 1.9526e-01,
        3.9310e-01, 1.4567e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,493][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0896, 0.0138, 0.1102, 0.0066, 0.0215, 0.1378, 0.0014, 0.0868, 0.0698,
        0.0101, 0.1261, 0.0664, 0.0863, 0.1720, 0.0016], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,495][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0264, 0.0136, 0.0336, 0.0585, 0.0275, 0.0730, 0.1369, 0.1259, 0.0468,
        0.1351, 0.0304, 0.0488, 0.0629, 0.0318, 0.1488], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,496][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0309, 0.0102, 0.0164, 0.0247, 0.0167, 0.0433, 0.0412, 0.0557, 0.0643,
        0.0551, 0.0911, 0.0843, 0.1336, 0.2147, 0.1178], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,497][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([3.2858e-03, 3.1749e-10, 7.9961e-08, 3.6854e-08, 1.4101e-06, 4.8449e-07,
        3.7590e-06, 1.8836e-05, 3.1870e-06, 1.2812e-04, 2.1599e-02, 4.0766e-04,
        3.2989e-02, 8.5809e-01, 8.3470e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,498][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([9.6925e-01, 3.0505e-04, 3.0660e-04, 1.8139e-03, 3.1966e-04, 4.9724e-04,
        2.0985e-03, 3.3540e-03, 1.3799e-03, 4.2198e-03, 7.1722e-04, 1.0819e-03,
        4.7601e-03, 4.0462e-03, 5.8472e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,499][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.4381e-03, 5.2815e-11, 1.8900e-09, 1.1438e-08, 3.3367e-08, 1.4407e-08,
        9.1531e-08, 1.8052e-06, 1.1441e-06, 9.6960e-05, 2.5283e-03, 5.7394e-05,
        4.3408e-03, 9.7956e-01, 1.1972e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,501][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0464, 0.0279, 0.0722, 0.0514, 0.0563, 0.0610, 0.0408, 0.0734, 0.0784,
        0.0367, 0.1463, 0.1050, 0.0695, 0.0895, 0.0452], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,502][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0398, 0.0103, 0.0073, 0.0077, 0.0266, 0.0292, 0.3174, 0.0520, 0.1219,
        0.0989, 0.1167, 0.0349, 0.0346, 0.0288, 0.0739], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,504][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0471, 0.0569, 0.0506, 0.0667, 0.0581, 0.0594, 0.0668, 0.0718, 0.0663,
        0.0671, 0.0692, 0.0695, 0.0832, 0.0883, 0.0791], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,505][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([7.8989e-02, 6.3814e-08, 9.4632e-07, 5.3692e-07, 1.6663e-05, 1.2490e-05,
        4.6732e-05, 2.0230e-04, 4.4944e-05, 4.6377e-04, 1.1195e-02, 5.0498e-03,
        6.1298e-02, 6.8972e-01, 1.5296e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,506][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1571, 0.0309, 0.0198, 0.0298, 0.0137, 0.0576, 0.0373, 0.0767, 0.0732,
        0.0612, 0.0467, 0.0959, 0.1116, 0.0827, 0.1059], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,507][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.4994e-07, 2.4983e-03, 6.8933e-03, 2.8648e-02, 1.4637e-02, 3.3632e-03,
        1.2394e-02, 7.0948e-03, 6.1308e-03, 8.7399e-03, 1.6019e-01, 1.5749e-01,
        3.6954e-01, 1.5432e-01, 6.8071e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,545][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:50,546][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,547][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,548][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,549][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,551][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,552][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,553][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,554][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,555][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,556][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,557][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,558][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,560][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2779, 0.7221], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,561][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.3134, 0.6866], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,562][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7614, 0.2386], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,564][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4427, 0.5573], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,565][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4626, 0.5374], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,566][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2659, 0.7341], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,568][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.7145, 0.2855], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,569][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2987, 0.7013], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,571][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9806, 0.0194], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,572][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7386, 0.2614], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,573][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9843, 0.0157], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,574][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([1.0000e+00, 2.7697e-06], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,576][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.4769, 0.0643, 0.4589], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,577][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.2680, 0.1523, 0.5798], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,578][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.5668, 0.0564, 0.3768], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,580][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.3368, 0.0588, 0.6044], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,581][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.2535, 0.1272, 0.6194], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,582][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.1459, 0.0627, 0.7913], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,583][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.6621, 0.1789, 0.1591], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,583][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.0994, 0.1659, 0.7347], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,583][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.8830, 0.0427, 0.0742], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,584][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.7995, 0.0245, 0.1760], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,584][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.9722, 0.0064, 0.0214], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,584][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.9935, 0.0013, 0.0052], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,585][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2212, 0.0080, 0.0649, 0.7059], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,585][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1724, 0.0184, 0.0741, 0.7351], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,586][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5295, 0.0663, 0.1996, 0.2046], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,587][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1381, 0.0075, 0.4993, 0.3551], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,588][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2712, 0.2036, 0.0169, 0.5083], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,589][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2273, 0.0346, 0.3134, 0.4247], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,591][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5591, 0.0354, 0.0794, 0.3261], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,592][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0347, 0.0400, 0.1419, 0.7834], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,593][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9647, 0.0102, 0.0103, 0.0148], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,595][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.7001, 0.0206, 0.1662, 0.1131], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,596][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9810, 0.0083, 0.0035, 0.0072], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,597][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([2.5284e-01, 1.8227e-07, 8.0273e-03, 7.3913e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,598][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.3124, 0.0027, 0.0377, 0.2670, 0.3801], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,600][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0901, 0.0045, 0.0301, 0.2740, 0.6013], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,601][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.6151, 0.0292, 0.0940, 0.0759, 0.1857], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,603][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.2895, 0.0051, 0.0708, 0.1315, 0.5030], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,604][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.2610, 0.1125, 0.1434, 0.1232, 0.3599], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,605][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.1075, 0.0071, 0.0832, 0.1386, 0.6636], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,607][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.3462, 0.0519, 0.0584, 0.4691, 0.0744], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,608][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.0264, 0.0166, 0.0795, 0.2906, 0.5869], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,610][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.8035, 0.0204, 0.0470, 0.0486, 0.0805], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,611][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.6812, 0.0065, 0.0572, 0.0428, 0.2123], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,613][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.9225, 0.0033, 0.0108, 0.0090, 0.0544], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,613][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([4.6935e-01, 1.0528e-08, 2.8903e-06, 4.6515e-01, 6.5491e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,614][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([1.4343e-01, 4.2113e-05, 4.5603e-04, 1.0399e-02, 2.3144e-02, 8.2253e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,615][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([4.4276e-02, 2.2319e-04, 1.8473e-03, 2.9468e-02, 8.5818e-02, 8.3837e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,617][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.6787, 0.0116, 0.0356, 0.0356, 0.0551, 0.1834], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,618][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([2.7252e-02, 2.8925e-04, 1.8733e-02, 2.4568e-02, 1.0597e-01, 8.2319e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,619][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.1108, 0.0810, 0.0337, 0.1082, 0.0848, 0.5815], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,620][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.0713, 0.0008, 0.0100, 0.0465, 0.1552, 0.7163], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,622][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.4151, 0.0325, 0.0481, 0.2455, 0.0743, 0.1845], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,623][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0043, 0.0016, 0.0045, 0.0353, 0.0599, 0.8943], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,625][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.8411, 0.0102, 0.0128, 0.0276, 0.0414, 0.0668], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,626][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.5379, 0.0014, 0.0105, 0.0071, 0.0962, 0.3470], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,628][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.9775, 0.0040, 0.0025, 0.0041, 0.0031, 0.0089], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,628][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([2.2266e-02, 6.8517e-16, 1.4517e-09, 1.7037e-06, 4.2531e-03, 9.7348e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,629][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([6.0806e-02, 2.8177e-06, 3.8930e-05, 5.6871e-04, 1.8449e-03, 8.3510e-02,
        8.5323e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,630][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.8074e-02, 1.9991e-05, 2.0319e-04, 2.2569e-03, 1.0044e-02, 9.1832e-02,
        8.4757e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,632][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.6555, 0.0048, 0.0141, 0.0139, 0.0313, 0.0839, 0.1963],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,633][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([7.2566e-02, 4.6859e-05, 3.3464e-03, 2.9499e-03, 3.3021e-02, 1.4540e-01,
        7.4267e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,634][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.3255, 0.1688, 0.0217, 0.3207, 0.0860, 0.0508, 0.0265],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,635][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.0751e-02, 6.4151e-05, 1.2296e-03, 3.9789e-03, 1.9008e-02, 7.3457e-02,
        8.1151e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,636][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.4443, 0.0067, 0.0139, 0.0403, 0.0226, 0.0420, 0.4301],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,637][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([2.5808e-03, 6.1199e-04, 2.2631e-03, 1.0037e-02, 2.2826e-02, 1.8667e-01,
        7.7501e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,639][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.8515, 0.0062, 0.0084, 0.0145, 0.0256, 0.0424, 0.0514],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,640][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([4.7491e-01, 3.3191e-04, 3.1003e-03, 2.5718e-03, 3.2213e-02, 1.1575e-01,
        3.7113e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,640][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.9273, 0.0054, 0.0044, 0.0070, 0.0104, 0.0121, 0.0335],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,641][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.1425e-02, 5.0559e-20, 4.3806e-12, 8.4121e-12, 2.9127e-05, 2.3917e-03,
        9.8615e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,641][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([3.6690e-02, 4.0023e-08, 8.8375e-07, 1.3386e-05, 8.1945e-05, 1.1763e-03,
        7.4226e-02, 8.8781e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,641][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([9.1427e-02, 1.9737e-06, 2.2509e-05, 2.7524e-04, 2.1584e-03, 7.1088e-03,
        1.4247e-01, 7.5653e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,642][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.7001, 0.0010, 0.0048, 0.0034, 0.0109, 0.0260, 0.0684, 0.1853],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,642][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([2.1283e-01, 3.2543e-06, 4.7887e-04, 3.2297e-04, 5.6713e-03, 1.0303e-02,
        8.8663e-02, 6.8173e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,642][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.2435, 0.1120, 0.0799, 0.1856, 0.1969, 0.0174, 0.0090, 0.1557],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,643][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([7.2645e-02, 3.2534e-06, 6.5610e-05, 1.4653e-04, 1.3038e-03, 3.8027e-03,
        9.6388e-02, 8.2565e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,643][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2859, 0.0047, 0.0100, 0.0250, 0.0167, 0.0306, 0.2560, 0.3711],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,644][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([4.3370e-03, 1.6252e-04, 7.7716e-04, 2.7224e-03, 7.5974e-03, 5.0843e-02,
        2.2549e-01, 7.0807e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,645][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.6337, 0.0043, 0.0089, 0.0133, 0.0280, 0.0477, 0.0692, 0.1950],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,646][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([6.5363e-01, 4.0918e-05, 5.0604e-04, 2.6725e-04, 4.6500e-03, 1.3027e-02,
        4.8811e-02, 2.7906e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,647][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.8001, 0.0058, 0.0084, 0.0092, 0.0155, 0.0168, 0.0392, 0.1050],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,648][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([9.9903e-01, 9.6567e-24, 8.4896e-17, 2.3535e-14, 1.9168e-09, 6.9905e-09,
        9.3279e-04, 4.1570e-05], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,649][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([1.1500e-03, 2.3378e-08, 5.9188e-07, 6.1755e-06, 2.9107e-05, 1.1927e-03,
        6.5379e-02, 9.2339e-01, 8.8477e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,650][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([2.8266e-03, 7.7918e-07, 7.8541e-06, 9.6829e-05, 5.8745e-04, 5.1796e-03,
        6.5598e-02, 8.8155e-01, 4.4151e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,651][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([0.3039, 0.0023, 0.0088, 0.0079, 0.0147, 0.0589, 0.1464, 0.3987, 0.0584],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,652][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([6.8148e-03, 1.7487e-06, 1.4702e-04, 1.6585e-04, 1.8465e-03, 8.9577e-03,
        5.5801e-02, 8.7895e-01, 4.7313e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,654][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([0.0973, 0.0367, 0.0200, 0.0754, 0.0228, 0.0114, 0.0013, 0.0375, 0.6976],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,655][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([2.1308e-03, 8.7308e-07, 2.0911e-05, 6.7012e-05, 6.3763e-04, 1.8541e-03,
        4.8310e-02, 9.1677e-01, 3.0210e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,656][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([0.0376, 0.0083, 0.0114, 0.0466, 0.0157, 0.0400, 0.3563, 0.4539, 0.0302],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,657][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([5.0964e-04, 6.2359e-05, 3.6819e-04, 1.1602e-03, 3.3315e-03, 2.9620e-02,
        1.4760e-01, 6.3654e-01, 1.8081e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,658][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([0.4958, 0.0035, 0.0157, 0.0147, 0.0512, 0.0411, 0.0630, 0.2239, 0.0910],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,659][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([6.7762e-02, 5.0923e-05, 8.0056e-04, 4.2213e-04, 4.9868e-03, 2.1216e-02,
        8.0541e-02, 7.4311e-01, 8.1115e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,661][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([0.8122, 0.0028, 0.0042, 0.0061, 0.0111, 0.0096, 0.0309, 0.0639, 0.0590],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,662][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([3.1107e-04, 1.4416e-21, 4.2903e-15, 1.0357e-12, 4.4556e-08, 2.9451e-06,
        1.7535e-01, 8.2338e-01, 9.5498e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,663][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([3.2559e-02, 1.5382e-08, 2.5214e-07, 4.7317e-06, 1.7030e-05, 3.5075e-04,
        1.5869e-02, 1.7006e-01, 1.2712e-03, 7.7986e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,664][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([5.2393e-02, 7.1977e-07, 7.6729e-06, 7.7835e-05, 4.8835e-04, 1.7041e-03,
        2.3049e-02, 1.4853e-01, 7.8121e-03, 7.6593e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,665][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.5218, 0.0007, 0.0032, 0.0027, 0.0079, 0.0147, 0.0367, 0.0862, 0.0189,
        0.3070], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,666][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([8.6096e-02, 1.4016e-06, 2.1625e-04, 1.4368e-04, 2.8143e-03, 5.6034e-03,
        3.0939e-02, 3.5552e-01, 2.4077e-02, 4.9459e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,668][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.1192, 0.0892, 0.0229, 0.2187, 0.0889, 0.0160, 0.0054, 0.0344, 0.2915,
        0.1138], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,668][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([1.5446e-02, 4.1450e-07, 1.0783e-05, 3.2668e-05, 3.2705e-04, 4.8272e-04,
        1.4744e-02, 1.8039e-01, 6.5927e-03, 7.8197e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,670][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.2207, 0.0027, 0.0061, 0.0154, 0.0102, 0.0192, 0.1715, 0.2585, 0.0252,
        0.2705], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,671][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([4.2405e-04, 2.9621e-05, 1.0875e-04, 7.2060e-04, 1.5422e-03, 1.0952e-02,
        5.0461e-02, 1.8591e-01, 5.2901e-02, 6.9695e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,672][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.5774, 0.0037, 0.0068, 0.0101, 0.0183, 0.0359, 0.0408, 0.0901, 0.0841,
        0.1328], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,673][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([4.4057e-01, 3.3385e-05, 4.8975e-04, 2.1295e-04, 4.4825e-03, 1.2186e-02,
        3.8336e-02, 2.3737e-01, 4.9650e-02, 2.1667e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,675][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.8677, 0.0022, 0.0032, 0.0030, 0.0052, 0.0061, 0.0135, 0.0344, 0.0197,
        0.0450], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,676][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([9.2341e-04, 1.7137e-27, 1.7864e-18, 1.5848e-18, 1.9389e-11, 4.3484e-11,
        1.8608e-07, 1.7947e-07, 2.0060e-07, 9.9908e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,677][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([1.8211e-01, 6.8165e-08, 1.2134e-06, 7.3391e-06, 3.9425e-05, 1.7377e-04,
        5.6285e-03, 2.6052e-02, 7.6016e-04, 1.7868e-01, 6.0655e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,678][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([8.8122e-02, 1.1189e-06, 8.4847e-06, 8.0534e-05, 7.9957e-04, 7.6828e-04,
        7.1092e-03, 2.5335e-02, 5.3543e-03, 3.2818e-01, 5.4424e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,679][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.4643, 0.0006, 0.0043, 0.0019, 0.0094, 0.0099, 0.0155, 0.0294, 0.0119,
        0.1408, 0.3120], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,680][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([1.2654e-01, 1.4668e-06, 4.2473e-05, 6.8749e-05, 7.1014e-04, 5.8946e-04,
        4.1919e-03, 1.0850e-02, 1.8729e-03, 6.4658e-02, 7.9048e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,682][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.0768, 0.0294, 0.1473, 0.0314, 0.2216, 0.0125, 0.0021, 0.0342, 0.1965,
        0.0437, 0.2045], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,682][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([2.6684e-02, 8.8362e-07, 1.1325e-05, 4.6710e-05, 3.5070e-04, 2.5082e-04,
        4.7066e-03, 3.8879e-02, 2.8022e-03, 4.4665e-01, 4.7962e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,684][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.1373, 0.0040, 0.0029, 0.0200, 0.0067, 0.0189, 0.2087, 0.2367, 0.0206,
        0.3087, 0.0356], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,685][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([1.4469e-03, 4.1518e-05, 2.9951e-04, 8.3115e-04, 3.8915e-03, 9.0561e-03,
        4.4025e-02, 1.2170e-01, 3.3210e-02, 4.1802e-01, 3.6748e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,686][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.6110, 0.0048, 0.0092, 0.0118, 0.0247, 0.0269, 0.0255, 0.0652, 0.0666,
        0.0778, 0.0764], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,687][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([5.7138e-01, 2.2956e-05, 2.2836e-04, 1.0964e-04, 1.8031e-03, 2.0931e-03,
        8.2307e-03, 2.1013e-02, 7.7220e-03, 4.1984e-02, 3.4542e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,689][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.9412, 0.0011, 0.0017, 0.0018, 0.0038, 0.0045, 0.0074, 0.0115, 0.0093,
        0.0112, 0.0067], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,690][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([2.9342e-02, 1.0959e-24, 3.8091e-20, 1.1234e-17, 1.4095e-12, 3.3189e-13,
        1.1398e-09, 6.3617e-12, 2.5885e-11, 7.0436e-03, 9.6361e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,691][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([3.8462e-02, 3.8963e-09, 9.3926e-08, 1.1091e-06, 7.5865e-06, 4.3792e-05,
        2.8277e-03, 1.8996e-02, 1.4925e-04, 1.2465e-01, 5.0098e-01, 3.1388e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,692][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([5.6444e-03, 7.0749e-08, 6.7349e-07, 9.1861e-06, 6.1241e-05, 1.4511e-04,
        3.3635e-03, 3.3109e-02, 1.8943e-03, 3.3670e-01, 4.1432e-01, 2.0476e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,692][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([3.3447e-01, 3.2717e-04, 1.7043e-03, 1.1090e-03, 4.0297e-03, 6.4444e-03,
        1.6334e-02, 3.7988e-02, 6.4145e-03, 1.7693e-01, 3.4986e-01, 6.4392e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,693][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([2.5412e-04, 1.5020e-08, 3.8789e-06, 1.6672e-06, 3.0594e-05, 3.1305e-05,
        5.5137e-04, 3.9195e-03, 2.8435e-04, 1.6209e-02, 9.5167e-01, 2.7042e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,695][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0503, 0.0586, 0.0430, 0.0840, 0.0401, 0.0652, 0.0093, 0.0760, 0.1594,
        0.0663, 0.0754, 0.2723], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,696][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([1.2350e-03, 5.9533e-08, 1.7298e-06, 5.3111e-06, 3.4630e-05, 2.6965e-05,
        1.5160e-03, 2.9361e-02, 8.4235e-04, 2.7436e-01, 5.7753e-01, 1.1508e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,697][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0885, 0.0025, 0.0036, 0.0138, 0.0059, 0.0127, 0.1609, 0.2232, 0.0156,
        0.2643, 0.0679, 0.1409], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,698][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([1.6742e-04, 7.5838e-06, 2.7739e-05, 1.6094e-04, 5.7770e-04, 4.2604e-03,
        1.4252e-02, 5.1065e-02, 1.5721e-02, 2.1789e-01, 1.3350e-01, 5.6237e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,699][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.6181, 0.0027, 0.0046, 0.0071, 0.0132, 0.0276, 0.0232, 0.0522, 0.0564,
        0.0849, 0.0443, 0.0657], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,699][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([8.4673e-02, 6.3935e-06, 5.1978e-05, 3.2065e-05, 6.3785e-04, 1.7266e-03,
        6.7108e-03, 4.4217e-02, 6.0921e-03, 5.9645e-02, 3.9282e-01, 4.0338e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,700][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([9.4771e-01, 1.0008e-03, 6.3089e-04, 1.3367e-03, 1.1237e-03, 2.5672e-03,
        5.7637e-03, 1.0145e-02, 5.0284e-03, 1.2395e-02, 2.5170e-03, 9.7759e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,700][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([2.0764e-10, 4.5144e-34, 1.2990e-25, 9.4485e-25, 2.4061e-17, 1.0491e-17,
        1.3456e-12, 2.4254e-14, 4.6086e-13, 2.3240e-05, 9.9786e-01, 2.1137e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,700][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.1204e-02, 2.6446e-11, 1.0381e-09, 7.6171e-09, 1.2081e-07, 3.9176e-07,
        2.9282e-05, 1.0377e-04, 2.0307e-06, 2.4857e-03, 1.5113e-02, 1.4378e-02,
        9.5668e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,701][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([7.0199e-02, 5.4569e-09, 9.5316e-08, 7.8798e-07, 1.4784e-05, 1.0135e-05,
        1.7934e-04, 3.6140e-04, 7.2137e-05, 9.4228e-03, 7.8741e-02, 1.5784e-02,
        8.2521e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,701][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([5.2116e-01, 6.8896e-05, 4.5053e-04, 2.7047e-04, 1.3322e-03, 1.8559e-03,
        4.5663e-03, 9.1699e-03, 1.8082e-03, 5.6015e-02, 1.4150e-01, 3.5510e-02,
        2.2629e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,702][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([4.9924e-02, 8.5033e-09, 1.8358e-06, 9.7854e-07, 3.6268e-05, 1.6271e-05,
        1.6934e-04, 4.7174e-04, 8.6221e-05, 4.0576e-03, 4.2990e-01, 1.3694e-02,
        5.0164e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,703][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0590, 0.0419, 0.0352, 0.0591, 0.0626, 0.0164, 0.0019, 0.0335, 0.2883,
        0.0462, 0.0550, 0.0129, 0.2880], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,704][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([2.7991e-02, 5.6713e-09, 2.9702e-07, 3.9693e-07, 1.5561e-05, 2.7820e-06,
        1.7520e-04, 1.0610e-03, 5.8429e-05, 2.6261e-02, 1.9745e-01, 1.4719e-02,
        7.3226e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,706][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2035, 0.0013, 0.0024, 0.0047, 0.0040, 0.0065, 0.0496, 0.0745, 0.0094,
        0.0885, 0.0485, 0.0680, 0.4391], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,707][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([8.5667e-04, 4.7915e-06, 2.2320e-05, 7.5137e-05, 3.0375e-04, 1.2908e-03,
        5.5531e-03, 1.2371e-02, 5.0693e-03, 6.3496e-02, 8.8315e-02, 1.3791e-01,
        6.8473e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,708][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2396, 0.0011, 0.0040, 0.0040, 0.0120, 0.0176, 0.0248, 0.0834, 0.0701,
        0.1195, 0.0879, 0.0706, 0.2655], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,709][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([3.5196e-01, 7.1192e-07, 1.1949e-05, 4.0550e-06, 1.4739e-04, 1.3643e-04,
        5.2116e-04, 1.9665e-03, 4.9877e-04, 3.9872e-03, 1.0090e-01, 6.4598e-02,
        4.7526e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,710][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.6523, 0.0029, 0.0048, 0.0047, 0.0102, 0.0086, 0.0235, 0.0500, 0.0486,
        0.0788, 0.0253, 0.0199, 0.0703], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,711][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.1616e-01, 6.7923e-34, 4.8298e-25, 7.7239e-25, 2.7932e-16, 5.8292e-19,
        1.3359e-14, 8.4885e-18, 2.0379e-15, 1.3407e-07, 7.7899e-01, 2.4225e-04,
        4.6043e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,712][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([7.7316e-02, 2.7077e-11, 6.0806e-10, 4.0396e-09, 4.1472e-08, 1.2345e-07,
        5.6453e-06, 1.5452e-05, 1.8944e-07, 2.3197e-04, 2.7364e-03, 2.7801e-03,
        1.1469e-01, 8.0222e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,713][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([1.9549e-02, 7.3332e-10, 8.0662e-09, 4.8868e-08, 1.1707e-06, 4.9328e-07,
        9.7598e-06, 1.3307e-05, 1.8186e-06, 1.6150e-04, 1.8820e-03, 3.3777e-04,
        2.5405e-02, 9.5264e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,714][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([7.4847e-01, 6.7821e-05, 2.5582e-04, 2.2308e-04, 1.1087e-03, 1.1702e-03,
        2.3815e-03, 3.0283e-03, 9.7936e-04, 1.5128e-02, 4.3571e-02, 1.2880e-02,
        5.6095e-02, 1.1464e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,715][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([4.0650e-02, 2.5397e-09, 3.6587e-07, 1.8365e-07, 5.8582e-06, 1.5631e-06,
        1.2024e-05, 2.9605e-05, 6.9694e-06, 2.1406e-04, 3.9612e-02, 8.0853e-04,
        3.5482e-02, 8.8318e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,717][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0398, 0.0191, 0.0167, 0.0237, 0.0463, 0.0081, 0.0008, 0.0123, 0.1966,
        0.0275, 0.0232, 0.0147, 0.0990, 0.4724], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,718][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([1.6172e-02, 1.1088e-09, 3.1486e-08, 9.0202e-08, 1.7327e-06, 2.2988e-07,
        8.6821e-06, 3.8248e-05, 3.4770e-06, 4.8225e-04, 5.2961e-03, 5.1536e-04,
        3.3509e-02, 9.4397e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,719][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.0568, 0.0035, 0.0042, 0.0115, 0.0057, 0.0112, 0.0807, 0.1006, 0.0126,
        0.1091, 0.0375, 0.0798, 0.4515, 0.0352], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,720][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([2.6758e-04, 1.4034e-06, 6.4710e-06, 1.3562e-05, 9.0098e-05, 2.9607e-04,
        1.0465e-03, 1.8373e-03, 1.0925e-03, 8.3349e-03, 1.8865e-02, 2.7926e-02,
        9.8088e-02, 8.4213e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,722][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.6199, 0.0014, 0.0058, 0.0036, 0.0129, 0.0072, 0.0090, 0.0195, 0.0172,
        0.0388, 0.0453, 0.0283, 0.0657, 0.1253], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,723][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([1.8928e-01, 2.8688e-07, 5.9132e-06, 1.5143e-06, 5.9702e-05, 3.5762e-05,
        1.1892e-04, 3.8046e-04, 1.0038e-04, 5.9217e-04, 2.7277e-02, 1.1143e-02,
        9.0011e-02, 6.8099e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,724][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.9317, 0.0011, 0.0013, 0.0018, 0.0016, 0.0012, 0.0040, 0.0081, 0.0049,
        0.0108, 0.0036, 0.0053, 0.0132, 0.0116], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,725][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([1.8750e-04, 6.3890e-38, 3.3910e-29, 5.5899e-30, 3.1922e-21, 1.1434e-25,
        4.0704e-21, 3.4479e-24, 9.3573e-22, 3.3448e-15, 1.1772e-06, 1.8184e-11,
        1.3833e-09, 9.9981e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,726][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([8.0416e-03, 1.5527e-12, 5.0062e-11, 4.1528e-10, 6.0871e-09, 1.5747e-08,
        3.5349e-07, 2.5528e-06, 2.7024e-08, 8.1155e-05, 6.1832e-04, 3.4452e-04,
        2.9297e-02, 4.4168e-01, 5.1993e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,727][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.7895e-03, 3.6258e-11, 5.4875e-10, 4.7947e-09, 6.4866e-08, 5.4771e-08,
        6.7025e-07, 3.3771e-06, 4.7324e-07, 6.0312e-05, 4.4201e-04, 5.7935e-05,
        9.3949e-03, 8.8854e-01, 9.9714e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,728][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([4.9157e-01, 3.0107e-05, 1.3802e-04, 1.0254e-04, 5.7130e-04, 6.5423e-04,
        1.5173e-03, 3.1258e-03, 7.9502e-04, 1.9344e-02, 4.4738e-02, 1.0466e-02,
        7.7290e-02, 2.2412e-01, 1.2555e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,729][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.2858e-03, 3.1749e-10, 7.9961e-08, 3.6854e-08, 1.4101e-06, 4.8449e-07,
        3.7590e-06, 1.8836e-05, 3.1870e-06, 1.2812e-04, 2.1599e-02, 4.0766e-04,
        3.2989e-02, 8.5809e-01, 8.3470e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,730][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1339, 0.0582, 0.0071, 0.1144, 0.0316, 0.0197, 0.0114, 0.0337, 0.1706,
        0.0921, 0.0101, 0.0092, 0.0771, 0.2149, 0.0160], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,731][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.6523e-04, 9.8467e-11, 3.0301e-09, 1.0017e-08, 1.5405e-07, 3.4703e-08,
        1.0131e-06, 1.3363e-05, 7.0739e-07, 3.6117e-04, 1.9466e-03, 1.5493e-04,
        1.8170e-02, 8.7345e-01, 1.0493e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,733][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1648, 0.0007, 0.0012, 0.0022, 0.0020, 0.0028, 0.0219, 0.0354, 0.0047,
        0.0407, 0.0249, 0.0287, 0.2157, 0.0284, 0.4257], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,734][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([7.9579e-05, 4.7822e-07, 1.7749e-06, 5.9335e-06, 2.8977e-05, 8.8627e-05,
        4.7067e-04, 9.2167e-04, 4.1936e-04, 5.1674e-03, 7.0696e-03, 1.1780e-02,
        6.4295e-02, 3.4588e-01, 5.6379e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,735][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.4438, 0.0008, 0.0015, 0.0022, 0.0054, 0.0078, 0.0073, 0.0166, 0.0169,
        0.0290, 0.0187, 0.0262, 0.0520, 0.2873, 0.0845], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,736][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([7.8989e-02, 6.3814e-08, 9.4632e-07, 5.3692e-07, 1.6663e-05, 1.2490e-05,
        4.6732e-05, 2.0230e-04, 4.4944e-05, 4.6377e-04, 1.1195e-02, 5.0498e-03,
        6.1298e-02, 6.8972e-01, 1.5296e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,738][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.7884, 0.0026, 0.0016, 0.0029, 0.0037, 0.0057, 0.0097, 0.0219, 0.0146,
        0.0331, 0.0062, 0.0129, 0.0321, 0.0280, 0.0366], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,739][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.3421e-08, 3.0829e-44, 7.0553e-34, 1.5167e-35, 1.2549e-24, 5.6770e-29,
        1.1444e-25, 7.7195e-28, 1.3264e-24, 3.5949e-18, 2.2963e-09, 1.1361e-14,
        2.6926e-12, 1.0000e+00, 2.3681e-06], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:50,740][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:50,742][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[23263],
        [46357],
        [49218],
        [46832],
        [49994],
        [48481],
        [47860],
        [47321],
        [49335],
        [45209],
        [49615],
        [47108],
        [48232],
        [47177],
        [46497]], device='cuda:0')
[2024-07-24 10:21:50,744][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[22701],
        [40597],
        [48464],
        [43854],
        [49965],
        [45338],
        [43552],
        [40299],
        [47025],
        [37579],
        [48471],
        [43544],
        [43261],
        [41884],
        [38227]], device='cuda:0')
[2024-07-24 10:21:50,745][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[  612],
        [ 1611],
        [10873],
        [ 6034],
        [ 5792],
        [ 3064],
        [ 3642],
        [ 1535],
        [ 3673],
        [ 3888],
        [ 4357],
        [ 3660],
        [ 3744],
        [ 4904],
        [ 3082]], device='cuda:0')
[2024-07-24 10:21:50,747][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[47454],
        [43213],
        [43764],
        [43709],
        [43661],
        [43957],
        [44855],
        [44661],
        [44701],
        [44716],
        [44641],
        [44649],
        [44597],
        [44546],
        [44893]], device='cuda:0')
[2024-07-24 10:21:50,748][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[27329],
        [47611],
        [47386],
        [43961],
        [46157],
        [47858],
        [48147],
        [47909],
        [48382],
        [48459],
        [48581],
        [48582],
        [48230],
        [48517],
        [48350]], device='cuda:0')
[2024-07-24 10:21:50,749][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[14168],
        [23797],
        [45900],
        [43442],
        [47691],
        [40200],
        [39906],
        [47210],
        [47995],
        [39715],
        [44848],
        [45301],
        [46561],
        [34726],
        [34357]], device='cuda:0')
[2024-07-24 10:21:50,751][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[11052],
        [11063],
        [11027],
        [10721],
        [10955],
        [10999],
        [10965],
        [10784],
        [10671],
        [11229],
        [11064],
        [11125],
        [10953],
        [11091],
        [11220]], device='cuda:0')
[2024-07-24 10:21:50,752][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 6633],
        [ 6360],
        [44718],
        [11642],
        [45119],
        [36222],
        [34603],
        [38673],
        [40011],
        [21675],
        [38436],
        [39515],
        [35591],
        [16851],
        [17001]], device='cuda:0')
[2024-07-24 10:21:50,754][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[45915],
        [45954],
        [45095],
        [44125],
        [44245],
        [42944],
        [42795],
        [42404],
        [42017],
        [41818],
        [41966],
        [41691],
        [42001],
        [41967],
        [42003]], device='cuda:0')
[2024-07-24 10:21:50,755][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[37547],
        [38702],
        [38672],
        [40479],
        [38343],
        [39292],
        [39503],
        [39482],
        [40540],
        [40702],
        [40308],
        [40686],
        [40631],
        [40686],
        [40970]], device='cuda:0')
[2024-07-24 10:21:50,757][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 6971],
        [21422],
        [22184],
        [20700],
        [23258],
        [24222],
        [23467],
        [24425],
        [24041],
        [23974],
        [23905],
        [24019],
        [24633],
        [24374],
        [24298]], device='cuda:0')
[2024-07-24 10:21:50,758][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[29215],
        [11520],
        [ 7716],
        [ 5825],
        [21020],
        [30791],
        [23080],
        [20457],
        [16147],
        [13158],
        [ 9454],
        [ 9864],
        [21943],
        [22901],
        [21632]], device='cuda:0')
[2024-07-24 10:21:50,759][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[23261],
        [39948],
        [33037],
        [39670],
        [34075],
        [39151],
        [38533],
        [39351],
        [36384],
        [36854],
        [34928],
        [37999],
        [37491],
        [37143],
        [37392]], device='cuda:0')
[2024-07-24 10:21:50,760][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[24135],
        [13762],
        [12203],
        [ 9569],
        [ 9554],
        [ 8768],
        [ 9357],
        [ 9445],
        [ 9302],
        [ 9390],
        [ 9309],
        [ 8404],
        [ 9276],
        [ 9587],
        [ 9619]], device='cuda:0')
[2024-07-24 10:21:50,761][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 4909],
        [17301],
        [ 5650],
        [ 5143],
        [ 2003],
        [ 6974],
        [ 4821],
        [ 4965],
        [ 5478],
        [ 3429],
        [ 4400],
        [ 4517],
        [ 6341],
        [ 3446],
        [ 5945]], device='cuda:0')
[2024-07-24 10:21:50,762][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[15651],
        [ 6841],
        [14716],
        [16785],
        [23306],
        [ 5934],
        [ 4733],
        [21437],
        [21515],
        [20317],
        [18183],
        [ 9882],
        [18961],
        [21607],
        [12074]], device='cuda:0')
[2024-07-24 10:21:50,763][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[16143],
        [41662],
        [22470],
        [39040],
        [30326],
        [27481],
        [28480],
        [31898],
        [31350],
        [28315],
        [13707],
        [19371],
        [25275],
        [ 6563],
        [ 7334]], device='cuda:0')
[2024-07-24 10:21:50,765][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[4711],
        [2114],
        [ 786],
        [ 649],
        [ 690],
        [ 984],
        [ 982],
        [1203],
        [1598],
        [1689],
        [1011],
        [1060],
        [ 838],
        [1628],
        [2141]], device='cuda:0')
[2024-07-24 10:21:50,766][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 5280],
        [12568],
        [23123],
        [23319],
        [22084],
        [20975],
        [15961],
        [11313],
        [11971],
        [18381],
        [10139],
        [10326],
        [10996],
        [32912],
        [32609]], device='cuda:0')
[2024-07-24 10:21:50,768][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[  636],
        [14918],
        [24180],
        [ 8017],
        [36005],
        [ 5713],
        [ 8598],
        [12104],
        [ 1958],
        [ 5172],
        [19039],
        [ 2228],
        [ 1744],
        [13665],
        [ 2726]], device='cuda:0')
[2024-07-24 10:21:50,769][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[10802],
        [11141],
        [ 2238],
        [  793],
        [  338],
        [  206],
        [  210],
        [  156],
        [  171],
        [  377],
        [  499],
        [  478],
        [  589],
        [  367],
        [  267]], device='cuda:0')
[2024-07-24 10:21:50,770][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 8363],
        [20480],
        [21160],
        [30435],
        [34338],
        [29675],
        [33531],
        [31948],
        [33054],
        [32725],
        [33211],
        [31723],
        [26999],
        [28260],
        [30217]], device='cuda:0')
[2024-07-24 10:21:50,772][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[2255],
        [ 941],
        [ 678],
        [1297],
        [1092],
        [2073],
        [1709],
        [2758],
        [3010],
        [2846],
        [2606],
        [3742],
        [5549],
        [4761],
        [4130]], device='cuda:0')
[2024-07-24 10:21:50,773][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 5649],
        [ 6155],
        [ 6804],
        [ 6326],
        [ 8365],
        [ 7804],
        [ 8540],
        [23042],
        [25306],
        [22870],
        [19950],
        [18963],
        [24999],
        [17359],
        [18350]], device='cuda:0')
[2024-07-24 10:21:50,775][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[10659],
        [16810],
        [27634],
        [28920],
        [23374],
        [13184],
        [ 8497],
        [ 9843],
        [12520],
        [13930],
        [22911],
        [15392],
        [14463],
        [ 6379],
        [ 6183]], device='cuda:0')
[2024-07-24 10:21:50,776][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[2092],
        [1753],
        [1718],
        [1742],
        [1403],
        [1628],
        [1115],
        [1141],
        [1207],
        [1032],
        [1260],
        [1242],
        [1327],
        [1253],
        [1126]], device='cuda:0')
[2024-07-24 10:21:50,778][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[47428],
        [47428],
        [47447],
        [38625],
        [46182],
        [47963],
        [35754],
        [47427],
        [32775],
        [42492],
        [37566],
        [37061],
        [41087],
        [44687],
        [44686]], device='cuda:0')
[2024-07-24 10:21:50,779][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[48883],
        [46786],
        [47268],
        [46780],
        [47250],
        [48640],
        [49027],
        [48162],
        [48079],
        [47184],
        [47785],
        [48417],
        [47649],
        [47217],
        [48064]], device='cuda:0')
[2024-07-24 10:21:50,780][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[47822],
        [30298],
        [40104],
        [46073],
        [42634],
        [42567],
        [44393],
        [44548],
        [40727],
        [44854],
        [39175],
        [43062],
        [45691],
        [47023],
        [45550]], device='cuda:0')
[2024-07-24 10:21:50,782][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[32830],
        [32830],
        [32830],
        [32830],
        [32830],
        [32830],
        [32830],
        [32830],
        [32830],
        [32830],
        [32830],
        [32830],
        [32830],
        [32830],
        [32830]], device='cuda:0')
[2024-07-24 10:21:50,817][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:50,819][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,820][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,820][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,820][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,821][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,821][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,821][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,822][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,822][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,822][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,822][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,823][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:50,824][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0216, 0.9784], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,825][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([5.3246e-07, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,826][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9983, 0.0017], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,827][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1693, 0.8307], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,829][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.7021, 0.2979], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,829][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0264, 0.9736], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,831][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4321, 0.5679], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,832][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1417, 0.8583], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,834][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2216, 0.7784], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,835][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9499, 0.0501], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,836][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.5048, 0.4952], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,838][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.5327, 0.4673], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:50,839][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.0449, 0.3986, 0.5565], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,840][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([1.4389e-06, 4.5895e-01, 5.4105e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,841][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.9542, 0.0056, 0.0402], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,843][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.6538, 0.0259, 0.3202], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,844][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.4494, 0.0045, 0.5461], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,846][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.0915, 0.8230, 0.0855], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,847][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.3734, 0.3056, 0.3210], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,848][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.1748, 0.4955, 0.3296], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,850][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.0700, 0.6391, 0.2909], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,851][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.9589, 0.0360, 0.0052], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,852][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.2280, 0.3653, 0.4067], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,854][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.4196, 0.2708, 0.3096], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:50,855][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0084, 0.4438, 0.2858, 0.2620], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,856][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.8027e-08, 1.4333e-01, 1.4560e-02, 8.4211e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,857][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([9.4290e-01, 4.3117e-04, 5.5723e-02, 9.4631e-04], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,858][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0589, 0.0122, 0.6343, 0.2945], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,860][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3400, 0.0014, 0.3227, 0.3359], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,861][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0280, 0.5710, 0.2235, 0.1774], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,863][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3075, 0.2363, 0.2416, 0.2145], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,864][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1376, 0.2920, 0.2103, 0.3602], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,866][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1590, 0.4648, 0.1156, 0.2607], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,867][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.8705, 0.0725, 0.0264, 0.0306], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,868][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2113, 0.2126, 0.2376, 0.3384], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,869][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3279, 0.2380, 0.1887, 0.2455], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:50,871][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.0111, 0.2913, 0.1523, 0.3575, 0.1878], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,872][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([3.5386e-06, 3.0996e-01, 3.3901e-02, 1.4511e-01, 5.1103e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,873][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.7483, 0.0075, 0.0517, 0.0591, 0.1334], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,875][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.1147, 0.0066, 0.1475, 0.4870, 0.2442], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,876][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.4495, 0.0006, 0.0636, 0.1002, 0.3861], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,878][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0956, 0.5651, 0.1299, 0.1343, 0.0750], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,878][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.2111, 0.1847, 0.1930, 0.1757, 0.2354], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,878][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.0741, 0.2549, 0.1707, 0.3334, 0.1670], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,879][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.0536, 0.3743, 0.1208, 0.1963, 0.2550], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,879][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.9559, 0.0297, 0.0043, 0.0088, 0.0013], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,879][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.1222, 0.1920, 0.2043, 0.2891, 0.1924], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,880][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.2557, 0.2074, 0.1776, 0.1510, 0.2082], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:50,880][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0048, 0.1943, 0.1234, 0.2502, 0.1818, 0.2455], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,881][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ went] are: tensor([1.7528e-06, 1.3698e-01, 3.8754e-02, 1.9498e-01, 5.3296e-01, 9.6315e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,881][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.5880, 0.0016, 0.1194, 0.0188, 0.2522, 0.0201], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,882][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.1303, 0.0030, 0.2008, 0.2308, 0.3951, 0.0400], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,883][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ went] are: tensor([4.7880e-01, 2.6628e-05, 7.9503e-03, 6.0815e-03, 7.7768e-02, 4.2937e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,884][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0097, 0.7064, 0.0374, 0.0557, 0.0144, 0.1765], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,886][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.1790, 0.1497, 0.1575, 0.1457, 0.1937, 0.1743], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,887][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0688, 0.1974, 0.1298, 0.2465, 0.1253, 0.2322], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,888][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0458, 0.2818, 0.1602, 0.1449, 0.2461, 0.1213], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,890][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.8929, 0.0483, 0.0163, 0.0183, 0.0077, 0.0164], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,891][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.1329, 0.1547, 0.1627, 0.2394, 0.1503, 0.1599], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,893][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.2152, 0.1575, 0.1413, 0.1371, 0.1174, 0.2314], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:50,894][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0064, 0.2403, 0.1110, 0.2180, 0.1373, 0.1141, 0.1730],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,895][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([7.3420e-07, 1.2374e-01, 2.7871e-02, 3.7250e-01, 3.4723e-01, 6.8756e-02,
        5.9904e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,896][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([7.5995e-01, 7.2374e-04, 7.1468e-02, 3.8721e-03, 1.4857e-01, 1.1667e-02,
        3.7409e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,897][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0462, 0.0038, 0.1026, 0.1762, 0.1762, 0.1702, 0.3248],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,898][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([3.5756e-01, 8.8865e-06, 5.2149e-03, 1.6093e-03, 5.4394e-02, 2.4015e-01,
        3.4106e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,900][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0123, 0.4178, 0.0406, 0.0495, 0.0140, 0.2530, 0.2127],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,901][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1293, 0.1334, 0.1398, 0.1313, 0.1711, 0.1546, 0.1405],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,903][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0387, 0.1504, 0.1043, 0.2019, 0.1045, 0.1862, 0.2141],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,904][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0678, 0.2313, 0.0907, 0.1926, 0.2175, 0.1467, 0.0534],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,905][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.8849, 0.0428, 0.0166, 0.0188, 0.0074, 0.0131, 0.0164],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,907][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1174, 0.1345, 0.1581, 0.2206, 0.1421, 0.1262, 0.1011],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,908][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1787, 0.1499, 0.1188, 0.1288, 0.1170, 0.1411, 0.1657],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:50,910][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0121, 0.1829, 0.0918, 0.3116, 0.1130, 0.0765, 0.1149, 0.0973],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,911][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ the] are: tensor([4.3163e-06, 9.5029e-02, 4.3221e-02, 2.4866e-01, 4.9950e-01, 5.0788e-02,
        5.8033e-02, 4.7598e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,911][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ the] are: tensor([8.8098e-01, 3.4273e-04, 1.9084e-02, 2.7757e-03, 7.4172e-02, 4.6586e-03,
        1.5694e-02, 2.2941e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,913][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0523, 0.0011, 0.0622, 0.0699, 0.1340, 0.1105, 0.4199, 0.1501],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,914][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ the] are: tensor([4.7496e-01, 3.3704e-06, 1.4306e-03, 5.3246e-04, 1.4031e-02, 6.8401e-02,
        1.0801e-01, 3.3264e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,915][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0067, 0.2549, 0.0281, 0.0463, 0.0052, 0.1309, 0.1653, 0.3627],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,917][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1263, 0.1192, 0.1222, 0.1143, 0.1467, 0.1362, 0.1198, 0.1153],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,918][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0401, 0.1228, 0.0860, 0.1516, 0.0851, 0.1370, 0.1580, 0.2194],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,920][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0604, 0.2321, 0.1276, 0.1770, 0.1996, 0.1215, 0.0430, 0.0390],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,921][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.9249, 0.0335, 0.0096, 0.0103, 0.0046, 0.0056, 0.0081, 0.0034],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,922][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1087, 0.1111, 0.1251, 0.1767, 0.1183, 0.1196, 0.0914, 0.1492],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,924][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1621, 0.1421, 0.1251, 0.1103, 0.1214, 0.1238, 0.1145, 0.1007],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:50,925][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ house] are: tensor([0.0025, 0.1155, 0.0469, 0.1215, 0.1230, 0.1177, 0.1615, 0.2053, 0.1061],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,926][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ house] are: tensor([4.1897e-06, 1.2829e-01, 3.7173e-02, 1.1419e-01, 5.0308e-01, 7.8373e-02,
        3.5458e-02, 2.1392e-03, 1.0128e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,928][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.6060, 0.0007, 0.0560, 0.0072, 0.1218, 0.0124, 0.0318, 0.0211, 0.1431],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,929][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ house] are: tensor([0.0508, 0.0027, 0.0434, 0.1211, 0.1596, 0.0253, 0.1693, 0.3421, 0.0858],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,930][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ house] are: tensor([2.1409e-01, 9.8266e-07, 6.4935e-04, 3.8243e-04, 9.0525e-03, 3.2423e-02,
        1.0243e-01, 3.8717e-01, 2.5379e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,932][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ house] are: tensor([0.0041, 0.2030, 0.0236, 0.0422, 0.0112, 0.1365, 0.1962, 0.2705, 0.1128],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,933][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ house] are: tensor([0.1255, 0.1039, 0.1097, 0.1037, 0.1267, 0.1172, 0.1045, 0.0989, 0.1099],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,935][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ house] are: tensor([0.0387, 0.1044, 0.0721, 0.1302, 0.0701, 0.1189, 0.1406, 0.1831, 0.1419],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,936][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.0549, 0.3846, 0.0658, 0.1242, 0.1314, 0.0815, 0.0374, 0.0399, 0.0802],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,936][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ house] are: tensor([0.7873, 0.0739, 0.0250, 0.0278, 0.0118, 0.0137, 0.0219, 0.0123, 0.0262],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,936][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.0531, 0.1151, 0.1146, 0.1861, 0.1064, 0.1276, 0.0906, 0.1493, 0.0572],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,937][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ house] are: tensor([0.1403, 0.1268, 0.1046, 0.1058, 0.1100, 0.1051, 0.1040, 0.0736, 0.1298],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:50,937][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0062, 0.1516, 0.0653, 0.1140, 0.1215, 0.1079, 0.1059, 0.1448, 0.0728,
        0.1101], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,938][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [.] are: tensor([4.3762e-06, 1.6254e-01, 2.3904e-02, 1.9046e-01, 4.7470e-01, 5.3860e-02,
        3.7489e-02, 3.2478e-03, 3.7803e-02, 1.5988e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,938][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [.] are: tensor([7.5909e-01, 1.4531e-04, 2.5057e-02, 1.4170e-03, 6.5737e-02, 1.3822e-02,
        5.4870e-03, 1.7010e-02, 1.0910e-01, 3.1346e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,938][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0161, 0.0007, 0.0734, 0.0468, 0.0700, 0.0626, 0.2504, 0.3738, 0.0946,
        0.0116], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,939][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [.] are: tensor([6.1020e-01, 8.5975e-07, 5.1664e-04, 8.1224e-05, 5.1339e-03, 1.0685e-02,
        1.5058e-02, 5.9780e-02, 3.8440e-02, 2.6011e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,940][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0102, 0.1578, 0.0482, 0.0576, 0.0236, 0.1057, 0.1386, 0.2333, 0.1687,
        0.0564], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,941][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.1061, 0.0935, 0.0990, 0.0885, 0.1230, 0.1106, 0.0968, 0.0954, 0.1004,
        0.0867], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,943][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0299, 0.0881, 0.0624, 0.1119, 0.0597, 0.1026, 0.1148, 0.1584, 0.1159,
        0.1562], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,944][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0410, 0.2158, 0.1108, 0.1423, 0.1699, 0.0837, 0.0479, 0.0518, 0.0877,
        0.0491], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,946][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.8280, 0.0501, 0.0161, 0.0205, 0.0095, 0.0127, 0.0175, 0.0077, 0.0191,
        0.0189], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,947][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0615, 0.0999, 0.1113, 0.1671, 0.0996, 0.1090, 0.0793, 0.1355, 0.0566,
        0.0803], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,949][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.1445, 0.1252, 0.0976, 0.1045, 0.0909, 0.0895, 0.1001, 0.0532, 0.0902,
        0.1044], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:50,950][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.0030, 0.1094, 0.0643, 0.0955, 0.1043, 0.0815, 0.0874, 0.1654, 0.0822,
        0.1032, 0.1039], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,951][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([3.2208e-05, 1.0662e-01, 9.6312e-02, 6.4571e-02, 3.4369e-01, 1.0978e-01,
        3.8431e-02, 7.8951e-03, 1.7012e-01, 2.5842e-02, 3.6717e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,952][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([6.4774e-01, 5.3466e-04, 5.7588e-03, 5.1996e-03, 2.3572e-02, 4.8541e-03,
        2.3989e-02, 1.5809e-02, 1.4216e-01, 6.7214e-02, 6.3171e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,953][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.1608, 0.0011, 0.0142, 0.0373, 0.0655, 0.0495, 0.1251, 0.2535, 0.1172,
        0.1096, 0.0662], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,954][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([4.8628e-01, 1.6637e-06, 1.7697e-04, 7.0150e-05, 1.4421e-03, 1.8077e-03,
        4.0717e-03, 7.5350e-03, 4.9554e-03, 5.3659e-02, 4.4000e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,956][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.0262, 0.1472, 0.0502, 0.0696, 0.0228, 0.0986, 0.1466, 0.2475, 0.0681,
        0.0486, 0.0747], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,957][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.1084, 0.0824, 0.0876, 0.0777, 0.1127, 0.0991, 0.0842, 0.0818, 0.0873,
        0.0759, 0.1029], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,958][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.0403, 0.0857, 0.0560, 0.1010, 0.0546, 0.0966, 0.1108, 0.1425, 0.1110,
        0.1377, 0.0638], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,960][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.0241, 0.2002, 0.0858, 0.1091, 0.1870, 0.0689, 0.0471, 0.0612, 0.0967,
        0.0543, 0.0655], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,962][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.9347, 0.0265, 0.0037, 0.0082, 0.0016, 0.0045, 0.0065, 0.0020, 0.0038,
        0.0072, 0.0013], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,963][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.0473, 0.0960, 0.0991, 0.1429, 0.0959, 0.0975, 0.0817, 0.1322, 0.0445,
        0.0704, 0.0924], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,964][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.1413, 0.0896, 0.1030, 0.0687, 0.0986, 0.0979, 0.0749, 0.0588, 0.0832,
        0.0781, 0.1059], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:50,966][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0023, 0.0679, 0.0334, 0.0865, 0.0949, 0.0844, 0.1149, 0.1607, 0.0600,
        0.0819, 0.0515, 0.1615], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,967][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([1.1906e-06, 8.9355e-02, 2.0494e-02, 1.7679e-01, 3.8422e-01, 7.0514e-02,
        2.1553e-02, 1.4819e-03, 5.3490e-02, 8.3527e-03, 5.3132e-03, 1.6843e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,968][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.2669, 0.0009, 0.0318, 0.0049, 0.1160, 0.0074, 0.0291, 0.0495, 0.1187,
        0.0573, 0.3085, 0.0089], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,969][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([3.8108e-02, 4.1275e-04, 2.4315e-02, 2.2436e-02, 6.2610e-02, 7.9336e-03,
        6.2767e-02, 4.3792e-01, 6.2344e-02, 5.5500e-02, 2.2012e-01, 5.5320e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,970][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([9.8359e-02, 5.9011e-08, 3.4255e-05, 8.1114e-06, 4.0702e-04, 5.5683e-04,
        1.5913e-03, 4.9796e-03, 2.7086e-03, 4.3255e-02, 7.9010e-01, 5.8001e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,972][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0049, 0.1143, 0.0126, 0.0316, 0.0082, 0.1370, 0.1212, 0.3292, 0.1095,
        0.0319, 0.0174, 0.0821], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,973][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1297, 0.0743, 0.0758, 0.0689, 0.0947, 0.0877, 0.0750, 0.0721, 0.0774,
        0.0688, 0.0953, 0.0803], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,974][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0460, 0.0787, 0.0525, 0.0899, 0.0529, 0.0803, 0.0950, 0.1276, 0.0961,
        0.1315, 0.0628, 0.0868], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,976][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0488, 0.1972, 0.0724, 0.1095, 0.1313, 0.1016, 0.0482, 0.0505, 0.0935,
        0.0582, 0.0589, 0.0300], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,978][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.8438, 0.0589, 0.0107, 0.0179, 0.0047, 0.0107, 0.0149, 0.0056, 0.0085,
        0.0145, 0.0040, 0.0058], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,979][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0650, 0.0887, 0.0859, 0.1366, 0.0897, 0.0927, 0.0718, 0.1096, 0.0476,
        0.0681, 0.0828, 0.0615], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,980][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.1165, 0.0898, 0.0706, 0.0865, 0.0755, 0.0808, 0.0798, 0.0618, 0.0791,
        0.0825, 0.0720, 0.1051], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:50,982][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0111, 0.1099, 0.0484, 0.1553, 0.1057, 0.0561, 0.0948, 0.0791, 0.0395,
        0.0790, 0.0491, 0.0694, 0.1028], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,983][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([9.1953e-07, 2.8129e-02, 2.9382e-02, 1.4877e-01, 6.0672e-01, 3.0995e-02,
        2.9045e-02, 2.1760e-03, 4.0462e-02, 5.9561e-03, 6.9764e-03, 6.5473e-02,
        5.9222e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,984][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([5.5062e-01, 2.0067e-04, 1.5173e-02, 3.0812e-03, 1.0539e-01, 4.3015e-03,
        1.2397e-02, 5.4273e-03, 1.0038e-01, 2.5674e-02, 1.6848e-01, 6.9707e-03,
        1.9042e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,985][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0227, 0.0006, 0.0285, 0.0459, 0.0641, 0.0396, 0.1770, 0.1226, 0.1499,
        0.0471, 0.1862, 0.0892, 0.0268], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,986][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([2.2571e-01, 9.0396e-08, 3.8328e-05, 7.0589e-06, 3.7588e-04, 5.3244e-04,
        8.8055e-04, 2.8548e-03, 1.9072e-03, 2.1255e-02, 4.9677e-01, 5.2658e-02,
        1.9702e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,988][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0020, 0.1130, 0.0105, 0.0316, 0.0036, 0.0548, 0.0874, 0.2410, 0.0625,
        0.0303, 0.0202, 0.1191, 0.2241], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,989][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1079, 0.0716, 0.0742, 0.0650, 0.0885, 0.0827, 0.0729, 0.0696, 0.0726,
        0.0647, 0.0865, 0.0737, 0.0699], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,991][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0348, 0.0679, 0.0489, 0.0794, 0.0490, 0.0710, 0.0817, 0.1098, 0.0898,
        0.1145, 0.0594, 0.0798, 0.1140], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,992][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0330, 0.2667, 0.0607, 0.1346, 0.1310, 0.0715, 0.0347, 0.0326, 0.0828,
        0.0513, 0.0428, 0.0222, 0.0362], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,993][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.8867, 0.0451, 0.0083, 0.0139, 0.0041, 0.0057, 0.0089, 0.0032, 0.0067,
        0.0096, 0.0023, 0.0034, 0.0020], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,994][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0559, 0.0790, 0.0825, 0.1204, 0.0841, 0.0843, 0.0656, 0.1010, 0.0483,
        0.0664, 0.0763, 0.0554, 0.0808], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,994][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1059, 0.0770, 0.0778, 0.0680, 0.0795, 0.0816, 0.0734, 0.0609, 0.0718,
        0.0715, 0.0795, 0.0755, 0.0776], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:50,994][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0019, 0.0866, 0.0308, 0.0887, 0.0658, 0.0644, 0.0826, 0.1118, 0.0653,
        0.0730, 0.0567, 0.1009, 0.1198, 0.0515], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,995][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([4.5796e-06, 6.2528e-02, 2.3657e-02, 1.3188e-01, 4.9718e-01, 4.7218e-02,
        2.7835e-02, 2.2032e-03, 7.6419e-02, 9.1417e-03, 4.5510e-03, 4.1354e-02,
        4.1479e-03, 7.1875e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,995][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.3091, 0.0005, 0.0406, 0.0029, 0.0628, 0.0100, 0.0104, 0.0158, 0.0474,
        0.0190, 0.2623, 0.0166, 0.0241, 0.1784], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,996][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.0098, 0.0024, 0.0233, 0.0855, 0.0329, 0.0081, 0.1233, 0.2129, 0.0528,
        0.0797, 0.0989, 0.0134, 0.2481, 0.0090], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,996][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([4.2577e-01, 1.2695e-08, 4.3955e-06, 6.9946e-07, 3.9866e-05, 2.6491e-05,
        6.7606e-05, 2.1117e-04, 8.0591e-05, 1.1162e-03, 4.7467e-02, 2.4256e-03,
        2.2571e-02, 5.0022e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,998][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.0062, 0.0480, 0.0136, 0.0306, 0.0054, 0.0727, 0.1003, 0.1797, 0.0599,
        0.0265, 0.0193, 0.0988, 0.2437, 0.0954], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:50,999][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.0969, 0.0656, 0.0660, 0.0623, 0.0818, 0.0768, 0.0677, 0.0661, 0.0666,
        0.0592, 0.0765, 0.0670, 0.0638, 0.0835], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,000][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0343, 0.0617, 0.0431, 0.0714, 0.0444, 0.0732, 0.0800, 0.1019, 0.0876,
        0.1022, 0.0536, 0.0754, 0.0953, 0.0761], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,002][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.0271, 0.3618, 0.0522, 0.1080, 0.1005, 0.0593, 0.0268, 0.0304, 0.0616,
        0.0484, 0.0414, 0.0220, 0.0276, 0.0329], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,003][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.7969, 0.0648, 0.0146, 0.0227, 0.0063, 0.0112, 0.0168, 0.0057, 0.0117,
        0.0173, 0.0050, 0.0076, 0.0051, 0.0144], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,004][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.0464, 0.0823, 0.0788, 0.1222, 0.0766, 0.0878, 0.0633, 0.1027, 0.0400,
        0.0573, 0.0720, 0.0548, 0.0761, 0.0398], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,006][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.1010, 0.0723, 0.0738, 0.0601, 0.0711, 0.0560, 0.0707, 0.0494, 0.0723,
        0.0638, 0.0749, 0.0654, 0.0552, 0.1140], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,007][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0025, 0.1292, 0.0514, 0.1231, 0.0851, 0.0507, 0.0754, 0.1052, 0.0344,
        0.0650, 0.0426, 0.0590, 0.0860, 0.0219, 0.0684], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,008][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([3.6913e-06, 5.0333e-02, 2.7578e-02, 2.5209e-01, 4.0435e-01, 4.0677e-02,
        4.6554e-02, 3.4458e-03, 4.8578e-02, 1.0532e-02, 7.4606e-03, 6.5341e-02,
        6.3126e-03, 2.4355e-02, 1.2385e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,009][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.8816e-01, 5.8909e-05, 1.2704e-02, 3.1057e-04, 2.2203e-02, 1.7225e-03,
        3.8649e-04, 8.1159e-03, 3.2261e-02, 5.4551e-03, 1.4675e-01, 2.9981e-03,
        7.3346e-03, 4.6944e-01, 2.0911e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,011][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0301, 0.0005, 0.0257, 0.0318, 0.0413, 0.0298, 0.0473, 0.1067, 0.0883,
        0.0484, 0.1868, 0.0509, 0.1097, 0.0313, 0.1714], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,012][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([8.8460e-02, 6.2993e-09, 4.2330e-06, 3.8619e-07, 3.5118e-05, 3.0084e-05,
        5.2341e-05, 1.8698e-04, 9.0716e-05, 1.5463e-03, 8.8410e-02, 3.3566e-03,
        2.0492e-02, 6.7036e-01, 1.2697e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,013][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0099, 0.1333, 0.0214, 0.0536, 0.0079, 0.0830, 0.0856, 0.1517, 0.0649,
        0.0254, 0.0249, 0.0722, 0.1248, 0.0762, 0.0654], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,015][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0817, 0.0629, 0.0607, 0.0573, 0.0737, 0.0696, 0.0637, 0.0595, 0.0629,
        0.0546, 0.0702, 0.0608, 0.0600, 0.0813, 0.0810], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,016][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0267, 0.0556, 0.0402, 0.0666, 0.0401, 0.0613, 0.0694, 0.0949, 0.0756,
        0.0985, 0.0492, 0.0680, 0.0961, 0.0682, 0.0897], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,018][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0295, 0.1995, 0.0491, 0.1443, 0.1259, 0.0781, 0.0374, 0.0382, 0.0632,
        0.0428, 0.0484, 0.0260, 0.0479, 0.0565, 0.0133], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,019][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.7800, 0.0633, 0.0165, 0.0216, 0.0078, 0.0118, 0.0151, 0.0055, 0.0106,
        0.0149, 0.0058, 0.0076, 0.0049, 0.0153, 0.0194], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,020][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0522, 0.0752, 0.0803, 0.1151, 0.0753, 0.0814, 0.0584, 0.0993, 0.0407,
        0.0572, 0.0686, 0.0503, 0.0759, 0.0402, 0.0298], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,022][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0892, 0.0740, 0.0576, 0.0633, 0.0585, 0.0633, 0.0812, 0.0414, 0.0592,
        0.0617, 0.0577, 0.0636, 0.0510, 0.0855, 0.0928], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,062][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:51,063][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,064][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,065][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,067][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,068][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,069][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,070][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,071][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,072][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,073][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,075][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,076][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,077][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0456, 0.9544], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,078][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.3027, 0.6973], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,080][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7816, 0.2184], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,081][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3490, 0.6510], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,083][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.8091, 0.1909], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,084][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7968, 0.2032], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,085][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9890, 0.0110], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,086][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.7695, 0.2305], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,088][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8637, 0.1363], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,089][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.5023, 0.4977], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,091][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0967, 0.9033], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,092][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9637, 0.0363], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,093][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.0167, 0.3215, 0.6618], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,095][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.3491, 0.1840, 0.4669], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,096][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.6590, 0.0221, 0.3189], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,098][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.2583, 0.0770, 0.6647], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,099][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.5612, 0.0159, 0.4229], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,100][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.6444, 0.3543, 0.0013], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,102][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.7959, 0.1808, 0.0234], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,103][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.2888, 0.0256, 0.6856], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,104][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.7396, 0.0212, 0.2392], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,105][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.2913, 0.4903, 0.2184], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,107][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.0587, 0.4865, 0.4547], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,108][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.9625, 0.0086, 0.0289], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,109][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0126, 0.3336, 0.4521, 0.2017], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,109][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2902, 0.1260, 0.3883, 0.1956], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,110][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.6120, 0.0040, 0.2190, 0.1650], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,110][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1569, 0.0184, 0.3547, 0.4699], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,110][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.6175, 0.0042, 0.1185, 0.2598], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,111][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3042, 0.2745, 0.4024, 0.0190], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,111][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9514, 0.0141, 0.0247, 0.0099], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,111][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2558, 0.0482, 0.5982, 0.0978], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,112][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.5754, 0.0062, 0.2401, 0.1783], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,113][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2999, 0.2208, 0.2294, 0.2499], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,114][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0355, 0.3187, 0.2968, 0.3491], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,115][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.9436, 0.0075, 0.0105, 0.0384], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,117][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.0089, 0.2067, 0.3680, 0.1381, 0.2783], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,118][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.2620, 0.0684, 0.1825, 0.2867, 0.2004], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,119][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.3969, 0.0051, 0.1026, 0.1179, 0.3774], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,121][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.1219, 0.0190, 0.1872, 0.3239, 0.3480], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,122][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.4053, 0.0037, 0.0761, 0.2185, 0.2964], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,124][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.1391, 0.5960, 0.0790, 0.1617, 0.0242], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,125][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.5865, 0.1055, 0.0475, 0.2393, 0.0212], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,126][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.2507, 0.0094, 0.3332, 0.1120, 0.2948], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,128][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.5546, 0.0048, 0.0744, 0.1480, 0.2182], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,129][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.2148, 0.2022, 0.2574, 0.1954, 0.1302], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,131][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0332, 0.2376, 0.2196, 0.2617, 0.2478], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,132][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.8910, 0.0081, 0.0218, 0.0367, 0.0424], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,133][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0067, 0.1762, 0.2380, 0.1103, 0.1898, 0.2791], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,135][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0662, 0.0769, 0.1829, 0.2052, 0.1246, 0.3441], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,136][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([3.7891e-01, 3.7873e-04, 2.8568e-02, 2.6297e-02, 1.5153e-01, 4.1432e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,137][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.1140, 0.0020, 0.0558, 0.0591, 0.1223, 0.6467], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,138][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([5.2339e-01, 1.4874e-04, 5.9049e-03, 1.6817e-02, 3.9281e-02, 4.1446e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,139][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.6840, 0.1029, 0.0790, 0.0291, 0.1010, 0.0041], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,141][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.8081, 0.0600, 0.0177, 0.0843, 0.0225, 0.0074], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,142][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.2521, 0.0212, 0.1357, 0.2472, 0.1371, 0.2067], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,144][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.4566, 0.0008, 0.0251, 0.0441, 0.0946, 0.3788], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,145][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.1819, 0.1193, 0.1815, 0.1204, 0.1452, 0.2516], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,146][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0205, 0.1913, 0.1755, 0.2133, 0.1994, 0.2000], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,148][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.9150, 0.0024, 0.0079, 0.0128, 0.0113, 0.0506], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,149][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0040, 0.1600, 0.2200, 0.0852, 0.1731, 0.2536, 0.1041],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,151][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1330, 0.0529, 0.1441, 0.1149, 0.1089, 0.2482, 0.1980],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,152][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([6.3164e-01, 4.0857e-05, 3.7093e-03, 2.2196e-03, 3.2785e-02, 4.8204e-02,
        2.8140e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,153][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1547, 0.0010, 0.0202, 0.0287, 0.0581, 0.2426, 0.4947],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,154][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([5.5052e-01, 4.6822e-05, 2.4608e-03, 4.6869e-03, 1.8297e-02, 1.2432e-01,
        2.9967e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,155][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.4136, 0.1258, 0.1669, 0.0637, 0.0660, 0.1040, 0.0601],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,157][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.8852, 0.0184, 0.0265, 0.0163, 0.0317, 0.0175, 0.0044],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,158][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0508, 0.0027, 0.1134, 0.0154, 0.2429, 0.4867, 0.0882],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,159][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([5.8731e-01, 1.6886e-04, 6.8367e-03, 7.9547e-03, 3.9197e-02, 1.0329e-01,
        2.5524e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,160][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1433, 0.1036, 0.1275, 0.1198, 0.0949, 0.2773, 0.1335],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,162][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0169, 0.1594, 0.1470, 0.1762, 0.1685, 0.1657, 0.1663],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,163][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.9441, 0.0014, 0.0046, 0.0077, 0.0060, 0.0175, 0.0186],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,165][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0027, 0.1289, 0.2164, 0.0854, 0.1977, 0.2401, 0.0776, 0.0512],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,166][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.4713, 0.0340, 0.0645, 0.0766, 0.0357, 0.0825, 0.1151, 0.1204],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,167][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([6.5594e-01, 8.1103e-06, 7.7048e-04, 4.0816e-04, 6.3425e-03, 6.2685e-03,
        4.7199e-02, 2.8306e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,167][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([1.4254e-01, 2.9204e-04, 6.2249e-03, 6.9721e-03, 1.5006e-02, 5.4232e-02,
        1.4099e-01, 6.3375e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,167][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([6.2023e-01, 1.1094e-05, 4.6519e-04, 9.1613e-04, 3.9623e-03, 1.8220e-02,
        4.9995e-02, 3.0620e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,168][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1418, 0.1542, 0.0394, 0.0573, 0.0834, 0.0383, 0.4625, 0.0231],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,168][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.8781, 0.0170, 0.0221, 0.0169, 0.0257, 0.0206, 0.0120, 0.0075],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,169][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0896, 0.0084, 0.1472, 0.0432, 0.2277, 0.0846, 0.2640, 0.1353],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,169][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([6.5848e-01, 4.5219e-05, 1.8770e-03, 2.1402e-03, 9.8646e-03, 1.9934e-02,
        7.4044e-02, 2.3361e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,169][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1172, 0.0840, 0.1000, 0.1042, 0.0821, 0.2213, 0.1213, 0.1701],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,170][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0133, 0.1356, 0.1264, 0.1510, 0.1443, 0.1422, 0.1424, 0.1446],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,170][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([9.3389e-01, 5.9005e-04, 3.2397e-03, 4.2826e-03, 5.6938e-03, 1.1148e-02,
        1.0136e-02, 3.1017e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,172][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([0.0025, 0.1198, 0.2161, 0.0777, 0.1782, 0.2173, 0.0748, 0.0410, 0.0726],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,173][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([0.0933, 0.0159, 0.0513, 0.0753, 0.0640, 0.2086, 0.2119, 0.1621, 0.1176],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,174][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([6.8548e-02, 5.7397e-06, 6.6402e-04, 4.6899e-04, 5.2431e-03, 9.7110e-03,
        1.0262e-01, 6.7956e-01, 1.3317e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,175][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([1.3857e-02, 1.2748e-04, 2.8433e-03, 3.9339e-03, 8.0351e-03, 4.2774e-02,
        1.1637e-01, 6.6316e-01, 1.4890e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,176][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([1.6113e-01, 4.3145e-06, 3.2082e-04, 7.5916e-04, 3.1317e-03, 2.2335e-02,
        8.7080e-02, 5.8542e-01, 1.3982e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,177][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([0.3009, 0.1625, 0.0763, 0.0400, 0.0110, 0.0568, 0.2150, 0.1306, 0.0068],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,178][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([0.3972, 0.0782, 0.0365, 0.1038, 0.0175, 0.0200, 0.0603, 0.2689, 0.0175],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,179][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([0.0819, 0.0039, 0.1157, 0.0260, 0.1835, 0.1238, 0.2415, 0.1549, 0.0688],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,180][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([1.0762e-01, 3.5378e-05, 1.9444e-03, 2.6431e-03, 1.0119e-02, 4.0554e-02,
        1.6102e-01, 6.1377e-01, 6.2291e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,182][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([0.1349, 0.0787, 0.1052, 0.0843, 0.0725, 0.1968, 0.1103, 0.1572, 0.0601],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,183][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([0.0135, 0.1170, 0.1094, 0.1297, 0.1232, 0.1237, 0.1224, 0.1231, 0.1379],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,185][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([0.8143, 0.0009, 0.0054, 0.0075, 0.0102, 0.0304, 0.0243, 0.0546, 0.0523],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,186][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0032, 0.1238, 0.1923, 0.0793, 0.1641, 0.2040, 0.0718, 0.0442, 0.0717,
        0.0455], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,188][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.1391, 0.0356, 0.0903, 0.0905, 0.0632, 0.1236, 0.1207, 0.1211, 0.0485,
        0.1673], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,188][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([4.8768e-01, 3.2920e-06, 4.2584e-04, 1.7623e-04, 3.6209e-03, 3.3960e-03,
        2.5031e-02, 1.8900e-01, 2.3214e-02, 2.6745e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,189][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([1.3417e-01, 1.0499e-04, 2.8428e-03, 2.9554e-03, 8.1411e-03, 2.4118e-02,
        4.6989e-02, 2.6382e-01, 7.1304e-02, 4.4555e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,190][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([5.1195e-01, 2.8934e-06, 1.6836e-04, 3.2080e-04, 1.5944e-03, 5.8009e-03,
        1.8983e-02, 1.4563e-01, 2.0396e-02, 2.9515e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,192][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0816, 0.0690, 0.0585, 0.0478, 0.0723, 0.0977, 0.2407, 0.1280, 0.1449,
        0.0595], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,193][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.8703, 0.0047, 0.0244, 0.0076, 0.0266, 0.0147, 0.0054, 0.0296, 0.0146,
        0.0020], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,195][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0391, 0.0028, 0.2265, 0.0263, 0.1445, 0.0504, 0.1631, 0.2298, 0.0797,
        0.0379], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,196][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([4.6883e-01, 2.1975e-05, 1.2689e-03, 1.2946e-03, 6.8813e-03, 9.7786e-03,
        3.4824e-02, 1.3803e-01, 1.4857e-02, 3.2422e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,197][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.1068, 0.0734, 0.0769, 0.0830, 0.0665, 0.1722, 0.1016, 0.1282, 0.0879,
        0.1036], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,199][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0118, 0.1047, 0.0977, 0.1149, 0.1101, 0.1082, 0.1078, 0.1095, 0.1239,
        0.1115], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,200][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([8.9782e-01, 4.9227e-04, 2.1511e-03, 3.7000e-03, 4.0010e-03, 8.6954e-03,
        8.2626e-03, 1.8705e-02, 1.3072e-02, 4.3098e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,201][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.0033, 0.0992, 0.1939, 0.0664, 0.1453, 0.1778, 0.0715, 0.0351, 0.0570,
        0.0407, 0.1099], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,203][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.0933, 0.0202, 0.0516, 0.0596, 0.0395, 0.1107, 0.1249, 0.0771, 0.0494,
        0.1940, 0.1796], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,203][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([4.2541e-01, 7.2456e-06, 1.5436e-04, 1.1573e-04, 9.9657e-04, 7.8751e-04,
        6.6856e-03, 2.2655e-02, 4.9102e-03, 6.3575e-02, 4.7470e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,204][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([2.2121e-01, 2.9778e-04, 2.6616e-03, 3.1744e-03, 7.3539e-03, 1.3700e-02,
        2.5023e-02, 8.9594e-02, 2.1083e-02, 1.8695e-01, 4.2896e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,205][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([3.7781e-01, 3.9857e-06, 8.0789e-05, 1.9315e-04, 6.6928e-04, 1.5634e-03,
        6.0301e-03, 2.2492e-02, 3.0909e-03, 6.6071e-02, 5.2200e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,207][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.2351, 0.0543, 0.0007, 0.0726, 0.0311, 0.0104, 0.2375, 0.0982, 0.0963,
        0.1632, 0.0005], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,208][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.4154, 0.1071, 0.0121, 0.1527, 0.0099, 0.0113, 0.0513, 0.1778, 0.0198,
        0.0340, 0.0086], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,210][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.0964, 0.0014, 0.0505, 0.0130, 0.2067, 0.0267, 0.0781, 0.0592, 0.1412,
        0.0753, 0.2516], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,211][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([5.3372e-01, 3.4799e-05, 4.7543e-04, 6.2451e-04, 2.6528e-03, 3.7276e-03,
        9.6044e-03, 2.9539e-02, 5.5259e-03, 9.4936e-02, 3.1916e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,212][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.0622, 0.0904, 0.0432, 0.0776, 0.0748, 0.2042, 0.1020, 0.1211, 0.0839,
        0.1060, 0.0346], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,214][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.0131, 0.0956, 0.0886, 0.1057, 0.0982, 0.0982, 0.0989, 0.1003, 0.1114,
        0.1006, 0.0896], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,215][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([8.7189e-01, 5.7698e-04, 3.2515e-03, 3.7736e-03, 6.1526e-03, 9.8637e-03,
        5.8203e-03, 1.2096e-02, 1.0590e-02, 1.9626e-02, 5.6354e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,216][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0034, 0.1031, 0.1526, 0.0646, 0.1224, 0.1547, 0.0644, 0.0331, 0.0472,
        0.0347, 0.0867, 0.1331], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,218][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0146, 0.0107, 0.0265, 0.0397, 0.0199, 0.1006, 0.0903, 0.1101, 0.0397,
        0.1670, 0.0858, 0.2953], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,219][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([5.6573e-02, 4.7874e-07, 4.9730e-05, 2.1747e-05, 3.4856e-04, 4.0325e-04,
        4.8249e-03, 3.5351e-02, 3.2681e-03, 6.4641e-02, 7.0639e-01, 1.2813e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,220][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([3.4532e-02, 1.5259e-05, 5.6284e-04, 3.5871e-04, 1.4877e-03, 3.5249e-03,
        9.9710e-03, 6.0943e-02, 1.1407e-02, 9.9580e-02, 5.3696e-01, 2.4065e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,221][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([9.6510e-02, 3.2619e-07, 1.6213e-05, 3.4506e-05, 1.6391e-04, 5.7979e-04,
        2.7400e-03, 1.6685e-02, 2.0017e-03, 5.2869e-02, 7.1473e-01, 1.1367e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,222][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.1878, 0.1182, 0.0976, 0.0198, 0.0703, 0.0123, 0.0852, 0.0659, 0.1548,
        0.1076, 0.0795, 0.0009], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,224][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.6856, 0.0523, 0.0114, 0.0696, 0.0118, 0.0064, 0.0296, 0.0669, 0.0120,
        0.0258, 0.0114, 0.0174], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,225][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0737, 0.0039, 0.0359, 0.0173, 0.0931, 0.0528, 0.2009, 0.0614, 0.0665,
        0.1145, 0.2261, 0.0540], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,225][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([1.3506e-01, 4.2666e-06, 2.3173e-04, 1.8259e-04, 9.5974e-04, 1.9788e-03,
        8.2275e-03, 4.1226e-02, 3.5344e-03, 1.0228e-01, 5.8984e-01, 1.1648e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,226][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1136, 0.0601, 0.0964, 0.0543, 0.0665, 0.1403, 0.0783, 0.1069, 0.0678,
        0.0795, 0.0811, 0.0551], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,226][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0087, 0.0857, 0.0793, 0.0962, 0.0896, 0.0881, 0.0906, 0.0925, 0.1029,
        0.0937, 0.0826, 0.0900], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,227][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([8.5272e-01, 3.7156e-04, 1.6261e-03, 2.5813e-03, 2.9554e-03, 7.8047e-03,
        4.6887e-03, 1.1120e-02, 7.7143e-03, 2.2176e-02, 4.4343e-02, 4.1893e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,227][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0021, 0.0918, 0.1543, 0.0597, 0.1328, 0.1502, 0.0528, 0.0345, 0.0570,
        0.0356, 0.0836, 0.1140, 0.0315], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,227][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1810, 0.0189, 0.0366, 0.0579, 0.0240, 0.0534, 0.0831, 0.0782, 0.0349,
        0.0870, 0.0707, 0.2002, 0.0739], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,228][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([3.7399e-01, 2.0223e-07, 2.1882e-05, 7.4515e-06, 2.1236e-04, 7.3783e-05,
        7.2803e-04, 4.1105e-03, 5.5464e-04, 6.6788e-03, 1.7841e-01, 1.5603e-02,
        4.1960e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,229][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([9.1602e-02, 1.4215e-05, 3.5377e-04, 2.4394e-04, 9.4865e-04, 1.5890e-03,
        4.3924e-03, 2.0077e-02, 4.5567e-03, 4.0610e-02, 2.4821e-01, 1.3743e-01,
        4.4997e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,230][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([2.9438e-01, 4.1326e-07, 1.2870e-05, 2.3945e-05, 1.3948e-04, 2.6599e-04,
        9.2982e-04, 5.6347e-03, 8.6952e-04, 1.4207e-02, 1.9378e-01, 3.5912e-02,
        4.5384e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,231][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1384, 0.0988, 0.0108, 0.0671, 0.0328, 0.0154, 0.2356, 0.0321, 0.1292,
        0.2037, 0.0143, 0.0157, 0.0060], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,233][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.8513, 0.0150, 0.0128, 0.0155, 0.0131, 0.0102, 0.0133, 0.0079, 0.0077,
        0.0119, 0.0145, 0.0232, 0.0037], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,234][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0073, 0.0015, 0.0384, 0.0052, 0.0362, 0.0532, 0.0282, 0.0206, 0.0390,
        0.0383, 0.2416, 0.4824, 0.0080], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,235][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([3.7158e-01, 2.6034e-06, 1.0262e-04, 1.0271e-04, 6.0285e-04, 6.8508e-04,
        2.7792e-03, 1.0079e-02, 1.3811e-03, 2.5133e-02, 1.7150e-01, 5.6679e-02,
        3.5936e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,237][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0864, 0.0504, 0.0567, 0.0595, 0.0472, 0.1305, 0.0775, 0.1087, 0.0602,
        0.0865, 0.0484, 0.0783, 0.1097], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,238][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0080, 0.0789, 0.0730, 0.0877, 0.0830, 0.0816, 0.0825, 0.0838, 0.0941,
        0.0851, 0.0766, 0.0830, 0.0827], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,239][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([8.2829e-01, 2.1342e-04, 1.7558e-03, 1.6919e-03, 3.2693e-03, 5.2179e-03,
        3.9858e-03, 1.0969e-02, 7.1564e-03, 1.5118e-02, 4.7939e-02, 2.3103e-02,
        5.1293e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,241][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.0020, 0.0862, 0.1476, 0.0532, 0.1099, 0.1566, 0.0543, 0.0275, 0.0477,
        0.0310, 0.0783, 0.1132, 0.0226, 0.0700], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,242][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.0406, 0.0070, 0.0315, 0.0297, 0.0152, 0.0398, 0.0763, 0.0601, 0.0267,
        0.0667, 0.0943, 0.2222, 0.1348, 0.1550], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,243][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([3.4966e-01, 7.5822e-08, 6.2995e-06, 1.6205e-06, 4.9006e-05, 1.3137e-05,
        1.0683e-04, 6.0714e-04, 6.9171e-05, 8.0543e-04, 2.6034e-02, 2.2290e-03,
        5.7627e-02, 5.6279e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,244][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([1.0359e-01, 5.7524e-06, 1.0493e-04, 6.7401e-05, 2.9557e-04, 3.0286e-04,
        8.1391e-04, 3.8398e-03, 7.0816e-04, 6.6226e-03, 4.7169e-02, 1.9866e-02,
        8.3473e-02, 7.3314e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,245][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([2.8582e-01, 8.2780e-08, 2.4479e-06, 2.9367e-06, 2.0907e-05, 2.3593e-05,
        8.4331e-05, 5.4694e-04, 6.2237e-05, 8.6441e-04, 2.7670e-02, 2.5669e-03,
        4.9674e-02, 6.3266e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,246][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([0.0864, 0.0892, 0.0358, 0.0157, 0.0276, 0.0176, 0.4130, 0.0869, 0.0252,
        0.1396, 0.0199, 0.0144, 0.0221, 0.0065], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,248][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.7130, 0.0464, 0.0143, 0.0528, 0.0096, 0.0044, 0.0200, 0.0460, 0.0075,
        0.0155, 0.0151, 0.0250, 0.0210, 0.0094], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,249][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.1420, 0.0016, 0.0288, 0.0114, 0.0718, 0.0832, 0.0471, 0.0482, 0.0752,
        0.0443, 0.1319, 0.0736, 0.0873, 0.1538], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,250][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([2.5448e-01, 7.9589e-07, 4.3784e-05, 1.9896e-05, 1.5246e-04, 1.1562e-04,
        5.3483e-04, 1.7543e-03, 1.7298e-04, 3.0320e-03, 4.5817e-02, 9.1531e-03,
        6.7538e-02, 6.1718e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,252][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.0863, 0.0510, 0.0687, 0.0516, 0.0524, 0.1402, 0.0685, 0.0931, 0.0626,
        0.0768, 0.0574, 0.0543, 0.0938, 0.0433], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,253][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.0086, 0.0733, 0.0685, 0.0812, 0.0762, 0.0747, 0.0754, 0.0767, 0.0850,
        0.0771, 0.0693, 0.0749, 0.0751, 0.0841], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,254][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([9.2925e-01, 8.4854e-05, 8.9660e-04, 5.8185e-04, 1.3441e-03, 1.3586e-03,
        1.0268e-03, 2.9098e-03, 2.1684e-03, 4.3369e-03, 1.4888e-02, 6.3638e-03,
        1.3219e-02, 2.1571e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,256][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0015, 0.0977, 0.1427, 0.0503, 0.1143, 0.1567, 0.0562, 0.0306, 0.0498,
        0.0295, 0.0715, 0.0963, 0.0222, 0.0604, 0.0202], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,257][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0366, 0.0134, 0.0357, 0.0336, 0.0258, 0.0571, 0.0477, 0.0666, 0.0384,
        0.0848, 0.0837, 0.2226, 0.0845, 0.0617, 0.1079], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,258][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([9.9483e-02, 1.5064e-08, 2.1957e-06, 5.3371e-07, 2.1700e-05, 6.0988e-06,
        4.5349e-05, 3.6835e-04, 3.5346e-05, 5.7367e-04, 2.6240e-02, 1.6225e-03,
        5.4134e-02, 7.1741e-01, 1.0006e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,259][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.7209e-02, 1.5082e-06, 4.1206e-05, 2.5507e-05, 1.2527e-04, 1.6851e-04,
        3.6490e-04, 2.1043e-03, 4.3235e-04, 4.4385e-03, 3.2117e-02, 1.3945e-02,
        5.7939e-02, 7.2104e-01, 1.4005e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,260][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([8.1881e-02, 4.6989e-08, 1.6030e-06, 2.2169e-06, 1.4152e-05, 2.1402e-05,
        7.6485e-05, 5.0798e-04, 5.4705e-05, 1.3077e-03, 2.9563e-02, 3.0735e-03,
        5.1713e-02, 6.8279e-01, 1.4899e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,261][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1610, 0.0430, 0.0428, 0.0215, 0.0376, 0.0451, 0.0349, 0.0880, 0.1643,
        0.0900, 0.0711, 0.0230, 0.0432, 0.1091, 0.0256], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,263][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.7319, 0.0148, 0.0217, 0.0108, 0.0226, 0.0122, 0.0030, 0.0454, 0.0182,
        0.0057, 0.0289, 0.0272, 0.0237, 0.0310, 0.0028], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,264][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0230, 0.0004, 0.0207, 0.0025, 0.0397, 0.0826, 0.0162, 0.0631, 0.0289,
        0.0352, 0.2244, 0.1696, 0.0522, 0.1691, 0.0723], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,265][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.0764e-01, 2.4917e-07, 1.6333e-05, 1.0211e-05, 1.0844e-04, 9.7342e-05,
        2.5098e-04, 1.2345e-03, 1.5258e-04, 3.2635e-03, 3.9182e-02, 8.0569e-03,
        6.5389e-02, 6.5020e-01, 1.2440e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,267][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0545, 0.0457, 0.0547, 0.0522, 0.0416, 0.1199, 0.0571, 0.0902, 0.0638,
        0.0749, 0.0442, 0.0654, 0.0918, 0.0929, 0.0510], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,268][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0062, 0.0667, 0.0618, 0.0740, 0.0696, 0.0682, 0.0694, 0.0713, 0.0795,
        0.0732, 0.0651, 0.0705, 0.0708, 0.0799, 0.0737], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,269][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([8.8011e-01, 1.5177e-04, 6.6127e-04, 8.9247e-04, 1.0617e-03, 2.1998e-03,
        1.8497e-03, 4.3311e-03, 2.7570e-03, 6.5792e-03, 1.8011e-02, 1.1686e-02,
        2.0177e-02, 2.5222e-02, 2.4310e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,271][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:51,273][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[23444],
        [39226],
        [42488],
        [39473],
        [49963],
        [35954],
        [34302],
        [33436],
        [31872],
        [21052],
        [37011],
        [21149],
        [32393],
        [19867],
        [22598]], device='cuda:0')
[2024-07-24 10:21:51,274][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[23844],
        [46904],
        [49146],
        [46075],
        [50173],
        [47977],
        [47088],
        [45829],
        [48873],
        [43481],
        [49550],
        [44769],
        [46735],
        [44928],
        [44296]], device='cuda:0')
[2024-07-24 10:21:51,276][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[29366],
        [10274],
        [13749],
        [12923],
        [12513],
        [11143],
        [10490],
        [10342],
        [ 7821],
        [ 8265],
        [ 8512],
        [ 8594],
        [ 9047],
        [ 8381],
        [ 8711]], device='cuda:0')
[2024-07-24 10:21:51,277][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[22067],
        [21040],
        [16944],
        [17744],
        [14321],
        [13219],
        [14474],
        [13366],
        [12343],
        [13302],
        [11815],
        [11832],
        [11599],
        [11596],
        [12451]], device='cuda:0')
[2024-07-24 10:21:51,278][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[4916],
        [4851],
        [3321],
        [3005],
        [1904],
        [1667],
        [2004],
        [2834],
        [2239],
        [2733],
        [3175],
        [1725],
        [2051],
        [1494],
        [1968]], device='cuda:0')
[2024-07-24 10:21:51,280][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[25586],
        [32344],
        [37933],
        [39892],
        [42531],
        [46977],
        [44411],
        [41467],
        [41376],
        [40225],
        [39502],
        [39674],
        [43580],
        [39537],
        [43726]], device='cuda:0')
[2024-07-24 10:21:51,281][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[10540],
        [ 5805],
        [10873],
        [ 7267],
        [ 8482],
        [ 6769],
        [ 2633],
        [ 1122],
        [ 1295],
        [  492],
        [ 5438],
        [ 7679],
        [ 3526],
        [ 5946],
        [ 5498]], device='cuda:0')
[2024-07-24 10:21:51,283][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[7311],
        [3870],
        [3337],
        [2858],
        [2667],
        [3178],
        [2957],
        [2589],
        [2332],
        [2037],
        [2084],
        [2048],
        [1878],
        [1927],
        [2053]], device='cuda:0')
[2024-07-24 10:21:51,284][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[41254],
        [39825],
        [39591],
        [39242],
        [39147],
        [38468],
        [37557],
        [37427],
        [37212],
        [36757],
        [36764],
        [36677],
        [36519],
        [36462],
        [35732]], device='cuda:0')
[2024-07-24 10:21:51,285][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 7570],
        [ 5905],
        [ 6369],
        [ 8329],
        [ 8502],
        [ 9900],
        [ 9963],
        [ 9580],
        [10079],
        [10178],
        [ 9936],
        [10372],
        [10456],
        [10439],
        [10549]], device='cuda:0')
[2024-07-24 10:21:51,286][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[37856],
        [37921],
        [38844],
        [38389],
        [39381],
        [40259],
        [40002],
        [39627],
        [37890],
        [38083],
        [37345],
        [37000],
        [36260],
        [35998],
        [34937]], device='cuda:0')
[2024-07-24 10:21:51,287][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[12425],
        [13402],
        [12988],
        [13987],
        [12990],
        [12671],
        [12492],
        [12582],
        [12992],
        [12168],
        [12274],
        [12480],
        [12352],
        [12198],
        [12053]], device='cuda:0')
[2024-07-24 10:21:51,288][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[20934],
        [18907],
        [19453],
        [20570],
        [21772],
        [21460],
        [23019],
        [23871],
        [24254],
        [24242],
        [25310],
        [24861],
        [25149],
        [25243],
        [25467]], device='cuda:0')
[2024-07-24 10:21:51,289][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[35852],
        [35731],
        [32084],
        [33552],
        [40393],
        [33895],
        [34398],
        [33671],
        [34234],
        [34035],
        [33678],
        [32377],
        [31654],
        [32129],
        [31370]], device='cuda:0')
[2024-07-24 10:21:51,291][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 9609],
        [23169],
        [ 6738],
        [29951],
        [ 3295],
        [11720],
        [25626],
        [19617],
        [14896],
        [18211],
        [ 3161],
        [17803],
        [15135],
        [ 5819],
        [13264]], device='cuda:0')
[2024-07-24 10:21:51,292][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[13514],
        [16903],
        [14079],
        [14856],
        [13709],
        [14174],
        [14179],
        [14099],
        [13995],
        [14158],
        [13851],
        [13895],
        [13883],
        [13764],
        [13818]], device='cuda:0')
[2024-07-24 10:21:51,294][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[11661],
        [13517],
        [16301],
        [16234],
        [16525],
        [17287],
        [15609],
        [10934],
        [13390],
        [13634],
        [12751],
        [12051],
        [10994],
        [ 9840],
        [10404]], device='cuda:0')
[2024-07-24 10:21:51,295][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[7935],
        [1728],
        [4192],
        [3260],
        [3567],
        [3060],
        [1750],
        [1317],
        [2081],
        [1918],
        [5194],
        [6441],
        [2149],
        [4333],
        [4900]], device='cuda:0')
[2024-07-24 10:21:51,297][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[4085],
        [6245],
        [3249],
        [3424],
        [4223],
        [3357],
        [1218],
        [1653],
        [2012],
        [4163],
        [3462],
        [6499],
        [2769],
        [5442],
        [4957]], device='cuda:0')
[2024-07-24 10:21:51,298][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[22661],
        [25787],
        [26090],
        [21258],
        [21114],
        [28901],
        [22519],
        [24693],
        [20513],
        [22429],
        [26671],
        [26101],
        [22488],
        [16563],
        [16405]], device='cuda:0')
[2024-07-24 10:21:51,299][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[17079],
        [28093],
        [33690],
        [43221],
        [42736],
        [29985],
        [41524],
        [45270],
        [43577],
        [45964],
        [44658],
        [45097],
        [45825],
        [46374],
        [44906]], device='cuda:0')
[2024-07-24 10:21:51,301][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[40457],
        [40705],
        [43374],
        [41906],
        [44241],
        [43533],
        [42821],
        [42653],
        [39775],
        [42439],
        [41217],
        [42239],
        [42487],
        [42037],
        [41945]], device='cuda:0')
[2024-07-24 10:21:51,302][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 8646],
        [ 3317],
        [45366],
        [40738],
        [42165],
        [18264],
        [33903],
        [31392],
        [27625],
        [25706],
        [36087],
        [31937],
        [25974],
        [30781],
        [35432]], device='cuda:0')
[2024-07-24 10:21:51,304][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[22951],
        [29834],
        [35600],
        [38889],
        [39649],
        [40433],
        [44836],
        [36779],
        [37839],
        [45853],
        [38768],
        [31375],
        [38926],
        [37302],
        [37309]], device='cuda:0')
[2024-07-24 10:21:51,305][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[34192],
        [24297],
        [29965],
        [31265],
        [30977],
        [31184],
        [31336],
        [28970],
        [28590],
        [29411],
        [29757],
        [28816],
        [28237],
        [28617],
        [29232]], device='cuda:0')
[2024-07-24 10:21:51,306][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 3702],
        [11892],
        [11411],
        [11784],
        [11403],
        [11750],
        [11812],
        [11912],
        [12147],
        [12309],
        [12431],
        [12614],
        [12595],
        [12666],
        [12694]], device='cuda:0')
[2024-07-24 10:21:51,308][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[39632],
        [39242],
        [40978],
        [40932],
        [44420],
        [41683],
        [41265],
        [41668],
        [42539],
        [44969],
        [45903],
        [45031],
        [44273],
        [42460],
        [44313]], device='cuda:0')
[2024-07-24 10:21:51,309][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[36763],
        [37969],
        [24475],
        [24743],
        [23032],
        [29222],
        [27814],
        [31129],
        [31497],
        [26881],
        [22561],
        [22433],
        [29027],
        [26981],
        [26127]], device='cuda:0')
[2024-07-24 10:21:51,311][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[34101],
        [23977],
        [24127],
        [20861],
        [26419],
        [30364],
        [24635],
        [26405],
        [31674],
        [27419],
        [30803],
        [32698],
        [33152],
        [34051],
        [34547]], device='cuda:0')
[2024-07-24 10:21:51,312][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[45678],
        [45678],
        [45678],
        [45678],
        [45678],
        [45678],
        [45678],
        [45678],
        [45678],
        [45678],
        [45678],
        [45678],
        [45678],
        [45678],
        [45678]], device='cuda:0')
[2024-07-24 10:21:51,343][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:51,345][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,346][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,347][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,348][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,349][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,350][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,351][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,352][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,353][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,353][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,353][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,354][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,354][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2209, 0.7791], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,354][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0570, 0.9430], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,355][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3641, 0.6359], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,355][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2503, 0.7497], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,355][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1491, 0.8509], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,356][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0241, 0.9759], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,356][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4388, 0.5612], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,357][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.7154, 0.2846], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,358][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.7633, 0.2367], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,359][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.5286, 0.4714], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,361][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9975, 0.0025], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,362][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.5465, 0.4535], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,363][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.1861, 0.1091, 0.7048], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,364][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.0328, 0.4736, 0.4936], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,366][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.2129, 0.4151, 0.3719], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,367][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.1841, 0.5114, 0.3045], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,369][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.0838, 0.4679, 0.4484], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,370][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.0116, 0.4055, 0.5830], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,371][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.4807, 0.2183, 0.3010], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,373][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.6213, 0.0532, 0.3256], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,374][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.5849, 0.0025, 0.4126], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,375][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.0123, 0.4546, 0.5331], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,377][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.8522, 0.0166, 0.1312], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,378][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.2554, 0.1147, 0.6299], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,379][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0514, 0.0028, 0.1009, 0.8449], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,381][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0192, 0.2949, 0.3122, 0.3737], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,382][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1809, 0.2877, 0.2596, 0.2718], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,383][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1319, 0.3139, 0.2228, 0.3314], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,385][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0883, 0.3050, 0.2808, 0.3258], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,386][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0127, 0.1250, 0.2171, 0.6452], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,387][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3800, 0.1831, 0.2005, 0.2364], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,389][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.6692, 0.0054, 0.0785, 0.2469], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,390][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([5.3190e-01, 2.7394e-04, 3.6751e-01, 1.0031e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,391][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0302, 0.0479, 0.8968, 0.0251], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,392][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.9773, 0.0027, 0.0174, 0.0025], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,394][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1656, 0.0555, 0.3964, 0.3826], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,395][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.0590, 0.0055, 0.0432, 0.6875, 0.2047], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,397][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0128, 0.2315, 0.2413, 0.2978, 0.2165], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,398][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.1067, 0.2415, 0.2116, 0.2287, 0.2115], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,400][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.1238, 0.2761, 0.1593, 0.2792, 0.1615], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,401][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.0351, 0.2315, 0.2146, 0.2573, 0.2615], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,402][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0067, 0.0910, 0.1291, 0.3950, 0.3783], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,404][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.2785, 0.1207, 0.1693, 0.1641, 0.2675], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,405][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.2572, 0.0222, 0.0988, 0.5063, 0.1155], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,406][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([3.6624e-01, 3.8459e-04, 7.8835e-02, 8.9326e-02, 4.6521e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,407][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0111, 0.1380, 0.6808, 0.0981, 0.0720], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,409][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.4295, 0.0262, 0.1455, 0.1016, 0.2972], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,410][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.3326, 0.0440, 0.2852, 0.1928, 0.1453], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,411][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ went] are: tensor([9.3215e-02, 3.3752e-04, 1.6131e-02, 1.2565e-01, 1.6923e-01, 5.9544e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,411][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0148, 0.1771, 0.1861, 0.2264, 0.1712, 0.2245], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,412][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.1021, 0.2003, 0.1728, 0.1898, 0.1708, 0.1642], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,412][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0948, 0.1853, 0.1159, 0.2086, 0.1349, 0.2606], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,412][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0504, 0.1811, 0.1696, 0.2041, 0.2019, 0.1928], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,413][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0017, 0.0713, 0.1020, 0.3762, 0.2881, 0.1607], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,413][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.2790, 0.0854, 0.1175, 0.1029, 0.1684, 0.2468], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,414][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.3505, 0.0008, 0.0095, 0.0403, 0.0152, 0.5836], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,414][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ went] are: tensor([3.5466e-01, 1.1548e-05, 1.7646e-02, 8.6735e-03, 2.0468e-01, 4.1433e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,415][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0103, 0.0629, 0.5011, 0.0582, 0.3525, 0.0149], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,416][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.8826, 0.0032, 0.0254, 0.0048, 0.0338, 0.0501], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,417][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.1390, 0.0482, 0.3154, 0.2173, 0.1413, 0.1388], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,418][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([2.2268e-01, 1.5363e-05, 7.6345e-04, 2.4749e-03, 7.4302e-03, 1.4281e-02,
        7.5235e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,420][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0124, 0.1487, 0.1567, 0.1831, 0.1416, 0.1805, 0.1769],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,421][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0881, 0.1678, 0.1483, 0.1604, 0.1477, 0.1428, 0.1449],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,422][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0968, 0.1362, 0.0951, 0.1438, 0.1069, 0.1954, 0.2259],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,423][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0345, 0.1525, 0.1446, 0.1704, 0.1552, 0.1697, 0.1731],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,425][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0023, 0.0466, 0.0750, 0.2472, 0.2353, 0.1283, 0.2654],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,426][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1832, 0.0818, 0.1050, 0.0940, 0.1537, 0.1946, 0.1877],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,427][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([7.3013e-01, 2.3012e-04, 3.7606e-03, 7.5869e-03, 7.5373e-03, 1.4867e-01,
        1.0209e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,428][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([4.9835e-01, 4.9636e-06, 7.3839e-03, 1.7687e-03, 8.9776e-02, 9.7227e-02,
        3.0549e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,430][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0295, 0.0469, 0.5626, 0.0227, 0.1637, 0.1523, 0.0223],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,431][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.8457, 0.0039, 0.0303, 0.0054, 0.0499, 0.0466, 0.0182],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,433][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.4073, 0.0313, 0.1678, 0.1185, 0.0966, 0.0927, 0.0858],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,433][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ the] are: tensor([2.7995e-01, 2.9882e-06, 1.6497e-04, 2.7232e-04, 1.6180e-03, 1.3235e-03,
        5.2988e-02, 6.6368e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,435][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0096, 0.1277, 0.1327, 0.1587, 0.1198, 0.1552, 0.1531, 0.1432],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,436][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0801, 0.1417, 0.1283, 0.1348, 0.1253, 0.1225, 0.1233, 0.1439],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,438][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0754, 0.1068, 0.0834, 0.1146, 0.0847, 0.1699, 0.1841, 0.1811],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,439][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0292, 0.1309, 0.1218, 0.1472, 0.1317, 0.1435, 0.1486, 0.1471],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,441][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0020, 0.0379, 0.0567, 0.1773, 0.1699, 0.0882, 0.1922, 0.2758],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,442][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0724, 0.0672, 0.0978, 0.0902, 0.1384, 0.1768, 0.1555, 0.2016],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,443][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ the] are: tensor([7.7777e-01, 5.7361e-05, 1.0064e-03, 1.5294e-03, 2.2021e-03, 1.6660e-02,
        2.0037e-02, 1.8074e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,444][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ the] are: tensor([7.0527e-01, 1.2882e-06, 1.3192e-03, 1.5927e-04, 1.3531e-02, 8.4241e-03,
        5.2997e-02, 2.1829e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,445][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0605, 0.0893, 0.3771, 0.0999, 0.1712, 0.0926, 0.0904, 0.0190],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,447][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.7245, 0.0026, 0.0368, 0.0070, 0.0899, 0.0692, 0.0376, 0.0324],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,448][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1337, 0.0315, 0.1589, 0.0988, 0.0784, 0.0613, 0.0671, 0.3703],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,449][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ house] are: tensor([1.1030e-02, 5.1497e-07, 3.7619e-05, 1.2986e-04, 4.3376e-04, 7.5534e-04,
        7.7393e-02, 7.7686e-01, 1.3336e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,451][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ house] are: tensor([0.0111, 0.1113, 0.1142, 0.1376, 0.1060, 0.1349, 0.1324, 0.1264, 0.1262],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,452][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.0636, 0.1272, 0.1121, 0.1212, 0.1116, 0.1092, 0.1096, 0.1277, 0.1178],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,454][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ house] are: tensor([0.0813, 0.0873, 0.0610, 0.0897, 0.0664, 0.1337, 0.1579, 0.1473, 0.1754],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,455][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ house] are: tensor([0.0247, 0.1156, 0.1095, 0.1310, 0.1158, 0.1143, 0.1296, 0.1224, 0.1372],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,456][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ house] are: tensor([0.0012, 0.0271, 0.0402, 0.1356, 0.1283, 0.0647, 0.1463, 0.2151, 0.2415],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,458][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ house] are: tensor([0.0961, 0.0446, 0.0822, 0.0630, 0.1191, 0.1364, 0.1208, 0.1588, 0.1791],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,459][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ house] are: tensor([2.8999e-01, 6.9142e-05, 1.2947e-03, 3.0943e-03, 2.5908e-03, 4.8598e-02,
        5.3515e-02, 5.5507e-01, 4.5778e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,460][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ house] are: tensor([9.1923e-02, 5.3461e-07, 1.1732e-03, 2.4403e-04, 1.6004e-02, 1.5921e-02,
        1.6638e-01, 5.5519e-01, 1.5317e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,461][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ house] are: tensor([0.0118, 0.1062, 0.5234, 0.0488, 0.1486, 0.0769, 0.0313, 0.0474, 0.0057],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,463][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.3275, 0.0104, 0.0551, 0.0337, 0.0749, 0.1700, 0.0939, 0.1506, 0.0838],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,464][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ house] are: tensor([0.3491, 0.0181, 0.0811, 0.0449, 0.0423, 0.0350, 0.0401, 0.3034, 0.0861],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,465][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [.] are: tensor([1.8773e-01, 5.9758e-08, 1.3203e-05, 1.5287e-05, 1.8062e-04, 7.6115e-05,
        4.2726e-03, 1.4171e-01, 1.2249e-02, 6.5376e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,467][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0082, 0.0993, 0.1009, 0.1250, 0.0925, 0.1215, 0.1191, 0.1119, 0.1100,
        0.1115], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,468][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0607, 0.1117, 0.1006, 0.1069, 0.0983, 0.0976, 0.0974, 0.1123, 0.1053,
        0.1092], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,469][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0529, 0.0726, 0.0533, 0.0763, 0.0566, 0.1223, 0.1361, 0.1312, 0.1588,
        0.1399], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,469][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0276, 0.0997, 0.0955, 0.1121, 0.1061, 0.1066, 0.1141, 0.1099, 0.1129,
        0.1155], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,470][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0014, 0.0285, 0.0408, 0.1232, 0.1118, 0.0595, 0.1273, 0.1719, 0.1991,
        0.1366], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,470][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0586, 0.0478, 0.0741, 0.0609, 0.0975, 0.1230, 0.1111, 0.1479, 0.1496,
        0.1294], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,471][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [.] are: tensor([5.6846e-01, 3.1324e-05, 5.9895e-04, 1.1041e-03, 1.5285e-03, 1.6669e-02,
        1.5405e-02, 2.0991e-01, 1.3370e-02, 1.7292e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,471][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [.] are: tensor([5.5789e-01, 2.6209e-07, 4.2999e-04, 6.4185e-05, 6.2214e-03, 3.4768e-03,
        2.1740e-02, 1.4496e-01, 3.1350e-02, 2.3387e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,471][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0470, 0.0360, 0.4480, 0.0215, 0.1370, 0.1288, 0.0440, 0.0401, 0.0786,
        0.0190], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,472][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.7195, 0.0042, 0.0290, 0.0072, 0.0499, 0.0389, 0.0288, 0.0472, 0.0485,
        0.0269], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,472][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.2396, 0.0221, 0.0868, 0.0472, 0.0441, 0.0357, 0.0391, 0.3066, 0.0868,
        0.0921], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,473][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([2.0760e-01, 3.0159e-07, 1.0680e-05, 1.1581e-05, 8.5049e-05, 2.7871e-05,
        1.2327e-03, 2.5641e-02, 1.0299e-03, 1.2006e-01, 6.4430e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,474][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.0083, 0.0882, 0.0896, 0.1104, 0.0828, 0.1048, 0.1054, 0.0988, 0.0989,
        0.0993, 0.1135], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,476][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.0530, 0.1029, 0.0920, 0.0975, 0.0908, 0.0846, 0.0887, 0.1042, 0.0972,
        0.1002, 0.0889], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,477][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.0633, 0.0716, 0.0440, 0.0701, 0.0478, 0.1076, 0.1198, 0.1130, 0.1280,
        0.1295, 0.1054], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,479][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.0174, 0.0906, 0.0895, 0.0981, 0.1046, 0.0935, 0.0983, 0.0900, 0.1177,
        0.1052, 0.0952], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,480][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.0021, 0.0243, 0.0325, 0.0917, 0.0905, 0.0487, 0.0959, 0.1353, 0.1410,
        0.1176, 0.2203], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,481][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.0997, 0.0270, 0.0533, 0.0325, 0.0802, 0.0879, 0.0749, 0.1058, 0.1135,
        0.0908, 0.2344], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,482][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([6.2667e-01, 5.4391e-05, 3.9697e-04, 7.3700e-04, 1.0415e-03, 4.5633e-03,
        7.4298e-03, 6.1976e-02, 4.2682e-03, 7.7468e-02, 2.1540e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,483][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([3.8766e-01, 2.4618e-07, 7.1147e-05, 1.9745e-05, 9.7702e-04, 2.7611e-04,
        1.9147e-03, 6.9041e-03, 1.2945e-03, 2.5390e-02, 5.7549e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,485][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.0042, 0.1293, 0.1226, 0.1434, 0.2231, 0.0866, 0.0557, 0.0551, 0.0558,
        0.0674, 0.0569], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,486][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.3795, 0.0061, 0.0636, 0.0172, 0.0743, 0.1042, 0.0595, 0.0796, 0.0694,
        0.0485, 0.0981], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,487][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.5468, 0.0079, 0.0329, 0.0164, 0.0171, 0.0148, 0.0181, 0.1536, 0.0406,
        0.0491, 0.1028], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,488][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([1.4966e-03, 2.2125e-09, 5.3748e-07, 3.5318e-07, 4.9219e-06, 3.0473e-06,
        2.4289e-04, 9.9019e-03, 5.7867e-04, 5.5689e-02, 9.0042e-01, 3.1662e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,490][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0076, 0.0782, 0.0798, 0.0960, 0.0740, 0.0946, 0.0939, 0.0901, 0.0909,
        0.0898, 0.1015, 0.1034], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,491][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0560, 0.0932, 0.0817, 0.0875, 0.0830, 0.0772, 0.0809, 0.0935, 0.0871,
        0.0913, 0.0800, 0.0887], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,493][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0477, 0.0550, 0.0391, 0.0575, 0.0431, 0.0934, 0.1033, 0.1033, 0.1219,
        0.1141, 0.1008, 0.1209], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,494][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0200, 0.0780, 0.0788, 0.0835, 0.0884, 0.0918, 0.0882, 0.0879, 0.1021,
        0.0956, 0.0839, 0.1018], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,496][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0009, 0.0142, 0.0211, 0.0690, 0.0678, 0.0324, 0.0732, 0.1081, 0.1175,
        0.0938, 0.2113, 0.1908], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,497][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1465, 0.0241, 0.0404, 0.0275, 0.0555, 0.0704, 0.0649, 0.0952, 0.0918,
        0.0834, 0.1789, 0.1214], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,498][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([1.7650e-01, 8.9169e-06, 2.6777e-04, 2.8210e-04, 4.7471e-04, 3.9938e-03,
        5.1812e-03, 5.7411e-02, 3.6663e-03, 6.9435e-02, 5.3048e-01, 1.5229e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,499][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([2.7599e-02, 6.0798e-09, 1.3320e-05, 1.0165e-06, 1.2129e-04, 7.1946e-05,
        6.3070e-04, 3.7384e-03, 6.0872e-04, 8.2139e-03, 8.7862e-01, 8.0377e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,500][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0090, 0.0414, 0.3789, 0.0324, 0.1069, 0.0473, 0.0244, 0.0238, 0.0210,
        0.0154, 0.2671, 0.0324], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,502][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.4013, 0.0040, 0.0440, 0.0109, 0.0711, 0.0559, 0.0252, 0.0463, 0.0553,
        0.0320, 0.1121, 0.1420], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,503][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.1838, 0.0109, 0.0618, 0.0304, 0.0273, 0.0249, 0.0290, 0.2768, 0.0582,
        0.0739, 0.1803, 0.0427], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,504][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([1.5591e-01, 1.5573e-08, 1.2025e-06, 7.0851e-07, 1.2925e-05, 2.4517e-06,
        9.3551e-05, 3.9254e-03, 1.2874e-04, 9.7946e-03, 1.5486e-01, 6.0064e-03,
        6.6926e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,506][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0091, 0.0697, 0.0717, 0.0842, 0.0665, 0.0826, 0.0828, 0.0791, 0.0790,
        0.0788, 0.0892, 0.0896, 0.1176], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,507][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0523, 0.0826, 0.0751, 0.0782, 0.0751, 0.0728, 0.0732, 0.0851, 0.0791,
        0.0817, 0.0742, 0.0811, 0.0894], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,508][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0501, 0.0512, 0.0382, 0.0529, 0.0404, 0.0834, 0.0923, 0.0886, 0.1067,
        0.0964, 0.0874, 0.1068, 0.1054], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,510][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0221, 0.0748, 0.0707, 0.0827, 0.0776, 0.0799, 0.0814, 0.0809, 0.0896,
        0.0857, 0.0735, 0.0926, 0.0885], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,511][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0013, 0.0124, 0.0176, 0.0505, 0.0534, 0.0252, 0.0537, 0.0775, 0.0811,
        0.0708, 0.1563, 0.1254, 0.2748], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,513][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0757, 0.0228, 0.0378, 0.0286, 0.0545, 0.0720, 0.0635, 0.0939, 0.0916,
        0.0774, 0.1580, 0.1052, 0.1191], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,514][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([5.8189e-01, 5.3071e-06, 1.0140e-04, 9.0015e-05, 2.2848e-04, 7.8294e-04,
        1.1556e-03, 1.1846e-02, 6.1051e-04, 1.2078e-02, 8.3273e-02, 2.2397e-02,
        2.8554e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,515][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([3.1589e-01, 2.8889e-08, 2.7495e-05, 1.6435e-06, 2.7050e-04, 6.0962e-05,
        4.3173e-04, 2.4942e-03, 4.0391e-04, 3.0875e-03, 3.4025e-01, 2.6607e-02,
        3.1047e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,516][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0188, 0.0594, 0.1565, 0.0729, 0.1105, 0.0562, 0.0504, 0.0208, 0.0526,
        0.0425, 0.1946, 0.1273, 0.0375], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,518][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.6280, 0.0021, 0.0260, 0.0040, 0.0659, 0.0280, 0.0141, 0.0227, 0.0430,
        0.0200, 0.0552, 0.0735, 0.0173], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,519][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1603, 0.0145, 0.0646, 0.0362, 0.0282, 0.0246, 0.0313, 0.2509, 0.0453,
        0.0625, 0.1341, 0.0369, 0.1105], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,520][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([1.1623e-01, 9.5766e-10, 1.0352e-07, 2.6577e-08, 8.3785e-07, 6.5870e-08,
        3.6904e-06, 3.9199e-04, 5.9268e-06, 2.6781e-04, 1.3123e-02, 2.3292e-04,
        1.1651e-01, 7.5323e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,522][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0083, 0.0645, 0.0652, 0.0767, 0.0600, 0.0747, 0.0755, 0.0722, 0.0708,
        0.0714, 0.0808, 0.0811, 0.1082, 0.0906], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,523][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.0465, 0.0772, 0.0691, 0.0728, 0.0686, 0.0670, 0.0678, 0.0791, 0.0725,
        0.0753, 0.0677, 0.0759, 0.0846, 0.0757], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,525][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.0559, 0.0485, 0.0334, 0.0487, 0.0375, 0.0700, 0.0836, 0.0827, 0.0938,
        0.0915, 0.0772, 0.0916, 0.0934, 0.0921], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,526][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0192, 0.0672, 0.0651, 0.0742, 0.0722, 0.0739, 0.0731, 0.0737, 0.0827,
        0.0801, 0.0695, 0.0797, 0.0850, 0.0844], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,527][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.0018, 0.0096, 0.0132, 0.0326, 0.0386, 0.0176, 0.0359, 0.0525, 0.0517,
        0.0495, 0.1076, 0.0777, 0.1731, 0.3384], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,527][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.0621, 0.0190, 0.0321, 0.0248, 0.0535, 0.0644, 0.0527, 0.0733, 0.0799,
        0.0571, 0.1402, 0.0990, 0.1022, 0.1397], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,528][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([6.8530e-01, 2.9996e-06, 5.7722e-05, 2.2349e-05, 7.2299e-05, 1.9866e-04,
        2.4744e-04, 3.2270e-03, 1.3052e-04, 2.3138e-03, 2.5496e-02, 5.4767e-03,
        8.1087e-02, 1.9637e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,528][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([3.1911e-01, 4.3068e-09, 5.8243e-06, 6.8084e-08, 3.0755e-05, 2.4530e-06,
        2.7967e-05, 1.5348e-04, 1.8671e-05, 9.0917e-05, 4.4472e-02, 2.0914e-03,
        3.3515e-02, 6.0048e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,528][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.0083, 0.0474, 0.2566, 0.0287, 0.0962, 0.0372, 0.0434, 0.0390, 0.0144,
        0.0208, 0.1634, 0.0778, 0.0554, 0.1113], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,529][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.4267, 0.0034, 0.0247, 0.0085, 0.0444, 0.0557, 0.0382, 0.0582, 0.0428,
        0.0582, 0.0539, 0.0879, 0.0519, 0.0453], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,529][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.4808, 0.0055, 0.0243, 0.0065, 0.0094, 0.0069, 0.0105, 0.0897, 0.0198,
        0.0266, 0.0628, 0.0128, 0.0450, 0.1994], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,530][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([2.2825e-02, 1.6400e-10, 3.0058e-08, 5.5085e-09, 2.1768e-07, 2.2234e-08,
        1.0529e-06, 1.2260e-04, 1.8835e-06, 2.8011e-04, 1.2355e-02, 1.5043e-04,
        5.5972e-02, 7.6468e-01, 1.4361e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,531][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0069, 0.0580, 0.0602, 0.0697, 0.0546, 0.0686, 0.0683, 0.0655, 0.0655,
        0.0656, 0.0742, 0.0746, 0.0990, 0.0843, 0.0850], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,532][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0452, 0.0723, 0.0645, 0.0687, 0.0642, 0.0621, 0.0634, 0.0733, 0.0677,
        0.0707, 0.0629, 0.0704, 0.0773, 0.0697, 0.0677], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,533][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0484, 0.0470, 0.0322, 0.0461, 0.0351, 0.0672, 0.0776, 0.0747, 0.0872,
        0.0827, 0.0707, 0.0839, 0.0849, 0.0818, 0.0805], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,535][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0148, 0.0641, 0.0599, 0.0721, 0.0641, 0.0710, 0.0721, 0.0712, 0.0711,
        0.0739, 0.0620, 0.0770, 0.0768, 0.0755, 0.0744], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,536][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0008, 0.0058, 0.0089, 0.0236, 0.0270, 0.0126, 0.0260, 0.0399, 0.0418,
        0.0373, 0.0827, 0.0648, 0.1511, 0.3063, 0.1715], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,538][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1184, 0.0199, 0.0316, 0.0227, 0.0479, 0.0536, 0.0497, 0.0716, 0.0697,
        0.0568, 0.1181, 0.0757, 0.0806, 0.1223, 0.0612], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,539][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([4.4438e-01, 1.9378e-06, 5.0138e-05, 2.4857e-05, 8.9060e-05, 3.1455e-04,
        3.2807e-04, 3.9921e-03, 1.6401e-04, 4.1737e-03, 4.1666e-02, 8.5645e-03,
        1.1717e-01, 2.9500e-01, 8.4076e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,540][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([4.6054e-02, 1.5015e-09, 2.1466e-06, 8.5502e-08, 1.7913e-05, 3.3769e-06,
        1.7893e-05, 1.4482e-04, 2.3393e-05, 2.6248e-04, 4.7498e-02, 1.9240e-03,
        2.9080e-02, 7.5064e-01, 1.2433e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,541][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0152, 0.0215, 0.1860, 0.0114, 0.0611, 0.0471, 0.0113, 0.0192, 0.0289,
        0.0139, 0.2242, 0.1095, 0.0428, 0.1943, 0.0136], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,543][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.6508, 0.0025, 0.0239, 0.0038, 0.0385, 0.0346, 0.0155, 0.0207, 0.0329,
        0.0159, 0.0442, 0.0628, 0.0151, 0.0238, 0.0151], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,544][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.2040, 0.0094, 0.0426, 0.0154, 0.0160, 0.0122, 0.0177, 0.1476, 0.0318,
        0.0398, 0.0894, 0.0214, 0.0628, 0.2180, 0.0719], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,590][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:51,590][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,590][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,591][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,591][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,591][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,592][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,592][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,593][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,594][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,595][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,596][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,597][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,598][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9703, 0.0297], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,600][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1603, 0.8397], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,601][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.5307, 0.4693], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,602][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9646, 0.0354], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,604][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9981, 0.0019], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,605][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.8364, 0.1636], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,607][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9979, 0.0021], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,608][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.5596, 0.4404], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,610][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8814, 0.1186], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,610][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.2203e-04, 9.9988e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,612][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2899, 0.7101], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,613][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.5051, 0.4949], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,615][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.7752, 0.0077, 0.2171], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,616][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.1377, 0.0658, 0.7964], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,617][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.2443, 0.1315, 0.6242], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,619][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.6896, 0.0221, 0.2884], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,620][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.9703, 0.0037, 0.0260], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,621][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.4033, 0.0431, 0.5536], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,623][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.9789, 0.0024, 0.0187], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,624][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.3687, 0.0847, 0.5467], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,625][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.7142, 0.0091, 0.2767], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,626][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([1.1627e-04, 9.0695e-01, 9.2931e-02], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,627][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.0854, 0.6503, 0.2643], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,629][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.1767, 0.0407, 0.7826], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,630][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.7636, 0.0011, 0.1169, 0.1184], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,632][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0170, 0.0079, 0.3682, 0.6069], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,633][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4197, 0.0598, 0.3330, 0.1875], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,635][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.7762, 0.0033, 0.1568, 0.0637], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,635][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.9019e-01, 7.7190e-04, 5.1222e-03, 3.9137e-03], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,637][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4027, 0.0049, 0.2306, 0.3618], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,638][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([9.8814e-01, 9.1335e-04, 6.6584e-03, 4.2845e-03], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,639][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3137, 0.0229, 0.2935, 0.3698], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,641][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.6441, 0.0012, 0.1674, 0.1873], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,642][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([9.4172e-05, 4.0919e-01, 8.8845e-02, 5.0187e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,643][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2483, 0.2333, 0.1577, 0.3607], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,644][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1738, 0.0041, 0.2067, 0.6154], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,646][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.4620, 0.0034, 0.0939, 0.2047, 0.2360], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,646][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0347, 0.0118, 0.1622, 0.4661, 0.3252], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,647][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.1436, 0.0557, 0.3013, 0.1720, 0.3273], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,647][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.4167, 0.0118, 0.1777, 0.1250, 0.2689], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,648][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.8778, 0.0032, 0.0219, 0.0132, 0.0838], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,648][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.1796, 0.0087, 0.1279, 0.2658, 0.4180], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,648][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.9383, 0.0032, 0.0181, 0.0104, 0.0300], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,649][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.1784, 0.0331, 0.1994, 0.3522, 0.2369], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,649][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.3386, 0.0019, 0.0878, 0.2088, 0.3629], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,649][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([5.8027e-05, 2.5149e-01, 4.2657e-02, 6.6852e-01, 3.7274e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,650][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0598, 0.2592, 0.1383, 0.2988, 0.2438], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,651][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.0564, 0.0066, 0.1254, 0.5542, 0.2575], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,652][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([7.3417e-01, 1.4525e-04, 2.2000e-02, 2.0430e-02, 8.0826e-02, 1.4243e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,653][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([4.8568e-02, 6.5918e-04, 2.1494e-02, 6.2907e-02, 6.4772e-02, 8.0160e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,654][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.2001, 0.0302, 0.1978, 0.0808, 0.2369, 0.2542], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,656][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.3568, 0.0015, 0.0510, 0.0363, 0.0871, 0.4674], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,657][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.9542, 0.0013, 0.0066, 0.0057, 0.0206, 0.0116], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,658][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.2206, 0.0007, 0.0320, 0.0494, 0.1306, 0.5668], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,659][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([9.7736e-01, 7.8522e-04, 5.9412e-03, 2.7115e-03, 7.9522e-03, 5.2517e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,661][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.1543, 0.0036, 0.0429, 0.0679, 0.0640, 0.6674], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,662][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([4.8826e-01, 6.1810e-05, 1.5988e-02, 1.8784e-02, 9.2165e-02, 3.8474e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,663][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([5.2347e-05, 2.6500e-01, 3.8122e-02, 4.8321e-01, 2.6639e-02, 1.8697e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,664][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0550, 0.1450, 0.0889, 0.2315, 0.2011, 0.2784], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,665][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([9.2437e-02, 3.1827e-04, 2.5201e-02, 7.2794e-02, 6.6806e-02, 7.4244e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,666][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([8.9501e-01, 2.4361e-05, 3.9514e-03, 2.5086e-03, 1.6456e-02, 1.6865e-02,
        6.5184e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,667][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.6475e-02, 9.0834e-05, 4.9577e-03, 5.7259e-03, 1.4136e-02, 9.6006e-02,
        8.6261e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,668][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3439, 0.0161, 0.1041, 0.0393, 0.1489, 0.1172, 0.2304],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,669][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([7.7860e-01, 2.6097e-04, 1.5348e-02, 5.5759e-03, 2.8581e-02, 8.5791e-02,
        8.5844e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,670][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.7877e-01, 3.0106e-04, 2.8456e-03, 1.4862e-03, 1.0285e-02, 3.1925e-03,
        3.1221e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,671][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.7588e-01, 1.4744e-04, 1.0887e-02, 1.0233e-02, 4.5829e-02, 1.2187e-01,
        5.3515e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,672][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.8950e-01, 2.1469e-04, 1.9090e-03, 1.0324e-03, 3.7046e-03, 1.4559e-03,
        2.1839e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,673][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.3596, 0.0010, 0.0207, 0.0171, 0.0351, 0.2333, 0.3332],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,674][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([6.7208e-01, 8.4052e-06, 2.9709e-03, 1.3835e-03, 1.8413e-02, 3.6133e-02,
        2.6901e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,675][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([7.6090e-05, 1.4970e-01, 5.0283e-02, 2.2416e-01, 4.1552e-02, 1.7988e-01,
        3.5434e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,676][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1543, 0.0552, 0.0497, 0.1177, 0.1489, 0.1464, 0.3278],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,677][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.6026e-01, 5.7781e-05, 6.4112e-03, 9.1872e-03, 1.7475e-02, 1.0243e-01,
        7.0418e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:51,678][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([8.8566e-01, 1.1877e-05, 1.5256e-03, 7.5173e-04, 5.9343e-03, 4.3432e-03,
        1.6645e-02, 8.5124e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,679][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([6.2962e-02, 4.9892e-05, 2.8413e-03, 2.0837e-03, 8.3193e-03, 2.7225e-02,
        2.4296e-01, 6.5356e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,681][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2266, 0.0118, 0.0720, 0.0305, 0.1072, 0.0775, 0.1593, 0.3151],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,681][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([7.6146e-01, 1.4465e-04, 1.0005e-02, 2.6041e-03, 1.7969e-02, 3.6457e-02,
        3.1972e-02, 1.3938e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,682][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([9.6277e-01, 3.7082e-04, 4.4695e-03, 1.3650e-03, 1.3959e-02, 4.4608e-03,
        3.5050e-03, 9.0957e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,683][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([3.8136e-01, 1.0683e-04, 4.9246e-03, 3.9006e-03, 1.9331e-02, 3.3406e-02,
        1.1929e-01, 4.3768e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,684][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([9.8905e-01, 1.6775e-04, 1.7749e-03, 8.5815e-04, 3.1691e-03, 1.3782e-03,
        1.3104e-03, 2.2950e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,685][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.3694, 0.0005, 0.0091, 0.0069, 0.0163, 0.0530, 0.0998, 0.4450],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,686][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([6.8781e-01, 3.8668e-06, 8.3411e-04, 2.9898e-04, 4.4455e-03, 5.7708e-03,
        4.4488e-02, 2.5635e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,687][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([2.5445e-04, 1.6568e-01, 3.7795e-02, 2.2091e-01, 3.7942e-02, 1.1237e-01,
        3.4372e-01, 8.1331e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,689][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1252, 0.0271, 0.0405, 0.0899, 0.1208, 0.1228, 0.3047, 0.1690],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,690][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([1.8138e-01, 3.6467e-05, 3.0331e-03, 3.1673e-03, 7.2155e-03, 2.6630e-02,
        1.7978e-01, 5.9877e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:51,690][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([3.1569e-01, 1.8037e-05, 2.9722e-03, 2.0662e-03, 1.2203e-02, 1.6273e-02,
        9.1476e-02, 4.3204e-01, 1.2726e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,691][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([2.8192e-03, 9.8588e-06, 7.0033e-04, 9.1414e-04, 2.6442e-03, 2.1371e-02,
        2.5571e-01, 6.3108e-01, 8.4755e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,693][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([0.1080, 0.0067, 0.0517, 0.0239, 0.0726, 0.0719, 0.1592, 0.2751, 0.2310],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,694][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([2.3389e-01, 1.6086e-04, 1.0557e-02, 4.3850e-03, 2.4476e-02, 7.1614e-02,
        1.0135e-01, 3.6966e-01, 1.8392e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,695][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([9.1708e-01, 5.9116e-04, 6.3485e-03, 3.9513e-03, 2.5675e-02, 8.6703e-03,
        1.1725e-02, 2.1280e-02, 4.6799e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,696][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([7.5135e-02, 3.5128e-05, 2.3293e-03, 2.4908e-03, 1.1019e-02, 3.7861e-02,
        1.6438e-01, 5.4304e-01, 1.6372e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,697][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([9.7827e-01, 2.6385e-04, 2.6367e-03, 1.6071e-03, 5.5249e-03, 2.7359e-03,
        2.4710e-03, 4.1579e-03, 2.3326e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,697][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([8.9132e-02, 2.7075e-04, 5.3127e-03, 5.4279e-03, 9.2827e-03, 6.4429e-02,
        1.3353e-01, 6.1335e-01, 7.9258e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,698][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([7.4486e-02, 1.4157e-06, 5.6733e-04, 3.3985e-04, 3.8899e-03, 9.4548e-03,
        1.1499e-01, 6.4000e-01, 1.5627e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,699][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([5.8407e-05, 7.4136e-02, 2.8045e-02, 1.5205e-01, 3.1460e-02, 1.1564e-01,
        3.6373e-01, 8.7184e-02, 1.4770e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,701][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([0.0190, 0.0336, 0.0232, 0.0627, 0.0682, 0.0942, 0.2630, 0.1036, 0.3325],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,702][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([7.0120e-03, 8.2812e-06, 8.6317e-04, 1.6857e-03, 2.1804e-03, 2.0310e-02,
        1.8591e-01, 6.9341e-01, 8.8621e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:51,703][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([9.1550e-01, 1.1988e-06, 3.7490e-04, 1.4496e-04, 2.0088e-03, 9.3262e-04,
        3.3303e-03, 2.5591e-02, 5.6615e-03, 4.6458e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,704][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([3.2742e-02, 5.3622e-06, 4.2116e-04, 3.6400e-04, 1.4009e-03, 5.7590e-03,
        5.5480e-02, 2.0306e-01, 1.4088e-02, 6.8668e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,705][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1538, 0.0049, 0.0348, 0.0128, 0.0614, 0.0390, 0.0840, 0.1611, 0.1198,
        0.3284], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,705][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([5.9557e-01, 5.4715e-05, 4.7217e-03, 1.4009e-03, 9.7265e-03, 2.8458e-02,
        2.6458e-02, 1.3307e-01, 6.4641e-02, 1.3590e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,705][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([9.8466e-01, 1.3087e-04, 1.4259e-03, 5.5159e-04, 5.2136e-03, 1.6655e-03,
        1.2446e-03, 3.0363e-03, 6.6043e-04, 1.4072e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,706][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([2.2317e-01, 1.5464e-05, 1.3600e-03, 1.0833e-03, 6.6780e-03, 9.9724e-03,
        4.3219e-02, 1.9492e-01, 4.0369e-02, 4.7921e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,706][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([9.8548e-01, 1.8244e-04, 1.6846e-03, 8.3921e-04, 2.7489e-03, 1.1963e-03,
        1.2397e-03, 2.1046e-03, 8.9617e-04, 3.6315e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,706][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([2.2565e-01, 1.3790e-04, 3.2778e-03, 2.3894e-03, 6.5181e-03, 2.8733e-02,
        4.9063e-02, 3.2847e-01, 2.9767e-02, 3.2599e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,707][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([4.9381e-01, 4.3740e-07, 1.7380e-04, 7.0801e-05, 1.3754e-03, 1.3081e-03,
        1.2465e-02, 1.1426e-01, 1.6315e-02, 3.6022e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,707][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([6.8089e-05, 9.4090e-02, 3.5541e-02, 1.4341e-01, 3.1061e-02, 7.0806e-02,
        2.0661e-01, 4.7483e-02, 9.5721e-02, 2.7521e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,709][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0567, 0.0276, 0.0284, 0.0567, 0.0821, 0.0782, 0.1830, 0.0877, 0.2358,
        0.1639], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,709][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([2.4581e-01, 4.0534e-06, 5.2943e-04, 5.5193e-04, 2.3178e-03, 5.5882e-03,
        3.6327e-02, 1.7214e-01, 1.4867e-02, 5.2186e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:51,710][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([6.5042e-01, 5.1973e-06, 3.6556e-04, 1.8172e-04, 1.3526e-03, 4.7833e-04,
        2.1363e-03, 1.0685e-02, 1.7510e-03, 2.6403e-02, 3.0623e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,711][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([3.4365e-02, 1.2225e-05, 3.4525e-04, 3.7456e-04, 1.1278e-03, 2.6609e-03,
        2.3817e-02, 7.0324e-02, 6.3951e-03, 2.0496e-01, 6.5562e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,713][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.1113, 0.0055, 0.0402, 0.0128, 0.0530, 0.0277, 0.0494, 0.0856, 0.0809,
        0.1787, 0.3550], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,714][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([3.3508e-01, 1.4562e-04, 2.9148e-03, 1.1466e-03, 5.8752e-03, 1.1075e-02,
        1.1616e-02, 4.2411e-02, 1.3665e-02, 7.5933e-02, 5.0014e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,715][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([9.1108e-01, 8.0303e-04, 6.1789e-03, 2.4408e-03, 1.6348e-02, 5.9319e-03,
        6.1266e-03, 9.7499e-03, 3.2424e-03, 7.3770e-03, 3.0725e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,715][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([1.1874e-01, 3.6764e-05, 9.2247e-04, 7.4538e-04, 3.4650e-03, 5.7832e-03,
        1.5997e-02, 7.1030e-02, 1.4688e-02, 1.5397e-01, 6.1462e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,716][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([9.4136e-01, 4.3587e-04, 4.0852e-03, 1.6068e-03, 6.7659e-03, 2.1970e-03,
        2.0555e-03, 3.4455e-03, 1.7241e-03, 5.5925e-03, 3.0736e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,717][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([2.5289e-01, 2.8460e-04, 2.7239e-03, 2.2409e-03, 5.1969e-03, 1.1787e-02,
        2.7125e-02, 1.1582e-01, 1.2891e-02, 1.3925e-01, 4.2979e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,718][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([3.4706e-01, 1.1542e-06, 1.0260e-04, 6.1868e-05, 6.7443e-04, 4.6223e-04,
        3.7474e-03, 1.9843e-02, 3.2561e-03, 9.1677e-02, 5.3311e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,719][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([3.2670e-05, 6.7049e-02, 1.1273e-02, 9.5409e-02, 1.5096e-02, 5.5866e-02,
        2.0351e-01, 4.2320e-02, 9.1801e-02, 3.5963e-01, 5.8019e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,721][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.0195, 0.0506, 0.0322, 0.0535, 0.0571, 0.0771, 0.1832, 0.0731, 0.2157,
        0.1769, 0.0609], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,721][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([6.3856e-02, 5.1201e-06, 2.4330e-04, 2.6272e-04, 7.8833e-04, 1.5353e-03,
        8.5270e-03, 3.5229e-02, 3.1558e-03, 1.2411e-01, 7.6229e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:51,722][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([1.2000e-01, 4.7993e-07, 1.5246e-04, 3.7913e-05, 5.2520e-04, 3.9363e-04,
        1.6278e-03, 1.4134e-02, 2.3546e-03, 2.5244e-02, 7.5603e-01, 7.9495e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,723][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([1.0281e-03, 5.5908e-07, 4.8898e-05, 3.8183e-05, 1.5305e-04, 5.9535e-04,
        7.4088e-03, 2.9264e-02, 2.7309e-03, 1.2023e-01, 6.8150e-01, 1.5701e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,725][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0590, 0.0021, 0.0193, 0.0056, 0.0288, 0.0183, 0.0369, 0.0745, 0.0690,
        0.1712, 0.3585, 0.1568], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,726][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([1.2557e-01, 1.6204e-05, 1.1024e-03, 3.1631e-04, 2.0810e-03, 5.2826e-03,
        6.8749e-03, 3.5274e-02, 1.2572e-02, 4.0685e-02, 5.9021e-01, 1.8002e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,727][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([8.7487e-01, 5.3636e-04, 5.1530e-03, 2.0511e-03, 1.5564e-02, 5.2653e-03,
        5.3943e-03, 1.1870e-02, 3.1184e-03, 7.2788e-03, 5.3118e-02, 1.5780e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,728][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([2.1702e-02, 2.9571e-06, 2.0412e-04, 1.2951e-04, 8.2583e-04, 1.5779e-03,
        7.7495e-03, 3.6181e-02, 6.7536e-03, 1.0844e-01, 6.2082e-01, 1.9562e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,729][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([9.2476e-01, 3.5170e-04, 3.6222e-03, 1.5670e-03, 5.1596e-03, 2.8023e-03,
        2.3914e-03, 4.3015e-03, 1.7361e-03, 6.8927e-03, 3.4060e-02, 1.2352e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,730][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([4.3516e-02, 4.2077e-05, 1.0728e-03, 6.4940e-04, 1.6459e-03, 5.9961e-03,
        1.3678e-02, 7.3394e-02, 6.9219e-03, 9.6878e-02, 5.1699e-01, 2.3921e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,731][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([3.7723e-02, 4.8878e-08, 2.0027e-05, 5.5078e-06, 9.3809e-05, 1.3135e-04,
        1.3857e-03, 1.1880e-02, 1.5705e-03, 5.4272e-02, 7.7971e-01, 1.1321e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,731][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([1.2507e-05, 5.0593e-02, 9.7013e-03, 1.0116e-01, 9.0001e-03, 6.7827e-02,
        1.5906e-01, 4.9815e-02, 5.2248e-02, 3.6612e-01, 4.1451e-02, 9.3015e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,733][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0183, 0.0256, 0.0285, 0.0513, 0.0729, 0.0764, 0.1550, 0.0799, 0.2222,
        0.1542, 0.0486, 0.0669], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,734][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([8.0389e-03, 2.0284e-07, 3.5381e-05, 2.5128e-05, 1.1138e-04, 2.9864e-04,
        2.4037e-03, 1.2472e-02, 8.1088e-04, 4.3479e-02, 8.1212e-01, 1.2020e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:51,735][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([6.8172e-01, 7.7067e-07, 1.0315e-04, 3.2387e-05, 4.4755e-04, 1.3352e-04,
        5.3213e-04, 3.9270e-03, 5.7645e-04, 6.2753e-03, 1.5966e-01, 1.4875e-02,
        1.3172e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,736][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([2.3600e-02, 1.2652e-06, 8.3751e-05, 4.3917e-05, 2.6772e-04, 4.1352e-04,
        3.9430e-03, 1.6539e-02, 1.2773e-03, 3.6137e-02, 2.6783e-01, 4.5743e-02,
        6.0412e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,737][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0984, 0.0030, 0.0203, 0.0064, 0.0285, 0.0155, 0.0305, 0.0685, 0.0487,
        0.1103, 0.2057, 0.1120, 0.2520], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,738][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([4.0223e-01, 2.3251e-05, 1.4674e-03, 3.1203e-04, 2.7241e-03, 3.8146e-03,
        3.4641e-03, 1.7432e-02, 7.0565e-03, 1.6065e-02, 2.7243e-01, 8.3003e-02,
        1.8998e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,739][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([9.1507e-01, 3.0776e-04, 3.5643e-03, 8.3183e-04, 1.0728e-02, 3.1560e-03,
        2.6992e-03, 6.5685e-03, 2.0956e-03, 3.4125e-03, 2.6487e-02, 8.4175e-03,
        1.6660e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,740][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.6175e-01, 6.8429e-06, 3.3753e-04, 1.6453e-04, 1.2738e-03, 1.0924e-03,
        3.7822e-03, 1.8402e-02, 3.1757e-03, 3.5168e-02, 2.6132e-01, 6.4782e-02,
        4.4875e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,741][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([9.6521e-01, 1.3196e-04, 1.6991e-03, 6.9292e-04, 2.9620e-03, 1.2101e-03,
        9.8049e-04, 1.8401e-03, 9.1572e-04, 2.3078e-03, 1.1721e-02, 4.1243e-03,
        6.2016e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,742][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([1.8624e-01, 5.1357e-05, 9.3362e-04, 4.7858e-04, 1.6055e-03, 2.9992e-03,
        5.8168e-03, 3.1852e-02, 2.8595e-03, 3.4567e-02, 1.7662e-01, 8.1714e-02,
        4.7426e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,743][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([3.5480e-01, 1.0979e-07, 2.7009e-05, 5.0604e-06, 1.4253e-04, 6.6267e-05,
        5.2449e-04, 4.6658e-03, 4.8649e-04, 9.8342e-03, 2.0514e-01, 2.1971e-02,
        4.0234e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,744][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([9.1951e-05, 7.5398e-02, 1.6237e-02, 1.1862e-01, 1.8666e-02, 5.3709e-02,
        1.7788e-01, 4.2991e-02, 8.5155e-02, 2.2715e-01, 5.0809e-02, 9.4923e-02,
        3.8368e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,745][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0682, 0.0131, 0.0216, 0.0437, 0.0637, 0.0602, 0.1398, 0.0845, 0.1718,
        0.1373, 0.0490, 0.0780, 0.0691], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,746][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([6.3818e-02, 7.0664e-07, 6.7151e-05, 3.7791e-05, 1.8652e-04, 2.8029e-04,
        1.7164e-03, 8.9213e-03, 7.4762e-04, 1.9032e-02, 3.7371e-01, 6.4429e-02,
        4.6706e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:51,747][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([7.3099e-01, 8.7836e-08, 1.6195e-05, 2.6581e-06, 5.7617e-05, 9.7979e-06,
        4.0163e-05, 4.3749e-04, 4.7538e-05, 3.5048e-04, 2.1268e-02, 1.1671e-03,
        1.9605e-02, 2.2601e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,748][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([9.6005e-03, 1.5650e-07, 1.3721e-05, 3.9548e-06, 3.0669e-05, 3.3642e-05,
        2.8935e-04, 1.5677e-03, 8.4919e-05, 2.3374e-03, 4.4904e-02, 5.5505e-03,
        7.0974e-02, 8.6461e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,750][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.0943, 0.0017, 0.0138, 0.0030, 0.0170, 0.0079, 0.0150, 0.0325, 0.0252,
        0.0570, 0.1430, 0.0628, 0.1294, 0.3974], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,751][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([2.9997e-01, 7.8498e-06, 6.0921e-04, 9.2005e-05, 1.2097e-03, 1.1144e-03,
        1.2504e-03, 6.2257e-03, 2.3312e-03, 6.4668e-03, 1.4189e-01, 3.5009e-02,
        7.8805e-02, 4.2502e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,752][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([9.6841e-01, 1.1781e-04, 1.1740e-03, 3.8883e-04, 3.4666e-03, 8.6085e-04,
        8.0087e-04, 2.2886e-03, 3.7519e-04, 9.3979e-04, 8.1683e-03, 2.4764e-03,
        4.4460e-03, 6.0846e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,753][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([6.9992e-02, 1.2913e-06, 7.4646e-05, 1.9964e-05, 2.1355e-04, 1.5531e-04,
        5.4099e-04, 3.0223e-03, 4.0711e-04, 4.6692e-03, 6.4779e-02, 1.1042e-02,
        9.5872e-02, 7.4921e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,754][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([9.5757e-01, 1.1444e-04, 1.1026e-03, 5.0989e-04, 1.9685e-03, 8.3186e-04,
        6.1235e-04, 1.2684e-03, 6.3194e-04, 1.7947e-03, 9.1317e-03, 2.8347e-03,
        3.8823e-03, 1.7747e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,755][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([1.5384e-01, 1.6664e-05, 3.2696e-04, 9.9399e-05, 3.8788e-04, 6.7327e-04,
        1.1920e-03, 9.2687e-03, 5.8877e-04, 7.1301e-03, 5.5297e-02, 2.1298e-02,
        1.5701e-01, 5.9287e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,756][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([1.9335e-01, 8.1569e-09, 3.0373e-06, 1.8302e-07, 1.0864e-05, 2.4253e-06,
        2.0098e-05, 2.5728e-04, 1.8628e-05, 3.7418e-04, 2.0483e-02, 1.3208e-03,
        3.6370e-02, 7.4779e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,757][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([5.7286e-05, 3.0228e-02, 1.3304e-02, 8.3968e-02, 1.3890e-02, 4.3724e-02,
        2.0656e-01, 4.0573e-02, 7.2254e-02, 1.6271e-01, 5.6762e-02, 1.0828e-01,
        5.0867e-02, 1.1681e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,758][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.0266, 0.0184, 0.0156, 0.0390, 0.0460, 0.0559, 0.1392, 0.0565, 0.1509,
        0.1435, 0.0340, 0.0579, 0.0499, 0.1666], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,759][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([7.5012e-02, 7.4416e-08, 1.0938e-05, 2.3520e-06, 2.0064e-05, 1.5956e-05,
        7.8976e-05, 6.4968e-04, 3.1760e-05, 8.2075e-04, 4.5617e-02, 3.7132e-03,
        5.0496e-02, 8.2353e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:51,760][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([3.7152e-01, 7.7522e-08, 1.9486e-05, 2.9361e-06, 6.4401e-05, 1.2992e-05,
        5.1148e-05, 5.8392e-04, 6.0979e-05, 8.7526e-04, 4.4372e-02, 2.0000e-03,
        2.9518e-02, 5.0326e-01, 4.7661e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,761][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.9722e-03, 6.8147e-08, 6.6545e-06, 2.2389e-06, 1.7198e-05, 2.2449e-05,
        1.8425e-04, 1.2305e-03, 6.9238e-05, 2.6197e-03, 2.7311e-02, 4.0207e-03,
        6.7998e-02, 6.8633e-01, 2.0722e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,762][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0772, 0.0011, 0.0079, 0.0020, 0.0111, 0.0057, 0.0106, 0.0243, 0.0166,
        0.0418, 0.1035, 0.0451, 0.1087, 0.3636, 0.1810], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,762][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.4479e-01, 4.3734e-06, 3.9935e-04, 5.5436e-05, 7.4913e-04, 8.3093e-04,
        6.7351e-04, 4.1548e-03, 1.5155e-03, 3.5260e-03, 1.0361e-01, 2.1687e-02,
        5.8767e-02, 3.5884e-01, 1.0040e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,763][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.5306e-01, 1.5035e-04, 1.4643e-03, 4.7298e-04, 4.9685e-03, 1.1970e-03,
        1.0357e-03, 2.7741e-03, 5.9405e-04, 9.6379e-04, 9.4501e-03, 2.9137e-03,
        6.8107e-03, 9.1347e-03, 5.0108e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,763][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([3.2367e-02, 4.6402e-07, 3.9295e-05, 1.2417e-05, 1.3294e-04, 9.6999e-05,
        3.7396e-04, 2.1955e-03, 3.0062e-04, 4.3798e-03, 4.7184e-02, 8.0190e-03,
        7.9114e-02, 6.3405e-01, 1.9174e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,764][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.5698e-01, 8.4507e-05, 1.0341e-03, 4.4562e-04, 1.9500e-03, 6.8613e-04,
        7.0562e-04, 1.1256e-03, 5.4044e-04, 1.4620e-03, 8.4691e-03, 2.4780e-03,
        3.8616e-03, 1.4380e-02, 5.7925e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,764][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([8.8335e-02, 7.2991e-06, 1.9877e-04, 6.2292e-05, 2.8806e-04, 5.2175e-04,
        8.3120e-04, 6.1083e-03, 3.8617e-04, 5.9607e-03, 5.1320e-02, 1.7309e-02,
        1.2252e-01, 5.0323e-01, 2.0293e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,765][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([5.3203e-02, 3.4106e-09, 1.3658e-06, 1.4395e-07, 5.7463e-06, 2.1460e-06,
        1.7802e-05, 2.1962e-04, 1.5730e-05, 4.5446e-04, 1.7971e-02, 1.0983e-03,
        3.0517e-02, 7.9973e-01, 9.6764e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,765][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([3.3184e-05, 5.3229e-02, 1.7091e-02, 8.6419e-02, 1.9841e-02, 6.2342e-02,
        1.1644e-01, 3.1667e-02, 6.9442e-02, 2.1571e-01, 5.5660e-02, 1.0142e-01,
        2.8832e-02, 3.4688e-02, 1.0718e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,766][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0850, 0.0112, 0.0189, 0.0394, 0.0572, 0.0544, 0.0956, 0.0650, 0.1328,
        0.1012, 0.0319, 0.0558, 0.0520, 0.1345, 0.0651], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,767][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.5061e-02, 2.4367e-08, 3.9471e-06, 1.1672e-06, 9.1699e-06, 9.8864e-06,
        6.0366e-05, 5.0802e-04, 2.2630e-05, 1.0149e-03, 3.3389e-02, 3.2210e-03,
        4.3116e-02, 7.0084e-01, 2.0274e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:51,768][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:51,770][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[23999],
        [39212],
        [26808],
        [20118],
        [48231],
        [12471],
        [11548],
        [ 9812],
        [ 9443],
        [ 6229],
        [12869],
        [ 3996],
        [ 8344],
        [ 4254],
        [ 5911]], device='cuda:0')
[2024-07-24 10:21:51,771][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[23926],
        [40321],
        [41038],
        [35918],
        [50102],
        [33515],
        [30357],
        [27225],
        [27133],
        [18171],
        [36292],
        [16981],
        [26746],
        [18547],
        [20999]], device='cuda:0')
[2024-07-24 10:21:51,773][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[34535],
        [49282],
        [43815],
        [48391],
        [48266],
        [47039],
        [48448],
        [47797],
        [47917],
        [47697],
        [41552],
        [39882],
        [45882],
        [44029],
        [44437]], device='cuda:0')
[2024-07-24 10:21:51,774][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[26450],
        [33741],
        [32434],
        [29313],
        [28168],
        [26085],
        [25484],
        [26053],
        [25833],
        [25570],
        [25571],
        [25651],
        [25955],
        [25836],
        [25631]], device='cuda:0')
[2024-07-24 10:21:51,775][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[35994],
        [39596],
        [39565],
        [40232],
        [40562],
        [39787],
        [40069],
        [40814],
        [40920],
        [41164],
        [41270],
        [41136],
        [41306],
        [41081],
        [41116]], device='cuda:0')
[2024-07-24 10:21:51,777][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[18607],
        [20066],
        [14483],
        [14998],
        [14838],
        [15704],
        [16167],
        [15334],
        [14432],
        [14295],
        [13399],
        [12724],
        [12239],
        [12362],
        [12430]], device='cuda:0')
[2024-07-24 10:21:51,778][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[25625],
        [22343],
        [20423],
        [20654],
        [11258],
        [12128],
        [15269],
        [16443],
        [17046],
        [16177],
        [15466],
        [15606],
        [16058],
        [15735],
        [16848]], device='cuda:0')
[2024-07-24 10:21:51,780][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[2919],
        [5926],
        [3554],
        [3791],
        [2402],
        [2441],
        [2272],
        [2456],
        [2782],
        [2612],
        [2615],
        [2747],
        [2886],
        [2945],
        [2924]], device='cuda:0')
[2024-07-24 10:21:51,781][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[1518],
        [1038],
        [ 420],
        [ 398],
        [ 246],
        [ 216],
        [ 232],
        [ 213],
        [ 182],
        [ 193],
        [ 169],
        [ 203],
        [ 194],
        [ 170],
        [ 166]], device='cuda:0')
[2024-07-24 10:21:51,782][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[24661],
        [31586],
        [39791],
        [37622],
        [38879],
        [31868],
        [33178],
        [38009],
        [39355],
        [37873],
        [39258],
        [38732],
        [37797],
        [36516],
        [37365]], device='cuda:0')
[2024-07-24 10:21:51,784][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 3685],
        [ 7898],
        [ 3716],
        [ 4462],
        [ 6725],
        [ 5258],
        [ 5873],
        [ 5989],
        [11544],
        [ 7740],
        [ 6542],
        [ 8091],
        [ 8272],
        [ 6564],
        [ 7671]], device='cuda:0')
[2024-07-24 10:21:51,785][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[31756],
        [16463],
        [ 2015],
        [  853],
        [  794],
        [  241],
        [ 1107],
        [ 1192],
        [  978],
        [ 1626],
        [ 1828],
        [ 1146],
        [ 2173],
        [ 2292],
        [ 4063]], device='cuda:0')
[2024-07-24 10:21:51,787][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[27036],
        [26753],
        [12572],
        [24102],
        [ 5479],
        [15405],
        [13756],
        [10356],
        [ 7978],
        [ 9303],
        [ 6925],
        [ 6690],
        [ 7643],
        [ 7116],
        [ 8192]], device='cuda:0')
[2024-07-24 10:21:51,788][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[13115],
        [ 8516],
        [ 7165],
        [ 7293],
        [ 7092],
        [ 6529],
        [ 6688],
        [ 6424],
        [ 5894],
        [ 5939],
        [ 5801],
        [ 5603],
        [ 5713],
        [ 5705],
        [ 5629]], device='cuda:0')
[2024-07-24 10:21:51,790][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[22120],
        [39426],
        [32075],
        [27655],
        [25811],
        [28199],
        [22924],
        [28499],
        [24959],
        [33864],
        [27425],
        [24054],
        [24218],
        [21942],
        [14640]], device='cuda:0')
[2024-07-24 10:21:51,791][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[18971],
        [18009],
        [29667],
        [24024],
        [23390],
        [28298],
        [21458],
        [22000],
        [13778],
        [21454],
        [25247],
        [19944],
        [22501],
        [18443],
        [ 6505]], device='cuda:0')
[2024-07-24 10:21:51,792][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[20170],
        [11882],
        [  176],
        [ 1752],
        [ 1306],
        [ 1726],
        [ 6803],
        [ 9572],
        [ 9025],
        [15645],
        [ 2147],
        [ 1574],
        [ 2880],
        [ 1751],
        [ 2263]], device='cuda:0')
[2024-07-24 10:21:51,794][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 5329],
        [16838],
        [21352],
        [17230],
        [14847],
        [15305],
        [15094],
        [16915],
        [19298],
        [19092],
        [17911],
        [17310],
        [19051],
        [30371],
        [27343]], device='cuda:0')
[2024-07-24 10:21:51,795][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 9653],
        [10095],
        [ 6280],
        [ 8000],
        [ 7576],
        [ 5251],
        [ 5723],
        [ 6831],
        [ 6637],
        [ 7765],
        [ 6436],
        [ 5605],
        [ 5343],
        [ 8741],
        [ 8616]], device='cuda:0')
[2024-07-24 10:21:51,797][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[24073],
        [24267],
        [26780],
        [25010],
        [33720],
        [27483],
        [25593],
        [26992],
        [30724],
        [25331],
        [31312],
        [34855],
        [31252],
        [27088],
        [28567]], device='cuda:0')
[2024-07-24 10:21:51,798][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 1249],
        [ 2173],
        [12063],
        [14804],
        [10488],
        [10183],
        [21158],
        [24754],
        [28684],
        [27399],
        [27370],
        [28150],
        [31644],
        [38285],
        [38250]], device='cuda:0')
[2024-07-24 10:21:51,799][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[48147],
        [48210],
        [48489],
        [48413],
        [48144],
        [48358],
        [48317],
        [48300],
        [48229],
        [48281],
        [46919],
        [45663],
        [47827],
        [47319],
        [47463]], device='cuda:0')
[2024-07-24 10:21:51,801][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[33503],
        [14014],
        [12727],
        [ 7534],
        [ 7867],
        [12058],
        [ 8209],
        [ 6790],
        [ 8097],
        [ 9172],
        [10383],
        [11209],
        [10452],
        [15921],
        [12835]], device='cuda:0')
[2024-07-24 10:21:51,802][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[44165],
        [40907],
        [35709],
        [34082],
        [30680],
        [40045],
        [37030],
        [39940],
        [28647],
        [31517],
        [21225],
        [15545],
        [28123],
        [28961],
        [27240]], device='cuda:0')
[2024-07-24 10:21:51,804][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[39508],
        [21183],
        [20405],
        [14317],
        [12432],
        [14294],
        [15424],
        [15715],
        [16784],
        [16432],
        [17034],
        [16201],
        [16510],
        [16320],
        [16053]], device='cuda:0')
[2024-07-24 10:21:51,805][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[13788],
        [18061],
        [17416],
        [18046],
        [20000],
        [24037],
        [21010],
        [21032],
        [26620],
        [25708],
        [25524],
        [26597],
        [26435],
        [27909],
        [27687]], device='cuda:0')
[2024-07-24 10:21:51,807][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 6717],
        [ 8765],
        [24925],
        [12365],
        [11980],
        [17504],
        [ 8051],
        [ 9794],
        [ 9561],
        [ 9542],
        [17243],
        [15757],
        [11290],
        [19483],
        [16142]], device='cuda:0')
[2024-07-24 10:21:51,808][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[36254],
        [39528],
        [36147],
        [38035],
        [38443],
        [36197],
        [37588],
        [33741],
        [33613],
        [31571],
        [34155],
        [36335],
        [34295],
        [30043],
        [34399]], device='cuda:0')
[2024-07-24 10:21:51,809][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[31170],
        [20687],
        [29199],
        [36334],
        [37661],
        [33814],
        [31548],
        [28544],
        [32416],
        [23477],
        [28385],
        [32963],
        [29015],
        [26144],
        [32882]], device='cuda:0')
[2024-07-24 10:21:51,811][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[42309],
        [42309],
        [42309],
        [42309],
        [42309],
        [42309],
        [42309],
        [42309],
        [42309],
        [42309],
        [42309],
        [42309],
        [42309],
        [42309],
        [42309]], device='cuda:0')
[2024-07-24 10:21:51,846][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:51,846][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,847][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,848][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,850][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,851][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,851][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,852][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,853][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,853][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,854][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,854][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,855][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:51,856][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4099, 0.5901], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,856][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9515, 0.0485], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,860][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0025, 0.9975], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,864][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9593, 0.0407], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,868][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9464, 0.0536], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,872][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.6752, 0.3248], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,875][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3587, 0.6413], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,875][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0387, 0.9613], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,876][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4733, 0.5267], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,877][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.5332, 0.4668], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,878][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([3.4749e-07, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,879][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2400, 0.7600], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:51,882][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.2081, 0.4182, 0.3737], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,886][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.9141, 0.0631, 0.0227], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,888][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([6.3675e-04, 6.6553e-01, 3.3383e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,893][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.5209, 0.0194, 0.4597], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,896][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.7076, 0.0083, 0.2842], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,900][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.4097, 0.2268, 0.3635], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,902][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.1260, 0.4708, 0.4031], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,903][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.0143, 0.4898, 0.4959], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,903][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.3546, 0.3621, 0.2834], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,904][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.1188, 0.0257, 0.8555], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,905][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([5.0270e-07, 7.2533e-01, 2.7467e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,908][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.1262, 0.4872, 0.3867], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:51,911][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1288, 0.2650, 0.4247, 0.1815], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,915][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.7245, 0.0643, 0.0319, 0.1793], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,919][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0012, 0.3418, 0.1873, 0.4697], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,922][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.6182, 0.0024, 0.1845, 0.1949], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,927][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.6366, 0.0007, 0.1028, 0.2599], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,929][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.4752, 0.1135, 0.3259, 0.0854], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,930][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2209, 0.2649, 0.2493, 0.2649], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,930][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0042, 0.1564, 0.1682, 0.6712], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,931][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2182, 0.2918, 0.2475, 0.2425], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,932][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2013, 0.0010, 0.3345, 0.4632], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,933][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([2.5630e-07, 1.3810e-01, 1.1465e-01, 7.4725e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,936][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0748, 0.3324, 0.3386, 0.2542], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:51,940][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.0408, 0.2656, 0.2814, 0.2498, 0.1623], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,944][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.7014, 0.0796, 0.0225, 0.1677, 0.0288], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,946][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([2.6229e-04, 3.0390e-01, 1.5566e-01, 4.2413e-01, 1.1604e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,950][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.2930, 0.0064, 0.1483, 0.2506, 0.3016], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,954][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.0957, 0.0032, 0.1052, 0.6363, 0.1596], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,956][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.2767, 0.1354, 0.2459, 0.1135, 0.2285], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,957][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.1000, 0.2587, 0.2150, 0.2626, 0.1636], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,957][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.0031, 0.1364, 0.1441, 0.6685, 0.0479], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,958][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.1078, 0.2451, 0.2165, 0.2169, 0.2137], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,960][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0381, 0.0023, 0.1053, 0.5815, 0.2728], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,962][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([3.2467e-07, 1.1334e-01, 5.9626e-02, 8.1203e-01, 1.5003e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,967][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.0674, 0.2649, 0.2369, 0.2106, 0.2202], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:51,971][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0704, 0.2419, 0.2310, 0.2091, 0.1593, 0.0883], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,974][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.6835, 0.0615, 0.0161, 0.1308, 0.0181, 0.0899], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,976][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ went] are: tensor([3.4853e-04, 2.5178e-01, 1.3369e-01, 3.5553e-01, 9.6294e-02, 1.6236e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,978][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ went] are: tensor([2.6165e-01, 4.6076e-04, 2.7736e-02, 3.4519e-02, 6.9729e-02, 6.0591e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,982][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.4781, 0.0005, 0.0414, 0.1235, 0.0549, 0.3016], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,983][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.1998, 0.1067, 0.2116, 0.0910, 0.2015, 0.1893], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,984][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.1686, 0.1694, 0.1656, 0.1658, 0.1311, 0.1996], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,985][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0043, 0.1227, 0.1305, 0.5554, 0.0470, 0.1402], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,985][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.1709, 0.1914, 0.1559, 0.1746, 0.1616, 0.1456], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,987][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ went] are: tensor([3.4505e-02, 9.1605e-05, 1.9057e-02, 3.7126e-02, 6.2503e-02, 8.4672e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,989][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ went] are: tensor([3.7733e-08, 8.2855e-02, 4.2109e-02, 6.2305e-01, 1.6764e-02, 2.3522e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,992][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0800, 0.1990, 0.1714, 0.1978, 0.1871, 0.1646], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:51,996][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0669, 0.1526, 0.2045, 0.1331, 0.1448, 0.1153, 0.1828],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,000][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.6707, 0.0429, 0.0188, 0.0929, 0.0213, 0.0814, 0.0721],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,003][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0005, 0.2079, 0.1117, 0.2676, 0.0809, 0.1302, 0.2012],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,006][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([5.8204e-01, 5.7776e-05, 5.5521e-03, 4.5205e-03, 1.6664e-02, 7.5093e-02,
        3.1607e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,008][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([6.4861e-01, 2.4692e-05, 4.4226e-03, 5.7768e-03, 7.0923e-03, 1.4682e-02,
        3.1940e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,010][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2513, 0.0700, 0.1804, 0.0543, 0.1657, 0.1589, 0.1193],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,011][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2705, 0.1222, 0.1157, 0.1108, 0.0970, 0.1431, 0.1408],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,011][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0024, 0.0910, 0.1003, 0.3867, 0.0467, 0.1218, 0.2510],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,012][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1805, 0.1531, 0.1381, 0.1373, 0.1402, 0.1266, 0.1242],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,013][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([4.1587e-02, 3.7689e-05, 8.4268e-03, 9.3023e-03, 4.2075e-02, 2.8501e-01,
        6.1356e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,016][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([2.2906e-08, 3.7109e-02, 2.2553e-02, 2.8107e-01, 8.0559e-03, 1.7560e-01,
        4.7561e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,019][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0611, 0.1665, 0.1721, 0.1498, 0.1535, 0.1604, 0.1367],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,023][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0323, 0.1380, 0.1385, 0.0962, 0.0965, 0.1007, 0.2105, 0.1873],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,027][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.8970, 0.0097, 0.0039, 0.0280, 0.0040, 0.0189, 0.0208, 0.0177],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,030][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0005, 0.1803, 0.0988, 0.2241, 0.0739, 0.1164, 0.1792, 0.1267],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,032][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ the] are: tensor([5.2169e-01, 2.2433e-05, 2.3818e-03, 1.3269e-03, 7.1038e-03, 2.0272e-02,
        8.0181e-02, 3.6702e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,035][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ the] are: tensor([6.4885e-01, 1.6138e-05, 1.9599e-03, 1.9800e-03, 3.0471e-03, 5.0471e-03,
        1.0403e-01, 2.3507e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,037][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.2215, 0.0631, 0.1536, 0.0487, 0.1456, 0.1336, 0.0993, 0.1347],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,037][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.4163, 0.0750, 0.0701, 0.0727, 0.0715, 0.0982, 0.1088, 0.0874],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,038][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0020, 0.0734, 0.0831, 0.3491, 0.0395, 0.1053, 0.2162, 0.1314],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,039][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1328, 0.1462, 0.1213, 0.1289, 0.1300, 0.1167, 0.1217, 0.1023],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,040][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ the] are: tensor([6.1098e-02, 3.4919e-05, 4.0267e-03, 2.8692e-03, 1.0698e-02, 4.4904e-02,
        1.0582e-01, 7.7055e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,041][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ the] are: tensor([1.1681e-08, 9.6290e-03, 5.9254e-03, 6.5828e-02, 2.2581e-03, 2.7988e-02,
        1.5088e-01, 7.3749e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,044][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0469, 0.1532, 0.1427, 0.1407, 0.1374, 0.1376, 0.1383, 0.1033],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,048][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ house] are: tensor([0.0255, 0.1147, 0.1067, 0.1110, 0.0640, 0.0641, 0.1859, 0.2561, 0.0720],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,052][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ house] are: tensor([0.9573, 0.0044, 0.0012, 0.0124, 0.0016, 0.0069, 0.0068, 0.0059, 0.0037],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,055][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.0002, 0.1708, 0.0848, 0.2180, 0.0630, 0.1070, 0.1699, 0.1095, 0.0768],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,058][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ house] are: tensor([5.7934e-02, 1.0426e-05, 1.3394e-03, 1.1628e-03, 4.4565e-03, 2.5770e-02,
        1.2595e-01, 6.6993e-01, 1.1345e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,060][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ house] are: tensor([5.0631e-02, 3.5892e-05, 3.6219e-03, 5.0758e-03, 3.9468e-03, 1.7355e-02,
        3.7640e-01, 5.3543e-01, 7.5107e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,064][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ house] are: tensor([0.1719, 0.0633, 0.1357, 0.0446, 0.1217, 0.1162, 0.0908, 0.1216, 0.1341],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,065][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ house] are: tensor([0.2854, 0.0951, 0.0845, 0.0813, 0.0753, 0.1021, 0.1178, 0.0851, 0.0735],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,065][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ house] are: tensor([0.0025, 0.0761, 0.0731, 0.3195, 0.0318, 0.0887, 0.2002, 0.1148, 0.0932],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,066][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.0977, 0.1350, 0.1062, 0.1201, 0.1055, 0.1079, 0.1133, 0.0989, 0.1155],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,068][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ house] are: tensor([3.2079e-03, 3.7785e-06, 1.3675e-03, 1.4319e-03, 3.8212e-03, 4.2211e-02,
        1.2059e-01, 7.0677e-01, 1.2060e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,070][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ house] are: tensor([4.4147e-09, 2.7815e-03, 2.8501e-03, 2.5045e-02, 1.6466e-03, 1.5423e-02,
        9.5311e-02, 5.4174e-01, 3.1520e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,074][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ house] are: tensor([0.0406, 0.1444, 0.1294, 0.1221, 0.1205, 0.1270, 0.1195, 0.1055, 0.0912],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,077][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0258, 0.0661, 0.0969, 0.0575, 0.0603, 0.0391, 0.1188, 0.1563, 0.0469,
        0.3322], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,081][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.8742, 0.0102, 0.0040, 0.0293, 0.0049, 0.0174, 0.0173, 0.0148, 0.0110,
        0.0169], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,086][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0005, 0.1446, 0.0806, 0.1810, 0.0595, 0.0917, 0.1419, 0.0971, 0.0647,
        0.1383], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,088][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [.] are: tensor([4.6649e-01, 3.8300e-06, 5.4440e-04, 3.4656e-04, 2.2271e-03, 5.4752e-03,
        2.2012e-02, 1.2976e-01, 1.4740e-02, 3.5839e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,090][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [.] are: tensor([6.3832e-01, 7.1224e-06, 1.1033e-03, 1.1559e-03, 2.1387e-03, 3.3171e-03,
        5.7312e-02, 1.7284e-01, 1.9759e-03, 1.2182e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,091][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.2001, 0.0509, 0.1175, 0.0359, 0.1092, 0.1012, 0.0743, 0.1045, 0.1122,
        0.0942], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,092][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.2518, 0.0776, 0.0856, 0.0715, 0.0781, 0.1009, 0.1003, 0.0883, 0.0622,
        0.0837], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,092][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0014, 0.0622, 0.0685, 0.2573, 0.0295, 0.0801, 0.1578, 0.1034, 0.0836,
        0.1561], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,095][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.1692, 0.1022, 0.0942, 0.0899, 0.0988, 0.0856, 0.0920, 0.0836, 0.0926,
        0.0919], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,097][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [.] are: tensor([1.1975e-01, 6.5867e-06, 1.5039e-03, 1.0218e-03, 8.1190e-03, 1.8109e-02,
        4.0614e-02, 3.4514e-01, 3.3649e-02, 4.3209e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,099][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [.] are: tensor([1.6608e-09, 2.6816e-03, 2.5115e-03, 1.9299e-02, 1.0242e-03, 9.0380e-03,
        4.3085e-02, 2.3456e-01, 1.6077e-01, 5.2704e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,103][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0369, 0.1194, 0.1220, 0.1014, 0.1118, 0.1209, 0.1056, 0.0935, 0.1008,
        0.0878], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,106][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.0338, 0.0748, 0.0589, 0.0662, 0.0404, 0.0388, 0.0904, 0.1100, 0.0453,
        0.3303, 0.1110], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,110][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.8468, 0.0177, 0.0060, 0.0388, 0.0074, 0.0198, 0.0175, 0.0132, 0.0123,
        0.0154, 0.0052], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,113][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([1.5155e-04, 1.3185e-01, 7.0697e-02, 1.8087e-01, 5.2729e-02, 8.4012e-02,
        1.3012e-01, 8.4078e-02, 5.7167e-02, 1.2809e-01, 8.0239e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,115][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([1.1372e-01, 9.0513e-06, 3.3551e-04, 3.0167e-04, 1.2444e-03, 2.9843e-03,
        9.3178e-03, 4.3049e-02, 5.3058e-03, 1.5321e-01, 6.7052e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,117][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([4.1080e-01, 2.4161e-05, 1.1238e-03, 1.2326e-03, 1.8189e-03, 2.7419e-03,
        4.7828e-02, 8.4721e-02, 1.4712e-03, 7.9125e-02, 3.6912e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,118][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.1762, 0.0540, 0.0911, 0.0357, 0.0868, 0.0761, 0.0625, 0.0790, 0.0840,
        0.0734, 0.1814], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,119][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.1424, 0.0977, 0.0898, 0.0811, 0.0734, 0.0958, 0.0978, 0.0805, 0.0650,
        0.0853, 0.0912], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,120][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.0019, 0.0717, 0.0669, 0.2937, 0.0248, 0.0672, 0.1562, 0.0805, 0.0581,
        0.1443, 0.0345], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,123][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.1109, 0.1063, 0.0859, 0.0945, 0.0911, 0.0823, 0.0829, 0.0746, 0.0922,
        0.0929, 0.0863], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,126][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([2.8717e-02, 9.0527e-06, 4.2842e-04, 4.7773e-04, 1.8648e-03, 5.7511e-03,
        2.3897e-02, 9.9888e-02, 1.1473e-02, 2.4176e-01, 5.8574e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,128][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([2.8949e-09, 1.6615e-03, 8.3201e-04, 9.5668e-03, 5.6740e-04, 5.6380e-03,
        3.1984e-02, 2.1072e-01, 1.2125e-01, 4.3528e-01, 1.8250e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,132][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.0317, 0.1208, 0.0983, 0.0949, 0.0961, 0.1105, 0.1077, 0.0835, 0.0795,
        0.0931, 0.0840], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,136][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0194, 0.0588, 0.0554, 0.0543, 0.0396, 0.0241, 0.0801, 0.0958, 0.0415,
        0.2978, 0.1378, 0.0954], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,141][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.7121, 0.0255, 0.0069, 0.0531, 0.0084, 0.0369, 0.0378, 0.0316, 0.0208,
        0.0303, 0.0078, 0.0288], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,143][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0003, 0.1114, 0.0640, 0.1578, 0.0472, 0.0753, 0.1161, 0.0760, 0.0512,
        0.1138, 0.0698, 0.1170], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,144][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([1.6207e-02, 4.3827e-07, 6.3259e-05, 3.1959e-05, 1.9081e-04, 5.3249e-04,
        3.2169e-03, 1.8697e-02, 2.0084e-03, 6.3058e-02, 7.2611e-01, 1.6988e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,145][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([2.7128e-01, 4.4393e-06, 6.9706e-04, 4.7804e-04, 8.7499e-04, 1.4416e-03,
        3.3634e-02, 8.0627e-02, 8.2188e-04, 5.7722e-02, 4.6384e-01, 8.8583e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,146][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.1278, 0.0390, 0.0815, 0.0275, 0.0797, 0.0692, 0.0552, 0.0714, 0.0766,
        0.0660, 0.2033, 0.1027], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,148][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1345, 0.0794, 0.0761, 0.0727, 0.0617, 0.0882, 0.0959, 0.0816, 0.0598,
        0.0873, 0.0858, 0.0769], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,150][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0018, 0.0709, 0.0624, 0.2571, 0.0238, 0.0609, 0.1384, 0.0837, 0.0619,
        0.1408, 0.0354, 0.0628], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,154][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0994, 0.0978, 0.0807, 0.0878, 0.0838, 0.0715, 0.0811, 0.0702, 0.0854,
        0.0856, 0.0818, 0.0750], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,157][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([6.4883e-03, 8.2773e-07, 2.8200e-04, 6.2685e-05, 5.6301e-04, 2.1808e-03,
        6.2322e-03, 5.9034e-02, 5.3834e-03, 7.5374e-02, 7.0042e-01, 1.4398e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,159][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([2.3164e-09, 1.6602e-03, 8.6962e-04, 1.0375e-02, 3.7098e-04, 6.0500e-03,
        2.1340e-02, 1.6000e-01, 7.2672e-02, 3.6704e-01, 1.8732e-01, 1.7230e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,163][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0286, 0.1025, 0.0959, 0.0883, 0.0938, 0.0958, 0.0942, 0.0783, 0.0765,
        0.0805, 0.0849, 0.0807], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,168][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0163, 0.0574, 0.0603, 0.0422, 0.0350, 0.0287, 0.0808, 0.0724, 0.0297,
        0.2922, 0.1466, 0.1275, 0.0109], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,170][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.8351, 0.0106, 0.0034, 0.0263, 0.0036, 0.0166, 0.0194, 0.0162, 0.0117,
        0.0192, 0.0039, 0.0154, 0.0187], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,171][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0002, 0.1056, 0.0571, 0.1407, 0.0425, 0.0680, 0.1107, 0.0740, 0.0480,
        0.1075, 0.0641, 0.1099, 0.0717], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,172][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.4657e-01, 1.0166e-06, 1.0026e-04, 4.1427e-05, 3.1741e-04, 4.8056e-04,
        1.8616e-03, 1.1295e-02, 1.1079e-03, 2.7231e-02, 2.8442e-01, 6.0550e-02,
        4.6603e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,173][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([5.9836e-01, 1.8837e-06, 2.3723e-04, 1.0230e-04, 3.4564e-04, 2.8589e-04,
        4.3997e-03, 1.3194e-02, 1.5448e-04, 8.5690e-03, 1.0073e-01, 1.2236e-02,
        2.6139e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,175][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1634, 0.0284, 0.0716, 0.0191, 0.0694, 0.0600, 0.0416, 0.0591, 0.0634,
        0.0543, 0.1855, 0.0876, 0.0966], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,178][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3455, 0.0529, 0.0512, 0.0456, 0.0469, 0.0646, 0.0682, 0.0568, 0.0369,
        0.0585, 0.0655, 0.0557, 0.0516], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,181][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0011, 0.0475, 0.0487, 0.2201, 0.0217, 0.0645, 0.1385, 0.0822, 0.0651,
        0.1371, 0.0351, 0.0654, 0.0731], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,185][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1100, 0.0875, 0.0730, 0.0762, 0.0786, 0.0711, 0.0740, 0.0623, 0.0758,
        0.0798, 0.0767, 0.0735, 0.0614], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,188][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([2.9172e-02, 3.6057e-06, 4.1285e-04, 1.3358e-04, 1.0895e-03, 1.5553e-03,
        4.3128e-03, 3.7036e-02, 3.2897e-03, 4.0413e-02, 2.3823e-01, 6.8696e-02,
        5.7566e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,190][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.2750e-10, 6.0280e-04, 2.6458e-04, 3.4076e-03, 1.3442e-04, 1.5979e-03,
        1.0431e-02, 5.1416e-02, 4.0068e-02, 1.5887e-01, 4.5548e-02, 6.9276e-02,
        6.1838e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,195][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0244, 0.0989, 0.0883, 0.0887, 0.0875, 0.0936, 0.0862, 0.0726, 0.0733,
        0.0751, 0.0769, 0.0755, 0.0588], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,197][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0239, 0.0476, 0.0498, 0.0429, 0.0232, 0.0273, 0.0866, 0.0827, 0.0217,
        0.3067, 0.1189, 0.1261, 0.0173, 0.0252], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,198][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([9.8380e-01, 1.1822e-03, 3.4610e-04, 3.1991e-03, 4.6842e-04, 1.7971e-03,
        1.6563e-03, 1.5129e-03, 8.9092e-04, 1.4481e-03, 2.8716e-04, 1.2704e-03,
        1.4036e-03, 7.3962e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,198][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([1.0861e-04, 1.0123e-01, 5.1502e-02, 1.3855e-01, 3.8275e-02, 6.4449e-02,
        1.0565e-01, 6.6975e-02, 4.4382e-02, 1.0447e-01, 5.9988e-02, 1.0399e-01,
        6.4796e-02, 5.5632e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,199][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([5.1500e-02, 1.2222e-07, 1.7715e-05, 3.6997e-06, 5.0254e-05, 5.0462e-05,
        1.9696e-04, 1.2722e-03, 1.1524e-04, 2.4294e-03, 5.4552e-02, 7.8123e-03,
        5.8209e-02, 8.2379e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,201][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([2.6299e-01, 1.7928e-05, 1.2902e-03, 3.0200e-04, 1.0434e-03, 1.3513e-03,
        1.3102e-02, 2.6611e-02, 7.7497e-04, 1.2525e-02, 1.7264e-01, 3.8926e-02,
        4.0359e-01, 6.4844e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,204][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.1863, 0.0304, 0.0692, 0.0166, 0.0599, 0.0492, 0.0338, 0.0483, 0.0515,
        0.0445, 0.1504, 0.0697, 0.0753, 0.1149], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,208][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.2164, 0.0617, 0.0523, 0.0536, 0.0475, 0.0655, 0.0713, 0.0513, 0.0411,
        0.0628, 0.0649, 0.0560, 0.0509, 0.1048], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,212][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0015, 0.0541, 0.0488, 0.2384, 0.0206, 0.0582, 0.1376, 0.0779, 0.0596,
        0.1324, 0.0272, 0.0548, 0.0586, 0.0301], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,217][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.1052, 0.0847, 0.0644, 0.0780, 0.0674, 0.0633, 0.0698, 0.0593, 0.0722,
        0.0756, 0.0641, 0.0650, 0.0607, 0.0701], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,219][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([5.2623e-02, 1.5251e-06, 1.8387e-04, 2.7666e-05, 2.4572e-04, 3.1114e-04,
        7.7819e-04, 9.2151e-03, 6.4206e-04, 6.2018e-03, 9.3446e-02, 2.2175e-02,
        2.2207e-01, 5.9208e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,222][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([7.5195e-09, 2.7641e-04, 3.6526e-04, 2.6904e-03, 1.5671e-04, 1.1008e-03,
        7.0673e-03, 3.0689e-02, 1.9694e-02, 6.3566e-02, 6.5739e-02, 4.8468e-02,
        4.5992e-01, 3.0027e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,223][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.0246, 0.0866, 0.0833, 0.0748, 0.0829, 0.0891, 0.0834, 0.0708, 0.0650,
        0.0686, 0.0746, 0.0730, 0.0625, 0.0608], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,224][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0217, 0.0439, 0.0541, 0.0344, 0.0330, 0.0279, 0.0509, 0.0840, 0.0348,
        0.2417, 0.1684, 0.1255, 0.0173, 0.0400, 0.0223], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,225][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.8505, 0.0085, 0.0030, 0.0212, 0.0038, 0.0143, 0.0151, 0.0128, 0.0100,
        0.0140, 0.0033, 0.0126, 0.0135, 0.0074, 0.0098], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,227][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0002, 0.0921, 0.0488, 0.1257, 0.0365, 0.0603, 0.0969, 0.0666, 0.0434,
        0.0967, 0.0564, 0.0974, 0.0639, 0.0536, 0.0615], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,229][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([4.1619e-02, 6.0806e-08, 9.1455e-06, 2.8245e-06, 3.1026e-05, 3.5218e-05,
        1.4543e-04, 1.0642e-03, 8.1049e-05, 2.4182e-03, 4.3109e-02, 5.8968e-03,
        5.9795e-02, 7.1494e-01, 1.3085e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,232][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([3.2408e-01, 7.8054e-07, 9.8018e-05, 3.0252e-05, 1.4049e-04, 8.9322e-05,
        1.1781e-03, 4.4428e-03, 5.0947e-05, 3.2271e-03, 5.1991e-02, 5.0759e-03,
        1.1731e-01, 1.5743e-02, 4.7655e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,236][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1296, 0.0216, 0.0552, 0.0141, 0.0523, 0.0460, 0.0314, 0.0467, 0.0490,
        0.0420, 0.1563, 0.0706, 0.0803, 0.1337, 0.0712], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,241][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2272, 0.0532, 0.0529, 0.0445, 0.0477, 0.0609, 0.0601, 0.0502, 0.0346,
        0.0513, 0.0606, 0.0523, 0.0470, 0.0907, 0.0669], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,245][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0011, 0.0472, 0.0446, 0.2104, 0.0208, 0.0560, 0.1293, 0.0786, 0.0623,
        0.1280, 0.0300, 0.0572, 0.0619, 0.0325, 0.0401], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,249][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1127, 0.0724, 0.0655, 0.0652, 0.0678, 0.0604, 0.0594, 0.0566, 0.0651,
        0.0632, 0.0666, 0.0630, 0.0561, 0.0646, 0.0614], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,250][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.3425e-03, 6.1004e-07, 9.4899e-05, 1.8297e-05, 2.4992e-04, 3.4825e-04,
        7.6660e-04, 7.3559e-03, 5.1211e-04, 1.0301e-02, 7.6360e-02, 1.4251e-02,
        1.5686e-01, 4.5678e-01, 2.6676e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,251][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.7251e-10, 1.6832e-04, 1.0534e-04, 1.2835e-03, 5.1283e-05, 8.3331e-04,
        2.5745e-03, 1.9853e-02, 1.5343e-02, 5.2033e-02, 2.8609e-02, 4.3715e-02,
        3.7152e-01, 1.4285e-01, 3.2106e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,252][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0238, 0.0822, 0.0871, 0.0713, 0.0769, 0.0831, 0.0694, 0.0629, 0.0637,
        0.0597, 0.0749, 0.0716, 0.0593, 0.0577, 0.0564], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,326][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:52,327][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,328][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,328][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,329][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,330][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,330][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,331][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,332][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,332][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,333][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,334][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,334][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,335][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3607, 0.6393], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,336][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.8122, 0.1878], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,336][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([6.2749e-07, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,337][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9728, 0.0272], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,338][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5075, 0.4925], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,339][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9986, 0.0014], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,343][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9671, 0.0329], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,346][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1964, 0.8036], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,350][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8032, 0.1968], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,354][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2812, 0.7188], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,354][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([9.0545e-06, 9.9999e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,355][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2989, 0.7011], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,356][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.0195, 0.0220, 0.9585], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,357][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.0658, 0.2806, 0.6536], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,358][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([6.7002e-08, 9.9011e-01, 9.8872e-03], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,361][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.3295, 0.0194, 0.6511], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,361][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.0736, 0.0317, 0.8947], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,362][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.9060, 0.0113, 0.0827], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,363][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.6482, 0.1170, 0.2347], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,365][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.0090, 0.4661, 0.5248], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,368][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.0856, 0.0180, 0.8964], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,372][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.0693, 0.1085, 0.8222], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,374][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([9.1155e-07, 8.8534e-01, 1.1466e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,378][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.0280, 0.7353, 0.2367], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,381][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([1.0200e-02, 2.6591e-04, 2.1916e-01, 7.7037e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,383][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2151, 0.0753, 0.5629, 0.1468], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,384][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.8304e-07, 4.0078e-01, 6.3627e-03, 5.9286e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,385][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3483, 0.0015, 0.3883, 0.2619], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,386][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0300, 0.0011, 0.2154, 0.7535], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,386][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([9.4976e-01, 5.6902e-04, 4.3954e-02, 5.7204e-03], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,388][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.8167, 0.0160, 0.1014, 0.0659], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,391][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0140, 0.0681, 0.2582, 0.6598], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,395][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0703, 0.0012, 0.2719, 0.6566], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,399][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0294, 0.0029, 0.1866, 0.7811], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,401][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([8.7982e-06, 1.9622e-01, 8.5906e-02, 7.1786e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,404][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0756, 0.2354, 0.2028, 0.4862], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,408][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.0014, 0.0010, 0.0879, 0.8146, 0.0951], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,410][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0340, 0.2673, 0.2408, 0.2855, 0.1723], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,411][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([5.0222e-08, 3.9058e-01, 5.7284e-03, 5.9967e-01, 4.0196e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,412][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.1112, 0.0069, 0.2498, 0.3949, 0.2373], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,413][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.0041, 0.0042, 0.0880, 0.7885, 0.1152], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,415][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.6526, 0.0110, 0.1252, 0.0590, 0.1522], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,417][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.3087, 0.0821, 0.1736, 0.2116, 0.2240], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,421][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.0029, 0.1680, 0.1363, 0.6312, 0.0616], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,425][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.0126, 0.0028, 0.1538, 0.6462, 0.1846], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,428][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.0065, 0.0070, 0.0729, 0.8107, 0.1029], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,431][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([8.5373e-07, 2.3833e-01, 2.3310e-02, 7.3177e-01, 6.5946e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,435][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.0133, 0.2506, 0.1037, 0.4719, 0.1605], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,437][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([6.6918e-03, 2.9253e-05, 2.5254e-02, 7.1536e-02, 4.0400e-02, 8.5609e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,437][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0390, 0.1655, 0.2123, 0.1688, 0.1245, 0.2900], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,438][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([7.5458e-08, 3.4462e-01, 3.3411e-03, 5.0924e-01, 2.7785e-03, 1.4002e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,439][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([1.2963e-01, 5.6570e-04, 8.6693e-02, 6.1570e-02, 6.6619e-02, 6.5493e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,440][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([1.7987e-02, 3.1851e-04, 4.0069e-02, 1.6426e-01, 6.0000e-02, 7.1736e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,441][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([8.7638e-01, 6.3327e-04, 3.4408e-02, 7.8329e-03, 5.7969e-02, 2.2775e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,444][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.5629, 0.0215, 0.0956, 0.0779, 0.1700, 0.0722], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,448][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0074, 0.0567, 0.1392, 0.4047, 0.0695, 0.3225], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,450][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([1.7631e-02, 1.2862e-04, 3.8964e-02, 9.7688e-02, 7.3493e-02, 7.7210e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,452][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([7.3403e-03, 5.3134e-04, 2.6549e-02, 1.1535e-01, 4.0729e-02, 8.0950e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,455][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([2.1153e-06, 1.3636e-01, 3.3243e-02, 6.4725e-01, 9.8301e-03, 1.7332e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,458][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0287, 0.1440, 0.0987, 0.3778, 0.1724, 0.1784], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,460][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.2674e-02, 3.7665e-06, 6.6202e-03, 7.1402e-03, 1.0345e-02, 9.6182e-02,
        8.6704e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,464][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.2353, 0.0367, 0.1885, 0.0712, 0.1621, 0.2148, 0.0914],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,465][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.0450e-08, 4.2014e-02, 8.0926e-04, 7.6527e-02, 4.6814e-04, 2.4865e-02,
        8.5532e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,466][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([4.1218e-01, 8.2163e-05, 2.7125e-02, 1.0624e-02, 2.3152e-02, 1.1659e-01,
        4.1025e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,466][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([5.9249e-02, 4.1681e-05, 1.6137e-02, 2.2845e-02, 2.6705e-02, 1.0407e-01,
        7.7095e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,468][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.6725e-01, 6.5354e-05, 9.7110e-03, 8.9783e-04, 1.5198e-02, 3.8530e-03,
        3.0215e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,471][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.7863, 0.0046, 0.0374, 0.0211, 0.0824, 0.0207, 0.0476],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,475][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0322, 0.0213, 0.1107, 0.2204, 0.0742, 0.1683, 0.3730],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,477][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.2221e-01, 2.9844e-05, 2.1242e-02, 1.3457e-02, 4.2041e-02, 1.7501e-01,
        6.2601e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,480][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.7513e-02, 9.0738e-05, 7.2815e-03, 1.4062e-02, 1.2920e-02, 1.2312e-01,
        8.2501e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,482][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.6173e-06, 5.2853e-02, 1.7574e-02, 2.0628e-01, 6.1004e-03, 1.4250e-01,
        5.7469e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,486][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0832, 0.0731, 0.0783, 0.1813, 0.1495, 0.1163, 0.3183],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,488][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([1.3560e-02, 4.8191e-06, 3.1552e-03, 2.1250e-03, 3.3590e-03, 2.3580e-02,
        1.7791e-01, 7.7631e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,491][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1967, 0.0356, 0.1730, 0.0803, 0.1235, 0.1518, 0.1007, 0.1383],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,492][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([2.3989e-07, 5.5801e-02, 1.6078e-03, 8.0002e-02, 1.0216e-03, 2.3913e-02,
        7.9329e-01, 4.4360e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,492][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([3.5788e-01, 4.8776e-05, 1.4287e-02, 3.5216e-03, 1.1904e-02, 3.3654e-02,
        1.0106e-01, 4.7764e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,493][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([4.2285e-02, 4.7470e-05, 7.7047e-03, 8.5652e-03, 1.1371e-02, 3.5570e-02,
        2.0020e-01, 6.9426e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,494][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([9.6360e-01, 7.8455e-05, 9.0525e-03, 9.6438e-04, 1.5399e-02, 3.5078e-03,
        2.7521e-03, 4.6419e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,496][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.7586, 0.0078, 0.0331, 0.0239, 0.0675, 0.0190, 0.0488, 0.0413],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,500][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0484, 0.0131, 0.1042, 0.1388, 0.0779, 0.1152, 0.2837, 0.2188],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,502][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([1.7083e-01, 2.6884e-05, 1.0878e-02, 4.9265e-03, 1.6024e-02, 3.7669e-02,
        1.2374e-01, 6.3590e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,504][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([1.8878e-02, 9.7048e-05, 4.4830e-03, 5.0179e-03, 5.8073e-03, 2.9950e-02,
        1.8305e-01, 7.5271e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,507][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([4.7688e-06, 6.8110e-02, 1.9562e-02, 2.0553e-01, 7.2306e-03, 7.3702e-02,
        5.0969e-01, 1.1617e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,510][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0474, 0.0666, 0.0714, 0.1558, 0.1179, 0.0976, 0.2253, 0.2180],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:52,512][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([1.0905e-04, 3.7372e-07, 4.5710e-04, 6.2945e-04, 4.2185e-04, 1.3896e-02,
        2.1945e-01, 7.0732e-01, 5.7717e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,516][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([0.0857, 0.0433, 0.1271, 0.0813, 0.1248, 0.2230, 0.0970, 0.1141, 0.1037],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,518][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([1.0656e-08, 1.9698e-02, 4.0079e-04, 4.3528e-02, 5.0284e-04, 1.7641e-02,
        6.0292e-01, 1.7246e-02, 2.9807e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,519][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([2.1138e-02, 1.6550e-05, 5.7615e-03, 2.8386e-03, 4.5523e-03, 3.8439e-02,
        1.5283e-01, 6.8682e-01, 8.7603e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,520][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([1.3125e-03, 7.2530e-06, 2.1982e-03, 4.4311e-03, 2.6089e-03, 2.3825e-02,
        2.3855e-01, 6.3639e-01, 9.0681e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,521][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([9.1660e-01, 1.6829e-04, 1.6584e-02, 2.6537e-03, 2.6297e-02, 8.0738e-03,
        1.0327e-02, 1.3294e-02, 6.0071e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,524][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([0.6465, 0.0079, 0.0367, 0.0307, 0.0798, 0.0259, 0.0720, 0.0531, 0.0475],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,527][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([0.0051, 0.0094, 0.0377, 0.1159, 0.0271, 0.0965, 0.2881, 0.1174, 0.3027],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,529][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([2.4898e-03, 4.2826e-06, 1.9667e-03, 2.8563e-03, 3.5778e-03, 3.0750e-02,
        2.0021e-01, 6.5062e-01, 1.0753e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,532][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([4.9573e-04, 1.0493e-05, 9.2242e-04, 2.3666e-03, 1.2614e-03, 2.2136e-02,
        2.0064e-01, 6.6918e-01, 1.0298e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,534][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([7.3978e-07, 1.7110e-02, 7.4210e-03, 1.0129e-01, 3.6098e-03, 4.1718e-02,
        3.1495e-01, 5.9077e-02, 4.5482e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,538][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([0.0180, 0.0605, 0.0470, 0.1235, 0.0825, 0.0656, 0.2824, 0.1997, 0.1208],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:52,540][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([7.8480e-03, 1.2782e-07, 2.7756e-04, 1.8477e-04, 6.5870e-04, 3.3399e-03,
        3.1868e-02, 2.4872e-01, 9.5653e-03, 6.9754e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,545][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.2161, 0.0211, 0.1188, 0.0664, 0.1124, 0.1444, 0.0653, 0.0773, 0.0953,
        0.0828], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,547][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([4.2993e-08, 2.6756e-02, 8.8686e-04, 6.0108e-02, 5.5657e-04, 1.5446e-02,
        4.7285e-01, 1.9299e-02, 1.4216e-01, 2.6194e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,548][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([3.1277e-01, 6.4503e-06, 3.2688e-03, 9.4204e-04, 3.6457e-03, 1.0088e-02,
        3.2833e-02, 2.1658e-01, 1.6569e-02, 4.0329e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,548][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([3.3016e-02, 3.1507e-06, 1.6355e-03, 1.6911e-03, 3.5986e-03, 8.3841e-03,
        5.4274e-02, 3.1796e-01, 2.1479e-02, 5.5795e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,549][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([9.9060e-01, 1.3107e-05, 2.0913e-03, 1.7006e-04, 3.5592e-03, 7.6761e-04,
        5.4471e-04, 1.3925e-03, 3.8603e-04, 4.7959e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,551][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.8047, 0.0033, 0.0180, 0.0124, 0.0494, 0.0108, 0.0270, 0.0245, 0.0198,
        0.0301], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,554][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0199, 0.0093, 0.0479, 0.1064, 0.0397, 0.0801, 0.1978, 0.1275, 0.1642,
        0.2072], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,556][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([1.1580e-01, 2.0075e-06, 2.1475e-03, 9.8130e-04, 5.4654e-03, 1.1978e-02,
        4.5065e-02, 3.5167e-01, 1.7836e-02, 4.4906e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,559][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([1.6304e-02, 6.3580e-06, 7.5619e-04, 9.3034e-04, 1.8404e-03, 6.7240e-03,
        4.4923e-02, 2.7741e-01, 1.8652e-02, 6.3245e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,561][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([1.1185e-06, 2.2459e-02, 1.0733e-02, 9.8103e-02, 3.9998e-03, 3.8141e-02,
        2.4241e-01, 4.7884e-02, 2.4537e-01, 2.9090e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,565][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0546, 0.0372, 0.0556, 0.1051, 0.1128, 0.0649, 0.1407, 0.1485, 0.0767,
        0.2040], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:52,567][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([1.3973e-03, 6.5696e-07, 1.2594e-04, 9.8217e-05, 1.5273e-04, 7.3057e-04,
        8.5471e-03, 3.4939e-02, 1.4125e-03, 1.5225e-01, 8.0034e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,572][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.0127, 0.0733, 0.0966, 0.0786, 0.0496, 0.1022, 0.1001, 0.0696, 0.1137,
        0.1232, 0.1803], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,574][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([2.8760e-09, 2.1985e-02, 3.1784e-04, 2.5345e-02, 2.1427e-04, 1.0408e-02,
        4.2799e-01, 1.4668e-02, 1.7064e-01, 3.2417e-01, 4.2644e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,575][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([5.3563e-02, 1.9248e-05, 1.5465e-03, 6.4193e-04, 1.7203e-03, 4.4159e-03,
        1.2310e-02, 5.5103e-02, 5.1263e-03, 1.3572e-01, 7.2984e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,576][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([1.0281e-02, 1.1957e-05, 7.4713e-04, 1.0185e-03, 9.5676e-04, 2.1119e-03,
        1.9559e-02, 6.9448e-02, 5.0130e-03, 1.9043e-01, 7.0043e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,576][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([8.7083e-01, 4.9846e-04, 8.1043e-03, 2.3200e-03, 1.3817e-02, 4.5832e-03,
        5.7109e-03, 9.2906e-03, 3.0609e-03, 6.2489e-03, 7.5541e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,578][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.3915, 0.0172, 0.0417, 0.0369, 0.0833, 0.0364, 0.0651, 0.0502, 0.0568,
        0.0665, 0.1545], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,581][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.0016, 0.0241, 0.0299, 0.0977, 0.0164, 0.0706, 0.1866, 0.0674, 0.2081,
        0.1703, 0.1274], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,583][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([1.2690e-02, 3.4802e-06, 6.5637e-04, 2.9597e-04, 9.5015e-04, 1.4019e-03,
        7.3902e-03, 3.3953e-02, 2.7081e-03, 7.9491e-02, 8.6046e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,586][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([1.0081e-02, 2.7748e-05, 7.1104e-04, 1.0847e-03, 1.1646e-03, 4.6825e-03,
        2.9748e-02, 1.1298e-01, 1.1983e-02, 3.1862e-01, 5.0891e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,588][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([3.9966e-08, 2.1675e-02, 2.6722e-03, 5.6149e-02, 1.0974e-03, 2.0900e-02,
        1.6427e-01, 3.6554e-02, 2.5579e-01, 4.0544e-01, 3.5444e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,592][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.0044, 0.0611, 0.0234, 0.0851, 0.0364, 0.0473, 0.1905, 0.1037, 0.1116,
        0.2650, 0.0714], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:52,595][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([1.1744e-04, 1.2992e-08, 2.0278e-05, 6.9270e-06, 1.8764e-05, 1.2342e-04,
        1.9516e-03, 7.8386e-03, 3.2851e-04, 5.1957e-02, 8.6985e-01, 6.7791e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,599][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0232, 0.0372, 0.0757, 0.0391, 0.0495, 0.0966, 0.0668, 0.0794, 0.0637,
        0.0809, 0.1762, 0.2118], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,601][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([2.2674e-09, 2.0600e-02, 1.6904e-04, 2.9721e-02, 1.3124e-04, 1.0285e-02,
        3.8043e-01, 1.2501e-02, 1.1946e-01, 4.0485e-01, 2.9928e-03, 1.8860e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,602][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([6.7053e-03, 1.3203e-06, 4.7699e-04, 8.9037e-05, 2.8861e-04, 9.9480e-04,
        4.2917e-03, 2.3998e-02, 1.9573e-03, 5.5352e-02, 7.3294e-01, 1.7291e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,603][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([1.7789e-03, 5.7831e-07, 2.0426e-04, 1.5224e-04, 2.6009e-04, 8.2319e-04,
        5.9686e-03, 3.0191e-02, 2.3804e-03, 6.8957e-02, 7.2866e-01, 1.6063e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,603][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([7.9188e-01, 8.0350e-05, 7.8089e-03, 8.5300e-04, 1.4574e-02, 2.8195e-03,
        3.1745e-03, 5.4141e-03, 1.9769e-03, 3.1522e-03, 1.5798e-01, 1.0284e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,606][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.3703, 0.0069, 0.0324, 0.0239, 0.0683, 0.0239, 0.0524, 0.0461, 0.0419,
        0.0575, 0.1934, 0.0830], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,608][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0031, 0.0089, 0.0283, 0.0633, 0.0157, 0.0527, 0.1682, 0.0906, 0.1283,
        0.1835, 0.1491, 0.1082], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,611][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([1.3587e-03, 2.2292e-07, 1.5006e-04, 5.5960e-05, 1.6065e-04, 4.6055e-04,
        2.7580e-03, 1.4971e-02, 1.1862e-03, 3.1462e-02, 8.2956e-01, 1.1787e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,613][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([8.5075e-04, 2.4906e-06, 2.2845e-04, 1.6293e-04, 2.1571e-04, 1.5736e-03,
        1.0771e-02, 6.3409e-02, 4.9765e-03, 1.6836e-01, 5.7215e-01, 1.7731e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,615][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([1.0662e-07, 1.1085e-02, 2.4203e-03, 5.0848e-02, 8.9951e-04, 2.2979e-02,
        1.4879e-01, 4.3935e-02, 2.0318e-01, 4.1793e-01, 4.3050e-02, 5.4888e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,619][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0039, 0.0361, 0.0205, 0.0830, 0.0326, 0.0477, 0.1478, 0.1130, 0.0841,
        0.2867, 0.0650, 0.0797], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:52,622][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([5.1532e-03, 1.5607e-07, 9.1831e-05, 2.3255e-05, 8.7085e-05, 1.8726e-04,
        1.6110e-03, 1.0306e-02, 3.4495e-04, 2.5246e-02, 4.5998e-01, 3.2448e-02,
        4.6452e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,626][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0757, 0.0223, 0.0683, 0.0416, 0.0502, 0.0705, 0.0523, 0.0714, 0.0512,
        0.0641, 0.1300, 0.1677, 0.1348], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,628][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([4.3379e-08, 2.4193e-02, 5.9475e-04, 3.8775e-02, 4.5014e-04, 1.2124e-02,
        4.8417e-01, 1.8956e-02, 1.2738e-01, 2.5783e-01, 5.9724e-03, 2.1994e-02,
        7.5551e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,629][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([7.9847e-02, 3.8333e-06, 9.3054e-04, 1.4388e-04, 6.9917e-04, 1.1291e-03,
        3.0531e-03, 2.0286e-02, 1.5422e-03, 2.9416e-02, 3.8054e-01, 8.8303e-02,
        3.9410e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,630][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.3003e-02, 2.8023e-06, 4.8523e-04, 2.3973e-04, 6.2965e-04, 9.4420e-04,
        4.6016e-03, 2.3756e-02, 1.6872e-03, 3.2641e-02, 4.0175e-01, 7.6640e-02,
        4.4362e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,631][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([9.3811e-01, 3.3349e-05, 3.0526e-03, 3.1176e-04, 5.6455e-03, 1.0503e-03,
        8.8187e-04, 1.9053e-03, 6.4915e-04, 8.6625e-04, 3.4472e-02, 3.7774e-03,
        9.2481e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,633][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.5824, 0.0064, 0.0238, 0.0155, 0.0506, 0.0143, 0.0320, 0.0280, 0.0220,
        0.0339, 0.0956, 0.0474, 0.0481], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,635][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0183, 0.0064, 0.0439, 0.0576, 0.0335, 0.0432, 0.1232, 0.0823, 0.1158,
        0.1077, 0.1658, 0.0909, 0.1113], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,638][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([5.3592e-02, 1.1509e-06, 4.6009e-04, 9.1831e-05, 6.1606e-04, 5.9807e-04,
        1.9990e-03, 1.4627e-02, 7.4644e-04, 1.7564e-02, 4.9185e-01, 6.2246e-02,
        3.5561e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,640][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([8.2182e-03, 6.2262e-06, 4.2605e-04, 1.8937e-04, 5.1085e-04, 9.8884e-04,
        5.7510e-03, 3.3972e-02, 2.4434e-03, 5.4500e-02, 2.5684e-01, 6.7130e-02,
        5.6903e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,642][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([8.3008e-07, 2.0020e-02, 4.9998e-03, 6.9716e-02, 2.2841e-03, 2.2309e-02,
        1.8844e-01, 3.9443e-02, 2.3739e-01, 2.6000e-01, 4.4390e-02, 6.5940e-02,
        4.5064e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,646][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0158, 0.0352, 0.0324, 0.0780, 0.0569, 0.0507, 0.1167, 0.1055, 0.0889,
        0.1803, 0.0772, 0.0867, 0.0755], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:52,649][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([1.8253e-03, 1.0083e-08, 1.0579e-05, 4.4833e-07, 3.8781e-06, 4.4845e-06,
        4.4708e-05, 6.7086e-04, 9.2802e-06, 7.2222e-04, 4.6017e-02, 1.4589e-03,
        5.1103e-02, 8.9813e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,653][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.0628, 0.0241, 0.0495, 0.0328, 0.0505, 0.0905, 0.0450, 0.0591, 0.0418,
        0.0567, 0.1114, 0.1579, 0.1091, 0.1090], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,655][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([3.9759e-09, 1.1006e-02, 1.5240e-04, 3.1755e-02, 1.8090e-04, 8.7182e-03,
        4.4084e-01, 1.1552e-02, 1.4262e-01, 2.9713e-01, 2.6201e-03, 1.8279e-02,
        5.3720e-03, 2.9781e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,656][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([2.7342e-02, 4.1330e-07, 1.8833e-04, 1.0082e-05, 9.9849e-05, 1.1574e-04,
        3.0004e-04, 2.6382e-03, 1.6312e-04, 2.8188e-03, 8.3872e-02, 1.4085e-02,
        6.1406e-02, 8.0696e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,657][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([7.7299e-03, 3.1345e-07, 1.0109e-04, 1.8493e-05, 9.0708e-05, 8.9514e-05,
        4.5365e-04, 3.3901e-03, 1.6206e-04, 2.9192e-03, 8.0099e-02, 1.1503e-02,
        9.1924e-02, 8.0152e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,658][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([9.6293e-01, 1.8571e-05, 2.0974e-03, 9.7586e-05, 2.5734e-03, 3.6744e-04,
        2.7284e-04, 6.8402e-04, 1.7140e-04, 2.8241e-04, 1.9256e-02, 1.4709e-03,
        3.9133e-03, 5.8686e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,660][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.7038, 0.0027, 0.0129, 0.0087, 0.0312, 0.0083, 0.0145, 0.0170, 0.0123,
        0.0147, 0.0626, 0.0262, 0.0329, 0.0522], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,662][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.0057, 0.0064, 0.0224, 0.0449, 0.0202, 0.0384, 0.1013, 0.0563, 0.0935,
        0.1043, 0.1003, 0.0747, 0.0650, 0.2664], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,664][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([5.0680e-02, 1.4408e-07, 9.5963e-05, 7.2156e-06, 8.9615e-05, 5.5783e-05,
        1.6191e-04, 2.2719e-03, 8.5237e-05, 1.3429e-03, 9.2769e-02, 1.1655e-02,
        8.1083e-02, 7.5970e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,667][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([8.3767e-03, 8.7952e-07, 8.1546e-05, 1.5745e-05, 6.6324e-05, 9.0240e-05,
        4.7236e-04, 4.5643e-03, 2.1333e-04, 4.3558e-03, 4.5041e-02, 9.1873e-03,
        1.1138e-01, 8.1616e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,669][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([1.0127e-06, 8.8065e-03, 3.9900e-03, 5.2497e-02, 2.2004e-03, 1.4440e-02,
        1.8305e-01, 3.8392e-02, 2.4902e-01, 2.1209e-01, 4.9577e-02, 5.5454e-02,
        4.9416e-02, 8.1069e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,673][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([0.0083, 0.0255, 0.0212, 0.0611, 0.0404, 0.0305, 0.1048, 0.0876, 0.0696,
        0.1821, 0.0722, 0.0631, 0.0686, 0.1649], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:52,675][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.2549e-03, 3.2166e-09, 5.7412e-06, 4.2966e-07, 4.2314e-06, 4.2595e-06,
        3.5098e-05, 4.1800e-04, 6.4696e-06, 8.7154e-04, 4.1767e-02, 1.0992e-03,
        3.1430e-02, 7.4125e-01, 1.8185e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,680][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1688, 0.0104, 0.0509, 0.0266, 0.0551, 0.0617, 0.0296, 0.0465, 0.0414,
        0.0350, 0.1083, 0.1364, 0.0915, 0.0775, 0.0601], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,682][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.0502e-08, 1.5366e-02, 3.6900e-04, 3.7753e-02, 2.6672e-04, 1.0019e-02,
        4.3670e-01, 1.4044e-02, 1.2348e-01, 2.7521e-01, 4.5469e-03, 1.8713e-02,
        5.2734e-03, 1.6734e-02, 4.1529e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,683][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.5362e-02, 2.4885e-07, 1.0812e-04, 1.0152e-05, 7.4304e-05, 9.3821e-05,
        2.5748e-04, 2.3047e-03, 1.2583e-04, 3.0221e-03, 6.7298e-02, 1.0623e-02,
        6.2351e-02, 6.8999e-01, 1.3838e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,683][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([4.6128e-03, 1.8278e-07, 5.7299e-05, 1.6651e-05, 7.6495e-05, 7.3785e-05,
        3.8769e-04, 2.8695e-03, 1.4138e-04, 3.6160e-03, 7.5720e-02, 1.0147e-02,
        7.8971e-02, 5.8871e-01, 2.3460e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,684][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.5945e-01, 9.1586e-06, 1.5662e-03, 8.8945e-05, 2.6067e-03, 3.4755e-04,
        2.1922e-04, 6.1542e-04, 1.6210e-04, 2.1191e-04, 2.0402e-02, 1.2664e-03,
        3.7450e-03, 6.1421e-03, 3.1632e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,686][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.6721, 0.0027, 0.0132, 0.0075, 0.0365, 0.0073, 0.0151, 0.0150, 0.0117,
        0.0152, 0.0643, 0.0243, 0.0257, 0.0530, 0.0363], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,689][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0158, 0.0047, 0.0280, 0.0451, 0.0250, 0.0329, 0.0728, 0.0550, 0.0742,
        0.0745, 0.1132, 0.0632, 0.0696, 0.1955, 0.1306], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,691][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.6728e-02, 8.8321e-08, 7.5531e-05, 6.0907e-06, 8.3597e-05, 5.7201e-05,
        1.5434e-04, 1.9444e-03, 5.4729e-05, 1.7759e-03, 1.2525e-01, 8.1810e-03,
        6.8074e-02, 5.9399e-01, 1.7363e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,693][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.6070e-03, 3.5795e-07, 3.9828e-05, 9.6766e-06, 4.2734e-05, 7.0851e-05,
        3.4122e-04, 3.2525e-03, 1.3982e-04, 4.5508e-03, 3.3720e-02, 5.6481e-03,
        8.0659e-02, 5.9634e-01, 2.7257e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,696][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([7.2271e-07, 9.9994e-03, 4.6316e-03, 5.5289e-02, 2.3373e-03, 2.2509e-02,
        1.3763e-01, 3.8564e-02, 1.9672e-01, 2.1442e-01, 5.6506e-02, 6.0477e-02,
        4.7032e-02, 4.8868e-02, 1.0502e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,700][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0186, 0.0227, 0.0250, 0.0600, 0.0560, 0.0410, 0.0849, 0.0900, 0.0628,
        0.1492, 0.0651, 0.0697, 0.0642, 0.0882, 0.1026], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:52,703][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:52,706][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[32286],
        [21940],
        [10689],
        [ 2126],
        [35565],
        [ 2034],
        [ 2275],
        [ 1931],
        [ 4833],
        [ 1014],
        [ 4007],
        [  404],
        [ 1155],
        [ 1761],
        [ 2132]], device='cuda:0')
[2024-07-24 10:21:52,708][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[35764],
        [20453],
        [11952],
        [ 2235],
        [39016],
        [  969],
        [ 1419],
        [  799],
        [ 1394],
        [  448],
        [ 3120],
        [  148],
        [  453],
        [  171],
        [  433]], device='cuda:0')
[2024-07-24 10:21:52,711][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[15403],
        [14652],
        [18090],
        [17657],
        [15692],
        [15606],
        [15829],
        [15754],
        [15660],
        [16039],
        [16575],
        [16809],
        [16937],
        [16678],
        [17045]], device='cuda:0')
[2024-07-24 10:21:52,712][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[45356],
        [41018],
        [37475],
        [24433],
        [23082],
        [20258],
        [21309],
        [38980],
        [43112],
        [37163],
        [34468],
        [24230],
        [33542],
        [44566],
        [34751]], device='cuda:0')
[2024-07-24 10:21:52,714][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[24553],
        [23471],
        [24606],
        [24759],
        [25499],
        [24981],
        [25490],
        [25767],
        [25704],
        [25729],
        [25942],
        [26030],
        [25994],
        [25803],
        [25829]], device='cuda:0')
[2024-07-24 10:21:52,715][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 1809],
        [ 2334],
        [  594],
        [ 2363],
        [ 2309],
        [12564],
        [ 8594],
        [12512],
        [22710],
        [18087],
        [ 4999],
        [ 6778],
        [19792],
        [30596],
        [31774]], device='cuda:0')
[2024-07-24 10:21:52,718][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 7302],
        [16883],
        [36931],
        [35195],
        [39272],
        [40083],
        [33366],
        [34760],
        [39927],
        [35863],
        [39885],
        [41253],
        [37529],
        [41121],
        [37690]], device='cuda:0')
[2024-07-24 10:21:52,721][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[23541],
        [ 8522],
        [11544],
        [12961],
        [14577],
        [11191],
        [11151],
        [11327],
        [10357],
        [10186],
        [10438],
        [ 9996],
        [10266],
        [10595],
        [10549]], device='cuda:0')
[2024-07-24 10:21:52,723][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 838],
        [ 727],
        [1008],
        [1216],
        [1507],
        [1714],
        [1419],
        [ 953],
        [1385],
        [1465],
        [1766],
        [1836],
        [1152],
        [1856],
        [1777]], device='cuda:0')
[2024-07-24 10:21:52,726][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[35276],
        [27121],
        [24376],
        [24650],
        [24537],
        [24651],
        [25268],
        [25977],
        [26472],
        [26796],
        [26448],
        [26343],
        [26610],
        [26550],
        [26643]], device='cuda:0')
[2024-07-24 10:21:52,728][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[25643],
        [24576],
        [22118],
        [19771],
        [14250],
        [18961],
        [20646],
        [21099],
        [21254],
        [22336],
        [22272],
        [21677],
        [22088],
        [21691],
        [22075]], device='cuda:0')
[2024-07-24 10:21:52,731][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[46702],
        [26579],
        [35226],
        [29919],
        [25917],
        [17279],
        [28799],
        [30957],
        [31984],
        [28756],
        [28929],
        [29717],
        [29354],
        [43570],
        [42742]], device='cuda:0')
[2024-07-24 10:21:52,734][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[23230],
        [29293],
        [28321],
        [27897],
        [29263],
        [27834],
        [27506],
        [30323],
        [26114],
        [29952],
        [28881],
        [26820],
        [26251],
        [22294],
        [21893]], device='cuda:0')
[2024-07-24 10:21:52,736][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[37121],
        [40074],
        [23010],
        [26645],
        [21364],
        [22244],
        [21909],
        [20837],
        [22547],
        [26181],
        [25519],
        [25223],
        [24828],
        [25664],
        [25969]], device='cuda:0')
[2024-07-24 10:21:52,739][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 9626],
        [37880],
        [35231],
        [36767],
        [34133],
        [29951],
        [26461],
        [31913],
        [31826],
        [38253],
        [31348],
        [31027],
        [32747],
        [29557],
        [35818]], device='cuda:0')
[2024-07-24 10:21:52,742][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[28224],
        [14599],
        [24893],
        [14984],
        [14070],
        [29133],
        [10382],
        [10317],
        [10513],
        [ 6501],
        [17285],
        [19835],
        [12168],
        [13952],
        [12793]], device='cuda:0')
[2024-07-24 10:21:52,743][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[14989],
        [28517],
        [41877],
        [42504],
        [43453],
        [45062],
        [45099],
        [46114],
        [46347],
        [46166],
        [46757],
        [47511],
        [47649],
        [47464],
        [47536]], device='cuda:0')
[2024-07-24 10:21:52,744][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[29649],
        [39385],
        [39455],
        [32824],
        [32681],
        [33800],
        [19184],
        [20106],
        [15879],
        [22490],
        [23005],
        [25348],
        [23004],
        [22914],
        [23217]], device='cuda:0')
[2024-07-24 10:21:52,746][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[21267],
        [21784],
        [26152],
        [24868],
        [26154],
        [35317],
        [33801],
        [30165],
        [31127],
        [22499],
        [15290],
        [12810],
        [16164],
        [18276],
        [18602]], device='cuda:0')
[2024-07-24 10:21:52,749][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[31840],
        [14508],
        [15199],
        [11913],
        [10765],
        [12276],
        [ 7908],
        [ 9447],
        [ 9091],
        [ 6945],
        [10356],
        [11540],
        [ 9202],
        [10736],
        [ 9599]], device='cuda:0')
[2024-07-24 10:21:52,751][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[32980],
        [33114],
        [30455],
        [30974],
        [19980],
        [25174],
        [30648],
        [30697],
        [29221],
        [32362],
        [29497],
        [28565],
        [30938],
        [31382],
        [31400]], device='cuda:0')
[2024-07-24 10:21:52,754][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[43419],
        [45153],
        [47013],
        [46960],
        [46967],
        [47598],
        [47260],
        [47047],
        [47025],
        [46014],
        [46044],
        [45593],
        [46302],
        [46300],
        [46152]], device='cuda:0')
[2024-07-24 10:21:52,756][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[24277],
        [10444],
        [ 8314],
        [13093],
        [12951],
        [10965],
        [11740],
        [10859],
        [12192],
        [11225],
        [11181],
        [10878],
        [10523],
        [10754],
        [10824]], device='cuda:0')
[2024-07-24 10:21:52,759][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[26092],
        [20956],
        [33002],
        [44184],
        [43411],
        [34218],
        [43568],
        [44140],
        [43387],
        [42470],
        [27805],
        [27852],
        [33001],
        [29886],
        [34187]], device='cuda:0')
[2024-07-24 10:21:52,762][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[12772],
        [ 6587],
        [ 8759],
        [ 3529],
        [ 3524],
        [ 8245],
        [ 9083],
        [ 8586],
        [ 9572],
        [ 9444],
        [10512],
        [10001],
        [ 9488],
        [13013],
        [10873]], device='cuda:0')
[2024-07-24 10:21:52,764][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[41895],
        [11373],
        [10563],
        [15723],
        [16312],
        [14553],
        [15222],
        [14977],
        [11840],
        [11200],
        [10461],
        [10704],
        [11367],
        [12359],
        [12841]], device='cuda:0')
[2024-07-24 10:21:52,767][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[37290],
        [13025],
        [11203],
        [14504],
        [14701],
        [15716],
        [15612],
        [15956],
        [15471],
        [15625],
        [14815],
        [15360],
        [15502],
        [15587],
        [16062]], device='cuda:0')
[2024-07-24 10:21:52,770][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[14388],
        [34770],
        [23590],
        [24525],
        [26163],
        [19362],
        [23752],
        [24097],
        [25113],
        [29779],
        [29477],
        [28665],
        [29002],
        [28259],
        [27575]], device='cuda:0')
[2024-07-24 10:21:52,772][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[41267],
        [20730],
        [18274],
        [13915],
        [20223],
        [22583],
        [31346],
        [24670],
        [24976],
        [13851],
        [19892],
        [18253],
        [20368],
        [24565],
        [16966]], device='cuda:0')
[2024-07-24 10:21:52,774][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[42346],
        [42346],
        [42346],
        [42346],
        [42346],
        [42346],
        [42346],
        [42346],
        [42346],
        [42346],
        [42346],
        [42346],
        [42346],
        [42346],
        [42346]], device='cuda:0')
[2024-07-24 10:21:52,860][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:52,861][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,862][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,862][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,863][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,864][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,864][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,865][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,866][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,866][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,867][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,868][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,868][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:52,869][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9951, 0.0049], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,870][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([3.8572e-04, 9.9961e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,870][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6819, 0.3181], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,871][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5762, 0.4238], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,875][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3307, 0.6693], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,878][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2021, 0.7979], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,878][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9937, 0.0063], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,879][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0016, 0.9984], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,880][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9196, 0.0804], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,881][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.8857, 0.1143], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,882][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9939, 0.0061], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,885][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0668, 0.9332], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:52,889][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.9617, 0.0037, 0.0346], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,891][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([6.1548e-06, 9.2412e-01, 7.5872e-02], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,894][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.3830, 0.3136, 0.3034], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,898][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.0264, 0.2885, 0.6851], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,902][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.0064, 0.0208, 0.9728], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,905][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.0638, 0.2645, 0.6717], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,905][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.5796, 0.0445, 0.3759], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,906][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([1.8560e-04, 7.2407e-01, 2.7575e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,907][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.5748, 0.0353, 0.3899], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,907][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.2206, 0.1133, 0.6661], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,910][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.8953, 0.0045, 0.1002], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,912][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.0058, 0.1620, 0.8322], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:52,914][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.8165e-01, 2.8265e-03, 1.4933e-02, 5.8952e-04], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,916][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.0686e-05, 2.1092e-01, 4.8868e-02, 7.4020e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,920][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4137, 0.2096, 0.1910, 0.1857], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,924][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0298, 0.3500, 0.5190, 0.1012], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,926][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([4.2080e-03, 2.0805e-04, 3.2555e-01, 6.7004e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,930][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0565, 0.0749, 0.5263, 0.3423], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,931][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.8423, 0.0024, 0.0593, 0.0960], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,932][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([2.1445e-04, 8.3207e-02, 1.2613e-01, 7.9045e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,933][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.6662, 0.0108, 0.2350, 0.0879], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,934][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.6623, 0.0041, 0.2822, 0.0514], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,935][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.8360, 0.0126, 0.1071, 0.0444], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,937][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0021, 0.0083, 0.2965, 0.6932], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:52,940][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.8814, 0.0112, 0.0465, 0.0012, 0.0597], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,942][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([2.3914e-06, 3.0621e-01, 1.8332e-02, 6.6970e-01, 5.7569e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,946][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.1593, 0.1964, 0.1793, 0.2008, 0.2641], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,949][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0008, 0.5448, 0.2461, 0.0562, 0.1521], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,952][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([2.6383e-04, 1.7882e-03, 9.7016e-02, 8.6282e-01, 3.8114e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,956][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0348, 0.0890, 0.3022, 0.3193, 0.2548], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,958][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.2806, 0.0150, 0.1118, 0.3395, 0.2531], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,959][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([3.3284e-05, 4.9566e-02, 4.1764e-02, 8.0896e-01, 9.9673e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,959][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.2931, 0.0235, 0.2648, 0.2044, 0.2141], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,960][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0379, 0.0572, 0.3001, 0.4261, 0.1787], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,961][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.2863, 0.0137, 0.1705, 0.0815, 0.4480], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,962][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([1.8695e-04, 2.8942e-02, 9.9827e-02, 8.1943e-01, 5.1615e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:52,964][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ went] are: tensor([4.3058e-01, 1.2908e-03, 5.7192e-03, 1.1144e-04, 6.7672e-03, 5.5553e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,967][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ went] are: tensor([7.1163e-06, 1.2757e-01, 2.1459e-02, 4.9239e-01, 5.3042e-03, 3.5327e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,971][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.3052, 0.1300, 0.1240, 0.1292, 0.1789, 0.1328], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,974][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0135, 0.3830, 0.3306, 0.1132, 0.0504, 0.1093], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,976][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ went] are: tensor([1.4872e-03, 4.9416e-05, 4.6373e-02, 9.3490e-02, 1.2276e-02, 8.4632e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,980][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0150, 0.0540, 0.2260, 0.2199, 0.1804, 0.3048], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,984][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.7799, 0.0018, 0.0405, 0.0635, 0.0876, 0.0267], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,985][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ went] are: tensor([3.3203e-04, 4.1482e-02, 5.2310e-02, 4.5172e-01, 1.1926e-01, 3.3490e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,985][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.3271, 0.0190, 0.1758, 0.1057, 0.1712, 0.2012], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,986][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.3524, 0.0072, 0.2239, 0.0745, 0.1375, 0.2045], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,987][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.6055, 0.0087, 0.0842, 0.0618, 0.1034, 0.1365], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,988][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ went] are: tensor([5.8449e-04, 4.1814e-03, 8.6190e-02, 2.0674e-01, 3.0812e-02, 6.7150e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:52,990][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([6.5606e-01, 1.3071e-03, 8.2289e-03, 1.9228e-04, 7.3152e-03, 3.2685e-01,
        4.7455e-05], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,991][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([7.3371e-06, 2.2119e-02, 1.0984e-02, 1.4919e-01, 2.9063e-03, 1.7211e-01,
        6.4269e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,995][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2239, 0.1267, 0.1213, 0.1170, 0.1714, 0.1336, 0.1061],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:52,999][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0384, 0.1833, 0.3220, 0.0393, 0.1554, 0.1194, 0.1421],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,002][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([8.9414e-03, 6.4363e-06, 3.7483e-02, 1.8817e-02, 7.2361e-03, 2.2374e-01,
        7.0378e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,005][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0276, 0.0267, 0.1795, 0.1021, 0.1301, 0.2079, 0.3261],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,007][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([9.1374e-01, 4.0395e-04, 1.5400e-02, 1.7387e-02, 3.2283e-02, 7.3950e-03,
        1.3393e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,009][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.6587e-04, 1.6712e-02, 2.6398e-02, 1.2393e-01, 5.6190e-02, 2.6991e-01,
        5.0670e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,011][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.4060, 0.0098, 0.1515, 0.0495, 0.1154, 0.1188, 0.1489],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,012][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.6214, 0.0017, 0.1440, 0.0187, 0.0995, 0.0532, 0.0615],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,013][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.5806, 0.0043, 0.0656, 0.0222, 0.0690, 0.0580, 0.2002],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,013][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([5.0378e-04, 5.6116e-04, 3.0253e-02, 3.6001e-02, 1.0552e-02, 1.2478e-01,
        7.9735e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,015][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ the] are: tensor([6.6429e-01, 1.0454e-03, 7.6974e-03, 2.5172e-04, 5.9815e-03, 3.2069e-01,
        4.5818e-05, 2.0470e-08], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,016][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ the] are: tensor([2.7917e-05, 3.6035e-02, 1.4463e-02, 1.4902e-01, 5.3008e-03, 1.2568e-01,
        5.2140e-01, 1.4807e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,018][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2086, 0.1110, 0.1119, 0.1012, 0.1595, 0.1198, 0.1017, 0.0864],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,022][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1773, 0.0630, 0.1903, 0.0422, 0.1571, 0.1359, 0.0719, 0.1623],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,024][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ the] are: tensor([1.0731e-02, 1.5031e-05, 2.1336e-02, 6.3900e-03, 4.3278e-03, 6.0821e-02,
        1.9097e-01, 7.0541e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,028][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0325, 0.0213, 0.1142, 0.0587, 0.0815, 0.1149, 0.1690, 0.4078],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,031][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ the] are: tensor([9.7809e-01, 1.0087e-04, 3.7145e-03, 3.7368e-03, 7.3154e-03, 1.3363e-03,
        1.9598e-03, 3.7490e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,033][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ the] are: tensor([6.9708e-05, 8.7619e-03, 6.0717e-03, 4.6747e-02, 1.3561e-02, 1.4220e-01,
        3.0934e-01, 4.7325e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,035][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ the] are: tensor([8.4740e-01, 6.1182e-04, 4.4137e-02, 3.0320e-03, 3.3467e-02, 1.5147e-02,
        1.7357e-02, 3.8845e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,038][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.4366, 0.0032, 0.1352, 0.0202, 0.0874, 0.0573, 0.0588, 0.2014],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,039][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ the] are: tensor([8.8394e-01, 8.3248e-04, 1.4393e-02, 4.8179e-03, 2.7370e-02, 1.1133e-02,
        3.8247e-02, 1.9272e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,039][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0016, 0.0008, 0.0307, 0.0273, 0.0134, 0.0810, 0.4154, 0.4297],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,040][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ house] are: tensor([7.3013e-01, 1.7495e-03, 7.3165e-03, 2.5241e-04, 1.0143e-02, 2.4084e-01,
        2.1813e-05, 4.4771e-09, 9.5523e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,041][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ house] are: tensor([1.3803e-06, 2.4107e-02, 4.1412e-03, 9.5406e-02, 1.5260e-03, 8.7407e-02,
        4.4157e-01, 5.8090e-02, 2.8776e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,044][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.0911, 0.1084, 0.1024, 0.1083, 0.1447, 0.1128, 0.0976, 0.0948, 0.1399],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,048][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ house] are: tensor([0.0014, 0.3597, 0.1976, 0.0251, 0.0270, 0.0480, 0.1494, 0.1509, 0.0408],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,051][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ house] are: tensor([2.5521e-05, 1.0936e-06, 2.9169e-03, 2.9909e-03, 5.1567e-04, 5.2127e-02,
        3.2926e-01, 5.7780e-01, 3.4364e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,054][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ house] are: tensor([0.0061, 0.0156, 0.0746, 0.0548, 0.0535, 0.0929, 0.1695, 0.3641, 0.1689],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,056][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ house] are: tensor([9.2274e-01, 3.0494e-04, 8.6081e-03, 1.3534e-02, 2.4091e-02, 4.7182e-03,
        8.4375e-03, 1.5126e-02, 2.4375e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,059][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ house] are: tensor([2.7479e-05, 3.6051e-03, 3.1976e-03, 3.0717e-02, 6.5404e-03, 5.1861e-02,
        1.8259e-01, 4.1920e-01, 3.0227e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,063][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.1365, 0.0037, 0.1017, 0.0330, 0.0767, 0.0819, 0.1087, 0.3682, 0.0896],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,065][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ house] are: tensor([0.1494, 0.0024, 0.1150, 0.0415, 0.0671, 0.0853, 0.1048, 0.3350, 0.0994],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,066][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.4100, 0.0036, 0.0537, 0.0172, 0.0598, 0.0373, 0.2029, 0.1144, 0.1011],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,066][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ house] are: tensor([6.3352e-05, 2.2085e-04, 8.5805e-03, 1.8045e-02, 4.3113e-03, 6.0938e-02,
        5.0741e-01, 3.1160e-01, 8.8829e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,067][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [.] are: tensor([5.5693e-01, 1.2298e-03, 8.4943e-03, 1.7734e-04, 8.6945e-03, 4.0895e-01,
        3.5718e-05, 1.1210e-08, 1.4888e-02, 5.9313e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,068][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [.] are: tensor([6.1093e-06, 1.2650e-02, 5.9670e-03, 7.0055e-02, 1.8042e-03, 6.1055e-02,
        2.2079e-01, 5.4053e-02, 1.9360e-01, 3.8002e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,071][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1000, 0.1006, 0.0952, 0.0948, 0.1257, 0.0998, 0.0844, 0.0791, 0.1164,
        0.1039], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,075][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0144, 0.0998, 0.0860, 0.0412, 0.0396, 0.0845, 0.1125, 0.2666, 0.0551,
        0.2003], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,078][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [.] are: tensor([4.9545e-03, 8.2406e-07, 3.2723e-03, 1.4079e-03, 1.0013e-03, 1.4823e-02,
        6.2585e-02, 2.7746e-01, 4.6871e-03, 6.2981e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,081][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0191, 0.0103, 0.0567, 0.0315, 0.0435, 0.0636, 0.0902, 0.2210, 0.1033,
        0.3607], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,083][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [.] are: tensor([9.4610e-01, 2.3307e-04, 6.1309e-03, 7.4515e-03, 1.5288e-02, 3.2478e-03,
        4.8023e-03, 9.7621e-03, 1.6502e-03, 5.3359e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,086][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [.] are: tensor([7.6817e-05, 3.0596e-03, 5.6643e-03, 2.0559e-02, 9.1346e-03, 5.5683e-02,
        1.0749e-01, 3.1084e-01, 3.8377e-01, 1.0372e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,090][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.5884, 0.0031, 0.0449, 0.0147, 0.0495, 0.0359, 0.0530, 0.1152, 0.0303,
        0.0650], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,092][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [.] are: tensor([7.2297e-01, 5.2910e-04, 6.3752e-02, 6.0902e-03, 4.0072e-02, 1.6971e-02,
        1.6399e-02, 8.6285e-02, 1.1983e-02, 3.4945e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,093][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.5822, 0.0015, 0.0428, 0.0069, 0.0351, 0.0471, 0.1126, 0.0500, 0.0244,
        0.0974], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,094][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [.] are: tensor([3.8802e-04, 9.5287e-05, 7.8115e-03, 5.4117e-03, 2.8544e-03, 1.9893e-02,
        1.2504e-01, 1.8141e-01, 2.0174e-02, 6.3692e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,094][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([4.0923e-01, 1.5083e-03, 1.1327e-02, 1.0995e-04, 7.9603e-03, 3.4021e-01,
        1.2825e-05, 1.0403e-09, 4.3424e-03, 2.8419e-04, 2.2502e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,096][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([9.7233e-07, 3.5959e-02, 3.2060e-03, 6.5549e-02, 1.1084e-03, 4.2778e-02,
        2.5200e-01, 4.1645e-02, 1.8958e-01, 3.3939e-01, 2.8788e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,099][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.0776, 0.0888, 0.0892, 0.0810, 0.1212, 0.0862, 0.0746, 0.0725, 0.1088,
        0.0979, 0.1022], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,103][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.0095, 0.0747, 0.1378, 0.0413, 0.0494, 0.0807, 0.0689, 0.1606, 0.0461,
        0.1007, 0.2303], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,105][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([7.7206e-04, 4.9253e-06, 1.4158e-03, 6.3305e-04, 3.2255e-04, 4.5950e-03,
        1.9840e-02, 8.1598e-02, 1.7263e-03, 2.0883e-01, 6.8026e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,108][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.0196, 0.0122, 0.0412, 0.0222, 0.0311, 0.0386, 0.0589, 0.1206, 0.0612,
        0.2012, 0.3934], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,112][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.5307, 0.0029, 0.0420, 0.0513, 0.1034, 0.0228, 0.0403, 0.0615, 0.0128,
        0.0331, 0.0990], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,115][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([1.0637e-05, 1.7041e-03, 8.5805e-04, 8.1783e-03, 1.6524e-03, 2.3941e-02,
        7.5270e-02, 3.0340e-01, 3.6047e-01, 1.8086e-01, 4.3658e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,119][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.2639, 0.0026, 0.0329, 0.0102, 0.0177, 0.0267, 0.0395, 0.1157, 0.0332,
        0.0691, 0.3886], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,120][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.0990, 0.0026, 0.0448, 0.0110, 0.0279, 0.0203, 0.0247, 0.0665, 0.0230,
        0.0548, 0.6255], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,121][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.5927, 0.0013, 0.0409, 0.0070, 0.0431, 0.0269, 0.0566, 0.0280, 0.0178,
        0.0511, 0.1347], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,122][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([2.3162e-04, 4.6976e-04, 4.9398e-03, 6.7287e-03, 2.2037e-03, 1.8985e-02,
        8.7665e-02, 8.7745e-02, 2.2941e-02, 3.7956e-01, 3.8853e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,123][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([3.4904e-01, 8.6237e-04, 4.5081e-03, 1.1273e-04, 4.5741e-03, 4.2002e-01,
        1.0784e-05, 1.1717e-09, 2.6256e-03, 2.0106e-04, 1.0648e-01, 1.1156e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,124][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([3.6319e-07, 1.5880e-02, 1.8966e-03, 4.7429e-02, 6.6995e-04, 3.8132e-02,
        1.8701e-01, 4.1236e-02, 1.4587e-01, 4.3823e-01, 2.8532e-02, 5.5117e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,128][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1089, 0.0792, 0.0732, 0.0760, 0.1016, 0.0835, 0.0676, 0.0634, 0.0922,
        0.0840, 0.0874, 0.0829], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,131][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0147, 0.1425, 0.1096, 0.0242, 0.0314, 0.0751, 0.1026, 0.1149, 0.0232,
        0.0759, 0.1334, 0.1526], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,133][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([9.8286e-05, 2.2422e-07, 4.5130e-04, 9.8660e-05, 5.5163e-05, 1.2522e-03,
        5.9194e-03, 2.3161e-02, 5.2495e-04, 7.1977e-02, 7.3097e-01, 1.6549e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,137][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0045, 0.0055, 0.0272, 0.0138, 0.0179, 0.0263, 0.0441, 0.1031, 0.0449,
        0.1707, 0.4071, 0.1349], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,140][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([8.1043e-01, 5.1163e-04, 1.5055e-02, 1.7021e-02, 3.2118e-02, 6.7868e-03,
        1.1471e-02, 2.2982e-02, 3.2662e-03, 1.1178e-02, 4.3763e-02, 2.5415e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,142][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([2.8009e-05, 1.3915e-03, 2.5539e-03, 1.0935e-02, 4.5100e-03, 1.8184e-02,
        8.3897e-02, 2.9550e-01, 2.7270e-01, 1.3309e-01, 1.5165e-01, 2.5563e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,146][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1433, 0.0015, 0.0251, 0.0070, 0.0161, 0.0187, 0.0273, 0.0870, 0.0190,
        0.0481, 0.4183, 0.1884], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,147][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([7.2433e-02, 3.9298e-04, 1.8701e-02, 3.3285e-03, 1.2279e-02, 7.3994e-03,
        1.0096e-02, 3.3769e-02, 6.6013e-03, 2.4195e-02, 5.8925e-01, 2.2155e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,148][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.2758, 0.0029, 0.0493, 0.0109, 0.0626, 0.0274, 0.0945, 0.0470, 0.0185,
        0.0730, 0.2412, 0.0968], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,149][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([4.5067e-05, 9.0564e-05, 2.2261e-03, 2.4266e-03, 7.9932e-04, 8.9775e-03,
        5.6424e-02, 5.8087e-02, 1.0172e-02, 3.0897e-01, 3.8746e-01, 1.6433e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,150][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([5.7863e-01, 9.8160e-04, 6.7679e-03, 1.5609e-04, 5.0519e-03, 2.2829e-01,
        2.1211e-05, 1.3349e-08, 3.1750e-03, 2.6846e-04, 9.3196e-02, 8.3462e-02,
        9.2090e-08], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,152][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([7.1654e-06, 2.6650e-02, 5.2507e-03, 6.2309e-02, 2.4618e-03, 4.4026e-02,
        2.2084e-01, 6.0074e-02, 1.5662e-01, 2.7177e-01, 3.8247e-02, 6.4299e-02,
        4.7450e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,156][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1338, 0.0680, 0.0719, 0.0614, 0.0988, 0.0723, 0.0628, 0.0575, 0.0877,
        0.0763, 0.0850, 0.0711, 0.0535], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,160][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0228, 0.0205, 0.0619, 0.0125, 0.0414, 0.0633, 0.0332, 0.0593, 0.0494,
        0.0430, 0.1757, 0.1986, 0.2184], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,162][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([3.5235e-03, 1.7170e-06, 1.5166e-03, 2.1086e-04, 2.5151e-04, 1.4476e-03,
        4.4891e-03, 2.4765e-02, 4.8299e-04, 2.9416e-02, 4.0745e-01, 8.5936e-02,
        4.4050e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,166][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0175, 0.0054, 0.0270, 0.0103, 0.0184, 0.0219, 0.0294, 0.0749, 0.0313,
        0.1204, 0.3095, 0.0918, 0.2423], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,169][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([9.5014e-01, 1.4539e-04, 4.2069e-03, 4.1100e-03, 8.9554e-03, 1.5381e-03,
        2.2429e-03, 3.9351e-03, 7.6628e-04, 2.2997e-03, 9.3424e-03, 5.0106e-03,
        7.3027e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,171][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([1.0653e-05, 2.1356e-03, 1.0102e-03, 1.2312e-02, 3.4601e-03, 2.1228e-02,
        8.5176e-02, 1.7768e-01, 3.5770e-01, 1.2795e-01, 4.6831e-02, 2.2339e-02,
        1.4216e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,173][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([6.7164e-01, 1.7703e-04, 1.0845e-02, 5.1643e-04, 6.8116e-03, 2.8359e-03,
        3.7733e-03, 8.7973e-03, 1.6464e-03, 5.8510e-03, 1.4174e-01, 3.6126e-02,
        1.0924e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,174][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2591, 0.0008, 0.0296, 0.0030, 0.0203, 0.0080, 0.0079, 0.0310, 0.0056,
        0.0149, 0.3684, 0.1336, 0.1178], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,175][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([6.8622e-01, 4.5111e-04, 1.0617e-02, 2.4226e-03, 1.2979e-02, 6.0676e-03,
        1.8792e-02, 1.0591e-02, 8.3117e-03, 1.5950e-02, 5.1871e-02, 1.5701e-02,
        1.6003e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,176][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([8.2694e-04, 2.1177e-04, 5.9161e-03, 3.7694e-03, 2.4606e-03, 9.4605e-03,
        4.5663e-02, 5.9414e-02, 8.8645e-03, 1.7569e-01, 2.8973e-01, 1.0502e-01,
        2.9297e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,177][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([5.4453e-01, 8.4160e-04, 6.4606e-03, 7.1099e-05, 8.1979e-03, 1.0962e-01,
        6.6318e-06, 1.3903e-09, 3.2824e-03, 3.2635e-04, 1.5833e-01, 5.5973e-02,
        1.8076e-08, 1.1237e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,179][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([1.5846e-06, 2.7627e-02, 2.6888e-03, 3.7054e-02, 9.3460e-04, 3.1571e-02,
        1.9980e-01, 4.1757e-02, 1.2401e-01, 2.3630e-01, 2.3119e-02, 4.7782e-02,
        3.3693e-02, 1.9366e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,183][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.0496, 0.0724, 0.0688, 0.0671, 0.1007, 0.0658, 0.0612, 0.0592, 0.0878,
        0.0804, 0.0874, 0.0699, 0.0537, 0.0759], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,187][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.0023, 0.1166, 0.0728, 0.0171, 0.0086, 0.0239, 0.0921, 0.0745, 0.0087,
        0.0789, 0.0869, 0.0752, 0.2367, 0.1058], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,189][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([2.1420e-03, 1.3070e-07, 2.3252e-04, 7.4360e-06, 1.5447e-05, 6.4947e-05,
        2.1802e-04, 2.1949e-03, 2.4189e-05, 1.6445e-03, 5.0099e-02, 8.4269e-03,
        7.2263e-02, 8.6267e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,193][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.0252, 0.0033, 0.0186, 0.0043, 0.0099, 0.0112, 0.0129, 0.0374, 0.0154,
        0.0562, 0.1723, 0.0450, 0.1307, 0.4575], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,196][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([9.1628e-01, 2.5801e-04, 6.5831e-03, 6.2023e-03, 1.5147e-02, 2.2747e-03,
        3.3523e-03, 6.4449e-03, 1.1128e-03, 3.6280e-03, 1.4647e-02, 8.7097e-03,
        1.1291e-02, 4.0718e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,198][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([5.6369e-05, 1.8350e-03, 1.4526e-03, 5.9954e-03, 1.3299e-03, 1.2583e-02,
        5.0777e-02, 1.7713e-01, 1.2903e-01, 7.7156e-02, 3.3049e-02, 1.3334e-02,
        1.9939e-01, 2.9688e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,200][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.6219, 0.0008, 0.0105, 0.0016, 0.0051, 0.0051, 0.0084, 0.0142, 0.0038,
        0.0104, 0.0629, 0.0526, 0.0957, 0.1071], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,201][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([1.6063e-01, 3.5241e-04, 2.0486e-02, 1.3224e-03, 8.2791e-03, 3.3499e-03,
        3.1084e-03, 1.6223e-02, 2.8254e-03, 7.0129e-03, 2.4428e-01, 8.2349e-02,
        6.9794e-02, 3.7999e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,202][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([3.5103e-01, 2.0785e-04, 5.8487e-03, 1.0732e-03, 8.8762e-03, 3.4533e-03,
        1.1427e-02, 3.9020e-03, 3.9286e-03, 1.1279e-02, 3.1329e-02, 6.4204e-03,
        5.0988e-02, 5.1023e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,203][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([4.1751e-04, 5.0588e-05, 1.8715e-03, 5.9022e-04, 5.5955e-04, 1.5545e-03,
        9.4979e-03, 1.6644e-02, 1.8809e-03, 3.4620e-02, 1.1726e-01, 3.6233e-02,
        1.0815e-01, 6.7067e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,204][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([5.0972e-01, 9.6293e-04, 5.9919e-03, 1.0774e-04, 6.0336e-03, 2.4138e-01,
        3.2865e-05, 1.9923e-08, 2.6699e-03, 3.9685e-04, 8.7496e-02, 7.5101e-02,
        1.3793e-07, 7.0031e-02, 7.7641e-05], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,206][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.9616e-06, 1.5688e-02, 4.5382e-03, 4.2554e-02, 1.8539e-03, 3.7233e-02,
        1.4240e-01, 3.9486e-02, 1.2544e-01, 2.1824e-01, 3.7749e-02, 5.1813e-02,
        3.5638e-02, 1.4932e-01, 9.8040e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,210][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0961, 0.0650, 0.0656, 0.0597, 0.0904, 0.0692, 0.0573, 0.0520, 0.0787,
        0.0686, 0.0763, 0.0635, 0.0470, 0.0592, 0.0513], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,214][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0297, 0.0347, 0.0635, 0.0094, 0.0352, 0.0341, 0.0342, 0.0594, 0.0253,
        0.0447, 0.1350, 0.0558, 0.2020, 0.1231, 0.1140], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,216][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.2175e-03, 5.5529e-08, 1.5939e-04, 7.1149e-06, 1.4701e-05, 6.5451e-05,
        1.6720e-04, 1.8652e-03, 1.7483e-05, 1.9830e-03, 5.7833e-02, 6.7846e-03,
        6.1834e-02, 6.7407e-01, 1.9398e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,220][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0078, 0.0018, 0.0107, 0.0032, 0.0067, 0.0079, 0.0099, 0.0293, 0.0111,
        0.0474, 0.1409, 0.0358, 0.1087, 0.4368, 0.1419], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,223][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([8.8523e-01, 2.3632e-04, 7.9310e-03, 6.4675e-03, 1.7633e-02, 2.8000e-03,
        4.0027e-03, 7.4531e-03, 1.5880e-03, 4.0235e-03, 1.8551e-02, 8.4404e-03,
        1.3252e-02, 4.8198e-03, 1.7571e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,225][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([5.4380e-05, 7.7022e-04, 1.3524e-03, 3.2757e-03, 1.6547e-03, 8.9358e-03,
        2.3217e-02, 8.6107e-02, 1.0122e-01, 6.0226e-02, 4.5222e-02, 1.3381e-02,
        1.3168e-01, 4.0947e-01, 1.1343e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,227][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([5.5702e-01, 2.3305e-04, 8.7657e-03, 5.4001e-04, 5.5500e-03, 2.7651e-03,
        3.8360e-03, 8.4905e-03, 1.6573e-03, 5.1702e-03, 7.6866e-02, 2.7497e-02,
        8.9704e-02, 8.8824e-02, 1.2308e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,228][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([3.3003e-01, 2.0057e-04, 1.4627e-02, 8.1020e-04, 1.0785e-02, 2.2076e-03,
        2.2095e-03, 1.0763e-02, 1.3093e-03, 3.6130e-03, 2.1948e-01, 4.9437e-02,
        4.7839e-02, 2.4643e-01, 6.0271e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,229][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.3055, 0.0006, 0.0149, 0.0018, 0.0123, 0.0075, 0.0176, 0.0146, 0.0045,
        0.0121, 0.0744, 0.0325, 0.1534, 0.1269, 0.2212], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,230][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.9152e-04, 3.1255e-05, 1.1365e-03, 5.2011e-04, 4.5187e-04, 1.4784e-03,
        7.0042e-03, 1.1911e-02, 1.1087e-03, 3.0405e-02, 8.2839e-02, 2.1813e-02,
        7.6856e-02, 4.4695e-01, 3.1720e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,317][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:53,321][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,322][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,322][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,323][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,324][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,324][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,325][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,326][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,327][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,327][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,328][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,329][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,329][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9947, 0.0053], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,330][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([3.8572e-04, 9.9961e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,331][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9946, 0.0054], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,332][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2143, 0.7857], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,332][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3307, 0.6693], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,333][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9592, 0.0408], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,334][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9489, 0.0511], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,334][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0517, 0.9483], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,336][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9971, 0.0029], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,338][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9434, 0.0566], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,342][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9345, 0.0655], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,346][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0668, 0.9332], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,350][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.8703, 0.0653, 0.0644], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,352][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([6.1548e-06, 9.2412e-01, 7.5872e-02], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,356][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.4315, 0.0603, 0.5082], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,358][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.0066, 0.2529, 0.7405], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,359][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.0064, 0.0208, 0.9728], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,360][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.2355, 0.0098, 0.7547], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,360][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.0420, 0.2704, 0.6876], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,361][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.0010, 0.0402, 0.9589], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,363][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.4379, 0.0055, 0.5566], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,366][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.2599, 0.0898, 0.6503], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,369][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.0462, 0.0357, 0.9181], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,373][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.0058, 0.1620, 0.8322], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,377][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9129, 0.0083, 0.0227, 0.0561], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,379][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.0686e-05, 2.1092e-01, 4.8868e-02, 7.4020e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,383][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5386, 0.0111, 0.3027, 0.1476], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,387][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0116, 0.0532, 0.5654, 0.3698], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,388][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([4.2080e-03, 2.0805e-04, 3.2555e-01, 6.7004e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,388][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([1.5637e-01, 2.2847e-04, 5.5608e-01, 2.8732e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,389][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0859, 0.0248, 0.5891, 0.3001], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,390][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([3.2942e-04, 1.3587e-04, 1.5143e-01, 8.4810e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,390][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([6.6700e-01, 3.6233e-04, 3.1823e-01, 1.4410e-02], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,392][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4402, 0.0086, 0.4254, 0.1258], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,395][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0604, 0.0033, 0.5697, 0.3666], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,399][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0021, 0.0083, 0.2965, 0.6932], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,403][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.6947, 0.0401, 0.0337, 0.1920, 0.0395], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,405][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([2.3914e-06, 3.0621e-01, 1.8332e-02, 6.6970e-01, 5.7569e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,408][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.0685, 0.0314, 0.2103, 0.2228, 0.4671], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,412][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.0022, 0.1357, 0.2467, 0.4286, 0.1867], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,415][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([2.6383e-04, 1.7882e-03, 9.7016e-02, 8.6282e-01, 3.8114e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,415][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.0428, 0.0016, 0.2347, 0.5181, 0.2028], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,416][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.0158, 0.0992, 0.2437, 0.4464, 0.1949], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,417][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([1.9969e-05, 9.9877e-04, 5.5441e-02, 9.2221e-01, 2.1328e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,418][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.2525, 0.0064, 0.4246, 0.1016, 0.2150], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,420][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.0512, 0.0614, 0.3488, 0.3433, 0.1953], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,423][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0145, 0.0126, 0.3239, 0.4354, 0.2135], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,425][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([1.8695e-04, 2.8942e-02, 9.9827e-02, 8.1943e-01, 5.1615e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,429][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.8810, 0.0085, 0.0212, 0.0551, 0.0188, 0.0154], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:53,431][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([7.1163e-06, 1.2757e-01, 2.1459e-02, 4.9239e-01, 5.3042e-03, 3.5327e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:53,435][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.1369, 0.0080, 0.1491, 0.0905, 0.4392, 0.1763], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:53,439][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.0029, 0.0232, 0.1681, 0.1269, 0.0996, 0.5792], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:53,441][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([1.4872e-03, 4.9416e-05, 4.6373e-02, 9.3490e-02, 1.2276e-02, 8.4632e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:53,442][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([9.1180e-02, 1.0424e-04, 2.0885e-01, 9.6538e-02, 9.9120e-02, 5.0421e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:53,443][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.0692, 0.0179, 0.2586, 0.1782, 0.2043, 0.2718], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:53,444][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([2.0268e-04, 3.7207e-05, 4.3416e-02, 1.5988e-01, 1.1369e-02, 7.8510e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:53,445][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.4866, 0.0006, 0.2643, 0.0141, 0.1305, 0.1039], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:53,448][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.2734, 0.0091, 0.2666, 0.0825, 0.1367, 0.2318], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:53,453][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0233, 0.0020, 0.1945, 0.1344, 0.0950, 0.5508], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:53,455][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([5.8449e-04, 4.1814e-03, 8.6190e-02, 2.0674e-01, 3.0812e-02, 6.7150e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:53,459][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.9546, 0.0016, 0.0065, 0.0113, 0.0053, 0.0028, 0.0180],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,461][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([7.3371e-06, 2.2119e-02, 1.0984e-02, 1.4919e-01, 2.9063e-03, 1.7211e-01,
        6.4269e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,466][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2787, 0.0030, 0.1022, 0.0462, 0.4169, 0.1126, 0.0404],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,468][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0089, 0.0073, 0.1440, 0.0427, 0.0840, 0.3583, 0.3549],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,469][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([8.9414e-03, 6.4363e-06, 3.7483e-02, 1.8817e-02, 7.2361e-03, 2.2374e-01,
        7.0378e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,470][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([3.1037e-01, 1.9608e-05, 1.0256e-01, 1.5189e-02, 4.2792e-02, 1.0682e-01,
        4.2226e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,471][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2438, 0.0044, 0.2300, 0.0848, 0.1787, 0.1266, 0.1317],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,471][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([3.3541e-04, 2.0769e-06, 6.6390e-03, 7.2529e-03, 1.9303e-03, 4.5135e-02,
        9.3871e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,473][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([8.6238e-01, 3.7341e-05, 7.6559e-02, 1.2838e-03, 3.5917e-02, 1.2543e-02,
        1.1281e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,476][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.5840, 0.0019, 0.1569, 0.0225, 0.0886, 0.0630, 0.0831],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,480][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0697, 0.0005, 0.1397, 0.0454, 0.0727, 0.2250, 0.4470],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,482][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([5.0378e-04, 5.6116e-04, 3.0253e-02, 3.6001e-02, 1.0552e-02, 1.2478e-01,
        7.9735e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:53,486][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.7636, 0.0027, 0.0073, 0.0105, 0.0088, 0.0041, 0.0171, 0.1859],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,488][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([2.7917e-05, 3.6035e-02, 1.4463e-02, 1.4902e-01, 5.3008e-03, 1.2568e-01,
        5.2140e-01, 1.4807e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,492][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1136, 0.0069, 0.1098, 0.0662, 0.4417, 0.1386, 0.0722, 0.0509],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,495][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0122, 0.0080, 0.1220, 0.0367, 0.0740, 0.2636, 0.2168, 0.2667],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,496][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([1.0731e-02, 1.5031e-05, 2.1336e-02, 6.3900e-03, 4.3278e-03, 6.0821e-02,
        1.9097e-01, 7.0541e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,497][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([2.9962e-01, 3.9338e-05, 5.2883e-02, 6.2407e-03, 1.9423e-02, 3.2599e-02,
        1.0754e-01, 4.8166e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,498][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.3206, 0.0053, 0.2052, 0.0576, 0.1455, 0.0757, 0.0788, 0.1113],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,499][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([1.2261e-03, 1.6996e-05, 8.9155e-03, 4.9911e-03, 1.6878e-03, 2.2607e-02,
        2.8823e-01, 6.7232e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,501][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([8.7858e-01, 5.1453e-05, 5.3764e-02, 9.7577e-04, 2.6910e-02, 7.4726e-03,
        5.9412e-03, 2.6301e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,506][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.4813, 0.0029, 0.1329, 0.0201, 0.0720, 0.0523, 0.0609, 0.1775],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,509][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0700, 0.0006, 0.0868, 0.0256, 0.0384, 0.0941, 0.1474, 0.5371],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,513][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0016, 0.0008, 0.0307, 0.0273, 0.0134, 0.0810, 0.4154, 0.4297],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:53,517][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([0.6368, 0.0018, 0.0058, 0.0172, 0.0076, 0.0046, 0.0257, 0.2948, 0.0057],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,520][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([1.3803e-06, 2.4107e-02, 4.1412e-03, 9.5406e-02, 1.5260e-03, 8.7407e-02,
        4.4157e-01, 5.8090e-02, 2.8776e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,522][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([0.0951, 0.0057, 0.0980, 0.0670, 0.3452, 0.1401, 0.0688, 0.0457, 0.1346],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,523][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([0.0010, 0.0039, 0.0758, 0.0381, 0.0455, 0.2341, 0.2811, 0.2124, 0.1081],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,523][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([2.5521e-05, 1.0936e-06, 2.9169e-03, 2.9909e-03, 5.1567e-04, 5.2127e-02,
        3.2926e-01, 5.7780e-01, 3.4364e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,524][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([7.9828e-03, 4.9246e-06, 1.6877e-02, 4.3901e-03, 5.6057e-03, 3.6106e-02,
        2.1530e-01, 6.5001e-01, 6.3720e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,526][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([0.0633, 0.0059, 0.1523, 0.0702, 0.1122, 0.1298, 0.1399, 0.1624, 0.1639],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,528][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([9.8604e-07, 5.5661e-07, 7.5106e-04, 1.6661e-03, 1.1831e-04, 1.4186e-02,
        5.1199e-01, 4.4344e-01, 2.7843e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,531][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([4.3151e-01, 1.4447e-04, 1.5744e-01, 6.5294e-03, 7.3860e-02, 5.4586e-02,
        6.4535e-02, 1.7889e-01, 3.2504e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,535][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([0.1201, 0.0026, 0.1229, 0.0444, 0.0638, 0.0918, 0.1386, 0.3236, 0.0921],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,537][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([4.5023e-03, 2.1575e-04, 3.1004e-02, 2.0060e-02, 1.4458e-02, 8.8249e-02,
        1.9885e-01, 4.8652e-01, 1.5614e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,539][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([6.3352e-05, 2.2085e-04, 8.5805e-03, 1.8045e-02, 4.3113e-03, 6.0938e-02,
        5.0741e-01, 3.1160e-01, 8.8829e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:53,542][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([8.4686e-01, 5.6468e-04, 3.2708e-03, 4.7487e-03, 3.5157e-03, 1.1458e-03,
        6.6474e-03, 1.1602e-01, 1.2698e-03, 1.5960e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,544][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([6.1093e-06, 1.2650e-02, 5.9670e-03, 7.0055e-02, 1.8042e-03, 6.1055e-02,
        2.2079e-01, 5.4053e-02, 1.9360e-01, 3.8002e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,547][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1966, 0.0027, 0.0957, 0.0397, 0.4152, 0.0895, 0.0315, 0.0293, 0.0775,
        0.0223], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,549][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0062, 0.0041, 0.0709, 0.0255, 0.0441, 0.1452, 0.1601, 0.1794, 0.0447,
        0.3197], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,550][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([4.9545e-03, 8.2406e-07, 3.2723e-03, 1.4079e-03, 1.0013e-03, 1.4823e-02,
        6.2585e-02, 2.7746e-01, 4.6871e-03, 6.2981e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,551][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([3.3465e-01, 1.4283e-06, 9.2487e-03, 1.0114e-03, 4.7911e-03, 5.9699e-03,
        2.2475e-02, 1.8627e-01, 6.5835e-03, 4.2900e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,552][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.1774, 0.0036, 0.1262, 0.0518, 0.1127, 0.1022, 0.0951, 0.1409, 0.1028,
        0.0872], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,554][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([1.8861e-04, 2.0361e-07, 3.7329e-04, 3.7650e-04, 1.4583e-04, 1.8447e-03,
        3.3640e-02, 1.2268e-01, 2.0729e-03, 8.3868e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,555][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([9.2156e-01, 1.1957e-05, 2.5802e-02, 3.9317e-04, 1.5945e-02, 3.1826e-03,
        3.3427e-03, 1.9069e-02, 1.2666e-03, 9.4281e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,560][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.5228, 0.0009, 0.0856, 0.0122, 0.0454, 0.0311, 0.0380, 0.1357, 0.0209,
        0.1074], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,562][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([2.4101e-02, 8.0567e-05, 2.2677e-02, 7.6409e-03, 1.1695e-02, 2.8968e-02,
        5.5400e-02, 2.2633e-01, 4.2848e-02, 5.8026e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,565][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([3.8802e-04, 9.5287e-05, 7.8115e-03, 5.4117e-03, 2.8544e-03, 1.9893e-02,
        1.2504e-01, 1.8141e-01, 2.0174e-02, 6.3692e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:53,569][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.4890, 0.0060, 0.0089, 0.0239, 0.0087, 0.0046, 0.0234, 0.1981, 0.0049,
        0.0477, 0.1848], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,571][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([9.7233e-07, 3.5959e-02, 3.2060e-03, 6.5549e-02, 1.1084e-03, 4.2778e-02,
        2.5200e-01, 4.1645e-02, 1.8958e-01, 3.3939e-01, 2.8788e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,575][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.0928, 0.0140, 0.0976, 0.0643, 0.2725, 0.0940, 0.0527, 0.0411, 0.1078,
        0.0419, 0.1213], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,576][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.0020, 0.0070, 0.0321, 0.0264, 0.0225, 0.0889, 0.1369, 0.1242, 0.0502,
        0.2539, 0.2558], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,577][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([7.7206e-04, 4.9253e-06, 1.4158e-03, 6.3305e-04, 3.2255e-04, 4.5950e-03,
        1.9840e-02, 8.1598e-02, 1.7263e-03, 2.0883e-01, 6.8026e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,578][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([7.7855e-02, 4.2834e-06, 2.2040e-03, 2.6074e-04, 1.1025e-03, 7.4445e-04,
        4.4353e-03, 1.8363e-02, 1.0116e-03, 4.7711e-02, 8.4631e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,580][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.0146, 0.0200, 0.0862, 0.0595, 0.0607, 0.0965, 0.1379, 0.1120, 0.1207,
        0.1048, 0.1871], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,582][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([5.4089e-05, 1.3751e-06, 2.7223e-04, 1.3294e-04, 4.1584e-05, 3.7988e-04,
        8.1418e-03, 2.2143e-02, 4.4152e-04, 1.3118e-01, 8.3721e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,584][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([2.5052e-01, 9.9467e-05, 2.6834e-02, 1.1590e-03, 1.1318e-02, 6.2871e-03,
        7.2224e-03, 2.8947e-02, 4.7554e-03, 2.2856e-02, 6.4000e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,589][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.1139, 0.0023, 0.0482, 0.0110, 0.0278, 0.0213, 0.0299, 0.0735, 0.0224,
        0.0798, 0.5700], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,591][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([4.6883e-03, 2.0537e-04, 9.9921e-03, 4.6597e-03, 4.7477e-03, 1.4874e-02,
        2.9266e-02, 7.9571e-02, 2.0859e-02, 2.2061e-01, 6.1053e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,594][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([2.3162e-04, 4.6976e-04, 4.9398e-03, 6.7287e-03, 2.2037e-03, 1.8985e-02,
        8.7665e-02, 8.7745e-02, 2.2941e-02, 3.7956e-01, 3.8853e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:53,598][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.4029, 0.0033, 0.0066, 0.0171, 0.0071, 0.0037, 0.0249, 0.2568, 0.0048,
        0.0571, 0.1979, 0.0176], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,600][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([3.6319e-07, 1.5880e-02, 1.8966e-03, 4.7429e-02, 6.6995e-04, 3.8132e-02,
        1.8701e-01, 4.1236e-02, 1.4587e-01, 4.3823e-01, 2.8532e-02, 5.5117e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,602][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0392, 0.0065, 0.0728, 0.0502, 0.2387, 0.1050, 0.0587, 0.0387, 0.0961,
        0.0390, 0.1221, 0.1331], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,603][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0014, 0.0030, 0.0300, 0.0135, 0.0156, 0.0701, 0.0933, 0.0851, 0.0313,
        0.1998, 0.2934, 0.1636], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,604][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([9.8286e-05, 2.2422e-07, 4.5130e-04, 9.8660e-05, 5.5163e-05, 1.2522e-03,
        5.9194e-03, 2.3161e-02, 5.2495e-04, 7.1977e-02, 7.3097e-01, 1.6549e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,605][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([3.1538e-03, 1.8982e-07, 6.9303e-04, 3.4547e-05, 1.5684e-04, 2.4266e-04,
        1.3258e-03, 7.1142e-03, 3.4577e-04, 2.3277e-02, 9.1451e-01, 4.9146e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,608][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0151, 0.0050, 0.0759, 0.0413, 0.0485, 0.0647, 0.0782, 0.1018, 0.0841,
        0.0817, 0.2510, 0.1527], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,610][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([3.1745e-06, 2.8635e-08, 5.3461e-05, 1.2581e-05, 4.4000e-06, 6.9053e-05,
        2.0481e-03, 5.5924e-03, 1.1123e-04, 5.0499e-02, 8.8412e-01, 5.7490e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,613][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([1.3522e-01, 1.4723e-05, 1.3414e-02, 3.0176e-04, 5.2363e-03, 2.2186e-03,
        2.6364e-03, 1.2774e-02, 1.3327e-03, 1.0501e-02, 7.1463e-01, 1.0172e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,615][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([7.6581e-02, 5.1383e-04, 2.5319e-02, 4.6641e-03, 1.4514e-02, 1.0855e-02,
        1.6958e-02, 4.4813e-02, 9.0874e-03, 4.8924e-02, 5.5262e-01, 1.9515e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,618][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([1.3056e-03, 4.1342e-05, 5.1821e-03, 1.5859e-03, 1.9875e-03, 7.2041e-03,
        1.5473e-02, 5.0119e-02, 1.1472e-02, 1.5547e-01, 5.6021e-01, 1.8994e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,620][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([4.5067e-05, 9.0564e-05, 2.2261e-03, 2.4266e-03, 7.9932e-04, 8.9775e-03,
        5.6424e-02, 5.8087e-02, 1.0172e-02, 3.0897e-01, 3.8746e-01, 1.6433e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:53,624][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.5766, 0.0019, 0.0042, 0.0066, 0.0059, 0.0023, 0.0093, 0.0937, 0.0019,
        0.0179, 0.0824, 0.0078, 0.1894], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,627][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([7.1654e-06, 2.6650e-02, 5.2507e-03, 6.2309e-02, 2.4618e-03, 4.4026e-02,
        2.2084e-01, 6.0074e-02, 1.5662e-01, 2.7177e-01, 3.8247e-02, 6.4299e-02,
        4.7450e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,628][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0494, 0.0067, 0.0713, 0.0466, 0.2798, 0.0936, 0.0547, 0.0364, 0.0894,
        0.0377, 0.0944, 0.1072, 0.0328], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,629][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0070, 0.0036, 0.0465, 0.0120, 0.0295, 0.0733, 0.0663, 0.0864, 0.0269,
        0.1270, 0.2332, 0.1301, 0.1581], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,630][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([3.5235e-03, 1.7170e-06, 1.5166e-03, 2.1086e-04, 2.5151e-04, 1.4476e-03,
        4.4891e-03, 2.4765e-02, 4.8299e-04, 2.9416e-02, 4.0745e-01, 8.5936e-02,
        4.4050e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,631][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([7.3020e-02, 3.3121e-06, 2.7900e-03, 1.5206e-04, 8.7135e-04, 6.1622e-04,
        2.0911e-03, 1.2974e-02, 5.8096e-04, 2.0849e-02, 6.3965e-01, 4.9486e-02,
        1.9692e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,633][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1213, 0.0046, 0.0999, 0.0342, 0.0780, 0.0436, 0.0503, 0.0662, 0.0517,
        0.0448, 0.2117, 0.0922, 0.1014], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,635][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([3.8940e-04, 6.7825e-07, 3.0359e-04, 5.0359e-05, 4.5517e-05, 1.5946e-04,
        2.0270e-03, 8.7400e-03, 1.6234e-04, 2.4668e-02, 5.3921e-01, 3.7772e-02,
        3.8647e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,638][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([6.1598e-01, 2.2860e-05, 1.5303e-02, 2.6097e-04, 7.4293e-03, 1.6560e-03,
        1.3679e-03, 7.4484e-03, 7.3518e-04, 3.5475e-03, 2.5121e-01, 4.1919e-02,
        5.3122e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,642][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2142, 0.0011, 0.0365, 0.0049, 0.0227, 0.0122, 0.0143, 0.0418, 0.0088,
        0.0332, 0.3355, 0.1298, 0.1449], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,644][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([1.3863e-02, 9.6630e-05, 1.0127e-02, 2.2567e-03, 4.5409e-03, 8.1859e-03,
        1.1813e-02, 4.9727e-02, 9.6385e-03, 8.6407e-02, 3.9011e-01, 1.3022e-01,
        2.8302e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,647][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([8.2694e-04, 2.1177e-04, 5.9161e-03, 3.7694e-03, 2.4606e-03, 9.4605e-03,
        4.5663e-02, 5.9414e-02, 8.8645e-03, 1.7569e-01, 2.8973e-01, 1.0502e-01,
        2.9297e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:53,651][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.5866, 0.0013, 0.0040, 0.0066, 0.0043, 0.0011, 0.0063, 0.0756, 0.0015,
        0.0126, 0.0835, 0.0054, 0.1766, 0.0348], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,653][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([1.5846e-06, 2.7627e-02, 2.6888e-03, 3.7054e-02, 9.3460e-04, 3.1571e-02,
        1.9980e-01, 4.1757e-02, 1.2401e-01, 2.3630e-01, 2.3119e-02, 4.7782e-02,
        3.3693e-02, 1.9366e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,655][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.0839, 0.0062, 0.0769, 0.0489, 0.2706, 0.0758, 0.0417, 0.0310, 0.0694,
        0.0263, 0.0959, 0.1036, 0.0293, 0.0403], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,656][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([0.0097, 0.0033, 0.0428, 0.0083, 0.0195, 0.0519, 0.0441, 0.0744, 0.0155,
        0.0809, 0.2095, 0.0952, 0.1462, 0.1987], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,657][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([2.1420e-03, 1.3070e-07, 2.3252e-04, 7.4360e-06, 1.5447e-05, 6.4947e-05,
        2.1802e-04, 2.1949e-03, 2.4189e-05, 1.6445e-03, 5.0099e-02, 8.4269e-03,
        7.2263e-02, 8.6267e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,658][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([1.2195e-01, 3.1829e-07, 7.7408e-04, 6.6535e-06, 8.8222e-05, 3.6874e-05,
        1.1883e-04, 1.5227e-03, 3.0833e-05, 1.1087e-03, 1.1983e-01, 5.4109e-03,
        4.7038e-02, 7.0209e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,661][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.0852, 0.0047, 0.0902, 0.0275, 0.0585, 0.0390, 0.0423, 0.0605, 0.0415,
        0.0328, 0.1737, 0.0889, 0.0947, 0.1606], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,663][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([8.4377e-05, 2.0257e-08, 2.6440e-05, 5.0804e-07, 1.0931e-06, 2.2596e-06,
        3.3117e-05, 3.0296e-04, 2.2281e-06, 4.2715e-04, 4.0140e-02, 1.2735e-03,
        2.5345e-02, 9.3236e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,666][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([6.8795e-01, 7.1150e-06, 7.1649e-03, 5.9899e-05, 2.5336e-03, 4.2898e-04,
        3.7504e-04, 3.0078e-03, 1.9529e-04, 1.0226e-03, 1.1883e-01, 1.9309e-02,
        2.6666e-02, 1.3245e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,670][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.1962, 0.0004, 0.0230, 0.0018, 0.0099, 0.0047, 0.0051, 0.0206, 0.0036,
        0.0140, 0.2222, 0.0739, 0.0822, 0.3424], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,672][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([7.9421e-03, 3.0733e-05, 4.1653e-03, 5.5849e-04, 1.3073e-03, 1.9770e-03,
        3.3712e-03, 1.7520e-02, 2.5705e-03, 2.3353e-02, 1.7280e-01, 4.6603e-02,
        1.1745e-01, 6.0035e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,675][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([4.1751e-04, 5.0588e-05, 1.8715e-03, 5.9022e-04, 5.5955e-04, 1.5545e-03,
        9.4979e-03, 1.6644e-02, 1.8809e-03, 3.4620e-02, 1.1726e-01, 3.6233e-02,
        1.0815e-01, 6.7067e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:53,679][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.6268, 0.0012, 0.0031, 0.0039, 0.0038, 0.0012, 0.0055, 0.0695, 0.0011,
        0.0109, 0.0652, 0.0044, 0.1413, 0.0235, 0.0388], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,681][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.9616e-06, 1.5688e-02, 4.5382e-03, 4.2554e-02, 1.8539e-03, 3.7233e-02,
        1.4240e-01, 3.9486e-02, 1.2544e-01, 2.1824e-01, 3.7749e-02, 5.1813e-02,
        3.5638e-02, 1.4932e-01, 9.8040e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,682][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0694, 0.0047, 0.0691, 0.0387, 0.3237, 0.0799, 0.0410, 0.0311, 0.0691,
        0.0237, 0.0768, 0.0876, 0.0255, 0.0329, 0.0267], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,683][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0117, 0.0023, 0.0391, 0.0071, 0.0225, 0.0407, 0.0402, 0.0516, 0.0120,
        0.0673, 0.2116, 0.0718, 0.1014, 0.1288, 0.1918], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,684][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.2175e-03, 5.5529e-08, 1.5939e-04, 7.1149e-06, 1.4701e-05, 6.5451e-05,
        1.6720e-04, 1.8652e-03, 1.7483e-05, 1.9830e-03, 5.7833e-02, 6.7846e-03,
        6.1834e-02, 6.7407e-01, 1.9398e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,685][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([3.1629e-02, 1.6290e-07, 4.5031e-04, 7.5803e-06, 8.8983e-05, 4.2306e-05,
        1.1879e-04, 1.3697e-03, 3.0958e-05, 1.6874e-03, 1.2817e-01, 4.8349e-03,
        3.5812e-02, 6.9165e-01, 1.0410e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,688][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1552, 0.0028, 0.0937, 0.0217, 0.0778, 0.0303, 0.0285, 0.0433, 0.0343,
        0.0217, 0.1674, 0.0630, 0.0684, 0.1051, 0.0869], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,691][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([8.3955e-05, 8.2373e-09, 1.4883e-05, 6.7163e-07, 1.4820e-06, 3.0146e-06,
        3.8443e-05, 3.2028e-04, 2.7246e-06, 8.3039e-04, 4.3381e-02, 1.2218e-03,
        2.5804e-02, 7.5205e-01, 1.7625e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,693][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([6.5844e-01, 4.7834e-06, 6.6806e-03, 5.1129e-05, 2.9973e-03, 4.4131e-04,
        3.1828e-04, 2.4424e-03, 1.5808e-04, 8.9077e-04, 1.3322e-01, 1.5161e-02,
        2.3741e-02, 1.1661e-01, 3.8839e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,695][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.9004e-01, 2.7963e-04, 1.8348e-02, 1.4814e-03, 1.2306e-02, 3.7677e-03,
        4.2587e-03, 1.5174e-02, 2.2603e-03, 9.2330e-03, 2.0170e-01, 5.1131e-02,
        6.3206e-02, 2.2934e-01, 9.7477e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,697][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([7.1989e-03, 1.6477e-05, 2.9067e-03, 4.5010e-04, 1.2238e-03, 1.7618e-03,
        2.7900e-03, 1.3353e-02, 2.0497e-03, 2.3608e-02, 1.5588e-01, 3.5044e-02,
        9.8754e-02, 4.1585e-01, 2.3911e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,700][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.9152e-04, 3.1255e-05, 1.1365e-03, 5.2011e-04, 4.5187e-04, 1.4784e-03,
        7.0042e-03, 1.1911e-02, 1.1087e-03, 3.0405e-02, 8.2839e-02, 2.1813e-02,
        7.6856e-02, 4.4695e-01, 3.1720e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:53,703][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:53,706][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[11098],
        [ 6097],
        [10176],
        [  707],
        [    1],
        [22238],
        [12095],
        [17854],
        [23242],
        [ 2239],
        [ 7640],
        [ 4220],
        [11339],
        [ 3677],
        [ 5380]], device='cuda:0')
[2024-07-24 10:21:53,708][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[11430],
        [ 5817],
        [10275],
        [ 1074],
        [    1],
        [24169],
        [13880],
        [20116],
        [26894],
        [ 2730],
        [ 8518],
        [ 5537],
        [13599],
        [ 4960],
        [ 7499]], device='cuda:0')
[2024-07-24 10:21:53,711][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 5483],
        [ 5677],
        [ 4906],
        [ 5223],
        [ 9786],
        [26809],
        [22524],
        [22286],
        [20150],
        [24745],
        [19018],
        [24894],
        [20576],
        [17094],
        [21930]], device='cuda:0')
[2024-07-24 10:21:53,712][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[14823],
        [48780],
        [48692],
        [45837],
        [46507],
        [46148],
        [44543],
        [45120],
        [44145],
        [45521],
        [45574],
        [45631],
        [45434],
        [45696],
        [45489]], device='cuda:0')
[2024-07-24 10:21:53,713][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[5130],
        [5589],
        [6648],
        [7208],
        [5206],
        [4612],
        [5104],
        [5792],
        [5622],
        [6460],
        [6457],
        [6294],
        [6536],
        [7037],
        [6864]], device='cuda:0')
[2024-07-24 10:21:53,715][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[35069],
        [ 2890],
        [ 1397],
        [ 1619],
        [ 1389],
        [ 1441],
        [ 1367],
        [ 1162],
        [ 1663],
        [ 1908],
        [ 1271],
        [ 1334],
        [ 1129],
        [ 1614],
        [ 1440]], device='cuda:0')
[2024-07-24 10:21:53,717][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[38573],
        [13782],
        [18858],
        [ 4556],
        [ 2807],
        [ 7412],
        [ 5096],
        [ 5309],
        [ 5091],
        [ 7249],
        [14531],
        [16640],
        [10161],
        [16765],
        [13417]], device='cuda:0')
[2024-07-24 10:21:53,720][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 9807],
        [ 8725],
        [ 8275],
        [ 9585],
        [ 9271],
        [ 8464],
        [ 9381],
        [10615],
        [10519],
        [ 9691],
        [ 8495],
        [ 8782],
        [ 9641],
        [ 9224],
        [ 9834]], device='cuda:0')
[2024-07-24 10:21:53,723][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[20566],
        [20325],
        [25569],
        [14420],
        [15863],
        [18628],
        [19961],
        [20172],
        [18790],
        [19068],
        [19481],
        [18768],
        [19508],
        [18812],
        [18944]], device='cuda:0')
[2024-07-24 10:21:53,725][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[12155],
        [29339],
        [29015],
        [29040],
        [31060],
        [29890],
        [29973],
        [28120],
        [27083],
        [27476],
        [28152],
        [28557],
        [26474],
        [23451],
        [24578]], device='cuda:0')
[2024-07-24 10:21:53,728][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[17840],
        [12261],
        [10583],
        [ 9157],
        [13401],
        [10631],
        [10189],
        [13777],
        [ 9571],
        [10428],
        [12515],
        [10266],
        [11676],
        [ 7032],
        [ 8457]], device='cuda:0')
[2024-07-24 10:21:53,730][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[12010],
        [ 6178],
        [19918],
        [19864],
        [17748],
        [14886],
        [12690],
        [12569],
        [12929],
        [11380],
        [13946],
        [14688],
        [14014],
        [16063],
        [15131]], device='cuda:0')
[2024-07-24 10:21:53,733][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[32130],
        [30431],
        [24589],
        [16768],
        [47270],
        [22313],
        [11176],
        [22237],
        [ 9538],
        [ 6999],
        [14930],
        [12499],
        [11310],
        [11759],
        [ 5390]], device='cuda:0')
[2024-07-24 10:21:53,736][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[39554],
        [48210],
        [49655],
        [48197],
        [48450],
        [50215],
        [49943],
        [49784],
        [49796],
        [49810],
        [49993],
        [49991],
        [49830],
        [49501],
        [49171]], device='cuda:0')
[2024-07-24 10:21:53,738][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[23502],
        [40922],
        [35363],
        [22754],
        [26265],
        [23360],
        [25918],
        [22683],
        [24420],
        [18149],
        [25299],
        [21444],
        [16035],
        [16577],
        [16484]], device='cuda:0')
[2024-07-24 10:21:53,741][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[12411],
        [11155],
        [ 1343],
        [ 2434],
        [ 1938],
        [ 1600],
        [ 3993],
        [ 1293],
        [ 1119],
        [ 1598],
        [ 1246],
        [ 1281],
        [ 1550],
        [ 1663],
        [ 1530]], device='cuda:0')
[2024-07-24 10:21:53,742][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[19082],
        [10379],
        [ 9563],
        [20221],
        [19315],
        [15896],
        [ 8986],
        [ 7591],
        [10463],
        [10402],
        [10280],
        [10776],
        [10052],
        [ 8980],
        [ 8752]], device='cuda:0')
[2024-07-24 10:21:53,744][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[27800],
        [29929],
        [19019],
        [23231],
        [11186],
        [16691],
        [19248],
        [19255],
        [24849],
        [22355],
        [23336],
        [20920],
        [21337],
        [20614],
        [20963]], device='cuda:0')
[2024-07-24 10:21:53,745][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[44353],
        [46095],
        [35667],
        [34257],
        [36253],
        [45314],
        [41666],
        [41071],
        [39699],
        [40114],
        [38317],
        [39178],
        [39202],
        [38215],
        [37982]], device='cuda:0')
[2024-07-24 10:21:53,748][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[14336],
        [30933],
        [16116],
        [23452],
        [25596],
        [22942],
        [20737],
        [22913],
        [22692],
        [21855],
        [19872],
        [20724],
        [20025],
        [15795],
        [16919]], device='cuda:0')
[2024-07-24 10:21:53,751][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[36755],
        [37517],
        [37924],
        [34832],
        [33776],
        [37728],
        [34829],
        [34577],
        [32956],
        [32749],
        [43302],
        [43422],
        [42133],
        [41111],
        [39795]], device='cuda:0')
[2024-07-24 10:21:53,753][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[29953],
        [28054],
        [28805],
        [33177],
        [33901],
        [33385],
        [32892],
        [32890],
        [33474],
        [33596],
        [32626],
        [32786],
        [32584],
        [34647],
        [33635]], device='cuda:0')
[2024-07-24 10:21:53,756][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 6274],
        [24853],
        [25177],
        [19998],
        [19587],
        [24121],
        [17859],
        [21274],
        [19569],
        [16947],
        [16941],
        [17685],
        [19206],
        [21075],
        [21267]], device='cuda:0')
[2024-07-24 10:21:53,759][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[27826],
        [27885],
        [46917],
        [45660],
        [46247],
        [46648],
        [35867],
        [35131],
        [46430],
        [31041],
        [42172],
        [42014],
        [41160],
        [43770],
        [43924]], device='cuda:0')
[2024-07-24 10:21:53,761][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[45722],
        [48394],
        [40020],
        [38955],
        [35483],
        [38046],
        [40023],
        [40237],
        [38968],
        [41406],
        [37266],
        [36893],
        [38407],
        [39714],
        [40056]], device='cuda:0')
[2024-07-24 10:21:53,764][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[14876],
        [ 9888],
        [18358],
        [19211],
        [21620],
        [24627],
        [27987],
        [27742],
        [28630],
        [26536],
        [23194],
        [22819],
        [23648],
        [24937],
        [26574]], device='cuda:0')
[2024-07-24 10:21:53,766][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 9437],
        [41303],
        [46304],
        [47229],
        [46113],
        [43066],
        [46683],
        [44806],
        [45401],
        [46536],
        [47389],
        [47777],
        [46777],
        [43485],
        [45128]], device='cuda:0')
[2024-07-24 10:21:53,769][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[15627],
        [ 5740],
        [11088],
        [ 7745],
        [12840],
        [ 6346],
        [ 8600],
        [13372],
        [10568],
        [11522],
        [13278],
        [12402],
        [12484],
        [13404],
        [12795]], device='cuda:0')
[2024-07-24 10:21:53,772][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[26519],
        [ 2333],
        [ 9912],
        [14247],
        [14780],
        [17005],
        [22436],
        [22737],
        [19638],
        [26702],
        [18374],
        [20058],
        [25477],
        [24386],
        [27128]], device='cuda:0')
[2024-07-24 10:21:53,773][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[44491],
        [44491],
        [44491],
        [44491],
        [44491],
        [44491],
        [44491],
        [44491],
        [44491],
        [44491],
        [44491],
        [44491],
        [44491],
        [44491],
        [44491]], device='cuda:0')
[2024-07-24 10:21:53,881][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:53,884][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,885][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,886][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,887][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,887][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,888][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,889][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,889][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,890][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,890][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,891][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,892][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:53,892][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9933, 0.0067], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,893][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0756, 0.9244], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,894][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9428, 0.0572], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,894][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9916, 0.0084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,897][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0224, 0.9776], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,898][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2788, 0.7212], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,899][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([1.1791e-04, 9.9988e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,899][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9358, 0.0642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,902][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9983, 0.0017], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,904][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9963, 0.0037], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,905][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4230, 0.5770], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,906][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([6.1163e-05, 9.9994e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:53,906][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.4209, 0.0181, 0.5610], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,908][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([4.2771e-04, 7.5300e-01, 2.4657e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,910][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.0904, 0.0345, 0.8750], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,913][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.7589, 0.0106, 0.2305], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,917][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.0014, 0.7691, 0.2294], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,921][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.1179, 0.3734, 0.5087], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,923][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([9.0293e-07, 9.7384e-01, 2.6163e-02], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,927][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.4981, 0.1908, 0.3111], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,931][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.9636, 0.0105, 0.0259], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,931][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.5819, 0.0222, 0.3959], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,932][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.0044, 0.0110, 0.9846], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,933][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([3.1827e-06, 9.5826e-01, 4.1734e-02], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:53,933][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3741, 0.0049, 0.5816, 0.0394], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,935][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0024, 0.1635, 0.3736, 0.4605], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,938][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0928, 0.0048, 0.8427, 0.0596], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,940][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([5.0758e-01, 7.2972e-05, 3.2647e-01, 1.6587e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,944][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0040, 0.3531, 0.4405, 0.2024], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,948][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1001, 0.2424, 0.3312, 0.3262], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,950][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([1.1412e-06, 1.1044e-01, 3.2246e-02, 8.5731e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,953][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.6671, 0.0461, 0.1234, 0.1633], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,956][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([9.9469e-01, 2.0798e-03, 2.7317e-03, 4.9719e-04], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,957][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9697, 0.0010, 0.0275, 0.0018], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,958][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([1.3833e-03, 9.8318e-06, 6.1434e-01, 3.8427e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,959][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([2.4709e-07, 4.4595e-02, 6.0161e-03, 9.4939e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:53,960][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.1011, 0.0368, 0.5073, 0.1669, 0.1879], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,961][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([6.0561e-05, 3.9795e-01, 7.6964e-02, 4.1773e-01, 1.0730e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,964][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.0175, 0.0263, 0.4945, 0.2247, 0.2370], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,968][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0476, 0.0013, 0.2518, 0.6438, 0.0555], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,972][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.0008, 0.6803, 0.1003, 0.1139, 0.1047], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,975][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0625, 0.1788, 0.2574, 0.2434, 0.2579], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,977][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([5.7947e-08, 3.7177e-01, 4.4981e-03, 6.1945e-01, 4.2799e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,981][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.0945, 0.0915, 0.1478, 0.5313, 0.1350], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,983][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.7272, 0.0636, 0.0513, 0.0424, 0.1154], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,984][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0627, 0.0106, 0.1291, 0.1172, 0.6804], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,985][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([3.4276e-05, 1.3547e-04, 7.6645e-02, 9.0402e-01, 1.9165e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,985][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([1.2757e-07, 7.2668e-02, 4.9030e-03, 9.1724e-01, 5.1872e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:53,986][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.2565, 0.0065, 0.3233, 0.0650, 0.1285, 0.2203], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:53,988][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ went] are: tensor([3.2751e-04, 9.8558e-02, 8.2282e-02, 1.7135e-01, 9.9363e-02, 5.4812e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:53,990][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0449, 0.0064, 0.4368, 0.0689, 0.1918, 0.2512], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:53,992][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ went] are: tensor([6.5401e-01, 8.5154e-05, 2.0738e-01, 5.3396e-02, 1.8048e-02, 6.7079e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:53,996][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0009, 0.1900, 0.1272, 0.0682, 0.1310, 0.4827], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:54,000][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0599, 0.1432, 0.1980, 0.1916, 0.1960, 0.2114], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:54,002][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ went] are: tensor([1.8732e-07, 6.9172e-02, 6.7294e-03, 3.8923e-01, 6.1880e-03, 5.2868e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:54,006][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.1271, 0.0497, 0.0548, 0.3922, 0.0587, 0.3175], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:54,010][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.9068, 0.0067, 0.0141, 0.0025, 0.0201, 0.0498], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:54,011][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.6121, 0.0074, 0.0975, 0.0243, 0.2339, 0.0248], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:54,011][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ went] are: tensor([4.3377e-04, 7.4806e-06, 1.5095e-01, 1.1142e-01, 8.4439e-03, 7.2874e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:54,012][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ went] are: tensor([1.0661e-07, 4.3408e-02, 5.9426e-03, 8.6889e-01, 7.4244e-03, 7.4330e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:54,013][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.3929, 0.0016, 0.3269, 0.0133, 0.1208, 0.0926, 0.0519],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,016][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0007, 0.0246, 0.0895, 0.0806, 0.1434, 0.4142, 0.2469],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,018][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0534, 0.0019, 0.5321, 0.0282, 0.1806, 0.1621, 0.0418],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,021][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([8.7363e-01, 5.5926e-06, 3.4477e-02, 3.1512e-03, 3.2106e-03, 5.0603e-03,
        8.0463e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,025][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0031, 0.0680, 0.1642, 0.0421, 0.2021, 0.3423, 0.1781],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,028][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0509, 0.1186, 0.1645, 0.1563, 0.1582, 0.1695, 0.1820],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,030][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([1.2744e-07, 6.9443e-03, 3.2406e-03, 7.8464e-02, 2.1476e-03, 1.5103e-01,
        7.5817e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,034][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.3353, 0.0206, 0.0636, 0.0784, 0.0423, 0.2964, 0.1634],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,036][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([9.8835e-01, 5.9455e-04, 1.5484e-03, 1.6576e-04, 3.0912e-03, 5.2264e-03,
        1.0285e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,037][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.7300, 0.0020, 0.0541, 0.0055, 0.1686, 0.0352, 0.0047],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,038][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([5.8114e-03, 8.9437e-07, 5.7367e-02, 8.7933e-03, 4.0337e-03, 9.8197e-02,
        8.2580e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,038][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.4771e-07, 4.1343e-02, 5.3228e-03, 6.2032e-01, 5.4061e-03, 5.5554e-02,
        2.7205e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,040][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.3690, 0.0025, 0.2603, 0.0133, 0.0890, 0.0829, 0.0400, 0.1430],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,043][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0011, 0.0409, 0.0678, 0.1144, 0.1112, 0.3492, 0.1998, 0.1156],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,047][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0571, 0.0038, 0.3740, 0.0290, 0.2020, 0.1788, 0.0494, 0.1060],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,050][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ the] are: tensor([9.0375e-01, 1.3401e-05, 1.2857e-02, 5.9650e-04, 1.0414e-03, 1.0174e-03,
        1.1403e-02, 6.9319e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,054][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0017, 0.0720, 0.1206, 0.0397, 0.1086, 0.3479, 0.1752, 0.1342],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,057][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0501, 0.0987, 0.1369, 0.1306, 0.1310, 0.1399, 0.1481, 0.1647],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,059][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ the] are: tensor([2.5101e-07, 1.1172e-02, 5.0206e-03, 8.6459e-02, 3.4237e-03, 1.5391e-01,
        6.5504e-01, 8.4974e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,063][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.5251, 0.0138, 0.0258, 0.0779, 0.0166, 0.1689, 0.1237, 0.0482],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,064][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ the] are: tensor([9.8936e-01, 2.7957e-04, 1.0539e-03, 1.2361e-04, 2.8256e-03, 3.7579e-03,
        8.4596e-04, 1.7574e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,065][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.6620, 0.0017, 0.0234, 0.0039, 0.2852, 0.0202, 0.0026, 0.0009],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,066][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ the] are: tensor([4.7829e-03, 2.3254e-06, 1.9479e-02, 1.9653e-03, 9.1468e-04, 1.7452e-02,
        1.4287e-01, 8.1253e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,067][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.7501e-07, 2.6179e-02, 5.3964e-03, 4.6542e-01, 5.1691e-03, 3.7227e-02,
        2.1397e-01, 2.4664e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,070][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ house] are: tensor([0.0925, 0.0020, 0.2545, 0.0296, 0.0954, 0.1271, 0.0855, 0.2612, 0.0523],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,072][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ house] are: tensor([1.3575e-04, 2.6306e-02, 2.6168e-02, 8.3793e-02, 5.7930e-02, 3.0811e-01,
        1.9145e-01, 7.0322e-02, 2.3579e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,076][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.0072, 0.0026, 0.2400, 0.0519, 0.1482, 0.2476, 0.0988, 0.1310, 0.0727],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,079][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ house] are: tensor([4.0532e-03, 3.5870e-06, 1.1637e-02, 3.7449e-03, 6.7779e-04, 7.0531e-03,
        3.1228e-01, 6.5818e-01, 2.3777e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,083][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ house] are: tensor([0.0005, 0.0671, 0.1089, 0.0426, 0.1098, 0.2522, 0.1309, 0.1128, 0.1752],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,087][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ house] are: tensor([0.0355, 0.0828, 0.1194, 0.1158, 0.1174, 0.1252, 0.1298, 0.1416, 0.1325],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,089][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ house] are: tensor([2.5176e-08, 8.0829e-03, 1.3744e-03, 7.4905e-02, 1.4298e-03, 1.3166e-01,
        6.6388e-01, 5.2615e-02, 6.6045e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,090][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ house] are: tensor([0.0306, 0.0164, 0.0274, 0.1948, 0.0198, 0.1585, 0.3331, 0.1673, 0.0521],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,091][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.7645, 0.0083, 0.0054, 0.0021, 0.0271, 0.0742, 0.0218, 0.0474, 0.0493],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,092][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ house] are: tensor([0.1141, 0.0150, 0.1501, 0.0158, 0.2463, 0.1017, 0.0122, 0.0029, 0.3419],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,093][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ house] are: tensor([6.0454e-07, 4.9533e-08, 1.7790e-03, 9.5605e-04, 5.4848e-05, 1.3798e-02,
        2.7887e-01, 7.0014e-01, 4.4003e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,095][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ house] are: tensor([1.1565e-07, 2.1965e-02, 2.4129e-03, 4.3364e-01, 4.9659e-03, 3.3727e-02,
        2.2009e-01, 2.2229e-01, 6.0912e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,098][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.4171, 0.0013, 0.2640, 0.0076, 0.0838, 0.0529, 0.0222, 0.0922, 0.0098,
        0.0491], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,101][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0004, 0.0128, 0.0479, 0.0509, 0.0965, 0.2183, 0.1303, 0.0695, 0.1954,
        0.1779], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,105][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0501, 0.0026, 0.3556, 0.0309, 0.1863, 0.1333, 0.0372, 0.0848, 0.0235,
        0.0957], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,108][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [.] are: tensor([9.0564e-01, 1.7204e-07, 8.7669e-04, 4.6034e-05, 1.4669e-04, 7.2877e-05,
        1.1794e-03, 1.6950e-02, 1.1243e-05, 7.5074e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,112][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0006, 0.0537, 0.1080, 0.0353, 0.1087, 0.2391, 0.1293, 0.1129, 0.1169,
        0.0954], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,116][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0390, 0.0781, 0.1043, 0.1022, 0.0994, 0.1078, 0.1166, 0.1278, 0.1130,
        0.1120], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,117][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [.] are: tensor([4.6839e-08, 4.4339e-03, 2.6976e-03, 4.8034e-02, 1.8362e-03, 1.0877e-01,
        4.7341e-01, 5.2266e-02, 4.8918e-02, 2.5964e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,118][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.4312, 0.0070, 0.0277, 0.0206, 0.0160, 0.1134, 0.0711, 0.0472, 0.0182,
        0.2475], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,119][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [.] are: tensor([9.8296e-01, 5.5060e-04, 1.4098e-03, 1.8502e-04, 2.3847e-03, 4.6479e-03,
        9.7312e-04, 3.4002e-03, 2.5845e-03, 9.0446e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,121][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.2758, 0.0015, 0.0461, 0.0039, 0.3399, 0.0264, 0.0044, 0.0020, 0.2939,
        0.0062], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,123][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [.] are: tensor([2.7978e-03, 7.0798e-08, 2.9067e-03, 3.2914e-04, 2.4474e-04, 3.0922e-03,
        2.8630e-02, 3.2054e-01, 4.4150e-04, 6.4102e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,125][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [.] are: tensor([9.1742e-08, 1.5627e-02, 3.1559e-03, 3.3762e-01, 3.3767e-03, 3.3599e-02,
        1.3570e-01, 1.6483e-01, 4.8389e-02, 2.5771e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,129][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.1229, 0.0029, 0.1300, 0.0073, 0.0317, 0.0274, 0.0206, 0.0667, 0.0114,
        0.0425, 0.5367], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,132][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([7.7306e-05, 5.9110e-02, 2.2773e-02, 6.8420e-02, 2.8667e-02, 1.6540e-01,
        1.8041e-01, 7.1361e-02, 1.5414e-01, 1.8221e-01, 6.7434e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,135][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.0265, 0.0052, 0.1308, 0.0199, 0.0674, 0.0552, 0.0275, 0.0503, 0.0201,
        0.0689, 0.5283], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,137][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([4.4065e-01, 4.0552e-06, 1.1694e-03, 2.0994e-05, 4.8944e-05, 2.3715e-05,
        5.0771e-04, 5.1314e-03, 3.9326e-06, 1.4777e-02, 5.3766e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,141][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.0003, 0.1761, 0.0488, 0.0360, 0.0332, 0.1990, 0.1254, 0.0620, 0.1224,
        0.1334, 0.0633], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,144][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.0278, 0.0691, 0.0962, 0.0910, 0.0901, 0.0969, 0.1021, 0.1116, 0.1012,
        0.0950, 0.1188], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,144][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([2.1147e-08, 3.0997e-02, 9.5357e-04, 5.1981e-02, 9.1972e-04, 7.3877e-02,
        4.5319e-01, 4.1668e-02, 5.6450e-02, 2.7821e-01, 1.1747e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,145][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.1106, 0.0146, 0.0374, 0.0656, 0.0242, 0.1186, 0.1187, 0.0547, 0.0289,
        0.3537, 0.0731], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,146][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.8089, 0.0033, 0.0148, 0.0021, 0.0154, 0.0331, 0.0047, 0.0323, 0.0188,
        0.0068, 0.0598], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,148][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.0972, 0.0035, 0.0647, 0.0221, 0.2322, 0.0524, 0.0150, 0.0058, 0.2821,
        0.0099, 0.2153], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,150][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([4.2754e-04, 2.1543e-07, 2.9977e-04, 1.5916e-05, 6.7950e-06, 1.4042e-04,
        2.3074e-03, 1.9215e-02, 2.5548e-05, 3.8700e-02, 9.3886e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,153][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([1.0943e-07, 3.0627e-02, 2.0905e-03, 2.7839e-01, 2.4547e-03, 2.1069e-02,
        1.6099e-01, 1.1805e-01, 5.5065e-02, 3.1541e-01, 1.5841e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,157][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0351, 0.0007, 0.0480, 0.0043, 0.0208, 0.0204, 0.0189, 0.0537, 0.0074,
        0.0409, 0.4432, 0.3065], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,160][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([5.9277e-05, 2.3035e-02, 1.8163e-02, 5.1494e-02, 2.5955e-02, 1.5505e-01,
        1.3184e-01, 6.4025e-02, 1.2027e-01, 1.6303e-01, 8.2387e-02, 1.6469e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,164][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0109, 0.0014, 0.0950, 0.0094, 0.0552, 0.0395, 0.0147, 0.0237, 0.0094,
        0.0334, 0.5401, 0.1673], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,166][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([1.0889e-02, 1.2930e-07, 3.6938e-04, 3.0414e-06, 5.4501e-06, 5.5921e-06,
        1.9409e-04, 1.8084e-03, 1.1348e-06, 1.0488e-02, 9.6548e-01, 1.0760e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,169][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([1.5941e-04, 5.8838e-02, 4.0689e-02, 2.9082e-02, 3.9255e-02, 1.9370e-01,
        1.3405e-01, 8.5314e-02, 1.2715e-01, 9.4649e-02, 5.9164e-02, 1.3795e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,170][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0268, 0.0597, 0.0842, 0.0803, 0.0822, 0.0868, 0.0915, 0.1015, 0.0922,
        0.0864, 0.1071, 0.1016], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,171][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([1.2951e-08, 8.2817e-03, 7.7582e-04, 4.4802e-02, 7.9278e-04, 7.2390e-02,
        4.2405e-01, 4.1422e-02, 4.0301e-02, 2.6255e-01, 1.5540e-02, 8.9097e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,172][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0249, 0.0134, 0.0285, 0.0600, 0.0129, 0.0945, 0.1217, 0.0669, 0.0206,
        0.3801, 0.0772, 0.0994], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,174][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.8657, 0.0018, 0.0057, 0.0009, 0.0098, 0.0151, 0.0038, 0.0261, 0.0112,
        0.0051, 0.0359, 0.0188], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,178][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.6686, 0.0024, 0.0161, 0.0038, 0.1078, 0.0062, 0.0034, 0.0015, 0.1051,
        0.0049, 0.0702, 0.0101], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,180][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([3.2122e-06, 3.3240e-09, 7.9227e-05, 1.6145e-06, 6.6796e-07, 1.9124e-05,
        4.0376e-04, 3.4082e-03, 4.4286e-06, 9.4127e-03, 9.5843e-01, 2.8237e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,183][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([1.5515e-08, 1.0295e-02, 1.2911e-03, 2.3539e-01, 1.7732e-03, 1.9155e-02,
        1.1289e-01, 1.3032e-01, 2.4220e-02, 2.9321e-01, 1.6733e-02, 1.5473e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,186][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1375, 0.0014, 0.0836, 0.0046, 0.0329, 0.0254, 0.0139, 0.0487, 0.0081,
        0.0271, 0.2892, 0.2049, 0.1227], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,190][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0004, 0.0259, 0.0293, 0.0541, 0.0480, 0.1685, 0.1057, 0.0542, 0.0935,
        0.1148, 0.0759, 0.1928, 0.0368], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,194][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0347, 0.0022, 0.1152, 0.0084, 0.0757, 0.0445, 0.0148, 0.0287, 0.0116,
        0.0280, 0.4069, 0.1319, 0.0973], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,197][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([5.0910e-01, 2.8136e-06, 1.3861e-03, 1.5646e-05, 6.0761e-05, 2.3549e-05,
        2.7533e-04, 2.8289e-03, 4.0052e-06, 6.4215e-03, 3.0255e-01, 6.7017e-03,
        1.7063e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,199][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0006, 0.0482, 0.0587, 0.0266, 0.0572, 0.1706, 0.0987, 0.0823, 0.1062,
        0.0752, 0.0759, 0.1379, 0.0619], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,200][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0312, 0.0548, 0.0766, 0.0716, 0.0727, 0.0770, 0.0808, 0.0903, 0.0838,
        0.0780, 0.0958, 0.0895, 0.0979], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,201][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([2.0764e-07, 1.0579e-02, 2.9358e-03, 5.1972e-02, 2.9242e-03, 8.4366e-02,
        3.9533e-01, 5.1061e-02, 5.1189e-02, 1.9255e-01, 2.2821e-02, 1.1281e-01,
        2.1462e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,201][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.3079, 0.0076, 0.0316, 0.0265, 0.0086, 0.0483, 0.0463, 0.0295, 0.0121,
        0.2175, 0.0853, 0.0641, 0.1146], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,203][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([9.5134e-01, 3.3161e-04, 1.6530e-03, 1.6385e-04, 2.3079e-03, 3.4095e-03,
        1.3056e-03, 2.8969e-03, 1.7563e-03, 8.4849e-04, 8.0793e-03, 6.5748e-03,
        1.9332e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,205][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([7.6799e-01, 7.9949e-04, 1.3551e-02, 9.7062e-04, 6.3700e-02, 6.8619e-03,
        5.7245e-04, 4.4337e-04, 9.5460e-02, 1.4553e-03, 3.5821e-02, 1.2030e-02,
        3.4561e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,207][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([5.0875e-04, 1.0754e-07, 3.1786e-04, 9.1251e-06, 9.4648e-06, 6.8763e-05,
        7.3488e-04, 5.4754e-03, 1.2463e-05, 8.4263e-03, 4.6312e-01, 1.8591e-02,
        5.0273e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,210][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.1888e-07, 1.2983e-02, 3.1486e-03, 2.1641e-01, 3.4275e-03, 2.2029e-02,
        1.1995e-01, 1.3230e-01, 2.8218e-02, 2.6123e-01, 2.2357e-02, 1.3396e-01,
        4.3996e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,213][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.3973, 0.0008, 0.0699, 0.0015, 0.0182, 0.0098, 0.0044, 0.0216, 0.0030,
        0.0103, 0.1735, 0.0900, 0.0727, 0.1270], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,217][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0003, 0.0231, 0.0319, 0.0403, 0.0365, 0.1426, 0.0781, 0.0459, 0.1184,
        0.0929, 0.0826, 0.1843, 0.0357, 0.0875], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,221][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.0643, 0.0020, 0.1152, 0.0043, 0.0754, 0.0236, 0.0086, 0.0192, 0.0074,
        0.0197, 0.4109, 0.1026, 0.0822, 0.0644], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,224][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([6.0974e-01, 1.6697e-07, 2.1275e-04, 1.1516e-07, 1.6509e-06, 2.8621e-07,
        3.6095e-06, 1.2849e-04, 4.4004e-08, 1.1175e-04, 2.7151e-02, 3.0412e-04,
        2.1518e-02, 3.4083e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,226][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0007, 0.0566, 0.0714, 0.0233, 0.0628, 0.1266, 0.0826, 0.0587, 0.1231,
        0.0706, 0.0865, 0.1366, 0.0535, 0.0470], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,227][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.0281, 0.0499, 0.0724, 0.0658, 0.0714, 0.0716, 0.0739, 0.0799, 0.0765,
        0.0667, 0.0869, 0.0813, 0.0845, 0.0911], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,228][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([9.5934e-08, 8.1033e-03, 2.7147e-03, 3.3087e-02, 2.0202e-03, 7.9415e-02,
        3.7229e-01, 5.1380e-02, 5.6737e-02, 1.8903e-01, 2.6299e-02, 1.2806e-01,
        2.2758e-02, 2.8102e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,229][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0846, 0.0092, 0.0179, 0.0342, 0.0066, 0.0438, 0.0879, 0.0494, 0.0093,
        0.2618, 0.0371, 0.0693, 0.1746, 0.1143], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,230][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([6.3295e-01, 7.7023e-04, 1.8816e-03, 2.4099e-04, 5.2594e-03, 7.8945e-03,
        1.9412e-03, 7.8048e-03, 7.1689e-03, 2.1878e-03, 1.1848e-02, 1.4848e-02,
        5.0505e-02, 2.5470e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,233][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.0281, 0.0023, 0.0230, 0.0037, 0.0492, 0.0157, 0.0037, 0.0013, 0.0539,
        0.0055, 0.1052, 0.0130, 0.0027, 0.6926], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,235][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([2.9278e-04, 1.4691e-08, 1.0632e-04, 1.2495e-07, 4.1957e-07, 1.9247e-06,
        2.3343e-05, 4.2073e-04, 3.0775e-07, 2.8328e-04, 4.7340e-02, 1.3711e-03,
        7.6370e-02, 8.7379e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,237][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([2.5986e-08, 1.1840e-02, 1.2001e-03, 2.1128e-01, 1.9313e-03, 1.2936e-02,
        9.7180e-02, 1.1319e-01, 2.8695e-02, 2.7007e-01, 1.2384e-02, 1.1838e-01,
        3.4976e-02, 8.5938e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,242][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2434, 0.0005, 0.0638, 0.0020, 0.0278, 0.0129, 0.0060, 0.0247, 0.0032,
        0.0116, 0.2155, 0.1137, 0.0809, 0.1069, 0.0871], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,246][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0004, 0.0163, 0.0332, 0.0384, 0.0594, 0.1506, 0.0830, 0.0414, 0.0931,
        0.0857, 0.0938, 0.1440, 0.0304, 0.0633, 0.0669], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,250][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0499, 0.0015, 0.1103, 0.0062, 0.0666, 0.0364, 0.0097, 0.0203, 0.0068,
        0.0183, 0.3600, 0.1048, 0.0839, 0.0608, 0.0645], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,252][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([4.2171e-01, 1.1943e-07, 1.8106e-04, 3.5359e-07, 3.5256e-06, 7.2327e-07,
        7.0485e-06, 1.9081e-04, 8.3511e-08, 2.9845e-04, 4.7150e-02, 3.5896e-04,
        2.4005e-02, 4.4971e-01, 5.6383e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,253][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0011, 0.0451, 0.0629, 0.0251, 0.0802, 0.1421, 0.0897, 0.0637, 0.0853,
        0.0529, 0.0758, 0.1155, 0.0469, 0.0235, 0.0902], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,254][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0259, 0.0460, 0.0647, 0.0602, 0.0614, 0.0641, 0.0689, 0.0752, 0.0679,
        0.0666, 0.0808, 0.0741, 0.0811, 0.0797, 0.0834], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,255][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([1.6673e-07, 5.3342e-03, 2.6417e-03, 4.0058e-02, 2.3970e-03, 7.7560e-02,
        3.2471e-01, 4.0492e-02, 3.9074e-02, 1.5705e-01, 2.5766e-02, 9.9790e-02,
        1.8290e-02, 2.1838e-02, 1.4499e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,257][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.3766, 0.0052, 0.0197, 0.0100, 0.0078, 0.0585, 0.0244, 0.0183, 0.0076,
        0.0880, 0.0510, 0.0588, 0.0823, 0.0871, 0.1048], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,259][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([8.4841e-01, 3.7591e-04, 1.6230e-03, 1.5352e-04, 2.4452e-03, 4.5491e-03,
        1.2019e-03, 3.6430e-03, 2.4807e-03, 6.5726e-04, 8.1394e-03, 6.8589e-03,
        2.5069e-02, 8.9010e-02, 5.3833e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,263][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.4224, 0.0010, 0.0214, 0.0017, 0.0863, 0.0158, 0.0013, 0.0013, 0.0951,
        0.0016, 0.0742, 0.0262, 0.0017, 0.2477, 0.0024], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,266][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([3.9816e-04, 3.0588e-09, 3.9007e-05, 1.5576e-07, 5.8195e-07, 1.8947e-06,
        1.5422e-05, 2.9369e-04, 2.1173e-07, 2.9581e-04, 5.5594e-02, 8.6249e-04,
        5.4566e-02, 6.7222e-01, 2.1571e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,268][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([4.4770e-08, 1.2804e-02, 2.6075e-03, 2.0846e-01, 2.7874e-03, 2.1570e-02,
        8.9691e-02, 1.1181e-01, 2.1485e-02, 2.0850e-01, 1.9845e-02, 1.3320e-01,
        3.5883e-02, 4.6594e-02, 8.4770e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,375][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:54,376][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,376][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,377][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,378][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,379][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,379][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,380][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,381][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,381][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,382][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,383][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,383][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,384][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9933, 0.0067], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,385][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0756, 0.9244], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,385][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9428, 0.0572], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,386][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9916, 0.0084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,387][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0224, 0.9776], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,389][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([9.9956e-01, 4.4462e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,390][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([1.1791e-04, 9.9988e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,394][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.7479, 0.2521], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,398][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9749, 0.0251], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,401][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.1303e-06, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,404][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4425, 0.5575], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,406][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([3.9503e-04, 9.9961e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,410][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.4209, 0.0181, 0.5610], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,411][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([4.2771e-04, 7.5300e-01, 2.4657e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,412][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.0904, 0.0345, 0.8750], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,412][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.7589, 0.0106, 0.2305], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,413][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.0014, 0.7691, 0.2294], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,415][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.4435, 0.0075, 0.5490], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,417][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([9.0293e-07, 9.7384e-01, 2.6163e-02], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,421][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.0344, 0.0234, 0.9422], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,424][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.1303, 0.1269, 0.7428], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,426][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([1.7084e-08, 9.9484e-01, 5.1576e-03], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,430][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.0073, 0.0349, 0.9578], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,433][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([3.6166e-06, 9.7920e-01, 2.0797e-02], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,437][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3741, 0.0049, 0.5816, 0.0394], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:54,437][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0024, 0.1635, 0.3736, 0.4605], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:54,438][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0928, 0.0048, 0.8427, 0.0596], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:54,439][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([5.0758e-01, 7.2972e-05, 3.2647e-01, 1.6587e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:54,440][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0040, 0.3531, 0.4405, 0.2024], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:54,441][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.6606, 0.0008, 0.3211, 0.0176], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:54,443][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([1.1412e-06, 1.1044e-01, 3.2246e-02, 8.5731e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:54,446][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([2.7190e-03, 3.6052e-04, 6.9126e-01, 3.0566e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:54,449][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1565, 0.0164, 0.4119, 0.4153], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:54,451][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([2.1287e-08, 2.0128e-01, 4.2918e-03, 7.9443e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:54,454][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([1.5035e-03, 5.5155e-05, 5.9382e-01, 4.0462e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:54,456][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([1.8048e-06, 1.1486e-01, 1.2448e-02, 8.7269e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:54,460][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.1011, 0.0368, 0.5073, 0.1669, 0.1879], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:54,463][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([6.0561e-05, 3.9795e-01, 7.6964e-02, 4.1773e-01, 1.0730e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:54,464][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.0175, 0.0263, 0.4945, 0.2247, 0.2370], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:54,465][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.0476, 0.0013, 0.2518, 0.6438, 0.0555], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:54,466][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.0008, 0.6803, 0.1003, 0.1139, 0.1047], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:54,467][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.2844, 0.0055, 0.3819, 0.0470, 0.2813], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:54,468][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([5.7947e-08, 3.7177e-01, 4.4981e-03, 6.1945e-01, 4.2799e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:54,471][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.0017, 0.0032, 0.2853, 0.6221, 0.0878], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:54,475][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.0098, 0.0439, 0.1397, 0.5563, 0.2502], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:54,477][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([1.2267e-09, 3.1211e-01, 8.1556e-04, 6.8558e-01, 1.4944e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:54,480][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([6.5142e-05, 6.3990e-04, 9.3082e-02, 8.8514e-01, 2.1072e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:54,482][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([5.6748e-07, 2.2603e-01, 5.7148e-03, 7.6476e-01, 3.4903e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:54,485][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.2565, 0.0065, 0.3233, 0.0650, 0.1285, 0.2203], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:54,487][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([3.2751e-04, 9.8558e-02, 8.2282e-02, 1.7135e-01, 9.9363e-02, 5.4812e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:54,491][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0449, 0.0064, 0.4368, 0.0689, 0.1918, 0.2512], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:54,492][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([6.5401e-01, 8.5154e-05, 2.0738e-01, 5.3396e-02, 1.8048e-02, 6.7079e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:54,493][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.0009, 0.1900, 0.1272, 0.0682, 0.1310, 0.4827], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:54,494][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.5223, 0.0006, 0.1928, 0.0112, 0.1159, 0.1571], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:54,494][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([1.8732e-07, 6.9172e-02, 6.7294e-03, 3.8923e-01, 6.1880e-03, 5.2868e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:54,496][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([2.2908e-03, 1.8001e-04, 2.9313e-01, 1.2993e-01, 3.9252e-02, 5.3521e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:54,499][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0565, 0.0130, 0.1249, 0.2631, 0.2365, 0.3060], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:54,501][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([6.3026e-09, 1.6213e-01, 1.8827e-03, 6.5820e-01, 3.0172e-03, 1.7476e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:54,503][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([4.8898e-04, 5.4927e-05, 1.8308e-01, 1.6029e-01, 1.0419e-02, 6.4567e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:54,505][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([8.8545e-07, 1.0058e-01, 1.1046e-02, 7.5797e-01, 8.3210e-03, 1.2208e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:54,509][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3929, 0.0016, 0.3269, 0.0133, 0.1208, 0.0926, 0.0519],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,514][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0007, 0.0246, 0.0895, 0.0806, 0.1434, 0.4142, 0.2469],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,517][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0534, 0.0019, 0.5321, 0.0282, 0.1806, 0.1621, 0.0418],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,519][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([8.7363e-01, 5.5926e-06, 3.4477e-02, 3.1512e-03, 3.2106e-03, 5.0603e-03,
        8.0463e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,519][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0031, 0.0680, 0.1642, 0.0421, 0.2021, 0.3423, 0.1781],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,520][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([7.3180e-01, 1.4166e-04, 1.3403e-01, 3.2392e-03, 5.5522e-02, 4.7344e-02,
        2.7927e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,521][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.2744e-07, 6.9443e-03, 3.2406e-03, 7.8464e-02, 2.1476e-03, 1.5103e-01,
        7.5817e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,522][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([5.5202e-03, 6.4458e-05, 1.5657e-01, 3.2715e-02, 1.9984e-02, 1.5338e-01,
        6.3176e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,525][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1574, 0.0035, 0.1260, 0.0775, 0.2472, 0.1583, 0.2301],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,527][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.9116e-09, 1.1752e-02, 2.8980e-04, 6.6431e-02, 3.7009e-04, 3.2227e-02,
        8.8893e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,530][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([7.2743e-03, 4.7816e-06, 7.4705e-02, 1.2557e-02, 4.7430e-03, 7.7477e-02,
        8.2324e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,532][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.5481e-06, 7.8848e-02, 9.1467e-03, 4.5886e-01, 6.5994e-03, 7.1203e-02,
        3.7534e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:54,536][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.3690, 0.0025, 0.2603, 0.0133, 0.0890, 0.0829, 0.0400, 0.1430],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,541][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0011, 0.0409, 0.0678, 0.1144, 0.1112, 0.3492, 0.1998, 0.1156],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,544][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0571, 0.0038, 0.3740, 0.0290, 0.2020, 0.1788, 0.0494, 0.1060],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,546][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([9.0375e-01, 1.3401e-05, 1.2857e-02, 5.9650e-04, 1.0414e-03, 1.0174e-03,
        1.1403e-02, 6.9319e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,546][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0017, 0.0720, 0.1206, 0.0397, 0.1086, 0.3479, 0.1752, 0.1342],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,547][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([6.9882e-01, 2.1180e-04, 1.1155e-01, 3.6996e-03, 5.5742e-02, 4.2129e-02,
        2.3537e-02, 6.4311e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,548][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([2.5101e-07, 1.1172e-02, 5.0206e-03, 8.6459e-02, 3.4237e-03, 1.5391e-01,
        6.5504e-01, 8.4974e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,549][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([1.5524e-02, 1.3368e-04, 1.1200e-01, 2.2104e-02, 1.7792e-02, 7.5870e-02,
        2.3311e-01, 5.2346e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,551][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0231, 0.0083, 0.0810, 0.0719, 0.1810, 0.1852, 0.2133, 0.2362],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,553][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([3.7069e-09, 1.9570e-02, 5.8209e-04, 6.6232e-02, 6.5409e-04, 3.5880e-02,
        8.0532e-01, 7.1759e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,555][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([4.5043e-03, 1.5787e-05, 2.5534e-02, 3.8444e-03, 1.3330e-03, 1.7657e-02,
        1.6074e-01, 7.8638e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,557][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([2.4700e-06, 7.6992e-02, 1.0669e-02, 4.1319e-01, 7.9605e-03, 6.1515e-02,
        3.8734e-01, 4.2327e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:54,561][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([0.0925, 0.0020, 0.2545, 0.0296, 0.0954, 0.1271, 0.0855, 0.2612, 0.0523],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,564][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([1.3575e-04, 2.6306e-02, 2.6168e-02, 8.3793e-02, 5.7930e-02, 3.0811e-01,
        1.9145e-01, 7.0322e-02, 2.3579e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,568][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([0.0072, 0.0026, 0.2400, 0.0519, 0.1482, 0.2476, 0.0988, 0.1310, 0.0727],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,571][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([4.0532e-03, 3.5870e-06, 1.1637e-02, 3.7449e-03, 6.7779e-04, 7.0531e-03,
        3.1228e-01, 6.5818e-01, 2.3777e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,573][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([0.0005, 0.0671, 0.1089, 0.0426, 0.1098, 0.2522, 0.1309, 0.1128, 0.1752],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,573][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([0.2702, 0.0004, 0.2157, 0.0122, 0.0970, 0.1209, 0.0984, 0.1453, 0.0398],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,574][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([2.5176e-08, 8.0829e-03, 1.3744e-03, 7.4905e-02, 1.4298e-03, 1.3166e-01,
        6.6388e-01, 5.2615e-02, 6.6045e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,575][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([2.6218e-05, 1.5440e-05, 1.5242e-02, 1.7661e-02, 2.1345e-03, 6.8246e-02,
        4.3254e-01, 4.3198e-01, 3.2160e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,577][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([0.0048, 0.0032, 0.0353, 0.1261, 0.0778, 0.1849, 0.2714, 0.2393, 0.0572],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,579][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([6.1034e-10, 7.5771e-03, 1.8693e-04, 6.1273e-02, 2.9647e-04, 2.8845e-02,
        7.5672e-01, 3.4885e-02, 1.1022e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,580][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([1.0648e-06, 5.1809e-07, 3.1405e-03, 1.9548e-03, 9.9094e-05, 1.3164e-02,
        3.9295e-01, 5.8565e-01, 3.0348e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,581][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([3.5574e-07, 3.7997e-02, 3.8936e-03, 3.2926e-01, 3.9024e-03, 4.3273e-02,
        2.7083e-01, 2.2584e-02, 2.8827e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:54,584][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.4171, 0.0013, 0.2640, 0.0076, 0.0838, 0.0529, 0.0222, 0.0922, 0.0098,
        0.0491], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,588][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0004, 0.0128, 0.0479, 0.0509, 0.0965, 0.2183, 0.1303, 0.0695, 0.1954,
        0.1779], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,592][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0501, 0.0026, 0.3556, 0.0309, 0.1863, 0.1333, 0.0372, 0.0848, 0.0235,
        0.0957], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,594][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([9.0564e-01, 1.7204e-07, 8.7669e-04, 4.6034e-05, 1.4669e-04, 7.2877e-05,
        1.1794e-03, 1.6950e-02, 1.1243e-05, 7.5074e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,599][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0006, 0.0537, 0.1080, 0.0353, 0.1087, 0.2391, 0.1293, 0.1129, 0.1169,
        0.0954], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,601][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([7.4346e-01, 9.5213e-05, 9.6527e-02, 2.6261e-03, 4.1295e-02, 2.7394e-02,
        1.7976e-02, 5.0092e-02, 7.9055e-03, 1.2632e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,601][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([4.6839e-08, 4.4339e-03, 2.6976e-03, 4.8034e-02, 1.8362e-03, 1.0877e-01,
        4.7341e-01, 5.2266e-02, 4.8918e-02, 2.5964e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,602][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([1.2638e-03, 9.2075e-06, 2.1123e-02, 4.8325e-03, 2.5243e-03, 1.8155e-02,
        8.7701e-02, 2.2891e-01, 6.6486e-03, 6.2883e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,603][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0392, 0.0032, 0.0555, 0.0458, 0.1072, 0.0910, 0.1060, 0.1554, 0.0179,
        0.3787], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,604][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([5.4643e-10, 4.3136e-03, 1.9293e-04, 3.0363e-02, 2.6979e-04, 1.4223e-02,
        4.0765e-01, 2.4089e-02, 5.5173e-02, 4.6373e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,606][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([2.8131e-03, 3.1301e-07, 3.6169e-03, 4.5098e-04, 2.6360e-04, 2.4105e-03,
        2.5429e-02, 2.7232e-01, 2.2342e-04, 6.9247e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,608][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([1.3717e-06, 2.7960e-02, 5.0806e-03, 2.8136e-01, 4.5091e-03, 3.9320e-02,
        1.9785e-01, 2.2411e-02, 2.2425e-01, 1.9726e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:54,612][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.1229, 0.0029, 0.1300, 0.0073, 0.0317, 0.0274, 0.0206, 0.0667, 0.0114,
        0.0425, 0.5367], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,614][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([7.7306e-05, 5.9110e-02, 2.2773e-02, 6.8420e-02, 2.8667e-02, 1.6540e-01,
        1.8041e-01, 7.1361e-02, 1.5414e-01, 1.8221e-01, 6.7434e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,619][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.0265, 0.0052, 0.1308, 0.0199, 0.0674, 0.0552, 0.0275, 0.0503, 0.0201,
        0.0689, 0.5283], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,621][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([4.4065e-01, 4.0552e-06, 1.1694e-03, 2.0994e-05, 4.8944e-05, 2.3715e-05,
        5.0771e-04, 5.1314e-03, 3.9326e-06, 1.4777e-02, 5.3766e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,625][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.0003, 0.1761, 0.0488, 0.0360, 0.0332, 0.1990, 0.1254, 0.0620, 0.1224,
        0.1334, 0.0633], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,628][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.2175, 0.0007, 0.0819, 0.0042, 0.0355, 0.0366, 0.0276, 0.0538, 0.0131,
        0.0210, 0.5081], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,628][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([2.1147e-08, 3.0997e-02, 9.5357e-04, 5.1981e-02, 9.1972e-04, 7.3877e-02,
        4.5319e-01, 4.1668e-02, 5.6450e-02, 2.7821e-01, 1.1747e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,629][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([1.4985e-03, 3.4060e-05, 1.2470e-02, 2.0921e-03, 1.4141e-03, 8.8827e-03,
        3.0257e-02, 7.7561e-02, 2.3445e-03, 1.3236e-01, 7.3109e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,630][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.0089, 0.0079, 0.0429, 0.0531, 0.0621, 0.0901, 0.0855, 0.1372, 0.0261,
        0.2929, 0.1935], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,631][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([2.9429e-10, 3.2591e-02, 1.2488e-04, 3.7597e-02, 1.4137e-04, 1.3870e-02,
        4.1795e-01, 2.2023e-02, 5.5526e-02, 4.1365e-01, 6.5201e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,634][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([8.2549e-04, 2.6404e-06, 1.0381e-03, 7.5578e-05, 2.6822e-05, 3.6401e-04,
        5.3098e-03, 3.9515e-02, 4.6610e-05, 9.1910e-02, 8.6089e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,636][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([4.1934e-07, 7.8534e-02, 2.5170e-03, 1.9621e-01, 1.4330e-03, 2.6564e-02,
        2.3091e-01, 1.8629e-02, 2.1433e-01, 2.1824e-01, 1.2631e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:54,639][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0351, 0.0007, 0.0480, 0.0043, 0.0208, 0.0204, 0.0189, 0.0537, 0.0074,
        0.0409, 0.4432, 0.3065], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,642][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([5.9277e-05, 2.3035e-02, 1.8163e-02, 5.1494e-02, 2.5955e-02, 1.5505e-01,
        1.3184e-01, 6.4025e-02, 1.2027e-01, 1.6303e-01, 8.2387e-02, 1.6469e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,646][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0109, 0.0014, 0.0950, 0.0094, 0.0552, 0.0395, 0.0147, 0.0237, 0.0094,
        0.0334, 0.5401, 0.1673], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,648][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([1.0889e-02, 1.2930e-07, 3.6938e-04, 3.0414e-06, 5.4501e-06, 5.5921e-06,
        1.9409e-04, 1.8084e-03, 1.1348e-06, 1.0488e-02, 9.6548e-01, 1.0760e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,650][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([1.5941e-04, 5.8838e-02, 4.0689e-02, 2.9082e-02, 3.9255e-02, 1.9370e-01,
        1.3405e-01, 8.5314e-02, 1.2715e-01, 9.4649e-02, 5.9164e-02, 1.3795e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,653][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([1.0516e-01, 1.7424e-04, 5.1623e-02, 2.7045e-03, 2.4104e-02, 2.6250e-02,
        1.9672e-02, 4.2771e-02, 8.6900e-03, 1.9212e-02, 5.1393e-01, 1.8570e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,654][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([1.2951e-08, 8.2817e-03, 7.7582e-04, 4.4802e-02, 7.9278e-04, 7.2390e-02,
        4.2405e-01, 4.1422e-02, 4.0301e-02, 2.6255e-01, 1.5540e-02, 8.9097e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,655][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([6.9529e-05, 1.8937e-06, 3.3736e-03, 5.2383e-04, 3.5071e-04, 2.3886e-03,
        1.3655e-02, 3.0778e-02, 1.0042e-03, 8.5538e-02, 6.8873e-01, 1.7359e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,656][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0039, 0.0031, 0.0186, 0.0331, 0.0382, 0.0552, 0.0814, 0.0815, 0.0178,
        0.2805, 0.1816, 0.2052], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,657][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([7.3442e-11, 9.2528e-03, 4.2055e-05, 2.2661e-02, 7.5152e-05, 7.8222e-03,
        3.6253e-01, 1.8104e-02, 3.5320e-02, 5.3081e-01, 5.1163e-03, 8.2711e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,658][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([8.8796e-06, 7.6207e-08, 3.1831e-04, 1.0743e-05, 3.3762e-06, 6.6424e-05,
        1.4819e-03, 8.9274e-03, 1.0529e-05, 3.2993e-02, 9.1846e-01, 3.7714e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,660][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([1.1604e-07, 3.4922e-02, 2.1344e-03, 1.9389e-01, 1.7388e-03, 3.0623e-02,
        2.0178e-01, 1.8011e-02, 1.7357e-01, 2.6818e-01, 1.5178e-02, 5.9975e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:54,664][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1375, 0.0014, 0.0836, 0.0046, 0.0329, 0.0254, 0.0139, 0.0487, 0.0081,
        0.0271, 0.2892, 0.2049, 0.1227], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,668][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0004, 0.0259, 0.0293, 0.0541, 0.0480, 0.1685, 0.1057, 0.0542, 0.0935,
        0.1148, 0.0759, 0.1928, 0.0368], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,672][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0347, 0.0022, 0.1152, 0.0084, 0.0757, 0.0445, 0.0148, 0.0287, 0.0116,
        0.0280, 0.4069, 0.1319, 0.0973], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,675][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([5.0910e-01, 2.8136e-06, 1.3861e-03, 1.5646e-05, 6.0761e-05, 2.3549e-05,
        2.7533e-04, 2.8289e-03, 4.0052e-06, 6.4215e-03, 3.0255e-01, 6.7017e-03,
        1.7063e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,679][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0006, 0.0482, 0.0587, 0.0266, 0.0572, 0.1706, 0.0987, 0.0823, 0.1062,
        0.0752, 0.0759, 0.1379, 0.0619], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,681][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([3.7460e-01, 1.7048e-04, 4.7084e-02, 1.8522e-03, 2.6165e-02, 1.7977e-02,
        9.8440e-03, 2.9740e-02, 6.7783e-03, 8.1318e-03, 2.9462e-01, 9.4173e-02,
        8.8873e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,682][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([2.0764e-07, 1.0579e-02, 2.9358e-03, 5.1972e-02, 2.9242e-03, 8.4366e-02,
        3.9533e-01, 5.1061e-02, 5.1189e-02, 1.9255e-01, 2.2821e-02, 1.1281e-01,
        2.1462e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,683][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([3.3565e-03, 2.1342e-05, 1.2914e-02, 1.3623e-03, 1.9189e-03, 4.7475e-03,
        1.4922e-02, 4.0873e-02, 1.7676e-03, 6.4826e-02, 5.2684e-01, 1.2990e-01,
        1.9655e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,683][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0061, 0.0059, 0.0294, 0.0248, 0.0757, 0.0801, 0.0699, 0.0748, 0.0251,
        0.2374, 0.1310, 0.1564, 0.0832], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,685][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.2253e-09, 1.8907e-02, 2.4530e-04, 3.2239e-02, 3.1902e-04, 1.4109e-02,
        3.8698e-01, 3.2199e-02, 5.6319e-02, 4.2411e-01, 8.6355e-03, 1.6591e-02,
        9.3454e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,687][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([8.1599e-04, 1.4604e-06, 9.7210e-04, 5.1141e-05, 3.5041e-05, 1.9627e-04,
        2.0827e-03, 1.3815e-02, 2.9702e-05, 2.5453e-02, 4.1992e-01, 2.4073e-02,
        5.1256e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,689][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.5626e-06, 4.0389e-02, 6.2482e-03, 1.8759e-01, 5.0746e-03, 3.8596e-02,
        2.1070e-01, 2.4709e-02, 1.5613e-01, 2.3989e-01, 2.2742e-02, 5.9900e-02,
        8.0303e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:54,692][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.3973, 0.0008, 0.0699, 0.0015, 0.0182, 0.0098, 0.0044, 0.0216, 0.0030,
        0.0103, 0.1735, 0.0900, 0.0727, 0.1270], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,697][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.0003, 0.0231, 0.0319, 0.0403, 0.0365, 0.1426, 0.0781, 0.0459, 0.1184,
        0.0929, 0.0826, 0.1843, 0.0357, 0.0875], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,701][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.0643, 0.0020, 0.1152, 0.0043, 0.0754, 0.0236, 0.0086, 0.0192, 0.0074,
        0.0197, 0.4109, 0.1026, 0.0822, 0.0644], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,704][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([6.0974e-01, 1.6697e-07, 2.1275e-04, 1.1516e-07, 1.6509e-06, 2.8621e-07,
        3.6095e-06, 1.2849e-04, 4.4004e-08, 1.1175e-04, 2.7151e-02, 3.0412e-04,
        2.1518e-02, 3.4083e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,708][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0007, 0.0566, 0.0714, 0.0233, 0.0628, 0.1266, 0.0826, 0.0587, 0.1231,
        0.0706, 0.0865, 0.1366, 0.0535, 0.0470], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,708][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([3.1834e-01, 1.0520e-04, 4.1327e-02, 1.0698e-03, 2.2039e-02, 1.0731e-02,
        5.7525e-03, 1.4662e-02, 3.0120e-03, 3.6401e-03, 2.2196e-01, 6.4026e-02,
        4.2704e-02, 2.5063e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,709][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([9.5934e-08, 8.1033e-03, 2.7147e-03, 3.3087e-02, 2.0202e-03, 7.9415e-02,
        3.7229e-01, 5.1380e-02, 5.6737e-02, 1.8903e-01, 2.6299e-02, 1.2806e-01,
        2.2758e-02, 2.8102e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,710][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([1.3483e-03, 3.5056e-06, 4.6235e-03, 1.7960e-04, 3.3885e-04, 7.8526e-04,
        2.5611e-03, 1.3851e-02, 3.1409e-04, 1.5764e-02, 1.8687e-01, 3.3514e-02,
        8.3896e-02, 6.5595e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,712][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.0105, 0.0055, 0.0369, 0.0259, 0.0481, 0.0450, 0.0597, 0.0588, 0.0130,
        0.1531, 0.1540, 0.1543, 0.0741, 0.1609], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,714][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([9.8945e-10, 1.7761e-02, 2.1740e-04, 2.3073e-02, 1.9486e-04, 1.1194e-02,
        3.5393e-01, 3.5379e-02, 5.5053e-02, 4.4502e-01, 9.0633e-03, 1.2239e-02,
        1.0791e-02, 2.6080e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,716][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([4.6437e-04, 1.7236e-07, 3.0417e-04, 8.0785e-07, 1.7467e-06, 6.4038e-06,
        7.1568e-05, 1.2678e-03, 8.0212e-07, 9.9467e-04, 5.4256e-02, 2.0374e-03,
        9.1989e-02, 8.4860e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,719][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([1.7254e-07, 3.5930e-02, 2.3548e-03, 2.0273e-01, 1.7847e-03, 2.4408e-02,
        1.7351e-01, 1.5147e-02, 1.6878e-01, 2.0678e-01, 1.2241e-02, 4.5493e-02,
        4.3473e-03, 1.0649e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:54,723][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2434, 0.0005, 0.0638, 0.0020, 0.0278, 0.0129, 0.0060, 0.0247, 0.0032,
        0.0116, 0.2155, 0.1137, 0.0809, 0.1069, 0.0871], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,727][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0004, 0.0163, 0.0332, 0.0384, 0.0594, 0.1506, 0.0830, 0.0414, 0.0931,
        0.0857, 0.0938, 0.1440, 0.0304, 0.0633, 0.0669], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,732][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0499, 0.0015, 0.1103, 0.0062, 0.0666, 0.0364, 0.0097, 0.0203, 0.0068,
        0.0183, 0.3600, 0.1048, 0.0839, 0.0608, 0.0645], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,734][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([4.2171e-01, 1.1943e-07, 1.8106e-04, 3.5359e-07, 3.5256e-06, 7.2327e-07,
        7.0485e-06, 1.9081e-04, 8.3511e-08, 2.9845e-04, 4.7150e-02, 3.5896e-04,
        2.4005e-02, 4.4971e-01, 5.6383e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,735][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0011, 0.0451, 0.0629, 0.0251, 0.0802, 0.1421, 0.0897, 0.0637, 0.0853,
        0.0529, 0.0758, 0.1155, 0.0469, 0.0235, 0.0902], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,736][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([3.4276e-01, 7.3310e-05, 3.5307e-02, 9.2457e-04, 1.6763e-02, 9.2631e-03,
        5.0479e-03, 1.4884e-02, 2.4363e-03, 4.1998e-03, 2.3250e-01, 5.0421e-02,
        5.0034e-02, 1.7278e-01, 6.2597e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,737][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.6673e-07, 5.3342e-03, 2.6417e-03, 4.0058e-02, 2.3970e-03, 7.7560e-02,
        3.2471e-01, 4.0492e-02, 3.9074e-02, 1.5705e-01, 2.5766e-02, 9.9790e-02,
        1.8290e-02, 2.1838e-02, 1.4499e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,738][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.2364e-03, 2.2874e-06, 2.7438e-03, 1.5490e-04, 3.4575e-04, 6.5952e-04,
        2.2951e-03, 8.7437e-03, 2.2341e-04, 1.3549e-02, 1.5930e-01, 2.3169e-02,
        5.6285e-02, 4.6841e-01, 2.6288e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,741][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0174, 0.0023, 0.0237, 0.0138, 0.0681, 0.0401, 0.0402, 0.0453, 0.0105,
        0.1390, 0.1254, 0.1040, 0.0623, 0.0976, 0.2104], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,743][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.8125e-10, 1.5502e-02, 1.6099e-04, 2.8254e-02, 2.1728e-04, 1.1703e-02,
        3.5212e-01, 2.7073e-02, 4.6765e-02, 3.8924e-01, 8.4681e-03, 1.1724e-02,
        7.3593e-03, 1.9518e-02, 8.1896e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,746][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([6.5554e-04, 4.3634e-08, 1.2882e-04, 9.5906e-07, 2.2701e-06, 5.9100e-06,
        4.7779e-05, 8.9160e-04, 4.9411e-07, 9.7926e-04, 5.8570e-02, 1.2713e-03,
        6.5584e-02, 6.2135e-01, 2.5051e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,748][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([7.2972e-07, 4.1370e-02, 5.5772e-03, 1.9968e-01, 4.3531e-03, 3.8105e-02,
        1.7668e-01, 1.8344e-02, 1.4846e-01, 2.0331e-01, 2.0839e-02, 5.8896e-02,
        5.4430e-03, 6.1238e-02, 1.7702e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:54,751][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:54,754][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[13470],
        [ 7236],
        [ 9052],
        [ 1462],
        [    1],
        [10401],
        [10425],
        [24622],
        [24560],
        [ 5940],
        [ 8800],
        [ 3562],
        [13547],
        [ 7230],
        [ 5504]], device='cuda:0')
[2024-07-24 10:21:54,756][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 8036],
        [ 5342],
        [ 5895],
        [  966],
        [    1],
        [ 9600],
        [ 7235],
        [20143],
        [20143],
        [ 4830],
        [ 6788],
        [ 3109],
        [10504],
        [ 3648],
        [ 2792]], device='cuda:0')
[2024-07-24 10:21:54,759][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[39260],
        [39056],
        [20029],
        [20629],
        [26631],
        [28374],
        [26548],
        [25367],
        [24270],
        [27040],
        [20739],
        [23507],
        [23645],
        [25228],
        [22641]], device='cuda:0')
[2024-07-24 10:21:54,761][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[27246],
        [ 5290],
        [ 4301],
        [ 6439],
        [ 6625],
        [ 8685],
        [11300],
        [11108],
        [16022],
        [13709],
        [14213],
        [14955],
        [14253],
        [14851],
        [14343]], device='cuda:0')
[2024-07-24 10:21:54,764][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[25209],
        [28556],
        [49264],
        [49282],
        [49649],
        [49471],
        [49505],
        [49362],
        [48675],
        [49305],
        [49404],
        [49370],
        [49289],
        [49298],
        [49106]], device='cuda:0')
[2024-07-24 10:21:54,765][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[28142],
        [27792],
        [26910],
        [28026],
        [30068],
        [28275],
        [30091],
        [30605],
        [36891],
        [30015],
        [35892],
        [36857],
        [36593],
        [36919],
        [37962]], device='cuda:0')
[2024-07-24 10:21:54,767][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[27957],
        [ 3840],
        [ 2897],
        [ 2553],
        [ 3076],
        [ 5313],
        [ 4691],
        [ 5134],
        [ 4273],
        [ 4275],
        [ 3580],
        [ 3864],
        [ 3923],
        [ 3703],
        [ 3925]], device='cuda:0')
[2024-07-24 10:21:54,768][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[39689],
        [26672],
        [22905],
        [18414],
        [14351],
        [15299],
        [15628],
        [15959],
        [15432],
        [16104],
        [16738],
        [17643],
        [18398],
        [18954],
        [19434]], device='cuda:0')
[2024-07-24 10:21:54,771][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[45694],
        [47861],
        [47875],
        [43762],
        [46013],
        [49157],
        [49571],
        [49572],
        [49513],
        [49587],
        [49509],
        [49592],
        [49599],
        [49586],
        [49468]], device='cuda:0')
[2024-07-24 10:21:54,774][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 923],
        [ 634],
        [ 898],
        [1080],
        [4121],
        [3618],
        [2637],
        [2184],
        [4203],
        [2712],
        [3112],
        [3866],
        [2587],
        [2849],
        [1762]], device='cuda:0')
[2024-07-24 10:21:54,776][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[50230],
        [50230],
        [50247],
        [50233],
        [50170],
        [50243],
        [50236],
        [50236],
        [50250],
        [50240],
        [50256],
        [50256],
        [50251],
        [50229],
        [50251]], device='cuda:0')
[2024-07-24 10:21:54,779][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[49105],
        [49225],
        [47996],
        [49590],
        [   23],
        [ 1341],
        [ 2243],
        [   36],
        [32390],
        [ 7835],
        [36482],
        [37081],
        [44858],
        [48224],
        [46883]], device='cuda:0')
[2024-07-24 10:21:54,782][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[22804],
        [ 8712],
        [ 8527],
        [ 7432],
        [ 6658],
        [ 6285],
        [ 4886],
        [ 7123],
        [ 6624],
        [ 7852],
        [ 6337],
        [ 6398],
        [ 6767],
        [ 7857],
        [ 7836]], device='cuda:0')
[2024-07-24 10:21:54,784][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[24547],
        [24194],
        [26388],
        [34053],
        [33997],
        [34804],
        [38932],
        [41947],
        [42317],
        [42970],
        [43508],
        [43716],
        [44210],
        [43769],
        [44191]], device='cuda:0')
[2024-07-24 10:21:54,787][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[42672],
        [25673],
        [30091],
        [30416],
        [31010],
        [23537],
        [25398],
        [26858],
        [21423],
        [18347],
        [23293],
        [22168],
        [22947],
        [24130],
        [24170]], device='cuda:0')
[2024-07-24 10:21:54,790][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 2425],
        [ 2465],
        [40048],
        [40481],
        [42550],
        [41030],
        [40646],
        [40295],
        [41012],
        [39878],
        [38127],
        [38037],
        [39009],
        [36909],
        [38866]], device='cuda:0')
[2024-07-24 10:21:54,792][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[41056],
        [42627],
        [42998],
        [43845],
        [42941],
        [35932],
        [38358],
        [37599],
        [40748],
        [40852],
        [40132],
        [37505],
        [36781],
        [37415],
        [37181]], device='cuda:0')
[2024-07-24 10:21:54,795][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[11159],
        [13902],
        [13393],
        [13261],
        [15914],
        [19496],
        [18926],
        [22876],
        [26732],
        [23454],
        [24225],
        [24937],
        [26370],
        [24549],
        [26290]], device='cuda:0')
[2024-07-24 10:21:54,796][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[5434],
        [5530],
        [6006],
        [5033],
        [2842],
        [4626],
        [3999],
        [4344],
        [1553],
        [4228],
        [2261],
        [1692],
        [2388],
        [3860],
        [2511]], device='cuda:0')
[2024-07-24 10:21:54,797][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 9714],
        [26031],
        [27694],
        [29661],
        [27254],
        [22332],
        [24655],
        [22920],
        [23804],
        [24185],
        [23442],
        [24128],
        [24783],
        [25090],
        [24999]], device='cuda:0')
[2024-07-24 10:21:54,799][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[15759],
        [15760],
        [ 9888],
        [10723],
        [13757],
        [14945],
        [14919],
        [13980],
        [14427],
        [14539],
        [14888],
        [15229],
        [14765],
        [17865],
        [17251]], device='cuda:0')
[2024-07-24 10:21:54,802][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[20031],
        [29941],
        [29916],
        [26783],
        [29480],
        [25279],
        [28728],
        [28982],
        [28078],
        [28155],
        [28030],
        [26549],
        [25859],
        [24421],
        [25721]], device='cuda:0')
[2024-07-24 10:21:54,804][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[15597],
        [36240],
        [42841],
        [44792],
        [45424],
        [44084],
        [45116],
        [46152],
        [45948],
        [47152],
        [46619],
        [45939],
        [45795],
        [44533],
        [44838]], device='cuda:0')
[2024-07-24 10:21:54,807][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 9730],
        [10234],
        [21290],
        [18062],
        [21098],
        [19690],
        [24164],
        [24835],
        [23617],
        [22925],
        [21095],
        [16019],
        [17021],
        [17278],
        [18722]], device='cuda:0')
[2024-07-24 10:21:54,810][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[38192],
        [ 8617],
        [ 8616],
        [14934],
        [12820],
        [16705],
        [17189],
        [16887],
        [15002],
        [21836],
        [20353],
        [22964],
        [20536],
        [21742],
        [21258]], device='cuda:0')
[2024-07-24 10:21:54,812][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 6504],
        [13028],
        [11166],
        [11945],
        [15435],
        [13617],
        [17380],
        [ 9019],
        [10903],
        [ 9320],
        [12932],
        [13955],
        [12281],
        [ 8244],
        [10038]], device='cuda:0')
[2024-07-24 10:21:54,815][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[13091],
        [31253],
        [30981],
        [24721],
        [25350],
        [23594],
        [22185],
        [21757],
        [18667],
        [18453],
        [18678],
        [17615],
        [17510],
        [16839],
        [17062]], device='cuda:0')
[2024-07-24 10:21:54,818][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[45978],
        [38833],
        [26818],
        [25421],
        [23228],
        [25278],
        [22095],
        [24593],
        [26287],
        [23571],
        [26252],
        [27393],
        [27128],
        [26978],
        [26139]], device='cuda:0')
[2024-07-24 10:21:54,820][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 9842],
        [24304],
        [29899],
        [24129],
        [25645],
        [31007],
        [28464],
        [28950],
        [32281],
        [30768],
        [30440],
        [31085],
        [32496],
        [35789],
        [29902]], device='cuda:0')
[2024-07-24 10:21:54,823][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[35744],
        [35744],
        [35744],
        [35744],
        [35744],
        [35744],
        [35744],
        [35744],
        [35744],
        [35744],
        [35744],
        [35744],
        [35744],
        [35744],
        [35744]], device='cuda:0')
[2024-07-24 10:21:54,936][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:54,938][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,938][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,939][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,940][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,940][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,941][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,942][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,942][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,943][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,944][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,946][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,948][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:54,949][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9368, 0.0632], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,950][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([4.7007e-07, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,951][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0014, 0.9986], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,953][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([1.0881e-04, 9.9989e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,954][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5270, 0.4730], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,954][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1323, 0.8677], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,955][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4374, 0.5626], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,956][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1570, 0.8430], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,957][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2307, 0.7693], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,960][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2007, 0.7993], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,964][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0466, 0.9534], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,967][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0714, 0.9286], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:54,971][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.3137, 0.3422, 0.3441], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,973][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([9.9984e-08, 8.5380e-01, 1.4620e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,976][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([5.6003e-05, 9.1411e-01, 8.5839e-02], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,978][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([3.9521e-04, 7.2310e-01, 2.7651e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,980][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.4307, 0.2192, 0.3501], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,981][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.0198, 0.8368, 0.1435], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,981][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.0897, 0.2779, 0.6324], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,982][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.0040, 0.0023, 0.9937], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,983][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.0032, 0.7184, 0.2783], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,985][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.0922, 0.5716, 0.3361], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,987][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.0297, 0.6793, 0.2909], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,991][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.0237, 0.5829, 0.3934], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:54,995][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2595, 0.3227, 0.2368, 0.1810], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:54,997][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.6845e-08, 6.7134e-01, 3.0895e-01, 1.9708e-02], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,000][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([4.7802e-05, 4.0035e-01, 1.5983e-01, 4.3978e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,002][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([7.3378e-07, 1.1146e-01, 6.6624e-01, 2.2230e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,005][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3808, 0.1548, 0.2788, 0.1856], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,007][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([3.6957e-02, 6.9972e-04, 2.3193e-01, 7.3041e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,008][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0738, 0.2690, 0.4380, 0.2193], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,008][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0152, 0.0235, 0.9423, 0.0190], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,009][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0062, 0.2278, 0.1692, 0.5969], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,010][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0311, 0.2979, 0.2596, 0.4115], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,012][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0075, 0.3962, 0.1812, 0.4150], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,015][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0091, 0.3743, 0.3070, 0.3095], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,018][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.0091, 0.0063, 0.0798, 0.0076, 0.8971], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,020][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([6.9808e-09, 1.5791e-01, 6.6721e-02, 3.3465e-03, 7.7202e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,023][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([2.1147e-05, 5.7066e-01, 5.3170e-02, 2.9524e-01, 8.0909e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,025][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([1.8265e-05, 1.9094e-01, 1.2262e-01, 8.2423e-02, 6.0400e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,029][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.1236, 0.1309, 0.2028, 0.1268, 0.4159], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,032][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0054, 0.0016, 0.0721, 0.4004, 0.5205], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,034][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.0111, 0.0466, 0.3976, 0.0469, 0.4978], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,035][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([4.9700e-03, 7.2735e-04, 8.2454e-02, 9.1054e-04, 9.1094e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,035][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.0011, 0.3979, 0.1309, 0.3649, 0.1052], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,036][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0255, 0.2212, 0.1978, 0.3782, 0.1773], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,038][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.0086, 0.3594, 0.1455, 0.3945, 0.0920], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,041][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.0017, 0.2615, 0.2323, 0.2122, 0.2923], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,045][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0781, 0.2576, 0.0869, 0.4333, 0.0847, 0.0594], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,047][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ went] are: tensor([2.3391e-08, 7.1230e-01, 3.6152e-02, 2.3641e-02, 1.3016e-01, 9.7745e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,049][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ went] are: tensor([2.2806e-05, 3.5831e-01, 7.9991e-02, 3.2758e-01, 1.2169e-01, 1.1241e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,052][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ went] are: tensor([7.0087e-06, 3.5711e-01, 1.0342e-01, 1.3323e-01, 1.8750e-01, 2.1873e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,056][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.1419, 0.0842, 0.1299, 0.0997, 0.3469, 0.1974], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,058][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0074, 0.0028, 0.0397, 0.1589, 0.1404, 0.6507], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,059][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0495, 0.1509, 0.1295, 0.1585, 0.3512, 0.1604], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,060][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0057, 0.0086, 0.1059, 0.0029, 0.5311, 0.3458], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,061][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0012, 0.0722, 0.0763, 0.2542, 0.0725, 0.5237], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,061][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0179, 0.1908, 0.1563, 0.2680, 0.1140, 0.2529], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,063][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0125, 0.3077, 0.1202, 0.3358, 0.0719, 0.1519], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,066][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0070, 0.2263, 0.1582, 0.2001, 0.2344, 0.1740], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,070][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0898, 0.0461, 0.2513, 0.0568, 0.4770, 0.0568, 0.0222],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,072][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([9.0475e-10, 5.9240e-03, 8.8933e-03, 3.3684e-04, 1.0847e-01, 7.9668e-01,
        7.9700e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,075][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([5.8770e-05, 2.0563e-01, 7.2061e-02, 2.4081e-01, 1.3139e-01, 1.5290e-01,
        1.9716e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,077][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([4.6008e-06, 5.7388e-02, 1.3937e-01, 5.5977e-02, 4.2041e-01, 2.1220e-01,
        1.1465e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,081][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0909, 0.0753, 0.1391, 0.0892, 0.3183, 0.2010, 0.0861],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,083][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([4.2907e-03, 1.2495e-04, 1.8393e-02, 4.4486e-02, 1.0582e-01, 6.4566e-01,
        1.8123e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,084][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0132, 0.0950, 0.2258, 0.0915, 0.3550, 0.1531, 0.0665],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,085][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0037, 0.0064, 0.4203, 0.0070, 0.4174, 0.0983, 0.0470],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,086][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0028, 0.0561, 0.0638, 0.1645, 0.0799, 0.3465, 0.2864],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,088][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0095, 0.1498, 0.1349, 0.2065, 0.0997, 0.1919, 0.2077],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,090][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0039, 0.2410, 0.1054, 0.2508, 0.0672, 0.1348, 0.1968],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,094][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0025, 0.1948, 0.1654, 0.1579, 0.2324, 0.1137, 0.1334],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,098][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.3474, 0.0139, 0.0399, 0.0294, 0.5444, 0.0119, 0.0087, 0.0045],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,101][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ the] are: tensor([1.0264e-08, 2.0490e-02, 3.2474e-02, 3.2026e-04, 4.4944e-01, 1.7111e-01,
        1.0086e-01, 2.2531e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,103][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ the] are: tensor([2.0314e-05, 2.2054e-01, 7.1569e-02, 1.4294e-01, 1.6218e-01, 7.8689e-02,
        1.2016e-01, 2.0391e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,105][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ the] are: tensor([9.9482e-07, 2.4081e-02, 6.8207e-02, 2.0585e-02, 2.5764e-01, 1.8053e-01,
        9.3385e-02, 3.5558e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,108][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0871, 0.0638, 0.1226, 0.0924, 0.3088, 0.1808, 0.0880, 0.0565],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,109][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ the] are: tensor([4.8346e-02, 1.5473e-04, 2.7677e-02, 2.4771e-02, 5.9306e-02, 4.1270e-01,
        2.6150e-01, 1.6554e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,110][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0414, 0.0748, 0.1686, 0.0742, 0.4566, 0.1140, 0.0499, 0.0204],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,110][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0030, 0.0032, 0.2127, 0.0021, 0.6537, 0.0145, 0.0212, 0.0895],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,112][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0046, 0.0557, 0.0474, 0.1665, 0.0612, 0.2667, 0.2435, 0.1545],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,115][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0075, 0.1290, 0.1126, 0.1541, 0.0700, 0.1628, 0.1733, 0.1907],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,119][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0048, 0.1938, 0.0850, 0.2136, 0.0557, 0.1057, 0.1598, 0.1816],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,123][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0046, 0.1781, 0.1333, 0.1470, 0.1845, 0.1215, 0.1317, 0.0994],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,126][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ house] are: tensor([0.0070, 0.0736, 0.1355, 0.0469, 0.6888, 0.0047, 0.0304, 0.0079, 0.0051],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,129][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ house] are: tensor([2.5052e-09, 6.9903e-03, 1.3295e-02, 5.3342e-04, 2.8976e-01, 8.6350e-02,
        1.2488e-01, 1.8877e-01, 2.8942e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,131][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ house] are: tensor([1.8964e-05, 1.3397e-01, 6.3923e-02, 1.3005e-01, 1.2085e-01, 7.1755e-02,
        1.1500e-01, 2.6137e-01, 1.0307e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,133][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ house] are: tensor([3.4802e-06, 6.2913e-02, 6.9253e-02, 2.7132e-02, 1.5669e-01, 7.7315e-02,
        4.8464e-02, 4.4164e-01, 1.1659e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,134][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ house] are: tensor([0.0559, 0.0565, 0.0918, 0.0687, 0.2159, 0.1152, 0.0534, 0.0331, 0.3095],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,134][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ house] are: tensor([7.3743e-04, 2.2635e-05, 9.1089e-03, 1.5211e-02, 1.0464e-02, 1.3401e-01,
        1.5294e-01, 4.6813e-01, 2.0938e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,135][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ house] are: tensor([0.0121, 0.0436, 0.1669, 0.0403, 0.3541, 0.0623, 0.0311, 0.0078, 0.2818],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,137][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ house] are: tensor([0.0008, 0.0011, 0.0830, 0.0023, 0.5686, 0.0140, 0.0129, 0.0420, 0.2753],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,141][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.0012, 0.0244, 0.0538, 0.1337, 0.0634, 0.3144, 0.2207, 0.1324, 0.0560],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,144][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ house] are: tensor([0.0124, 0.0955, 0.0859, 0.1571, 0.0533, 0.1450, 0.1599, 0.1854, 0.1054],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,148][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.0053, 0.1702, 0.0774, 0.1923, 0.0472, 0.0916, 0.1479, 0.1761, 0.0919],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,152][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ house] are: tensor([0.0091, 0.1452, 0.1192, 0.1153, 0.1474, 0.0963, 0.1159, 0.1071, 0.1444],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,156][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0690, 0.0066, 0.1207, 0.0061, 0.7138, 0.0301, 0.0047, 0.0080, 0.0268,
        0.0141], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,157][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [.] are: tensor([2.2882e-11, 3.3326e-04, 2.0401e-03, 8.7831e-06, 3.5471e-02, 1.4696e-02,
        7.4878e-03, 2.0382e-02, 9.1920e-01, 3.8176e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,158][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [.] are: tensor([2.5061e-05, 8.5073e-02, 6.4288e-02, 7.6739e-02, 1.1753e-01, 7.1509e-02,
        9.5248e-02, 2.7646e-01, 1.1717e-01, 9.5948e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,159][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [.] are: tensor([3.3645e-07, 5.2935e-03, 1.3356e-01, 5.6386e-03, 2.0839e-01, 1.1603e-01,
        1.8589e-02, 2.1106e-01, 2.9902e-01, 2.4194e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,160][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0592, 0.0507, 0.0844, 0.0548, 0.1773, 0.1122, 0.0485, 0.0343, 0.2714,
        0.1072], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,161][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [.] are: tensor([9.8087e-04, 3.4802e-05, 8.5145e-03, 1.8326e-02, 2.1895e-02, 2.3811e-01,
        7.1738e-02, 2.3690e-01, 3.6524e-01, 3.8255e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,164][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0178, 0.0522, 0.1455, 0.0401, 0.2834, 0.0882, 0.0304, 0.0170, 0.2609,
        0.0646], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,168][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0015, 0.0029, 0.0685, 0.0024, 0.6152, 0.0595, 0.0201, 0.1045, 0.1136,
        0.0119], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,171][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0026, 0.0197, 0.0658, 0.1368, 0.0523, 0.2265, 0.1753, 0.1376, 0.0457,
        0.1377], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,175][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0065, 0.0883, 0.0860, 0.1144, 0.0563, 0.1111, 0.1224, 0.1567, 0.0841,
        0.1742], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,180][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0026, 0.1668, 0.0695, 0.1702, 0.0430, 0.0874, 0.1338, 0.1552, 0.0852,
        0.0865], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,182][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0016, 0.1218, 0.1155, 0.0897, 0.1437, 0.0760, 0.0890, 0.0830, 0.1549,
        0.1248], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,183][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.0437, 0.0794, 0.1047, 0.0445, 0.1339, 0.0590, 0.0288, 0.0922, 0.0750,
        0.1610, 0.1777], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,184][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([1.7809e-09, 1.4644e-02, 4.7941e-03, 1.6193e-04, 3.5778e-02, 1.7077e-02,
        1.0513e-02, 7.3540e-02, 8.0030e-01, 2.1884e-03, 4.1001e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,184][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([1.1385e-05, 2.2125e-01, 2.8059e-02, 1.2982e-01, 7.5894e-02, 7.1925e-02,
        8.5942e-02, 1.4202e-01, 7.2740e-02, 1.0052e-01, 7.1813e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,186][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([2.3824e-05, 3.2041e-02, 2.8504e-02, 3.3561e-02, 1.0039e-01, 1.1774e-01,
        4.4798e-02, 4.2541e-01, 1.1565e-01, 1.1988e-02, 8.9892e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,189][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.0951, 0.0456, 0.0692, 0.0488, 0.1393, 0.0896, 0.0405, 0.0329, 0.2408,
        0.0938, 0.1044], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,193][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.0046, 0.0010, 0.0082, 0.0055, 0.0076, 0.0724, 0.1125, 0.3322, 0.1486,
        0.1327, 0.1746], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,197][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.0130, 0.0581, 0.1227, 0.0540, 0.2377, 0.0958, 0.0366, 0.0236, 0.1859,
        0.0783, 0.0942], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,200][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([1.1015e-03, 5.5190e-04, 4.5401e-01, 4.5084e-04, 2.3477e-02, 1.8284e-03,
        1.4073e-03, 7.4065e-03, 3.8000e-03, 1.4040e-03, 5.0456e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,204][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.0005, 0.0985, 0.0542, 0.1268, 0.0493, 0.1609, 0.1820, 0.0778, 0.0422,
        0.1357, 0.0721], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,206][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.0147, 0.0943, 0.0719, 0.0991, 0.0511, 0.1130, 0.1140, 0.1286, 0.0890,
        0.1525, 0.0716], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,207][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.0054, 0.1539, 0.0622, 0.1649, 0.0405, 0.0804, 0.1210, 0.1557, 0.0824,
        0.0776, 0.0559], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,208][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.0048, 0.1136, 0.0878, 0.0915, 0.1191, 0.0827, 0.0801, 0.0906, 0.1196,
        0.1211, 0.0893], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,209][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0696, 0.0146, 0.1341, 0.0138, 0.3613, 0.0128, 0.0048, 0.0081, 0.0604,
        0.0251, 0.2625, 0.0330], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,210][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([1.7112e-10, 3.1938e-03, 1.8252e-03, 8.5003e-05, 2.0374e-02, 1.3480e-02,
        2.3432e-02, 3.6132e-02, 8.4460e-01, 2.1113e-03, 3.9030e-02, 1.5734e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,211][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([3.5827e-06, 1.0038e-01, 3.5675e-02, 9.1440e-02, 6.9635e-02, 5.2121e-02,
        6.6973e-02, 2.1148e-01, 6.8278e-02, 7.5815e-02, 1.1175e-01, 1.1645e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,213][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([3.8216e-07, 2.0995e-02, 2.8166e-02, 9.6906e-03, 5.8862e-02, 5.0044e-02,
        3.9265e-02, 3.3031e-01, 1.4254e-01, 6.2958e-03, 1.0793e-01, 2.0591e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,217][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0916, 0.0421, 0.0659, 0.0445, 0.1447, 0.0836, 0.0391, 0.0260, 0.2042,
        0.0920, 0.0976, 0.0688], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,220][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([2.3160e-03, 2.6923e-04, 1.8616e-02, 6.8870e-03, 1.0847e-02, 3.5708e-02,
        7.9002e-02, 1.3639e-01, 1.0906e-01, 2.8153e-02, 4.5576e-01, 1.1699e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,223][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0283, 0.0393, 0.1110, 0.0320, 0.2257, 0.0562, 0.0170, 0.0118, 0.2217,
        0.0499, 0.0916, 0.1156], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,225][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([3.7893e-04, 9.5066e-04, 7.5501e-02, 5.9410e-04, 2.4264e-01, 9.2422e-03,
        1.3547e-02, 2.2824e-02, 4.3501e-02, 2.5569e-03, 1.6230e-01, 4.2597e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,228][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([1.1675e-04, 4.9880e-02, 3.3287e-02, 1.2306e-01, 2.5238e-02, 1.6771e-01,
        2.1150e-01, 6.6841e-02, 2.8939e-02, 1.0051e-01, 6.4890e-02, 1.2803e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,232][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0090, 0.0880, 0.0823, 0.0836, 0.0386, 0.0965, 0.0999, 0.1161, 0.0710,
        0.1478, 0.0826, 0.0847], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,232][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0052, 0.1414, 0.0601, 0.1551, 0.0366, 0.0747, 0.1154, 0.1433, 0.0734,
        0.0737, 0.0547, 0.0665], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,233][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0047, 0.1041, 0.0852, 0.0772, 0.1223, 0.0679, 0.0704, 0.0633, 0.1210,
        0.1161, 0.0861, 0.0816], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,234][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1832, 0.0230, 0.0986, 0.0499, 0.3853, 0.0132, 0.0200, 0.0165, 0.0248,
        0.0504, 0.1008, 0.0219, 0.0124], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,236][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([2.3955e-10, 1.4274e-03, 1.6920e-03, 2.7222e-05, 2.3342e-02, 6.7006e-03,
        7.1010e-03, 1.0605e-02, 9.2288e-01, 4.1703e-04, 1.7952e-02, 5.5939e-03,
        2.2568e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,238][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([3.9262e-06, 8.2787e-02, 4.3054e-02, 5.0432e-02, 1.2953e-01, 3.8117e-02,
        5.5936e-02, 1.3236e-01, 9.7672e-02, 6.9855e-02, 1.4835e-01, 9.8091e-02,
        5.3817e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,240][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([4.6429e-07, 1.0654e-02, 2.2491e-02, 5.7228e-03, 8.2237e-02, 8.0233e-02,
        4.0783e-02, 1.9654e-01, 2.4914e-01, 4.8662e-03, 8.4979e-02, 1.2243e-01,
        9.9926e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,245][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0512, 0.0332, 0.0598, 0.0441, 0.1438, 0.0929, 0.0443, 0.0302, 0.1971,
        0.0894, 0.1010, 0.0722, 0.0409], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,247][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([3.4044e-03, 1.4316e-04, 6.5768e-03, 1.0548e-02, 9.0627e-03, 4.4573e-02,
        6.5062e-02, 2.5626e-02, 1.0936e-01, 3.0390e-02, 2.7539e-01, 3.0935e-01,
        1.1051e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,251][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0259, 0.0518, 0.0887, 0.0517, 0.1715, 0.0606, 0.0419, 0.0163, 0.2198,
        0.0687, 0.0684, 0.1179, 0.0168], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,256][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0009, 0.0019, 0.1202, 0.0011, 0.3969, 0.0106, 0.0182, 0.0462, 0.1419,
        0.0066, 0.1974, 0.0428, 0.0153], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,256][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0018, 0.0488, 0.0339, 0.1225, 0.0435, 0.1226, 0.1755, 0.0823, 0.0357,
        0.1041, 0.0506, 0.1216, 0.0570], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,257][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0056, 0.0789, 0.0796, 0.0766, 0.0383, 0.0843, 0.0908, 0.1026, 0.0593,
        0.1215, 0.0763, 0.0792, 0.1072], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,258][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0025, 0.1304, 0.0553, 0.1452, 0.0344, 0.0660, 0.1056, 0.1242, 0.0678,
        0.0721, 0.0507, 0.0592, 0.0866], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,260][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0030, 0.1151, 0.0792, 0.0840, 0.0951, 0.0675, 0.0738, 0.0489, 0.1016,
        0.1086, 0.0776, 0.0865, 0.0588], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,263][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0150, 0.0220, 0.0198, 0.0360, 0.0666, 0.0075, 0.0201, 0.0094, 0.0061,
        0.0971, 0.0357, 0.0096, 0.0077, 0.6475], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,265][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([2.4747e-09, 6.9867e-03, 1.5056e-02, 5.2855e-05, 4.3301e-02, 1.1576e-02,
        2.3183e-02, 3.6862e-02, 6.8770e-01, 1.5706e-03, 8.7204e-02, 2.1258e-02,
        9.4374e-03, 5.5815e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,267][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([1.2459e-05, 8.1268e-02, 4.7436e-02, 5.6860e-02, 5.5074e-02, 3.8049e-02,
        4.8534e-02, 1.2681e-01, 6.5505e-02, 5.2192e-02, 1.1630e-01, 1.0724e-01,
        7.4737e-02, 1.2999e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,270][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([8.9114e-07, 1.6866e-02, 1.7717e-02, 1.1507e-02, 4.2010e-02, 5.0629e-02,
        2.4804e-02, 2.4493e-01, 1.1571e-01, 4.4146e-03, 5.6861e-02, 1.7705e-01,
        1.1484e-01, 1.2266e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,274][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0398, 0.0301, 0.0418, 0.0387, 0.0719, 0.0565, 0.0304, 0.0245, 0.1298,
        0.0730, 0.0636, 0.0473, 0.0386, 0.3142], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,278][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.0014, 0.0011, 0.0163, 0.0016, 0.0040, 0.0352, 0.0493, 0.0559, 0.0569,
        0.0181, 0.0988, 0.1535, 0.3904, 0.1174], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,280][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.0094, 0.0249, 0.0458, 0.0294, 0.0606, 0.0189, 0.0129, 0.0047, 0.1200,
        0.0396, 0.0393, 0.0932, 0.0075, 0.4938], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,281][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([6.2385e-05, 9.2598e-05, 2.4396e-03, 5.4725e-05, 7.7237e-03, 7.0190e-04,
        2.8041e-04, 6.9631e-04, 6.8489e-03, 1.5018e-04, 3.9486e-03, 2.3188e-03,
        2.6811e-04, 9.7441e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,282][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.0008, 0.0457, 0.0371, 0.0936, 0.0334, 0.1381, 0.1538, 0.0677, 0.0327,
        0.0870, 0.0560, 0.1292, 0.0521, 0.0730], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,283][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.0085, 0.0691, 0.0679, 0.0683, 0.0296, 0.0691, 0.0801, 0.1038, 0.0526,
        0.1063, 0.0638, 0.0665, 0.1214, 0.0930], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,285][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.0037, 0.1201, 0.0491, 0.1331, 0.0290, 0.0603, 0.1009, 0.1213, 0.0626,
        0.0649, 0.0464, 0.0578, 0.0845, 0.0662], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,287][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.0028, 0.0926, 0.0622, 0.0809, 0.0769, 0.0472, 0.0643, 0.0684, 0.0922,
        0.0985, 0.0620, 0.0606, 0.0817, 0.1097], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,291][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0245, 0.0258, 0.1515, 0.0345, 0.1682, 0.0218, 0.0109, 0.0188, 0.0052,
        0.0205, 0.1173, 0.0155, 0.0169, 0.3565, 0.0121], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,294][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.3941e-10, 6.0965e-04, 1.7528e-03, 2.0210e-05, 2.8893e-02, 5.2937e-02,
        7.0320e-03, 2.9249e-02, 7.0635e-01, 5.3259e-04, 3.0208e-02, 1.2812e-02,
        3.7296e-03, 7.7805e-02, 4.8072e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,296][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([4.3423e-06, 4.5559e-02, 2.4573e-02, 4.3170e-02, 5.3854e-02, 4.1162e-02,
        4.3550e-02, 1.4653e-01, 5.0541e-02, 4.5757e-02, 9.9169e-02, 8.6224e-02,
        9.9612e-02, 1.0143e-01, 1.1886e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,299][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([4.4248e-07, 6.0668e-03, 2.1499e-02, 5.2796e-03, 7.7769e-02, 4.9163e-02,
        1.5973e-02, 2.2485e-01, 1.2721e-01, 3.5737e-03, 8.4139e-02, 1.5911e-01,
        9.8193e-02, 8.9313e-02, 3.7856e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,303][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0294, 0.0237, 0.0446, 0.0289, 0.0936, 0.0611, 0.0283, 0.0210, 0.1385,
        0.0536, 0.0757, 0.0517, 0.0302, 0.2947, 0.0252], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,305][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.4329e-03, 3.8242e-05, 6.4692e-03, 8.2411e-04, 3.2890e-03, 2.7418e-02,
        7.3707e-03, 3.1970e-02, 5.7323e-02, 9.0669e-03, 1.7793e-01, 2.4556e-01,
        1.4581e-01, 1.2826e-01, 1.5724e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,306][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0056, 0.0428, 0.0902, 0.0386, 0.1067, 0.0549, 0.0277, 0.0116, 0.1038,
        0.0480, 0.0710, 0.1317, 0.0135, 0.2227, 0.0312], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,306][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([5.3879e-04, 4.0827e-04, 5.3009e-02, 5.3949e-04, 8.5650e-02, 1.0348e-02,
        4.4694e-03, 2.0681e-02, 2.5059e-02, 2.9312e-03, 1.5652e-01, 7.2281e-02,
        7.1802e-03, 5.1985e-01, 4.0530e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,307][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0016, 0.0464, 0.0353, 0.0960, 0.0443, 0.1374, 0.1398, 0.0778, 0.0288,
        0.0792, 0.0492, 0.1004, 0.0530, 0.0422, 0.0686], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,309][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0043, 0.0621, 0.0650, 0.0655, 0.0347, 0.0694, 0.0716, 0.0870, 0.0488,
        0.0986, 0.0665, 0.0627, 0.0907, 0.0850, 0.0881], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,312][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0014, 0.1165, 0.0489, 0.1179, 0.0300, 0.0622, 0.0924, 0.1087, 0.0601,
        0.0605, 0.0457, 0.0537, 0.0755, 0.0609, 0.0655], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,316][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0006, 0.0909, 0.0711, 0.0693, 0.0946, 0.0464, 0.0561, 0.0475, 0.0982,
        0.0873, 0.0697, 0.0519, 0.0478, 0.1149, 0.0538], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,433][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:55,437][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:55,439][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:55,442][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:55,442][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:55,443][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:55,444][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:55,444][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:55,446][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:55,448][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:55,451][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:55,454][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:55,457][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:55,460][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([2.0417e-04, 9.9980e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:55,462][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([4.7007e-07, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:55,464][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([8.8266e-05, 9.9991e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:55,467][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([5.8331e-04, 9.9942e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:55,467][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9557, 0.0443], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:55,468][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9901, 0.0099], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:55,469][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([4.2595e-05, 9.9996e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:55,470][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1570, 0.8430], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:55,471][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0734, 0.9266], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:55,474][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.3540, 0.6460], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:55,476][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.0000e+00, 2.5905e-06], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:55,479][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([1.2703e-06, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:55,481][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([2.4312e-04, 1.0203e-01, 8.9772e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:55,483][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([9.9984e-08, 8.5380e-01, 1.4620e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:55,485][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([1.3875e-05, 9.8274e-01, 1.7244e-02], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:55,490][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.0009, 0.8810, 0.1181], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:55,492][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.7695, 0.0429, 0.1876], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:55,493][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.0254, 0.0197, 0.9548], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:55,493][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([1.0349e-06, 8.5315e-01, 1.4685e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:55,494][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.0040, 0.0023, 0.9937], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:55,495][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([1.3455e-04, 7.3827e-01, 2.6160e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:55,496][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.2887, 0.5941, 0.1171], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:55,498][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([1.0532e-03, 9.5663e-05, 9.9885e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:55,500][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([4.4457e-09, 9.9872e-01, 1.2835e-03], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:55,503][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([1.3537e-06, 2.1324e-02, 8.2943e-01, 1.4924e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,505][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.6845e-08, 6.7134e-01, 3.0895e-01, 1.9708e-02], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,507][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([6.0079e-06, 2.5351e-01, 2.6577e-01, 4.8071e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,510][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([1.1378e-05, 8.8494e-02, 5.4882e-01, 3.6267e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,513][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.4217, 0.0042, 0.1117, 0.4625], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,515][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([6.0371e-02, 7.6987e-05, 4.2255e-01, 5.1700e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,517][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([2.5783e-07, 2.6466e-01, 6.6259e-01, 7.2750e-02], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,518][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0152, 0.0235, 0.9423, 0.0190], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,519][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([1.1663e-04, 1.9568e-01, 6.7784e-01, 1.2637e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,519][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1295, 0.3871, 0.1367, 0.3467], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,520][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([4.8259e-04, 3.6072e-08, 9.9952e-01, 4.9741e-10], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,521][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([7.3839e-09, 9.4375e-01, 4.5534e-02, 1.0719e-02], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:55,523][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([3.5481e-06, 5.1088e-03, 1.3417e-01, 9.8133e-03, 8.5091e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,524][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([6.9808e-09, 1.5791e-01, 6.6721e-02, 3.3465e-03, 7.7202e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,527][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([7.7248e-06, 7.0685e-01, 1.8095e-02, 2.3997e-01, 3.5073e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,529][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([6.4854e-05, 2.1784e-01, 5.0030e-02, 5.6051e-02, 6.7602e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,533][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.1914, 0.0122, 0.0774, 0.6579, 0.0611], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,535][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([3.8804e-03, 2.4604e-04, 1.9870e-01, 7.3850e-01, 5.8674e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,538][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([8.1240e-07, 1.0915e-01, 7.0312e-01, 8.9246e-03, 1.7880e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,540][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([4.9700e-03, 7.2735e-04, 8.2454e-02, 9.1054e-04, 9.1094e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,542][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([2.7589e-05, 4.2720e-01, 5.5512e-02, 1.3127e-01, 3.8599e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,543][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.1185, 0.3026, 0.1247, 0.3612, 0.0930], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,544][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([9.9115e-05, 2.4617e-07, 5.3343e-02, 2.3337e-09, 9.4656e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,545][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([2.6358e-09, 9.7494e-01, 6.5403e-03, 1.1182e-02, 7.3374e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:55,545][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([1.6289e-06, 1.4063e-02, 2.3421e-02, 2.5422e-02, 8.7243e-02, 8.4985e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,547][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([2.3391e-08, 7.1230e-01, 3.6152e-02, 2.3641e-02, 1.3016e-01, 9.7745e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,549][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([2.3563e-06, 4.2475e-01, 4.8114e-02, 3.6789e-01, 1.0616e-01, 5.3085e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,551][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([4.9650e-06, 2.5102e-01, 2.1920e-02, 6.9691e-02, 1.2092e-01, 5.3644e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,554][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.1627, 0.0064, 0.0609, 0.6107, 0.0764, 0.0830], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,556][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([6.7972e-03, 1.1084e-04, 2.2219e-01, 3.1030e-01, 3.4471e-02, 4.2613e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,559][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([8.0495e-07, 4.1147e-01, 3.9946e-02, 2.6981e-02, 9.2091e-02, 4.2951e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,563][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0057, 0.0086, 0.1059, 0.0029, 0.5311, 0.3458], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,565][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([8.0628e-06, 4.9484e-02, 2.0500e-02, 4.3581e-02, 5.4348e-02, 8.3208e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,567][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.1038, 0.3063, 0.0841, 0.3215, 0.0503, 0.1339], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,568][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([1.3732e-05, 1.7321e-05, 6.4837e-02, 2.9108e-07, 9.0775e-01, 2.7385e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,569][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([5.4327e-09, 9.3470e-01, 2.8747e-03, 6.5442e-03, 8.7809e-03, 4.7102e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:55,570][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([8.4597e-08, 6.4605e-04, 9.3749e-02, 2.4685e-03, 4.3658e-01, 3.8478e-01,
        8.1781e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,570][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([9.0475e-10, 5.9240e-03, 8.8933e-03, 3.3684e-04, 1.0847e-01, 7.9668e-01,
        7.9700e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,572][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.3650e-06, 6.3891e-02, 4.1810e-02, 1.5702e-01, 1.9241e-01, 2.3131e-01,
        3.1355e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,574][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.2240e-06, 1.4573e-02, 3.3352e-02, 1.3305e-02, 3.3740e-01, 5.0631e-01,
        9.5055e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,578][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.3269, 0.0022, 0.0810, 0.3537, 0.0705, 0.0643, 0.1015],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,580][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([4.6582e-02, 7.0096e-05, 1.7509e-01, 2.2770e-01, 3.7052e-02, 2.3525e-01,
        2.7825e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,583][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([3.8684e-08, 2.0128e-02, 1.6095e-01, 8.1634e-03, 8.0933e-02, 5.9342e-01,
        1.3640e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,586][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0037, 0.0064, 0.4203, 0.0070, 0.4174, 0.0983, 0.0470],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,588][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.1467e-05, 5.9470e-03, 1.5776e-02, 4.1196e-03, 8.8509e-02, 6.9500e-01,
        1.9063e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,592][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0494, 0.2238, 0.0999, 0.2745, 0.0498, 0.1075, 0.1950],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,593][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.5885e-05, 7.3387e-10, 4.1036e-02, 1.3581e-11, 9.4807e-01, 1.0861e-02,
        4.7622e-08], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,594][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([4.4693e-08, 2.5140e-01, 2.8396e-02, 1.6686e-02, 1.1498e-01, 3.4633e-02,
        5.5390e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:55,594][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([9.0883e-07, 6.2915e-04, 5.3666e-02, 2.1502e-04, 7.7703e-01, 1.3397e-01,
        1.5570e-02, 1.8920e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,595][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([1.0264e-08, 2.0490e-02, 3.2474e-02, 3.2026e-04, 4.4944e-01, 1.7111e-01,
        1.0086e-01, 2.2531e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,597][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([1.5890e-05, 1.8137e-01, 9.8819e-02, 4.7453e-02, 4.9039e-01, 3.6256e-02,
        9.2200e-02, 5.3488e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,599][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([7.6645e-06, 1.9293e-02, 1.8257e-02, 8.9590e-03, 1.4415e-01, 4.2729e-01,
        1.2869e-01, 2.5335e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,603][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.4045, 0.0027, 0.0714, 0.2550, 0.0752, 0.0616, 0.0671, 0.0625],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,605][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([4.0910e-02, 1.9762e-04, 1.4645e-01, 7.1297e-02, 1.9641e-02, 1.0927e-01,
        1.7815e-01, 4.3408e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,608][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([7.0062e-08, 5.0307e-02, 1.8002e-01, 1.6239e-03, 3.2299e-01, 3.2552e-01,
        6.6262e-02, 5.3280e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,611][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0030, 0.0032, 0.2127, 0.0021, 0.6537, 0.0145, 0.0212, 0.0895],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,613][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([6.0663e-05, 3.1853e-02, 1.5555e-02, 6.8318e-03, 3.9626e-02, 4.3892e-01,
        4.1204e-01, 5.5123e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,617][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0205, 0.2143, 0.0869, 0.1928, 0.0418, 0.1135, 0.1857, 0.1446],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,618][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([3.6455e-05, 2.2486e-09, 4.8741e-02, 9.7777e-12, 9.4867e-01, 2.5481e-03,
        3.4314e-08, 5.3847e-08], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,619][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([6.1200e-09, 2.9565e-01, 8.6373e-03, 4.2660e-03, 1.5029e-02, 4.2947e-02,
        5.4598e-01, 8.7496e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:55,619][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([2.8283e-07, 2.0641e-04, 4.8901e-02, 8.7191e-04, 3.5026e-01, 1.2023e-01,
        2.0643e-02, 5.9515e-02, 3.9937e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,620][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([2.5052e-09, 6.9903e-03, 1.3295e-02, 5.3342e-04, 2.8976e-01, 8.6350e-02,
        1.2488e-01, 1.8877e-01, 2.8942e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,621][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([1.9119e-06, 3.4539e-02, 5.5792e-02, 5.3074e-02, 3.1169e-01, 3.5077e-02,
        1.1577e-01, 1.0781e-01, 2.8624e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,624][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([9.1394e-07, 2.3813e-02, 1.5704e-02, 8.5864e-03, 1.5423e-01, 1.4013e-01,
        4.6220e-02, 2.1036e-01, 4.0095e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,628][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([0.1543, 0.0017, 0.0471, 0.4345, 0.0681, 0.0613, 0.0766, 0.0461, 0.1103],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,630][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([2.5411e-04, 1.4840e-05, 5.9078e-02, 1.0920e-01, 6.2795e-03, 1.2247e-01,
        2.4533e-01, 4.4599e-01, 1.1392e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,633][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([5.5579e-07, 6.6125e-03, 1.1155e-01, 1.1018e-03, 2.6907e-01, 2.5885e-01,
        4.1189e-02, 2.8950e-02, 2.8268e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,636][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([0.0008, 0.0011, 0.0830, 0.0023, 0.5686, 0.0140, 0.0129, 0.0420, 0.2753],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,638][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([1.2086e-05, 4.9421e-02, 3.0718e-02, 6.2392e-02, 9.8907e-02, 2.0153e-01,
        1.9977e-01, 2.4592e-01, 1.1133e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,642][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([0.0834, 0.1668, 0.0502, 0.2046, 0.0317, 0.0797, 0.1895, 0.1403, 0.0538],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,643][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([4.6536e-06, 1.1257e-08, 3.4852e-02, 4.0427e-10, 8.8347e-01, 8.9639e-04,
        2.4239e-07, 4.0688e-07, 8.0775e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,644][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([1.4722e-09, 1.5188e-01, 1.6389e-03, 5.9897e-04, 1.7109e-03, 1.6856e-02,
        4.9392e-01, 3.2745e-01, 5.9550e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:55,644][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([1.7072e-08, 3.7728e-05, 3.0505e-02, 3.8449e-05, 2.8394e-01, 5.5183e-02,
        3.1202e-03, 8.2064e-03, 6.1812e-01, 8.5906e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,645][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([2.2882e-11, 3.3326e-04, 2.0401e-03, 8.7831e-06, 3.5471e-02, 1.4696e-02,
        7.4878e-03, 2.0382e-02, 9.1920e-01, 3.8176e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,647][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([3.2861e-07, 5.9807e-03, 4.6594e-02, 4.9306e-03, 3.0243e-01, 2.7055e-02,
        3.6934e-02, 1.1561e-01, 4.3606e-01, 2.4404e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,649][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([6.8887e-08, 1.2255e-04, 9.3147e-03, 1.9350e-04, 4.5526e-02, 6.3287e-02,
        1.9233e-03, 1.7053e-02, 8.6247e-01, 1.1251e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,653][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.3392, 0.0016, 0.0539, 0.2382, 0.0403, 0.0334, 0.0519, 0.0407, 0.0664,
        0.1344], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,655][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([7.2675e-02, 2.4504e-05, 7.5405e-02, 4.9396e-02, 1.1634e-02, 4.8623e-02,
        7.3378e-02, 2.8574e-01, 3.8483e-03, 3.7927e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,657][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([2.8230e-09, 3.3001e-03, 1.0814e-01, 2.6143e-04, 1.1227e-01, 1.4109e-01,
        1.1486e-02, 1.5260e-02, 6.0229e-01, 5.9064e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,661][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0015, 0.0029, 0.0685, 0.0024, 0.6152, 0.0595, 0.0201, 0.1045, 0.1136,
        0.0119], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,663][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([7.5535e-06, 3.7830e-04, 9.7393e-03, 2.2413e-03, 2.4206e-02, 2.6428e-01,
        2.5413e-01, 3.2296e-01, 1.1944e-01, 2.6308e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,667][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0309, 0.1205, 0.0736, 0.1365, 0.0355, 0.0672, 0.1285, 0.1431, 0.0517,
        0.2124], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,668][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([3.3624e-06, 3.0111e-11, 1.7462e-02, 1.4332e-13, 5.1610e-01, 1.2129e-03,
        3.1568e-09, 4.2912e-09, 4.6522e-01, 7.1029e-09], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,669][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([7.0143e-09, 1.9515e-02, 1.2918e-02, 6.7677e-04, 3.5622e-02, 1.4650e-02,
        3.6656e-01, 1.5111e-01, 3.9492e-01, 4.0259e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:55,669][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([1.5861e-06, 4.8973e-04, 1.8348e-02, 2.9117e-04, 2.8629e-02, 8.3093e-02,
        2.2776e-03, 1.1641e-02, 7.3278e-01, 2.4807e-03, 1.1997e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,671][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([1.7809e-09, 1.4644e-02, 4.7941e-03, 1.6193e-04, 3.5778e-02, 1.7077e-02,
        1.0513e-02, 7.3540e-02, 8.0030e-01, 2.1884e-03, 4.1001e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,672][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([4.3343e-06, 2.9890e-01, 1.1361e-02, 1.1834e-01, 1.0828e-01, 6.6005e-02,
        8.4784e-02, 3.8793e-02, 1.4813e-01, 9.6706e-02, 2.8697e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,674][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([4.0736e-05, 2.7400e-02, 7.4841e-03, 1.6942e-02, 5.3692e-02, 1.8475e-01,
        3.8613e-02, 2.6645e-01, 3.5979e-01, 1.0099e-02, 3.4742e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,678][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.4641, 0.0024, 0.0269, 0.0990, 0.0239, 0.0153, 0.0247, 0.0233, 0.0310,
        0.0719, 0.2174], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,680][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([5.9599e-03, 1.7913e-05, 7.2799e-03, 6.8326e-04, 2.6710e-04, 1.4773e-03,
        4.2009e-03, 1.6093e-02, 1.3309e-04, 1.2905e-02, 9.5098e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,683][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([1.3508e-07, 8.4423e-02, 2.9931e-02, 3.6748e-03, 7.8719e-02, 2.1219e-01,
        3.1380e-02, 5.5701e-02, 2.8102e-01, 4.2393e-02, 1.8057e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,685][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([1.1015e-03, 5.5190e-04, 4.5401e-01, 4.5084e-04, 2.3477e-02, 1.8284e-03,
        1.4073e-03, 7.4065e-03, 3.8000e-03, 1.4040e-03, 5.0456e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,688][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([1.0467e-05, 5.7076e-02, 3.2927e-02, 2.2082e-02, 1.6217e-01, 2.6305e-01,
        1.2714e-01, 1.0240e-01, 1.0909e-01, 3.2995e-02, 9.1066e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,692][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.1056, 0.1416, 0.0378, 0.1153, 0.0308, 0.0932, 0.1225, 0.0943, 0.0661,
        0.1611, 0.0317], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,692][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([8.1201e-06, 8.8068e-07, 2.6462e-02, 1.6624e-08, 4.1287e-01, 1.8221e-02,
        1.9897e-06, 1.1106e-05, 4.9407e-01, 1.3327e-05, 4.8341e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,693][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([8.7705e-09, 4.3718e-01, 1.9177e-03, 1.2232e-03, 2.7559e-03, 2.7617e-02,
        1.9511e-01, 3.2168e-01, 9.3777e-03, 2.1191e-03, 1.0221e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:55,694][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([3.0731e-08, 3.1672e-04, 1.1811e-02, 4.0782e-04, 3.1868e-02, 6.0951e-02,
        5.9895e-03, 2.0139e-02, 6.1018e-01, 4.4635e-03, 1.3522e-01, 1.1866e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,695][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([1.7112e-10, 3.1938e-03, 1.8252e-03, 8.5003e-05, 2.0374e-02, 1.3480e-02,
        2.3432e-02, 3.6132e-02, 8.4460e-01, 2.1113e-03, 3.9030e-02, 1.5734e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,697][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([1.4252e-07, 6.0298e-02, 2.1199e-02, 5.4462e-02, 1.0561e-01, 3.1333e-02,
        7.7320e-02, 9.7792e-02, 2.1493e-01, 6.1051e-02, 8.2797e-02, 1.9320e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,698][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([3.8632e-07, 1.1054e-02, 4.1926e-03, 3.5930e-03, 2.5498e-02, 6.1036e-02,
        4.1209e-02, 1.3307e-01, 6.0101e-01, 3.2478e-03, 2.2906e-02, 9.3186e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,703][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.2907, 0.0011, 0.0174, 0.1073, 0.0272, 0.0159, 0.0203, 0.0187, 0.0233,
        0.0676, 0.2904, 0.1201], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,705][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([1.6290e-04, 1.8076e-06, 3.1578e-03, 2.3581e-04, 5.8071e-05, 5.9520e-04,
        1.5002e-03, 4.6630e-03, 4.1524e-05, 5.2501e-03, 9.5136e-01, 3.2972e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,708][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([2.3898e-08, 7.1953e-03, 3.5372e-02, 5.0066e-04, 6.6467e-02, 1.7270e-01,
        1.0134e-02, 8.5093e-03, 3.3954e-01, 6.3110e-03, 2.9183e-01, 6.1441e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,710][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([3.7893e-04, 9.5066e-04, 7.5501e-02, 5.9410e-04, 2.4264e-01, 9.2422e-03,
        1.3547e-02, 2.2824e-02, 4.3501e-02, 2.5569e-03, 1.6230e-01, 4.2597e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,712][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([5.1737e-07, 1.1439e-02, 3.1700e-02, 1.6364e-02, 4.1585e-02, 2.8424e-01,
        1.3917e-01, 2.1836e-01, 5.9636e-02, 1.8452e-02, 1.2552e-01, 5.3532e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,716][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0777, 0.1290, 0.0605, 0.0983, 0.0251, 0.0719, 0.1060, 0.0901, 0.0550,
        0.1715, 0.0621, 0.0528], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,717][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([1.7092e-06, 4.9190e-07, 2.3954e-02, 2.1965e-08, 2.9313e-01, 1.6077e-02,
        7.8987e-06, 2.0586e-05, 5.7774e-01, 3.6182e-05, 8.3736e-02, 5.2942e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,718][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([5.6641e-09, 1.7205e-01, 2.8592e-03, 1.2663e-03, 9.2503e-03, 1.5726e-02,
        4.0629e-01, 1.8916e-01, 1.2613e-01, 5.9269e-03, 3.1969e-03, 6.8141e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:55,719][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.8366e-07, 1.6509e-04, 1.4737e-02, 5.8014e-05, 1.0734e-01, 3.0340e-02,
        3.7210e-03, 4.6991e-03, 6.5530e-01, 1.2076e-03, 1.1885e-01, 6.2761e-02,
        8.2473e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,720][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([2.3955e-10, 1.4274e-03, 1.6920e-03, 2.7222e-05, 2.3342e-02, 6.7006e-03,
        7.1010e-03, 1.0605e-02, 9.2288e-01, 4.1703e-04, 1.7952e-02, 5.5939e-03,
        2.2568e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,721][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([4.4910e-06, 3.0515e-02, 4.2405e-02, 1.0142e-02, 2.6432e-01, 1.4568e-02,
        4.0737e-02, 3.5339e-02, 3.0168e-01, 3.0123e-02, 1.4136e-01, 8.3658e-02,
        5.1380e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,723][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([4.0213e-06, 6.7416e-03, 4.4466e-03, 2.0225e-03, 2.8745e-02, 8.0733e-02,
        3.4411e-02, 7.6787e-02, 6.9947e-01, 3.2577e-03, 2.1128e-02, 2.9696e-02,
        1.2555e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,727][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1503, 0.0022, 0.0269, 0.0868, 0.0345, 0.0247, 0.0278, 0.0296, 0.0421,
        0.0976, 0.2724, 0.1415, 0.0637], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,730][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([3.1576e-03, 2.7790e-05, 7.7060e-03, 1.1429e-03, 5.0092e-04, 2.3642e-03,
        4.9124e-03, 1.5163e-02, 2.1547e-04, 1.5711e-02, 7.6235e-01, 4.2531e-02,
        1.4422e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,732][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([3.5672e-08, 1.8498e-02, 2.3570e-02, 7.1976e-04, 6.7688e-02, 8.3180e-02,
        3.2149e-02, 2.7006e-02, 4.6579e-01, 1.6328e-02, 1.7095e-01, 8.8307e-02,
        5.8054e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,736][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0009, 0.0019, 0.1202, 0.0011, 0.3969, 0.0106, 0.0182, 0.0462, 0.1419,
        0.0066, 0.1974, 0.0428, 0.0153], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,738][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([2.2985e-05, 1.6940e-02, 1.5307e-02, 1.4154e-02, 4.4602e-02, 1.5697e-01,
        2.7892e-01, 7.0977e-02, 1.7460e-01, 1.8894e-02, 4.6720e-02, 1.4761e-01,
        1.4273e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,741][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0422, 0.1192, 0.0648, 0.0956, 0.0265, 0.0566, 0.0979, 0.0686, 0.0338,
        0.1508, 0.0706, 0.0703, 0.1032], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,742][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([1.3021e-05, 1.1947e-08, 2.5044e-02, 9.9282e-11, 6.7644e-01, 1.7538e-03,
        1.3596e-07, 2.9736e-07, 2.4971e-01, 6.4038e-07, 4.6049e-02, 9.8658e-04,
        1.9184e-06], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,743][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([5.0077e-09, 2.8093e-01, 3.8969e-03, 2.4428e-03, 5.8937e-03, 2.0449e-02,
        3.9752e-01, 3.7251e-02, 7.9612e-02, 8.2803e-03, 5.0042e-03, 1.5403e-01,
        4.6807e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:55,744][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([1.7532e-06, 5.4736e-04, 1.1298e-02, 1.6658e-04, 9.1381e-02, 7.9367e-02,
        3.7233e-03, 9.1046e-03, 5.3631e-01, 1.9484e-03, 6.4267e-02, 9.9562e-02,
        1.5813e-03, 1.0075e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,745][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([2.4747e-09, 6.9867e-03, 1.5056e-02, 5.2855e-05, 4.3301e-02, 1.1576e-02,
        2.3183e-02, 3.6862e-02, 6.8770e-01, 1.5706e-03, 8.7204e-02, 2.1258e-02,
        9.4374e-03, 5.5815e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,747][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([2.1237e-06, 2.3348e-02, 4.3705e-02, 1.0898e-02, 5.1208e-02, 1.1534e-02,
        1.9274e-02, 3.4635e-02, 1.6385e-01, 1.4993e-02, 1.0443e-01, 1.4900e-01,
        6.0528e-03, 3.6707e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,750][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([8.1647e-07, 5.2125e-03, 1.9945e-03, 1.5426e-03, 1.6794e-02, 6.0460e-02,
        1.4969e-02, 8.3835e-02, 6.3795e-01, 9.6355e-04, 1.0695e-02, 5.5606e-02,
        9.8443e-03, 1.0014e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,754][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.2367, 0.0008, 0.0153, 0.0313, 0.0142, 0.0085, 0.0110, 0.0131, 0.0160,
        0.0340, 0.1410, 0.0559, 0.0426, 0.3796], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,756][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([6.2393e-03, 1.7288e-05, 9.6537e-03, 2.5962e-04, 1.2452e-04, 6.1062e-04,
        1.2663e-03, 5.9362e-03, 4.4326e-05, 3.3216e-03, 4.2643e-01, 2.0262e-02,
        1.0100e-01, 4.2484e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,758][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([1.9287e-07, 1.9365e-02, 2.4769e-02, 6.4536e-04, 2.1881e-02, 2.9542e-02,
        1.4004e-02, 1.0115e-02, 4.1635e-01, 7.3649e-03, 1.3092e-01, 9.8010e-02,
        6.7403e-03, 2.2029e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,761][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([6.2385e-05, 9.2598e-05, 2.4396e-03, 5.4725e-05, 7.7237e-03, 7.0190e-04,
        2.8041e-04, 6.9631e-04, 6.8489e-03, 1.5018e-04, 3.9486e-03, 2.3188e-03,
        2.6811e-04, 9.7441e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,763][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([1.4627e-05, 6.1665e-02, 1.0156e-02, 1.8296e-02, 6.6956e-02, 1.2426e-01,
        2.7358e-01, 1.3138e-01, 1.1381e-01, 2.4100e-02, 3.0949e-02, 6.1718e-02,
        5.3991e-02, 2.9126e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,766][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.0949, 0.0907, 0.0415, 0.0667, 0.0151, 0.0315, 0.0799, 0.0837, 0.0268,
        0.1090, 0.0425, 0.0355, 0.2016, 0.0806], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,768][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([2.1517e-05, 3.7692e-07, 2.8515e-02, 3.7872e-09, 3.7723e-01, 3.8834e-03,
        1.5500e-06, 2.0172e-06, 4.5575e-01, 5.8791e-06, 4.0830e-02, 5.2548e-03,
        1.1533e-05, 8.8496e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,769][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([5.0999e-09, 5.7838e-01, 1.0269e-03, 2.3616e-03, 1.2800e-03, 3.5343e-03,
        1.7361e-01, 1.8326e-01, 1.8143e-02, 3.9985e-03, 8.9751e-04, 1.7800e-02,
        1.3357e-02, 2.3649e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:55,770][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([3.0402e-08, 4.4622e-05, 1.5300e-02, 6.3011e-05, 7.3872e-02, 2.8519e-02,
        3.1534e-03, 5.9451e-03, 5.2110e-01, 1.1790e-03, 1.7661e-01, 7.7719e-02,
        1.2225e-03, 6.8962e-02, 2.6310e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,771][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.3941e-10, 6.0965e-04, 1.7528e-03, 2.0210e-05, 2.8893e-02, 5.2937e-02,
        7.0320e-03, 2.9249e-02, 7.0635e-01, 5.3259e-04, 3.0208e-02, 1.2812e-02,
        3.7296e-03, 7.7805e-02, 4.8072e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,772][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([8.3015e-07, 7.4895e-03, 1.8753e-02, 1.0892e-02, 8.1120e-02, 4.0522e-02,
        3.4108e-02, 5.9232e-02, 1.4233e-01, 2.2054e-02, 1.1986e-01, 1.4987e-01,
        1.1736e-02, 2.3424e-01, 6.7784e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,774][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([5.2114e-07, 1.7740e-03, 3.2862e-03, 8.0941e-04, 3.7704e-02, 6.7523e-02,
        9.0676e-03, 7.6708e-02, 6.5751e-01, 1.3385e-03, 2.3526e-02, 4.4618e-02,
        9.0164e-03, 5.1188e-02, 1.5927e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,778][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1208, 0.0013, 0.0176, 0.0524, 0.0197, 0.0143, 0.0190, 0.0175, 0.0240,
        0.0527, 0.1658, 0.0895, 0.0444, 0.3117, 0.0492], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,780][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([3.1056e-03, 8.5939e-06, 4.0306e-03, 3.3514e-04, 1.4453e-04, 5.7466e-04,
        1.1653e-03, 5.1438e-03, 4.0902e-05, 4.0358e-03, 3.8519e-01, 1.6012e-02,
        7.5018e-02, 3.3804e-01, 1.6715e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,782][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([8.9601e-09, 2.7527e-03, 2.5613e-02, 4.2333e-04, 2.7555e-02, 8.2146e-02,
        1.5618e-02, 2.5880e-02, 2.0928e-01, 9.2953e-03, 3.1631e-01, 1.0079e-01,
        7.2014e-03, 7.3179e-02, 1.0396e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,784][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([5.3879e-04, 4.0827e-04, 5.3009e-02, 5.3949e-04, 8.5650e-02, 1.0348e-02,
        4.4694e-03, 2.0681e-02, 2.5059e-02, 2.9312e-03, 1.5652e-01, 7.2281e-02,
        7.1802e-03, 5.1985e-01, 4.0530e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,787][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([5.2725e-06, 5.1094e-03, 5.1111e-03, 3.2482e-03, 2.6309e-02, 2.9298e-01,
        1.5043e-01, 2.2364e-01, 9.1698e-02, 5.2986e-03, 2.4034e-02, 4.0102e-02,
        5.1770e-02, 1.6978e-02, 6.3291e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,791][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0320, 0.0827, 0.0564, 0.0751, 0.0247, 0.0446, 0.0617, 0.0832, 0.0311,
        0.1104, 0.0615, 0.0478, 0.1208, 0.0841, 0.0840], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,793][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.9280e-05, 9.3827e-10, 2.5910e-02, 1.3860e-11, 6.3716e-01, 4.3491e-03,
        4.5398e-08, 1.1218e-07, 2.2598e-01, 2.1441e-07, 5.5700e-02, 9.9107e-04,
        1.9294e-06, 4.9882e-02, 5.8776e-07], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,794][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([3.9679e-08, 5.6725e-02, 9.8787e-03, 3.5691e-03, 4.7279e-02, 1.1267e-02,
        1.6856e-01, 1.3985e-01, 3.3209e-01, 7.3856e-03, 1.8766e-02, 7.3927e-02,
        7.9316e-03, 6.6167e-02, 5.6601e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:55,797][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:55,800][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[20135],
        [14967],
        [ 9098],
        [ 1636],
        [    1],
        [ 4123],
        [  967],
        [ 6117],
        [ 3253],
        [  338],
        [ 5261],
        [  894],
        [ 3455],
        [ 4351],
        [ 1425]], device='cuda:0')
[2024-07-24 10:21:55,803][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[17404],
        [ 6675],
        [ 4693],
        [  950],
        [    2],
        [ 5192],
        [ 3063],
        [11992],
        [ 9062],
        [ 1616],
        [ 3172],
        [ 1212],
        [ 5660],
        [ 1736],
        [ 1561]], device='cuda:0')
[2024-07-24 10:21:55,805][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[36654],
        [28553],
        [21752],
        [31359],
        [    1],
        [20704],
        [    4],
        [    1],
        [    1],
        [    1],
        [ 5179],
        [   85],
        [    9],
        [12773],
        [ 2548]], device='cuda:0')
[2024-07-24 10:21:55,808][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[15645],
        [ 6753],
        [ 5712],
        [ 4978],
        [46969],
        [14353],
        [26828],
        [38937],
        [22536],
        [ 3574],
        [ 3273],
        [ 3026],
        [ 3248],
        [ 3135],
        [ 3173]], device='cuda:0')
[2024-07-24 10:21:55,811][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 6576],
        [ 5272],
        [ 9376],
        [12659],
        [18228],
        [30422],
        [34793],
        [37793],
        [33046],
        [33541],
        [28513],
        [32499],
        [40878],
        [29953],
        [29016]], device='cuda:0')
[2024-07-24 10:21:55,813][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[11148],
        [48923],
        [45603],
        [22016],
        [50109],
        [47533],
        [49256],
        [48852],
        [47375],
        [42481],
        [43655],
        [37120],
        [34042],
        [32574],
        [36315]], device='cuda:0')
[2024-07-24 10:21:55,816][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[28910],
        [ 8288],
        [14190],
        [13558],
        [11838],
        [10148],
        [ 9572],
        [ 9538],
        [ 5419],
        [ 5306],
        [ 6245],
        [ 7244],
        [ 7109],
        [ 4939],
        [ 5140]], device='cuda:0')
[2024-07-24 10:21:55,819][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[45871],
        [43091],
        [41728],
        [38834],
        [38462],
        [33720],
        [35135],
        [39510],
        [42126],
        [39117],
        [41342],
        [37167],
        [38753],
        [42146],
        [40358]], device='cuda:0')
[2024-07-24 10:21:55,821][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[28193],
        [30227],
        [11815],
        [12343],
        [   45],
        [   42],
        [   61],
        [   19],
        [  105],
        [  231],
        [  356],
        [  361],
        [  757],
        [  952],
        [  543]], device='cuda:0')
[2024-07-24 10:21:55,823][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[20655],
        [ 5776],
        [  885],
        [  882],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [  689],
        [    1],
        [    1],
        [16018],
        [  993]], device='cuda:0')
[2024-07-24 10:21:55,824][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[32228],
        [37519],
        [37555],
        [35822],
        [35577],
        [26010],
        [24449],
        [25149],
        [24118],
        [25189],
        [27170],
        [24260],
        [24504],
        [24416],
        [24414]], device='cuda:0')
[2024-07-24 10:21:55,825][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[32100],
        [10104],
        [ 2894],
        [ 4611],
        [ 3018],
        [ 2720],
        [ 3377],
        [ 3653],
        [ 4061],
        [ 4849],
        [ 4143],
        [ 4169],
        [ 4408],
        [ 4369],
        [ 4697]], device='cuda:0')
[2024-07-24 10:21:55,828][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[31822],
        [23424],
        [19340],
        [21192],
        [14414],
        [17475],
        [17268],
        [17653],
        [18957],
        [19424],
        [18711],
        [18914],
        [20234],
        [21068],
        [20796]], device='cuda:0')
[2024-07-24 10:21:55,831][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[38015],
        [ 2480],
        [ 3166],
        [ 2732],
        [  454],
        [  647],
        [  582],
        [  795],
        [ 1037],
        [  979],
        [ 1229],
        [ 1333],
        [ 1674],
        [ 1842],
        [ 1566]], device='cuda:0')
[2024-07-24 10:21:55,833][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[35092],
        [44692],
        [42204],
        [41755],
        [39331],
        [32759],
        [35960],
        [39910],
        [27178],
        [43299],
        [41324],
        [36319],
        [39698],
        [39351],
        [38445]], device='cuda:0')
[2024-07-24 10:21:55,836][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[36798],
        [49423],
        [49211],
        [48984],
        [47135],
        [47469],
        [47438],
        [47152],
        [47708],
        [46991],
        [46582],
        [46498],
        [46602],
        [45829],
        [46729]], device='cuda:0')
[2024-07-24 10:21:55,839][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[41996],
        [46062],
        [43563],
        [38596],
        [47754],
        [45455],
        [41892],
        [48949],
        [49482],
        [46834],
        [47470],
        [47048],
        [46531],
        [47438],
        [47743]], device='cuda:0')
[2024-07-24 10:21:55,841][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[45892],
        [47755],
        [47543],
        [40711],
        [47462],
        [45526],
        [35335],
        [34936],
        [41230],
        [42829],
        [44176],
        [38100],
        [36639],
        [40660],
        [35969]], device='cuda:0')
[2024-07-24 10:21:55,844][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[33877],
        [16759],
        [20120],
        [42477],
        [43414],
        [34893],
        [43307],
        [43084],
        [39779],
        [36636],
        [36859],
        [33650],
        [35314],
        [34689],
        [35778]], device='cuda:0')
[2024-07-24 10:21:55,847][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[28087],
        [28376],
        [24500],
        [30827],
        [33536],
        [33467],
        [32775],
        [32253],
        [34521],
        [34334],
        [35816],
        [36160],
        [36494],
        [33954],
        [35227]], device='cuda:0')
[2024-07-24 10:21:55,849][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[37393],
        [35668],
        [12708],
        [ 9097],
        [ 8066],
        [ 6926],
        [ 7947],
        [12360],
        [12051],
        [15808],
        [10811],
        [10634],
        [10883],
        [ 8542],
        [ 9638]], device='cuda:0')
[2024-07-24 10:21:55,850][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[30471],
        [21561],
        [20017],
        [29914],
        [30620],
        [35333],
        [37001],
        [35400],
        [39483],
        [44206],
        [39303],
        [38935],
        [42529],
        [41778],
        [36082]], device='cuda:0')
[2024-07-24 10:21:55,852][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[44059],
        [43442],
        [49024],
        [49057],
        [37848],
        [37186],
        [44464],
        [40956],
        [38842],
        [39223],
        [48946],
        [44376],
        [43636],
        [36212],
        [37777]], device='cuda:0')
[2024-07-24 10:21:55,853][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[33700],
        [37206],
        [37997],
        [40532],
        [41529],
        [42867],
        [42166],
        [39536],
        [37515],
        [34956],
        [41197],
        [36801],
        [41073],
        [39231],
        [35995]], device='cuda:0')
[2024-07-24 10:21:55,856][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[41600],
        [47262],
        [47734],
        [46377],
        [46751],
        [45417],
        [43687],
        [42837],
        [42458],
        [41993],
        [42387],
        [42835],
        [42800],
        [41979],
        [41500]], device='cuda:0')
[2024-07-24 10:21:55,859][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[38363],
        [38363],
        [46743],
        [46742],
        [42830],
        [42931],
        [42899],
        [42845],
        [42672],
        [41513],
        [41788],
        [42114],
        [42109],
        [42474],
        [42331]], device='cuda:0')
[2024-07-24 10:21:55,861][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[20752],
        [34130],
        [34121],
        [34101],
        [34081],
        [33428],
        [33428],
        [32827],
        [31432],
        [34108],
        [30915],
        [31443],
        [31356],
        [31867],
        [32198]], device='cuda:0')
[2024-07-24 10:21:55,864][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[2076],
        [ 865],
        [ 874],
        [ 813],
        [ 951],
        [1243],
        [1364],
        [1068],
        [ 891],
        [ 912],
        [ 930],
        [1154],
        [1055],
        [1388],
        [1468]], device='cuda:0')
[2024-07-24 10:21:55,867][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[10459],
        [ 2625],
        [ 6251],
        [ 3410],
        [10602],
        [12110],
        [ 4402],
        [ 5527],
        [18180],
        [ 2592],
        [ 7259],
        [15913],
        [ 5746],
        [ 8685],
        [ 4831]], device='cuda:0')
[2024-07-24 10:21:55,869][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[42507],
        [42507],
        [42507],
        [42507],
        [42507],
        [42507],
        [42507],
        [42507],
        [42507],
        [42507],
        [42507],
        [42507],
        [42507],
        [42507],
        [42507]], device='cuda:0')
[2024-07-24 10:21:55,989][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:55,992][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:55,995][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:55,996][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:55,997][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:55,998][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:55,999][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:55,999][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:56,000][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:56,001][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:56,001][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:56,002][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:56,003][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:56,003][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9205, 0.0795], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,004][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0628, 0.9372], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,005][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9934, 0.0066], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,005][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.8923, 0.1077], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,006][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([8.5136e-04, 9.9915e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,007][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([2.2654e-04, 9.9977e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,011][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9668, 0.0332], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,013][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([1.3575e-05, 9.9999e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,014][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0444, 0.9556], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,015][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1307, 0.8693], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,015][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0105, 0.9895], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,016][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0012, 0.9988], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,017][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([8.3806e-01, 6.0847e-06, 1.6193e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,020][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.0400, 0.3389, 0.6211], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,024][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.8881, 0.0946, 0.0173], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,026][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([9.9872e-01, 2.0782e-04, 1.0726e-03], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,028][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([3.7139e-04, 6.0672e-01, 3.9291e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,031][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([2.0221e-04, 5.9573e-01, 4.0406e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,034][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.8880, 0.0310, 0.0810], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,036][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([2.0287e-06, 4.5510e-01, 5.4490e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,038][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.0114, 0.5846, 0.4041], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,039][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.0097, 0.1148, 0.8756], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,039][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.0043, 0.7047, 0.2909], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,040][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.1178, 0.7455, 0.1368], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,041][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1253, 0.0009, 0.8688, 0.0050], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,042][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([4.7240e-04, 6.2025e-04, 9.9407e-01, 4.8384e-03], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,045][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.5328, 0.0177, 0.4479, 0.0016], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,047][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([9.6135e-01, 5.9641e-04, 3.4177e-02, 3.8752e-03], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,052][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0004, 0.3753, 0.2750, 0.3493], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,054][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([7.0934e-05, 4.8166e-02, 9.5033e-01, 1.4375e-03], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,058][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0926, 0.2856, 0.6189, 0.0028], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,060][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([4.6566e-06, 9.9382e-02, 5.0831e-01, 3.9231e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,063][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0189, 0.4202, 0.2577, 0.3032], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,064][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0011, 0.0131, 0.9839, 0.0019], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,064][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0011, 0.2335, 0.0618, 0.7037], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,065][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0447, 0.3226, 0.1422, 0.4905], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,066][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([7.5773e-02, 7.9762e-06, 7.2486e-01, 1.6612e-05, 1.9934e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,068][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0011, 0.0517, 0.1564, 0.0699, 0.7209], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,070][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.1025, 0.0139, 0.0348, 0.0023, 0.8464], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,073][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([8.9755e-01, 6.8421e-04, 8.2806e-02, 1.7122e-02, 1.8354e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,075][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([1.8660e-04, 2.6952e-01, 1.8250e-01, 2.5449e-01, 2.9329e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,077][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([5.5082e-07, 8.9895e-04, 1.9784e-03, 1.2454e-05, 9.9711e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,079][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([4.4963e-03, 2.9369e-03, 1.1405e-02, 9.1668e-05, 9.8107e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,082][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([8.5142e-06, 2.7828e-01, 1.1003e-01, 2.1286e-01, 3.9882e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,086][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.0038, 0.2990, 0.2007, 0.2692, 0.2272], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,088][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([1.3226e-05, 1.4430e-04, 6.9885e-03, 1.1136e-05, 9.9284e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,089][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.0012, 0.2696, 0.0893, 0.6189, 0.0210], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,090][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.0374, 0.2425, 0.1747, 0.3629, 0.1826], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,090][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ went] are: tensor([2.3078e-02, 1.5599e-05, 3.2620e-01, 4.2876e-06, 1.4125e-02, 6.3658e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,091][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ went] are: tensor([9.6742e-05, 2.4303e-02, 4.2115e-02, 7.4981e-03, 9.0183e-01, 2.4159e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,093][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.5828, 0.0233, 0.0312, 0.0008, 0.3588, 0.0031], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,095][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ went] are: tensor([9.8647e-01, 4.2940e-04, 1.1191e-02, 1.1833e-03, 1.6624e-04, 5.5793e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,098][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ went] are: tensor([1.2109e-04, 2.2709e-01, 1.4893e-01, 1.9471e-01, 2.4928e-01, 1.7987e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,100][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ went] are: tensor([1.0175e-06, 1.6033e-02, 9.6982e-03, 1.7443e-04, 9.7329e-01, 7.9958e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,102][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ went] are: tensor([6.6902e-02, 1.3460e-03, 5.1426e-03, 9.8683e-05, 9.1506e-01, 1.1456e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,105][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ went] are: tensor([3.3989e-07, 3.7124e-01, 3.9252e-02, 1.2708e-01, 2.0810e-01, 2.5433e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,109][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0061, 0.2511, 0.1527, 0.2183, 0.1805, 0.1913], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,111][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ went] are: tensor([1.7187e-05, 9.9584e-04, 2.1244e-03, 4.6472e-05, 9.9665e-01, 1.6868e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,113][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0008, 0.2623, 0.0803, 0.4276, 0.0171, 0.2119], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,114][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0204, 0.2489, 0.1190, 0.2855, 0.1292, 0.1969], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,115][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0149, 0.0024, 0.1167, 0.0191, 0.0479, 0.7739, 0.0251],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,115][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.1452e-05, 3.9022e-05, 3.3024e-02, 1.7483e-04, 9.6482e-01, 1.7119e-03,
        2.1367e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,116][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.7100e-02, 3.2021e-04, 7.5287e-03, 2.9414e-05, 9.6473e-01, 2.1298e-04,
        8.2311e-05], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,117][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([9.7086e-01, 8.9154e-04, 1.9952e-02, 1.1073e-03, 1.8637e-04, 6.4747e-04,
        6.3525e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,120][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0002, 0.1765, 0.1410, 0.1672, 0.2118, 0.1714, 0.1318],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,123][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([4.8643e-06, 2.7049e-03, 3.2647e-03, 1.6227e-04, 8.9333e-01, 9.3709e-02,
        6.8213e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,125][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([2.5756e-03, 2.9034e-03, 4.6580e-03, 2.8403e-05, 9.8796e-01, 1.6631e-03,
        2.1102e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,127][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([2.0873e-06, 4.5436e-02, 6.1503e-02, 1.5882e-01, 5.8746e-01, 1.9150e-02,
        1.2763e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,131][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0083, 0.2268, 0.1343, 0.1622, 0.1559, 0.1574, 0.1551],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,134][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.4174e-05, 3.5412e-04, 6.6024e-03, 6.6068e-05, 9.9150e-01, 1.0058e-03,
        4.5372e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,138][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0023, 0.1583, 0.0484, 0.4178, 0.0107, 0.1097, 0.2528],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,139][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0042, 0.2518, 0.0595, 0.2033, 0.0563, 0.1152, 0.3097],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,140][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ the] are: tensor([1.1805e-01, 5.1853e-04, 7.8138e-02, 6.3132e-03, 5.9390e-02, 1.2586e-01,
        6.5452e-03, 6.0518e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,140][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ the] are: tensor([5.2085e-06, 4.8984e-07, 8.0035e-03, 8.0090e-07, 9.9188e-01, 3.3972e-05,
        1.8241e-06, 7.3594e-05], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,142][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ the] are: tensor([6.9222e-02, 1.3688e-04, 3.1572e-03, 1.4513e-05, 9.2740e-01, 3.7805e-05,
        2.6656e-05, 9.9915e-06], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,143][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ the] are: tensor([9.9678e-01, 8.4102e-05, 2.3380e-03, 5.2075e-05, 9.9682e-06, 2.5501e-05,
        2.4281e-04, 4.7099e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,145][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ the] are: tensor([1.1375e-04, 1.4231e-01, 1.1212e-01, 1.2351e-01, 1.9197e-01, 1.3720e-01,
        1.0160e-01, 1.9117e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,147][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ the] are: tensor([5.2129e-06, 2.2753e-05, 9.5307e-04, 6.8790e-09, 9.9847e-01, 5.4968e-04,
        2.5530e-06, 2.3991e-07], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,150][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ the] are: tensor([5.4245e-03, 1.6945e-04, 4.6673e-03, 5.8880e-06, 9.8898e-01, 7.1869e-04,
        9.6750e-06, 2.0306e-05], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,152][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ the] are: tensor([2.8566e-09, 5.4944e-05, 3.3124e-05, 5.8400e-05, 3.5489e-04, 2.2004e-05,
        1.0126e-04, 9.9938e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,156][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0118, 0.1905, 0.1123, 0.1230, 0.1324, 0.1282, 0.1289, 0.1729],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,159][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ the] are: tensor([6.2143e-06, 9.2420e-05, 2.9373e-03, 9.7600e-06, 9.9662e-01, 2.7877e-04,
        4.4807e-05, 8.9197e-06], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,163][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0009, 0.0570, 0.0121, 0.1560, 0.0034, 0.0274, 0.1011, 0.6420],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,163][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.8826e-04, 8.1012e-02, 4.2286e-03, 2.4791e-02, 5.3832e-03, 1.2656e-02,
        4.6125e-02, 8.2562e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,164][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ house] are: tensor([7.3099e-02, 1.0547e-05, 4.5030e-02, 4.6298e-05, 1.3701e-02, 6.4620e-01,
        3.7486e-04, 1.8406e-02, 2.0313e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,165][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ house] are: tensor([8.9994e-05, 8.3289e-05, 4.7991e-02, 1.3225e-04, 7.2329e-01, 2.5138e-02,
        5.9572e-04, 9.1932e-03, 1.9349e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,166][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ house] are: tensor([1.2255e-02, 1.0791e-03, 1.7254e-02, 9.3440e-05, 9.5716e-01, 1.5904e-04,
        1.8205e-04, 5.4847e-05, 1.1766e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,167][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ house] are: tensor([7.8584e-01, 6.5564e-04, 1.0345e-01, 7.4347e-03, 9.4763e-04, 4.9721e-03,
        3.2988e-02, 6.3356e-02, 3.5717e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,169][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ house] are: tensor([6.8415e-05, 1.0814e-01, 9.2577e-02, 1.0466e-01, 1.4830e-01, 9.9627e-02,
        8.3335e-02, 1.6652e-01, 1.9677e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,172][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ house] are: tensor([2.5854e-07, 4.9446e-05, 8.8338e-04, 9.2417e-07, 9.2405e-01, 2.5866e-03,
        1.2002e-04, 2.8478e-05, 7.2282e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,174][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ house] are: tensor([3.9097e-03, 1.2137e-04, 3.1126e-03, 1.3551e-05, 9.6955e-01, 5.4482e-03,
        4.6849e-05, 1.4559e-04, 1.7655e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,176][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ house] are: tensor([6.4226e-10, 5.9069e-05, 1.1519e-05, 1.1276e-04, 1.2145e-04, 2.6340e-05,
        9.6116e-05, 9.9938e-01, 1.9554e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,179][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.0060, 0.1649, 0.1026, 0.1082, 0.1197, 0.1128, 0.1088, 0.1471, 0.1299],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,182][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ house] are: tensor([1.2906e-06, 1.1283e-05, 1.3226e-03, 5.8418e-07, 9.9349e-01, 2.5160e-05,
        4.6566e-06, 3.7877e-07, 5.1403e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,184][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ house] are: tensor([2.9114e-04, 5.5985e-02, 1.4179e-02, 1.7748e-01, 4.2095e-03, 2.9842e-02,
        1.1052e-01, 6.0092e-01, 6.5764e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,186][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ house] are: tensor([3.5828e-04, 4.2796e-02, 1.7660e-02, 5.2944e-02, 1.4447e-02, 3.2124e-02,
        9.6563e-02, 7.3715e-01, 5.9578e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,188][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [.] are: tensor([1.8457e-02, 4.6946e-04, 2.2221e-02, 2.9578e-03, 1.3006e-02, 7.2522e-02,
        2.0812e-03, 5.5263e-01, 2.6471e-01, 5.0946e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,189][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [.] are: tensor([1.6187e-05, 2.6587e-05, 1.1350e-02, 5.7611e-05, 4.4551e-01, 7.4771e-04,
        2.0156e-04, 2.2095e-02, 5.1922e-01, 7.7868e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,190][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [.] are: tensor([4.2754e-02, 3.2466e-04, 4.1495e-03, 6.9901e-06, 9.4790e-01, 1.2126e-04,
        2.7403e-05, 2.1894e-05, 4.4758e-03, 2.1870e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,191][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [.] are: tensor([9.8848e-01, 2.6392e-04, 6.2895e-03, 2.5108e-04, 3.9572e-05, 1.1703e-04,
        1.0821e-03, 1.7631e-03, 6.5944e-06, 1.7054e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,192][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [.] are: tensor([1.3844e-04, 1.0243e-01, 8.6011e-02, 9.0398e-02, 1.2227e-01, 1.0171e-01,
        7.4881e-02, 1.5951e-01, 1.6638e-01, 9.6272e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,194][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [.] are: tensor([1.7877e-06, 3.6628e-04, 6.3576e-03, 3.9366e-06, 3.9476e-01, 7.4025e-02,
        6.8130e-04, 1.3337e-03, 5.2238e-01, 9.5477e-05], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,195][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [.] are: tensor([4.3415e-04, 7.9511e-05, 8.4213e-04, 9.6693e-07, 9.7774e-01, 3.5493e-04,
        6.0000e-06, 2.9195e-05, 2.0404e-02, 1.1184e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,198][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [.] are: tensor([1.3913e-11, 1.0293e-05, 1.9076e-05, 9.5652e-06, 8.0139e-05, 4.1005e-06,
        1.4921e-05, 9.9972e-01, 1.4198e-04, 3.4377e-06], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,202][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0092, 0.1526, 0.0902, 0.0894, 0.1045, 0.0957, 0.0962, 0.1225, 0.1021,
        0.1377], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,204][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [.] are: tensor([5.0407e-06, 1.5614e-04, 1.5223e-03, 9.9830e-06, 9.8412e-01, 2.8672e-04,
        1.1932e-04, 1.0899e-05, 1.3362e-02, 4.1102e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,208][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0010, 0.0763, 0.0262, 0.1609, 0.0065, 0.0471, 0.1333, 0.4148, 0.0074,
        0.1264], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,213][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0020, 0.0632, 0.0117, 0.0448, 0.0102, 0.0214, 0.0657, 0.5074, 0.0033,
        0.2702], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,214][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([1.6026e-01, 8.0668e-07, 2.5997e-02, 4.2548e-06, 7.0037e-03, 2.4107e-02,
        1.5793e-05, 4.1468e-04, 7.4811e-01, 3.0499e-05, 3.4058e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,214][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([3.1407e-04, 5.5908e-03, 1.6429e-02, 1.6214e-03, 4.9926e-01, 1.6043e-02,
        1.0144e-03, 9.9996e-02, 2.2188e-01, 1.2258e-01, 1.5271e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,215][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.3016, 0.0215, 0.0029, 0.0010, 0.5559, 0.0097, 0.0011, 0.0012, 0.0915,
        0.0094, 0.0041], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,217][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([9.7024e-01, 2.9299e-04, 1.0325e-02, 5.3274e-04, 8.7236e-05, 2.7061e-04,
        3.8446e-03, 5.0653e-03, 1.6416e-05, 3.9930e-03, 5.3271e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,218][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([5.2266e-05, 1.0387e-01, 7.1679e-02, 9.3631e-02, 1.1365e-01, 7.7952e-02,
        6.8414e-02, 1.2829e-01, 1.5537e-01, 7.9583e-02, 1.0752e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,220][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([4.9099e-08, 1.7591e-04, 2.4451e-04, 1.6452e-06, 8.8153e-01, 1.5830e-04,
        7.4221e-05, 1.4384e-04, 1.1736e-01, 1.9465e-06, 3.1124e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,222][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([7.0511e-02, 1.3767e-03, 3.6466e-03, 2.3604e-04, 7.8789e-01, 5.4197e-02,
        1.0504e-04, 2.3454e-03, 7.2980e-02, 1.0696e-03, 5.6476e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,225][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([1.4949e-10, 6.9936e-05, 7.8341e-05, 4.8005e-05, 5.6638e-04, 3.0371e-05,
        6.0868e-05, 9.9861e-01, 2.0780e-04, 2.8380e-05, 2.9912e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,229][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.0033, 0.1326, 0.0801, 0.0878, 0.0940, 0.0901, 0.0898, 0.1172, 0.1007,
        0.1269, 0.0774], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,231][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([4.3107e-06, 5.2943e-05, 2.7462e-04, 1.9962e-06, 9.8097e-01, 3.7394e-05,
        5.6784e-06, 1.6264e-06, 1.8005e-02, 5.7294e-05, 5.9177e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,235][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.0005, 0.0666, 0.0282, 0.1527, 0.0039, 0.0439, 0.1110, 0.4504, 0.0072,
        0.0962, 0.0393], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,238][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.0024, 0.1130, 0.0143, 0.0698, 0.0110, 0.0227, 0.1001, 0.3931, 0.0028,
        0.2304, 0.0405], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,238][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([4.3890e-02, 3.1808e-06, 1.4404e-01, 1.4693e-06, 1.7101e-02, 3.3745e-01,
        9.0998e-06, 1.5330e-04, 2.3128e-01, 3.8279e-05, 1.7583e-01, 5.0202e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,239][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([4.1459e-07, 6.3407e-05, 5.5171e-02, 1.5503e-05, 6.8556e-01, 6.6902e-04,
        6.2510e-05, 2.5442e-02, 1.5582e-01, 4.2674e-04, 7.4749e-02, 2.0273e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,240][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([5.6956e-02, 5.6902e-04, 5.3266e-03, 1.3262e-05, 9.0881e-01, 6.1850e-04,
        2.8995e-05, 1.0220e-04, 8.1956e-03, 3.6601e-04, 1.6317e-02, 2.7014e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,242][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([9.6949e-01, 1.4906e-04, 1.1149e-02, 2.6757e-04, 3.8743e-05, 1.9449e-04,
        2.1021e-03, 3.6458e-03, 8.4777e-06, 3.6215e-03, 7.7732e-03, 1.5614e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,244][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([3.4521e-05, 8.3710e-02, 6.2628e-02, 7.5005e-02, 1.0919e-01, 7.3857e-02,
        5.8318e-02, 1.2124e-01, 1.4375e-01, 6.3706e-02, 9.5798e-02, 1.1277e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,246][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([6.0761e-08, 1.2378e-04, 3.7566e-03, 1.1932e-06, 9.5532e-01, 1.5664e-04,
        5.1535e-05, 1.6498e-04, 3.0486e-02, 8.0850e-06, 8.7702e-03, 1.1621e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,248][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([2.0733e-02, 3.9499e-05, 3.2370e-03, 1.8718e-06, 9.5010e-01, 8.9943e-04,
        5.7058e-06, 9.8120e-05, 1.9282e-02, 4.1247e-05, 5.5169e-03, 4.9365e-05],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,251][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([4.1508e-12, 4.6233e-06, 4.9347e-06, 6.2437e-06, 2.3551e-05, 2.6167e-06,
        6.3310e-06, 9.9989e-01, 2.2854e-05, 2.3362e-06, 2.1903e-05, 1.1869e-05],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,254][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0025, 0.1305, 0.0694, 0.0830, 0.0823, 0.0809, 0.0789, 0.1095, 0.0953,
        0.1209, 0.0672, 0.0797], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,256][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([2.5933e-05, 9.7096e-05, 1.5439e-03, 3.2269e-06, 9.8655e-01, 1.2271e-04,
        1.7379e-05, 7.0374e-06, 6.6090e-03, 1.7089e-04, 4.1891e-03, 6.6462e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,258][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([1.0709e-04, 5.4017e-02, 2.0426e-02, 1.1481e-01, 4.9942e-03, 3.3808e-02,
        8.9714e-02, 4.8384e-01, 8.2738e-03, 7.3727e-02, 3.5995e-02, 8.0286e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,262][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0041, 0.0424, 0.0202, 0.0470, 0.0123, 0.0227, 0.0871, 0.3847, 0.0029,
        0.2246, 0.0789, 0.0730], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,263][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0358, 0.0004, 0.0324, 0.0029, 0.0166, 0.1290, 0.0043, 0.2257, 0.3953,
        0.0110, 0.0285, 0.0542, 0.0639], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,264][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.7290e-06, 2.0173e-07, 4.1132e-03, 2.7516e-07, 8.5520e-01, 1.9902e-05,
        2.2777e-06, 1.4061e-04, 1.3470e-01, 1.1862e-05, 5.6590e-03, 1.4871e-04,
        4.9249e-06], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,265][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([8.5592e-02, 1.7445e-04, 1.1402e-02, 2.6220e-05, 8.7219e-01, 1.2392e-04,
        4.7924e-05, 4.9227e-05, 1.1906e-02, 2.6566e-04, 1.7671e-02, 5.2980e-04,
        2.6694e-05], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,266][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([9.9379e-01, 8.4575e-05, 2.9216e-03, 8.1433e-05, 1.5640e-05, 3.4047e-05,
        3.6347e-04, 7.2793e-04, 1.2149e-06, 6.5659e-04, 9.0311e-04, 1.3235e-04,
        2.8587e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,269][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([4.4859e-05, 6.7383e-02, 6.0860e-02, 6.2410e-02, 1.1429e-01, 7.0943e-02,
        5.3073e-02, 1.0764e-01, 1.5077e-01, 6.1168e-02, 9.2970e-02, 1.0130e-01,
        5.7146e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,271][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([2.9221e-06, 9.4255e-06, 3.1272e-03, 1.4480e-08, 6.0147e-01, 8.1300e-03,
        6.9576e-06, 8.3436e-07, 3.6652e-01, 3.9827e-07, 4.8857e-03, 1.5846e-02,
        1.4531e-07], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,273][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([6.3654e-03, 3.9774e-05, 2.5679e-03, 3.6411e-06, 9.5424e-01, 5.0639e-04,
        6.3509e-06, 7.6899e-05, 3.2968e-02, 1.4818e-04, 3.0014e-03, 7.5779e-05,
        3.3360e-06], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,276][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([1.6326e-10, 4.9004e-06, 3.5001e-06, 5.6736e-06, 2.4349e-05, 3.6493e-06,
        2.1266e-05, 9.9919e-01, 4.3640e-04, 1.1921e-06, 1.8367e-05, 1.6676e-05,
        2.7686e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,279][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0061, 0.1290, 0.0712, 0.0663, 0.0822, 0.0744, 0.0763, 0.0914, 0.0745,
        0.0985, 0.0665, 0.0731, 0.0905], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,281][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.0400e-05, 1.4918e-04, 2.9792e-03, 1.5283e-05, 9.3764e-01, 2.4875e-04,
        7.5430e-05, 1.6819e-05, 5.0324e-02, 4.5351e-04, 6.8904e-03, 1.1792e-03,
        1.6699e-05], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,283][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([1.7524e-04, 3.2618e-02, 1.1150e-02, 8.6717e-02, 2.4640e-03, 1.8196e-02,
        5.5527e-02, 3.3579e-01, 3.2382e-03, 5.0529e-02, 1.9958e-02, 4.5519e-02,
        3.3811e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,286][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([7.3419e-05, 2.4363e-02, 1.8301e-03, 8.4023e-03, 1.2145e-03, 2.9387e-03,
        1.4447e-02, 2.7423e-01, 2.4580e-04, 1.0073e-01, 6.7479e-03, 1.3362e-02,
        5.5142e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,288][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([8.7486e-02, 6.8159e-05, 6.8272e-02, 6.6953e-05, 4.5701e-03, 1.5152e-01,
        2.5435e-04, 1.1704e-03, 5.2844e-01, 1.2293e-03, 5.9558e-02, 3.3788e-02,
        8.1399e-03, 5.5432e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,288][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([6.8246e-06, 7.1060e-04, 1.1612e-02, 3.9797e-04, 7.9850e-01, 5.3662e-03,
        2.9856e-04, 1.0470e-01, 5.0942e-02, 2.5506e-03, 1.1885e-02, 3.0503e-03,
        8.2849e-04, 9.1498e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,289][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.2205, 0.0059, 0.0442, 0.0012, 0.5269, 0.0014, 0.0009, 0.0009, 0.0504,
        0.0093, 0.1038, 0.0219, 0.0032, 0.0096], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,290][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([9.6872e-01, 5.1077e-04, 1.4353e-02, 6.1233e-04, 1.3303e-04, 1.9215e-04,
        2.0344e-03, 2.3600e-03, 1.2371e-05, 2.3500e-03, 5.7013e-03, 1.0716e-03,
        1.1810e-03, 7.6490e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,292][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([4.2307e-05, 7.3339e-02, 5.5198e-02, 5.9253e-02, 7.9986e-02, 6.1960e-02,
        4.6413e-02, 8.9850e-02, 1.2644e-01, 5.7210e-02, 8.4447e-02, 9.6342e-02,
        5.2140e-02, 1.1738e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,294][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([1.0700e-08, 9.5354e-05, 8.2602e-04, 4.9995e-07, 9.6989e-01, 1.3736e-05,
        6.7499e-05, 1.5188e-05, 2.7229e-02, 4.7778e-07, 9.3852e-04, 3.4962e-04,
        2.0704e-07, 5.7669e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,297][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.0713, 0.0098, 0.0339, 0.0011, 0.4098, 0.0421, 0.0019, 0.0102, 0.0497,
        0.0073, 0.0385, 0.0036, 0.0019, 0.3189], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,299][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([2.8105e-11, 1.2671e-05, 1.0407e-05, 1.6858e-05, 2.4697e-05, 8.9214e-06,
        1.5513e-05, 9.9903e-01, 5.2696e-05, 5.1114e-06, 5.3476e-05, 2.7076e-05,
        7.1310e-04, 3.0473e-05], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,303][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.0092, 0.1191, 0.0684, 0.0579, 0.0782, 0.0714, 0.0709, 0.0816, 0.0680,
        0.0861, 0.0664, 0.0708, 0.0815, 0.0705], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,306][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([2.9971e-06, 5.3457e-05, 2.3909e-03, 1.6699e-06, 9.7361e-01, 1.0874e-04,
        1.6888e-05, 3.2273e-06, 8.6409e-03, 1.1394e-04, 8.1620e-03, 3.0882e-04,
        5.0807e-06, 6.5822e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,308][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([3.3089e-04, 3.8983e-02, 5.0347e-03, 1.1036e-01, 1.6604e-03, 1.3802e-02,
        5.3542e-02, 3.0706e-01, 2.3323e-03, 5.7050e-02, 9.3413e-03, 2.9649e-02,
        3.4268e-01, 2.8168e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,310][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([8.0293e-05, 3.6165e-02, 2.5822e-03, 1.7920e-02, 2.1826e-03, 5.4221e-03,
        2.6048e-02, 2.7629e-01, 5.6013e-04, 9.8529e-02, 9.3780e-03, 2.0826e-02,
        4.8134e-01, 2.2675e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,312][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([4.6737e-03, 5.3977e-05, 8.7816e-03, 2.8162e-04, 5.9133e-03, 6.3411e-02,
        8.0458e-04, 4.4579e-02, 7.6768e-01, 2.7808e-03, 8.4857e-03, 1.7219e-02,
        1.7418e-02, 5.4019e-02, 3.9011e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,313][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.2555e-06, 3.8571e-06, 1.1729e-02, 2.9815e-05, 8.2442e-01, 2.3340e-04,
        4.3663e-05, 3.0669e-03, 1.3973e-01, 1.0524e-04, 1.8151e-02, 3.3698e-04,
        3.8025e-05, 1.4173e-03, 6.9603e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,314][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.4505e-02, 3.2288e-04, 1.2653e-02, 3.7301e-05, 9.1730e-01, 2.0205e-04,
        7.7263e-05, 7.3867e-05, 7.2620e-03, 2.8854e-04, 2.7691e-02, 1.5808e-03,
        8.7769e-05, 7.0622e-03, 8.5754e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,315][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([9.7940e-01, 1.8518e-04, 8.1653e-03, 1.4352e-04, 3.9053e-05, 8.9264e-05,
        1.0183e-03, 1.7404e-03, 3.0806e-06, 1.5905e-03, 2.3802e-03, 2.8799e-04,
        6.1782e-04, 3.0149e-04, 4.0395e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,316][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([5.2128e-05, 5.7680e-02, 5.0381e-02, 5.1129e-02, 8.4627e-02, 5.9127e-02,
        4.3292e-02, 9.0439e-02, 1.1489e-01, 5.5661e-02, 7.6520e-02, 7.8396e-02,
        5.5945e-02, 1.0678e-01, 7.5077e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,318][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([4.7843e-07, 1.1950e-04, 1.2030e-03, 4.7518e-06, 5.3924e-01, 7.8350e-03,
        6.3443e-04, 9.8899e-04, 4.1561e-01, 9.0056e-06, 2.9604e-03, 2.3334e-02,
        3.5523e-05, 3.7402e-03, 4.2861e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,321][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([2.9775e-03, 6.2297e-04, 7.7177e-03, 6.6917e-06, 9.1333e-01, 8.8933e-04,
        4.9414e-05, 3.3766e-04, 1.7662e-02, 7.0070e-04, 8.6688e-03, 4.4707e-05,
        2.2385e-05, 4.6599e-02, 3.6730e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,323][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([3.7379e-11, 3.6609e-06, 5.4703e-06, 1.3453e-05, 4.9220e-05, 2.2476e-06,
        1.1799e-05, 9.9879e-01, 1.3398e-04, 1.1857e-06, 2.8302e-05, 1.3439e-05,
        3.0467e-04, 2.7244e-05, 6.1130e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,326][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0060, 0.1048, 0.0590, 0.0536, 0.0688, 0.0635, 0.0618, 0.0759, 0.0640,
        0.0806, 0.0586, 0.0650, 0.0776, 0.0666, 0.0943], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,329][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.2923e-05, 2.5123e-04, 5.0772e-03, 5.7553e-05, 9.5582e-01, 7.0495e-04,
        2.9624e-04, 1.1252e-04, 1.1853e-02, 6.7010e-04, 1.2518e-02, 5.5974e-03,
        8.5100e-05, 6.4961e-03, 4.5188e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,333][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0004, 0.0344, 0.0078, 0.0898, 0.0022, 0.0183, 0.0576, 0.2678, 0.0029,
        0.0611, 0.0158, 0.0460, 0.2718, 0.0220, 0.1020], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,335][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([6.6615e-05, 1.0284e-02, 2.0240e-03, 5.4305e-03, 1.2510e-03, 2.2582e-03,
        9.6515e-03, 1.4439e-01, 2.2403e-04, 5.3393e-02, 6.1273e-03, 9.2887e-03,
        2.9628e-01, 1.3336e-02, 4.4600e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,467][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:56,470][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:56,473][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:56,476][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:56,479][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:56,481][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:56,484][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:56,487][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:56,488][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:56,489][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:56,489][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:56,490][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:56,491][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:56,493][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9205, 0.0795], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,496][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0628, 0.9372], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,498][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([1.8513e-05, 9.9998e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,501][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0058, 0.9942], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,504][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([4.8325e-06, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,506][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([2.2654e-04, 9.9977e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,510][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1576, 0.8424], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,513][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0160, 0.9840], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,515][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([9.9923e-01, 7.6624e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,515][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7595, 0.2405], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,516][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([3.3351e-04, 9.9967e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,517][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([7.6997e-07, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:56,518][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([8.3806e-01, 6.0847e-06, 1.6193e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,520][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.0400, 0.3389, 0.6211], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,521][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([4.4904e-04, 9.8625e-01, 1.3299e-02], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,522][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.4655, 0.5306, 0.0040], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,523][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([7.3369e-04, 7.9341e-01, 2.0585e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,525][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([2.0221e-04, 5.9573e-01, 4.0406e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,529][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.0017, 0.2487, 0.7496], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,531][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([4.9165e-04, 1.0953e-01, 8.8998e-01], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,534][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([1.0000e+00, 3.4016e-08, 4.1166e-08], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,538][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.0014, 0.0516, 0.9470], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,540][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.0070, 0.0284, 0.9646], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,541][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([9.2955e-04, 9.5893e-01, 4.0137e-02], device='cuda:0') for source tokens [Then, Rebecca]
[2024-07-24 10:21:56,542][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1253, 0.0009, 0.8688, 0.0050], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,543][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([4.7240e-04, 6.2025e-04, 9.9407e-01, 4.8384e-03], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,543][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.4519e-06, 2.3482e-03, 9.9760e-01, 4.6271e-05], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,545][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0211, 0.0266, 0.6644, 0.2878], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,547][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([3.2592e-04, 3.1401e-01, 1.6638e-01, 5.1929e-01], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,549][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([7.0934e-05, 4.8166e-02, 9.5033e-01, 1.4375e-03], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,552][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([6.3774e-05, 3.0399e-04, 9.9962e-01, 1.1154e-05], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,555][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0068, 0.0043, 0.9347, 0.0542], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,559][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2888, 0.6475, 0.0454, 0.0184], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,561][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([2.3483e-06, 2.9347e-06, 9.9999e-01, 8.1671e-09], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,563][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([9.9005e-05, 4.2419e-02, 9.2549e-01, 3.1994e-02], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,565][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0097, 0.0794, 0.8442, 0.0666], device='cuda:0') for source tokens [Then, Rebecca and]
[2024-07-24 10:21:56,566][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([7.5773e-02, 7.9762e-06, 7.2486e-01, 1.6612e-05, 1.9934e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,566][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0011, 0.0517, 0.1564, 0.0699, 0.7209], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,567][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([6.7612e-05, 2.1187e-01, 1.3866e-01, 4.3025e-03, 6.4510e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,568][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([2.5910e-03, 1.7868e-03, 3.7064e-02, 9.5824e-01, 3.2339e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,570][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([1.2892e-05, 1.2659e-01, 1.3279e-02, 9.8998e-02, 7.6112e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,571][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([5.5082e-07, 8.9895e-04, 1.9784e-03, 1.2454e-05, 9.9711e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,574][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([1.1452e-06, 1.9399e-04, 1.6637e-02, 8.7960e-06, 9.8316e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,578][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.0015, 0.0158, 0.0266, 0.0057, 0.9504], device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,580][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([1.0000e+00, 1.8610e-09, 3.5567e-08, 4.2041e-09, 1.1770e-06],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,582][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([1.0850e-08, 1.4391e-05, 4.4660e-03, 1.2628e-08, 9.9552e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,584][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([4.6967e-04, 4.6047e-02, 8.3089e-01, 1.1986e-01, 2.7407e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,587][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([6.4941e-04, 3.4170e-03, 2.4958e-01, 9.2220e-03, 7.3713e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany]
[2024-07-24 10:21:56,589][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([2.3078e-02, 1.5599e-05, 3.2620e-01, 4.2876e-06, 1.4125e-02, 6.3658e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,590][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([9.6742e-05, 2.4303e-02, 4.2115e-02, 7.4981e-03, 9.0183e-01, 2.4159e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,590][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([1.2942e-05, 1.5293e-01, 7.9742e-02, 1.8281e-04, 7.4917e-01, 1.7955e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,591][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([2.1707e-04, 1.1816e-02, 1.9149e-03, 9.8486e-01, 8.5831e-05, 1.1076e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,592][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([4.1406e-05, 8.7629e-02, 1.1008e-02, 1.3369e-02, 8.6712e-01, 2.0834e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,593][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([1.0175e-06, 1.6033e-02, 9.6982e-03, 1.7443e-04, 9.7329e-01, 7.9958e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,594][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([2.4130e-07, 4.9637e-05, 3.5713e-03, 1.3115e-06, 9.9576e-01, 6.1740e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,596][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([8.3927e-05, 7.7839e-02, 8.5690e-03, 4.2895e-03, 8.3478e-01, 7.4442e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,598][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([1.0000e+00, 1.0943e-09, 7.4022e-10, 2.0348e-09, 1.1207e-07, 1.2115e-09],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,600][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([3.4755e-07, 2.2311e-04, 4.1004e-03, 1.7363e-07, 9.9563e-01, 4.3380e-05],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,603][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([6.4837e-05, 5.3414e-03, 8.2491e-03, 1.6932e-03, 5.8643e-06, 9.8465e-01],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,606][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0067, 0.0763, 0.0585, 0.0298, 0.3224, 0.5062], device='cuda:0') for source tokens [Then, Rebecca and Brittany went]
[2024-07-24 10:21:56,610][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0149, 0.0024, 0.1167, 0.0191, 0.0479, 0.7739, 0.0251],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,612][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.1452e-05, 3.9022e-05, 3.3024e-02, 1.7483e-04, 9.6482e-01, 1.7119e-03,
        2.1367e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,614][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([6.4547e-09, 8.4348e-05, 7.5586e-03, 2.6377e-06, 9.9089e-01, 1.1869e-03,
        2.7866e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,615][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0009, 0.0135, 0.1223, 0.4350, 0.0062, 0.4154, 0.0067],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,616][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.2501e-05, 1.7316e-02, 1.2626e-02, 1.7849e-02, 8.4994e-01, 5.8606e-02,
        4.3651e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,616][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([4.8643e-06, 2.7049e-03, 3.2647e-03, 1.6227e-04, 8.9333e-01, 9.3709e-02,
        6.8213e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,618][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.0376e-07, 6.1962e-08, 5.0829e-04, 2.6770e-09, 9.9948e-01, 1.0875e-05,
        9.6308e-07], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,620][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.1965e-04, 3.4031e-05, 1.4094e-03, 3.6521e-04, 9.9794e-01, 3.8121e-05,
        9.0382e-05], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,622][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.9824e-01, 5.6766e-04, 1.9432e-05, 2.6317e-04, 6.6696e-05, 6.1341e-04,
        2.2881e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,624][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.2584e-07, 1.6807e-07, 2.4717e-03, 8.5688e-10, 9.9744e-01, 9.1466e-05,
        8.5183e-07], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,626][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.9977e-04, 1.3944e-02, 3.1844e-01, 3.2845e-02, 3.8166e-05, 5.8011e-01,
        5.4417e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,629][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([5.8092e-06, 1.3906e-03, 1.0499e-01, 5.2647e-03, 5.7629e-01, 3.1020e-01,
        1.8548e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to]
[2024-07-24 10:21:56,631][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([1.1805e-01, 5.1853e-04, 7.8138e-02, 6.3132e-03, 5.9390e-02, 1.2586e-01,
        6.5452e-03, 6.0518e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,633][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([5.2085e-06, 4.8984e-07, 8.0035e-03, 8.0090e-07, 9.9188e-01, 3.3972e-05,
        1.8241e-06, 7.3594e-05], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,635][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([6.7324e-09, 8.8870e-06, 2.3301e-04, 1.5082e-08, 9.9970e-01, 7.8085e-06,
        1.6399e-05, 2.8946e-05], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,638][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([2.6737e-05, 1.0079e-03, 3.1309e-03, 1.2195e-01, 7.2184e-04, 2.3360e-03,
        1.6051e-03, 8.6922e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,638][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([1.2271e-05, 7.0748e-04, 7.7786e-03, 4.5958e-04, 8.6181e-01, 1.1469e-02,
        1.7893e-03, 1.1598e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,639][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([5.2129e-06, 2.2753e-05, 9.5307e-04, 6.8790e-09, 9.9847e-01, 5.4968e-04,
        2.5530e-06, 2.3991e-07], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,640][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([1.4586e-07, 1.7732e-08, 1.3692e-03, 8.9272e-11, 9.9863e-01, 4.7788e-06,
        3.1429e-08, 7.6798e-08], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,641][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([3.6413e-03, 6.2326e-05, 1.4121e-03, 1.1785e-04, 4.9207e-01, 1.2422e-04,
        8.6940e-05, 5.0249e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,642][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([1.0000e+00, 4.1105e-11, 8.6571e-12, 1.3014e-09, 4.1009e-11, 4.0697e-12,
        2.2196e-09, 1.9374e-10], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,644][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([8.8871e-08, 2.4548e-10, 1.8836e-04, 4.8491e-15, 9.9981e-01, 9.0580e-07,
        5.4989e-11, 1.5550e-12], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,647][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([4.6923e-06, 5.9816e-05, 4.5589e-04, 8.2715e-04, 1.1548e-06, 6.8940e-04,
        1.1897e-03, 9.9677e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,649][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([1.9673e-05, 7.9080e-04, 7.6715e-03, 1.3802e-03, 2.7587e-01, 2.0235e-01,
        2.9215e-03, 5.0899e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the]
[2024-07-24 10:21:56,651][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([7.3099e-02, 1.0547e-05, 4.5030e-02, 4.6298e-05, 1.3701e-02, 6.4620e-01,
        3.7486e-04, 1.8406e-02, 2.0313e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,653][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([8.9994e-05, 8.3289e-05, 4.7991e-02, 1.3225e-04, 7.2329e-01, 2.5138e-02,
        5.9572e-04, 9.1932e-03, 1.9349e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,656][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([5.5298e-08, 4.4471e-04, 1.1069e-02, 2.1287e-06, 9.8605e-01, 1.0003e-04,
        1.1304e-04, 5.5780e-04, 1.6660e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,658][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([1.6887e-03, 1.9801e-03, 2.0121e-02, 4.0473e-01, 1.1527e-03, 1.7416e-03,
        1.7964e-02, 5.5027e-01, 3.5052e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,660][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([9.3740e-07, 5.6442e-04, 4.2936e-03, 1.7923e-03, 1.9994e-01, 1.2929e-03,
        2.9377e-03, 3.2775e-01, 4.6143e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,663][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([2.5854e-07, 4.9446e-05, 8.8338e-04, 9.2417e-07, 9.2405e-01, 2.5866e-03,
        1.2002e-04, 2.8478e-05, 7.2282e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,663][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([9.6878e-08, 5.9173e-08, 7.3517e-04, 1.5637e-08, 9.9760e-01, 1.4823e-04,
        1.9585e-06, 1.5795e-05, 1.4989e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,664][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([1.4944e-05, 1.3377e-04, 7.8036e-05, 2.5627e-04, 4.0941e-02, 1.1145e-04,
        1.0626e-04, 8.8561e-01, 7.2753e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,665][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([1.0000e+00, 6.7566e-10, 6.5101e-10, 8.5469e-09, 1.3393e-08, 3.3695e-09,
        1.1575e-08, 3.5751e-08, 1.9210e-09], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,666][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([4.9435e-09, 3.4964e-11, 6.2641e-05, 4.9966e-15, 9.9899e-01, 4.4185e-08,
        4.4726e-11, 4.1545e-12, 9.4799e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,667][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([2.8456e-07, 1.4304e-04, 1.6459e-04, 3.8303e-03, 2.2098e-07, 4.6143e-04,
        1.8415e-03, 9.9353e-01, 2.9237e-05], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,669][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([3.5839e-05, 4.2268e-03, 6.8802e-03, 5.8617e-03, 4.1633e-01, 7.6985e-02,
        1.8242e-02, 4.6895e-01, 2.4957e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house]
[2024-07-24 10:21:56,671][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([1.8457e-02, 4.6946e-04, 2.2221e-02, 2.9578e-03, 1.3006e-02, 7.2522e-02,
        2.0812e-03, 5.5263e-01, 2.6471e-01, 5.0946e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,674][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([1.6187e-05, 2.6587e-05, 1.1350e-02, 5.7611e-05, 4.4551e-01, 7.4771e-04,
        2.0156e-04, 2.2095e-02, 5.1922e-01, 7.7868e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,676][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([5.4644e-10, 1.5494e-07, 3.9165e-04, 2.0202e-10, 9.9932e-01, 2.9633e-06,
        2.0826e-07, 7.2267e-07, 2.7769e-04, 4.0812e-06], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,679][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0013, 0.0023, 0.1528, 0.2467, 0.0014, 0.0295, 0.0146, 0.2950, 0.0047,
        0.2518], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,681][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([1.3473e-06, 2.7947e-04, 2.2245e-03, 1.0764e-04, 4.2155e-02, 3.3067e-03,
        9.3443e-04, 8.1768e-01, 1.3272e-01, 5.9413e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,684][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([1.7877e-06, 3.6628e-04, 6.3576e-03, 3.9366e-06, 3.9476e-01, 7.4025e-02,
        6.8130e-04, 1.3337e-03, 5.2238e-01, 9.5477e-05], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,686][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([1.1488e-09, 1.6059e-10, 6.9820e-05, 1.7656e-12, 9.9855e-01, 6.2528e-08,
        1.8924e-09, 1.8173e-08, 1.3827e-03, 2.2533e-09], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,688][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([5.4459e-06, 6.4886e-06, 1.0107e-03, 3.6713e-06, 1.9883e-01, 7.7102e-06,
        2.6395e-06, 1.5072e-01, 6.4941e-01, 1.6867e-06], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,689][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([3.8224e-01, 4.2179e-02, 4.7984e-04, 2.2917e-02, 1.3032e-03, 3.5753e-04,
        8.9283e-04, 2.0504e-03, 4.7616e-04, 5.4710e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,689][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([7.7002e-09, 1.3095e-09, 4.2751e-04, 1.9715e-13, 9.8718e-01, 7.7819e-06,
        1.1335e-08, 3.0689e-10, 1.2386e-02, 9.7705e-11], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,690][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([1.1707e-04, 5.5917e-03, 1.9286e-02, 1.6058e-02, 2.2708e-05, 6.0482e-02,
        6.4139e-02, 6.4347e-01, 1.4983e-04, 1.9068e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,691][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([7.7876e-06, 1.8322e-03, 1.3198e-01, 6.4906e-03, 5.1831e-01, 2.9229e-01,
        4.2710e-03, 1.9469e-02, 1.7394e-02, 7.9556e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house.]
[2024-07-24 10:21:56,693][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([1.6026e-01, 8.0668e-07, 2.5997e-02, 4.2548e-06, 7.0037e-03, 2.4107e-02,
        1.5793e-05, 4.1468e-04, 7.4811e-01, 3.0499e-05, 3.4058e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,695][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([3.1407e-04, 5.5908e-03, 1.6429e-02, 1.6214e-03, 4.9926e-01, 1.6043e-02,
        1.0144e-03, 9.9996e-02, 2.2188e-01, 1.2258e-01, 1.5271e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,697][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([3.4026e-06, 1.7255e-02, 3.9139e-04, 9.8828e-05, 4.7552e-01, 2.9212e-02,
        2.4402e-03, 1.3354e-02, 4.3492e-01, 2.5655e-02, 1.1502e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,699][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([7.7111e-03, 6.8265e-03, 3.3921e-04, 2.8929e-01, 4.4345e-05, 6.3774e-03,
        2.0577e-03, 2.4083e-01, 1.7884e-04, 4.4620e-01, 1.4052e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,701][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([9.9772e-06, 2.0965e-02, 8.2978e-03, 1.4372e-02, 2.0575e-01, 3.4733e-03,
        1.1516e-02, 1.4579e-01, 5.5768e-01, 7.2280e-04, 3.1418e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,704][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([4.9099e-08, 1.7591e-04, 2.4451e-04, 1.6452e-06, 8.8153e-01, 1.5830e-04,
        7.4221e-05, 1.4384e-04, 1.1736e-01, 1.9465e-06, 3.1124e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,706][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([1.9000e-06, 4.2403e-04, 5.4998e-03, 1.1443e-05, 7.6093e-01, 1.2391e-02,
        1.2918e-04, 3.4146e-03, 1.9329e-01, 8.3098e-05, 2.3821e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,709][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([5.9368e-07, 3.4381e-04, 2.1212e-03, 7.8211e-05, 3.6539e-01, 1.2272e-04,
        8.9942e-05, 5.8717e-01, 4.2809e-02, 5.7112e-05, 1.8150e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,711][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([1.0000e+00, 8.7004e-09, 3.4393e-08, 5.6333e-09, 5.7071e-07, 3.4382e-07,
        3.2823e-08, 2.9995e-07, 9.4380e-07, 1.5119e-06, 1.0271e-08],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,713][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([1.2867e-08, 1.7859e-07, 1.9981e-05, 6.1371e-11, 8.0932e-01, 1.3254e-06,
        5.3462e-09, 8.6626e-09, 1.9064e-01, 1.5715e-09, 1.9002e-05],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,713][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([5.5672e-05, 3.9144e-04, 1.8515e-02, 1.1474e-02, 1.3938e-06, 3.2296e-02,
        2.9238e-03, 9.2114e-01, 2.0463e-05, 8.7159e-03, 4.4670e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,714][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([1.4006e-06, 9.2915e-03, 6.7788e-04, 1.8508e-03, 3.4571e-03, 4.7846e-01,
        1.5784e-03, 4.9308e-01, 2.5084e-04, 1.0764e-02, 5.9586e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca]
[2024-07-24 10:21:56,715][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([4.3890e-02, 3.1808e-06, 1.4404e-01, 1.4693e-06, 1.7101e-02, 3.3745e-01,
        9.0998e-06, 1.5330e-04, 2.3128e-01, 3.8279e-05, 1.7583e-01, 5.0202e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,716][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([4.1459e-07, 6.3407e-05, 5.5171e-02, 1.5503e-05, 6.8556e-01, 6.6902e-04,
        6.2510e-05, 2.5442e-02, 1.5582e-01, 4.2674e-04, 7.4749e-02, 2.0273e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,718][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([8.6913e-10, 5.1622e-04, 5.9064e-04, 4.3849e-07, 9.3477e-01, 3.2221e-04,
        5.1731e-05, 2.6978e-03, 5.6450e-02, 7.0109e-04, 3.8742e-03, 2.5100e-05],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,721][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([7.6362e-05, 4.4543e-03, 2.8823e-03, 1.3871e-01, 8.0649e-04, 1.6606e-03,
        1.6175e-03, 3.4927e-01, 1.8512e-03, 4.9681e-01, 1.8347e-03, 2.2994e-05],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,723][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([7.9205e-07, 2.7759e-03, 2.2371e-03, 1.2936e-03, 2.1905e-01, 2.6121e-03,
        2.1448e-03, 3.4724e-01, 3.8029e-01, 5.8463e-05, 1.1102e-02, 3.1186e-02],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,725][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([6.0761e-08, 1.2378e-04, 3.7566e-03, 1.1932e-06, 9.5532e-01, 1.5664e-04,
        5.1535e-05, 1.6498e-04, 3.0486e-02, 8.0850e-06, 8.7702e-03, 1.1621e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,728][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([5.3227e-09, 2.3435e-07, 9.3762e-04, 9.0989e-09, 9.7222e-01, 1.8747e-05,
        2.2392e-06, 6.0892e-05, 2.1406e-02, 3.9352e-07, 5.3307e-03, 2.0766e-05],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,730][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([1.5522e-09, 3.1745e-06, 1.4160e-05, 2.8435e-06, 1.7678e-03, 1.5584e-06,
        1.8803e-06, 9.9661e-01, 1.5657e-03, 7.1831e-07, 1.3482e-05, 2.2264e-05],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,732][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([1.0000e+00, 2.9105e-09, 3.1204e-09, 1.0899e-09, 1.7351e-07, 2.3778e-09,
        3.5618e-09, 1.7478e-09, 4.6726e-08, 2.8359e-07, 5.3301e-10, 1.1746e-09],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,735][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([1.1765e-09, 1.1276e-08, 7.7570e-05, 5.6653e-13, 9.9418e-01, 5.9953e-07,
        1.8234e-09, 2.1959e-09, 5.5984e-03, 2.1407e-10, 1.3655e-04, 5.6626e-06],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,737][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([3.0236e-07, 1.3573e-03, 1.1892e-02, 1.1211e-03, 7.9824e-06, 5.2746e-03,
        1.8802e-03, 9.7081e-01, 7.0147e-04, 3.6836e-03, 2.9321e-03, 3.3822e-04],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,738][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([7.2771e-06, 6.8649e-04, 6.8717e-03, 3.6302e-03, 1.2346e-01, 5.5376e-02,
        1.4983e-03, 7.9018e-01, 1.2086e-03, 3.1962e-03, 9.0819e-03, 4.7998e-03],
       device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave]
[2024-07-24 10:21:56,739][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0358, 0.0004, 0.0324, 0.0029, 0.0166, 0.1290, 0.0043, 0.2257, 0.3953,
        0.0110, 0.0285, 0.0542, 0.0639], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,739][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.7290e-06, 2.0173e-07, 4.1132e-03, 2.7516e-07, 8.5520e-01, 1.9902e-05,
        2.2777e-06, 1.4061e-04, 1.3470e-01, 1.1862e-05, 5.6590e-03, 1.4871e-04,
        4.9249e-06], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,741][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([2.7741e-09, 3.0409e-06, 6.5360e-04, 1.8237e-08, 9.8438e-01, 1.0687e-05,
        1.6862e-05, 6.5707e-05, 1.2053e-02, 7.6629e-05, 2.7364e-03, 4.0739e-07,
        6.8622e-08], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,743][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.6871e-05, 3.4115e-03, 2.6219e-04, 4.0827e-01, 3.3873e-04, 1.3320e-03,
        2.0370e-03, 2.1824e-01, 1.8089e-03, 3.6337e-01, 3.8775e-04, 3.3792e-04,
        1.8938e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,745][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.5142e-06, 2.0361e-05, 1.7014e-03, 5.6619e-05, 2.7075e-01, 1.1260e-03,
        4.9123e-04, 8.0120e-02, 6.3362e-01, 7.8915e-06, 6.8016e-03, 4.8594e-03,
        4.4468e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,747][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([2.9221e-06, 9.4255e-06, 3.1272e-03, 1.4480e-08, 6.0147e-01, 8.1300e-03,
        6.9576e-06, 8.3436e-07, 3.6652e-01, 3.9827e-07, 4.8857e-03, 1.5846e-02,
        1.4531e-07], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,750][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([5.0494e-08, 1.7618e-09, 1.8452e-04, 9.6750e-11, 9.9619e-01, 3.1797e-06,
        2.6386e-08, 4.1711e-07, 3.0805e-03, 4.1713e-09, 5.4140e-04, 1.7267e-06,
        2.3352e-09], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,752][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([3.5349e-05, 2.2849e-06, 4.3561e-05, 4.8680e-06, 7.0751e-03, 9.2114e-06,
        1.4146e-05, 2.8903e-01, 7.0340e-01, 5.3905e-07, 4.0145e-05, 1.3982e-04,
        2.1074e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,754][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.0000e+00, 1.5426e-09, 9.9878e-10, 2.1304e-08, 8.5396e-10, 4.7164e-10,
        1.7658e-08, 3.1228e-09, 7.6496e-10, 7.2356e-07, 1.1981e-10, 2.8693e-09,
        1.6340e-10], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,757][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.6023e-07, 1.8054e-10, 7.9886e-04, 6.4341e-14, 9.5218e-01, 1.2401e-06,
        5.4803e-10, 7.8090e-11, 4.5125e-02, 1.0846e-11, 1.8711e-03, 2.0708e-05,
        1.0964e-10], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,759][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([1.0359e-05, 1.1566e-03, 5.5814e-02, 2.7597e-03, 7.4688e-05, 1.1775e-02,
        4.8008e-03, 8.6981e-01, 1.2423e-03, 1.4540e-02, 1.4703e-02, 2.1609e-04,
        2.3092e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,761][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.0531e-05, 5.3857e-04, 9.6561e-03, 4.8398e-03, 6.2652e-02, 2.8886e-01,
        7.2719e-03, 2.6605e-01, 7.6691e-02, 5.1559e-03, 1.5132e-02, 2.3403e-01,
        2.9098e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a]
[2024-07-24 10:21:56,762][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([8.7486e-02, 6.8159e-05, 6.8272e-02, 6.6953e-05, 4.5701e-03, 1.5152e-01,
        2.5435e-04, 1.1704e-03, 5.2844e-01, 1.2293e-03, 5.9558e-02, 3.3788e-02,
        8.1399e-03, 5.5432e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,763][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([6.8246e-06, 7.1060e-04, 1.1612e-02, 3.9797e-04, 7.9850e-01, 5.3662e-03,
        2.9856e-04, 1.0470e-01, 5.0942e-02, 2.5506e-03, 1.1885e-02, 3.0503e-03,
        8.2849e-04, 9.1498e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,764][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([1.9651e-07, 6.0180e-02, 3.0923e-02, 1.3424e-04, 3.5792e-01, 4.9836e-03,
        4.2539e-03, 4.6700e-02, 2.5347e-01, 8.8111e-02, 1.5171e-01, 1.2004e-03,
        3.2535e-04, 9.5498e-05], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,765][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([7.9490e-04, 3.5966e-02, 1.8650e-03, 3.8979e-01, 7.8651e-05, 6.1915e-03,
        1.8035e-03, 4.6625e-01, 3.4748e-04, 8.6527e-02, 5.2969e-04, 4.7275e-04,
        6.0080e-03, 3.3716e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,767][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([1.8014e-06, 4.2058e-03, 4.5765e-03, 6.9693e-04, 3.2558e-02, 2.1466e-03,
        5.7204e-04, 2.7721e-02, 7.6697e-01, 7.0961e-05, 2.0646e-02, 3.3477e-02,
        3.3512e-04, 1.0603e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,770][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([1.0700e-08, 9.5354e-05, 8.2602e-04, 4.9995e-07, 9.6989e-01, 1.3736e-05,
        6.7499e-05, 1.5188e-05, 2.7229e-02, 4.7778e-07, 9.3852e-04, 3.4962e-04,
        2.0704e-07, 5.7669e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,772][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([3.4478e-06, 1.9097e-05, 1.6001e-02, 7.7755e-07, 8.1324e-01, 4.2209e-03,
        7.7480e-05, 1.3810e-03, 6.4218e-02, 9.3933e-06, 3.8422e-02, 7.0219e-04,
        1.0876e-05, 6.1694e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,774][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([7.8045e-08, 2.0450e-05, 1.0124e-04, 1.4031e-05, 3.3777e-03, 1.8661e-05,
        6.2082e-06, 9.8153e-01, 1.3567e-02, 4.2080e-06, 1.3268e-04, 1.6344e-04,
        4.1701e-04, 6.5169e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,777][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([1.0000e+00, 2.0714e-15, 2.2229e-15, 2.8059e-14, 8.9141e-14, 7.9005e-16,
        6.7609e-14, 2.3972e-15, 9.7587e-15, 4.4020e-12, 8.8349e-17, 1.4021e-14,
        4.9958e-16, 1.6008e-15], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,780][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([1.0647e-07, 5.2421e-10, 1.5692e-03, 2.0933e-15, 9.8377e-01, 4.4284e-07,
        5.1279e-11, 3.6542e-12, 1.3403e-02, 1.5747e-12, 1.0182e-03, 8.5562e-07,
        2.8587e-11, 2.3962e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,782][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([5.7565e-07, 2.8931e-04, 9.9171e-06, 1.8640e-02, 3.1028e-08, 1.7384e-04,
        3.6644e-04, 9.4326e-01, 7.3888e-07, 4.6309e-03, 5.4085e-06, 4.9081e-06,
        3.1136e-02, 1.4781e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,784][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([3.3329e-08, 6.3690e-03, 1.3349e-04, 1.4784e-02, 2.8970e-05, 1.1037e-02,
        1.2223e-03, 4.9769e-02, 3.1866e-04, 6.1325e-02, 1.8383e-04, 9.4584e-04,
        3.5508e-02, 8.1837e-01], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring]
[2024-07-24 10:21:56,786][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([4.6737e-03, 5.3977e-05, 8.7816e-03, 2.8162e-04, 5.9133e-03, 6.3411e-02,
        8.0458e-04, 4.4579e-02, 7.6768e-01, 2.7808e-03, 8.4857e-03, 1.7219e-02,
        1.7418e-02, 5.4019e-02, 3.9011e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,787][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.2555e-06, 3.8571e-06, 1.1729e-02, 2.9815e-05, 8.2442e-01, 2.3340e-04,
        4.3663e-05, 3.0669e-03, 1.3973e-01, 1.0524e-04, 1.8151e-02, 3.3698e-04,
        3.8025e-05, 1.4173e-03, 6.9603e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,788][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.5126e-09, 5.8955e-06, 2.5512e-03, 7.2767e-08, 9.7654e-01, 9.9038e-05,
        1.9605e-05, 2.1290e-04, 9.1160e-03, 1.1668e-04, 1.0658e-02, 1.0915e-06,
        4.0523e-07, 8.7506e-05, 5.9136e-04], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,789][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.7291e-04, 2.7987e-03, 3.8359e-02, 1.2926e-01, 2.0193e-03, 6.6656e-02,
        1.4131e-03, 2.2080e-01, 1.3313e-02, 4.7852e-01, 2.1561e-02, 2.7043e-03,
        2.9897e-03, 1.1647e-02, 7.7870e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,790][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([5.8868e-07, 4.4128e-05, 1.6310e-03, 3.9932e-05, 2.2257e-01, 1.8981e-03,
        3.4872e-04, 1.1316e-01, 5.4481e-01, 9.3023e-05, 8.4147e-03, 2.9110e-03,
        2.2956e-03, 9.9764e-02, 2.0187e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,792][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([4.7843e-07, 1.1950e-04, 1.2030e-03, 4.7518e-06, 5.3924e-01, 7.8350e-03,
        6.3443e-04, 9.8899e-04, 4.1561e-01, 9.0056e-06, 2.9604e-03, 2.3334e-02,
        3.5523e-05, 3.7402e-03, 4.2861e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,794][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.5028e-08, 3.5489e-09, 3.1977e-04, 1.0005e-10, 9.9363e-01, 1.7347e-06,
        8.2932e-08, 5.8307e-07, 2.2957e-03, 2.2158e-08, 1.9100e-03, 4.2480e-07,
        4.6078e-09, 1.8379e-03, 1.9113e-06], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,797][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([8.9635e-06, 1.0614e-06, 9.2146e-05, 1.1901e-05, 5.7247e-02, 3.9943e-06,
        3.0937e-06, 4.4775e-01, 4.9249e-01, 4.2457e-07, 8.5920e-05, 9.2436e-05,
        1.6933e-04, 1.9492e-03, 8.7798e-05], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,799][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.9988e-01, 7.9736e-07, 1.1371e-07, 1.4692e-06, 5.3878e-07, 1.8688e-06,
        1.2459e-06, 2.6512e-06, 1.2365e-06, 1.0589e-04, 2.0728e-08, 2.5887e-06,
        8.7181e-08, 1.7951e-06, 3.9196e-06], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,801][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([4.3486e-08, 2.7233e-09, 2.1688e-03, 4.2884e-12, 9.8597e-01, 4.5506e-06,
        1.3134e-08, 5.0978e-09, 7.0513e-03, 2.4673e-10, 4.1498e-03, 2.5416e-05,
        2.9958e-09, 6.2620e-04, 4.1907e-07], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,804][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.1137e-05, 1.7242e-03, 4.1779e-02, 4.8232e-03, 1.2724e-05, 8.3042e-02,
        6.6210e-03, 6.8471e-01, 1.5132e-03, 9.6938e-02, 1.1470e-02, 4.9900e-04,
        8.4131e-03, 8.2327e-04, 5.7606e-02], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,806][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.0472e-07, 2.2521e-05, 9.3959e-03, 1.0474e-04, 4.6049e-02, 1.3782e-02,
        5.7121e-05, 2.4017e-03, 1.0894e-03, 3.5958e-04, 8.5875e-03, 5.7299e-04,
        8.9481e-05, 9.1504e-01, 2.4470e-03], device='cuda:0') for source tokens [Then, Rebecca and Brittany went to the house. Rebecca gave a ring to]
[2024-07-24 10:21:56,810][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:56,812][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[2889],
        [  70],
        [  80],
        [ 330],
        [   1],
        [  30],
        [   1],
        [  27],
        [   7],
        [   2],
        [   2],
        [   7],
        [   8],
        [   9],
        [   1]], device='cuda:0')
[2024-07-24 10:21:56,814][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[2568],
        [ 152],
        [  63],
        [ 224],
        [   1],
        [ 388],
        [ 219],
        [1087],
        [ 567],
        [ 359],
        [ 106],
        [ 386],
        [ 592],
        [ 117],
        [ 106]], device='cuda:0')
[2024-07-24 10:21:56,815][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[16816],
        [20563],
        [22297],
        [29166],
        [23278],
        [33408],
        [32716],
        [12220],
        [33549],
        [15002],
        [31898],
        [31828],
        [21455],
        [31581],
        [30018]], device='cuda:0')
[2024-07-24 10:21:56,817][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 6511],
        [ 4842],
        [50208],
        [50187],
        [50131],
        [50093],
        [50079],
        [50072],
        [50093],
        [49691],
        [49885],
        [50107],
        [50071],
        [50087],
        [50076]], device='cuda:0')
[2024-07-24 10:21:56,819][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[18715],
        [19814],
        [32240],
        [15373],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1]], device='cuda:0')
[2024-07-24 10:21:56,822][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[33808],
        [16917],
        [33458],
        [23754],
        [14757],
        [30232],
        [26874],
        [33003],
        [11085],
        [31035],
        [27044],
        [26557],
        [32330],
        [26288],
        [29533]], device='cuda:0')
[2024-07-24 10:21:56,824][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[23267],
        [  808],
        [   90],
        [  175],
        [  181],
        [  193],
        [  231],
        [  728],
        [  419],
        [  548],
        [  275],
        [  292],
        [  294],
        [  480],
        [  540]], device='cuda:0')
[2024-07-24 10:21:56,827][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[31311],
        [44190],
        [33074],
        [19127],
        [ 2439],
        [ 2505],
        [ 2889],
        [ 2434],
        [ 2338],
        [ 3703],
        [ 2287],
        [ 2420],
        [ 2552],
        [ 2390],
        [ 2833]], device='cuda:0')
[2024-07-24 10:21:56,830][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[26974],
        [25564],
        [ 9260],
        [ 2313],
        [    4],
        [    4],
        [    4],
        [    4],
        [    4],
        [    4],
        [    4],
        [    4],
        [    4],
        [   62],
        [    4]], device='cuda:0')
[2024-07-24 10:21:56,832][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[46186],
        [28135],
        [22460],
        [18694],
        [28057],
        [31627],
        [32077],
        [10701],
        [10703],
        [10696],
        [10704],
        [10696],
        [10702],
        [10699],
        [10710]], device='cuda:0')
[2024-07-24 10:21:56,835][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[32166],
        [12849],
        [12882],
        [12964],
        [13006],
        [13066],
        [13042],
        [12997],
        [12995],
        [12969],
        [12977],
        [12985],
        [13011],
        [13042],
        [13071]], device='cuda:0')
[2024-07-24 10:21:56,837][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[18419],
        [21700],
        [32452],
        [32827],
        [   25],
        [   24],
        [   25],
        [   24],
        [   23],
        [   24],
        [   24],
        [   25],
        [   32],
        [   25],
        [   28]], device='cuda:0')
[2024-07-24 10:21:56,840][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[42737],
        [  825],
        [   27],
        [  518],
        [  247],
        [  146],
        [  232],
        [ 1254],
        [ 1151],
        [  752],
        [  556],
        [  571],
        [ 1734],
        [ 2189],
        [ 1633]], device='cuda:0')
[2024-07-24 10:21:56,841][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[26174],
        [24099],
        [19468],
        [ 9415],
        [ 7918],
        [ 8295],
        [ 8550],
        [ 8438],
        [ 7754],
        [ 6187],
        [ 6276],
        [ 5258],
        [ 6074],
        [ 6104],
        [ 6312]], device='cuda:0')
[2024-07-24 10:21:56,843][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[27386],
        [18945],
        [25021],
        [31408],
        [33681],
        [28111],
        [30959],
        [30436],
        [28622],
        [29978],
        [35082],
        [30323],
        [28996],
        [21351],
        [23865]], device='cuda:0')
[2024-07-24 10:21:56,844][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[31110],
        [31260],
        [18994],
        [11717],
        [10304],
        [16348],
        [18584],
        [25915],
        [17971],
        [25170],
        [17894],
        [14335],
        [22045],
        [15883],
        [18768]], device='cuda:0')
[2024-07-24 10:21:56,847][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[34918],
        [34551],
        [15276],
        [20712],
        [30740],
        [33548],
        [34144],
        [34479],
        [35902],
        [35963],
        [30916],
        [33634],
        [36478],
        [34740],
        [36189]], device='cuda:0')
[2024-07-24 10:21:56,850][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[45389],
        [46602],
        [46575],
        [47288],
        [13068],
        [11083],
        [ 9031],
        [ 9016],
        [ 9042],
        [ 9018],
        [22442],
        [ 9227],
        [ 9035],
        [25975],
        [ 9054]], device='cuda:0')
[2024-07-24 10:21:56,852][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[18290],
        [42930],
        [41604],
        [31044],
        [36324],
        [36482],
        [40103],
        [34702],
        [34979],
        [36359],
        [38710],
        [38153],
        [38456],
        [36292],
        [38762]], device='cuda:0')
[2024-07-24 10:21:56,855][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[46207],
        [40992],
        [43125],
        [34401],
        [38032],
        [39157],
        [39235],
        [37794],
        [14881],
        [17008],
        [16629],
        [18553],
        [19507],
        [13088],
        [16889]], device='cuda:0')
[2024-07-24 10:21:56,857][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[34465],
        [ 9321],
        [15456],
        [27304],
        [30887],
        [30714],
        [28461],
        [30885],
        [31499],
        [34764],
        [32045],
        [31141],
        [34615],
        [31140],
        [34919]], device='cuda:0')
[2024-07-24 10:21:56,860][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[36854],
        [25880],
        [14648],
        [11585],
        [ 9769],
        [ 9990],
        [10034],
        [10029],
        [10046],
        [10053],
        [12284],
        [10149],
        [10056],
        [ 9841],
        [10029]], device='cuda:0')
[2024-07-24 10:21:56,863][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[26474],
        [12591],
        [20258],
        [21557],
        [12140],
        [11054],
        [12329],
        [17644],
        [28641],
        [ 6675],
        [18709],
        [32570],
        [ 9264],
        [32072],
        [12158]], device='cuda:0')
[2024-07-24 10:21:56,865][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[25228],
        [25228],
        [25228],
        [31144],
        [25228],
        [25228],
        [25228],
        [25228],
        [25228],
        [24865],
        [25228],
        [25228],
        [25228],
        [25228],
        [25228]], device='cuda:0')
[2024-07-24 10:21:56,868][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[39779],
        [31849],
        [38127],
        [38225],
        [ 8219],
        [ 8213],
        [ 8179],
        [ 8129],
        [ 8122],
        [ 8127],
        [ 8126],
        [ 8124],
        [ 8130],
        [ 8167],
        [ 8235]], device='cuda:0')
[2024-07-24 10:21:56,869][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[26711],
        [18158],
        [36555],
        [35392],
        [32911],
        [15066],
        [20254],
        [18397],
        [18381],
        [16904],
        [18164],
        [18429],
        [18723],
        [18324],
        [17039]], device='cuda:0')
[2024-07-24 10:21:56,870][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[19183],
        [20479],
        [20446],
        [16878],
        [11182],
        [11962],
        [10804],
        [13785],
        [12459],
        [10633],
        [15135],
        [17235],
        [15056],
        [22162],
        [22414]], device='cuda:0')
[2024-07-24 10:21:56,872][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 4444],
        [11396],
        [ 5230],
        [10001],
        [23668],
        [27141],
        [25623],
        [25265],
        [28904],
        [31902],
        [26742],
        [26966],
        [30111],
        [24398],
        [29741]], device='cuda:0')
[2024-07-24 10:21:56,874][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[21415],
        [28363],
        [22479],
        [16736],
        [15608],
        [20988],
        [18116],
        [17985],
        [21438],
        [23812],
        [13620],
        [18452],
        [18614],
        [26735],
        [24254]], device='cuda:0')
[2024-07-24 10:21:56,877][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[35808],
        [35808],
        [35808],
        [35808],
        [35808],
        [35808],
        [35808],
        [35808],
        [35808],
        [35808],
        [35808],
        [35808],
        [35808],
        [35808],
        [35808]], device='cuda:0')
