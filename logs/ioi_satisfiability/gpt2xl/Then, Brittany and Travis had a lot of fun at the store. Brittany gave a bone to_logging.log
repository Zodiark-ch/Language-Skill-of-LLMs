[2024-07-24 10:27:25,740][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isThen, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to
[2024-07-24 10:27:25,740][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Travis
[2024-07-24 10:27:25,740][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:27:25,740][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:27:25,740][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:27:25,740][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,741][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:27:25,741][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit24']
[2024-07-24 10:27:25,741][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:27:25,741][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,741][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:27:25,741][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:25,742][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:27:25,742][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,742][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:27:25,742][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,742][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:27:25,742][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,743][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:27:25,743][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit26']
[2024-07-24 10:27:25,743][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:27:25,743][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,743][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:27:25,743][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,743][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:27:25,744][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22']
[2024-07-24 10:27:25,744][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:27:25,744][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,744][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:27:25,744][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,744][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:27:25,745][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit5', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,745][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:27:25,745][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit23', 'circuit26']
[2024-07-24 10:27:25,745][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:27:25,745][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,745][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:27:25,746][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,746][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:27:25,746][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,746][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:27:25,746][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit8', 'circuit11', 'circuit21', 'circuit27']
[2024-07-24 10:27:25,746][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:27:25,746][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,747][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:27:25,747][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,747][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:27:25,747][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,747][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:27:25,747][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit28']
[2024-07-24 10:27:25,747][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:27:25,748][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,748][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:27:25,748][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,748][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:27:25,748][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,748][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:27:25,748][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,749][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:27:25,749][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,749][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:27:25,749][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,749][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:27:25,749][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,749][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,750][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:27:25,750][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:27:25,750][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,750][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:27:25,750][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:27:25,750][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit9', 'circuit15', 'circuit20']
[2024-07-24 10:27:25,750][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:27:25,751][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:25,751][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,751][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:27:25,751][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21']
[2024-07-24 10:27:25,751][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,751][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:27:25,751][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:27:25,752][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,752][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:27:25,752][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:27:25,752][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,752][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:27:25,752][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,753][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit20', 'circuit21']
[2024-07-24 10:27:25,753][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:27:25,753][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,753][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:27:25,753][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:27:25,753][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,753][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,754][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:27:25,754][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit27']
[2024-07-24 10:27:25,754][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,754][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:27:25,754][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit12']
[2024-07-24 10:27:25,754][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit7', 'circuit9', 'circuit11', 'circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,754][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:27:25,755][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,755][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,755][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:27:25,755][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,755][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,755][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:27:25,755][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,756][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,756][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:27:25,756][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,756][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit20']
[2024-07-24 10:27:25,756][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:27:25,756][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,756][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,757][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:27:25,757][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:27:25,757][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,757][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:27:25,757][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,757][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,757][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:27:25,758][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit20', 'circuit22']
[2024-07-24 10:27:25,758][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,758][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:27:25,758][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit22']
[2024-07-24 10:27:25,758][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,758][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:27:25,758][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit26']
[2024-07-24 10:27:25,759][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit24']
[2024-07-24 10:27:25,759][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:27:25,759][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:25,759][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:27:25,759][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:27:25,759][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,759][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit18', 'circuit19']
[2024-07-24 10:27:25,760][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:27:25,760][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit26']
[2024-07-24 10:27:25,760][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,760][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:27:25,760][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,760][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit16', 'circuit18', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,760][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:27:25,761][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,761][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,761][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:27:25,761][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,761][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,761][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:27:25,761][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,762][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,762][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:27:25,762][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,762][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,762][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,762][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:27:25,763][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,763][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit20']
[2024-07-24 10:27:25,763][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,763][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:27:25,763][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,763][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:27:25,763][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,764][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:27:25,764][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,764][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,764][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit6', 'circuit7', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,764][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:27:25,764][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:27:25,764][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:27:25,765][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,765][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:27:25,765][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:27:25,765][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit26']
[2024-07-24 10:27:25,765][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:27:25,765][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:27:25,766][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:27:25,766][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit21']
[2024-07-24 10:27:25,766][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,766][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:27:25,766][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,766][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,766][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,767][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:27:25,767][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,767][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0']
[2024-07-24 10:27:25,767][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit17', 'circuit18']
[2024-07-24 10:27:25,767][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:27:25,767][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,768][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit20', 'circuit21']
[2024-07-24 10:27:25,768][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,768][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:27:25,768][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,768][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,768][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,768][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:27:25,769][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:27:25,769][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,769][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,769][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:27:25,769][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,769][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:27:25,769][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19']
[2024-07-24 10:27:25,770][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:27:25,770][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,770][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,770][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,770][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:27:25,770][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,771][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,771][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,771][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:27:25,771][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22']
[2024-07-24 10:27:25,771][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,771][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,771][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:27:25,772][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17']
[2024-07-24 10:27:25,772][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,772][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,772][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:27:25,772][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,772][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,773][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,773][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:27:25,773][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,773][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,773][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,773][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:27:25,773][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:25,774][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,774][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,774][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:27:25,774][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,774][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,774][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,774][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:27:25,775][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22']
[2024-07-24 10:27:25,775][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,775][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,775][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:27:25,775][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,775][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,776][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,776][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:27:25,776][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,776][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,776][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,776][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:27:25,776][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,777][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit14']
[2024-07-24 10:27:25,777][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,777][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:27:25,777][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,777][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,777][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,777][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:27:25,778][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,778][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,778][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,778][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:27:25,778][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,778][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,779][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,779][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:27:25,779][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,779][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,779][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,779][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:27:25,779][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,780][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,780][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,780][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,780][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:27:25,780][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,780][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,781][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit11']
[2024-07-24 10:27:25,781][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,781][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:27:25,781][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22']
[2024-07-24 10:27:25,781][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,781][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,781][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,782][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:27:25,782][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:27:25,782][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:27:25,782][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit27']
[2024-07-24 10:27:25,782][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit27']
[2024-07-24 10:27:25,782][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:27:25,783][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:27:25,783][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,783][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,783][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22']
[2024-07-24 10:27:25,783][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:27:25,783][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,783][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,784][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit16', 'circuit18', 'circuit20']
[2024-07-24 10:27:25,784][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit17', 'circuit21']
[2024-07-24 10:27:25,784][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:27:25,784][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:27:25,784][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:27:25,784][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,785][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,785][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:27:25,785][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,785][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:27:25,785][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit20']
[2024-07-24 10:27:25,785][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,785][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:27:25,786][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,786][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit22']
[2024-07-24 10:27:25,786][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,786][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,786][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:27:25,786][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:27:25,787][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,787][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:27:25,787][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,787][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:27:25,787][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,787][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,787][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:27:25,788][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,788][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:27:25,788][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit8', 'circuit10', 'circuit12', 'circuit27']
[2024-07-24 10:27:25,788][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,788][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,788][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,788][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:27:25,789][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,789][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,789][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,789][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,789][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:27:25,789][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,790][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,790][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,790][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,790][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:27:25,790][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:27:25,790][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit16']
[2024-07-24 10:27:25,790][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit13', 'circuit14']
[2024-07-24 10:27:25,791][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13']
[2024-07-24 10:27:25,791][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:27:25,791][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,791][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,791][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17']
[2024-07-24 10:27:25,791][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,792][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:27:25,792][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,792][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,792][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,792][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,792][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:27:25,792][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,793][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,793][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,793][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13']
[2024-07-24 10:27:25,793][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:27:25,793][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit28']
[2024-07-24 10:27:25,793][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit13', 'circuit14']
[2024-07-24 10:27:25,794][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19']
[2024-07-24 10:27:25,794][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,794][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:27:25,794][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,794][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,794][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,794][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,795][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:27:25,795][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit21']
[2024-07-24 10:27:25,795][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,795][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,795][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,795][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:27:25,795][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,796][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,796][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,796][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,796][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:27:25,796][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,796][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21']
[2024-07-24 10:27:25,797][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:25,797][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,797][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:27:25,797][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,797][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,797][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,797][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,798][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:27:25,798][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,798][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,798][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,798][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,798][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:27:25,798][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,799][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,799][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,799][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,799][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:27:25,799][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,799][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,800][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,800][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,800][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:27:25,800][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,800][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,800][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,801][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,801][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:27:25,801][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,801][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,801][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,801][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,801][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:27:25,802][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,802][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit6', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,802][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,802][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,802][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,802][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:27:25,803][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,803][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,803][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,803][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,803][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,803][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:27:25,803][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,804][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,804][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,804][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,804][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,804][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:27:25,804][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,805][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,805][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,805][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,805][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,805][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:27:25,805][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,805][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,806][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,806][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,806][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,806][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:27:25,806][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,806][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,806][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,807][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,807][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:27:25,807][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:27:25,807][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,807][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22']
[2024-07-24 10:27:25,807][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,808][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,808][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:27:25,808][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:27:25,808][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,808][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,808][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,808][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,809][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,809][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:27:25,809][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22']
[2024-07-24 10:27:25,809][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,809][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,809][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit26']
[2024-07-24 10:27:25,810][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit18', 'circuit24']
[2024-07-24 10:27:25,810][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:27:25,810][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit14']
[2024-07-24 10:27:25,810][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14']
[2024-07-24 10:27:25,810][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,810][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,810][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,811][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:27:25,811][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit27']
[2024-07-24 10:27:25,811][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,811][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,811][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,811][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,811][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:27:25,812][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,812][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,812][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,812][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,812][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,812][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:27:25,813][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:27:25,813][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,813][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,813][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,813][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,813][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:27:25,813][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:25,814][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:27:25,814][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,814][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,814][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,814][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:27:25,814][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,815][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,815][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,815][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,815][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,815][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:27:25,815][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,815][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,816][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,816][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,816][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,816][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:27:25,816][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,816][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,817][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,817][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,817][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,817][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:27:25,817][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,817][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,817][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,818][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,818][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,818][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:27:25,818][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,818][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,818][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,819][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,819][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,819][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:27:25,819][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,819][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,819][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,819][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,820][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,820][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:27:25,820][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,820][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,820][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,820][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,820][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,821][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:27:25,821][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,821][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,821][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,821][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,821][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,821][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:27:25,822][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,822][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,822][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,822][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,822][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,822][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:27:25,823][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,823][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,823][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,823][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,823][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,823][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:27:25,823][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,824][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,824][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,824][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,824][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,824][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:27:25,824][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,825][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,825][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,825][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,825][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,825][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:27:25,825][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,825][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,826][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,826][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,826][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,826][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:27:25,826][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,826][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,827][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,827][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,827][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,827][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:27:25,827][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,827][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,828][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,828][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,828][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,828][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:27:25,828][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,828][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,828][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,829][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,829][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,829][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,829][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:27:25,829][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:27:25,829][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit6', 'circuit7']
[2024-07-24 10:27:25,830][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:27:25,830][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,830][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,830][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,830][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:27:25,830][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit20', 'circuit22']
[2024-07-24 10:27:25,830][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,831][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,831][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,831][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,831][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,831][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:27:25,831][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:27:25,832][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18', 'circuit21']
[2024-07-24 10:27:25,832][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,832][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,832][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,832][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,832][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:27:25,832][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,833][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,833][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit25']
[2024-07-24 10:27:25,833][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,833][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,833][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,833][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:27:25,834][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,834][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,834][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,834][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,834][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:27:25,834][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit10', 'circuit11']
[2024-07-24 10:27:25,834][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:27:25,835][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,835][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,835][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,835][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,835][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,835][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,835][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:27:25,836][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:25,836][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,836][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,836][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,836][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,836][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,837][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:27:25,837][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,837][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,837][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,837][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,837][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,837][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,838][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:27:25,838][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,838][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,838][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,838][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,838][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,839][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,839][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:27:25,839][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,839][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,839][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,839][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,839][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,840][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit26']
[2024-07-24 10:27:25,840][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:27:25,840][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,840][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,840][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,840][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,841][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:27:25,841][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit9', 'circuit12', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:27:25,841][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:27:25,841][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:27:25,841][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,841][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,841][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:27:25,842][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,842][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:27:25,842][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:27:25,842][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit4', 'circuit7', 'circuit13', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,842][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit19', 'circuit22', 'circuit26']
[2024-07-24 10:27:25,842][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,843][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,843][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,843][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:27:25,843][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:27:25,843][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,843][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,843][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,844][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,844][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,844][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,844][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:27:25,844][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,844][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,844][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,845][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,845][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,845][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,845][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:27:25,845][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,845][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,846][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,846][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,846][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,846][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,846][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:27:25,846][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,846][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,847][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,847][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,847][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,847][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,847][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:27:25,847][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,848][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,848][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,848][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,848][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,848][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,848][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:27:25,848][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,849][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,849][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,849][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,849][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,849][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,849][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:27:25,849][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,850][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,850][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,850][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,850][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,850][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,850][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:27:25,851][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,851][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,851][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,851][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,851][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,851][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,851][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:27:25,852][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,852][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,852][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,852][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,852][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,852][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,853][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:27:25,853][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,853][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,853][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,853][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,853][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,853][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,854][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:27:25,854][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,854][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,854][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,854][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,854][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,855][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,855][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:27:25,855][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,855][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,855][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,855][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,855][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,856][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,856][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:27:25,856][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,856][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,856][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,856][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,857][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,857][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,857][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:27:25,857][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,857][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,857][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,857][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,858][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,858][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,858][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:27:25,858][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,858][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,858][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,859][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,859][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,859][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,859][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:27:25,859][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,859][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,860][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,860][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,860][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,860][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,860][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,860][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:27:25,860][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,861][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,861][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,861][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,861][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,861][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:27:25,861][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit2', 'circuit7']
[2024-07-24 10:27:25,862][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:27:25,862][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,862][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,862][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:25,862][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,862][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,862][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,863][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,863][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:27:25,863][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,863][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:27:25,863][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,863][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,864][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:27:25,864][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,864][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,864][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:27:25,864][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,864][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,864][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,865][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,865][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,865][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23']
[2024-07-24 10:27:25,865][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,865][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:27:25,865][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:27:25,866][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,866][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,866][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:27:25,866][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:27:25,866][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,866][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,866][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:27:25,867][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:27:25,867][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,867][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,867][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:25,867][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:27:25,867][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:25,868][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:27:25,868][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:27:25,868][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,868][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,868][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,868][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,868][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,869][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:27:25,869][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:27:25,869][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:27:25,869][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,869][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21']
[2024-07-24 10:27:25,869][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,870][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,870][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,870][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:27:25,870][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit17', 'circuit23', 'circuit24']
[2024-07-24 10:27:25,870][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:27:25,870][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit24']
[2024-07-24 10:27:25,870][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,871][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,871][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20']
[2024-07-24 10:27:25,871][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:27:25,871][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit23']
[2024-07-24 10:27:25,871][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9']
[2024-07-24 10:27:25,871][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:27:25,872][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:27:25,872][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:25,872][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit24']
[2024-07-24 10:27:25,872][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,872][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:27:25,872][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:27:25,872][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit23', 'circuit25']
[2024-07-24 10:27:25,873][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:27:25,873][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,873][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:27:25,873][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,873][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,873][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,874][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit15', 'circuit17', 'circuit20', 'circuit23']
[2024-07-24 10:27:25,874][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,874][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:27:25,874][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,874][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,874][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,874][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,875][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,875][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,875][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,875][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:27:25,875][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:27:25,875][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19', 'circuit21', 'circuit22']
[2024-07-24 10:27:25,876][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,876][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,876][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,876][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,876][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,876][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:27:25,876][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,877][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,877][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,877][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,877][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,877][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,877][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,877][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:27:25,878][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,878][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,878][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,878][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,878][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,878][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,879][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,879][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:27:25,879][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,879][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,879][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,879][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,879][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,880][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,880][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,880][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:27:25,880][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,880][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,880][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,881][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,881][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,881][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,881][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,881][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:27:25,881][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,881][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,882][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,882][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,882][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,882][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,882][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,882][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:27:25,882][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,883][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,883][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,883][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,883][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,883][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,883][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,884][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:27:25,884][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,884][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,884][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,884][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,884][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,884][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,885][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,885][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:27:25,885][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,885][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,885][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,885][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,886][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,886][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,886][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,886][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:27:25,886][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,886][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,886][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,887][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,887][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,887][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,887][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,887][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:27:25,887][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,888][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,888][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,888][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,888][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,888][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,888][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,888][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:27:25,889][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,889][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,889][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,889][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,889][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,889][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,889][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,890][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:27:25,890][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,890][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,890][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,890][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,890][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,891][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,891][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,891][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:27:25,891][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,891][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,891][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,891][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,892][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,892][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,892][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,892][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:27:25,892][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,892][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,893][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,893][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,893][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,893][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,893][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,893][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:27:25,894][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,894][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,894][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,894][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,894][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,894][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,894][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,895][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:27:25,895][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,895][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit10', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,895][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,895][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit7', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,895][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,896][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,896][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,896][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit16', 'circuit17', 'circuit21', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,896][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:27:25,896][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,896][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,897][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,897][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,897][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,897][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,897][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit10']
[2024-07-24 10:27:25,897][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22']
[2024-07-24 10:27:25,897][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:27:25,898][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,898][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,898][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,898][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit27']
[2024-07-24 10:27:25,898][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,898][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13']
[2024-07-24 10:27:25,899][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:27:25,899][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,899][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:27:25,899][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:27:25,899][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:27:25,899][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,899][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,900][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:25,900][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:27:25,900][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit22']
[2024-07-24 10:27:25,900][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:27:25,900][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:27:25,900][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,901][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,901][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,901][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:27:25,901][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,901][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:27:25,901][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit16', 'circuit21', 'circuit24']
[2024-07-24 10:27:25,901][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:27:25,902][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:27:25,902][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,902][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,902][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,902][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,902][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,903][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,903][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:27:25,903][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,903][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:27:25,903][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,903][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,903][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,904][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,904][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,904][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:27:25,904][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:27:25,904][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,904][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:27:25,905][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22', 'circuit24']
[2024-07-24 10:27:25,905][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,905][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,905][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,905][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,905][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,905][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,906][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,906][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:27:25,906][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit23', 'circuit24']
[2024-07-24 10:27:25,906][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,906][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,906][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,907][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,907][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,907][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,907][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:27:25,907][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:27:25,907][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:25,907][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,908][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:25,908][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:27:25,908][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit24']
[2024-07-24 10:27:25,908][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit12', 'circuit24']
[2024-07-24 10:27:25,908][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:27:25,908][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit22']
[2024-07-24 10:27:25,908][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:27:25,909][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:27:25,909][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,909][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:27:25,909][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,909][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:27:25,909][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:27:25,910][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:27:25,910][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,910][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:27:25,910][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,910][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,910][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,910][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,911][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,911][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,911][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,911][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,911][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:27:25,911][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,912][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,912][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,912][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,912][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,912][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,912][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,912][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,913][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:27:25,913][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:27:25,913][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit22']
[2024-07-24 10:27:25,913][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,913][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,913][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,914][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,914][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24']
[2024-07-24 10:27:25,914][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,914][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:27:25,914][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,914][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,914][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,915][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,915][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,915][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,915][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,915][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,915][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:27:25,915][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,916][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,916][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,916][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,916][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,916][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,916][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,917][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,917][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:27:25,917][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,917][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,917][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,917][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,918][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,918][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,918][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,918][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,918][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:27:25,918][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,918][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,919][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,919][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,919][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,919][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,919][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,919][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,919][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:27:25,920][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,920][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,920][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,920][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,920][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,920][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,921][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,921][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,921][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:27:25,921][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,921][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,921][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,921][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,922][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,922][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,922][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,922][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,922][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:27:25,922][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,922][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,923][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,923][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,923][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,923][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,923][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,923][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,924][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:27:25,924][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,924][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,924][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,924][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,924][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,924][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,925][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,925][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,925][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:27:25,925][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,925][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,925][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,926][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,926][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,926][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,926][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,926][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,926][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:27:25,926][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,927][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,927][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,927][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,927][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,927][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,927][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,928][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,928][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:27:25,928][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,928][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,928][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,928][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,928][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,929][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,929][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,929][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,929][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:27:25,929][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,929][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,930][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,930][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,930][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,930][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,930][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,930][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,930][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:27:25,931][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,931][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,931][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,931][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,931][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,931][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,932][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,932][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,932][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:27:25,932][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,932][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,932][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,933][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,933][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,933][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,933][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,933][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,933][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:27:25,934][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,934][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,934][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,934][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,934][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,934][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,935][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,935][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,935][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:27:25,935][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:25,935][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:27:25,935][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,936][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,936][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit9', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,936][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:27:25,936][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit22', 'circuit27']
[2024-07-24 10:27:25,936][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit7', 'circuit15']
[2024-07-24 10:27:25,936][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit4', 'circuit10', 'circuit11', 'circuit13', 'circuit16', 'circuit18', 'circuit23']
[2024-07-24 10:27:25,937][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:27:25,937][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,937][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,937][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,937][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,937][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,937][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,938][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,938][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,938][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,938][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:27:25,938][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,938][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,939][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,939][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,939][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,939][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,939][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,939][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,939][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,940][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:27:25,940][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,940][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,940][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,940][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,940][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,941][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,941][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,941][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,941][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,941][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:27:25,941][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,941][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,942][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,942][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,942][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,942][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,942][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,942][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,943][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,943][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:27:25,943][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,943][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,943][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,943][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,943][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,944][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,944][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,944][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,944][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,944][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:27:25,944][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,945][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,945][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,945][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,945][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,945][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,945][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,945][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,946][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,946][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:27:25,946][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,946][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,946][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,946][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,947][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,947][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,947][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,947][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,947][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,947][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:27:25,947][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,948][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,948][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,948][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,948][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,948][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,948][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,949][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,949][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,949][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:27:25,949][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,949][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,949][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,949][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,950][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,950][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,950][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,950][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,950][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,950][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:27:25,951][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,951][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,951][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,951][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,951][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,951][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,951][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,952][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,952][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,952][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:27:25,952][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,952][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,952][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,952][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,953][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,953][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,953][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,953][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,953][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,953][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:27:25,954][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,954][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,954][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,954][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,954][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,954][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,954][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,955][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,955][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,955][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:27:25,955][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,955][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19', 'circuit22']
[2024-07-24 10:27:25,955][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,956][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,956][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,956][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,956][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit17', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:25,956][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,956][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,956][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:27:25,957][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,957][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,957][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,957][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,957][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,957][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,958][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,958][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,958][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,958][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:27:25,958][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,958][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,958][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,959][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,959][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,959][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,959][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,959][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,959][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,959][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:27:25,960][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,960][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,960][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,960][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,960][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,960][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,961][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,961][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,961][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,961][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:27:25,961][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,961][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,961][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,962][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,962][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,962][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,962][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,962][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,962][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,963][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:27:25,963][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,963][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,963][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,963][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,963][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,964][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,964][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,964][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,964][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,964][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:27:25,964][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,964][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,965][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,965][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,965][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,965][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,965][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,965][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,965][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,966][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:27:25,966][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,966][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,966][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,966][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,966][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,967][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,967][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,967][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,967][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,967][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:27:25,967][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,968][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,968][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,968][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,968][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,968][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,968][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,968][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,969][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,969][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:27:25,969][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,969][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,969][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,969][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,970][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,970][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,970][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,970][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,970][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,970][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:27:25,970][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,971][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,971][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,971][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,971][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,971][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,971][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,971][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,972][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,972][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:27:25,972][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,972][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,972][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,972][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,973][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,973][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,973][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,973][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,973][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,973][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:27:25,973][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,974][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,974][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,974][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,974][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,974][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,974][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,975][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,975][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,975][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:27:25,975][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,975][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,975][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,975][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,976][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,976][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,976][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,976][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,976][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,976][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:27:25,977][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,977][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,977][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,977][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,977][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,977][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,978][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,978][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,978][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,978][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:27:25,978][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,978][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,979][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,979][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,979][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,979][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,979][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,979][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,979][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:25,980][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:27:25,980][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,980][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit26']
[2024-07-24 10:27:25,980][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,980][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,980][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit11', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:25,981][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:27:25,981][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:27:25,981][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit7', 'circuit11', 'circuit15', 'circuit22', 'circuit27']
[2024-07-24 10:27:25,981][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit15', 'circuit18', 'circuit21', 'circuit22']
[2024-07-24 10:27:25,981][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit22', 'circuit24']
[2024-07-24 10:27:25,981][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:27:25,981][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,982][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,982][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,982][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,982][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,982][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,982][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,983][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,983][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,983][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:25,983][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:27:25,983][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,983][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,984][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,984][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,984][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,984][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,984][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,984][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,984][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,985][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:25,985][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:27:25,985][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,985][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,985][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,985][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,986][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,986][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,986][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,986][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,986][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,986][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:25,986][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:27:25,987][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,987][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,987][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,987][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,987][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,987][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,987][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,988][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,988][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,988][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:25,988][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:27:25,988][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,988][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,989][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,989][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,989][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,989][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,989][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,989][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,989][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,990][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:25,990][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:27:25,990][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,990][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,990][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,990][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,991][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,991][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,991][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,991][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,991][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,991][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:25,991][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:27:25,992][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,992][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,992][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,992][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,992][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,992][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,993][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,993][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,993][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,993][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:25,993][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:27:25,993][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,993][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,994][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,994][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,994][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,994][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,994][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,994][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,995][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,995][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:25,995][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:27:25,995][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,995][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,995][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,995][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,996][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,996][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,996][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,996][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,996][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,996][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:25,997][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:27:25,997][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,997][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,997][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,997][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,997][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,997][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,998][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,998][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:25,998][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:25,998][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:25,998][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:27:25,998][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:25,998][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:25,999][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:25,999][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:25,999][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:25,999][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:25,999][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:25,999][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,000][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,000][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,000][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:27:26,000][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,000][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,000][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,001][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,001][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,001][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,001][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,001][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,001][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,001][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,002][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:27:26,002][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,002][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:26,002][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,002][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,002][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,002][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,003][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,003][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,003][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,003][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,003][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:27:26,003][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,004][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,004][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,004][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,004][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,004][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,004][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,004][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,005][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,005][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,005][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:27:26,005][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,005][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,005][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,006][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,006][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,006][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,006][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,006][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,006][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,006][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,007][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:27:26,007][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,007][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,007][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,007][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,007][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,008][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,008][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,008][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,008][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,008][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,008][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:27:26,008][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,009][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,009][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,009][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,009][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,009][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,009][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,010][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,010][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,010][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,010][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:27:26,010][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,010][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,010][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,011][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,011][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,011][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,011][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,011][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,011][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,012][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,012][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:27:26,012][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,012][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,012][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,012][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,012][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,013][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,013][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,013][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,013][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,013][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,013][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:27:26,013][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,014][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,014][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,014][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,014][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,014][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,014][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,015][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,015][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,015][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,015][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:27:26,015][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,015][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,015][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,016][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,016][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,016][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,016][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,016][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,016][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,017][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,017][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:27:26,017][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,017][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,017][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,017][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,017][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,018][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,018][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,018][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,018][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,018][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,018][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:27:26,019][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,019][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,019][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,019][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,019][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,019][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,019][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,020][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,020][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,020][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,020][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:27:26,020][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,020][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,021][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,021][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,021][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,021][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,021][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,021][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,021][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,022][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,022][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:27:26,022][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,022][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,022][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,022][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,023][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,023][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,023][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,023][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,023][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,023][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,023][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:27:26,024][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,024][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,024][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,024][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,024][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,024][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,025][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,025][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,025][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,025][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,025][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:27:26,025][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,025][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,026][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,026][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,026][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,026][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,026][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,026][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,027][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,027][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,027][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:27:26,027][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,027][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,027][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,028][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,028][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,028][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,028][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,028][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,028][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,029][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,029][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:27:26,029][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:26,029][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit20', 'circuit24']
[2024-07-24 10:27:26,029][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:26,029][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:27:26,029][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit11', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:26,030][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit16', 'circuit19', 'circuit21']
[2024-07-24 10:27:26,030][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:27:26,030][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit11', 'circuit13']
[2024-07-24 10:27:26,030][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit16', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:27:26,030][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:26,030][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit16', 'circuit20', 'circuit21', 'circuit25']
[2024-07-24 10:27:26,031][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:27:26,031][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,031][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,031][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,031][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,031][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,031][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,032][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,032][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,032][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,032][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,032][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,032][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:27:26,033][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,033][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,033][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,033][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,033][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,033][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,033][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,034][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,034][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,034][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,034][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,034][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:27:26,034][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,035][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,035][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,035][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,035][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,035][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,035][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,035][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,036][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,036][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,036][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,036][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:27:26,036][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,036][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,037][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,037][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,037][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,037][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,037][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,037][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,037][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,038][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,038][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,038][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:27:26,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,038][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,038][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,039][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,039][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,039][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,039][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,039][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,039][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,039][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,040][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,040][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:27:26,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,040][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,040][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,040][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,041][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,041][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,041][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,041][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,041][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,041][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,041][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,042][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:27:26,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,042][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,042][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,042][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,043][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,043][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,043][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,043][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,043][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,043][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,043][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:27:26,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,044][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,044][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,044][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,044][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,045][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,045][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,045][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,045][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,045][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,045][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:27:26,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,046][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22']
[2024-07-24 10:27:26,046][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:26,046][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:27:26,046][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,046][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,046][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,047][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,047][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,047][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:27:26,047][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:27:26,047][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:27:26,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,048][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,048][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,048][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,048][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,048][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,048][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,049][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,049][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,049][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,049][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:27:26,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,049][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,050][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,050][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,050][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,050][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,050][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,050][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,051][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,051][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,051][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:27:26,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,051][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,051][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,052][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,052][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,052][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,052][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,052][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,052][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,053][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,053][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:27:26,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit20']
[2024-07-24 10:27:26,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19', 'circuit21', 'circuit24']
[2024-07-24 10:27:26,053][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,053][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,053][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,054][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,054][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:27:26,054][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit20', 'circuit22']
[2024-07-24 10:27:26,054][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:26,054][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:27:26,054][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:26,055][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:27:26,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,055][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,055][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,055][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,055][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,056][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,056][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,056][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,056][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,056][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,056][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:27:26,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,057][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,057][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,057][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,057][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,057][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,058][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,058][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,058][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,058][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,058][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:27:26,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,059][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,059][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,059][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,059][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,059][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,060][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,060][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,060][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,060][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:27:26,060][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,060][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,060][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,061][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,061][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,061][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,061][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,061][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,061][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,062][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,062][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,062][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:27:26,062][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,062][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,062][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,062][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,063][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,063][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,063][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,063][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,063][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,063][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,064][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,064][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:27:26,064][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,064][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,064][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,064][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,064][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,065][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,065][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,065][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,065][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,065][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,065][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,065][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:27:26,066][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,066][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,066][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,066][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,066][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,066][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,067][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,067][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,067][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,067][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,067][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,067][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:27:26,067][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,068][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,068][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,068][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,068][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,068][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,068][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,069][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,069][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,069][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,069][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,069][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:27:26,069][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,069][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,070][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,070][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,070][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,070][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,070][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,070][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,071][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,071][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,071][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,071][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:27:26,071][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,071][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,071][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,072][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,072][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,072][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,072][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,072][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,072][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,073][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,073][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,073][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:27:26,073][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,073][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,073][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,073][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,074][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,074][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,074][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,074][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,074][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,074][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,075][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,075][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:27:26,075][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:26,075][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:26,075][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:26,075][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:26,075][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:26,076][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:26,076][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:26,076][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:26,076][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:26,076][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:26,076][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:26,077][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:27:26,077][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,077][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,077][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,077][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,077][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,077][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,078][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,078][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,078][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,078][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,078][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,078][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:27:26,079][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,079][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,079][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,079][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,079][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,079][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,080][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,080][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,080][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,080][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,080][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,080][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:27:26,081][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,081][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,081][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,081][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,081][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,081][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,082][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,082][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,082][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,082][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:26,082][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:27,388][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:27,390][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,391][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,392][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,393][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,394][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,396][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,398][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,399][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,400][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,401][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,403][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,404][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,406][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,407][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,409][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,410][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,411][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,412][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,412][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,413][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,414][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,416][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,417][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,419][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,421][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.5234, 0.3854, 0.0911], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,422][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([1.6624e-05, 1.2859e-04, 9.9985e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,423][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.5514, 0.3139, 0.1348], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,424][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([3.0511e-02, 6.7522e-04, 9.6881e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,425][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([1.2213e-02, 7.7023e-04, 9.8702e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,426][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([1.3095e-02, 4.4606e-06, 9.8690e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,428][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.4239, 0.3498, 0.2263], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,430][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.5606, 0.3651, 0.0743], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,431][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.5531, 0.3567, 0.0902], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,433][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.6031, 0.3494, 0.0475], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,435][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.3949, 0.2391, 0.3660], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,436][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.2970, 0.4791, 0.2239], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,438][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.5786, 0.0656, 0.3047, 0.0511], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,439][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.3024e-03, 3.9245e-02, 5.3311e-04, 9.5792e-01], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,441][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2337, 0.1750, 0.0528, 0.5385], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,442][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1154, 0.3943, 0.0081, 0.4823], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,444][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3519, 0.1594, 0.1999, 0.2888], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,446][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1228, 0.1966, 0.0093, 0.6714], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,447][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6692, 0.0320, 0.2745, 0.0243], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,448][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2281, 0.1734, 0.3374, 0.2611], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,448][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0670, 0.4691, 0.0240, 0.4399], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,449][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4254, 0.2375, 0.1165, 0.2207], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,450][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4210, 0.3135, 0.0586, 0.2069], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,451][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4331, 0.1892, 0.1305, 0.2472], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,453][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.1576, 0.2000, 0.3099, 0.1945, 0.1379], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,454][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([1.5117e-05, 2.2404e-05, 1.8332e-04, 4.0190e-05, 9.9974e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,456][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.2460, 0.1365, 0.1629, 0.0845, 0.3700], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,457][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([2.9969e-04, 1.0561e-05, 1.2447e-04, 2.7833e-05, 9.9954e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,458][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.0129, 0.0019, 0.0027, 0.0020, 0.9805], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,459][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([4.7704e-03, 6.1323e-07, 5.3233e-05, 1.5965e-07, 9.9518e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,461][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.1494, 0.1977, 0.4334, 0.1135, 0.1059], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,463][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.2183, 0.1640, 0.1033, 0.3477, 0.1666], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,464][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.2737, 0.2029, 0.1943, 0.1504, 0.1787], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,466][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.3246, 0.2350, 0.2336, 0.1993, 0.0076], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,468][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.2737, 0.2301, 0.0799, 0.1508, 0.2655], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,469][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([0.3442, 0.2113, 0.1227, 0.1993, 0.1225], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,471][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.3815, 0.0335, 0.1664, 0.0334, 0.0913, 0.2939], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,472][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ had] are: tensor([3.2214e-04, 1.6753e-03, 4.2359e-04, 2.8614e-03, 1.2643e-04, 9.9459e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,474][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.4730, 0.1206, 0.0489, 0.1427, 0.0735, 0.1413], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,475][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ had] are: tensor([4.9398e-03, 5.4292e-03, 2.4623e-04, 1.1489e-02, 2.0562e-03, 9.7584e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,477][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2078, 0.0591, 0.0404, 0.1069, 0.1447, 0.4411], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,478][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ had] are: tensor([3.9815e-02, 1.8580e-03, 2.4582e-04, 1.2917e-03, 2.7458e-04, 9.5651e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,479][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.3778, 0.0282, 0.2150, 0.0265, 0.3146, 0.0379], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,481][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1350, 0.1051, 0.0725, 0.2440, 0.1400, 0.3034], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,483][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0965, 0.2710, 0.0327, 0.3560, 0.0236, 0.2202], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,484][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.2937, 0.1771, 0.1155, 0.1824, 0.1080, 0.1233], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,485][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.2580, 0.1989, 0.0445, 0.1457, 0.0366, 0.3163], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,486][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.4120, 0.1376, 0.1044, 0.1716, 0.0877, 0.0867], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,486][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4465, 0.0514, 0.2797, 0.0389, 0.0850, 0.0641, 0.0345],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,487][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.5635e-04, 4.3036e-03, 6.6909e-04, 4.3016e-03, 4.1427e-04, 4.6870e-04,
        9.8899e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,489][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2968, 0.1841, 0.0633, 0.2171, 0.0700, 0.1229, 0.0459],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,491][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0294, 0.0180, 0.0033, 0.0331, 0.0197, 0.1791, 0.7174],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,492][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1375, 0.0302, 0.0732, 0.0426, 0.0788, 0.4298, 0.2079],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,494][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0559, 0.1296, 0.0022, 0.0970, 0.0045, 0.0448, 0.6661],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,495][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3468, 0.0115, 0.3062, 0.0098, 0.2634, 0.0510, 0.0113],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,497][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0951, 0.0572, 0.0693, 0.1277, 0.1414, 0.2143, 0.2950],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,499][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0241, 0.1311, 0.0091, 0.1947, 0.0067, 0.1423, 0.4920],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,500][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2630, 0.1684, 0.0799, 0.1709, 0.0771, 0.1060, 0.1348],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,502][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2318, 0.1976, 0.0478, 0.1676, 0.0379, 0.0858, 0.2317],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,504][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3121, 0.1251, 0.1311, 0.1344, 0.1132, 0.0807, 0.1035],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,505][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.3794, 0.0839, 0.0994, 0.0886, 0.0732, 0.0791, 0.0938, 0.1024],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,506][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([2.6411e-04, 1.0261e-03, 3.3105e-03, 1.2063e-03, 6.9117e-04, 1.3644e-03,
        5.0217e-04, 9.9164e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,508][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.2900, 0.1121, 0.0692, 0.2005, 0.0648, 0.1490, 0.0773, 0.0371],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,509][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([1.0760e-03, 1.2847e-04, 2.2808e-05, 2.5192e-04, 1.4962e-03, 2.0020e-03,
        1.6722e-03, 9.9335e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,511][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0443, 0.0137, 0.0197, 0.0152, 0.0523, 0.0585, 0.0688, 0.7274],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,512][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([3.2507e-03, 1.1952e-04, 2.4017e-04, 1.7784e-05, 1.6407e-04, 9.6434e-06,
        5.2857e-06, 9.9619e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,514][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.2968, 0.0641, 0.1671, 0.0374, 0.1244, 0.0424, 0.0554, 0.2124],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,515][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0852, 0.0459, 0.0811, 0.0904, 0.0842, 0.1467, 0.2712, 0.1951],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,517][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.1237, 0.1503, 0.0480, 0.1389, 0.0346, 0.1133, 0.3365, 0.0549],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,519][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.2322, 0.1473, 0.1273, 0.1426, 0.0726, 0.0957, 0.1228, 0.0595],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,520][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.2092, 0.1503, 0.0495, 0.1242, 0.0408, 0.0838, 0.0836, 0.2587],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,521][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.4331, 0.0830, 0.0919, 0.0859, 0.1048, 0.0586, 0.0432, 0.0995],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,522][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.3275, 0.0515, 0.2076, 0.0370, 0.1073, 0.0676, 0.0450, 0.1278, 0.0287],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,523][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ of] are: tensor([8.9872e-04, 1.5861e-02, 6.6811e-05, 2.1565e-02, 2.1261e-05, 6.7603e-04,
        3.8737e-04, 9.5701e-05, 9.6043e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,524][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.3058, 0.1448, 0.0363, 0.1347, 0.0516, 0.0779, 0.0617, 0.0858, 0.1014],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,525][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0052, 0.0030, 0.0010, 0.0069, 0.0140, 0.0450, 0.0605, 0.3696, 0.4948],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,527][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1466, 0.0200, 0.0187, 0.0238, 0.1356, 0.1055, 0.0683, 0.3163, 0.1652],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,528][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0226, 0.0911, 0.0036, 0.1069, 0.0009, 0.0655, 0.2352, 0.0072, 0.4669],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,530][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.2077, 0.0177, 0.2382, 0.0156, 0.2456, 0.0405, 0.0163, 0.2072, 0.0111],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,532][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0551, 0.0267, 0.0207, 0.0557, 0.0436, 0.1102, 0.1865, 0.2769, 0.2246],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,533][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0230, 0.1181, 0.0086, 0.1846, 0.0072, 0.1243, 0.3553, 0.0217, 0.1572],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,535][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.2035, 0.1329, 0.0666, 0.1361, 0.0630, 0.0853, 0.1110, 0.0794, 0.1222],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,537][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.1726, 0.1600, 0.0318, 0.1513, 0.0255, 0.0781, 0.0929, 0.0603, 0.2275],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,538][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.2408, 0.1047, 0.1273, 0.1234, 0.1157, 0.0720, 0.0777, 0.0924, 0.0461],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,540][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.2489, 0.1004, 0.1215, 0.0921, 0.0679, 0.0351, 0.0880, 0.0977, 0.0542,
        0.0941], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,541][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([1.4047e-04, 4.5589e-05, 4.1286e-03, 3.7403e-05, 1.5506e-04, 2.0364e-05,
        1.1313e-03, 8.8221e-04, 1.7926e-05, 9.9344e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,543][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.1992, 0.0691, 0.0876, 0.1104, 0.0654, 0.1003, 0.0920, 0.0742, 0.1018,
        0.0999], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,544][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([4.4579e-04, 8.2970e-06, 2.8104e-05, 8.7113e-06, 2.4111e-05, 2.8330e-04,
        2.2894e-04, 1.8483e-03, 2.9448e-04, 9.9683e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,546][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0123, 0.0021, 0.0040, 0.0024, 0.0023, 0.0103, 0.0108, 0.0139, 0.0095,
        0.9324], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,547][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([4.2281e-03, 2.8175e-05, 1.4587e-04, 3.7843e-06, 7.8663e-06, 4.2781e-07,
        1.7978e-06, 1.4491e-04, 2.7546e-07, 9.9544e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,549][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.1716, 0.0364, 0.2736, 0.0284, 0.1674, 0.0238, 0.0259, 0.1132, 0.0309,
        0.1287], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,551][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0932, 0.0232, 0.0158, 0.0500, 0.0263, 0.0691, 0.1381, 0.1944, 0.2612,
        0.1286], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,552][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.1294, 0.1196, 0.0461, 0.1774, 0.0226, 0.1046, 0.1957, 0.0642, 0.1031,
        0.0372], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,554][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.1938, 0.1184, 0.0893, 0.1131, 0.0606, 0.0851, 0.0975, 0.0790, 0.1045,
        0.0588], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,556][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.1296, 0.1010, 0.0771, 0.0981, 0.0388, 0.0555, 0.0815, 0.0851, 0.0705,
        0.2628], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,558][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.3034, 0.1510, 0.0600, 0.1126, 0.0784, 0.0687, 0.0635, 0.0447, 0.0529,
        0.0650], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,558][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.2530, 0.0358, 0.1130, 0.0330, 0.0714, 0.0465, 0.0517, 0.1367, 0.0322,
        0.2024, 0.0244], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,559][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ at] are: tensor([7.4895e-04, 1.5252e-03, 1.0442e-04, 3.7657e-03, 4.3969e-04, 1.5076e-04,
        1.4845e-03, 3.0386e-05, 4.3035e-03, 3.3104e-05, 9.8741e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,560][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1980, 0.1022, 0.0236, 0.1209, 0.0575, 0.0800, 0.0448, 0.0632, 0.1170,
        0.0797, 0.1132], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,561][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ at] are: tensor([1.0225e-03, 3.5280e-04, 1.6895e-05, 6.9252e-04, 8.4773e-05, 4.8621e-03,
        7.4778e-03, 3.9674e-03, 3.0008e-02, 1.3054e-01, 8.2098e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,563][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0618, 0.0063, 0.0079, 0.0095, 0.0118, 0.0581, 0.0342, 0.0467, 0.0706,
        0.3778, 0.3152], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,564][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0544, 0.0230, 0.0024, 0.0096, 0.0048, 0.0362, 0.0160, 0.0012, 0.0039,
        0.0009, 0.8474], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,566][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1678, 0.0128, 0.1825, 0.0125, 0.1935, 0.0411, 0.0161, 0.1781, 0.0123,
        0.1634, 0.0199], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,567][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0366, 0.0124, 0.0063, 0.0280, 0.0230, 0.0468, 0.0820, 0.1098, 0.1265,
        0.1931, 0.3355], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,569][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0240, 0.1164, 0.0076, 0.2111, 0.0068, 0.1122, 0.1976, 0.0246, 0.1667,
        0.0262, 0.1069], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,571][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1508, 0.1052, 0.0484, 0.1139, 0.0557, 0.0788, 0.0910, 0.0700, 0.1097,
        0.0731, 0.1034], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,572][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1444, 0.1117, 0.0346, 0.1150, 0.0398, 0.0838, 0.0969, 0.0348, 0.0928,
        0.0305, 0.2158], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,574][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.2484, 0.0851, 0.0807, 0.0884, 0.0754, 0.0527, 0.0460, 0.0831, 0.0463,
        0.0806, 0.1134], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,576][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.3520, 0.0298, 0.2102, 0.0193, 0.0758, 0.0390, 0.0171, 0.0759, 0.0171,
        0.1246, 0.0183, 0.0209], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,577][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ the] are: tensor([2.9761e-03, 1.8217e-02, 9.7076e-05, 3.9255e-02, 1.0794e-04, 2.7160e-04,
        3.3110e-02, 8.6467e-05, 6.8776e-02, 7.4415e-05, 4.1129e-02, 7.9590e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,579][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1802, 0.0882, 0.0377, 0.0984, 0.0417, 0.0916, 0.0286, 0.0677, 0.1098,
        0.0610, 0.1661, 0.0291], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,580][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ the] are: tensor([1.0769e-02, 1.6528e-03, 4.0245e-04, 1.8822e-03, 1.6583e-03, 7.3215e-03,
        1.8890e-02, 1.2112e-02, 6.1530e-02, 5.5847e-02, 1.8253e-01, 6.4540e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,582][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1115, 0.0124, 0.0117, 0.0164, 0.0198, 0.0780, 0.0334, 0.0503, 0.0982,
        0.1413, 0.2317, 0.1954], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,583][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0651, 0.1020, 0.0131, 0.0835, 0.0203, 0.0624, 0.2047, 0.0497, 0.0536,
        0.0111, 0.0572, 0.2773], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,585][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1838, 0.0031, 0.1961, 0.0029, 0.2329, 0.0177, 0.0034, 0.1549, 0.0026,
        0.1941, 0.0066, 0.0020], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,587][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0376, 0.0088, 0.0113, 0.0175, 0.0290, 0.0227, 0.0362, 0.0568, 0.0934,
        0.0959, 0.2899, 0.3010], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,589][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0085, 0.0714, 0.0048, 0.1149, 0.0027, 0.0749, 0.2411, 0.0078, 0.0766,
        0.0135, 0.0511, 0.3327], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,590][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1671, 0.0944, 0.0574, 0.0979, 0.0492, 0.0686, 0.0783, 0.0640, 0.0909,
        0.0493, 0.0921, 0.0908], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,592][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1775, 0.1086, 0.0367, 0.1083, 0.0365, 0.0553, 0.1136, 0.0422, 0.0651,
        0.0306, 0.0748, 0.1508], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,594][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1874, 0.0754, 0.1051, 0.0790, 0.0823, 0.0489, 0.0818, 0.0720, 0.0299,
        0.0749, 0.0745, 0.0889], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,595][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.2065, 0.0918, 0.0276, 0.0830, 0.1118, 0.0587, 0.0866, 0.0519, 0.0715,
        0.0371, 0.0643, 0.0859, 0.0232], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,596][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ store] are: tensor([9.8100e-04, 2.2789e-03, 1.2200e-03, 1.7886e-03, 2.1859e-03, 1.1694e-03,
        3.9887e-04, 3.1041e-03, 5.1438e-04, 1.2960e-03, 5.8918e-04, 9.8637e-04,
        9.8349e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,597][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.1451, 0.0498, 0.2631, 0.0435, 0.0111, 0.0754, 0.0440, 0.0509, 0.0647,
        0.0870, 0.0670, 0.0496, 0.0487], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,598][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ store] are: tensor([2.6440e-04, 6.7578e-07, 1.1532e-05, 1.7832e-06, 1.5828e-05, 9.9484e-06,
        1.4848e-05, 9.9429e-04, 1.7501e-04, 3.6773e-03, 4.1684e-04, 3.5971e-04,
        9.9406e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,599][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0332, 0.0021, 0.0072, 0.0035, 0.0079, 0.0025, 0.0021, 0.0209, 0.0144,
        0.0288, 0.0308, 0.0253, 0.8214], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,600][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ store] are: tensor([1.1151e-02, 3.7606e-05, 5.4630e-05, 6.5190e-06, 4.9800e-05, 3.0191e-05,
        3.1773e-06, 1.7093e-04, 2.1962e-06, 2.0902e-05, 2.1611e-06, 1.7158e-06,
        9.8847e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,602][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.1767, 0.0363, 0.1642, 0.0227, 0.2076, 0.0141, 0.0159, 0.0416, 0.0157,
        0.1638, 0.0113, 0.0149, 0.1151], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,604][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0379, 0.0065, 0.0062, 0.0188, 0.0052, 0.0245, 0.0394, 0.0698, 0.0827,
        0.1359, 0.2082, 0.2705, 0.0943], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,605][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.1259, 0.0848, 0.0641, 0.0990, 0.0659, 0.0642, 0.0549, 0.0558, 0.0680,
        0.0881, 0.0945, 0.0877, 0.0473], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,607][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.1729, 0.0905, 0.1110, 0.0851, 0.0351, 0.0586, 0.0763, 0.0531, 0.0719,
        0.0746, 0.0713, 0.0831, 0.0165], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,609][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.1145, 0.0797, 0.0452, 0.0831, 0.0478, 0.0570, 0.0687, 0.0515, 0.0604,
        0.0299, 0.0564, 0.0642, 0.2416], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,611][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.2348, 0.0865, 0.0755, 0.0591, 0.0903, 0.0406, 0.0274, 0.0775, 0.0579,
        0.0721, 0.0910, 0.0248, 0.0625], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,612][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.4064, 0.0127, 0.1360, 0.0106, 0.0776, 0.0442, 0.0199, 0.0718, 0.0081,
        0.0989, 0.0154, 0.0338, 0.0554, 0.0092], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,614][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [.] are: tensor([2.9631e-03, 2.9734e-02, 1.5045e-03, 5.5047e-03, 4.5631e-04, 1.1779e-04,
        2.5988e-04, 2.2043e-04, 2.5099e-03, 7.6560e-05, 1.1358e-03, 2.5203e-04,
        4.5335e-05, 9.5522e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,615][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.3473, 0.0443, 0.0254, 0.0380, 0.0328, 0.1943, 0.0176, 0.0469, 0.0836,
        0.0370, 0.0516, 0.0216, 0.0146, 0.0450], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,617][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [.] are: tensor([1.3386e-02, 1.5914e-03, 4.7282e-04, 1.5420e-03, 8.9198e-04, 4.8082e-03,
        5.1833e-03, 2.1061e-02, 2.0166e-02, 2.1423e-02, 6.9303e-02, 1.8824e-01,
        1.3918e-01, 5.1274e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,619][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0275, 0.0093, 0.0044, 0.0177, 0.0052, 0.0192, 0.0164, 0.0406, 0.0541,
        0.0613, 0.1252, 0.1071, 0.2136, 0.2986], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,620][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1049, 0.1668, 0.0083, 0.1069, 0.0148, 0.0739, 0.0803, 0.0336, 0.0528,
        0.0111, 0.0557, 0.0646, 0.0117, 0.2147], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,622][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.2295, 0.0059, 0.1853, 0.0044, 0.1321, 0.0121, 0.0059, 0.0892, 0.0036,
        0.1883, 0.0077, 0.0039, 0.1296, 0.0029], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,624][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0177, 0.0043, 0.0067, 0.0079, 0.0120, 0.0119, 0.0181, 0.0296, 0.0308,
        0.0654, 0.0919, 0.1421, 0.1668, 0.3948], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,625][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0143, 0.1268, 0.0056, 0.1011, 0.0049, 0.0225, 0.0845, 0.0064, 0.0606,
        0.0048, 0.0400, 0.1367, 0.0071, 0.3846], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,627][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1443, 0.0806, 0.0539, 0.0838, 0.0487, 0.0639, 0.0645, 0.0608, 0.0675,
        0.0603, 0.0707, 0.0728, 0.0395, 0.0888], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,629][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1066, 0.0900, 0.0465, 0.0969, 0.0463, 0.0733, 0.0600, 0.0630, 0.0752,
        0.0528, 0.0742, 0.0603, 0.0283, 0.1267], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,631][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.2085, 0.0727, 0.0783, 0.0690, 0.0743, 0.0487, 0.0422, 0.0673, 0.0343,
        0.0613, 0.0726, 0.0326, 0.0477, 0.0904], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,632][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.1598, 0.0983, 0.0367, 0.1337, 0.0415, 0.0173, 0.0590, 0.0114, 0.0664,
        0.0367, 0.0475, 0.0655, 0.0568, 0.1375, 0.0319], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,632][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([9.9776e-06, 4.1278e-05, 5.0564e-01, 5.1011e-05, 1.0917e-04, 6.3076e-06,
        4.5202e-05, 5.1956e-05, 4.2096e-06, 1.4182e-04, 3.1054e-05, 8.5915e-06,
        3.7168e-06, 1.9188e-05, 4.9383e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,633][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.1650, 0.0921, 0.0744, 0.0629, 0.0258, 0.0636, 0.0784, 0.0255, 0.0633,
        0.0410, 0.0823, 0.0736, 0.0167, 0.0690, 0.0663], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,634][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([1.0776e-03, 1.3640e-06, 2.8182e-03, 1.1917e-06, 7.0692e-05, 6.3456e-06,
        9.9969e-06, 3.2920e-05, 3.6107e-05, 9.0034e-04, 8.9870e-05, 1.3817e-04,
        2.5031e-02, 2.1402e-04, 9.6957e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,635][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([9.5722e-04, 4.2768e-05, 4.5783e-02, 3.8930e-05, 3.4397e-04, 8.6464e-05,
        4.4324e-05, 1.9469e-04, 1.1933e-04, 8.1556e-05, 2.2803e-04, 1.8508e-04,
        6.7969e-04, 5.8749e-04, 9.5063e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,636][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([1.5829e-03, 3.4089e-07, 7.1137e-01, 2.4825e-07, 3.4737e-05, 2.9447e-07,
        1.5599e-08, 4.8969e-06, 7.5688e-08, 1.3905e-05, 7.5579e-08, 9.3573e-09,
        2.4704e-07, 3.2639e-09, 2.8699e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,638][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.1104, 0.1116, 0.1385, 0.0859, 0.0543, 0.0225, 0.0515, 0.0198, 0.0397,
        0.0323, 0.0138, 0.1046, 0.0372, 0.0558, 0.1223], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,640][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.0519, 0.0103, 0.0031, 0.0199, 0.0058, 0.0159, 0.0251, 0.0151, 0.0592,
        0.0367, 0.1100, 0.1383, 0.0809, 0.3787, 0.0489], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,641][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.1638, 0.1116, 0.0356, 0.1118, 0.0301, 0.0469, 0.0916, 0.0254, 0.0702,
        0.0145, 0.0763, 0.0928, 0.0121, 0.0852, 0.0321], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,643][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.1505, 0.0981, 0.0149, 0.0838, 0.0534, 0.0618, 0.0575, 0.0541, 0.0756,
        0.0439, 0.0676, 0.0702, 0.0656, 0.0891, 0.0140], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,645][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.0728, 0.0577, 0.2989, 0.0576, 0.0188, 0.0283, 0.0379, 0.0199, 0.0357,
        0.0254, 0.0289, 0.0328, 0.0121, 0.0383, 0.2349], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,647][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.0382, 0.0607, 0.0416, 0.0607, 0.0429, 0.0816, 0.0867, 0.0606, 0.0352,
        0.0752, 0.0862, 0.0724, 0.0731, 0.1157, 0.0694], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,648][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1957, 0.0193, 0.0770, 0.0232, 0.0624, 0.0960, 0.0183, 0.0467, 0.0226,
        0.0374, 0.0185, 0.0171, 0.0366, 0.0154, 0.1030, 0.2111],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:27,650][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([3.7507e-04, 5.8230e-04, 2.3851e-04, 1.2662e-03, 1.0604e-04, 6.5381e-03,
        1.4120e-04, 3.2843e-04, 7.6577e-04, 1.2331e-04, 3.5793e-04, 1.7576e-04,
        5.8585e-04, 5.0877e-05, 1.3780e-04, 9.8823e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:27,651][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1717, 0.0430, 0.0370, 0.0519, 0.0192, 0.0772, 0.0446, 0.0581, 0.0740,
        0.0651, 0.0731, 0.0548, 0.0431, 0.0728, 0.0374, 0.0769],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:27,653][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([8.5724e-04, 4.5927e-06, 2.7773e-06, 3.9900e-06, 1.8772e-06, 4.5492e-05,
        1.1779e-05, 3.8567e-05, 4.7068e-05, 2.9175e-04, 1.4089e-04, 2.0615e-04,
        2.0616e-03, 6.5096e-04, 1.2747e-03, 9.9436e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:27,655][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0880, 0.0069, 0.0033, 0.0069, 0.0032, 0.0113, 0.0079, 0.0107, 0.0201,
        0.0240, 0.0417, 0.0227, 0.0301, 0.0454, 0.0302, 0.6476],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:27,656][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([3.9535e-02, 2.1611e-05, 8.7926e-05, 2.1873e-05, 2.0067e-05, 1.8038e-03,
        1.2767e-05, 7.0411e-06, 5.9634e-06, 5.3258e-05, 1.5033e-05, 7.0796e-06,
        6.4641e-05, 1.0706e-06, 1.6710e-05, 9.5833e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:27,658][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0972, 0.0122, 0.1308, 0.0119, 0.1117, 0.0145, 0.0174, 0.0783, 0.0090,
        0.1501, 0.0105, 0.0134, 0.0956, 0.0125, 0.2051, 0.0298],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:27,659][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0192, 0.0043, 0.0036, 0.0063, 0.0051, 0.0063, 0.0122, 0.0142, 0.0156,
        0.0248, 0.0574, 0.0790, 0.0732, 0.3163, 0.1323, 0.2301],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:27,661][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0736, 0.0727, 0.0143, 0.0920, 0.0078, 0.0398, 0.1048, 0.0360, 0.0811,
        0.0653, 0.0755, 0.1271, 0.0550, 0.0986, 0.0205, 0.0359],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:27,663][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1061, 0.0581, 0.0637, 0.0617, 0.0476, 0.0575, 0.0516, 0.0515, 0.0570,
        0.0700, 0.0516, 0.0555, 0.0466, 0.0836, 0.0812, 0.0567],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:27,665][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0803, 0.0566, 0.0310, 0.0638, 0.0322, 0.1063, 0.0520, 0.0310, 0.0548,
        0.0343, 0.0565, 0.0499, 0.0319, 0.0672, 0.0307, 0.2215],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:27,667][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.2167, 0.0765, 0.0526, 0.0914, 0.0424, 0.0402, 0.0367, 0.0462, 0.0387,
        0.0448, 0.0679, 0.0329, 0.0276, 0.0824, 0.0490, 0.0540],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:27,668][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2040, 0.0161, 0.1162, 0.0125, 0.0358, 0.0260, 0.0112, 0.0496, 0.0106,
        0.0858, 0.0104, 0.0198, 0.0768, 0.0147, 0.1873, 0.1061, 0.0171],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:27,669][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([4.3936e-04, 1.1437e-03, 1.1094e-04, 1.2523e-03, 1.5833e-04, 1.3498e-04,
        4.3335e-01, 1.8448e-04, 1.1692e-03, 9.9741e-04, 3.4127e-03, 1.4678e-02,
        5.5874e-05, 2.8416e-04, 6.0603e-05, 1.1752e-04, 5.4245e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:27,670][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1001, 0.0512, 0.0253, 0.0780, 0.0327, 0.0469, 0.0159, 0.0593, 0.0786,
        0.0443, 0.1192, 0.0185, 0.0279, 0.1659, 0.0296, 0.0887, 0.0179],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:27,671][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([3.6062e-03, 2.7405e-04, 4.0180e-05, 1.7544e-04, 8.1995e-05, 3.7735e-04,
        1.3141e-03, 5.5635e-04, 1.7526e-03, 1.7610e-03, 4.7871e-03, 1.9567e-02,
        9.8086e-03, 2.9044e-02, 8.4373e-03, 1.3268e-01, 7.8574e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:27,673][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0227, 0.0027, 0.0041, 0.0029, 0.0027, 0.0189, 0.0075, 0.0070, 0.0113,
        0.0262, 0.0248, 0.0189, 0.0297, 0.0220, 0.0558, 0.5495, 0.1933],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:27,674][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([1.6602e-02, 5.2894e-02, 1.1566e-03, 4.6415e-02, 2.3619e-03, 2.4840e-02,
        4.1637e-01, 3.8494e-03, 2.4919e-02, 4.2860e-03, 3.1514e-02, 1.0138e-01,
        2.2489e-03, 1.3189e-02, 2.5104e-04, 3.8618e-03, 2.5386e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:27,676][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1039, 0.0024, 0.1102, 0.0023, 0.1009, 0.0152, 0.0026, 0.0992, 0.0025,
        0.1257, 0.0052, 0.0021, 0.1381, 0.0022, 0.2145, 0.0689, 0.0039],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:27,678][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0136, 0.0025, 0.0031, 0.0039, 0.0037, 0.0035, 0.0039, 0.0072, 0.0093,
        0.0117, 0.0294, 0.0345, 0.0314, 0.1958, 0.1241, 0.2689, 0.2535],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:27,680][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0069, 0.0339, 0.0028, 0.0595, 0.0020, 0.0463, 0.1369, 0.0065, 0.0438,
        0.0112, 0.0356, 0.1959, 0.0085, 0.1003, 0.0058, 0.0235, 0.2806],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:27,681][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1081, 0.0662, 0.0379, 0.0728, 0.0362, 0.0489, 0.0569, 0.0480, 0.0672,
        0.0423, 0.0664, 0.0684, 0.0333, 0.0718, 0.0418, 0.0615, 0.0724],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:27,683][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0759, 0.0590, 0.0250, 0.0696, 0.0241, 0.0462, 0.1291, 0.0346, 0.0553,
        0.0396, 0.0712, 0.0834, 0.0293, 0.0562, 0.0229, 0.0368, 0.1417],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:27,685][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1639, 0.0615, 0.0709, 0.0587, 0.0607, 0.0399, 0.0450, 0.0520, 0.0257,
        0.0505, 0.0513, 0.0332, 0.0417, 0.0663, 0.0723, 0.0622, 0.0441],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:27,687][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.1039, 0.0607, 0.0678, 0.0664, 0.0364, 0.0260, 0.0371, 0.0436, 0.0572,
        0.0555, 0.0379, 0.0376, 0.0134, 0.0326, 0.0659, 0.0437, 0.0419, 0.1723],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:27,688][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([7.1105e-05, 5.8871e-05, 3.7398e-03, 4.5509e-05, 1.3344e-04, 2.3543e-05,
        5.2985e-05, 8.3159e-05, 7.1650e-05, 1.5703e-04, 4.4947e-05, 1.2603e-05,
        3.0375e-06, 2.7224e-05, 1.9919e-03, 1.2429e-05, 3.2700e-05, 9.9344e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:27,690][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([0.1132, 0.0469, 0.0280, 0.0533, 0.0298, 0.0435, 0.0718, 0.0632, 0.0530,
        0.0440, 0.0485, 0.0861, 0.0464, 0.0473, 0.0232, 0.0646, 0.0786, 0.0585],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:27,691][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([1.2742e-03, 6.3947e-07, 6.3289e-06, 8.5438e-07, 1.2477e-05, 3.8617e-06,
        2.8822e-06, 1.0333e-04, 7.9536e-06, 1.2206e-04, 4.9044e-05, 3.3638e-05,
        2.3319e-03, 1.0151e-04, 1.8425e-03, 4.1465e-03, 1.3554e-03, 9.8861e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:27,693][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([1.1029e-02, 1.0145e-03, 5.1159e-03, 6.4159e-04, 1.2718e-03, 4.9043e-04,
        6.9292e-04, 1.3014e-03, 1.9818e-03, 5.3246e-03, 3.1662e-03, 1.6932e-03,
        4.6473e-03, 4.1845e-03, 3.9679e-02, 5.0081e-03, 8.1531e-03, 9.0460e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:27,694][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([8.9118e-03, 6.0990e-06, 7.4756e-04, 1.3543e-06, 2.7176e-05, 5.3741e-07,
        5.0804e-07, 2.2952e-05, 2.1883e-07, 9.3999e-06, 3.0648e-07, 1.8308e-07,
        2.9655e-08, 1.0944e-07, 1.6976e-04, 8.9334e-08, 1.5536e-07, 9.9010e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:27,696][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([0.0883, 0.0455, 0.1246, 0.0368, 0.0498, 0.0173, 0.0354, 0.0246, 0.0210,
        0.0681, 0.0170, 0.0417, 0.0723, 0.0264, 0.1360, 0.0349, 0.0404, 0.1199],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:27,698][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([0.0267, 0.0055, 0.0021, 0.0100, 0.0015, 0.0071, 0.0096, 0.0098, 0.0195,
        0.0114, 0.0398, 0.0408, 0.0115, 0.1609, 0.0378, 0.2004, 0.3083, 0.0973],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:27,700][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([0.1248, 0.0524, 0.0273, 0.0578, 0.0375, 0.0353, 0.0700, 0.0218, 0.0390,
        0.0379, 0.0603, 0.0637, 0.0147, 0.0447, 0.0258, 0.0386, 0.0800, 0.1683],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:27,701][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([0.0902, 0.0571, 0.0870, 0.0579, 0.0389, 0.0423, 0.0444, 0.0404, 0.0536,
        0.0661, 0.0454, 0.0436, 0.0549, 0.0663, 0.1067, 0.0431, 0.0557, 0.0065],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:27,703][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([0.0942, 0.0567, 0.0574, 0.0581, 0.0181, 0.0423, 0.0434, 0.0381, 0.0528,
        0.0354, 0.0345, 0.0389, 0.0121, 0.0559, 0.0556, 0.0240, 0.0446, 0.2377],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:27,705][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([0.1210, 0.0583, 0.0390, 0.0453, 0.0511, 0.0497, 0.0331, 0.0706, 0.0650,
        0.0732, 0.0679, 0.0219, 0.0431, 0.0672, 0.0419, 0.0756, 0.0351, 0.0410],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:27,706][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1936, 0.0170, 0.0867, 0.0142, 0.0412, 0.0473, 0.0150, 0.0486, 0.0156,
        0.0537, 0.0145, 0.0226, 0.0548, 0.0156, 0.1457, 0.1266, 0.0245, 0.0492,
        0.0137], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:27,707][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.0644e-03, 8.9854e-03, 3.2131e-05, 2.6125e-02, 8.6953e-05, 2.3097e-04,
        1.0627e-03, 3.7218e-05, 2.5762e-02, 1.8242e-04, 1.4922e-02, 1.4074e-03,
        6.7699e-05, 6.9825e-03, 1.8110e-05, 6.6516e-04, 9.9170e-04, 1.7519e-05,
        9.0836e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:27,708][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1048, 0.0427, 0.0159, 0.0622, 0.0235, 0.0383, 0.0159, 0.0457, 0.0672,
        0.0355, 0.0916, 0.0188, 0.0218, 0.1884, 0.0169, 0.0538, 0.0176, 0.0133,
        0.1260], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:27,709][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.1837e-03, 6.2422e-05, 4.9515e-06, 2.9931e-05, 8.6322e-07, 7.1425e-05,
        9.9584e-05, 2.9702e-05, 3.8797e-04, 2.6051e-04, 5.8936e-04, 2.3947e-03,
        6.5967e-04, 4.3375e-03, 6.7032e-04, 2.4780e-01, 7.0425e-02, 3.2798e-02,
        6.3819e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:27,711][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0225, 0.0012, 0.0014, 0.0018, 0.0005, 0.0120, 0.0032, 0.0050, 0.0044,
        0.0288, 0.0113, 0.0084, 0.0112, 0.0138, 0.0171, 0.4045, 0.0908, 0.0618,
        0.3002], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:27,712][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0298, 0.0436, 0.0017, 0.0587, 0.0013, 0.0250, 0.1858, 0.0075, 0.0395,
        0.0096, 0.0168, 0.1357, 0.0015, 0.0165, 0.0004, 0.0049, 0.1149, 0.0006,
        0.3062], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:27,714][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0888, 0.0039, 0.0537, 0.0034, 0.0463, 0.0120, 0.0032, 0.0381, 0.0048,
        0.1085, 0.0173, 0.0027, 0.0600, 0.0047, 0.1085, 0.0576, 0.0052, 0.0687,
        0.3126], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:27,716][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0159, 0.0023, 0.0023, 0.0031, 0.0028, 0.0028, 0.0034, 0.0047, 0.0041,
        0.0121, 0.0121, 0.0200, 0.0215, 0.0998, 0.0551, 0.1321, 0.1738, 0.1302,
        0.3018], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:27,718][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0054, 0.0389, 0.0029, 0.0698, 0.0010, 0.0316, 0.0855, 0.0057, 0.0497,
        0.0059, 0.0339, 0.1527, 0.0064, 0.1179, 0.0055, 0.0175, 0.1683, 0.0087,
        0.1927], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:27,720][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0916, 0.0545, 0.0360, 0.0616, 0.0313, 0.0419, 0.0523, 0.0416, 0.0558,
        0.0443, 0.0558, 0.0599, 0.0293, 0.0629, 0.0409, 0.0550, 0.0671, 0.0345,
        0.0838], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:27,722][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0714, 0.0546, 0.0263, 0.0702, 0.0267, 0.0550, 0.0633, 0.0346, 0.0626,
        0.0400, 0.0631, 0.0632, 0.0262, 0.0675, 0.0264, 0.0552, 0.0703, 0.0249,
        0.0984], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:27,723][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1512, 0.0582, 0.0642, 0.0589, 0.0562, 0.0433, 0.0381, 0.0463, 0.0274,
        0.0454, 0.0549, 0.0273, 0.0353, 0.0585, 0.0622, 0.0605, 0.0355, 0.0218,
        0.0549], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:27,741][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:27,742][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,742][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,743][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,744][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,745][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,745][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,746][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,747][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,747][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,748][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,749][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,749][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:27,750][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,751][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,752][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,754][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,756][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,757][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,759][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,760][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,762][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,762][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,763][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,764][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:27,764][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.5234, 0.3854, 0.0911], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,765][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([1.6624e-05, 1.2859e-04, 9.9985e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,767][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.5514, 0.3139, 0.1348], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,768][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([3.0511e-02, 6.7522e-04, 9.6881e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,769][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([1.2213e-02, 7.7023e-04, 9.8702e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,770][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([1.3095e-02, 4.4606e-06, 9.8690e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,772][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.4239, 0.3498, 0.2263], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,773][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.5606, 0.3651, 0.0743], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,775][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.5531, 0.3567, 0.0902], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,776][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.6031, 0.3494, 0.0475], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,778][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.3949, 0.2391, 0.3660], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,780][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.2970, 0.4791, 0.2239], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:27,781][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.5786, 0.0656, 0.3047, 0.0511], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,782][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.3024e-03, 3.9245e-02, 5.3311e-04, 9.5792e-01], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,784][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2337, 0.1750, 0.0528, 0.5385], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,786][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1154, 0.3943, 0.0081, 0.4823], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,787][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3519, 0.1594, 0.1999, 0.2888], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,789][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1228, 0.1966, 0.0093, 0.6714], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,790][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6692, 0.0320, 0.2745, 0.0243], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,792][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2281, 0.1734, 0.3374, 0.2611], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,794][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0670, 0.4691, 0.0240, 0.4399], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,795][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4254, 0.2375, 0.1165, 0.2207], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,797][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4210, 0.3135, 0.0586, 0.2069], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,799][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4331, 0.1892, 0.1305, 0.2472], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:27,800][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.1576, 0.2000, 0.3099, 0.1945, 0.1379], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,801][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([1.5117e-05, 2.2404e-05, 1.8332e-04, 4.0190e-05, 9.9974e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,803][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([0.2460, 0.1365, 0.1629, 0.0845, 0.3700], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,804][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([2.9969e-04, 1.0561e-05, 1.2447e-04, 2.7833e-05, 9.9954e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,805][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([0.0129, 0.0019, 0.0027, 0.0020, 0.9805], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,805][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([4.7704e-03, 6.1323e-07, 5.3233e-05, 1.5965e-07, 9.9518e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,806][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.1494, 0.1977, 0.4334, 0.1135, 0.1059], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,807][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.2183, 0.1640, 0.1033, 0.3477, 0.1666], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,809][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.2737, 0.2029, 0.1943, 0.1504, 0.1787], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,810][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.3246, 0.2350, 0.2336, 0.1993, 0.0076], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,812][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.2737, 0.2301, 0.0799, 0.1508, 0.2655], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,813][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.3442, 0.2113, 0.1227, 0.1993, 0.1225], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:27,815][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.3815, 0.0335, 0.1664, 0.0334, 0.0913, 0.2939], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,816][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([3.2214e-04, 1.6753e-03, 4.2359e-04, 2.8614e-03, 1.2643e-04, 9.9459e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,818][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.4730, 0.1206, 0.0489, 0.1427, 0.0735, 0.1413], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,819][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([4.9398e-03, 5.4292e-03, 2.4623e-04, 1.1489e-02, 2.0562e-03, 9.7584e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,820][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2078, 0.0591, 0.0404, 0.1069, 0.1447, 0.4411], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,821][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([3.9815e-02, 1.8580e-03, 2.4582e-04, 1.2917e-03, 2.7458e-04, 9.5651e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,823][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.3778, 0.0282, 0.2150, 0.0265, 0.3146, 0.0379], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,825][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1350, 0.1051, 0.0725, 0.2440, 0.1400, 0.3034], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,826][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0965, 0.2710, 0.0327, 0.3560, 0.0236, 0.2202], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,828][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.2937, 0.1771, 0.1155, 0.1824, 0.1080, 0.1233], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,830][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2580, 0.1989, 0.0445, 0.1457, 0.0366, 0.3163], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,831][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.4120, 0.1376, 0.1044, 0.1716, 0.0877, 0.0867], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:27,833][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4465, 0.0514, 0.2797, 0.0389, 0.0850, 0.0641, 0.0345],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,834][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([8.5635e-04, 4.3036e-03, 6.6909e-04, 4.3016e-03, 4.1427e-04, 4.6870e-04,
        9.8899e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,836][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2968, 0.1841, 0.0633, 0.2171, 0.0700, 0.1229, 0.0459],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,838][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0294, 0.0180, 0.0033, 0.0331, 0.0197, 0.1791, 0.7174],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,839][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1375, 0.0302, 0.0732, 0.0426, 0.0788, 0.4298, 0.2079],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,840][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0559, 0.1296, 0.0022, 0.0970, 0.0045, 0.0448, 0.6661],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,841][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.3468, 0.0115, 0.3062, 0.0098, 0.2634, 0.0510, 0.0113],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,842][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0951, 0.0572, 0.0693, 0.1277, 0.1414, 0.2143, 0.2950],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,843][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0241, 0.1311, 0.0091, 0.1947, 0.0067, 0.1423, 0.4920],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,844][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2630, 0.1684, 0.0799, 0.1709, 0.0771, 0.1060, 0.1348],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,846][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2318, 0.1976, 0.0478, 0.1676, 0.0379, 0.0858, 0.2317],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,848][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3121, 0.1251, 0.1311, 0.1344, 0.1132, 0.0807, 0.1035],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:27,849][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.3794, 0.0839, 0.0994, 0.0886, 0.0732, 0.0791, 0.0938, 0.1024],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,850][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([2.6411e-04, 1.0261e-03, 3.3105e-03, 1.2063e-03, 6.9117e-04, 1.3644e-03,
        5.0217e-04, 9.9164e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,852][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.2900, 0.1121, 0.0692, 0.2005, 0.0648, 0.1490, 0.0773, 0.0371],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,853][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([1.0760e-03, 1.2847e-04, 2.2808e-05, 2.5192e-04, 1.4962e-03, 2.0020e-03,
        1.6722e-03, 9.9335e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,855][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0443, 0.0137, 0.0197, 0.0152, 0.0523, 0.0585, 0.0688, 0.7274],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,856][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([3.2507e-03, 1.1952e-04, 2.4017e-04, 1.7784e-05, 1.6407e-04, 9.6434e-06,
        5.2857e-06, 9.9619e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,858][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.2968, 0.0641, 0.1671, 0.0374, 0.1244, 0.0424, 0.0554, 0.2124],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,859][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0852, 0.0459, 0.0811, 0.0904, 0.0842, 0.1467, 0.2712, 0.1951],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,861][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.1237, 0.1503, 0.0480, 0.1389, 0.0346, 0.1133, 0.3365, 0.0549],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,863][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.2322, 0.1473, 0.1273, 0.1426, 0.0726, 0.0957, 0.1228, 0.0595],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,864][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.2092, 0.1503, 0.0495, 0.1242, 0.0408, 0.0838, 0.0836, 0.2587],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,866][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.4331, 0.0830, 0.0919, 0.0859, 0.1048, 0.0586, 0.0432, 0.0995],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:27,868][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.3275, 0.0515, 0.2076, 0.0370, 0.1073, 0.0676, 0.0450, 0.1278, 0.0287],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,869][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([8.9872e-04, 1.5861e-02, 6.6811e-05, 2.1565e-02, 2.1261e-05, 6.7603e-04,
        3.8737e-04, 9.5701e-05, 9.6043e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,871][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.3058, 0.1448, 0.0363, 0.1347, 0.0516, 0.0779, 0.0617, 0.0858, 0.1014],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,872][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0052, 0.0030, 0.0010, 0.0069, 0.0140, 0.0450, 0.0605, 0.3696, 0.4948],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,874][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.1466, 0.0200, 0.0187, 0.0238, 0.1356, 0.1055, 0.0683, 0.3163, 0.1652],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,876][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0226, 0.0911, 0.0036, 0.1069, 0.0009, 0.0655, 0.2352, 0.0072, 0.4669],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,877][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.2077, 0.0177, 0.2382, 0.0156, 0.2456, 0.0405, 0.0163, 0.2072, 0.0111],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,878][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0551, 0.0267, 0.0207, 0.0557, 0.0436, 0.1102, 0.1865, 0.2769, 0.2246],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,878][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0230, 0.1181, 0.0086, 0.1846, 0.0072, 0.1243, 0.3553, 0.0217, 0.1572],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,879][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.2035, 0.1329, 0.0666, 0.1361, 0.0630, 0.0853, 0.1110, 0.0794, 0.1222],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,880][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.1726, 0.1600, 0.0318, 0.1513, 0.0255, 0.0781, 0.0929, 0.0603, 0.2275],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,882][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.2408, 0.1047, 0.1273, 0.1234, 0.1157, 0.0720, 0.0777, 0.0924, 0.0461],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:27,883][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.2489, 0.1004, 0.1215, 0.0921, 0.0679, 0.0351, 0.0880, 0.0977, 0.0542,
        0.0941], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,885][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([1.4047e-04, 4.5589e-05, 4.1286e-03, 3.7403e-05, 1.5506e-04, 2.0364e-05,
        1.1313e-03, 8.8221e-04, 1.7926e-05, 9.9344e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,886][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.1992, 0.0691, 0.0876, 0.1104, 0.0654, 0.1003, 0.0920, 0.0742, 0.1018,
        0.0999], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,888][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([4.4579e-04, 8.2970e-06, 2.8104e-05, 8.7113e-06, 2.4111e-05, 2.8330e-04,
        2.2894e-04, 1.8483e-03, 2.9448e-04, 9.9683e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,889][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0123, 0.0021, 0.0040, 0.0024, 0.0023, 0.0103, 0.0108, 0.0139, 0.0095,
        0.9324], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,890][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([4.2281e-03, 2.8175e-05, 1.4587e-04, 3.7843e-06, 7.8663e-06, 4.2781e-07,
        1.7978e-06, 1.4491e-04, 2.7546e-07, 9.9544e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,892][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.1716, 0.0364, 0.2736, 0.0284, 0.1674, 0.0238, 0.0259, 0.1132, 0.0309,
        0.1287], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,894][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0932, 0.0232, 0.0158, 0.0500, 0.0263, 0.0691, 0.1381, 0.1944, 0.2612,
        0.1286], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,895][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.1294, 0.1196, 0.0461, 0.1774, 0.0226, 0.1046, 0.1957, 0.0642, 0.1031,
        0.0372], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,897][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.1938, 0.1184, 0.0893, 0.1131, 0.0606, 0.0851, 0.0975, 0.0790, 0.1045,
        0.0588], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,899][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.1296, 0.1010, 0.0771, 0.0981, 0.0388, 0.0555, 0.0815, 0.0851, 0.0705,
        0.2628], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,901][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.3034, 0.1510, 0.0600, 0.1126, 0.0784, 0.0687, 0.0635, 0.0447, 0.0529,
        0.0650], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:27,902][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.2530, 0.0358, 0.1130, 0.0330, 0.0714, 0.0465, 0.0517, 0.1367, 0.0322,
        0.2024, 0.0244], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,903][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([7.4895e-04, 1.5252e-03, 1.0442e-04, 3.7657e-03, 4.3969e-04, 1.5076e-04,
        1.4845e-03, 3.0386e-05, 4.3035e-03, 3.3104e-05, 9.8741e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,905][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1980, 0.1022, 0.0236, 0.1209, 0.0575, 0.0800, 0.0448, 0.0632, 0.1170,
        0.0797, 0.1132], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,906][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([1.0225e-03, 3.5280e-04, 1.6895e-05, 6.9252e-04, 8.4773e-05, 4.8621e-03,
        7.4778e-03, 3.9674e-03, 3.0008e-02, 1.3054e-01, 8.2098e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,908][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0618, 0.0063, 0.0079, 0.0095, 0.0118, 0.0581, 0.0342, 0.0467, 0.0706,
        0.3778, 0.3152], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,910][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0544, 0.0230, 0.0024, 0.0096, 0.0048, 0.0362, 0.0160, 0.0012, 0.0039,
        0.0009, 0.8474], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,912][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.1678, 0.0128, 0.1825, 0.0125, 0.1935, 0.0411, 0.0161, 0.1781, 0.0123,
        0.1634, 0.0199], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,913][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0366, 0.0124, 0.0063, 0.0280, 0.0230, 0.0468, 0.0820, 0.1098, 0.1265,
        0.1931, 0.3355], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,914][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0240, 0.1164, 0.0076, 0.2111, 0.0068, 0.1122, 0.1976, 0.0246, 0.1667,
        0.0262, 0.1069], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,915][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.1508, 0.1052, 0.0484, 0.1139, 0.0557, 0.0788, 0.0910, 0.0700, 0.1097,
        0.0731, 0.1034], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,916][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.1444, 0.1117, 0.0346, 0.1150, 0.0398, 0.0838, 0.0969, 0.0348, 0.0928,
        0.0305, 0.2158], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,917][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.2484, 0.0851, 0.0807, 0.0884, 0.0754, 0.0527, 0.0460, 0.0831, 0.0463,
        0.0806, 0.1134], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:27,919][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.3520, 0.0298, 0.2102, 0.0193, 0.0758, 0.0390, 0.0171, 0.0759, 0.0171,
        0.1246, 0.0183, 0.0209], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,920][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([2.9761e-03, 1.8217e-02, 9.7076e-05, 3.9255e-02, 1.0794e-04, 2.7160e-04,
        3.3110e-02, 8.6467e-05, 6.8776e-02, 7.4415e-05, 4.1129e-02, 7.9590e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,922][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1802, 0.0882, 0.0377, 0.0984, 0.0417, 0.0916, 0.0286, 0.0677, 0.1098,
        0.0610, 0.1661, 0.0291], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,923][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([1.0769e-02, 1.6528e-03, 4.0245e-04, 1.8822e-03, 1.6583e-03, 7.3215e-03,
        1.8890e-02, 1.2112e-02, 6.1530e-02, 5.5847e-02, 1.8253e-01, 6.4540e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,925][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1115, 0.0124, 0.0117, 0.0164, 0.0198, 0.0780, 0.0334, 0.0503, 0.0982,
        0.1413, 0.2317, 0.1954], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,927][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0651, 0.1020, 0.0131, 0.0835, 0.0203, 0.0624, 0.2047, 0.0497, 0.0536,
        0.0111, 0.0572, 0.2773], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,929][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1838, 0.0031, 0.1961, 0.0029, 0.2329, 0.0177, 0.0034, 0.1549, 0.0026,
        0.1941, 0.0066, 0.0020], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,930][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0376, 0.0088, 0.0113, 0.0175, 0.0290, 0.0227, 0.0362, 0.0568, 0.0934,
        0.0959, 0.2899, 0.3010], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,932][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0085, 0.0714, 0.0048, 0.1149, 0.0027, 0.0749, 0.2411, 0.0078, 0.0766,
        0.0135, 0.0511, 0.3327], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,934][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1671, 0.0944, 0.0574, 0.0979, 0.0492, 0.0686, 0.0783, 0.0640, 0.0909,
        0.0493, 0.0921, 0.0908], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,935][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1775, 0.1086, 0.0367, 0.1083, 0.0365, 0.0553, 0.1136, 0.0422, 0.0651,
        0.0306, 0.0748, 0.1508], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,937][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1874, 0.0754, 0.1051, 0.0790, 0.0823, 0.0489, 0.0818, 0.0720, 0.0299,
        0.0749, 0.0745, 0.0889], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:27,939][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.2065, 0.0918, 0.0276, 0.0830, 0.1118, 0.0587, 0.0866, 0.0519, 0.0715,
        0.0371, 0.0643, 0.0859, 0.0232], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,940][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([9.8100e-04, 2.2789e-03, 1.2200e-03, 1.7886e-03, 2.1859e-03, 1.1694e-03,
        3.9887e-04, 3.1041e-03, 5.1438e-04, 1.2960e-03, 5.8918e-04, 9.8637e-04,
        9.8349e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,942][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.1451, 0.0498, 0.2631, 0.0435, 0.0111, 0.0754, 0.0440, 0.0509, 0.0647,
        0.0870, 0.0670, 0.0496, 0.0487], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,943][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([2.6440e-04, 6.7578e-07, 1.1532e-05, 1.7832e-06, 1.5828e-05, 9.9484e-06,
        1.4848e-05, 9.9429e-04, 1.7501e-04, 3.6773e-03, 4.1684e-04, 3.5971e-04,
        9.9406e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,945][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0332, 0.0021, 0.0072, 0.0035, 0.0079, 0.0025, 0.0021, 0.0209, 0.0144,
        0.0288, 0.0308, 0.0253, 0.8214], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,946][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([1.1151e-02, 3.7606e-05, 5.4630e-05, 6.5190e-06, 4.9800e-05, 3.0191e-05,
        3.1773e-06, 1.7093e-04, 2.1962e-06, 2.0902e-05, 2.1611e-06, 1.7158e-06,
        9.8847e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,948][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.1767, 0.0363, 0.1642, 0.0227, 0.2076, 0.0141, 0.0159, 0.0416, 0.0157,
        0.1638, 0.0113, 0.0149, 0.1151], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,950][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0379, 0.0065, 0.0062, 0.0188, 0.0052, 0.0245, 0.0394, 0.0698, 0.0827,
        0.1359, 0.2082, 0.2705, 0.0943], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,950][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.1259, 0.0848, 0.0641, 0.0990, 0.0659, 0.0642, 0.0549, 0.0558, 0.0680,
        0.0881, 0.0945, 0.0877, 0.0473], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,951][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.1729, 0.0905, 0.1110, 0.0851, 0.0351, 0.0586, 0.0763, 0.0531, 0.0719,
        0.0746, 0.0713, 0.0831, 0.0165], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,952][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.1145, 0.0797, 0.0452, 0.0831, 0.0478, 0.0570, 0.0687, 0.0515, 0.0604,
        0.0299, 0.0564, 0.0642, 0.2416], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,953][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.2348, 0.0865, 0.0755, 0.0591, 0.0903, 0.0406, 0.0274, 0.0775, 0.0579,
        0.0721, 0.0910, 0.0248, 0.0625], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:27,955][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.4064, 0.0127, 0.1360, 0.0106, 0.0776, 0.0442, 0.0199, 0.0718, 0.0081,
        0.0989, 0.0154, 0.0338, 0.0554, 0.0092], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,956][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([2.9631e-03, 2.9734e-02, 1.5045e-03, 5.5047e-03, 4.5631e-04, 1.1779e-04,
        2.5988e-04, 2.2043e-04, 2.5099e-03, 7.6560e-05, 1.1358e-03, 2.5203e-04,
        4.5335e-05, 9.5522e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,958][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.3473, 0.0443, 0.0254, 0.0380, 0.0328, 0.1943, 0.0176, 0.0469, 0.0836,
        0.0370, 0.0516, 0.0216, 0.0146, 0.0450], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,959][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([1.3386e-02, 1.5914e-03, 4.7282e-04, 1.5420e-03, 8.9198e-04, 4.8082e-03,
        5.1833e-03, 2.1061e-02, 2.0166e-02, 2.1423e-02, 6.9303e-02, 1.8824e-01,
        1.3918e-01, 5.1274e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,961][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0275, 0.0093, 0.0044, 0.0177, 0.0052, 0.0192, 0.0164, 0.0406, 0.0541,
        0.0613, 0.1252, 0.1071, 0.2136, 0.2986], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,963][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1049, 0.1668, 0.0083, 0.1069, 0.0148, 0.0739, 0.0803, 0.0336, 0.0528,
        0.0111, 0.0557, 0.0646, 0.0117, 0.2147], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,964][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.2295, 0.0059, 0.1853, 0.0044, 0.1321, 0.0121, 0.0059, 0.0892, 0.0036,
        0.1883, 0.0077, 0.0039, 0.1296, 0.0029], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,966][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0177, 0.0043, 0.0067, 0.0079, 0.0120, 0.0119, 0.0181, 0.0296, 0.0308,
        0.0654, 0.0919, 0.1421, 0.1668, 0.3948], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,968][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0143, 0.1268, 0.0056, 0.1011, 0.0049, 0.0225, 0.0845, 0.0064, 0.0606,
        0.0048, 0.0400, 0.1367, 0.0071, 0.3846], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,970][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.1443, 0.0806, 0.0539, 0.0838, 0.0487, 0.0639, 0.0645, 0.0608, 0.0675,
        0.0603, 0.0707, 0.0728, 0.0395, 0.0888], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,971][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1066, 0.0900, 0.0465, 0.0969, 0.0463, 0.0733, 0.0600, 0.0630, 0.0752,
        0.0528, 0.0742, 0.0603, 0.0283, 0.1267], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,973][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.2085, 0.0727, 0.0783, 0.0690, 0.0743, 0.0487, 0.0422, 0.0673, 0.0343,
        0.0613, 0.0726, 0.0326, 0.0477, 0.0904], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:27,975][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.1598, 0.0983, 0.0367, 0.1337, 0.0415, 0.0173, 0.0590, 0.0114, 0.0664,
        0.0367, 0.0475, 0.0655, 0.0568, 0.1375, 0.0319], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,976][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([9.9776e-06, 4.1278e-05, 5.0564e-01, 5.1011e-05, 1.0917e-04, 6.3076e-06,
        4.5202e-05, 5.1956e-05, 4.2096e-06, 1.4182e-04, 3.1054e-05, 8.5915e-06,
        3.7168e-06, 1.9188e-05, 4.9383e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,978][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.1650, 0.0921, 0.0744, 0.0629, 0.0258, 0.0636, 0.0784, 0.0255, 0.0633,
        0.0410, 0.0823, 0.0736, 0.0167, 0.0690, 0.0663], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,979][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([1.0776e-03, 1.3640e-06, 2.8182e-03, 1.1917e-06, 7.0692e-05, 6.3456e-06,
        9.9969e-06, 3.2920e-05, 3.6107e-05, 9.0034e-04, 8.9870e-05, 1.3817e-04,
        2.5031e-02, 2.1402e-04, 9.6957e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,981][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([9.5722e-04, 4.2768e-05, 4.5783e-02, 3.8930e-05, 3.4397e-04, 8.6464e-05,
        4.4324e-05, 1.9469e-04, 1.1933e-04, 8.1556e-05, 2.2803e-04, 1.8508e-04,
        6.7969e-04, 5.8749e-04, 9.5063e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,982][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([1.5829e-03, 3.4089e-07, 7.1137e-01, 2.4825e-07, 3.4737e-05, 2.9447e-07,
        1.5599e-08, 4.8969e-06, 7.5688e-08, 1.3905e-05, 7.5579e-08, 9.3573e-09,
        2.4704e-07, 3.2639e-09, 2.8699e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,984][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.1104, 0.1116, 0.1385, 0.0859, 0.0543, 0.0225, 0.0515, 0.0198, 0.0397,
        0.0323, 0.0138, 0.1046, 0.0372, 0.0558, 0.1223], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,986][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.0519, 0.0103, 0.0031, 0.0199, 0.0058, 0.0159, 0.0251, 0.0151, 0.0592,
        0.0367, 0.1100, 0.1383, 0.0809, 0.3787, 0.0489], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,987][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.1638, 0.1116, 0.0356, 0.1118, 0.0301, 0.0469, 0.0916, 0.0254, 0.0702,
        0.0145, 0.0763, 0.0928, 0.0121, 0.0852, 0.0321], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,988][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.1505, 0.0981, 0.0149, 0.0838, 0.0534, 0.0618, 0.0575, 0.0541, 0.0756,
        0.0439, 0.0676, 0.0702, 0.0656, 0.0891, 0.0140], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,989][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0728, 0.0577, 0.2989, 0.0576, 0.0188, 0.0283, 0.0379, 0.0199, 0.0357,
        0.0254, 0.0289, 0.0328, 0.0121, 0.0383, 0.2349], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,990][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.0382, 0.0607, 0.0416, 0.0607, 0.0429, 0.0816, 0.0867, 0.0606, 0.0352,
        0.0752, 0.0862, 0.0724, 0.0731, 0.1157, 0.0694], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:27,991][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.1957, 0.0193, 0.0770, 0.0232, 0.0624, 0.0960, 0.0183, 0.0467, 0.0226,
        0.0374, 0.0185, 0.0171, 0.0366, 0.0154, 0.1030, 0.2111],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:27,993][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([3.7507e-04, 5.8230e-04, 2.3851e-04, 1.2662e-03, 1.0604e-04, 6.5381e-03,
        1.4120e-04, 3.2843e-04, 7.6577e-04, 1.2331e-04, 3.5793e-04, 1.7576e-04,
        5.8585e-04, 5.0877e-05, 1.3780e-04, 9.8823e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:27,994][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1717, 0.0430, 0.0370, 0.0519, 0.0192, 0.0772, 0.0446, 0.0581, 0.0740,
        0.0651, 0.0731, 0.0548, 0.0431, 0.0728, 0.0374, 0.0769],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:27,996][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([8.5724e-04, 4.5927e-06, 2.7773e-06, 3.9900e-06, 1.8772e-06, 4.5492e-05,
        1.1779e-05, 3.8567e-05, 4.7068e-05, 2.9175e-04, 1.4089e-04, 2.0615e-04,
        2.0616e-03, 6.5096e-04, 1.2747e-03, 9.9436e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:27,997][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0880, 0.0069, 0.0033, 0.0069, 0.0032, 0.0113, 0.0079, 0.0107, 0.0201,
        0.0240, 0.0417, 0.0227, 0.0301, 0.0454, 0.0302, 0.6476],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:27,999][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([3.9535e-02, 2.1611e-05, 8.7926e-05, 2.1873e-05, 2.0067e-05, 1.8038e-03,
        1.2767e-05, 7.0411e-06, 5.9634e-06, 5.3258e-05, 1.5033e-05, 7.0796e-06,
        6.4641e-05, 1.0706e-06, 1.6710e-05, 9.5833e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,001][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0972, 0.0122, 0.1308, 0.0119, 0.1117, 0.0145, 0.0174, 0.0783, 0.0090,
        0.1501, 0.0105, 0.0134, 0.0956, 0.0125, 0.2051, 0.0298],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,002][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0192, 0.0043, 0.0036, 0.0063, 0.0051, 0.0063, 0.0122, 0.0142, 0.0156,
        0.0248, 0.0574, 0.0790, 0.0732, 0.3163, 0.1323, 0.2301],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,004][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0736, 0.0727, 0.0143, 0.0920, 0.0078, 0.0398, 0.1048, 0.0360, 0.0811,
        0.0653, 0.0755, 0.1271, 0.0550, 0.0986, 0.0205, 0.0359],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,006][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1061, 0.0581, 0.0637, 0.0617, 0.0476, 0.0575, 0.0516, 0.0515, 0.0570,
        0.0700, 0.0516, 0.0555, 0.0466, 0.0836, 0.0812, 0.0567],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,008][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0803, 0.0566, 0.0310, 0.0638, 0.0322, 0.1063, 0.0520, 0.0310, 0.0548,
        0.0343, 0.0565, 0.0499, 0.0319, 0.0672, 0.0307, 0.2215],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,009][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.2167, 0.0765, 0.0526, 0.0914, 0.0424, 0.0402, 0.0367, 0.0462, 0.0387,
        0.0448, 0.0679, 0.0329, 0.0276, 0.0824, 0.0490, 0.0540],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,011][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2040, 0.0161, 0.1162, 0.0125, 0.0358, 0.0260, 0.0112, 0.0496, 0.0106,
        0.0858, 0.0104, 0.0198, 0.0768, 0.0147, 0.1873, 0.1061, 0.0171],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,013][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([4.3936e-04, 1.1437e-03, 1.1094e-04, 1.2523e-03, 1.5833e-04, 1.3498e-04,
        4.3335e-01, 1.8448e-04, 1.1692e-03, 9.9741e-04, 3.4127e-03, 1.4678e-02,
        5.5874e-05, 2.8416e-04, 6.0603e-05, 1.1752e-04, 5.4245e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,014][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1001, 0.0512, 0.0253, 0.0780, 0.0327, 0.0469, 0.0159, 0.0593, 0.0786,
        0.0443, 0.1192, 0.0185, 0.0279, 0.1659, 0.0296, 0.0887, 0.0179],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,016][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([3.6062e-03, 2.7405e-04, 4.0180e-05, 1.7544e-04, 8.1995e-05, 3.7735e-04,
        1.3141e-03, 5.5635e-04, 1.7526e-03, 1.7610e-03, 4.7871e-03, 1.9567e-02,
        9.8086e-03, 2.9044e-02, 8.4373e-03, 1.3268e-01, 7.8574e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,018][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0227, 0.0027, 0.0041, 0.0029, 0.0027, 0.0189, 0.0075, 0.0070, 0.0113,
        0.0262, 0.0248, 0.0189, 0.0297, 0.0220, 0.0558, 0.5495, 0.1933],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,019][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.6602e-02, 5.2894e-02, 1.1566e-03, 4.6415e-02, 2.3619e-03, 2.4840e-02,
        4.1637e-01, 3.8494e-03, 2.4919e-02, 4.2860e-03, 3.1514e-02, 1.0138e-01,
        2.2489e-03, 1.3189e-02, 2.5104e-04, 3.8618e-03, 2.5386e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,021][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1039, 0.0024, 0.1102, 0.0023, 0.1009, 0.0152, 0.0026, 0.0992, 0.0025,
        0.1257, 0.0052, 0.0021, 0.1381, 0.0022, 0.2145, 0.0689, 0.0039],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,022][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0136, 0.0025, 0.0031, 0.0039, 0.0037, 0.0035, 0.0039, 0.0072, 0.0093,
        0.0117, 0.0294, 0.0345, 0.0314, 0.1958, 0.1241, 0.2689, 0.2535],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,024][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0069, 0.0339, 0.0028, 0.0595, 0.0020, 0.0463, 0.1369, 0.0065, 0.0438,
        0.0112, 0.0356, 0.1959, 0.0085, 0.1003, 0.0058, 0.0235, 0.2806],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,025][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1081, 0.0662, 0.0379, 0.0728, 0.0362, 0.0489, 0.0569, 0.0480, 0.0672,
        0.0423, 0.0664, 0.0684, 0.0333, 0.0718, 0.0418, 0.0615, 0.0724],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,026][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0759, 0.0590, 0.0250, 0.0696, 0.0241, 0.0462, 0.1291, 0.0346, 0.0553,
        0.0396, 0.0712, 0.0834, 0.0293, 0.0562, 0.0229, 0.0368, 0.1417],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,026][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1639, 0.0615, 0.0709, 0.0587, 0.0607, 0.0399, 0.0450, 0.0520, 0.0257,
        0.0505, 0.0513, 0.0332, 0.0417, 0.0663, 0.0723, 0.0622, 0.0441],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,028][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([0.1039, 0.0607, 0.0678, 0.0664, 0.0364, 0.0260, 0.0371, 0.0436, 0.0572,
        0.0555, 0.0379, 0.0376, 0.0134, 0.0326, 0.0659, 0.0437, 0.0419, 0.1723],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,030][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([7.1105e-05, 5.8871e-05, 3.7398e-03, 4.5509e-05, 1.3344e-04, 2.3543e-05,
        5.2985e-05, 8.3159e-05, 7.1650e-05, 1.5703e-04, 4.4947e-05, 1.2603e-05,
        3.0375e-06, 2.7224e-05, 1.9919e-03, 1.2429e-05, 3.2700e-05, 9.9344e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,031][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([0.1132, 0.0469, 0.0280, 0.0533, 0.0298, 0.0435, 0.0718, 0.0632, 0.0530,
        0.0440, 0.0485, 0.0861, 0.0464, 0.0473, 0.0232, 0.0646, 0.0786, 0.0585],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,033][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([1.2742e-03, 6.3947e-07, 6.3289e-06, 8.5438e-07, 1.2477e-05, 3.8617e-06,
        2.8822e-06, 1.0333e-04, 7.9536e-06, 1.2206e-04, 4.9044e-05, 3.3638e-05,
        2.3319e-03, 1.0151e-04, 1.8425e-03, 4.1465e-03, 1.3554e-03, 9.8861e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,034][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([1.1029e-02, 1.0145e-03, 5.1159e-03, 6.4159e-04, 1.2718e-03, 4.9043e-04,
        6.9292e-04, 1.3014e-03, 1.9818e-03, 5.3246e-03, 3.1662e-03, 1.6932e-03,
        4.6473e-03, 4.1845e-03, 3.9679e-02, 5.0081e-03, 8.1531e-03, 9.0460e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,035][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([8.9118e-03, 6.0990e-06, 7.4756e-04, 1.3543e-06, 2.7176e-05, 5.3741e-07,
        5.0804e-07, 2.2952e-05, 2.1883e-07, 9.3999e-06, 3.0648e-07, 1.8308e-07,
        2.9655e-08, 1.0944e-07, 1.6976e-04, 8.9334e-08, 1.5536e-07, 9.9010e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,037][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([0.0883, 0.0455, 0.1246, 0.0368, 0.0498, 0.0173, 0.0354, 0.0246, 0.0210,
        0.0681, 0.0170, 0.0417, 0.0723, 0.0264, 0.1360, 0.0349, 0.0404, 0.1199],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,039][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([0.0267, 0.0055, 0.0021, 0.0100, 0.0015, 0.0071, 0.0096, 0.0098, 0.0195,
        0.0114, 0.0398, 0.0408, 0.0115, 0.1609, 0.0378, 0.2004, 0.3083, 0.0973],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,041][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([0.1248, 0.0524, 0.0273, 0.0578, 0.0375, 0.0353, 0.0700, 0.0218, 0.0390,
        0.0379, 0.0603, 0.0637, 0.0147, 0.0447, 0.0258, 0.0386, 0.0800, 0.1683],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,043][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([0.0902, 0.0571, 0.0870, 0.0579, 0.0389, 0.0423, 0.0444, 0.0404, 0.0536,
        0.0661, 0.0454, 0.0436, 0.0549, 0.0663, 0.1067, 0.0431, 0.0557, 0.0065],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,044][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([0.0942, 0.0567, 0.0574, 0.0581, 0.0181, 0.0423, 0.0434, 0.0381, 0.0528,
        0.0354, 0.0345, 0.0389, 0.0121, 0.0559, 0.0556, 0.0240, 0.0446, 0.2377],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,046][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([0.1210, 0.0583, 0.0390, 0.0453, 0.0511, 0.0497, 0.0331, 0.0706, 0.0650,
        0.0732, 0.0679, 0.0219, 0.0431, 0.0672, 0.0419, 0.0756, 0.0351, 0.0410],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,048][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1936, 0.0170, 0.0867, 0.0142, 0.0412, 0.0473, 0.0150, 0.0486, 0.0156,
        0.0537, 0.0145, 0.0226, 0.0548, 0.0156, 0.1457, 0.1266, 0.0245, 0.0492,
        0.0137], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,049][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.0644e-03, 8.9854e-03, 3.2131e-05, 2.6125e-02, 8.6953e-05, 2.3097e-04,
        1.0627e-03, 3.7218e-05, 2.5762e-02, 1.8242e-04, 1.4922e-02, 1.4074e-03,
        6.7699e-05, 6.9825e-03, 1.8110e-05, 6.6516e-04, 9.9170e-04, 1.7519e-05,
        9.0836e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,051][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1048, 0.0427, 0.0159, 0.0622, 0.0235, 0.0383, 0.0159, 0.0457, 0.0672,
        0.0355, 0.0916, 0.0188, 0.0218, 0.1884, 0.0169, 0.0538, 0.0176, 0.0133,
        0.1260], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,053][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.1837e-03, 6.2422e-05, 4.9515e-06, 2.9931e-05, 8.6322e-07, 7.1425e-05,
        9.9584e-05, 2.9702e-05, 3.8797e-04, 2.6051e-04, 5.8936e-04, 2.3947e-03,
        6.5967e-04, 4.3375e-03, 6.7032e-04, 2.4780e-01, 7.0425e-02, 3.2798e-02,
        6.3819e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,054][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0225, 0.0012, 0.0014, 0.0018, 0.0005, 0.0120, 0.0032, 0.0050, 0.0044,
        0.0288, 0.0113, 0.0084, 0.0112, 0.0138, 0.0171, 0.4045, 0.0908, 0.0618,
        0.3002], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,056][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0298, 0.0436, 0.0017, 0.0587, 0.0013, 0.0250, 0.1858, 0.0075, 0.0395,
        0.0096, 0.0168, 0.1357, 0.0015, 0.0165, 0.0004, 0.0049, 0.1149, 0.0006,
        0.3062], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,058][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0888, 0.0039, 0.0537, 0.0034, 0.0463, 0.0120, 0.0032, 0.0381, 0.0048,
        0.1085, 0.0173, 0.0027, 0.0600, 0.0047, 0.1085, 0.0576, 0.0052, 0.0687,
        0.3126], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,060][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0159, 0.0023, 0.0023, 0.0031, 0.0028, 0.0028, 0.0034, 0.0047, 0.0041,
        0.0121, 0.0121, 0.0200, 0.0215, 0.0998, 0.0551, 0.1321, 0.1738, 0.1302,
        0.3018], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,061][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0054, 0.0389, 0.0029, 0.0698, 0.0010, 0.0316, 0.0855, 0.0057, 0.0497,
        0.0059, 0.0339, 0.1527, 0.0064, 0.1179, 0.0055, 0.0175, 0.1683, 0.0087,
        0.1927], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,062][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0916, 0.0545, 0.0360, 0.0616, 0.0313, 0.0419, 0.0523, 0.0416, 0.0558,
        0.0443, 0.0558, 0.0599, 0.0293, 0.0629, 0.0409, 0.0550, 0.0671, 0.0345,
        0.0838], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,063][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0714, 0.0546, 0.0263, 0.0702, 0.0267, 0.0550, 0.0633, 0.0346, 0.0626,
        0.0400, 0.0631, 0.0632, 0.0262, 0.0675, 0.0264, 0.0552, 0.0703, 0.0249,
        0.0984], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,064][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1512, 0.0582, 0.0642, 0.0589, 0.0562, 0.0433, 0.0381, 0.0463, 0.0274,
        0.0454, 0.0549, 0.0273, 0.0353, 0.0585, 0.0622, 0.0605, 0.0355, 0.0218,
        0.0549], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,068][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:28,070][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[29705],
        [10579],
        [ 2241],
        [18365],
        [    1],
        [16920],
        [15388],
        [ 6609],
        [14601],
        [18251],
        [22343],
        [14207],
        [ 4176],
        [11912],
        [ 3081],
        [13832],
        [17085],
        [ 4990],
        [15451]], device='cuda:0')
[2024-07-24 10:27:28,072][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[34185],
        [43510],
        [12518],
        [43744],
        [    1],
        [43110],
        [34513],
        [31911],
        [37735],
        [39026],
        [36171],
        [24872],
        [36903],
        [36519],
        [ 4138],
        [40579],
        [23720],
        [40884],
        [30826]], device='cuda:0')
[2024-07-24 10:27:28,074][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 1155],
        [ 1094],
        [ 2254],
        [ 3491],
        [ 6117],
        [ 3280],
        [ 2927],
        [ 2358],
        [ 2646],
        [ 4437],
        [ 6057],
        [ 4496],
        [ 4600],
        [ 2782],
        [ 7866],
        [ 8338],
        [13212],
        [ 5865],
        [ 8569]], device='cuda:0')
[2024-07-24 10:27:28,076][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 8962],
        [36730],
        [35712],
        [46320],
        [12953],
        [44031],
        [45757],
        [12723],
        [40307],
        [18526],
        [39536],
        [46558],
        [21580],
        [25672],
        [32506],
        [10994],
        [44118],
        [21964],
        [35193]], device='cuda:0')
[2024-07-24 10:27:28,078][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[14864],
        [14539],
        [16169],
        [20923],
        [ 9240],
        [20596],
        [21165],
        [22059],
        [20792],
        [20748],
        [20830],
        [22060],
        [25366],
        [24565],
        [22477],
        [24001],
        [26400],
        [19078],
        [27313]], device='cuda:0')
[2024-07-24 10:27:28,080][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[50204],
        [49407],
        [14101],
        [11533],
        [  147],
        [ 1565],
        [ 3342],
        [15099],
        [11435],
        [ 2540],
        [ 8050],
        [12801],
        [ 3653],
        [ 6222],
        [ 6180],
        [ 5521],
        [ 3931],
        [ 5220],
        [ 6264]], device='cuda:0')
[2024-07-24 10:27:28,082][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[32632],
        [32688],
        [ 5862],
        [21692],
        [  107],
        [12997],
        [13835],
        [ 2201],
        [ 3562],
        [ 7483],
        [ 8892],
        [13649],
        [29432],
        [13817],
        [ 4975],
        [23441],
        [18641],
        [42759],
        [26960]], device='cuda:0')
[2024-07-24 10:27:28,084][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[23280],
        [17534],
        [ 3176],
        [18437],
        [ 1757],
        [15793],
        [18987],
        [ 1645],
        [21277],
        [19764],
        [23614],
        [16611],
        [24795],
        [21953],
        [ 3569],
        [31782],
        [20689],
        [ 3319],
        [20309]], device='cuda:0')
[2024-07-24 10:27:28,086][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[27993],
        [27723],
        [10813],
        [11449],
        [ 1595],
        [  177],
        [  360],
        [ 2572],
        [  471],
        [  599],
        [  637],
        [  474],
        [  456],
        [ 2433],
        [ 3484],
        [ 1343],
        [ 2648],
        [ 2608],
        [ 7698]], device='cuda:0')
[2024-07-24 10:27:28,088][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 9289],
        [ 7403],
        [ 2048],
        [ 1253],
        [  679],
        [ 2324],
        [ 8304],
        [15755],
        [16180],
        [14069],
        [ 3012],
        [ 4918],
        [13323],
        [20852],
        [ 7963],
        [11152],
        [21278],
        [22925],
        [11859]], device='cuda:0')
[2024-07-24 10:27:28,089][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 4232],
        [ 6729],
        [ 2866],
        [13915],
        [  293],
        [10010],
        [15920],
        [ 7662],
        [13985],
        [ 6269],
        [10069],
        [10939],
        [ 1318],
        [12046],
        [ 3753],
        [ 5467],
        [12627],
        [10858],
        [13401]], device='cuda:0')
[2024-07-24 10:27:28,091][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[43405],
        [46907],
        [46897],
        [47640],
        [45552],
        [45175],
        [46616],
        [44681],
        [46827],
        [44586],
        [45994],
        [46352],
        [43900],
        [44763],
        [44914],
        [39922],
        [45456],
        [35789],
        [44612]], device='cuda:0')
[2024-07-24 10:27:28,093][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[11650],
        [ 5575],
        [21462],
        [ 3865],
        [14127],
        [ 1873],
        [ 3787],
        [11292],
        [ 2510],
        [19541],
        [ 1806],
        [ 4815],
        [34435],
        [ 2495],
        [31608],
        [ 2560],
        [ 5300],
        [19232],
        [ 2622]], device='cuda:0')
[2024-07-24 10:27:28,095][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[18290],
        [14023],
        [17188],
        [18456],
        [14655],
        [13132],
        [14039],
        [12630],
        [13135],
        [10379],
        [10033],
        [13461],
        [ 9384],
        [10415],
        [12203],
        [12761],
        [13697],
        [ 9565],
        [12176]], device='cuda:0')
[2024-07-24 10:27:28,097][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[39328],
        [ 8342],
        [ 1335],
        [31922],
        [    1],
        [38677],
        [37842],
        [28523],
        [25447],
        [42438],
        [20116],
        [32337],
        [14903],
        [ 9721],
        [ 1163],
        [38282],
        [37787],
        [ 6889],
        [19269]], device='cuda:0')
[2024-07-24 10:27:28,099][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[13149],
        [14219],
        [18842],
        [12656],
        [14332],
        [ 9526],
        [10867],
        [18700],
        [13930],
        [22038],
        [21852],
        [16179],
        [24146],
        [17541],
        [26780],
        [17333],
        [16968],
        [20336],
        [16627]], device='cuda:0')
[2024-07-24 10:27:28,101][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[11211],
        [ 6312],
        [18771],
        [ 4715],
        [21100],
        [12931],
        [ 3431],
        [13663],
        [ 3490],
        [16723],
        [11179],
        [ 2118],
        [17374],
        [ 8145],
        [16838],
        [28256],
        [ 4477],
        [21601],
        [ 7431]], device='cuda:0')
[2024-07-24 10:27:28,102][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[42288],
        [41480],
        [40862],
        [46487],
        [33697],
        [41830],
        [43270],
        [43187],
        [42525],
        [42003],
        [39549],
        [37979],
        [37543],
        [39471],
        [37165],
        [39007],
        [35930],
        [39750],
        [31980]], device='cuda:0')
[2024-07-24 10:27:28,104][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 9825],
        [12479],
        [ 5667],
        [18962],
        [14364],
        [13963],
        [10512],
        [18656],
        [11736],
        [29656],
        [ 8525],
        [ 7697],
        [11929],
        [12475],
        [ 5541],
        [10461],
        [10079],
        [13629],
        [10382]], device='cuda:0')
[2024-07-24 10:27:28,106][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 5949],
        [ 6066],
        [ 8674],
        [ 6480],
        [ 3936],
        [ 5085],
        [ 5291],
        [14934],
        [ 8557],
        [14444],
        [ 5298],
        [ 5694],
        [13539],
        [11534],
        [ 8492],
        [ 5629],
        [ 4517],
        [ 7514],
        [ 3827]], device='cuda:0')
[2024-07-24 10:27:28,108][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[27124],
        [23693],
        [29353],
        [17353],
        [ 6019],
        [11956],
        [10201],
        [16914],
        [12946],
        [ 5997],
        [11766],
        [11033],
        [13715],
        [15116],
        [28995],
        [ 7658],
        [ 8707],
        [27254],
        [11983]], device='cuda:0')
[2024-07-24 10:27:28,110][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[42737],
        [42673],
        [28896],
        [42156],
        [20305],
        [14217],
        [21499],
        [15211],
        [10676],
        [16854],
        [15265],
        [16729],
        [14672],
        [24841],
        [18790],
        [24331],
        [26207],
        [18264],
        [42089]], device='cuda:0')
[2024-07-24 10:27:28,111][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[41768],
        [41388],
        [40420],
        [43351],
        [44622],
        [39744],
        [28723],
        [33102],
        [33562],
        [38416],
        [40631],
        [27447],
        [35554],
        [40202],
        [32723],
        [35852],
        [24830],
        [25416],
        [29498]], device='cuda:0')
[2024-07-24 10:27:28,113][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[34926],
        [26729],
        [32747],
        [26051],
        [33607],
        [29453],
        [28976],
        [31524],
        [27920],
        [31846],
        [28246],
        [30561],
        [35189],
        [23527],
        [31214],
        [32601],
        [30881],
        [34347],
        [30161]], device='cuda:0')
[2024-07-24 10:27:28,115][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[38352],
        [37235],
        [37092],
        [36953],
        [37919],
        [38686],
        [35655],
        [36456],
        [35784],
        [36181],
        [35954],
        [35007],
        [35258],
        [33337],
        [33216],
        [34747],
        [33482],
        [34245],
        [33025]], device='cuda:0')
[2024-07-24 10:27:28,117][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[45158],
        [45654],
        [39685],
        [44397],
        [37546],
        [39410],
        [39817],
        [41254],
        [41290],
        [31811],
        [41172],
        [39315],
        [30350],
        [40156],
        [36150],
        [37656],
        [36836],
        [36014],
        [38752]], device='cuda:0')
[2024-07-24 10:27:28,119][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[10237],
        [ 7611],
        [24104],
        [ 7880],
        [18894],
        [11171],
        [22309],
        [ 8582],
        [18703],
        [16233],
        [14825],
        [24007],
        [18117],
        [19452],
        [25820],
        [16726],
        [21873],
        [16016],
        [18609]], device='cuda:0')
[2024-07-24 10:27:28,121][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 5358],
        [ 5770],
        [ 8882],
        [ 7791],
        [10620],
        [13796],
        [16031],
        [10007],
        [14999],
        [12556],
        [13840],
        [17462],
        [13765],
        [12816],
        [11854],
        [12158],
        [17477],
        [12129],
        [15068]], device='cuda:0')
[2024-07-24 10:27:28,123][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 7652],
        [34777],
        [47449],
        [12280],
        [50255],
        [ 8262],
        [ 7723],
        [15809],
        [17656],
        [ 5488],
        [24253],
        [11485],
        [28762],
        [35286],
        [47817],
        [ 8608],
        [ 7816],
        [38885],
        [24362]], device='cuda:0')
[2024-07-24 10:27:28,125][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267]], device='cuda:0')
[2024-07-24 10:27:28,148][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:28,149][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,150][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,150][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,150][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,151][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,151][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,151][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,152][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,152][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,153][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,153][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,154][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,154][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2035, 0.7965], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,154][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9605, 0.0395], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,155][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6445, 0.3555], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,155][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3955, 0.6045], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,155][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9204, 0.0796], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,156][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4290, 0.5710], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,156][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4825, 0.5175], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,156][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9730, 0.0270], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,157][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.6996, 0.3004], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,157][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0929, 0.9071], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,157][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([2.1750e-04, 9.9978e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,158][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9055, 0.0945], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,158][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.0125, 0.3258, 0.6616], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,158][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.9490, 0.0334, 0.0176], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,159][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.4477, 0.2785, 0.2738], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,159][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.3343, 0.5017, 0.1640], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,159][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.7075, 0.1466, 0.1459], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,160][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0480, 0.2605, 0.6914], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,160][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.0011, 0.0111, 0.9878], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,160][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.7115, 0.1028, 0.1857], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,161][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.6089, 0.2889, 0.1022], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,161][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0642, 0.7865, 0.1493], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,161][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.0008, 0.7050, 0.2943], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,162][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([3.0963e-05, 2.6245e-05, 9.9994e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,162][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0097, 0.1693, 0.6520, 0.1690], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,163][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.8732, 0.0371, 0.0285, 0.0612], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,163][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3458, 0.1996, 0.2233, 0.2312], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,164][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2433, 0.3611, 0.1103, 0.2853], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,165][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.6434, 0.0873, 0.1585, 0.1108], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,167][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3987, 0.2920, 0.2684, 0.0409], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,168][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([5.3150e-04, 3.1355e-04, 9.9808e-01, 1.0750e-03], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,169][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.5229, 0.0583, 0.2328, 0.1860], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,170][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.6079, 0.2654, 0.1022, 0.0246], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,172][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0465, 0.6712, 0.1828, 0.0995], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,173][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0023, 0.3940, 0.3349, 0.2689], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,175][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0332, 0.0285, 0.0033, 0.9349], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,176][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.0022, 0.0662, 0.6834, 0.1102, 0.1380], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,177][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([0.9028, 0.0250, 0.0139, 0.0508, 0.0076], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,179][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.2823, 0.1803, 0.1780, 0.1978, 0.1615], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,180][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.2287, 0.3267, 0.1029, 0.2633, 0.0783], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,181][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.5318, 0.1296, 0.1155, 0.1146, 0.1085], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,183][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([0.0389, 0.2630, 0.5115, 0.0420, 0.1446], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,184][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.0087, 0.1053, 0.5649, 0.3020, 0.0192], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,186][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.5187, 0.1019, 0.1751, 0.1624, 0.0419], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,187][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.6103, 0.2729, 0.0807, 0.0210, 0.0152], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,188][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.0296, 0.7523, 0.1198, 0.0596, 0.0387], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,190][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.0014, 0.3370, 0.2321, 0.2593, 0.1703], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,191][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([1.4193e-05, 9.4912e-06, 2.8559e-05, 2.1109e-05, 9.9993e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,192][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0212, 0.1114, 0.1704, 0.1708, 0.1220, 0.4041], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,193][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.8248, 0.0361, 0.0258, 0.0612, 0.0134, 0.0386], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,195][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2364, 0.1489, 0.1572, 0.1619, 0.1458, 0.1499], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,195][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.2033, 0.2698, 0.0869, 0.2154, 0.0681, 0.1566], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,196][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.4669, 0.0872, 0.1195, 0.0874, 0.1139, 0.1252], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,196][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0091, 0.0908, 0.1037, 0.0022, 0.3342, 0.4601], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,196][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ had] are: tensor([1.4917e-03, 7.9108e-04, 8.5750e-01, 9.6675e-03, 1.5050e-03, 1.2904e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,197][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.4269, 0.0420, 0.1353, 0.0958, 0.1494, 0.1506], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,197][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.6111, 0.2421, 0.0815, 0.0228, 0.0205, 0.0221], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,197][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0260, 0.5254, 0.1477, 0.0345, 0.0562, 0.2102], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,198][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0015, 0.2228, 0.2137, 0.1804, 0.1688, 0.2128], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,198][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ had] are: tensor([5.8084e-05, 6.3696e-04, 4.7460e-04, 3.2512e-04, 2.5394e-04, 9.9825e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,198][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0024, 0.0336, 0.1519, 0.0552, 0.0660, 0.5432, 0.1477],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,199][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.7646, 0.0344, 0.0261, 0.0560, 0.0134, 0.0371, 0.0684],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,199][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2127, 0.1262, 0.1336, 0.1427, 0.1246, 0.1257, 0.1344],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,201][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1771, 0.2388, 0.0760, 0.1847, 0.0578, 0.1356, 0.1299],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,202][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.4199, 0.0766, 0.1010, 0.0820, 0.0957, 0.1087, 0.1161],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,203][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0394, 0.0780, 0.1540, 0.0007, 0.4327, 0.2878, 0.0074],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,204][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([3.1070e-04, 2.5646e-04, 9.4406e-01, 1.7383e-03, 1.1724e-02, 4.1911e-02,
        9.6090e-07], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,205][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.3731, 0.0464, 0.1245, 0.0872, 0.1117, 0.1470, 0.1100],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,207][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.6024, 0.2367, 0.0763, 0.0226, 0.0206, 0.0211, 0.0202],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,208][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0281, 0.4162, 0.0942, 0.0420, 0.0538, 0.1368, 0.2288],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,209][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0022, 0.1690, 0.1840, 0.1466, 0.1468, 0.1680, 0.1833],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,210][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([2.4858e-05, 7.0001e-05, 4.2761e-05, 4.1705e-05, 3.9264e-05, 3.6656e-05,
        9.9974e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,212][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0010, 0.0158, 0.0435, 0.0291, 0.0322, 0.1233, 0.5824, 0.1726],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,213][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.7889, 0.0264, 0.0171, 0.0484, 0.0086, 0.0329, 0.0665, 0.0111],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,215][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.2002, 0.1136, 0.1148, 0.1233, 0.1057, 0.1094, 0.1124, 0.1205],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,216][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.1657, 0.2210, 0.0726, 0.1697, 0.0552, 0.1231, 0.1222, 0.0704],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,217][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.3659, 0.0747, 0.0860, 0.0820, 0.0920, 0.0962, 0.1017, 0.1016],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,219][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0607, 0.1318, 0.0645, 0.0361, 0.0737, 0.3256, 0.0930, 0.2146],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,220][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([2.6169e-03, 5.7130e-03, 9.1694e-01, 3.7675e-02, 1.0867e-03, 3.3809e-02,
        6.2623e-05, 2.1012e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,221][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.4558, 0.0356, 0.0819, 0.0727, 0.0704, 0.1397, 0.0931, 0.0508],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,223][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.5323, 0.2602, 0.0912, 0.0259, 0.0268, 0.0266, 0.0250, 0.0121],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,224][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0220, 0.3108, 0.1499, 0.0291, 0.0756, 0.1467, 0.2619, 0.0041],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,226][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0013, 0.1564, 0.1625, 0.1297, 0.1420, 0.1518, 0.1534, 0.1029],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,226][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([1.0073e-05, 6.1402e-05, 3.8969e-06, 2.7326e-05, 8.1109e-07, 9.0750e-06,
        1.6099e-06, 9.9989e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,228][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0007, 0.0120, 0.0911, 0.0215, 0.0349, 0.0734, 0.2460, 0.5085, 0.0119],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,229][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.6774, 0.0345, 0.0272, 0.0536, 0.0136, 0.0352, 0.0663, 0.0153, 0.0769],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,231][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.1670, 0.0988, 0.1092, 0.1106, 0.1017, 0.1026, 0.1038, 0.1097, 0.0966],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,232][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.1565, 0.2089, 0.0649, 0.1577, 0.0486, 0.1156, 0.1113, 0.0626, 0.0739],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,233][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.3111, 0.0695, 0.1028, 0.0721, 0.0970, 0.0907, 0.0918, 0.0645, 0.1005],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,233][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0164, 0.0470, 0.0865, 0.0024, 0.2485, 0.3199, 0.0246, 0.1799, 0.0748],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,233][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ of] are: tensor([3.3001e-03, 1.9622e-03, 6.4241e-01, 3.7400e-02, 7.0329e-02, 9.5087e-02,
        5.1207e-05, 3.9533e-02, 1.0993e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,234][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.3243, 0.0613, 0.1024, 0.0773, 0.1007, 0.0970, 0.0822, 0.0715, 0.0832],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,234][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.5494, 0.2446, 0.0848, 0.0263, 0.0252, 0.0252, 0.0231, 0.0111, 0.0103],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,234][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0192, 0.3942, 0.0936, 0.0395, 0.0424, 0.1087, 0.2318, 0.0037, 0.0668],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,235][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0032, 0.1188, 0.1502, 0.1129, 0.1202, 0.1420, 0.1305, 0.0915, 0.1307],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,235][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ of] are: tensor([1.8407e-03, 1.1169e-02, 3.5909e-04, 2.6568e-02, 2.0230e-03, 8.5006e-03,
        1.2668e-01, 4.3701e-03, 8.1849e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,236][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([2.5718e-04, 1.0847e-02, 5.0986e-02, 2.5619e-02, 2.0085e-02, 2.6444e-01,
        2.3158e-01, 3.3534e-01, 2.4766e-02, 3.6076e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,237][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.7252, 0.0232, 0.0129, 0.0435, 0.0066, 0.0299, 0.0615, 0.0095, 0.0814,
        0.0062], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,238][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.1589, 0.0950, 0.0937, 0.1029, 0.0851, 0.0903, 0.0927, 0.0946, 0.0882,
        0.0986], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,240][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.1466, 0.2020, 0.0619, 0.1556, 0.0444, 0.1097, 0.1074, 0.0595, 0.0714,
        0.0416], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,241][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.2946, 0.0660, 0.0653, 0.0703, 0.0657, 0.0808, 0.0756, 0.0766, 0.1010,
        0.1041], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,242][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0027, 0.0358, 0.0562, 0.0039, 0.0429, 0.1155, 0.0467, 0.0563, 0.0107,
        0.6293], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,243][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([9.4836e-04, 3.1181e-03, 3.6192e-01, 1.6683e-02, 1.5234e-03, 5.0906e-03,
        2.5426e-04, 1.5624e-03, 2.5231e-02, 5.8366e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,244][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.2573, 0.0407, 0.0436, 0.0793, 0.0726, 0.2118, 0.0797, 0.1227, 0.0676,
        0.0248], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,246][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.5382, 0.2447, 0.0879, 0.0264, 0.0228, 0.0254, 0.0239, 0.0114, 0.0103,
        0.0090], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,247][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0199, 0.2841, 0.1037, 0.0288, 0.0449, 0.1766, 0.2734, 0.0051, 0.0550,
        0.0085], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,248][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0018, 0.1193, 0.1288, 0.1037, 0.1049, 0.1152, 0.1154, 0.0818, 0.1018,
        0.1275], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,249][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([2.9589e-05, 6.1334e-05, 4.3185e-05, 3.1013e-05, 4.5589e-06, 2.7279e-06,
        1.5106e-05, 1.1786e-04, 4.6545e-05, 9.9965e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,251][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0020, 0.0328, 0.0672, 0.0478, 0.0421, 0.1810, 0.1582, 0.3436, 0.0488,
        0.0499, 0.0266], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,252][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.6285, 0.0316, 0.0250, 0.0507, 0.0126, 0.0335, 0.0636, 0.0143, 0.0750,
        0.0099, 0.0553], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,254][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1430, 0.0815, 0.0897, 0.0912, 0.0842, 0.0821, 0.0851, 0.0908, 0.0774,
        0.0938, 0.0812], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,255][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.1378, 0.1906, 0.0568, 0.1423, 0.0414, 0.1051, 0.0994, 0.0545, 0.0654,
        0.0377, 0.0688], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,257][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.2245, 0.0545, 0.0738, 0.0561, 0.0740, 0.0721, 0.0696, 0.0621, 0.0831,
        0.0975, 0.1327], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,258][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0107, 0.0273, 0.0493, 0.0010, 0.1852, 0.2531, 0.0121, 0.1083, 0.0075,
        0.1382, 0.2074], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,259][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ at] are: tensor([9.8762e-04, 2.6614e-03, 1.2667e-01, 6.9791e-03, 2.2540e-02, 9.1063e-02,
        4.1114e-06, 7.2707e-04, 4.1323e-03, 7.3671e-01, 7.5263e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,260][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.2024, 0.0252, 0.0974, 0.0620, 0.1325, 0.1577, 0.0538, 0.0652, 0.0547,
        0.0869, 0.0620], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,262][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.5246, 0.2475, 0.0878, 0.0261, 0.0262, 0.0264, 0.0241, 0.0115, 0.0105,
        0.0089, 0.0064], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,263][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0168, 0.2940, 0.1131, 0.0274, 0.0570, 0.1078, 0.2554, 0.0032, 0.0474,
        0.0088, 0.0691], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,264][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0028, 0.0870, 0.1120, 0.0877, 0.0911, 0.1042, 0.0987, 0.0732, 0.0925,
        0.1066, 0.1442], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,265][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ at] are: tensor([7.0730e-06, 1.3454e-04, 1.3905e-05, 1.1392e-04, 5.2150e-05, 1.2686e-04,
        5.1949e-05, 2.6363e-05, 1.5959e-04, 1.5518e-05, 9.9930e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,267][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0020, 0.0232, 0.0694, 0.0391, 0.0409, 0.2100, 0.1750, 0.2158, 0.0488,
        0.0416, 0.0611, 0.0732], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,268][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.6211, 0.0285, 0.0216, 0.0449, 0.0107, 0.0297, 0.0539, 0.0125, 0.0669,
        0.0086, 0.0492, 0.0524], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,269][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1254, 0.0752, 0.0824, 0.0848, 0.0778, 0.0767, 0.0805, 0.0864, 0.0727,
        0.0891, 0.0735, 0.0756], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,269][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1282, 0.1753, 0.0531, 0.1332, 0.0398, 0.0975, 0.0925, 0.0515, 0.0605,
        0.0353, 0.0635, 0.0698], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,270][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2020, 0.0485, 0.0646, 0.0484, 0.0624, 0.0597, 0.0666, 0.0633, 0.0667,
        0.0951, 0.1065, 0.1163], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,270][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ the] are: tensor([1.2801e-02, 2.7996e-02, 4.1862e-02, 1.7496e-04, 3.8019e-01, 1.3789e-01,
        2.8409e-03, 1.1124e-01, 2.1902e-03, 2.5391e-01, 2.5727e-02, 3.1834e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,270][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ the] are: tensor([4.2516e-05, 1.4989e-05, 7.3313e-02, 3.2543e-04, 2.8502e-03, 8.2790e-03,
        3.7164e-08, 1.7588e-04, 1.2341e-03, 9.1161e-01, 2.1500e-03, 3.5123e-08],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,271][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1936, 0.0215, 0.0846, 0.0506, 0.0727, 0.1125, 0.0668, 0.0534, 0.0516,
        0.0933, 0.0668, 0.1326], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,271][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.4843, 0.2596, 0.0905, 0.0274, 0.0296, 0.0282, 0.0247, 0.0119, 0.0113,
        0.0093, 0.0070, 0.0160], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,271][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0213, 0.2665, 0.0889, 0.0328, 0.0389, 0.1122, 0.2079, 0.0059, 0.0532,
        0.0113, 0.0824, 0.0787], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,272][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0033, 0.0676, 0.0943, 0.0762, 0.0828, 0.0905, 0.0960, 0.0598, 0.0789,
        0.0975, 0.1231, 0.1301], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,272][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.9651e-05, 1.4579e-04, 2.9671e-05, 1.5975e-04, 4.5480e-05, 8.0318e-05,
        1.3718e-03, 2.6371e-05, 8.1486e-04, 9.7088e-05, 2.9481e-04, 9.9691e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,273][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0002, 0.0196, 0.0562, 0.0301, 0.0393, 0.1737, 0.2002, 0.2157, 0.0435,
        0.0373, 0.0510, 0.0928, 0.0404], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,275][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.6644, 0.0194, 0.0106, 0.0361, 0.0055, 0.0249, 0.0520, 0.0079, 0.0692,
        0.0052, 0.0490, 0.0515, 0.0044], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,276][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.1274, 0.0731, 0.0756, 0.0794, 0.0683, 0.0712, 0.0726, 0.0744, 0.0668,
        0.0785, 0.0674, 0.0672, 0.0779], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,278][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.1190, 0.1731, 0.0505, 0.1357, 0.0343, 0.0930, 0.0914, 0.0477, 0.0599,
        0.0334, 0.0640, 0.0701, 0.0278], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,279][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.1871, 0.0439, 0.0601, 0.0462, 0.0603, 0.0575, 0.0514, 0.0519, 0.0631,
        0.0789, 0.0967, 0.0904, 0.1126], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,280][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0076, 0.0601, 0.0185, 0.0055, 0.0196, 0.0618, 0.0188, 0.0146, 0.0305,
        0.0448, 0.1763, 0.0263, 0.5154], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,281][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ store] are: tensor([7.6440e-04, 1.7393e-03, 1.1926e-01, 2.5533e-02, 9.4999e-04, 2.2470e-03,
        1.3621e-04, 3.2791e-04, 1.9132e-02, 7.8739e-02, 1.4783e-02, 1.8775e-05,
        7.3637e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,282][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.1730, 0.0233, 0.0979, 0.0515, 0.0519, 0.1981, 0.0822, 0.0450, 0.0383,
        0.0554, 0.0751, 0.0899, 0.0184], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,284][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.5392, 0.2386, 0.0796, 0.0225, 0.0211, 0.0228, 0.0214, 0.0104, 0.0095,
        0.0078, 0.0059, 0.0158, 0.0056], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,285][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0096, 0.1519, 0.0611, 0.0149, 0.0226, 0.1493, 0.3894, 0.0030, 0.0416,
        0.0066, 0.0562, 0.0809, 0.0128], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,287][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0015, 0.0781, 0.0819, 0.0782, 0.0642, 0.0844, 0.0853, 0.0577, 0.0701,
        0.0897, 0.1124, 0.1012, 0.0953], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,288][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ store] are: tensor([1.4078e-05, 1.8650e-05, 1.5608e-05, 1.1333e-05, 1.1749e-04, 3.6948e-06,
        3.4775e-06, 9.2081e-06, 5.6164e-06, 4.9129e-06, 6.0777e-05, 3.3767e-07,
        9.9973e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,289][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0017, 0.0209, 0.0753, 0.0339, 0.0753, 0.1016, 0.1492, 0.1765, 0.0375,
        0.0540, 0.0450, 0.0764, 0.0801, 0.0724], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,291][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.6138, 0.0243, 0.0185, 0.0393, 0.0090, 0.0251, 0.0474, 0.0106, 0.0579,
        0.0069, 0.0421, 0.0460, 0.0062, 0.0530], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,292][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1080, 0.0634, 0.0721, 0.0721, 0.0671, 0.0658, 0.0688, 0.0728, 0.0623,
        0.0758, 0.0622, 0.0633, 0.0756, 0.0707], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,294][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.1185, 0.1547, 0.0464, 0.1173, 0.0356, 0.0877, 0.0827, 0.0455, 0.0535,
        0.0311, 0.0561, 0.0614, 0.0262, 0.0833], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,295][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.1693, 0.0389, 0.0569, 0.0346, 0.0526, 0.0505, 0.0426, 0.0536, 0.0491,
        0.0717, 0.0748, 0.0719, 0.1051, 0.1282], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,296][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0111, 0.0206, 0.0414, 0.0011, 0.2354, 0.2860, 0.0071, 0.0654, 0.0050,
        0.0841, 0.0369, 0.0090, 0.1868, 0.0100], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,297][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [.] are: tensor([4.1367e-05, 2.0175e-04, 4.9697e-01, 1.4621e-03, 1.7668e-02, 2.1426e-02,
        3.3428e-07, 5.6796e-05, 3.1011e-03, 1.1045e-01, 1.2640e-02, 2.8220e-07,
        3.3472e-01, 1.2706e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,299][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.1490, 0.0124, 0.0981, 0.0420, 0.0542, 0.0696, 0.0367, 0.0633, 0.0466,
        0.1025, 0.0484, 0.0742, 0.1188, 0.0843], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,300][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.5001, 0.2499, 0.0804, 0.0247, 0.0274, 0.0266, 0.0243, 0.0117, 0.0113,
        0.0094, 0.0073, 0.0170, 0.0066, 0.0032], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,302][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0257, 0.2489, 0.0931, 0.0419, 0.0398, 0.0586, 0.1270, 0.0067, 0.0524,
        0.0134, 0.0601, 0.0530, 0.0408, 0.1386], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,303][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0036, 0.0599, 0.0747, 0.0623, 0.0603, 0.0713, 0.0661, 0.0461, 0.0643,
        0.0731, 0.0935, 0.0863, 0.0908, 0.1476], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,304][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0142, 0.0075, 0.1284, 0.0069, 0.1177, 0.0335, 0.0772, 0.0353, 0.0032,
        0.1698, 0.0393, 0.3166, 0.0395, 0.0110], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,306][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.0009, 0.0290, 0.0494, 0.0283, 0.0543, 0.1883, 0.1931, 0.0637, 0.0687,
        0.0216, 0.0259, 0.0945, 0.0524, 0.0744, 0.0555], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,306][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.5402, 0.0217, 0.0110, 0.0436, 0.0061, 0.0287, 0.0586, 0.0088, 0.0793,
        0.0056, 0.0559, 0.0584, 0.0049, 0.0663, 0.0107], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,307][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.1014, 0.0648, 0.0648, 0.0702, 0.0603, 0.0633, 0.0624, 0.0643, 0.0599,
        0.0677, 0.0599, 0.0590, 0.0674, 0.0671, 0.0674], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,307][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.1061, 0.1538, 0.0451, 0.1147, 0.0315, 0.0836, 0.0795, 0.0443, 0.0535,
        0.0302, 0.0561, 0.0615, 0.0252, 0.0860, 0.0290], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,307][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.1511, 0.0537, 0.0484, 0.0439, 0.0598, 0.0577, 0.0504, 0.0395, 0.0464,
        0.0593, 0.0668, 0.0685, 0.0636, 0.1021, 0.0890], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,308][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0006, 0.0203, 0.0820, 0.0017, 0.1808, 0.0381, 0.0159, 0.0119, 0.0101,
        0.0319, 0.0578, 0.0268, 0.0482, 0.0212, 0.4525], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,308][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([3.8058e-04, 4.5347e-03, 3.4924e-01, 2.1775e-02, 6.7702e-04, 1.4599e-03,
        3.2959e-04, 5.1368e-04, 2.0767e-02, 2.9935e-02, 2.5134e-02, 1.2923e-04,
        2.2372e-01, 2.7408e-02, 2.9400e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,308][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.0508, 0.0156, 0.0129, 0.0281, 0.0386, 0.1686, 0.0593, 0.0510, 0.0261,
        0.0527, 0.0311, 0.1378, 0.1125, 0.2017, 0.0133], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,310][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.4859, 0.2502, 0.0802, 0.0261, 0.0247, 0.0277, 0.0249, 0.0120, 0.0114,
        0.0094, 0.0071, 0.0172, 0.0064, 0.0036, 0.0132], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,311][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0131, 0.1668, 0.0323, 0.0165, 0.0203, 0.1449, 0.2857, 0.0037, 0.0475,
        0.0063, 0.0595, 0.0693, 0.0165, 0.0871, 0.0304], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,313][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.0023, 0.0602, 0.0623, 0.0611, 0.0542, 0.0695, 0.0645, 0.0417, 0.0591,
        0.0701, 0.0846, 0.0905, 0.0796, 0.1336, 0.0668], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,314][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([9.6488e-08, 1.8124e-05, 6.7233e-01, 1.7166e-07, 6.3562e-05, 5.3500e-07,
        8.7212e-07, 2.0033e-07, 8.1029e-08, 2.2787e-06, 4.6129e-07, 1.8083e-07,
        2.0266e-06, 4.7804e-05, 3.2754e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,315][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0013, 0.0223, 0.0420, 0.0283, 0.0316, 0.1355, 0.1195, 0.1485, 0.0313,
        0.0373, 0.0474, 0.0683, 0.0572, 0.0843, 0.0505, 0.0947],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,316][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.5462, 0.0238, 0.0156, 0.0419, 0.0080, 0.0266, 0.0528, 0.0101, 0.0654,
        0.0066, 0.0473, 0.0527, 0.0059, 0.0614, 0.0160, 0.0197],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,318][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0975, 0.0589, 0.0612, 0.0640, 0.0561, 0.0568, 0.0573, 0.0607, 0.0543,
        0.0622, 0.0546, 0.0534, 0.0648, 0.0611, 0.0626, 0.0744],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,319][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.1045, 0.1474, 0.0422, 0.1120, 0.0304, 0.0807, 0.0774, 0.0406, 0.0508,
        0.0286, 0.0548, 0.0596, 0.0244, 0.0838, 0.0282, 0.0346],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,321][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1400, 0.0381, 0.0463, 0.0370, 0.0470, 0.0421, 0.0368, 0.0283, 0.0485,
        0.0465, 0.0659, 0.0583, 0.0671, 0.1117, 0.0958, 0.0907],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,322][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0125, 0.0308, 0.0706, 0.0004, 0.1249, 0.1242, 0.0031, 0.0216, 0.0054,
        0.1406, 0.0295, 0.0045, 0.2870, 0.0055, 0.0978, 0.0416],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,323][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([5.5193e-05, 4.1979e-05, 7.7768e-02, 3.1192e-03, 3.0240e-04, 5.3219e-03,
        6.9115e-08, 2.0064e-04, 2.2370e-03, 1.9442e-01, 2.2245e-03, 1.3158e-07,
        5.7041e-01, 8.6586e-04, 1.2461e-01, 1.8417e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,324][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1160, 0.0285, 0.0595, 0.0422, 0.0420, 0.0496, 0.0440, 0.0519, 0.0416,
        0.0925, 0.0474, 0.0712, 0.1271, 0.1139, 0.0379, 0.0348],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,326][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.4974, 0.2425, 0.0805, 0.0250, 0.0224, 0.0242, 0.0230, 0.0107, 0.0102,
        0.0084, 0.0062, 0.0162, 0.0059, 0.0033, 0.0128, 0.0112],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,327][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0085, 0.1855, 0.0384, 0.0131, 0.0194, 0.0977, 0.2878, 0.0015, 0.0334,
        0.0036, 0.0852, 0.0829, 0.0155, 0.0707, 0.0340, 0.0231],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,329][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0012, 0.0510, 0.0642, 0.0552, 0.0523, 0.0633, 0.0558, 0.0377, 0.0544,
        0.0614, 0.0846, 0.0744, 0.0783, 0.1201, 0.0691, 0.0772],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,330][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([2.1045e-05, 2.7523e-04, 9.4752e-05, 9.4120e-05, 1.1504e-05, 2.4148e-04,
        6.9129e-06, 2.5040e-04, 3.3958e-05, 8.6240e-05, 1.9831e-05, 1.4446e-05,
        4.4488e-05, 6.1645e-04, 4.0507e-05, 9.9815e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,331][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0008, 0.0118, 0.0479, 0.0199, 0.0220, 0.2115, 0.0552, 0.1786, 0.0283,
        0.0228, 0.0259, 0.0594, 0.0278, 0.0485, 0.0695, 0.1196, 0.0504],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,332][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.5224, 0.0252, 0.0187, 0.0393, 0.0092, 0.0255, 0.0453, 0.0109, 0.0569,
        0.0073, 0.0415, 0.0450, 0.0064, 0.0534, 0.0191, 0.0192, 0.0548],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,334][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0872, 0.0530, 0.0571, 0.0593, 0.0531, 0.0528, 0.0562, 0.0598, 0.0514,
        0.0618, 0.0511, 0.0518, 0.0614, 0.0577, 0.0597, 0.0684, 0.0583],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,335][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1029, 0.1440, 0.0409, 0.1067, 0.0293, 0.0785, 0.0740, 0.0398, 0.0482,
        0.0269, 0.0508, 0.0557, 0.0225, 0.0780, 0.0261, 0.0319, 0.0440],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,337][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1142, 0.0296, 0.0353, 0.0292, 0.0336, 0.0357, 0.0399, 0.0351, 0.0408,
        0.0549, 0.0580, 0.0679, 0.0746, 0.0931, 0.0833, 0.0846, 0.0903],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,338][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([6.2053e-03, 1.7809e-02, 4.4275e-02, 1.0185e-04, 2.2084e-01, 9.3274e-02,
        1.8638e-03, 4.0560e-02, 1.3267e-03, 1.7194e-01, 1.6820e-02, 3.2376e-03,
        1.1564e-01, 2.4487e-03, 2.4985e-01, 1.0598e-02, 3.2046e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,339][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([2.1505e-05, 1.6842e-05, 8.5917e-02, 1.6956e-04, 1.4128e-03, 4.6174e-03,
        5.5324e-08, 2.6043e-04, 6.4876e-04, 3.2664e-01, 5.4200e-04, 7.7138e-08,
        4.0351e-01, 3.0396e-04, 1.7098e-01, 4.9583e-03, 9.7165e-08],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,340][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1183, 0.0203, 0.0510, 0.0321, 0.0418, 0.0570, 0.0367, 0.0560, 0.0372,
        0.0582, 0.0416, 0.0704, 0.0982, 0.1243, 0.0289, 0.0679, 0.0601],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,342][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.4890, 0.2509, 0.0770, 0.0241, 0.0254, 0.0245, 0.0215, 0.0103, 0.0103,
        0.0080, 0.0064, 0.0152, 0.0056, 0.0029, 0.0107, 0.0104, 0.0080],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,342][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0133, 0.1975, 0.0458, 0.0186, 0.0261, 0.0768, 0.1521, 0.0026, 0.0345,
        0.0059, 0.0791, 0.0561, 0.0217, 0.0900, 0.0414, 0.0209, 0.1176],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,343][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0027, 0.0385, 0.0565, 0.0468, 0.0486, 0.0571, 0.0618, 0.0369, 0.0482,
        0.0562, 0.0744, 0.0728, 0.0697, 0.1108, 0.0640, 0.0774, 0.0776],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,343][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.5744e-06, 2.3528e-05, 1.7034e-05, 4.7426e-06, 8.0357e-06, 5.3991e-06,
        1.1593e-01, 2.2792e-06, 1.9999e-05, 1.3396e-05, 5.6887e-05, 2.7863e-04,
        2.8849e-06, 2.1653e-04, 6.0007e-04, 1.1898e-05, 8.8281e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,343][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.0003, 0.0119, 0.0376, 0.0190, 0.0232, 0.0855, 0.1551, 0.1069, 0.0273,
        0.0209, 0.0382, 0.0674, 0.0384, 0.0675, 0.0489, 0.0968, 0.1345, 0.0208],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,344][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([0.5684, 0.0166, 0.0092, 0.0317, 0.0048, 0.0220, 0.0450, 0.0070, 0.0597,
        0.0047, 0.0419, 0.0445, 0.0040, 0.0512, 0.0090, 0.0165, 0.0574, 0.0063],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,344][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([0.0872, 0.0530, 0.0535, 0.0562, 0.0499, 0.0509, 0.0514, 0.0530, 0.0475,
        0.0556, 0.0483, 0.0474, 0.0566, 0.0550, 0.0555, 0.0657, 0.0529, 0.0604],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,345][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([0.0975, 0.1396, 0.0408, 0.1043, 0.0267, 0.0761, 0.0720, 0.0386, 0.0480,
        0.0263, 0.0506, 0.0553, 0.0219, 0.0784, 0.0258, 0.0314, 0.0435, 0.0233],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,345][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([0.1130, 0.0321, 0.0407, 0.0295, 0.0371, 0.0328, 0.0316, 0.0242, 0.0401,
        0.0436, 0.0536, 0.0516, 0.0569, 0.0930, 0.0854, 0.0745, 0.0689, 0.0912],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,345][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([0.0055, 0.0060, 0.0725, 0.0009, 0.0248, 0.0086, 0.0117, 0.0144, 0.0043,
        0.0531, 0.0037, 0.0077, 0.0077, 0.0022, 0.0334, 0.0526, 0.0132, 0.6776],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,346][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([1.1507e-03, 1.1580e-03, 3.7057e-01, 1.1082e-02, 1.5685e-03, 1.5827e-02,
        3.2965e-04, 4.1725e-04, 1.3144e-02, 4.7181e-02, 3.8662e-02, 1.0634e-04,
        1.6721e-01, 3.3644e-03, 2.5371e-01, 2.9504e-02, 5.0623e-04, 4.4521e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,348][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([0.1791, 0.0391, 0.0328, 0.0398, 0.0357, 0.0271, 0.0572, 0.0435, 0.0382,
        0.1104, 0.0323, 0.0681, 0.0896, 0.0916, 0.0142, 0.0267, 0.0660, 0.0087],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,349][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([0.5135, 0.2434, 0.0672, 0.0217, 0.0161, 0.0200, 0.0206, 0.0095, 0.0094,
        0.0068, 0.0057, 0.0176, 0.0051, 0.0035, 0.0130, 0.0103, 0.0101, 0.0066],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,350][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([0.0083, 0.1639, 0.0231, 0.0132, 0.0140, 0.1020, 0.2422, 0.0015, 0.0401,
        0.0036, 0.0549, 0.0515, 0.0102, 0.0727, 0.0218, 0.0203, 0.1533, 0.0032],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,352][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([0.0021, 0.0381, 0.0535, 0.0432, 0.0437, 0.0520, 0.0513, 0.0328, 0.0494,
        0.0566, 0.0701, 0.0664, 0.0688, 0.1131, 0.0594, 0.0715, 0.0634, 0.0643],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,353][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([1.8923e-05, 9.8029e-05, 2.3157e-04, 1.8961e-05, 4.7526e-05, 1.2170e-05,
        1.5618e-06, 4.0737e-05, 2.6864e-05, 1.7861e-05, 2.5876e-06, 3.5685e-06,
        1.6415e-06, 4.9154e-05, 2.6514e-06, 8.1874e-06, 4.0657e-07, 9.9942e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,354][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0006, 0.0105, 0.0134, 0.0127, 0.0171, 0.2048, 0.0801, 0.1329, 0.0262,
        0.0312, 0.0264, 0.0377, 0.0293, 0.0418, 0.0160, 0.2224, 0.0710, 0.0216,
        0.0043], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,356][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.5063, 0.0233, 0.0175, 0.0362, 0.0085, 0.0236, 0.0433, 0.0100, 0.0531,
        0.0067, 0.0387, 0.0423, 0.0059, 0.0498, 0.0179, 0.0178, 0.0528, 0.0095,
        0.0369], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,357][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0767, 0.0467, 0.0516, 0.0514, 0.0492, 0.0480, 0.0495, 0.0526, 0.0456,
        0.0537, 0.0459, 0.0460, 0.0549, 0.0511, 0.0537, 0.0639, 0.0517, 0.0573,
        0.0504], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,359][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0937, 0.1372, 0.0381, 0.1010, 0.0268, 0.0751, 0.0700, 0.0371, 0.0457,
        0.0248, 0.0480, 0.0527, 0.0207, 0.0749, 0.0239, 0.0296, 0.0411, 0.0215,
        0.0379], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,360][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0954, 0.0237, 0.0316, 0.0227, 0.0340, 0.0305, 0.0297, 0.0235, 0.0349,
        0.0358, 0.0525, 0.0493, 0.0575, 0.0763, 0.0672, 0.0740, 0.0662, 0.0879,
        0.1074], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,361][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.0719e-03, 7.6350e-03, 7.6939e-02, 1.7861e-04, 2.3850e-01, 1.0214e-01,
        2.8296e-03, 1.1002e-02, 2.1394e-03, 4.8530e-02, 2.6036e-02, 3.6061e-03,
        1.0187e-01, 3.0452e-03, 2.5321e-01, 8.0367e-03, 4.7171e-03, 7.0733e-02,
        3.6786e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,362][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([5.3452e-04, 1.2638e-04, 4.1828e-02, 1.5325e-03, 1.7263e-03, 1.7410e-02,
        2.7026e-06, 1.6656e-04, 2.9865e-03, 1.3085e-01, 3.6598e-03, 8.1970e-07,
        5.0180e-01, 5.4770e-04, 5.9523e-02, 2.1800e-01, 4.2406e-06, 1.7131e-02,
        2.1664e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,364][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1061, 0.0198, 0.0477, 0.0317, 0.0315, 0.0491, 0.0337, 0.0327, 0.0329,
        0.0455, 0.0354, 0.0532, 0.0642, 0.1002, 0.0226, 0.0643, 0.0519, 0.1165,
        0.0610], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,365][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.4319, 0.2491, 0.0870, 0.0249, 0.0279, 0.0273, 0.0250, 0.0128, 0.0113,
        0.0098, 0.0072, 0.0169, 0.0064, 0.0027, 0.0125, 0.0115, 0.0085, 0.0072,
        0.0202], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,367][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0120, 0.1431, 0.0392, 0.0178, 0.0212, 0.0686, 0.1869, 0.0027, 0.0354,
        0.0049, 0.0784, 0.0575, 0.0134, 0.0752, 0.0367, 0.0167, 0.1387, 0.0066,
        0.0449], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,368][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0035, 0.0343, 0.0505, 0.0417, 0.0422, 0.0527, 0.0487, 0.0293, 0.0446,
        0.0466, 0.0671, 0.0604, 0.0571, 0.0944, 0.0549, 0.0681, 0.0599, 0.0607,
        0.0833], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,369][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([3.2894e-04, 2.2314e-03, 2.7247e-05, 4.4314e-03, 9.8011e-05, 1.0548e-03,
        5.5876e-03, 1.0228e-04, 3.5157e-03, 3.7871e-04, 1.6934e-02, 3.6788e-03,
        8.7519e-05, 6.8901e-03, 2.7386e-04, 6.3905e-04, 1.4746e-02, 5.5078e-06,
        9.3899e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,391][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:28,391][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,391][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,392][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,392][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,392][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,393][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,393][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,393][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,394][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,394][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,394][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,395][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,395][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.9925e-01, 7.4647e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,395][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.7226, 0.2774], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,396][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9987, 0.0013], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,397][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4183, 0.5817], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,398][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.7588, 0.2412], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,400][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4108, 0.5892], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,401][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9975, 0.0025], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,402][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9939, 0.0061], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,404][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.5668, 0.4332], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,405][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0561, 0.9439], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,406][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0237, 0.9763], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,408][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1792, 0.8208], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,409][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.4922, 0.2888, 0.2190], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,411][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.2547, 0.5118, 0.2334], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,412][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.8649, 0.0427, 0.0924], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,413][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.5384, 0.2301, 0.2315], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,415][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.5658, 0.3421, 0.0921], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,416][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.1630, 0.6772, 0.1597], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,417][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.5823, 0.1225, 0.2953], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,419][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.5201, 0.1663, 0.3136], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,420][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.4040, 0.4077, 0.1883], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,421][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.0164, 0.4225, 0.5611], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,423][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0258, 0.4240, 0.5502], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,424][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.0781, 0.4902, 0.4317], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,425][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1333, 0.0703, 0.7871, 0.0093], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,427][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.3402, 0.2784, 0.1554, 0.2261], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,428][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5129, 0.0235, 0.0792, 0.3844], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,429][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.4433, 0.1525, 0.2013, 0.2030], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,429][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.4814, 0.1907, 0.1218, 0.2060], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,429][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1109, 0.7986, 0.0217, 0.0688], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,429][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5424, 0.0142, 0.3812, 0.0622], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,430][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2677, 0.0252, 0.3525, 0.3547], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,430][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1857, 0.1688, 0.0108, 0.6348], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,430][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0631, 0.3989, 0.3221, 0.2158], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,431][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0167, 0.2813, 0.4821, 0.2198], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,431][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0535, 0.1476, 0.0022, 0.7966], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,431][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.0645, 0.0401, 0.8089, 0.0592, 0.0272], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,432][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([0.1716, 0.2608, 0.1410, 0.3124, 0.1142], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,432][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([0.3813, 0.0455, 0.0703, 0.4073, 0.0956], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,434][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([0.4806, 0.1147, 0.1287, 0.1474, 0.1286], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,435][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([0.3537, 0.2384, 0.0790, 0.2117, 0.1171], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,436][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.0789, 0.0911, 0.3902, 0.4101, 0.0297], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,438][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.4281, 0.1149, 0.2618, 0.1636, 0.0317], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,439][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.1872, 0.1157, 0.3244, 0.3449, 0.0278], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,440][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.0984, 0.2741, 0.0679, 0.5178, 0.0418], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,442][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.0146, 0.2838, 0.3187, 0.2938, 0.0891], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,443][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.0190, 0.2520, 0.3253, 0.2024, 0.2013], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,445][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.0431, 0.1724, 0.0114, 0.7649, 0.0082], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,446][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.8197, 0.0305, 0.0299, 0.0639, 0.0484, 0.0076], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,447][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.2044, 0.2101, 0.1162, 0.2114, 0.0794, 0.1785], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,449][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.3258, 0.0298, 0.0785, 0.2300, 0.1162, 0.2196], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,450][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.4130, 0.0939, 0.1107, 0.1112, 0.1210, 0.1501], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,452][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.3125, 0.1639, 0.0858, 0.1265, 0.1298, 0.1815], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,453][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0344, 0.7740, 0.0387, 0.0091, 0.0604, 0.0835], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,454][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.3861, 0.0449, 0.1743, 0.1472, 0.0061, 0.2415], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,456][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1525, 0.0423, 0.2707, 0.1900, 0.1874, 0.1571], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,457][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0681, 0.2341, 0.0277, 0.3559, 0.0103, 0.3040], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,458][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0552, 0.2918, 0.2364, 0.1263, 0.0859, 0.2045], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,460][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0089, 0.2064, 0.2796, 0.1387, 0.1751, 0.1913], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,461][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([3.3840e-02, 2.0531e-01, 5.5191e-03, 5.7265e-01, 5.6866e-04, 1.8211e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,462][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0185, 0.0154, 0.2453, 0.0091, 0.0510, 0.6460, 0.0146],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,463][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1230, 0.1574, 0.0902, 0.1782, 0.0635, 0.1763, 0.2113],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,465][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2944, 0.0221, 0.0549, 0.1697, 0.0903, 0.1423, 0.2263],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,465][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.4135, 0.0711, 0.0888, 0.0904, 0.0976, 0.1240, 0.1147],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,466][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.3277, 0.1221, 0.0528, 0.1123, 0.0912, 0.1358, 0.1582],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,466][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1143, 0.4475, 0.3097, 0.0147, 0.0352, 0.0540, 0.0246],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,466][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2461, 0.0456, 0.2763, 0.1409, 0.0893, 0.0947, 0.1070],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,467][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1173, 0.0461, 0.2059, 0.1516, 0.1085, 0.1281, 0.2425],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,467][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1293, 0.1084, 0.0081, 0.3173, 0.0076, 0.1179, 0.3114],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,467][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0543, 0.2597, 0.1777, 0.1003, 0.0722, 0.1635, 0.1724],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,468][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0108, 0.1582, 0.2707, 0.1215, 0.1681, 0.1507, 0.1201],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,468][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.8811e-02, 1.1675e-01, 3.8069e-03, 3.7556e-01, 3.2741e-04, 1.2139e-02,
        4.6261e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,469][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([3.2183e-02, 3.7834e-04, 6.0950e-03, 7.7294e-04, 3.6041e-03, 4.0743e-04,
        9.5639e-01, 1.7365e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,470][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.1243, 0.1212, 0.0764, 0.1417, 0.0570, 0.1533, 0.1876, 0.1386],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,471][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.2491, 0.0264, 0.0514, 0.1624, 0.0865, 0.1295, 0.1953, 0.0994],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,472][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.3971, 0.0582, 0.0774, 0.0820, 0.0870, 0.1073, 0.0971, 0.0939],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,474][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.2747, 0.1213, 0.0522, 0.1035, 0.0853, 0.1114, 0.0990, 0.1526],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,475][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0890, 0.6306, 0.0297, 0.0318, 0.0220, 0.0405, 0.0628, 0.0935],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,476][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.2707, 0.0509, 0.0839, 0.1601, 0.0021, 0.1059, 0.2319, 0.0943],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,477][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.1557, 0.0447, 0.1355, 0.1544, 0.0672, 0.1559, 0.2475, 0.0390],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,479][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0164, 0.1127, 0.0090, 0.2849, 0.0052, 0.0937, 0.4684, 0.0098],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,480][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0246, 0.2284, 0.2083, 0.1364, 0.0672, 0.1378, 0.1413, 0.0559],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,482][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0104, 0.1375, 0.2411, 0.1031, 0.1505, 0.1234, 0.1000, 0.1341],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,482][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([3.5142e-02, 1.8430e-01, 5.0920e-03, 5.9748e-01, 2.3092e-04, 2.0005e-02,
        4.3048e-02, 1.1471e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,483][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([1.1276e-03, 9.2492e-04, 2.9733e-01, 7.9326e-04, 6.9050e-02, 2.8934e-04,
        2.8737e-01, 3.4308e-01, 3.9069e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,485][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.1064, 0.1023, 0.0675, 0.1095, 0.0459, 0.1095, 0.1465, 0.1125, 0.1999],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,486][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.2355, 0.0174, 0.0452, 0.1242, 0.0797, 0.1118, 0.1483, 0.0618, 0.1762],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,488][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.4143, 0.0497, 0.0656, 0.0670, 0.0728, 0.0948, 0.0821, 0.0767, 0.0772],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,489][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.1918, 0.0971, 0.0598, 0.0886, 0.0879, 0.0988, 0.1124, 0.0838, 0.1797],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,490][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([8.6570e-04, 3.7681e-04, 1.3713e-04, 9.3907e-05, 1.5610e-04, 1.7838e-04,
        2.5196e-03, 2.6563e-04, 9.9541e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,491][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.2050, 0.0472, 0.0212, 0.1263, 0.0413, 0.0660, 0.1357, 0.2610, 0.0962],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,493][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.1591, 0.0744, 0.1377, 0.1234, 0.0916, 0.0558, 0.1708, 0.0524, 0.1348],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,494][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0451, 0.0575, 0.0070, 0.1452, 0.0064, 0.0884, 0.1613, 0.0156, 0.4734],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,496][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0586, 0.2422, 0.1474, 0.0694, 0.0603, 0.1364, 0.1516, 0.0724, 0.0617],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,497][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0091, 0.1311, 0.2159, 0.0990, 0.1322, 0.1307, 0.0858, 0.1327, 0.0635],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,498][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([1.1476e-02, 5.1796e-02, 7.9952e-04, 2.2287e-01, 1.4784e-04, 6.2124e-03,
        2.5084e-02, 1.6858e-03, 6.7993e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,500][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0085, 0.0027, 0.0188, 0.0146, 0.0082, 0.0590, 0.8089, 0.0247, 0.0392,
        0.0155], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,501][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0855, 0.0795, 0.0534, 0.0939, 0.0398, 0.0982, 0.1302, 0.1150, 0.2215,
        0.0829], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,502][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.1546, 0.0233, 0.0408, 0.1525, 0.0579, 0.0985, 0.1362, 0.0618, 0.2024,
        0.0718], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,502][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.4358, 0.0407, 0.0528, 0.0592, 0.0589, 0.0797, 0.0691, 0.0682, 0.0655,
        0.0702], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,502][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.1974, 0.1199, 0.0322, 0.0932, 0.0539, 0.1074, 0.0873, 0.1147, 0.1603,
        0.0337], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,503][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0943, 0.3041, 0.0531, 0.0471, 0.0164, 0.0425, 0.1143, 0.1027, 0.0547,
        0.1708], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,503][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0676, 0.0149, 0.0138, 0.0447, 0.0436, 0.0965, 0.0551, 0.2381, 0.0337,
        0.3921], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,503][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0780, 0.0488, 0.0379, 0.1500, 0.0536, 0.2311, 0.1584, 0.1322, 0.1051,
        0.0049], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,504][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0255, 0.0363, 0.0142, 0.1079, 0.0211, 0.0559, 0.0997, 0.0206, 0.6140,
        0.0049], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,504][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0102, 0.1740, 0.2100, 0.1689, 0.0555, 0.1335, 0.1160, 0.0408, 0.0500,
        0.0412], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,504][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0088, 0.1231, 0.1743, 0.0903, 0.1109, 0.1072, 0.0807, 0.1084, 0.0507,
        0.1455], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,505][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([1.5425e-02, 8.0125e-02, 3.8853e-03, 2.8972e-01, 8.3010e-05, 5.8608e-03,
        1.7554e-02, 3.8205e-03, 5.7592e-01, 7.6087e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,506][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0905, 0.1056, 0.1481, 0.0482, 0.1260, 0.0271, 0.1170, 0.2683, 0.0247,
        0.0366, 0.0080], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,507][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0609, 0.0569, 0.0408, 0.0713, 0.0296, 0.0829, 0.1054, 0.0907, 0.1701,
        0.0691, 0.2224], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,508][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1822, 0.0146, 0.0362, 0.0925, 0.0636, 0.0805, 0.1077, 0.0516, 0.1220,
        0.0541, 0.1952], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,510][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.4492, 0.0339, 0.0450, 0.0475, 0.0533, 0.0668, 0.0573, 0.0526, 0.0533,
        0.0599, 0.0813], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,511][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.1889, 0.0843, 0.0377, 0.0752, 0.0657, 0.0856, 0.0924, 0.1186, 0.1359,
        0.0415, 0.0742], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,512][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([5.5668e-04, 1.1479e-03, 1.9237e-04, 1.4980e-04, 5.4536e-04, 1.0108e-04,
        2.5413e-03, 5.4611e-04, 9.9086e-04, 4.0872e-04, 9.9282e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,513][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0495, 0.0110, 0.0238, 0.0489, 0.0095, 0.0752, 0.0414, 0.0127, 0.0820,
        0.6274, 0.0186], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,514][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0714, 0.0216, 0.1432, 0.1092, 0.1695, 0.1610, 0.0907, 0.0551, 0.0747,
        0.0461, 0.0574], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,516][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0642, 0.0533, 0.0092, 0.1106, 0.0098, 0.0880, 0.2215, 0.0225, 0.4027,
        0.0057, 0.0126], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,517][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0382, 0.1858, 0.1208, 0.0630, 0.0473, 0.1057, 0.1213, 0.0527, 0.0469,
        0.0610, 0.1573], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,518][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0087, 0.1022, 0.1670, 0.0793, 0.1002, 0.0945, 0.0680, 0.1095, 0.0434,
        0.1357, 0.0916], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,519][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([1.3865e-02, 8.4316e-02, 2.2212e-03, 2.8568e-01, 3.7281e-04, 8.8817e-03,
        1.1748e-02, 3.0248e-03, 3.8677e-01, 8.8823e-04, 2.0223e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,521][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0332, 0.0063, 0.0440, 0.0093, 0.0444, 0.0469, 0.1888, 0.0239, 0.0527,
        0.0046, 0.5341, 0.0119], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,522][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0508, 0.0476, 0.0350, 0.0605, 0.0247, 0.0682, 0.0866, 0.0729, 0.1398,
        0.0547, 0.2036, 0.1555], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,524][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1470, 0.0139, 0.0333, 0.0775, 0.0583, 0.0673, 0.0991, 0.0521, 0.0955,
        0.0545, 0.1424, 0.1591], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,525][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.4532, 0.0292, 0.0369, 0.0399, 0.0459, 0.0581, 0.0520, 0.0481, 0.0466,
        0.0531, 0.0699, 0.0671], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,527][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1846, 0.0717, 0.0333, 0.0560, 0.0557, 0.0828, 0.0783, 0.1277, 0.1094,
        0.0495, 0.0568, 0.0943], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,528][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0365, 0.3616, 0.0346, 0.0032, 0.0870, 0.0205, 0.0201, 0.0502, 0.1375,
        0.0140, 0.2251, 0.0097], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,529][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0923, 0.0085, 0.1429, 0.1029, 0.0639, 0.0811, 0.0488, 0.0827, 0.0743,
        0.1708, 0.1118, 0.0200], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,531][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0464, 0.0169, 0.1136, 0.0812, 0.0647, 0.0912, 0.1462, 0.0380, 0.0710,
        0.0543, 0.0677, 0.2088], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,532][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0550, 0.0376, 0.0046, 0.1131, 0.0048, 0.0406, 0.1169, 0.0134, 0.2811,
        0.0035, 0.0119, 0.3175], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,534][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0336, 0.1724, 0.1141, 0.0614, 0.0443, 0.0956, 0.1070, 0.0471, 0.0422,
        0.0547, 0.1289, 0.0987], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,535][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0080, 0.0906, 0.1550, 0.0703, 0.0996, 0.0904, 0.0704, 0.0996, 0.0383,
        0.1283, 0.0760, 0.0736], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,536][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([2.9462e-02, 8.3904e-02, 1.4061e-03, 2.6504e-01, 2.1893e-04, 6.3782e-03,
        3.6812e-02, 3.1738e-03, 4.2364e-01, 1.3781e-03, 1.1177e-02, 1.3740e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,537][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.0327, 0.0276, 0.0679, 0.0198, 0.0640, 0.0121, 0.1294, 0.0059, 0.0878,
        0.0205, 0.4027, 0.1259, 0.0035], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,539][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0321, 0.0346, 0.0269, 0.0477, 0.0211, 0.0549, 0.0776, 0.0654, 0.1206,
        0.0508, 0.2184, 0.1734, 0.0764], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,539][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.1205, 0.0156, 0.0336, 0.0928, 0.0450, 0.0695, 0.0970, 0.0414, 0.1127,
        0.0471, 0.1475, 0.1254, 0.0520], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,539][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.4144, 0.0271, 0.0340, 0.0395, 0.0431, 0.0552, 0.0470, 0.0483, 0.0451,
        0.0542, 0.0707, 0.0595, 0.0620], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,540][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.1391, 0.0934, 0.0304, 0.0714, 0.0486, 0.0816, 0.0642, 0.0927, 0.1157,
        0.0382, 0.0546, 0.0684, 0.1018], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,540][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.0169, 0.1335, 0.0030, 0.0075, 0.0013, 0.0154, 0.0658, 0.0116, 0.0660,
        0.0044, 0.3723, 0.1034, 0.1989], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,541][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.0215, 0.0257, 0.0738, 0.0763, 0.0018, 0.0347, 0.0322, 0.0186, 0.0496,
        0.0011, 0.0159, 0.0135, 0.6354], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,541][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0283, 0.0213, 0.1338, 0.0778, 0.0342, 0.2286, 0.1760, 0.0266, 0.0422,
        0.0229, 0.0882, 0.1175, 0.0026], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,541][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.0170, 0.0291, 0.0056, 0.0598, 0.0049, 0.0431, 0.1361, 0.0152, 0.3503,
        0.0037, 0.0185, 0.3139, 0.0028], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,542][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.0109, 0.1511, 0.1747, 0.1225, 0.0479, 0.1079, 0.0993, 0.0360, 0.0413,
        0.0373, 0.0529, 0.0679, 0.0505], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,543][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.0064, 0.0941, 0.1316, 0.0714, 0.0810, 0.0870, 0.0653, 0.0824, 0.0382,
        0.1161, 0.0748, 0.0587, 0.0928], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,544][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([1.6430e-02, 8.7260e-02, 2.8773e-03, 3.0875e-01, 1.8880e-04, 7.2649e-03,
        9.4877e-03, 4.2978e-03, 5.3459e-01, 9.9871e-04, 1.3629e-02, 1.2943e-02,
        1.2888e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,546][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0670, 0.0117, 0.1043, 0.0319, 0.3702, 0.0024, 0.2023, 0.0117, 0.0444,
        0.0167, 0.0835, 0.0480, 0.0053, 0.0009], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,547][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0499, 0.0376, 0.0292, 0.0471, 0.0203, 0.0505, 0.0679, 0.0564, 0.1024,
        0.0428, 0.1512, 0.1277, 0.0687, 0.1483], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,548][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1060, 0.0098, 0.0291, 0.0553, 0.0467, 0.0579, 0.0706, 0.0425, 0.0754,
        0.0462, 0.0994, 0.1056, 0.0586, 0.1969], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,550][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.4763, 0.0223, 0.0287, 0.0299, 0.0350, 0.0434, 0.0359, 0.0344, 0.0337,
        0.0387, 0.0509, 0.0411, 0.0455, 0.0841], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,551][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.1361, 0.0496, 0.0265, 0.0463, 0.0443, 0.0624, 0.0612, 0.0823, 0.1096,
        0.0392, 0.0457, 0.0699, 0.0795, 0.1472], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,553][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1146, 0.0798, 0.0750, 0.0141, 0.1765, 0.0661, 0.0450, 0.0450, 0.0497,
        0.0512, 0.0966, 0.0586, 0.0405, 0.0873], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,554][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0526, 0.0035, 0.3670, 0.0252, 0.0052, 0.0284, 0.0074, 0.0177, 0.0288,
        0.0361, 0.0239, 0.0063, 0.2711, 0.1268], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,555][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0336, 0.0082, 0.2045, 0.0853, 0.0545, 0.0524, 0.0583, 0.0691, 0.0781,
        0.0896, 0.0460, 0.0869, 0.0686, 0.0650], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,557][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0718, 0.0463, 0.0133, 0.0711, 0.0067, 0.0930, 0.1325, 0.0415, 0.2181,
        0.0136, 0.0066, 0.1922, 0.0023, 0.0909], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,558][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0283, 0.1521, 0.1100, 0.0599, 0.0402, 0.0858, 0.0910, 0.0408, 0.0380,
        0.0472, 0.1041, 0.0814, 0.0651, 0.0560], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,560][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0061, 0.0845, 0.1332, 0.0650, 0.0793, 0.0789, 0.0552, 0.0825, 0.0354,
        0.1114, 0.0757, 0.0530, 0.1055, 0.0344], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,561][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0252, 0.0626, 0.0029, 0.2068, 0.0005, 0.0105, 0.0229, 0.0035, 0.2362,
        0.0022, 0.0247, 0.0409, 0.0005, 0.3605], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,563][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.0365, 0.0174, 0.0096, 0.0223, 0.0365, 0.0730, 0.2442, 0.0018, 0.3299,
        0.0052, 0.0320, 0.1721, 0.0137, 0.0033, 0.0025], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,564][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0202, 0.0263, 0.0163, 0.0384, 0.0154, 0.0458, 0.0560, 0.0491, 0.0943,
        0.0383, 0.1457, 0.1340, 0.0668, 0.1732, 0.0801], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,565][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.0665, 0.0154, 0.0235, 0.0639, 0.0370, 0.0534, 0.0641, 0.0323, 0.0912,
        0.0388, 0.1151, 0.1049, 0.0465, 0.1971, 0.0503], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,567][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.4678, 0.0155, 0.0176, 0.0239, 0.0277, 0.0417, 0.0323, 0.0317, 0.0323,
        0.0348, 0.0511, 0.0447, 0.0452, 0.0918, 0.0420], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,568][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.1211, 0.0857, 0.0199, 0.0636, 0.0414, 0.0803, 0.0639, 0.0640, 0.1010,
        0.0306, 0.0495, 0.0601, 0.0599, 0.1311, 0.0279], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,570][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.0049, 0.1071, 0.0351, 0.0272, 0.1754, 0.0103, 0.0492, 0.0053, 0.0340,
        0.0156, 0.0472, 0.0631, 0.0316, 0.1973, 0.1967], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,571][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.0393, 0.0401, 0.0631, 0.0354, 0.0053, 0.0460, 0.0560, 0.0261, 0.0396,
        0.0051, 0.0544, 0.0809, 0.1067, 0.3774, 0.0245], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,573][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.0067, 0.0144, 0.0069, 0.0312, 0.0214, 0.1671, 0.1088, 0.0359, 0.0212,
        0.0217, 0.0162, 0.2315, 0.0461, 0.2690, 0.0020], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,574][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.0196, 0.0202, 0.0101, 0.0268, 0.0093, 0.0437, 0.0786, 0.0763, 0.4252,
        0.0136, 0.0136, 0.1371, 0.0159, 0.0953, 0.0146], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,575][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.0054, 0.1410, 0.1727, 0.1656, 0.0412, 0.0950, 0.1011, 0.0261, 0.0331,
        0.0209, 0.0265, 0.0574, 0.0301, 0.0532, 0.0306], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,576][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0073, 0.0757, 0.1045, 0.0627, 0.0735, 0.0734, 0.0539, 0.0739, 0.0348,
        0.1030, 0.0617, 0.0536, 0.0893, 0.0328, 0.0998], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,576][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([5.1954e-03, 3.4859e-02, 2.8156e-02, 1.0549e-01, 8.7529e-05, 2.4217e-03,
        4.9403e-03, 6.1145e-04, 2.3937e-01, 6.2403e-04, 3.1367e-03, 4.6692e-03,
        6.1878e-05, 5.5652e-01, 1.3856e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,577][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0840, 0.0951, 0.0809, 0.0423, 0.1281, 0.0251, 0.1430, 0.0332, 0.0427,
        0.0282, 0.1709, 0.0699, 0.0163, 0.0104, 0.0245, 0.0055],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,577][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0321, 0.0257, 0.0214, 0.0339, 0.0155, 0.0392, 0.0519, 0.0413, 0.0795,
        0.0337, 0.1271, 0.1113, 0.0531, 0.1443, 0.0770, 0.1129],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,577][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0863, 0.0155, 0.0285, 0.0591, 0.0414, 0.0484, 0.0558, 0.0326, 0.0744,
        0.0364, 0.0994, 0.0776, 0.0504, 0.1565, 0.0590, 0.0787],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,578][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.4753, 0.0179, 0.0212, 0.0234, 0.0265, 0.0357, 0.0280, 0.0265, 0.0283,
        0.0301, 0.0442, 0.0334, 0.0370, 0.0796, 0.0376, 0.0554],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,578][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0984, 0.0677, 0.0290, 0.0484, 0.0475, 0.0522, 0.0497, 0.0534, 0.0870,
        0.0261, 0.0516, 0.0617, 0.1007, 0.1275, 0.0462, 0.0529],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,579][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0498, 0.1120, 0.0307, 0.0096, 0.0327, 0.1012, 0.0719, 0.0133, 0.0610,
        0.0094, 0.0903, 0.0472, 0.2350, 0.0856, 0.0211, 0.0293],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,580][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0264, 0.0102, 0.0060, 0.0321, 0.0009, 0.0231, 0.0240, 0.0223, 0.0307,
        0.0372, 0.0325, 0.0143, 0.6045, 0.0564, 0.0038, 0.0755],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,581][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0266, 0.0344, 0.0833, 0.0742, 0.0385, 0.0349, 0.0724, 0.0472, 0.0647,
        0.0814, 0.0519, 0.1058, 0.1019, 0.1535, 0.0219, 0.0073],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,582][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0300, 0.0295, 0.0027, 0.0904, 0.0029, 0.0494, 0.0887, 0.0101, 0.2400,
        0.0019, 0.0108, 0.3373, 0.0015, 0.0999, 0.0037, 0.0012],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,584][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0188, 0.1319, 0.1118, 0.0613, 0.0354, 0.0799, 0.0794, 0.0333, 0.0326,
        0.0385, 0.0731, 0.0661, 0.0535, 0.0472, 0.0463, 0.0908],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,585][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0045, 0.0704, 0.1025, 0.0517, 0.0648, 0.0655, 0.0445, 0.0676, 0.0313,
        0.0859, 0.0664, 0.0434, 0.0931, 0.0283, 0.0974, 0.0827],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,586][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([1.2166e-02, 4.9174e-02, 2.4334e-03, 1.6854e-01, 8.4357e-05, 7.5708e-03,
        9.0601e-03, 1.6499e-03, 2.1336e-01, 9.7968e-04, 4.4016e-03, 5.9953e-03,
        1.0508e-04, 5.1547e-01, 1.3347e-03, 7.6706e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,588][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0070, 0.0128, 0.1284, 0.0067, 0.0277, 0.4654, 0.0067, 0.1006, 0.0268,
        0.0053, 0.0452, 0.0386, 0.0031, 0.0011, 0.0692, 0.0515, 0.0040],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,589][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0247, 0.0236, 0.0176, 0.0324, 0.0131, 0.0376, 0.0427, 0.0370, 0.0752,
        0.0292, 0.1123, 0.0967, 0.0458, 0.1195, 0.0600, 0.1110, 0.1218],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,591][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0791, 0.0130, 0.0252, 0.0403, 0.0390, 0.0425, 0.0614, 0.0347, 0.0536,
        0.0368, 0.0777, 0.0785, 0.0505, 0.1219, 0.0527, 0.0759, 0.1172],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,592][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.5002, 0.0147, 0.0170, 0.0188, 0.0216, 0.0299, 0.0268, 0.0232, 0.0231,
        0.0254, 0.0363, 0.0316, 0.0311, 0.0658, 0.0326, 0.0513, 0.0504],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,594][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1210, 0.0493, 0.0192, 0.0432, 0.0334, 0.0517, 0.0604, 0.0701, 0.0851,
        0.0303, 0.0414, 0.0674, 0.0732, 0.1144, 0.0307, 0.0425, 0.0668],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,595][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0204, 0.1029, 0.1482, 0.0024, 0.0169, 0.0536, 0.0097, 0.0196, 0.0686,
        0.0190, 0.1453, 0.0177, 0.0260, 0.0304, 0.2075, 0.1056, 0.0064],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,597][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0431, 0.0112, 0.0681, 0.0428, 0.0237, 0.0236, 0.0196, 0.0750, 0.0532,
        0.1052, 0.0467, 0.0124, 0.2960, 0.0746, 0.0261, 0.0611, 0.0176],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,598][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0269, 0.0310, 0.0767, 0.0597, 0.0382, 0.0433, 0.0754, 0.0678, 0.0660,
        0.0389, 0.0445, 0.1046, 0.0532, 0.1703, 0.0109, 0.0235, 0.0691],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,600][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0421, 0.0362, 0.0029, 0.0997, 0.0029, 0.0377, 0.0833, 0.0080, 0.1974,
        0.0018, 0.0067, 0.3122, 0.0010, 0.0779, 0.0036, 0.0013, 0.0853],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,601][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0262, 0.1294, 0.0795, 0.0399, 0.0310, 0.0623, 0.0716, 0.0317, 0.0271,
        0.0376, 0.0912, 0.0667, 0.0523, 0.0427, 0.0464, 0.0866, 0.0778],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,603][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0051, 0.0586, 0.1033, 0.0471, 0.0655, 0.0591, 0.0477, 0.0714, 0.0265,
        0.0865, 0.0520, 0.0449, 0.0804, 0.0256, 0.1014, 0.0804, 0.0444],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,603][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([8.8248e-03, 3.8104e-02, 1.3740e-03, 1.2338e-01, 1.0663e-04, 3.7713e-03,
        1.4517e-01, 1.8687e-03, 2.3109e-01, 8.2879e-04, 6.5643e-03, 2.2689e-02,
        8.8281e-05, 3.1094e-01, 8.3192e-04, 6.2104e-04, 1.0375e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,605][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([0.0581, 0.0130, 0.0193, 0.0160, 0.0153, 0.0051, 0.1198, 0.0024, 0.0869,
        0.0066, 0.4562, 0.1270, 0.0042, 0.0015, 0.0028, 0.0040, 0.0547, 0.0071],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,606][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([0.0252, 0.0175, 0.0160, 0.0237, 0.0112, 0.0302, 0.0385, 0.0320, 0.0639,
        0.0278, 0.0988, 0.0869, 0.0463, 0.1214, 0.0657, 0.1111, 0.1359, 0.0478],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,608][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([0.0602, 0.0139, 0.0231, 0.0443, 0.0352, 0.0448, 0.0498, 0.0302, 0.0616,
        0.0358, 0.0876, 0.0720, 0.0466, 0.1336, 0.0434, 0.0729, 0.0861, 0.0588],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,609][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([0.4882, 0.0117, 0.0147, 0.0165, 0.0197, 0.0271, 0.0208, 0.0210, 0.0216,
        0.0227, 0.0358, 0.0270, 0.0290, 0.0711, 0.0314, 0.0515, 0.0435, 0.0466],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,611][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([0.0959, 0.0747, 0.0216, 0.0580, 0.0346, 0.0614, 0.0489, 0.0410, 0.0849,
        0.0226, 0.0437, 0.0444, 0.0467, 0.1229, 0.0318, 0.0410, 0.0499, 0.0763],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,612][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([0.0131, 0.1287, 0.0293, 0.0109, 0.0252, 0.0089, 0.1003, 0.0410, 0.0662,
        0.0088, 0.0026, 0.0504, 0.0033, 0.0469, 0.0097, 0.0092, 0.0715, 0.3738],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,613][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([0.2337, 0.0223, 0.0562, 0.0850, 0.0016, 0.0770, 0.0571, 0.0397, 0.0154,
        0.0046, 0.0253, 0.0342, 0.0171, 0.0326, 0.0103, 0.1567, 0.0434, 0.0877],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,613][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([0.0527, 0.0518, 0.0396, 0.0724, 0.0365, 0.0156, 0.1164, 0.0349, 0.0569,
        0.1115, 0.0292, 0.1085, 0.0653, 0.1122, 0.0057, 0.0061, 0.0835, 0.0012],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,613][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([0.0286, 0.0294, 0.0133, 0.0823, 0.0093, 0.0322, 0.0414, 0.0220, 0.3311,
        0.0032, 0.0091, 0.1680, 0.0049, 0.1483, 0.0196, 0.0020, 0.0448, 0.0104],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,614][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([0.0088, 0.1312, 0.1435, 0.1106, 0.0388, 0.0821, 0.0761, 0.0281, 0.0310,
        0.0274, 0.0333, 0.0486, 0.0379, 0.0440, 0.0328, 0.0635, 0.0418, 0.0208],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,614][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([0.0060, 0.0632, 0.0915, 0.0489, 0.0570, 0.0597, 0.0429, 0.0560, 0.0307,
        0.0816, 0.0531, 0.0408, 0.0708, 0.0285, 0.0877, 0.0814, 0.0391, 0.0611],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,615][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([9.6518e-03, 3.5361e-02, 9.9018e-04, 1.4560e-01, 3.7498e-05, 2.4648e-03,
        3.3406e-03, 1.1634e-03, 2.4278e-01, 3.2584e-04, 2.7825e-03, 7.2001e-03,
        2.7213e-05, 5.4350e-01, 5.3919e-04, 1.0546e-04, 2.2955e-03, 1.8361e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,615][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([4.2109e-02, 1.1511e-02, 3.2713e-03, 1.0653e-03, 3.2999e-02, 1.7752e-01,
        3.3354e-02, 1.3545e-02, 6.0722e-02, 2.6885e-02, 1.2154e-01, 1.8297e-02,
        7.4215e-03, 4.9672e-04, 1.6670e-03, 4.1924e-01, 2.0348e-02, 8.0058e-03,
        9.7485e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,615][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0291, 0.0222, 0.0165, 0.0295, 0.0121, 0.0340, 0.0427, 0.0328, 0.0607,
        0.0243, 0.0964, 0.0771, 0.0368, 0.0995, 0.0470, 0.0851, 0.1076, 0.0353,
        0.1114], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,617][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0690, 0.0128, 0.0275, 0.0319, 0.0433, 0.0380, 0.0433, 0.0279, 0.0478,
        0.0299, 0.0611, 0.0608, 0.0409, 0.0919, 0.0492, 0.0749, 0.0767, 0.0550,
        0.1182], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,618][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.5335, 0.0111, 0.0127, 0.0138, 0.0167, 0.0231, 0.0189, 0.0164, 0.0178,
        0.0187, 0.0287, 0.0224, 0.0236, 0.0510, 0.0241, 0.0395, 0.0367, 0.0395,
        0.0519], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,620][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1016, 0.0354, 0.0200, 0.0315, 0.0392, 0.0443, 0.0512, 0.0581, 0.0755,
        0.0195, 0.0361, 0.0562, 0.0719, 0.0929, 0.0342, 0.0459, 0.0572, 0.0670,
        0.0624], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,621][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([4.1787e-04, 1.5064e-04, 7.4898e-03, 5.8274e-05, 4.4253e-03, 4.3282e-04,
        7.1878e-04, 1.2960e-05, 5.7797e-04, 9.7523e-05, 1.8389e-03, 8.1754e-04,
        1.2377e-04, 4.2796e-04, 3.3666e-03, 2.3630e-04, 8.4895e-04, 3.0003e-03,
        9.7496e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,622][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0733, 0.0071, 0.0046, 0.0510, 0.0046, 0.0228, 0.0411, 0.0424, 0.0429,
        0.0439, 0.0548, 0.0120, 0.1545, 0.0715, 0.0019, 0.3063, 0.0392, 0.0154,
        0.0106], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,623][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0274, 0.0279, 0.0735, 0.0723, 0.0278, 0.0394, 0.0860, 0.0290, 0.0708,
        0.0283, 0.0430, 0.0786, 0.0286, 0.1419, 0.0082, 0.0255, 0.0727, 0.0559,
        0.0634], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,625][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0324, 0.0253, 0.0037, 0.0482, 0.0053, 0.0471, 0.0768, 0.0092, 0.2422,
        0.0028, 0.0112, 0.1851, 0.0013, 0.0672, 0.0048, 0.0013, 0.0808, 0.0164,
        0.1389], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,626][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0233, 0.1217, 0.0787, 0.0415, 0.0296, 0.0605, 0.0672, 0.0293, 0.0260,
        0.0342, 0.0802, 0.0605, 0.0466, 0.0399, 0.0418, 0.0785, 0.0678, 0.0234,
        0.0493], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,628][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0045, 0.0569, 0.0940, 0.0417, 0.0603, 0.0555, 0.0401, 0.0580, 0.0257,
        0.0730, 0.0548, 0.0381, 0.0717, 0.0234, 0.0903, 0.0729, 0.0373, 0.0650,
        0.0366], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,629][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.0044e-02, 4.0871e-02, 9.3792e-04, 1.5856e-01, 1.2470e-04, 3.9510e-03,
        1.1227e-02, 1.0562e-03, 2.2325e-01, 5.4589e-04, 1.1388e-02, 1.1568e-02,
        8.8259e-05, 3.3630e-01, 6.3767e-04, 4.1430e-04, 8.2604e-03, 2.1605e-04,
        1.8057e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,630][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:28,631][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[23395],
        [ 8503],
        [ 6847],
        [21055],
        [    6],
        [39521],
        [26624],
        [22405],
        [31821],
        [40009],
        [40126],
        [32064],
        [39885],
        [26955],
        [17951],
        [38629],
        [36635],
        [10722],
        [38158]], device='cuda:0')
[2024-07-24 10:27:28,633][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[22254],
        [ 1626],
        [ 2468],
        [13036],
        [    1],
        [25496],
        [16517],
        [ 9456],
        [14047],
        [24811],
        [25395],
        [15445],
        [ 2552],
        [10561],
        [ 5119],
        [11430],
        [14406],
        [ 3492],
        [11261]], device='cuda:0')
[2024-07-24 10:27:28,634][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[11251],
        [12662],
        [ 7450],
        [ 7568],
        [ 6509],
        [ 6748],
        [ 7243],
        [17612],
        [24810],
        [18913],
        [19942],
        [14945],
        [14935],
        [13610],
        [10503],
        [10928],
        [10424],
        [11698],
        [ 9873]], device='cuda:0')
[2024-07-24 10:27:28,636][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[39687],
        [39438],
        [39232],
        [38452],
        [38723],
        [38533],
        [38537],
        [38773],
        [37749],
        [38170],
        [37210],
        [37132],
        [37589],
        [36648],
        [35990],
        [36040],
        [35929],
        [36475],
        [35607]], device='cuda:0')
[2024-07-24 10:27:28,637][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[49115],
        [49379],
        [49442],
        [49505],
        [49580],
        [49551],
        [49572],
        [49533],
        [49551],
        [49550],
        [49571],
        [49549],
        [49496],
        [49525],
        [49540],
        [49513],
        [49512],
        [49555],
        [49543]], device='cuda:0')
[2024-07-24 10:27:28,639][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 955],
        [ 541],
        [ 597],
        [1087],
        [1108],
        [1319],
        [1554],
        [1804],
        [1970],
        [2057],
        [2151],
        [2300],
        [2346],
        [2427],
        [2416],
        [2402],
        [2352],
        [2353],
        [2326]], device='cuda:0')
[2024-07-24 10:27:28,640][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[25556],
        [26808],
        [30218],
        [26646],
        [26126],
        [28229],
        [29272],
        [33483],
        [28740],
        [33918],
        [32116],
        [32680],
        [31507],
        [28528],
        [28479],
        [27157],
        [29518],
        [32054],
        [28293]], device='cuda:0')
[2024-07-24 10:27:28,641][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[42219],
        [29917],
        [27285],
        [31949],
        [29778],
        [40254],
        [40273],
        [38726],
        [40181],
        [35178],
        [39127],
        [39676],
        [34913],
        [39870],
        [34856],
        [35917],
        [36388],
        [41339],
        [37714]], device='cuda:0')
[2024-07-24 10:27:28,643][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[24551],
        [29076],
        [34111],
        [34082],
        [35389],
        [33881],
        [33726],
        [34313],
        [34649],
        [47730],
        [48489],
        [49044],
        [49158],
        [45710],
        [42830],
        [48990],
        [48878],
        [42660],
        [48815]], device='cuda:0')
[2024-07-24 10:27:28,644][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[20471],
        [19579],
        [ 1857],
        [ 4543],
        [ 1850],
        [  119],
        [  449],
        [ 1049],
        [  463],
        [ 1332],
        [  188],
        [ 1192],
        [ 2310],
        [ 1085],
        [ 2482],
        [ 1565],
        [ 1873],
        [ 2655],
        [ 4439]], device='cuda:0')
[2024-07-24 10:27:28,646][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[30346],
        [33809],
        [33135],
        [32664],
        [32862],
        [31982],
        [31565],
        [31228],
        [31002],
        [30833],
        [30691],
        [30269],
        [30373],
        [30066],
        [29942],
        [29899],
        [29923],
        [29935],
        [29148]], device='cuda:0')
[2024-07-24 10:27:28,647][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[47241],
        [46430],
        [46852],
        [47245],
        [47468],
        [48656],
        [48445],
        [48705],
        [48187],
        [48432],
        [48585],
        [48392],
        [47810],
        [47915],
        [47992],
        [47978],
        [47906],
        [47507],
        [47865]], device='cuda:0')
[2024-07-24 10:27:28,649][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[5678],
        [2246],
        [3371],
        [3159],
        [2747],
        [3373],
        [2825],
        [2679],
        [3174],
        [2988],
        [2622],
        [2578],
        [2566],
        [2716],
        [3084],
        [3158],
        [2896],
        [3221],
        [3278]], device='cuda:0')
[2024-07-24 10:27:28,650][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[34415],
        [28252],
        [48531],
        [ 7673],
        [45699],
        [ 6607],
        [12896],
        [41169],
        [ 8795],
        [36115],
        [17184],
        [14406],
        [45792],
        [33309],
        [48895],
        [28581],
        [11783],
        [ 9993],
        [ 6433]], device='cuda:0')
[2024-07-24 10:27:28,652][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[12261],
        [ 3577],
        [ 3124],
        [11378],
        [ 2711],
        [40438],
        [17851],
        [ 7810],
        [14070],
        [ 9771],
        [15591],
        [12956],
        [41045],
        [ 9619],
        [ 9709],
        [31713],
        [17820],
        [10903],
        [11498]], device='cuda:0')
[2024-07-24 10:27:28,653][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[42170],
        [42171],
        [45214],
        [41811],
        [39617],
        [44071],
        [44038],
        [33763],
        [45516],
        [36118],
        [45466],
        [13343],
        [17319],
        [47279],
        [31995],
        [41190],
        [43755],
        [13627],
        [36123]], device='cuda:0')
[2024-07-24 10:27:28,654][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[1172],
        [1355],
        [ 896],
        [ 751],
        [ 666],
        [ 726],
        [ 901],
        [ 994],
        [1018],
        [1101],
        [1197],
        [1200],
        [1331],
        [1432],
        [1538],
        [1527],
        [1612],
        [1706],
        [1684]], device='cuda:0')
[2024-07-24 10:27:28,655][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[18507],
        [18463],
        [15830],
        [15126],
        [15037],
        [16240],
        [14544],
        [14941],
        [15420],
        [14989],
        [14318],
        [14521],
        [14826],
        [14947],
        [14737],
        [15149],
        [14695],
        [14489],
        [14290]], device='cuda:0')
[2024-07-24 10:27:28,656][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[12715],
        [ 7441],
        [ 7132],
        [ 6250],
        [ 6541],
        [ 6387],
        [ 6298],
        [ 5996],
        [ 5957],
        [ 5990],
        [ 5954],
        [ 5859],
        [ 5609],
        [ 5619],
        [ 5486],
        [ 5519],
        [ 5528],
        [ 5438],
        [ 5476]], device='cuda:0')
[2024-07-24 10:27:28,658][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[28715],
        [24065],
        [20561],
        [16499],
        [15051],
        [15122],
        [16654],
        [16668],
        [15090],
        [14913],
        [15584],
        [16784],
        [16006],
        [13542],
        [12955],
        [12959],
        [14136],
        [12238],
        [13650]], device='cuda:0')
[2024-07-24 10:27:28,659][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 8205],
        [33548],
        [32895],
        [34281],
        [18156],
        [34344],
        [33747],
        [43810],
        [26762],
        [45102],
        [28302],
        [46602],
        [20705],
        [18977],
        [15606],
        [24377],
        [34936],
        [ 2458],
        [16271]], device='cuda:0')
[2024-07-24 10:27:28,660][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[27364],
        [27330],
        [11622],
        [10209],
        [15689],
        [21966],
        [13206],
        [29321],
        [36044],
        [25785],
        [16336],
        [22933],
        [21491],
        [ 5233],
        [21524],
        [23163],
        [20247],
        [22806],
        [24132]], device='cuda:0')
[2024-07-24 10:27:28,662][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[14248],
        [14030],
        [41439],
        [30706],
        [31895],
        [42622],
        [39962],
        [36665],
        [41300],
        [38926],
        [44209],
        [38906],
        [37251],
        [43759],
        [16632],
        [34068],
        [32511],
        [27572],
        [30483]], device='cuda:0')
[2024-07-24 10:27:28,664][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[20189],
        [25733],
        [21922],
        [28509],
        [24391],
        [33157],
        [34447],
        [33567],
        [20942],
        [16019],
        [22949],
        [29702],
        [27312],
        [30270],
        [19985],
        [31942],
        [33102],
        [23988],
        [27069]], device='cuda:0')
[2024-07-24 10:27:28,665][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[33490],
        [46534],
        [45959],
        [46826],
        [47149],
        [47242],
        [47740],
        [47724],
        [47769],
        [47830],
        [47865],
        [47967],
        [47942],
        [47968],
        [47983],
        [47896],
        [47932],
        [47917],
        [47932]], device='cuda:0')
[2024-07-24 10:27:28,667][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[17718],
        [11001],
        [12791],
        [13044],
        [13604],
        [14071],
        [13688],
        [13920],
        [13545],
        [14086],
        [14340],
        [13992],
        [14427],
        [14290],
        [14046],
        [14413],
        [14175],
        [14189],
        [14131]], device='cuda:0')
[2024-07-24 10:27:28,668][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[31564],
        [36361],
        [27052],
        [34951],
        [34763],
        [31926],
        [25227],
        [32005],
        [31724],
        [32195],
        [29170],
        [29409],
        [32091],
        [33884],
        [35439],
        [35561],
        [30063],
        [35790],
        [33888]], device='cuda:0')
[2024-07-24 10:27:28,669][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[22236],
        [17218],
        [18249],
        [22572],
        [22378],
        [14575],
        [18222],
        [12463],
        [ 7268],
        [11943],
        [13253],
        [15119],
        [21819],
        [16867],
        [22710],
        [14289],
        [12746],
        [27750],
        [15228]], device='cuda:0')
[2024-07-24 10:27:28,671][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[12943],
        [35271],
        [32930],
        [28972],
        [37665],
        [ 3072],
        [22497],
        [36797],
        [32457],
        [38880],
        [26644],
        [37762],
        [12805],
        [36949],
        [41065],
        [12467],
        [28131],
        [41472],
        [41598]], device='cuda:0')
[2024-07-24 10:27:28,672][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813]], device='cuda:0')
[2024-07-24 10:27:28,700][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:28,701][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,702][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,703][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,704][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,705][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,705][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,706][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,706][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,706][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,707][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,707][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,707][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,708][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6840, 0.3160], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,708][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9932, 0.0068], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,708][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3536, 0.6464], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,710][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5594, 0.4406], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,711][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6151, 0.3849], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,712][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0596, 0.9404], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,714][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.6365, 0.3635], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,715][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.6689, 0.3311], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,716][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1159, 0.8841], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,718][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7249, 0.2751], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,719][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9149, 0.0851], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,720][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4937, 0.5063], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,722][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.4714, 0.3193, 0.2094], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,723][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.3349, 0.4024, 0.2627], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,725][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.1584, 0.3935, 0.4481], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,726][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.1779, 0.1709, 0.6511], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,727][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.2761, 0.6299, 0.0940], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,729][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0142, 0.4027, 0.5831], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,730][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.3192, 0.2196, 0.4612], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,732][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.4119, 0.3254, 0.2627], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,733][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.0024, 0.2025, 0.7950], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,734][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.4504, 0.2129, 0.3367], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,735][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.7558, 0.1090, 0.1353], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,737][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.2692, 0.2806, 0.4502], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:28,738][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1419, 0.3081, 0.4202, 0.1298], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,739][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.8869, 0.0702, 0.0216, 0.0213], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,741][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0593, 0.1324, 0.6151, 0.1931], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,742][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1565, 0.1362, 0.5082, 0.1990], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,743][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1771, 0.5607, 0.0681, 0.1942], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,743][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0088, 0.1143, 0.4218, 0.4552], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,744][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1978, 0.1214, 0.2559, 0.4249], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,744][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3628, 0.2314, 0.2010, 0.2048], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,744][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0015, 0.0898, 0.4364, 0.4723], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,745][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3544, 0.1046, 0.2801, 0.2609], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,745][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.7571, 0.0783, 0.0938, 0.0708], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,745][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2116, 0.2312, 0.3473, 0.2099], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:28,746][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.1313, 0.1180, 0.3595, 0.2254, 0.1658], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,747][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([0.6159, 0.0240, 0.0076, 0.3494, 0.0031], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,748][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.0606, 0.1126, 0.3157, 0.3342, 0.1769], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,749][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.0927, 0.0813, 0.3783, 0.1955, 0.2521], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,750][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.0878, 0.3651, 0.0687, 0.3546, 0.1238], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,752][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([0.0036, 0.0845, 0.2736, 0.4653, 0.1730], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,753][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.1042, 0.0777, 0.1581, 0.3056, 0.3544], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,754][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.2810, 0.1927, 0.1764, 0.1777, 0.1722], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,755][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.0007, 0.0254, 0.1655, 0.3966, 0.4118], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,757][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.1907, 0.1055, 0.2294, 0.2793, 0.1951], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,758][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.5419, 0.1079, 0.1388, 0.1084, 0.1031], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,759][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([0.1521, 0.1608, 0.2616, 0.1621, 0.2633], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:28,761][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0486, 0.1295, 0.4268, 0.1509, 0.2311, 0.0131], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,762][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.7082, 0.0553, 0.0311, 0.1320, 0.0209, 0.0525], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,764][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0302, 0.0938, 0.2813, 0.2195, 0.2512, 0.1240], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,765][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0736, 0.0576, 0.2563, 0.1391, 0.2711, 0.2024], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,766][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1850, 0.2468, 0.0287, 0.3443, 0.0652, 0.1300], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,768][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0014, 0.0445, 0.2221, 0.3152, 0.3384, 0.0784], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,769][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0883, 0.0618, 0.1218, 0.2423, 0.2498, 0.2360], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,771][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.2737, 0.1603, 0.1316, 0.1362, 0.1359, 0.1623], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,772][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ had] are: tensor([2.1125e-04, 1.9717e-02, 8.2514e-02, 2.3003e-01, 2.1780e-01, 4.4973e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,773][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.1164, 0.0415, 0.1476, 0.2197, 0.2991, 0.1757], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,775][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.6729, 0.0636, 0.0773, 0.0580, 0.0540, 0.0742], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,776][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1341, 0.1534, 0.2349, 0.1279, 0.2207, 0.1290], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:28,778][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0639, 0.1020, 0.1291, 0.4283, 0.1768, 0.0432, 0.0567],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,779][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.4722, 0.0380, 0.0690, 0.1919, 0.1334, 0.0588, 0.0368],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,780][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0381, 0.0700, 0.1448, 0.1980, 0.1997, 0.3080, 0.0414],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,780][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0466, 0.0395, 0.1622, 0.0791, 0.1877, 0.1593, 0.3256],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,780][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1433, 0.1931, 0.0908, 0.2290, 0.0798, 0.1654, 0.0985],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,781][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0016, 0.0319, 0.1309, 0.1746, 0.2133, 0.0773, 0.3703],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,781][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0729, 0.0513, 0.1005, 0.1866, 0.1964, 0.1872, 0.2050],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,781][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2409, 0.1306, 0.1119, 0.1181, 0.1186, 0.1382, 0.1417],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,782][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([5.4510e-05, 2.7144e-03, 2.4165e-02, 5.6795e-02, 1.8757e-01, 5.7425e-01,
        1.5445e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,782][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1049, 0.0356, 0.1096, 0.1241, 0.2127, 0.1558, 0.2573],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,783][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.6357, 0.0589, 0.0702, 0.0545, 0.0500, 0.0655, 0.0652],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,784][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1226, 0.1301, 0.1839, 0.1305, 0.1978, 0.1297, 0.1054],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:28,785][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0512, 0.1129, 0.1430, 0.3326, 0.1606, 0.0519, 0.0480, 0.0998],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,787][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.8200, 0.0145, 0.0192, 0.0581, 0.0033, 0.0014, 0.0503, 0.0333],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,788][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0130, 0.0418, 0.1471, 0.1086, 0.1773, 0.1769, 0.1326, 0.2028],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,789][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0402, 0.0313, 0.1271, 0.0700, 0.1069, 0.0994, 0.2437, 0.2815],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,791][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0700, 0.1627, 0.0141, 0.1628, 0.0419, 0.1187, 0.2319, 0.1979],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,792][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0008, 0.0193, 0.0761, 0.1424, 0.0878, 0.0503, 0.3351, 0.2882],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,794][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0673, 0.0452, 0.0837, 0.1625, 0.1656, 0.1615, 0.1790, 0.1352],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,795][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.1719, 0.1282, 0.1119, 0.1084, 0.1091, 0.1256, 0.1265, 0.1183],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,796][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([4.4481e-05, 1.9463e-03, 1.0904e-02, 3.7557e-02, 1.3532e-01, 5.1945e-01,
        1.6349e-01, 1.3128e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,797][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0809, 0.0319, 0.0842, 0.1319, 0.1833, 0.1178, 0.2573, 0.1127],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,799][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.6830, 0.0424, 0.0440, 0.0331, 0.0299, 0.0444, 0.0454, 0.0778],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,800][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.1061, 0.1068, 0.1692, 0.0982, 0.1725, 0.1033, 0.0855, 0.1585],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:28,802][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0358, 0.0634, 0.2287, 0.0899, 0.2265, 0.0172, 0.0651, 0.2193, 0.0542],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,803][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.4792, 0.0024, 0.0009, 0.1325, 0.0037, 0.0007, 0.3367, 0.0142, 0.0297],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,804][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0113, 0.0212, 0.0843, 0.0592, 0.0971, 0.1200, 0.0556, 0.5277, 0.0235],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,806][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0293, 0.0242, 0.0892, 0.0510, 0.0825, 0.0880, 0.1856, 0.2538, 0.1963],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,807][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0098, 0.0335, 0.0239, 0.0444, 0.0495, 0.0195, 0.0494, 0.7548, 0.0153],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,809][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0008, 0.0106, 0.0369, 0.0613, 0.0725, 0.0308, 0.1701, 0.1534, 0.4636],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,810][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0638, 0.0481, 0.0759, 0.1395, 0.1399, 0.1371, 0.1434, 0.1229, 0.1294],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,812][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.1796, 0.0968, 0.0913, 0.0959, 0.0954, 0.1104, 0.1100, 0.1061, 0.1146],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,813][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ of] are: tensor([5.4839e-05, 9.1435e-04, 1.3888e-02, 1.6430e-02, 5.8811e-02, 1.9747e-01,
        9.7792e-02, 1.3984e-01, 4.7481e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,814][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0798, 0.0259, 0.0724, 0.0959, 0.1427, 0.1020, 0.1917, 0.1053, 0.1843],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,816][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.6813, 0.0366, 0.0398, 0.0291, 0.0263, 0.0398, 0.0405, 0.0705, 0.0360],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,816][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0898, 0.0978, 0.1505, 0.0975, 0.1462, 0.0985, 0.0816, 0.1326, 0.1055],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:28,817][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0552, 0.0879, 0.0530, 0.1087, 0.0975, 0.0366, 0.0348, 0.0770, 0.4193,
        0.0299], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,817][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.1158, 0.0200, 0.0300, 0.4037, 0.0048, 0.0019, 0.3670, 0.0168, 0.0210,
        0.0190], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,818][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0125, 0.0250, 0.0734, 0.0704, 0.1192, 0.1801, 0.0654, 0.2407, 0.1446,
        0.0687], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,818][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0237, 0.0189, 0.0781, 0.0408, 0.0602, 0.0618, 0.1346, 0.1809, 0.1627,
        0.2383], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,819][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0254, 0.0807, 0.0052, 0.0553, 0.0258, 0.2312, 0.1052, 0.4078, 0.0442,
        0.0193], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,819][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([4.3738e-04, 1.0959e-02, 3.1344e-02, 4.7379e-02, 3.7010e-02, 2.9369e-02,
        1.3519e-01, 1.5810e-01, 5.0102e-01, 4.9196e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,819][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0504, 0.0319, 0.0636, 0.1252, 0.1280, 0.1255, 0.1412, 0.1032, 0.1537,
        0.0773], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,820][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.1478, 0.1046, 0.0861, 0.0875, 0.0843, 0.1030, 0.1040, 0.0920, 0.1057,
        0.0851], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,821][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([6.1940e-06, 1.9224e-04, 1.3762e-03, 2.5133e-03, 1.8560e-02, 2.4308e-01,
        4.6762e-02, 6.0482e-02, 3.8231e-01, 2.4471e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,822][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0395, 0.0205, 0.0462, 0.0864, 0.0951, 0.0764, 0.1569, 0.0742, 0.1484,
        0.2564], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,823][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.6694, 0.0296, 0.0311, 0.0219, 0.0201, 0.0317, 0.0318, 0.0590, 0.0290,
        0.0766], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,825][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0777, 0.0852, 0.1257, 0.0805, 0.1309, 0.0834, 0.0683, 0.1240, 0.0910,
        0.1334], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:28,826][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0269, 0.0603, 0.1764, 0.0886, 0.2991, 0.0303, 0.0571, 0.0555, 0.1107,
        0.0494, 0.0458], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,827][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0817, 0.0745, 0.0394, 0.1034, 0.1255, 0.0364, 0.1182, 0.3358, 0.0297,
        0.0485, 0.0069], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,829][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0119, 0.0355, 0.0890, 0.0732, 0.1022, 0.1373, 0.0671, 0.2445, 0.0986,
        0.1133, 0.0272], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,830][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0226, 0.0175, 0.0550, 0.0313, 0.0507, 0.0625, 0.1112, 0.1712, 0.1249,
        0.1911, 0.1622], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,832][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0366, 0.1243, 0.0165, 0.1486, 0.0232, 0.0626, 0.1473, 0.2481, 0.1010,
        0.0422, 0.0496], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,833][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0011, 0.0158, 0.0297, 0.0446, 0.0404, 0.0421, 0.1314, 0.1370, 0.3543,
        0.0468, 0.1568], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,835][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0638, 0.0373, 0.0677, 0.1237, 0.1256, 0.1067, 0.1198, 0.0899, 0.1075,
        0.0685, 0.0894], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,836][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.1550, 0.0891, 0.0737, 0.0784, 0.0758, 0.0926, 0.0942, 0.0843, 0.0994,
        0.0772, 0.0803], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,837][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ at] are: tensor([1.1489e-05, 9.1734e-05, 4.8219e-04, 1.2825e-03, 5.7946e-03, 1.5136e-02,
        1.9797e-02, 3.0412e-02, 1.4634e-01, 2.5574e-01, 5.2491e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,839][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0625, 0.0168, 0.0397, 0.0566, 0.0896, 0.0581, 0.1077, 0.0638, 0.1041,
        0.2495, 0.1514], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,840][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.6858, 0.0230, 0.0244, 0.0167, 0.0152, 0.0251, 0.0254, 0.0479, 0.0226,
        0.0619, 0.0519], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,842][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0727, 0.0737, 0.1159, 0.0756, 0.1219, 0.0740, 0.0637, 0.1124, 0.0817,
        0.1269, 0.0814], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:28,843][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0196, 0.0272, 0.0457, 0.1063, 0.0622, 0.0194, 0.0206, 0.0951, 0.2316,
        0.0766, 0.2674, 0.0283], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,844][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.2664, 0.0097, 0.0224, 0.1540, 0.1403, 0.0249, 0.0446, 0.1888, 0.0668,
        0.0314, 0.0026, 0.0479], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,846][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0110, 0.0248, 0.0565, 0.0729, 0.1037, 0.1431, 0.0380, 0.2441, 0.1079,
        0.1098, 0.0699, 0.0184], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,847][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0179, 0.0152, 0.0488, 0.0268, 0.0455, 0.0535, 0.0973, 0.1492, 0.1108,
        0.1681, 0.1471, 0.1198], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,849][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0874, 0.1377, 0.0201, 0.1429, 0.0574, 0.0729, 0.1039, 0.1328, 0.0469,
        0.0555, 0.0831, 0.0593], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,850][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0004, 0.0067, 0.0234, 0.0286, 0.0347, 0.0195, 0.0766, 0.1118, 0.2951,
        0.0409, 0.1829, 0.1792], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,852][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0417, 0.0304, 0.0564, 0.1014, 0.1088, 0.0971, 0.1069, 0.0885, 0.0995,
        0.0749, 0.0885, 0.1059], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,853][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1542, 0.0754, 0.0648, 0.0693, 0.0695, 0.0819, 0.0838, 0.0784, 0.0906,
        0.0711, 0.0713, 0.0897], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,854][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ the] are: tensor([2.3609e-06, 2.2190e-05, 1.8669e-04, 2.6293e-04, 1.1856e-03, 2.8375e-03,
        2.5539e-03, 6.4510e-03, 2.5267e-02, 1.6649e-01, 5.1182e-01, 2.8292e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,854][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0481, 0.0138, 0.0342, 0.0416, 0.0733, 0.0481, 0.0809, 0.0548, 0.0873,
        0.2258, 0.1420, 0.1502], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,855][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.4950, 0.0324, 0.0375, 0.0274, 0.0250, 0.0350, 0.0355, 0.0620, 0.0329,
        0.0909, 0.0777, 0.0487], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,855][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0658, 0.0721, 0.1016, 0.0730, 0.1085, 0.0760, 0.0592, 0.0997, 0.0783,
        0.1150, 0.0784, 0.0724], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:28,856][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0457, 0.0295, 0.1101, 0.0708, 0.0800, 0.0092, 0.0474, 0.0627, 0.1414,
        0.1044, 0.2184, 0.0727, 0.0077], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,856][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0028, 0.0231, 0.0369, 0.0663, 0.0167, 0.0007, 0.0215, 0.0120, 0.0560,
        0.1755, 0.0092, 0.0106, 0.5688], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,857][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0065, 0.0186, 0.0670, 0.0477, 0.0396, 0.0636, 0.0784, 0.2300, 0.1033,
        0.1472, 0.0455, 0.0553, 0.0972], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,858][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0111, 0.0078, 0.0363, 0.0185, 0.0254, 0.0323, 0.0732, 0.1018, 0.0856,
        0.1389, 0.1422, 0.1168, 0.2102], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,859][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0196, 0.1135, 0.0225, 0.1188, 0.0267, 0.0505, 0.1274, 0.1392, 0.0847,
        0.0393, 0.0670, 0.1769, 0.0140], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,860][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ store] are: tensor([8.6922e-05, 2.0320e-03, 1.0729e-02, 1.9911e-02, 1.3042e-02, 1.1650e-02,
        6.7755e-02, 7.8333e-02, 2.3336e-01, 3.4598e-02, 1.7222e-01, 2.9563e-01,
        6.0647e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,862][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0435, 0.0248, 0.0511, 0.0937, 0.0979, 0.0946, 0.1055, 0.0752, 0.1082,
        0.0558, 0.0847, 0.1102, 0.0549], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,863][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.1112, 0.0814, 0.0686, 0.0690, 0.0662, 0.0808, 0.0815, 0.0722, 0.0820,
        0.0682, 0.0697, 0.0865, 0.0627], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,864][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ store] are: tensor([8.7086e-07, 1.2391e-05, 4.9085e-05, 9.8645e-05, 1.7539e-04, 1.1408e-03,
        1.4717e-03, 2.6694e-03, 1.6792e-02, 7.0444e-02, 4.6870e-01, 3.5172e-01,
        8.6727e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,865][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0111, 0.0068, 0.0254, 0.0511, 0.0513, 0.0373, 0.0964, 0.0354, 0.0773,
        0.1285, 0.1498, 0.2073, 0.1221], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,867][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.6494, 0.0177, 0.0174, 0.0118, 0.0103, 0.0179, 0.0190, 0.0364, 0.0172,
        0.0476, 0.0414, 0.0268, 0.0871], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,868][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0571, 0.0605, 0.1008, 0.0568, 0.0987, 0.0595, 0.0475, 0.0931, 0.0623,
        0.1088, 0.0611, 0.0621, 0.1316], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:28,870][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0437, 0.0145, 0.0329, 0.0397, 0.0963, 0.0200, 0.0860, 0.0850, 0.1193,
        0.0750, 0.1702, 0.1407, 0.0485, 0.0282], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,871][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0289, 0.0419, 0.2339, 0.0278, 0.1336, 0.0117, 0.0712, 0.0615, 0.0695,
        0.0171, 0.0188, 0.0368, 0.2263, 0.0209], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,873][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0053, 0.0111, 0.0398, 0.0328, 0.0768, 0.0967, 0.0542, 0.2389, 0.0466,
        0.1097, 0.0478, 0.0309, 0.1915, 0.0179], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,874][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0148, 0.0127, 0.0328, 0.0208, 0.0309, 0.0398, 0.0734, 0.0977, 0.0725,
        0.1074, 0.1007, 0.0869, 0.1926, 0.1171], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,876][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0310, 0.0631, 0.0167, 0.0685, 0.0755, 0.0548, 0.1468, 0.1482, 0.0521,
        0.0352, 0.0573, 0.1455, 0.0682, 0.0370], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,877][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0004, 0.0054, 0.0173, 0.0216, 0.0265, 0.0192, 0.0870, 0.0892, 0.2499,
        0.0275, 0.1343, 0.1678, 0.0825, 0.0715], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,879][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0492, 0.0275, 0.0569, 0.0891, 0.0975, 0.0855, 0.0949, 0.0660, 0.0909,
        0.0528, 0.0730, 0.0937, 0.0523, 0.0707], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,880][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.1297, 0.0655, 0.0570, 0.0612, 0.0608, 0.0701, 0.0726, 0.0678, 0.0798,
        0.0609, 0.0625, 0.0780, 0.0554, 0.0788], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,881][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [.] are: tensor([2.2268e-06, 2.1555e-05, 1.1536e-04, 2.6442e-04, 2.5638e-04, 1.9264e-03,
        1.4483e-03, 3.2147e-03, 1.3588e-02, 3.3541e-02, 1.1679e-01, 2.4362e-01,
        1.4640e-01, 4.3881e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,883][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0392, 0.0095, 0.0226, 0.0297, 0.0550, 0.0367, 0.0610, 0.0405, 0.0629,
        0.1733, 0.1020, 0.1108, 0.1867, 0.0701], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,884][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.5425, 0.0192, 0.0209, 0.0143, 0.0128, 0.0195, 0.0200, 0.0389, 0.0185,
        0.0543, 0.0461, 0.0282, 0.1061, 0.0587], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,886][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0541, 0.0560, 0.0881, 0.0570, 0.0886, 0.0581, 0.0502, 0.0792, 0.0647,
        0.0958, 0.0624, 0.0624, 0.1168, 0.0666], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:28,887][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.0313, 0.0139, 0.0083, 0.0559, 0.0856, 0.0335, 0.0480, 0.0563, 0.1589,
        0.0401, 0.1056, 0.1290, 0.0865, 0.1285, 0.0185], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,889][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0073, 0.0115, 0.0110, 0.4107, 0.0040, 0.0042, 0.3497, 0.0023, 0.0133,
        0.0038, 0.0033, 0.1109, 0.0433, 0.0182, 0.0065], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,890][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.0075, 0.0192, 0.0229, 0.0384, 0.0699, 0.1270, 0.0588, 0.2004, 0.0891,
        0.0853, 0.0292, 0.0419, 0.1604, 0.0291, 0.0208], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,891][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0125, 0.0104, 0.0324, 0.0222, 0.0282, 0.0359, 0.0737, 0.0858, 0.0681,
        0.1038, 0.0995, 0.0886, 0.1675, 0.1090, 0.0624], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,891][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.0294, 0.0908, 0.0097, 0.0780, 0.0663, 0.0445, 0.1753, 0.0406, 0.0796,
        0.0257, 0.0659, 0.2012, 0.0268, 0.0573, 0.0088], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,891][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([1.5080e-04, 2.6317e-03, 4.5842e-03, 1.6142e-02, 1.1080e-02, 1.0691e-02,
        5.4340e-02, 5.8761e-02, 1.6631e-01, 2.4571e-02, 1.3818e-01, 2.2947e-01,
        6.4342e-02, 1.4206e-01, 7.6692e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,892][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.0336, 0.0222, 0.0447, 0.0759, 0.0885, 0.0761, 0.0850, 0.0652, 0.0909,
        0.0571, 0.0776, 0.0957, 0.0514, 0.0672, 0.0689], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,892][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.1013, 0.0623, 0.0585, 0.0595, 0.0590, 0.0681, 0.0685, 0.0650, 0.0707,
        0.0586, 0.0596, 0.0727, 0.0538, 0.0716, 0.0709], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,893][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([2.5931e-07, 1.3790e-06, 7.4952e-06, 1.7821e-05, 2.1791e-05, 1.0090e-04,
        1.9152e-04, 2.3690e-04, 1.4639e-03, 3.7560e-03, 1.5706e-02, 2.5450e-02,
        2.9883e-02, 1.1309e-01, 8.1007e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,893][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0207, 0.0118, 0.0205, 0.0457, 0.0401, 0.0313, 0.0702, 0.0357, 0.0703,
        0.1099, 0.1133, 0.1359, 0.1333, 0.1027, 0.0585], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,894][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.5577, 0.0199, 0.0163, 0.0122, 0.0106, 0.0166, 0.0185, 0.0333, 0.0172,
        0.0412, 0.0337, 0.0244, 0.0629, 0.0337, 0.1017], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,896][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.0455, 0.0474, 0.0773, 0.0483, 0.0854, 0.0547, 0.0431, 0.0718, 0.0527,
        0.0901, 0.0514, 0.0544, 0.1156, 0.0610, 0.1011], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:28,897][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0120, 0.0190, 0.0509, 0.0399, 0.0534, 0.0147, 0.0265, 0.0282, 0.0908,
        0.0381, 0.0911, 0.0681, 0.1825, 0.1509, 0.1294, 0.0044],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,898][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([3.0552e-04, 1.5080e-02, 2.1903e-02, 1.4351e-03, 2.2131e-02, 2.9588e-02,
        4.0775e-05, 1.1246e-01, 7.8602e-03, 3.7426e-01, 1.2748e-03, 5.3948e-04,
        3.6070e-01, 1.9699e-02, 3.0168e-02, 2.5608e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,900][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0070, 0.0206, 0.0444, 0.0515, 0.0598, 0.0795, 0.0371, 0.1626, 0.0670,
        0.0803, 0.0410, 0.0396, 0.1769, 0.0380, 0.0416, 0.0532],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,901][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0121, 0.0078, 0.0264, 0.0135, 0.0191, 0.0206, 0.0476, 0.0656, 0.0568,
        0.0834, 0.0975, 0.0836, 0.1626, 0.1299, 0.0770, 0.0966],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,902][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0404, 0.1039, 0.0118, 0.0998, 0.0369, 0.0586, 0.0923, 0.0555, 0.0952,
        0.0450, 0.0717, 0.1141, 0.0415, 0.1147, 0.0124, 0.0063],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,904][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([2.4248e-04, 2.8579e-03, 9.5968e-03, 1.5603e-02, 1.1372e-02, 8.6786e-03,
        5.5891e-02, 4.4786e-02, 1.7596e-01, 1.6580e-02, 9.3043e-02, 1.3397e-01,
        3.8972e-02, 9.5989e-02, 2.7179e-01, 2.4672e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,905][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0468, 0.0252, 0.0508, 0.0757, 0.0866, 0.0798, 0.0838, 0.0598, 0.0817,
        0.0457, 0.0634, 0.0834, 0.0432, 0.0570, 0.0660, 0.0510],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,907][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1045, 0.0590, 0.0519, 0.0549, 0.0539, 0.0626, 0.0639, 0.0593, 0.0687,
        0.0537, 0.0556, 0.0682, 0.0492, 0.0687, 0.0673, 0.0586],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,907][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([3.2026e-07, 1.3945e-06, 6.4206e-06, 1.2530e-05, 1.0784e-05, 2.6312e-05,
        6.8411e-05, 7.4862e-05, 6.5284e-04, 1.3091e-03, 4.3878e-03, 1.1889e-02,
        6.9297e-03, 1.1364e-01, 6.8102e-01, 1.7997e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,909][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0163, 0.0054, 0.0173, 0.0268, 0.0384, 0.0207, 0.0557, 0.0269, 0.0514,
        0.1277, 0.0998, 0.1185, 0.1391, 0.0773, 0.0931, 0.0858],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,910][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.4455, 0.0175, 0.0171, 0.0118, 0.0105, 0.0158, 0.0170, 0.0318, 0.0157,
        0.0416, 0.0356, 0.0236, 0.0735, 0.0401, 0.1238, 0.0791],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,912][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0443, 0.0490, 0.0753, 0.0447, 0.0747, 0.0441, 0.0402, 0.0701, 0.0496,
        0.0807, 0.0500, 0.0529, 0.1054, 0.0549, 0.0982, 0.0658],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:28,913][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0112, 0.0154, 0.0201, 0.0773, 0.0280, 0.0068, 0.0093, 0.0860, 0.1853,
        0.0386, 0.1343, 0.0507, 0.0759, 0.1672, 0.0556, 0.0215, 0.0169],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,915][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0131, 0.0160, 0.0776, 0.0139, 0.1195, 0.0239, 0.0014, 0.2872, 0.0287,
        0.1843, 0.0023, 0.0029, 0.1056, 0.0127, 0.1079, 0.0023, 0.0008],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,916][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0098, 0.0190, 0.0406, 0.0590, 0.0543, 0.0922, 0.0125, 0.1647, 0.0765,
        0.0664, 0.0450, 0.0259, 0.1459, 0.0270, 0.0411, 0.1099, 0.0100],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,918][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0108, 0.0087, 0.0275, 0.0146, 0.0238, 0.0296, 0.0516, 0.0789, 0.0580,
        0.0863, 0.0764, 0.0660, 0.1477, 0.0983, 0.0622, 0.0876, 0.0720],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,919][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0633, 0.0938, 0.0391, 0.1146, 0.0338, 0.0695, 0.0479, 0.1509, 0.0429,
        0.0255, 0.0530, 0.0878, 0.0196, 0.0672, 0.0426, 0.0140, 0.0345],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,921][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0004, 0.0054, 0.0174, 0.0150, 0.0214, 0.0115, 0.0337, 0.0558, 0.1352,
        0.0223, 0.0732, 0.0874, 0.0718, 0.0676, 0.2710, 0.0424, 0.0686],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,922][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0442, 0.0256, 0.0467, 0.0708, 0.0795, 0.0755, 0.0782, 0.0586, 0.0729,
        0.0453, 0.0598, 0.0746, 0.0436, 0.0544, 0.0613, 0.0496, 0.0596],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,924][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1124, 0.0488, 0.0464, 0.0507, 0.0509, 0.0578, 0.0584, 0.0572, 0.0659,
        0.0505, 0.0525, 0.0635, 0.0458, 0.0637, 0.0624, 0.0540, 0.0589],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,925][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([2.9801e-08, 1.0106e-07, 7.7009e-07, 1.3056e-06, 3.7622e-06, 6.7796e-06,
        2.0239e-06, 7.8844e-06, 8.5109e-05, 3.4356e-04, 1.3120e-03, 1.6166e-03,
        2.1190e-03, 9.7462e-03, 7.7993e-02, 7.5258e-01, 1.5418e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,926][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0324, 0.0082, 0.0192, 0.0218, 0.0410, 0.0256, 0.0434, 0.0310, 0.0475,
        0.1293, 0.0745, 0.0776, 0.1556, 0.0537, 0.0844, 0.0867, 0.0680],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,928][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.4335, 0.0147, 0.0151, 0.0102, 0.0093, 0.0142, 0.0148, 0.0285, 0.0136,
        0.0384, 0.0322, 0.0202, 0.0690, 0.0381, 0.1159, 0.0752, 0.0572],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,929][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0441, 0.0471, 0.0654, 0.0472, 0.0698, 0.0467, 0.0375, 0.0704, 0.0521,
        0.0734, 0.0512, 0.0486, 0.0948, 0.0540, 0.0845, 0.0691, 0.0441],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:28,931][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.0285, 0.0145, 0.0476, 0.0471, 0.0736, 0.0205, 0.0283, 0.0190, 0.1509,
        0.0410, 0.0754, 0.0458, 0.0875, 0.0984, 0.1052, 0.0550, 0.0501, 0.0116],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,932][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([1.0271e-02, 3.8802e-03, 7.5656e-03, 6.5321e-02, 1.7907e-03, 2.7917e-04,
        1.5925e-01, 5.7989e-04, 6.6358e-03, 6.7655e-03, 1.4323e-04, 6.9546e-03,
        3.2320e-02, 8.6883e-03, 1.1813e-02, 4.4014e-04, 6.6102e-01, 1.6285e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,932][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([0.0042, 0.0085, 0.0384, 0.0265, 0.0599, 0.0631, 0.0467, 0.2014, 0.0509,
        0.0618, 0.0438, 0.0260, 0.1719, 0.0187, 0.0357, 0.0849, 0.0388, 0.0186],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,933][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([0.0069, 0.0059, 0.0234, 0.0128, 0.0185, 0.0263, 0.0515, 0.0628, 0.0504,
        0.0774, 0.0725, 0.0620, 0.1217, 0.0845, 0.0542, 0.0783, 0.0723, 0.1186],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,933][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([0.0223, 0.0903, 0.0106, 0.0864, 0.0336, 0.0630, 0.1239, 0.0711, 0.0676,
        0.0409, 0.0540, 0.0904, 0.0498, 0.0697, 0.0097, 0.0112, 0.0947, 0.0109],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,934][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([0.0002, 0.0023, 0.0085, 0.0096, 0.0114, 0.0104, 0.0427, 0.0647, 0.1375,
        0.0239, 0.0768, 0.1143, 0.0562, 0.0644, 0.1678, 0.0387, 0.0923, 0.0782],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,934][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([0.0225, 0.0160, 0.0322, 0.0592, 0.0659, 0.0629, 0.0694, 0.0557, 0.0761,
        0.0468, 0.0645, 0.0763, 0.0434, 0.0592, 0.0568, 0.0551, 0.0657, 0.0723],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,935][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([0.0830, 0.0538, 0.0498, 0.0496, 0.0497, 0.0567, 0.0568, 0.0541, 0.0586,
        0.0506, 0.0499, 0.0599, 0.0463, 0.0600, 0.0599, 0.0531, 0.0543, 0.0537],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,935][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([1.5397e-08, 8.9383e-08, 4.9869e-07, 1.0378e-06, 4.4044e-06, 3.3922e-06,
        7.0586e-06, 9.1832e-06, 7.5707e-05, 3.5107e-04, 7.9198e-04, 1.3194e-03,
        4.8659e-03, 1.2621e-02, 6.0901e-02, 1.9609e-01, 4.9106e-01, 2.3190e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,936][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([0.0103, 0.0046, 0.0130, 0.0241, 0.0237, 0.0208, 0.0472, 0.0209, 0.0425,
        0.0734, 0.0699, 0.0909, 0.0907, 0.0619, 0.0550, 0.0900, 0.0897, 0.1715],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,937][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([0.2960, 0.0199, 0.0196, 0.0146, 0.0132, 0.0182, 0.0191, 0.0334, 0.0179,
        0.0458, 0.0375, 0.0249, 0.0774, 0.0430, 0.1218, 0.0817, 0.0662, 0.0497],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,939][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([0.0350, 0.0403, 0.0609, 0.0409, 0.0630, 0.0423, 0.0327, 0.0590, 0.0440,
        0.0676, 0.0425, 0.0422, 0.0909, 0.0511, 0.0808, 0.0618, 0.0395, 0.1055],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:28,940][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0095, 0.0131, 0.0112, 0.0490, 0.0239, 0.0086, 0.0162, 0.0402, 0.0856,
        0.0326, 0.2107, 0.0263, 0.1652, 0.0777, 0.0321, 0.0203, 0.0331, 0.1251,
        0.0198], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,942][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0144, 0.0123, 0.0150, 0.0309, 0.0326, 0.0027, 0.0284, 0.0100, 0.0431,
        0.0352, 0.0007, 0.0274, 0.1909, 0.0134, 0.0169, 0.0032, 0.0506, 0.1303,
        0.3420], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,943][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0055, 0.0119, 0.0286, 0.0349, 0.0479, 0.0809, 0.0351, 0.1677, 0.0448,
        0.0947, 0.0313, 0.0259, 0.1393, 0.0180, 0.0291, 0.1194, 0.0327, 0.0462,
        0.0063], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,945][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0098, 0.0069, 0.0216, 0.0112, 0.0176, 0.0209, 0.0380, 0.0556, 0.0458,
        0.0660, 0.0652, 0.0549, 0.1206, 0.0782, 0.0542, 0.0738, 0.0650, 0.1206,
        0.0740], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,946][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0322, 0.0707, 0.0099, 0.0765, 0.0529, 0.0996, 0.0785, 0.0430, 0.0916,
        0.0330, 0.0684, 0.0683, 0.0262, 0.0690, 0.0107, 0.0570, 0.0556, 0.0202,
        0.0367], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,948][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0005, 0.0042, 0.0142, 0.0147, 0.0181, 0.0109, 0.0387, 0.0426, 0.1067,
        0.0177, 0.0619, 0.0789, 0.0473, 0.0497, 0.2066, 0.0298, 0.0708, 0.1088,
        0.0778], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,949][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0368, 0.0253, 0.0391, 0.0618, 0.0646, 0.0649, 0.0661, 0.0545, 0.0617,
        0.0453, 0.0535, 0.0628, 0.0418, 0.0502, 0.0513, 0.0468, 0.0524, 0.0647,
        0.0566], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,951][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0976, 0.0427, 0.0420, 0.0456, 0.0463, 0.0517, 0.0514, 0.0522, 0.0573,
        0.0465, 0.0471, 0.0558, 0.0422, 0.0559, 0.0549, 0.0485, 0.0508, 0.0516,
        0.0599], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,952][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([1.6455e-08, 4.9331e-08, 2.1883e-07, 2.6265e-07, 1.0090e-06, 3.1359e-06,
        2.0199e-06, 2.2364e-06, 1.8159e-05, 4.9452e-05, 2.2155e-04, 3.8753e-04,
        3.4521e-04, 2.9760e-03, 1.2694e-02, 3.7064e-01, 1.1955e-01, 2.2683e-01,
        2.6628e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,953][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0232, 0.0059, 0.0137, 0.0174, 0.0290, 0.0185, 0.0341, 0.0219, 0.0351,
        0.0875, 0.0561, 0.0614, 0.1028, 0.0426, 0.0589, 0.0648, 0.0554, 0.2013,
        0.0703], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,955][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.4503, 0.0112, 0.0119, 0.0075, 0.0070, 0.0116, 0.0120, 0.0246, 0.0110,
        0.0326, 0.0269, 0.0165, 0.0581, 0.0301, 0.1122, 0.0636, 0.0487, 0.0385,
        0.0257], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,956][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0351, 0.0404, 0.0593, 0.0398, 0.0607, 0.0405, 0.0332, 0.0555, 0.0443,
        0.0630, 0.0436, 0.0437, 0.0779, 0.0470, 0.0764, 0.0570, 0.0392, 0.0969,
        0.0466], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:28,974][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:28,975][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,977][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,977][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,978][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,979][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,979][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,980][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,981][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,981][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,982][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,983][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,983][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:28,984][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1558, 0.8442], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,985][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9616, 0.0384], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,987][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,988][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5186, 0.4814], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,989][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0670, 0.9330], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,990][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1769, 0.8231], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,990][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1534, 0.8466], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,992][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.5024, 0.4976], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,995][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4754, 0.5246], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:28,997][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([9.9998e-01, 1.8689e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:29,001][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3317, 0.6683], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:29,005][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.4176, 0.5824], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:29,006][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.0826, 0.3531, 0.5643], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,007][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.3802, 0.1358, 0.4840], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,008][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([5.8663e-06, 1.2142e-01, 8.7857e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,008][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.2528, 0.2368, 0.5104], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,010][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([3.0784e-04, 4.6529e-02, 9.5316e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,013][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.0772, 0.8015, 0.1213], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,017][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.0255, 0.1336, 0.8410], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,021][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.2961, 0.3932, 0.3107], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,024][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.3274, 0.5109, 0.1616], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,024][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([5.6136e-01, 2.4107e-05, 4.3861e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,025][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.2111, 0.4425, 0.3463], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,026][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.3218, 0.4587, 0.2195], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,026][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0133, 0.1678, 0.5533, 0.2656], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,029][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.5895, 0.0791, 0.1538, 0.1776], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,030][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([2.5551e-07, 2.6614e-03, 7.6257e-01, 2.3476e-01], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,035][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2371, 0.1803, 0.4927, 0.0899], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,037][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([3.4026e-04, 2.7919e-02, 8.1155e-01, 1.6019e-01], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,041][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0564, 0.4418, 0.4054, 0.0964], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,042][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0185, 0.1447, 0.7048, 0.1321], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,043][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2693, 0.2752, 0.2105, 0.2450], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,044][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2159, 0.3171, 0.2035, 0.2635], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,044][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([8.0098e-01, 1.8705e-05, 1.8079e-01, 1.8210e-02], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,046][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1677, 0.3326, 0.2642, 0.2355], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,049][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2346, 0.3385, 0.1818, 0.2451], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,053][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.0113, 0.1813, 0.2885, 0.3386, 0.1803], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,057][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([0.4596, 0.0264, 0.0494, 0.4496, 0.0149], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,060][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([4.8364e-07, 1.1402e-03, 1.1007e-01, 3.4027e-01, 5.4852e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,060][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([0.1355, 0.1085, 0.2951, 0.0553, 0.4057], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,061][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([7.0676e-05, 8.7895e-03, 3.4631e-01, 1.5970e-01, 4.8513e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,062][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.0324, 0.4159, 0.2691, 0.2687, 0.0139], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,063][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.0101, 0.0460, 0.4036, 0.0382, 0.5021], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,066][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.1829, 0.2364, 0.1877, 0.2066, 0.1864], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,070][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.1463, 0.3070, 0.1143, 0.3185, 0.1138], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,073][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([6.7028e-01, 5.8942e-06, 8.8248e-03, 2.1574e-03, 3.1874e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,076][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.1180, 0.2653, 0.2084, 0.1744, 0.2340], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,078][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.1996, 0.2890, 0.1404, 0.1927, 0.1783], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,078][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0025, 0.1183, 0.2333, 0.2729, 0.2196, 0.1534], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,079][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.5719, 0.0333, 0.0705, 0.2449, 0.0344, 0.0450], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,080][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([1.2890e-08, 1.3200e-04, 2.1564e-02, 8.9151e-02, 6.6853e-01, 2.2062e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,082][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1093, 0.0858, 0.2255, 0.0474, 0.3498, 0.1822], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,084][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([4.3188e-05, 1.2461e-02, 3.0749e-02, 2.6413e-01, 1.5107e-01, 5.4154e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,088][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0493, 0.3446, 0.3174, 0.1912, 0.0651, 0.0324], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,093][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0070, 0.0649, 0.3724, 0.0547, 0.3987, 0.1023], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,095][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1987, 0.1818, 0.1348, 0.1621, 0.1500, 0.1727], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,096][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.1264, 0.2159, 0.1191, 0.1700, 0.1395, 0.2292], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,096][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([6.3651e-03, 8.8333e-07, 2.8736e-02, 1.1481e-03, 4.6529e-01, 4.9846e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,097][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.1041, 0.2148, 0.1730, 0.1490, 0.1969, 0.1622], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,101][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.1562, 0.2335, 0.1302, 0.1724, 0.1657, 0.1420], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,105][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0005, 0.0467, 0.1249, 0.1449, 0.1264, 0.1524, 0.4042],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,111][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.3113, 0.0272, 0.1092, 0.2512, 0.1023, 0.0463, 0.1527],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,112][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([6.4382e-09, 1.6916e-05, 2.7556e-03, 1.8865e-02, 1.7020e-01, 5.9645e-01,
        2.1171e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,113][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0944, 0.0703, 0.1987, 0.0386, 0.3228, 0.1735, 0.1017],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,114][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.7683e-05, 2.0996e-03, 7.2405e-02, 3.5015e-02, 4.9749e-01, 2.3792e-01,
        1.5505e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,114][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0359, 0.3219, 0.2721, 0.1524, 0.0608, 0.1505, 0.0064],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,118][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0049, 0.0625, 0.3350, 0.0680, 0.3314, 0.1448, 0.0534],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,124][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1650, 0.1536, 0.1203, 0.1408, 0.1307, 0.1485, 0.1410],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,128][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0776, 0.1351, 0.0872, 0.1583, 0.1396, 0.3124, 0.0899],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,128][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([3.6391e-03, 4.7378e-07, 9.0395e-03, 5.4701e-04, 1.8578e-01, 3.1047e-01,
        4.9053e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,129][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0906, 0.1816, 0.1454, 0.1275, 0.1669, 0.1384, 0.1496],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,130][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1356, 0.2076, 0.1127, 0.1545, 0.1468, 0.1292, 0.1136],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,132][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0026, 0.0910, 0.1055, 0.1622, 0.0927, 0.1040, 0.3215, 0.1205],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,138][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.5762, 0.0124, 0.0407, 0.1456, 0.0074, 0.0051, 0.1260, 0.0866],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,142][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([7.2736e-09, 1.5049e-05, 2.1775e-03, 5.6197e-03, 1.2650e-01, 8.5069e-02,
        6.6348e-01, 1.1715e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,144][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0793, 0.0642, 0.1676, 0.0376, 0.2496, 0.1512, 0.0882, 0.1625],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,145][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([1.7619e-05, 1.2016e-03, 1.4814e-02, 2.7801e-02, 7.4593e-02, 3.2779e-01,
        2.1347e-01, 3.4031e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,146][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0253, 0.3530, 0.2193, 0.2227, 0.0644, 0.0888, 0.0187, 0.0079],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,146][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0052, 0.0517, 0.3370, 0.0429, 0.3296, 0.0724, 0.0339, 0.1272],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,150][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.1054, 0.1516, 0.1129, 0.1281, 0.1132, 0.1368, 0.1248, 0.1273],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,155][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0649, 0.1315, 0.0572, 0.1251, 0.1116, 0.3130, 0.0898, 0.1069],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,158][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([1.2249e-02, 6.2544e-06, 1.5880e-02, 1.4500e-03, 1.8442e-01, 1.4880e-01,
        3.1104e-01, 3.2615e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,161][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0755, 0.1529, 0.1237, 0.1054, 0.1395, 0.1167, 0.1251, 0.1613],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,161][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.1235, 0.1859, 0.1017, 0.1373, 0.1334, 0.1118, 0.0980, 0.1085],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,162][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([3.9943e-05, 4.8378e-03, 2.1602e-02, 1.5916e-02, 2.1576e-02, 2.6501e-02,
        6.5193e-02, 2.7351e-02, 8.1698e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,163][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.2351, 0.0039, 0.0064, 0.2387, 0.0114, 0.0036, 0.4535, 0.0210, 0.0265],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,165][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([2.9525e-09, 2.6777e-07, 1.4815e-04, 2.9078e-04, 6.6188e-03, 7.3231e-03,
        5.4209e-02, 3.7869e-01, 5.5272e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,170][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0717, 0.0555, 0.1490, 0.0342, 0.2213, 0.1384, 0.0814, 0.1536, 0.0949],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,174][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([5.4600e-07, 2.5216e-05, 1.7201e-03, 7.2887e-04, 8.2519e-03, 3.1180e-03,
        5.8792e-03, 9.1104e-01, 6.9236e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,177][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0374, 0.2725, 0.2507, 0.1973, 0.0761, 0.1021, 0.0265, 0.0266, 0.0108],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,177][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0049, 0.0511, 0.2819, 0.0492, 0.2745, 0.0927, 0.0396, 0.1436, 0.0625],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,178][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.1401, 0.1112, 0.0907, 0.1074, 0.1004, 0.1120, 0.1091, 0.1094, 0.1197],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,179][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0666, 0.0894, 0.0998, 0.1019, 0.1315, 0.2065, 0.0913, 0.1200, 0.0931],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,180][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([5.8646e-01, 1.4126e-05, 1.4955e-03, 1.0722e-03, 3.9065e-02, 7.4278e-03,
        1.7821e-02, 7.7795e-02, 2.6885e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,185][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0732, 0.1343, 0.1082, 0.0944, 0.1236, 0.1027, 0.1103, 0.1391, 0.1143],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,191][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.1188, 0.1739, 0.0854, 0.1166, 0.1033, 0.0962, 0.0861, 0.0909, 0.1288],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,193][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([1.7978e-04, 1.7974e-02, 3.1201e-02, 3.7082e-02, 2.6156e-02, 3.1820e-02,
        8.3099e-02, 3.7601e-02, 6.4223e-01, 9.2655e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,194][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.3085, 0.0283, 0.0997, 0.2208, 0.0136, 0.0176, 0.1692, 0.1066, 0.0124,
        0.0234], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,195][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([7.7901e-11, 2.0775e-08, 3.1811e-06, 1.0160e-05, 4.4607e-04, 1.4955e-03,
        4.6794e-03, 5.4373e-03, 4.7018e-01, 5.1775e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,196][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0533, 0.0411, 0.1097, 0.0247, 0.1596, 0.0955, 0.0568, 0.1085, 0.0700,
        0.2808], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,197][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([6.7630e-07, 4.3606e-05, 3.7890e-04, 7.7039e-04, 4.6246e-03, 2.0075e-02,
        1.2141e-02, 4.3021e-01, 1.0688e-01, 4.2488e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,203][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0497, 0.3539, 0.2108, 0.1424, 0.0510, 0.0420, 0.0256, 0.0520, 0.0422,
        0.0305], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,209][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0064, 0.0430, 0.2489, 0.0369, 0.2751, 0.0574, 0.0315, 0.1054, 0.0483,
        0.1472], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,210][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0963, 0.1137, 0.0856, 0.0939, 0.0897, 0.1019, 0.0916, 0.0991, 0.0963,
        0.1318], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,211][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0493, 0.0810, 0.0333, 0.0881, 0.0734, 0.2877, 0.0775, 0.1375, 0.1076,
        0.0645], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,212][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([8.9487e-04, 7.4430e-08, 4.4458e-04, 2.0046e-05, 4.7172e-03, 3.7417e-03,
        4.1516e-03, 1.3790e-02, 1.5737e-02, 9.5650e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,214][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0621, 0.1221, 0.0987, 0.0839, 0.1106, 0.0925, 0.0984, 0.1257, 0.1021,
        0.1040], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,219][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.1023, 0.1489, 0.0817, 0.1096, 0.1061, 0.0899, 0.0777, 0.0859, 0.1356,
        0.0624], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,223][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([5.0349e-05, 8.1447e-03, 1.5574e-02, 1.5393e-02, 1.3788e-02, 1.6014e-02,
        3.6781e-02, 1.9450e-02, 4.0695e-01, 8.3438e-02, 3.8442e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,226][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.1055, 0.0332, 0.0774, 0.1451, 0.1026, 0.0543, 0.2558, 0.1462, 0.0307,
        0.0241, 0.0252], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,226][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([8.8365e-11, 2.1164e-09, 4.5104e-07, 1.3113e-06, 2.0592e-05, 3.5065e-05,
        2.8037e-04, 1.3781e-04, 3.7544e-02, 3.6107e-01, 6.0091e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,227][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0407, 0.0314, 0.0898, 0.0209, 0.1377, 0.0855, 0.0502, 0.0947, 0.0613,
        0.2612, 0.1267], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,228][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([7.1510e-07, 1.0329e-05, 9.8071e-05, 1.8589e-04, 3.1784e-04, 1.5345e-03,
        2.2342e-03, 1.1168e-02, 3.0210e-02, 8.0068e-01, 1.5356e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,232][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0385, 0.2650, 0.1436, 0.1607, 0.0446, 0.1075, 0.0414, 0.0847, 0.0395,
        0.0634, 0.0110], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,238][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0068, 0.0427, 0.2095, 0.0414, 0.2120, 0.0779, 0.0375, 0.1159, 0.0542,
        0.1540, 0.0480], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,242][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.1098, 0.0934, 0.0719, 0.0843, 0.0791, 0.0884, 0.0857, 0.0851, 0.0947,
        0.1146, 0.0930], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,242][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0542, 0.0727, 0.0465, 0.0744, 0.0752, 0.1912, 0.0917, 0.1305, 0.1163,
        0.0708, 0.0765], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,243][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([1.5901e-02, 2.9839e-08, 2.1104e-04, 1.1228e-05, 1.0643e-02, 1.4665e-03,
        2.3696e-03, 1.2177e-02, 4.0353e-02, 8.2501e-01, 9.1858e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,244][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0595, 0.1113, 0.0886, 0.0782, 0.1019, 0.0850, 0.0913, 0.1140, 0.0939,
        0.0956, 0.0807], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,248][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0922, 0.1461, 0.0736, 0.1018, 0.0954, 0.0846, 0.0733, 0.0801, 0.1214,
        0.0568, 0.0748], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,252][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([4.7313e-06, 1.3944e-03, 5.0584e-03, 3.8927e-03, 4.2054e-03, 3.8700e-03,
        9.3174e-03, 5.8663e-03, 1.5774e-01, 3.9121e-02, 2.2376e-01, 5.4578e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,258][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.2150, 0.0105, 0.0546, 0.2055, 0.0841, 0.0281, 0.1692, 0.0737, 0.0358,
        0.0120, 0.0123, 0.0993], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,259][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([1.7304e-12, 5.5325e-11, 1.2654e-08, 5.0228e-08, 1.1121e-06, 1.3444e-06,
        3.0205e-06, 8.7525e-06, 2.2982e-03, 2.0849e-02, 9.1878e-01, 5.8060e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,260][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0362, 0.0262, 0.0801, 0.0179, 0.1230, 0.0766, 0.0458, 0.0889, 0.0568,
        0.2498, 0.1205, 0.0783], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,260][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([6.5619e-07, 1.5162e-05, 2.4979e-04, 1.9374e-04, 1.9968e-03, 1.0780e-03,
        1.2989e-03, 2.6769e-02, 1.3535e-02, 3.5664e-01, 3.7379e-01, 2.2444e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,264][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0293, 0.2309, 0.1606, 0.1941, 0.0389, 0.1158, 0.0211, 0.0699, 0.0226,
        0.0805, 0.0258, 0.0106], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,270][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0041, 0.0376, 0.1900, 0.0415, 0.1896, 0.0838, 0.0328, 0.1175, 0.0527,
        0.1615, 0.0503, 0.0387], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,274][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0992, 0.0843, 0.0651, 0.0768, 0.0719, 0.0809, 0.0781, 0.0772, 0.0866,
        0.1038, 0.0850, 0.0912], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,275][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0371, 0.0685, 0.0453, 0.0823, 0.0641, 0.1561, 0.0648, 0.1121, 0.0926,
        0.1020, 0.1335, 0.0419], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,276][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([1.7039e-03, 4.6775e-11, 5.5609e-06, 1.0668e-07, 7.5188e-04, 6.3622e-05,
        1.3355e-04, 1.4160e-03, 5.7028e-03, 6.3048e-01, 8.2727e-02, 2.7701e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,277][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0544, 0.1015, 0.0808, 0.0708, 0.0927, 0.0767, 0.0824, 0.1039, 0.0854,
        0.0873, 0.0738, 0.0903], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,280][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0872, 0.1202, 0.0694, 0.0910, 0.0860, 0.0771, 0.0668, 0.0745, 0.1086,
        0.0585, 0.0725, 0.0881], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,284][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([8.3147e-05, 8.5035e-03, 8.9435e-03, 1.2296e-02, 7.6054e-03, 8.2270e-03,
        2.0032e-02, 1.1726e-02, 1.9518e-01, 3.3337e-02, 1.9312e-01, 4.1788e-01,
        8.3063e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,290][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0743, 0.0383, 0.2421, 0.1495, 0.0455, 0.0087, 0.0984, 0.0711, 0.0369,
        0.0294, 0.0595, 0.0829, 0.0634], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,291][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([7.8461e-13, 6.5261e-11, 1.4574e-08, 2.6122e-08, 2.9938e-07, 1.7290e-07,
        5.9540e-06, 9.5191e-06, 9.0328e-04, 3.3825e-02, 8.2963e-02, 6.6119e-01,
        2.2111e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,292][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.0388, 0.0262, 0.0664, 0.0155, 0.0877, 0.0612, 0.0377, 0.0693, 0.0449,
        0.1748, 0.0954, 0.0661, 0.2159], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,293][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([1.1446e-07, 6.6070e-06, 2.1801e-04, 1.0376e-04, 5.0316e-04, 4.7478e-04,
        1.3266e-03, 1.3232e-02, 1.1372e-02, 8.2619e-02, 1.3902e-01, 3.3429e-01,
        4.1684e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,294][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.0203, 0.2441, 0.3041, 0.1103, 0.0358, 0.0514, 0.0322, 0.0202, 0.0350,
        0.0511, 0.0316, 0.0544, 0.0096], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,299][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.0054, 0.0297, 0.1916, 0.0238, 0.2096, 0.0378, 0.0191, 0.0720, 0.0303,
        0.1033, 0.0285, 0.0225, 0.2263], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,305][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0641, 0.0887, 0.0649, 0.0740, 0.0657, 0.0791, 0.0723, 0.0738, 0.0727,
        0.0954, 0.0768, 0.0812, 0.0915], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,307][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.0359, 0.0668, 0.0280, 0.0737, 0.0346, 0.1180, 0.0752, 0.1195, 0.0992,
        0.0892, 0.1506, 0.0583, 0.0510], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,308][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([2.1072e-02, 1.2897e-07, 4.4401e-04, 1.9521e-05, 1.7303e-02, 1.0431e-03,
        1.6390e-03, 6.5669e-03, 6.2397e-02, 3.1513e-01, 1.7222e-01, 2.9570e-01,
        1.0647e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,309][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.0436, 0.0900, 0.0725, 0.0614, 0.0807, 0.0679, 0.0724, 0.0943, 0.0765,
        0.0784, 0.0662, 0.0797, 0.1165], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,312][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.0780, 0.1181, 0.0646, 0.0881, 0.0847, 0.0733, 0.0623, 0.0692, 0.1098,
        0.0522, 0.0673, 0.0817, 0.0507], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,316][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([2.4069e-06, 7.0494e-04, 3.2344e-03, 1.6782e-03, 2.4839e-03, 2.0587e-03,
        3.2017e-03, 3.2018e-03, 4.8971e-02, 1.5873e-02, 8.0922e-02, 1.5076e-01,
        5.6952e-02, 6.2995e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:29,322][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0378, 0.0147, 0.1492, 0.1135, 0.0631, 0.0142, 0.2126, 0.0317, 0.0475,
        0.0067, 0.0349, 0.1319, 0.0213, 0.1210], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:29,323][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([3.6747e-12, 2.0377e-11, 2.0969e-08, 1.8136e-08, 1.0084e-06, 5.2013e-07,
        5.3426e-06, 7.1281e-06, 1.5064e-04, 1.0055e-02, 2.5135e-02, 9.1449e-02,
        3.9599e-01, 4.7721e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:29,324][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0323, 0.0211, 0.0564, 0.0146, 0.0848, 0.0578, 0.0348, 0.0661, 0.0399,
        0.1738, 0.0849, 0.0574, 0.2208, 0.0553], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:29,325][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([6.8385e-07, 8.5277e-06, 2.2553e-04, 2.1165e-04, 2.7327e-03, 9.2190e-04,
        1.9626e-03, 1.2813e-02, 9.4098e-03, 7.4576e-02, 5.4222e-02, 2.9616e-01,
        1.9949e-01, 3.4726e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:29,327][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0336, 0.1965, 0.1026, 0.1484, 0.0415, 0.1125, 0.0320, 0.0741, 0.0375,
        0.0478, 0.0541, 0.0368, 0.0495, 0.0331], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:29,333][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0032, 0.0279, 0.1117, 0.0410, 0.1207, 0.0779, 0.0318, 0.0830, 0.0452,
        0.1290, 0.0473, 0.0360, 0.2331, 0.0121], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:29,339][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0855, 0.0700, 0.0550, 0.0638, 0.0608, 0.0670, 0.0651, 0.0645, 0.0722,
        0.0849, 0.0707, 0.0755, 0.0800, 0.0847], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:29,339][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0437, 0.0547, 0.0396, 0.0584, 0.0603, 0.1187, 0.0661, 0.0933, 0.0863,
        0.0793, 0.1163, 0.0550, 0.0784, 0.0499], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:29,340][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([7.8488e-03, 1.7651e-08, 9.1489e-05, 3.5035e-06, 3.8811e-03, 2.6404e-04,
        4.0216e-04, 1.8391e-03, 2.0412e-02, 1.4569e-01, 9.7787e-02, 1.2569e-01,
        8.2253e-02, 5.1384e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:29,341][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0439, 0.0820, 0.0661, 0.0582, 0.0755, 0.0629, 0.0678, 0.0856, 0.0704,
        0.0721, 0.0608, 0.0738, 0.1060, 0.0748], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:29,345][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0783, 0.1125, 0.0609, 0.0824, 0.0768, 0.0691, 0.0606, 0.0656, 0.0968,
        0.0485, 0.0627, 0.0769, 0.0491, 0.0598], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:29,349][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([4.2042e-05, 2.9266e-03, 5.3912e-03, 7.0575e-03, 7.4642e-03, 6.6535e-03,
        1.0898e-02, 8.8677e-03, 7.8496e-02, 2.8812e-02, 8.9077e-02, 1.6617e-01,
        6.5206e-02, 3.4538e-01, 1.7756e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:29,355][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0393, 0.0147, 0.0820, 0.2970, 0.0148, 0.0202, 0.2429, 0.0082, 0.0113,
        0.0081, 0.0091, 0.1070, 0.0545, 0.0507, 0.0402], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:29,355][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([2.0265e-13, 2.7994e-12, 7.7822e-11, 3.3909e-10, 1.9221e-08, 8.1071e-09,
        4.0161e-08, 5.4360e-08, 3.0868e-06, 3.5242e-05, 6.5478e-05, 1.2856e-03,
        5.6165e-03, 2.1873e-02, 9.7112e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:29,356][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.0327, 0.0205, 0.0453, 0.0139, 0.0646, 0.0504, 0.0304, 0.0536, 0.0347,
        0.1319, 0.0723, 0.0503, 0.1706, 0.0515, 0.1773], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:29,357][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([4.0211e-08, 3.4724e-07, 7.2789e-06, 5.3219e-06, 4.6760e-05, 7.0393e-06,
        5.2890e-05, 1.7000e-05, 2.2747e-04, 1.2117e-03, 2.2176e-03, 9.6900e-03,
        7.2470e-03, 3.3232e-02, 9.4604e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:29,361][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.0205, 0.1761, 0.0257, 0.1362, 0.0436, 0.0769, 0.0388, 0.0725, 0.0469,
        0.0840, 0.0541, 0.0435, 0.0879, 0.0756, 0.0176], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:29,367][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.0039, 0.0261, 0.1475, 0.0233, 0.1695, 0.0399, 0.0197, 0.0644, 0.0315,
        0.0942, 0.0307, 0.0223, 0.1878, 0.0070, 0.1322], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:29,371][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.0560, 0.0710, 0.0563, 0.0661, 0.0571, 0.0701, 0.0657, 0.0650, 0.0646,
        0.0788, 0.0680, 0.0725, 0.0773, 0.0782, 0.0534], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:29,372][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.0397, 0.0642, 0.0213, 0.0701, 0.0382, 0.1473, 0.0634, 0.0850, 0.1061,
        0.0593, 0.1184, 0.0511, 0.0630, 0.0540, 0.0189], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:29,372][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([4.0954e-02, 5.1393e-07, 1.3628e-04, 2.5885e-05, 5.7296e-03, 3.0640e-04,
        4.1798e-04, 1.7660e-03, 3.8858e-02, 2.4914e-02, 2.7545e-02, 1.7831e-02,
        2.1168e-02, 9.3805e-02, 7.2654e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:29,373][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0382, 0.0768, 0.0613, 0.0525, 0.0686, 0.0574, 0.0618, 0.0797, 0.0649,
        0.0667, 0.0556, 0.0673, 0.0980, 0.0691, 0.0822], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:29,377][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.0843, 0.1131, 0.0604, 0.0782, 0.0761, 0.0637, 0.0555, 0.0622, 0.0962,
        0.0450, 0.0593, 0.0721, 0.0445, 0.0559, 0.0333], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:29,381][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([1.8975e-05, 2.8127e-03, 5.1035e-03, 4.3369e-03, 3.4006e-03, 3.5362e-03,
        7.1485e-03, 4.7604e-03, 6.5126e-02, 1.5299e-02, 7.4280e-02, 1.6234e-01,
        5.5160e-02, 3.7372e-01, 1.7262e-01, 5.0344e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:29,387][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0219, 0.0395, 0.1254, 0.0247, 0.0631, 0.0985, 0.0070, 0.1781, 0.0245,
        0.0825, 0.0204, 0.0175, 0.1388, 0.0445, 0.0881, 0.0255],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:29,388][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([3.5620e-14, 2.7693e-13, 2.1996e-11, 8.6773e-11, 1.1615e-09, 6.9115e-10,
        4.9146e-09, 5.5772e-09, 4.5211e-07, 7.9188e-06, 6.0303e-05, 1.7938e-04,
        1.4195e-03, 1.0045e-02, 7.5310e-01, 2.3519e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:29,389][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0237, 0.0148, 0.0387, 0.0093, 0.0531, 0.0368, 0.0220, 0.0428, 0.0274,
        0.1086, 0.0580, 0.0394, 0.1442, 0.0414, 0.1718, 0.1682],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:29,389][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([7.3845e-08, 9.8903e-07, 3.7118e-06, 1.2280e-05, 2.6710e-05, 1.6759e-05,
        9.9107e-05, 3.0963e-04, 5.5378e-04, 2.0326e-03, 3.6922e-03, 9.3760e-03,
        1.0224e-02, 5.7196e-02, 4.5926e-01, 4.5719e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:29,393][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0240, 0.2081, 0.1560, 0.1017, 0.0325, 0.0216, 0.0269, 0.0300, 0.0266,
        0.0536, 0.0337, 0.0597, 0.0529, 0.0648, 0.1037, 0.0042],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:29,399][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0034, 0.0246, 0.1300, 0.0211, 0.1445, 0.0349, 0.0157, 0.0553, 0.0258,
        0.0878, 0.0252, 0.0186, 0.1817, 0.0064, 0.1345, 0.0906],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:29,403][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0626, 0.0657, 0.0496, 0.0591, 0.0530, 0.0622, 0.0598, 0.0576, 0.0625,
        0.0737, 0.0633, 0.0675, 0.0698, 0.0745, 0.0502, 0.0689],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:29,404][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0449, 0.0649, 0.0391, 0.0610, 0.0342, 0.1004, 0.0603, 0.1083, 0.0943,
        0.0635, 0.0852, 0.0514, 0.0587, 0.0501, 0.0362, 0.0476],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:29,405][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([2.5871e-03, 1.4741e-07, 1.7438e-04, 8.5249e-06, 2.7762e-03, 2.8263e-04,
        3.3866e-04, 9.8783e-04, 8.1549e-03, 3.4809e-02, 2.6198e-02, 3.7436e-02,
        1.7094e-02, 9.7079e-02, 6.9101e-01, 8.1068e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:29,406][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0337, 0.0698, 0.0572, 0.0486, 0.0634, 0.0532, 0.0572, 0.0732, 0.0602,
        0.0613, 0.0523, 0.0626, 0.0903, 0.0641, 0.0764, 0.0764],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:29,409][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0708, 0.1039, 0.0561, 0.0758, 0.0725, 0.0625, 0.0540, 0.0595, 0.0938,
        0.0441, 0.0568, 0.0705, 0.0433, 0.0541, 0.0333, 0.0489],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:29,413][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([5.8103e-07, 2.7536e-04, 9.8180e-04, 5.7698e-04, 7.4758e-04, 5.7640e-04,
        1.0430e-03, 1.0516e-03, 1.6232e-02, 4.8882e-03, 2.9917e-02, 5.6561e-02,
        2.2493e-02, 2.1984e-01, 1.3408e-01, 4.4814e-02, 4.6592e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:29,419][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0824, 0.0178, 0.1304, 0.0873, 0.0945, 0.0346, 0.0528, 0.1385, 0.0374,
        0.0309, 0.0170, 0.0389, 0.0318, 0.0487, 0.0929, 0.0183, 0.0461],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:29,420][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([7.4008e-15, 2.3364e-14, 4.6142e-12, 8.6371e-12, 1.5923e-10, 1.7255e-10,
        5.8626e-11, 1.3338e-09, 1.8048e-07, 2.3150e-06, 4.7944e-05, 2.3676e-05,
        7.8200e-05, 3.9499e-04, 1.0176e-01, 4.3310e-01, 4.6459e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:29,421][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0191, 0.0116, 0.0335, 0.0077, 0.0490, 0.0325, 0.0192, 0.0392, 0.0248,
        0.1067, 0.0521, 0.0343, 0.1391, 0.0368, 0.1704, 0.1694, 0.0547],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:29,422][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([2.1210e-08, 1.4461e-07, 3.6898e-06, 1.2485e-06, 1.7773e-05, 4.9581e-06,
        3.5674e-06, 1.0954e-04, 5.7866e-05, 3.3570e-04, 9.1270e-04, 9.6198e-04,
        1.2000e-03, 8.1608e-03, 2.8398e-01, 4.8508e-01, 2.1917e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:29,425][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0222, 0.1910, 0.1534, 0.0897, 0.0351, 0.0877, 0.0034, 0.0222, 0.0208,
        0.0462, 0.0203, 0.0262, 0.0613, 0.0756, 0.1132, 0.0298, 0.0020],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:29,431][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0019, 0.0204, 0.1019, 0.0248, 0.0993, 0.0490, 0.0177, 0.0619, 0.0292,
        0.0908, 0.0285, 0.0212, 0.1756, 0.0073, 0.1438, 0.1082, 0.0183],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:29,435][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0684, 0.0563, 0.0470, 0.0531, 0.0521, 0.0555, 0.0535, 0.0547, 0.0595,
        0.0709, 0.0584, 0.0618, 0.0674, 0.0681, 0.0497, 0.0637, 0.0599],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:29,436][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0286, 0.0493, 0.0298, 0.0588, 0.0458, 0.1145, 0.0340, 0.0650, 0.0712,
        0.0687, 0.0940, 0.0412, 0.0694, 0.0426, 0.0277, 0.1331, 0.0264],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:29,437][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.5059e-04, 1.4970e-10, 4.9060e-07, 1.2460e-08, 1.1308e-05, 9.8089e-07,
        6.8251e-07, 9.3785e-06, 1.0665e-04, 1.1671e-03, 2.2056e-04, 5.7138e-04,
        1.4342e-03, 1.5162e-02, 1.2752e-01, 2.1076e-02, 8.3257e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:29,438][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0317, 0.0649, 0.0523, 0.0450, 0.0591, 0.0492, 0.0533, 0.0681, 0.0554,
        0.0565, 0.0478, 0.0584, 0.0852, 0.0601, 0.0716, 0.0710, 0.0705],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:29,441][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0646, 0.0941, 0.0519, 0.0695, 0.0652, 0.0582, 0.0502, 0.0557, 0.0824,
        0.0429, 0.0538, 0.0691, 0.0437, 0.0532, 0.0332, 0.0494, 0.0628],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:29,445][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([1.6668e-05, 1.4092e-03, 2.3982e-03, 2.1667e-03, 1.8814e-03, 2.6178e-03,
        3.8509e-03, 3.2554e-03, 2.9296e-02, 7.4956e-03, 4.0349e-02, 7.1413e-02,
        2.7600e-02, 1.9233e-01, 1.0845e-01, 7.3283e-02, 3.1528e-01, 1.1691e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:29,451][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([0.0626, 0.0062, 0.0264, 0.1788, 0.0047, 0.0030, 0.1613, 0.0056, 0.0059,
        0.0043, 0.0017, 0.0429, 0.0075, 0.0770, 0.0160, 0.0071, 0.3803, 0.0085],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:29,453][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([8.5336e-16, 5.5831e-15, 1.5812e-12, 1.4451e-12, 6.8785e-11, 1.3478e-11,
        1.1502e-10, 2.7994e-10, 6.9366e-09, 3.6397e-07, 1.3754e-06, 2.9919e-06,
        3.0538e-05, 1.2402e-04, 3.0907e-02, 1.6763e-02, 5.7602e-01, 3.7616e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:29,454][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([0.0184, 0.0105, 0.0267, 0.0067, 0.0369, 0.0292, 0.0173, 0.0309, 0.0203,
        0.0821, 0.0440, 0.0295, 0.1039, 0.0313, 0.1235, 0.1316, 0.0473, 0.2096],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:29,455][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([1.5073e-08, 1.1777e-07, 6.5321e-07, 1.0163e-06, 4.3900e-06, 8.3173e-06,
        6.9694e-06, 2.7391e-05, 6.7631e-05, 5.4882e-04, 5.0948e-04, 1.2781e-03,
        3.2898e-03, 8.0040e-03, 7.6158e-02, 1.8316e-01, 5.9476e-01, 1.3217e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:29,459][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([0.0108, 0.1614, 0.0749, 0.0836, 0.0215, 0.0470, 0.0274, 0.0782, 0.0427,
        0.0914, 0.0464, 0.0332, 0.1198, 0.0576, 0.0476, 0.0326, 0.0222, 0.0017],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:29,464][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([0.0033, 0.0202, 0.1336, 0.0153, 0.1398, 0.0266, 0.0110, 0.0436, 0.0186,
        0.0676, 0.0178, 0.0132, 0.1531, 0.0043, 0.0980, 0.0655, 0.0105, 0.1579],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:29,468][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([0.0488, 0.0616, 0.0480, 0.0528, 0.0487, 0.0563, 0.0514, 0.0533, 0.0528,
        0.0675, 0.0545, 0.0571, 0.0646, 0.0638, 0.0466, 0.0620, 0.0531, 0.0572],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:29,469][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([0.0321, 0.0475, 0.0242, 0.0536, 0.0439, 0.1139, 0.0448, 0.0765, 0.0721,
        0.0632, 0.0747, 0.0413, 0.0782, 0.0436, 0.0238, 0.0926, 0.0409, 0.0332],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:29,470][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([4.8560e-05, 7.1544e-10, 2.2571e-06, 4.3061e-08, 2.3363e-05, 3.5162e-06,
        2.9438e-06, 1.7572e-05, 1.0188e-04, 2.3130e-03, 6.3244e-04, 1.8810e-03,
        1.5472e-03, 1.1125e-02, 6.1881e-02, 1.4421e-02, 7.5978e-01, 1.4622e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:29,471][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([0.0262, 0.0592, 0.0478, 0.0402, 0.0529, 0.0447, 0.0478, 0.0634, 0.0512,
        0.0522, 0.0441, 0.0529, 0.0789, 0.0548, 0.0658, 0.0666, 0.0640, 0.0874],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:29,475][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([0.0670, 0.0899, 0.0502, 0.0652, 0.0637, 0.0536, 0.0460, 0.0521, 0.0807,
        0.0395, 0.0506, 0.0610, 0.0391, 0.0489, 0.0304, 0.0444, 0.0559, 0.0617],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:29,478][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([4.1439e-09, 2.1904e-06, 2.3995e-05, 6.1005e-06, 2.0712e-05, 9.2382e-06,
        1.1281e-05, 1.6816e-05, 1.4034e-04, 1.0825e-04, 5.3490e-04, 7.8659e-04,
        5.7350e-04, 4.5653e-03, 6.2587e-03, 1.4900e-03, 1.5471e-02, 1.0169e-02,
        9.5981e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:29,484][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0446, 0.0063, 0.0331, 0.0995, 0.0273, 0.0052, 0.1635, 0.0115, 0.0235,
        0.0075, 0.0046, 0.0879, 0.0166, 0.0477, 0.0204, 0.0218, 0.2744, 0.0281,
        0.0767], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:29,485][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.0956e-15, 6.2820e-16, 8.0716e-14, 1.3409e-13, 2.4182e-12, 5.9839e-12,
        1.2717e-11, 2.8844e-11, 1.1880e-09, 1.0885e-07, 1.3054e-07, 5.0422e-07,
        1.2873e-06, 4.3573e-06, 1.4488e-03, 9.9990e-03, 7.6463e-02, 3.7709e-01,
        5.3499e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:29,486][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0106, 0.0071, 0.0209, 0.0054, 0.0335, 0.0241, 0.0138, 0.0264, 0.0184,
        0.0790, 0.0398, 0.0258, 0.1072, 0.0268, 0.1239, 0.1383, 0.0431, 0.2125,
        0.0434], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:29,488][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([4.7998e-09, 2.0087e-08, 1.8440e-07, 1.2417e-07, 1.3085e-06, 4.0651e-06,
        9.1065e-07, 5.6565e-06, 9.6536e-06, 2.5498e-04, 9.6206e-05, 1.3835e-04,
        2.6689e-04, 7.0406e-04, 1.8025e-02, 2.6182e-01, 6.8720e-02, 3.8754e-01,
        2.6241e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:29,492][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0186, 0.1237, 0.1082, 0.1270, 0.0531, 0.0954, 0.0126, 0.0711, 0.0360,
        0.0369, 0.0272, 0.0295, 0.0510, 0.0323, 0.0785, 0.0591, 0.0098, 0.0264,
        0.0034], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:29,498][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0024, 0.0190, 0.0886, 0.0212, 0.0808, 0.0423, 0.0156, 0.0509, 0.0240,
        0.0724, 0.0235, 0.0181, 0.1369, 0.0071, 0.1145, 0.0860, 0.0156, 0.1654,
        0.0156], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:29,500][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0671, 0.0482, 0.0418, 0.0460, 0.0467, 0.0481, 0.0465, 0.0492, 0.0526,
        0.0629, 0.0507, 0.0535, 0.0598, 0.0588, 0.0456, 0.0559, 0.0530, 0.0543,
        0.0594], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:29,501][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0278, 0.0459, 0.0324, 0.0501, 0.0458, 0.0985, 0.0466, 0.0598, 0.0609,
        0.0506, 0.0635, 0.0421, 0.0647, 0.0430, 0.0322, 0.1193, 0.0432, 0.0450,
        0.0285], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:29,502][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.5513e-02, 7.9861e-09, 3.1013e-06, 3.6472e-07, 1.0946e-04, 4.4992e-06,
        5.6213e-06, 8.9507e-05, 1.4573e-03, 1.8148e-03, 3.7049e-04, 1.9127e-04,
        2.9708e-03, 2.1210e-02, 2.5767e-01, 4.8895e-02, 2.3123e-01, 2.2244e-01,
        1.8603e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:29,504][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0296, 0.0562, 0.0451, 0.0386, 0.0514, 0.0419, 0.0458, 0.0585, 0.0480,
        0.0489, 0.0411, 0.0505, 0.0730, 0.0516, 0.0616, 0.0607, 0.0608, 0.0813,
        0.0553], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:29,510][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0619, 0.0884, 0.0454, 0.0612, 0.0544, 0.0513, 0.0451, 0.0485, 0.0664,
        0.0350, 0.0465, 0.0585, 0.0370, 0.0452, 0.0257, 0.0416, 0.0521, 0.0562,
        0.0796], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:29,514][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:29,516][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 9961],
        [ 2367],
        [ 3855],
        [ 8728],
        [  727],
        [ 8955],
        [ 3892],
        [ 4516],
        [15613],
        [14372],
        [ 4817],
        [ 3531],
        [10133],
        [ 5074],
        [12661],
        [ 5265],
        [ 4690],
        [ 2116],
        [ 7012]], device='cuda:0')
[2024-07-24 10:27:29,519][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[21499],
        [ 8461],
        [ 8533],
        [16583],
        [  328],
        [38691],
        [23552],
        [20107],
        [30052],
        [34635],
        [33557],
        [18656],
        [29421],
        [20143],
        [19613],
        [27851],
        [24875],
        [ 3325],
        [21720]], device='cuda:0')
[2024-07-24 10:27:29,520][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[  315],
        [ 1936],
        [ 5539],
        [18593],
        [19368],
        [28367],
        [10901],
        [14459],
        [28811],
        [15545],
        [26400],
        [17294],
        [17820],
        [13789],
        [14294],
        [23484],
        [17675],
        [17769],
        [21665]], device='cuda:0')
[2024-07-24 10:27:29,522][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[16436],
        [16341],
        [ 5451],
        [14700],
        [17730],
        [11701],
        [ 2565],
        [13769],
        [21614],
        [21187],
        [  241],
        [  689],
        [ 6622],
        [  964],
        [25984],
        [  955],
        [   56],
        [29989],
        [ 5935]], device='cuda:0')
[2024-07-24 10:27:29,525][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 9666],
        [ 8057],
        [12464],
        [15121],
        [10953],
        [12062],
        [14539],
        [18281],
        [25095],
        [22100],
        [22697],
        [23000],
        [23678],
        [22006],
        [21238],
        [19283],
        [18821],
        [19606],
        [19256]], device='cuda:0')
[2024-07-24 10:27:29,527][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[30348],
        [30525],
        [29127],
        [28043],
        [25835],
        [23808],
        [24088],
        [23605],
        [23265],
        [22902],
        [22874],
        [23942],
        [24849],
        [24696],
        [24584],
        [24352],
        [24545],
        [24714],
        [24865]], device='cuda:0')
[2024-07-24 10:27:29,530][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[17472],
        [17602],
        [17965],
        [16885],
        [11621],
        [13149],
        [12105],
        [ 8072],
        [ 4475],
        [ 6058],
        [ 6985],
        [ 8434],
        [ 7756],
        [ 6696],
        [ 8350],
        [ 9571],
        [ 8981],
        [ 8793],
        [ 9774]], device='cuda:0')
[2024-07-24 10:27:29,533][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[26408],
        [26095],
        [32509],
        [33821],
        [31578],
        [26958],
        [20869],
        [20041],
        [16146],
        [16831],
        [20066],
        [23463],
        [25968],
        [24807],
        [28205],
        [27042],
        [27699],
        [29601],
        [31274]], device='cuda:0')
[2024-07-24 10:27:29,535][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[30950],
        [33889],
        [33769],
        [33774],
        [33994],
        [33072],
        [32383],
        [33713],
        [34376],
        [35322],
        [35875],
        [36213],
        [36373],
        [36329],
        [36727],
        [36535],
        [36571],
        [37291],
        [37613]], device='cuda:0')
[2024-07-24 10:27:29,537][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[1391],
        [ 956],
        [ 841],
        [ 885],
        [ 860],
        [ 857],
        [ 905],
        [ 845],
        [ 841],
        [ 856],
        [ 876],
        [ 872],
        [ 891],
        [ 935],
        [1000],
        [1034],
        [1093],
        [1075],
        [1112]], device='cuda:0')
[2024-07-24 10:27:29,539][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[34039],
        [33847],
        [19033],
        [32618],
        [41201],
        [43966],
        [42200],
        [40919],
        [42421],
        [41865],
        [38284],
        [34566],
        [33120],
        [30766],
        [35317],
        [41554],
        [47385],
        [37763],
        [45521]], device='cuda:0')
[2024-07-24 10:27:29,541][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[24308],
        [26731],
        [33692],
        [34003],
        [40144],
        [42118],
        [41134],
        [40873],
        [40317],
        [40309],
        [40563],
        [40654],
        [41068],
        [41381],
        [41469],
        [41637],
        [41738],
        [41398],
        [41530]], device='cuda:0')
[2024-07-24 10:27:29,544][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 8476],
        [ 9299],
        [ 9932],
        [ 9431],
        [10701],
        [ 9749],
        [10054],
        [ 9761],
        [ 9677],
        [ 9229],
        [ 8647],
        [ 9436],
        [ 7703],
        [ 7724],
        [ 8109],
        [ 8306],
        [ 8552],
        [ 9563],
        [ 8882]], device='cuda:0')
[2024-07-24 10:27:29,546][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[17053],
        [19963],
        [24986],
        [26641],
        [30731],
        [27558],
        [26328],
        [23396],
        [22877],
        [23024],
        [22317],
        [22538],
        [22320],
        [22463],
        [23434],
        [23061],
        [22486],
        [23442],
        [23522]], device='cuda:0')
[2024-07-24 10:27:29,549][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 8488],
        [ 2889],
        [16168],
        [11864],
        [12391],
        [ 1293],
        [ 3248],
        [ 3613],
        [ 2526],
        [ 2404],
        [ 2532],
        [ 2887],
        [ 1308],
        [ 6846],
        [ 5668],
        [ 1982],
        [ 1977],
        [ 7779],
        [ 3349]], device='cuda:0')
[2024-07-24 10:27:29,552][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 5810],
        [14334],
        [11053],
        [ 9890],
        [10680],
        [10404],
        [11721],
        [11403],
        [14309],
        [14469],
        [13636],
        [13548],
        [14290],
        [18935],
        [17008],
        [16968],
        [13579],
        [14020],
        [12661]], device='cuda:0')
[2024-07-24 10:27:29,554][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 7163],
        [ 7009],
        [12786],
        [ 6310],
        [ 6865],
        [ 6915],
        [ 9325],
        [ 5406],
        [ 6137],
        [ 5287],
        [11929],
        [ 5888],
        [10135],
        [ 7647],
        [ 4819],
        [28966],
        [25363],
        [ 6128],
        [ 5455]], device='cuda:0')
[2024-07-24 10:27:29,556][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[17983],
        [11486],
        [14250],
        [10908],
        [ 7235],
        [ 8097],
        [ 6071],
        [ 5193],
        [ 1019],
        [ 6855],
        [ 1195],
        [  829],
        [ 6015],
        [ 2968],
        [13064],
        [10319],
        [ 7372],
        [13440],
        [ 8843]], device='cuda:0')
[2024-07-24 10:27:29,558][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[17790],
        [20982],
        [22664],
        [22396],
        [22219],
        [21636],
        [21048],
        [20180],
        [19688],
        [19012],
        [18616],
        [18117],
        [17544],
        [17458],
        [18005],
        [18499],
        [18457],
        [18795],
        [18691]], device='cuda:0')
[2024-07-24 10:27:29,560][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[13156],
        [10789],
        [13186],
        [11254],
        [26017],
        [14618],
        [23762],
        [ 9699],
        [ 6757],
        [12214],
        [18209],
        [ 8274],
        [ 9777],
        [ 7304],
        [16157],
        [ 3792],
        [ 3867],
        [ 6152],
        [ 7994]], device='cuda:0')
[2024-07-24 10:27:29,562][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[13727],
        [ 5139],
        [ 5145],
        [ 5824],
        [ 5146],
        [ 5277],
        [ 5184],
        [ 4917],
        [ 5139],
        [ 5478],
        [ 5629],
        [ 5548],
        [ 5055],
        [ 4803],
        [ 4323],
        [ 4690],
        [ 4708],
        [ 4283],
        [ 4730]], device='cuda:0')
[2024-07-24 10:27:29,565][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 5952],
        [10061],
        [ 9358],
        [ 9796],
        [ 9855],
        [10334],
        [10788],
        [10562],
        [10946],
        [10861],
        [11193],
        [11326],
        [11487],
        [12088],
        [11276],
        [11634],
        [11907],
        [11947],
        [12353]], device='cuda:0')
[2024-07-24 10:27:29,568][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[26668],
        [29198],
        [29254],
        [32001],
        [29651],
        [31260],
        [34525],
        [32660],
        [33867],
        [31461],
        [32574],
        [33927],
        [32493],
        [34040],
        [33298],
        [33225],
        [33540],
        [32356],
        [32828]], device='cuda:0')
[2024-07-24 10:27:29,570][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[18016],
        [18648],
        [18703],
        [19501],
        [19759],
        [17804],
        [17562],
        [17587],
        [18266],
        [17634],
        [18359],
        [18772],
        [19118],
        [19055],
        [18993],
        [19176],
        [18846],
        [19031],
        [19246]], device='cuda:0')
[2024-07-24 10:27:29,573][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[14283],
        [14283],
        [ 4657],
        [ 9190],
        [11055],
        [ 5196],
        [ 4536],
        [ 4652],
        [12266],
        [ 3434],
        [ 3721],
        [ 2634],
        [ 4120],
        [ 7295],
        [ 4021],
        [ 4125],
        [ 9160],
        [ 8551],
        [ 7185]], device='cuda:0')
[2024-07-24 10:27:29,575][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[8128],
        [8468],
        [7128],
        [6931],
        [6251],
        [6111],
        [6048],
        [5999],
        [5976],
        [5897],
        [5885],
        [5964],
        [5951],
        [6020],
        [6061],
        [6082],
        [6127],
        [6093],
        [6182]], device='cuda:0')
[2024-07-24 10:27:29,577][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[13238],
        [13157],
        [12982],
        [12755],
        [12293],
        [12003],
        [11875],
        [11485],
        [11545],
        [11468],
        [11518],
        [11638],
        [11381],
        [11349],
        [11328],
        [11051],
        [10915],
        [10935],
        [11082]], device='cuda:0')
[2024-07-24 10:27:29,579][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[26031],
        [25603],
        [27578],
        [27278],
        [23885],
        [28269],
        [26435],
        [32195],
        [30742],
        [31409],
        [30834],
        [34630],
        [30500],
        [31631],
        [28595],
        [30829],
        [30168],
        [28960],
        [29095]], device='cuda:0')
[2024-07-24 10:27:29,581][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[38350],
        [39839],
        [28857],
        [34805],
        [35661],
        [39700],
        [33696],
        [37611],
        [44778],
        [42597],
        [44340],
        [45560],
        [39759],
        [40402],
        [43584],
        [35251],
        [37798],
        [39152],
        [44672]], device='cuda:0')
[2024-07-24 10:27:29,583][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063]], device='cuda:0')
[2024-07-24 10:27:29,620][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:29,621][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:29,622][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:29,623][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:29,623][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:29,624][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:29,625][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:29,625][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:29,626][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:29,627][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:29,627][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:29,628][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:29,629][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:29,629][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8474, 0.1526], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:29,630][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.6326, 0.3674], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:29,631][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3661, 0.6339], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:29,631][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4089, 0.5911], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:29,636][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6540, 0.3460], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:29,640][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9387, 0.0613], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:29,644][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4173, 0.5827], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:29,645][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3181, 0.6819], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:29,645][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0635, 0.9365], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:29,646][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3350, 0.6650], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:29,649][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.6495, 0.3505], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:29,654][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.5424, 0.4576], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:29,659][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.6858, 0.1212, 0.1930], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,660][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.5235, 0.2362, 0.2402], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,661][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([1.2480e-07, 1.0000e+00, 2.0093e-07], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,662][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0945, 0.7757, 0.1298], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,663][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.4861, 0.2557, 0.2582], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,667][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.1870, 0.7469, 0.0661], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,672][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.0160, 0.8173, 0.1667], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,675][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.1048, 0.3399, 0.5552], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,676][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.0549, 0.3438, 0.6013], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,677][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0336, 0.8849, 0.0816], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,678][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.4452, 0.3159, 0.2389], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,681][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.3225, 0.0600, 0.6175], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:29,687][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.5375, 0.0860, 0.1504, 0.2261], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,691][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2860, 0.2048, 0.2650, 0.2442], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,691][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([1.8631e-04, 9.9756e-01, 2.6934e-07, 2.2503e-03], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,692][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1390, 0.5549, 0.1651, 0.1410], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,693][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3780, 0.2045, 0.2078, 0.2097], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,694][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1273, 0.0859, 0.7553, 0.0314], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,699][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0075, 0.6791, 0.2637, 0.0497], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,705][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0813, 0.2114, 0.3550, 0.3522], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,707][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0164, 0.2067, 0.5604, 0.2164], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,707][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0071, 0.8913, 0.0398, 0.0618], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,708][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.3689, 0.2380, 0.1704, 0.2226], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,709][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2117, 0.0636, 0.4862, 0.2385], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:29,712][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.3964, 0.0873, 0.1316, 0.2120, 0.1727], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,718][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([0.2057, 0.1702, 0.1996, 0.1999, 0.2246], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,722][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([2.1284e-09, 9.8832e-01, 2.7339e-07, 1.1675e-02, 3.6422e-09],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,723][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.0603, 0.3125, 0.1659, 0.1230, 0.3383], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,724][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.3095, 0.1676, 0.1713, 0.1730, 0.1785], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,724][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([0.1997, 0.2323, 0.0842, 0.3703, 0.1135], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,726][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.0036, 0.6242, 0.1527, 0.1658, 0.0537], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,731][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.0702, 0.1811, 0.2487, 0.2729, 0.2271], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,736][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.0315, 0.2024, 0.4018, 0.1929, 0.1714], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,739][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.0040, 0.7371, 0.0377, 0.1982, 0.0230], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,739][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.1599, 0.1770, 0.1602, 0.2943, 0.2086], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,740][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([0.1580, 0.0379, 0.3578, 0.1666, 0.2797], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:29,741][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.5162, 0.0428, 0.0903, 0.0964, 0.0856, 0.1687], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,744][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.1810, 0.1705, 0.2080, 0.1454, 0.1871, 0.1080], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,748][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ had] are: tensor([7.4127e-06, 9.7644e-01, 2.1323e-05, 2.3522e-02, 1.4280e-06, 1.0614e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,754][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0275, 0.1786, 0.0884, 0.1193, 0.5580, 0.0282], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,755][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2512, 0.1404, 0.1446, 0.1452, 0.1487, 0.1699], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,756][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1868, 0.1165, 0.2197, 0.0852, 0.3000, 0.0919], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,757][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ had] are: tensor([2.8197e-05, 3.3961e-01, 2.3684e-01, 1.7241e-01, 2.4914e-01, 1.9664e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,758][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0557, 0.1385, 0.2198, 0.2336, 0.2015, 0.1510], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,763][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0046, 0.1308, 0.3834, 0.1708, 0.1844, 0.1260], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,767][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ had] are: tensor([1.9657e-04, 8.7170e-01, 1.7675e-02, 9.9237e-02, 8.8998e-03, 2.2921e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,771][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.1753, 0.1637, 0.1139, 0.2254, 0.1211, 0.2006], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,771][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0999, 0.0270, 0.2887, 0.1239, 0.2417, 0.2188], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:29,772][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.3494, 0.0485, 0.1090, 0.1154, 0.1001, 0.1631, 0.1145],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,773][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1539, 0.1208, 0.1607, 0.1444, 0.1767, 0.1259, 0.1177],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,775][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([5.7540e-08, 9.9805e-01, 1.2883e-07, 1.9512e-03, 3.1026e-09, 7.5289e-08,
        4.1437e-07], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,780][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0430, 0.1460, 0.0372, 0.0376, 0.6569, 0.0590, 0.0202],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,786][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2247, 0.1194, 0.1214, 0.1212, 0.1267, 0.1462, 0.1404],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,787][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0568, 0.0621, 0.5711, 0.0196, 0.2324, 0.0484, 0.0096],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,788][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([1.2347e-05, 4.6134e-01, 1.5656e-01, 2.4875e-01, 1.2978e-01, 2.9066e-03,
        6.4618e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,789][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0480, 0.1229, 0.1895, 0.2020, 0.1667, 0.1333, 0.1377],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,791][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0019, 0.0806, 0.3369, 0.1088, 0.1232, 0.1037, 0.2449],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,795][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([7.5604e-05, 5.5866e-01, 4.7771e-02, 3.3384e-01, 4.9015e-02, 8.5068e-03,
        2.1333e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,801][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1313, 0.1525, 0.1092, 0.1958, 0.1253, 0.1394, 0.1465],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,803][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0820, 0.0243, 0.2422, 0.1095, 0.2124, 0.1919, 0.1376],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:29,804][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.3262, 0.0227, 0.1205, 0.1376, 0.1060, 0.1089, 0.1202, 0.0579],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,804][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.1689, 0.0881, 0.1320, 0.1364, 0.1386, 0.1203, 0.1137, 0.1019],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,805][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([8.6992e-08, 9.8534e-01, 1.2198e-06, 1.4643e-02, 4.1524e-08, 4.9693e-07,
        1.1574e-05, 3.6700e-07], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,809][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0249, 0.0893, 0.0382, 0.0457, 0.6882, 0.0242, 0.0678, 0.0217],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,815][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.2016, 0.1028, 0.1049, 0.1057, 0.1120, 0.1291, 0.1226, 0.1214],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,819][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0604, 0.1415, 0.4856, 0.0615, 0.0701, 0.0563, 0.0748, 0.0498],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,819][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([8.6561e-06, 4.2940e-01, 1.2718e-01, 3.0262e-01, 1.3677e-01, 2.3908e-03,
        1.5775e-03, 4.0226e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,820][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0353, 0.1027, 0.1910, 0.1891, 0.1522, 0.1093, 0.1175, 0.1031],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,821][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0019, 0.0659, 0.2869, 0.1096, 0.1215, 0.0867, 0.2289, 0.0986],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,822][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([7.5396e-05, 5.9859e-01, 4.8946e-02, 3.1300e-01, 2.8407e-02, 7.5302e-03,
        3.2912e-03, 1.5908e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,827][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0992, 0.1160, 0.1122, 0.1573, 0.1277, 0.1584, 0.1638, 0.0654],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,833][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.1046, 0.0185, 0.1687, 0.0934, 0.1728, 0.1422, 0.1259, 0.1739],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:29,835][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.2845, 0.0401, 0.0751, 0.1426, 0.0850, 0.1159, 0.0868, 0.0692, 0.1007],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,836][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.1207, 0.1228, 0.1487, 0.1197, 0.1273, 0.0924, 0.0908, 0.0859, 0.0918],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,837][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ of] are: tensor([8.1522e-09, 9.9910e-01, 1.5588e-07, 8.9363e-04, 4.4067e-09, 5.2646e-08,
        3.5042e-07, 4.0086e-08, 2.9072e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,838][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0246, 0.0759, 0.0487, 0.0293, 0.4024, 0.0355, 0.0218, 0.3489, 0.0130],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,842][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1835, 0.0943, 0.0952, 0.0954, 0.0985, 0.1159, 0.1105, 0.1070, 0.0997],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,847][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0176, 0.0157, 0.4244, 0.0057, 0.4507, 0.0098, 0.0071, 0.0639, 0.0050],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,851][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ of] are: tensor([6.2310e-05, 5.5145e-01, 1.0233e-01, 2.1969e-01, 1.0747e-01, 2.8002e-03,
        1.5715e-03, 1.1157e-04, 1.4507e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,852][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0262, 0.0934, 0.1715, 0.1598, 0.1375, 0.1023, 0.1039, 0.0893, 0.1161],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,853][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0036, 0.0876, 0.2810, 0.0840, 0.0928, 0.0786, 0.1966, 0.0887, 0.0871],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,853][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ of] are: tensor([2.3977e-04, 6.7554e-01, 4.2938e-02, 2.3535e-01, 2.1447e-02, 3.4216e-03,
        1.6774e-03, 2.1709e-04, 1.9167e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,857][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.1175, 0.1496, 0.0811, 0.1521, 0.1006, 0.0941, 0.0918, 0.0525, 0.1607],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,861][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0645, 0.0162, 0.1472, 0.0712, 0.1334, 0.1238, 0.0997, 0.1613, 0.1827],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:29,867][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.1248, 0.0268, 0.1209, 0.1456, 0.0714, 0.1205, 0.1539, 0.0742, 0.0454,
        0.1165], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,868][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.1551, 0.0912, 0.1094, 0.1092, 0.1107, 0.0963, 0.0858, 0.0908, 0.0798,
        0.0717], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,869][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([4.2845e-11, 9.8873e-01, 2.5742e-07, 1.1261e-02, 8.3755e-09, 2.2803e-08,
        3.7377e-06, 7.1683e-08, 4.2301e-06, 2.9160e-10], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,870][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0429, 0.1057, 0.0372, 0.0675, 0.5166, 0.0642, 0.0222, 0.1035, 0.0332,
        0.0070], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,873][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.1699, 0.0810, 0.0851, 0.0862, 0.0926, 0.1060, 0.0990, 0.1005, 0.0904,
        0.0892], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,879][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0194, 0.2353, 0.1542, 0.1592, 0.0835, 0.0794, 0.0839, 0.0460, 0.1086,
        0.0305], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,883][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([8.5497e-05, 4.7740e-01, 1.2642e-01, 2.2638e-01, 1.4025e-01, 3.7712e-03,
        9.0729e-04, 1.8191e-04, 2.1509e-02, 3.0871e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,884][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0202, 0.0801, 0.1684, 0.1595, 0.1281, 0.0859, 0.0912, 0.0763, 0.1040,
        0.0863], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,885][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([1.6597e-04, 2.9453e-02, 2.2374e-01, 7.3440e-02, 9.1923e-02, 6.5217e-02,
        1.8077e-01, 9.8977e-02, 9.9164e-02, 1.3715e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,886][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([4.6414e-04, 6.1055e-01, 3.3390e-02, 2.1469e-01, 2.5435e-02, 3.2109e-02,
        3.2661e-03, 4.0695e-04, 7.2816e-02, 6.8688e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,890][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0459, 0.0698, 0.0575, 0.1142, 0.0816, 0.1282, 0.1566, 0.0443, 0.2613,
        0.0406], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,895][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0677, 0.0108, 0.1016, 0.0562, 0.0998, 0.0852, 0.0790, 0.1233, 0.1615,
        0.2149], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:29,900][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.2276, 0.0394, 0.0714, 0.1181, 0.0647, 0.0956, 0.1105, 0.0754, 0.0461,
        0.0591, 0.0921], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,900][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.1074, 0.0934, 0.1131, 0.1016, 0.1110, 0.0864, 0.0841, 0.0754, 0.0798,
        0.0720, 0.0756], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,901][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ at] are: tensor([2.8123e-09, 9.9631e-01, 6.2490e-07, 3.6779e-03, 2.4326e-08, 1.3029e-07,
        1.5208e-06, 1.7220e-07, 1.0597e-05, 2.4685e-09, 2.4014e-07],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,902][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0268, 0.1751, 0.0572, 0.0504, 0.3315, 0.0565, 0.0364, 0.1568, 0.0458,
        0.0455, 0.0181], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,906][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1497, 0.0774, 0.0817, 0.0822, 0.0858, 0.0975, 0.0924, 0.0911, 0.0849,
        0.0807, 0.0767], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,910][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0178, 0.0030, 0.1777, 0.0065, 0.1001, 0.0108, 0.0049, 0.0146, 0.0042,
        0.6593, 0.0013], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,914][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ at] are: tensor([1.3173e-04, 4.3101e-01, 2.0189e-01, 1.6620e-01, 1.6384e-01, 3.1561e-03,
        1.6034e-03, 1.9404e-04, 1.6223e-02, 8.5131e-03, 7.2281e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,916][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0160, 0.0641, 0.1593, 0.1505, 0.1122, 0.0720, 0.0803, 0.0739, 0.1031,
        0.0825, 0.0861], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,917][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ at] are: tensor([1.0392e-04, 3.4922e-02, 1.8289e-01, 5.1053e-02, 4.5317e-02, 5.4664e-02,
        1.7241e-01, 9.5327e-02, 8.0227e-02, 2.0904e-01, 7.4048e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,918][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ at] are: tensor([7.5616e-04, 5.5018e-01, 3.3032e-02, 2.2924e-01, 7.8800e-02, 4.6180e-03,
        3.6009e-03, 1.9497e-04, 5.4674e-02, 2.9240e-02, 1.5666e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,921][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1230, 0.1113, 0.0574, 0.1099, 0.0643, 0.0712, 0.0674, 0.0378, 0.1157,
        0.0390, 0.2032], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,927][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0400, 0.0081, 0.0740, 0.0421, 0.0679, 0.0688, 0.0579, 0.1006, 0.1268,
        0.1971, 0.2167], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:29,932][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1356, 0.0235, 0.0317, 0.0436, 0.0235, 0.0633, 0.0269, 0.0271, 0.0301,
        0.1017, 0.3469, 0.1461], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,932][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0752, 0.0830, 0.1206, 0.0993, 0.1096, 0.0792, 0.0734, 0.0663, 0.0721,
        0.0731, 0.0713, 0.0768], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,933][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ the] are: tensor([6.2108e-09, 9.9702e-01, 4.5692e-07, 2.9646e-03, 2.1795e-08, 1.3464e-07,
        1.2861e-06, 1.4534e-07, 9.0702e-06, 2.5271e-09, 2.1834e-07, 1.9694e-07],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,934][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0433, 0.0933, 0.0498, 0.0238, 0.4514, 0.0437, 0.0168, 0.1635, 0.0240,
        0.0377, 0.0269, 0.0257], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,937][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1421, 0.0721, 0.0749, 0.0750, 0.0786, 0.0908, 0.0860, 0.0845, 0.0779,
        0.0738, 0.0699, 0.0745], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,943][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0133, 0.0091, 0.4417, 0.0065, 0.1044, 0.0109, 0.0024, 0.0155, 0.0154,
        0.3732, 0.0062, 0.0013], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,947][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ the] are: tensor([7.7354e-05, 4.1324e-01, 2.3020e-01, 1.5361e-01, 1.6265e-01, 2.1395e-03,
        9.8805e-04, 1.0614e-04, 1.3655e-02, 8.4027e-03, 1.0139e-02, 4.7894e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,949][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0196, 0.0588, 0.1321, 0.1384, 0.1047, 0.0688, 0.0824, 0.0742, 0.0983,
        0.0802, 0.0944, 0.0480], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,950][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0008, 0.0357, 0.1742, 0.0536, 0.0630, 0.0447, 0.1163, 0.0768, 0.0790,
        0.1237, 0.0894, 0.1429], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,951][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ the] are: tensor([3.7999e-04, 5.1430e-01, 5.2194e-02, 2.3063e-01, 7.0955e-02, 5.6815e-03,
        1.4986e-03, 4.4090e-04, 4.1866e-02, 3.2169e-02, 4.0288e-02, 9.5978e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,952][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0746, 0.0777, 0.0595, 0.0949, 0.0652, 0.0726, 0.0700, 0.0364, 0.1124,
        0.0371, 0.1760, 0.1236], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,956][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0336, 0.0064, 0.0652, 0.0324, 0.0649, 0.0554, 0.0459, 0.0762, 0.0995,
        0.1696, 0.1969, 0.1539], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:29,961][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.2077, 0.0387, 0.1322, 0.1141, 0.0880, 0.0952, 0.1211, 0.0624, 0.0355,
        0.0152, 0.0152, 0.0329, 0.0418], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,965][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.1133, 0.0572, 0.0786, 0.0862, 0.0857, 0.0904, 0.0782, 0.0799, 0.0666,
        0.0629, 0.0637, 0.0788, 0.0586], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,966][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ store] are: tensor([5.1784e-10, 9.9018e-01, 1.4182e-07, 9.8114e-03, 2.1664e-09, 1.7406e-08,
        1.6082e-06, 4.5964e-08, 3.4172e-06, 1.0205e-10, 1.1118e-07, 1.3262e-07,
        1.5273e-09], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,967][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0279, 0.1306, 0.0344, 0.0528, 0.3843, 0.0546, 0.0503, 0.0527, 0.0562,
        0.0099, 0.0973, 0.0377, 0.0112], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,968][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.1272, 0.0658, 0.0686, 0.0698, 0.0735, 0.0834, 0.0781, 0.0795, 0.0716,
        0.0713, 0.0659, 0.0702, 0.0751], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,972][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0041, 0.0799, 0.1813, 0.0980, 0.0405, 0.0690, 0.1114, 0.0101, 0.0949,
        0.0385, 0.1274, 0.1094, 0.0355], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,975][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ store] are: tensor([1.7854e-05, 3.8462e-01, 1.0552e-01, 2.9584e-01, 1.3849e-01, 2.9598e-03,
        1.1012e-03, 1.8432e-04, 3.5662e-02, 8.0288e-03, 1.7228e-02, 9.1149e-03,
        1.2282e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,981][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0178, 0.0577, 0.1183, 0.1271, 0.1021, 0.0686, 0.0806, 0.0713, 0.0924,
        0.0804, 0.0855, 0.0478, 0.0503], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,982][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ store] are: tensor([6.3027e-06, 9.4708e-03, 1.2905e-01, 3.1530e-02, 5.1278e-02, 4.7956e-02,
        1.0854e-01, 5.5246e-02, 6.3008e-02, 1.3721e-01, 1.0683e-01, 2.1175e-01,
        4.8136e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,983][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ store] are: tensor([4.9072e-04, 4.9103e-01, 5.1853e-02, 2.1333e-01, 3.5191e-02, 9.9045e-03,
        3.2561e-03, 5.2672e-04, 9.5546e-02, 1.9348e-02, 6.0416e-02, 1.8576e-02,
        5.2859e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,984][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0331, 0.0488, 0.0420, 0.0748, 0.0576, 0.0808, 0.0960, 0.0314, 0.1532,
        0.0267, 0.1849, 0.1358, 0.0348], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,987][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0397, 0.0070, 0.0542, 0.0301, 0.0497, 0.0499, 0.0405, 0.0667, 0.0930,
        0.1253, 0.1687, 0.1358, 0.1395], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:29,993][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.1819, 0.0436, 0.0721, 0.1054, 0.0599, 0.0870, 0.0620, 0.0424, 0.0401,
        0.0228, 0.0397, 0.0404, 0.1021, 0.1006], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:29,997][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0899, 0.0563, 0.0912, 0.0823, 0.0900, 0.0800, 0.0758, 0.0685, 0.0690,
        0.0602, 0.0640, 0.0737, 0.0526, 0.0465], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:29,998][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [.] are: tensor([1.0368e-08, 9.9942e-01, 1.1223e-07, 5.8105e-04, 1.7498e-09, 3.4316e-08,
        1.3442e-07, 2.6554e-08, 1.2202e-06, 3.6062e-10, 3.1383e-08, 3.8635e-08,
        1.2301e-09, 4.5542e-07], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:29,999][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0306, 0.0468, 0.0278, 0.0121, 0.4951, 0.0293, 0.0257, 0.1570, 0.0145,
        0.0353, 0.0071, 0.0195, 0.0943, 0.0049], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,000][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.1220, 0.0633, 0.0653, 0.0666, 0.0676, 0.0791, 0.0743, 0.0726, 0.0669,
        0.0616, 0.0597, 0.0641, 0.0661, 0.0708], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,004][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0115, 0.0061, 0.0960, 0.0055, 0.0436, 0.0176, 0.0129, 0.0112, 0.0120,
        0.4827, 0.0060, 0.0058, 0.2868, 0.0024], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,007][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [.] are: tensor([1.4097e-04, 2.8275e-01, 2.2644e-01, 2.0149e-01, 2.2851e-01, 2.2800e-03,
        1.2481e-03, 1.2237e-04, 9.4908e-03, 1.2337e-02, 8.5789e-03, 1.0731e-02,
        2.5511e-03, 1.3326e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,013][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0202, 0.0560, 0.1041, 0.1168, 0.0964, 0.0671, 0.0796, 0.0705, 0.0854,
        0.0733, 0.0813, 0.0465, 0.0522, 0.0505], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,014][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [.] are: tensor([2.4507e-05, 2.1404e-02, 1.5116e-01, 2.5180e-02, 3.9769e-02, 3.8504e-02,
        1.2335e-01, 6.9655e-02, 6.2089e-02, 1.1477e-01, 6.1846e-02, 2.0277e-01,
        6.4811e-02, 2.4663e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,015][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [.] are: tensor([4.3719e-04, 5.2515e-01, 5.6660e-02, 2.7173e-01, 3.5418e-02, 7.4947e-03,
        2.5165e-03, 4.8600e-04, 2.3564e-02, 1.9944e-02, 1.9271e-02, 1.5044e-02,
        1.7207e-03, 2.0562e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,016][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0760, 0.0688, 0.0433, 0.0816, 0.0572, 0.0616, 0.0604, 0.0314, 0.1005,
        0.0272, 0.1432, 0.0973, 0.0370, 0.1145], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,019][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0221, 0.0037, 0.0418, 0.0230, 0.0405, 0.0362, 0.0324, 0.0521, 0.0703,
        0.1200, 0.1443, 0.1271, 0.1485, 0.1379], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,025][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.1169, 0.0440, 0.0995, 0.1476, 0.1128, 0.0699, 0.0729, 0.0307, 0.0544,
        0.0154, 0.0250, 0.0379, 0.0634, 0.0846, 0.0249], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,029][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0606, 0.0649, 0.0800, 0.0637, 0.0852, 0.0715, 0.0580, 0.0747, 0.0614,
        0.0672, 0.0599, 0.0769, 0.0621, 0.0454, 0.0686], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,030][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([5.6102e-12, 9.8325e-01, 1.1010e-06, 1.6717e-02, 8.5871e-08, 3.9557e-08,
        1.1566e-05, 2.1169e-07, 1.2055e-05, 2.0443e-09, 4.1193e-07, 3.6066e-07,
        4.2945e-08, 4.6717e-06, 4.4575e-11], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,031][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0174, 0.1351, 0.0284, 0.0635, 0.2915, 0.0359, 0.0579, 0.1184, 0.0478,
        0.0140, 0.0545, 0.0402, 0.0492, 0.0333, 0.0127], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,032][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.1170, 0.0588, 0.0600, 0.0609, 0.0630, 0.0739, 0.0704, 0.0686, 0.0640,
        0.0594, 0.0575, 0.0609, 0.0631, 0.0668, 0.0557], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,036][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0211, 0.3288, 0.0236, 0.0335, 0.0974, 0.0912, 0.0195, 0.0132, 0.0967,
        0.0684, 0.0312, 0.0256, 0.1077, 0.0151, 0.0270], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,039][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([1.3984e-03, 4.2343e-01, 1.0185e-01, 1.4047e-01, 1.0087e-01, 1.1072e-03,
        6.8613e-04, 1.1733e-04, 1.0044e-02, 4.4084e-03, 9.1005e-03, 5.0475e-03,
        1.3701e-03, 5.1190e-02, 1.4891e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,045][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.0124, 0.0528, 0.1116, 0.1104, 0.0961, 0.0626, 0.0682, 0.0588, 0.0819,
        0.0688, 0.0752, 0.0424, 0.0451, 0.0468, 0.0668], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,046][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([1.2869e-06, 8.1046e-03, 1.5099e-01, 1.8828e-02, 4.3516e-02, 2.5108e-02,
        9.9515e-02, 6.0777e-02, 4.6937e-02, 1.3674e-01, 7.1504e-02, 2.2642e-01,
        7.4020e-02, 2.1998e-02, 1.5539e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,047][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([4.8190e-03, 5.4732e-01, 5.7903e-02, 1.5588e-01, 4.1943e-02, 3.6784e-03,
        2.0114e-03, 1.6652e-04, 1.9243e-02, 7.2599e-03, 5.5877e-03, 1.4682e-02,
        1.5562e-03, 4.2688e-02, 9.5263e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,048][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.0274, 0.0307, 0.0228, 0.0581, 0.0296, 0.0738, 0.0888, 0.0191, 0.1609,
        0.0192, 0.1839, 0.1231, 0.0219, 0.1176, 0.0233], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,051][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.0226, 0.0017, 0.0240, 0.0128, 0.0254, 0.0204, 0.0186, 0.0314, 0.0461,
        0.0791, 0.0977, 0.0838, 0.1057, 0.1136, 0.3170], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,057][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1943, 0.0461, 0.0892, 0.1098, 0.0779, 0.0987, 0.0805, 0.0503, 0.0374,
        0.0150, 0.0153, 0.0287, 0.0463, 0.0508, 0.0214, 0.0383],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,061][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0801, 0.0622, 0.0736, 0.0659, 0.0800, 0.0665, 0.0572, 0.0611, 0.0590,
        0.0558, 0.0537, 0.0651, 0.0526, 0.0428, 0.0679, 0.0564],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,062][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([6.8844e-09, 9.8387e-01, 3.5626e-06, 1.6063e-02, 1.8240e-07, 5.1181e-07,
        1.8230e-05, 1.1745e-06, 2.2032e-05, 1.5500e-08, 1.4991e-06, 1.6749e-06,
        1.4807e-07, 1.9384e-05, 5.0806e-10, 1.0701e-08], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,063][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0342, 0.1166, 0.0541, 0.0678, 0.2590, 0.0328, 0.0379, 0.0744, 0.0715,
        0.0269, 0.0675, 0.0372, 0.0420, 0.0407, 0.0255, 0.0120],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,064][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1050, 0.0557, 0.0574, 0.0587, 0.0603, 0.0691, 0.0659, 0.0644, 0.0598,
        0.0571, 0.0550, 0.0578, 0.0597, 0.0622, 0.0539, 0.0578],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,068][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0056, 0.0360, 0.1653, 0.0110, 0.0431, 0.0305, 0.0065, 0.0071, 0.0195,
        0.0452, 0.0202, 0.0077, 0.4120, 0.0297, 0.1518, 0.0087],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,071][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([1.8958e-04, 2.3689e-01, 1.1576e-01, 1.4013e-01, 1.7401e-01, 7.8740e-04,
        7.2287e-04, 5.7458e-05, 4.6182e-03, 5.2057e-03, 4.7334e-03, 3.8081e-03,
        2.1780e-03, 3.4320e-02, 2.4438e-01, 3.2211e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,077][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0138, 0.0487, 0.1055, 0.1076, 0.0870, 0.0572, 0.0666, 0.0578, 0.0747,
        0.0666, 0.0726, 0.0407, 0.0434, 0.0430, 0.0661, 0.0487],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,078][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([5.6842e-07, 8.6712e-03, 1.6657e-01, 2.1096e-02, 5.1767e-02, 3.2191e-02,
        8.3155e-02, 4.0763e-02, 5.0956e-02, 1.6660e-01, 4.3034e-02, 2.0997e-01,
        6.7950e-02, 3.0823e-02, 1.5925e-02, 1.0531e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,079][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([1.7315e-03, 6.7337e-01, 1.4419e-02, 1.5382e-01, 1.0910e-02, 5.5766e-03,
        1.2457e-03, 1.9362e-04, 1.8984e-02, 1.1019e-02, 1.4122e-02, 8.5084e-03,
        5.0653e-04, 4.9159e-02, 2.2289e-02, 1.4140e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,080][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0602, 0.0492, 0.0307, 0.0671, 0.0390, 0.0548, 0.0599, 0.0240, 0.0963,
        0.0213, 0.1378, 0.0984, 0.0264, 0.0973, 0.0253, 0.1122],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,084][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0271, 0.0031, 0.0264, 0.0167, 0.0263, 0.0215, 0.0206, 0.0346, 0.0494,
        0.0675, 0.0884, 0.0687, 0.0863, 0.0938, 0.1921, 0.1776],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,089][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1272, 0.0189, 0.0504, 0.0504, 0.0349, 0.0502, 0.0472, 0.0280, 0.0299,
        0.0333, 0.0609, 0.0467, 0.1096, 0.1105, 0.0456, 0.0860, 0.0704],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,093][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0631, 0.0585, 0.0835, 0.0633, 0.0765, 0.0658, 0.0582, 0.0570, 0.0540,
        0.0564, 0.0512, 0.0554, 0.0476, 0.0418, 0.0639, 0.0532, 0.0508],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,094][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([6.3584e-10, 9.9529e-01, 3.0483e-07, 4.7020e-03, 7.4186e-09, 3.8596e-08,
        1.0503e-06, 5.4426e-08, 2.9868e-06, 3.8749e-10, 8.0180e-08, 7.5518e-08,
        3.1858e-09, 1.4558e-06, 6.4734e-12, 3.1402e-10, 4.0310e-09],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,095][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0334, 0.0834, 0.0228, 0.0210, 0.4033, 0.0322, 0.0139, 0.1543, 0.0194,
        0.0131, 0.0241, 0.0213, 0.0954, 0.0160, 0.0127, 0.0232, 0.0105],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,096][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0985, 0.0530, 0.0539, 0.0546, 0.0559, 0.0651, 0.0624, 0.0608, 0.0560,
        0.0532, 0.0520, 0.0548, 0.0565, 0.0594, 0.0511, 0.0545, 0.0584],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,100][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0103, 0.0180, 0.1337, 0.0044, 0.0571, 0.0152, 0.0025, 0.0302, 0.0117,
        0.1888, 0.0134, 0.0031, 0.3808, 0.0150, 0.1107, 0.0034, 0.0016],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,103][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([3.4575e-04, 2.3731e-01, 1.0531e-01, 8.9160e-02, 7.4240e-02, 6.0571e-04,
        1.3314e-04, 3.4429e-05, 4.4383e-03, 2.9001e-03, 2.5197e-03, 1.4948e-03,
        1.0186e-03, 2.6252e-02, 1.9387e-01, 5.6766e-02, 2.0360e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,109][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0170, 0.0487, 0.0904, 0.0988, 0.0812, 0.0575, 0.0653, 0.0584, 0.0723,
        0.0619, 0.0668, 0.0401, 0.0431, 0.0430, 0.0598, 0.0479, 0.0478],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,110][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([6.5860e-06, 1.0416e-02, 1.7534e-01, 2.4700e-02, 4.7637e-02, 3.1734e-02,
        7.1722e-02, 5.9501e-02, 4.3101e-02, 1.2368e-01, 5.7617e-02, 1.2559e-01,
        6.2919e-02, 2.8621e-02, 2.3499e-02, 2.4431e-02, 8.9489e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,111][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.1182e-03, 2.5098e-01, 2.3834e-02, 1.4285e-01, 1.9322e-02, 3.2144e-03,
        5.0893e-04, 1.8449e-04, 1.4794e-02, 1.0664e-02, 2.0729e-02, 5.8623e-03,
        1.7769e-03, 2.5511e-02, 3.7761e-02, 2.7685e-01, 1.6404e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,112][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0599, 0.0590, 0.0333, 0.0686, 0.0424, 0.0407, 0.0420, 0.0253, 0.0712,
        0.0228, 0.1064, 0.0704, 0.0285, 0.0882, 0.0255, 0.0906, 0.1252],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,116][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0250, 0.0026, 0.0250, 0.0140, 0.0235, 0.0191, 0.0158, 0.0297, 0.0391,
        0.0601, 0.0702, 0.0606, 0.0716, 0.0781, 0.1909, 0.1675, 0.1070],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,121][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.1262, 0.0230, 0.0462, 0.0508, 0.0258, 0.0456, 0.0290, 0.0313, 0.0230,
        0.0580, 0.1208, 0.0697, 0.0828, 0.1181, 0.0305, 0.0623, 0.0400, 0.0168],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,125][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([0.0845, 0.0530, 0.0684, 0.0616, 0.0676, 0.0640, 0.0522, 0.0642, 0.0486,
        0.0521, 0.0478, 0.0554, 0.0466, 0.0357, 0.0495, 0.0506, 0.0494, 0.0486],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,126][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([1.0918e-12, 9.6677e-01, 2.4564e-07, 3.3218e-02, 1.0176e-08, 1.1434e-08,
        6.5961e-06, 6.1615e-08, 5.5133e-06, 2.3740e-10, 1.3638e-07, 1.5210e-07,
        8.5576e-09, 3.5259e-06, 2.4832e-12, 6.9402e-11, 9.6592e-09, 8.6006e-12],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,127][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([0.0173, 0.0537, 0.0643, 0.0248, 0.3572, 0.0361, 0.0256, 0.0781, 0.0308,
        0.0244, 0.0269, 0.0188, 0.0999, 0.0123, 0.0337, 0.0693, 0.0193, 0.0075],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,128][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([0.0947, 0.0492, 0.0504, 0.0517, 0.0538, 0.0621, 0.0582, 0.0584, 0.0533,
        0.0520, 0.0488, 0.0521, 0.0550, 0.0567, 0.0468, 0.0512, 0.0548, 0.0508],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,132][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([0.0120, 0.0296, 0.0376, 0.0385, 0.0260, 0.0417, 0.0801, 0.0336, 0.0416,
        0.1314, 0.0956, 0.0310, 0.1045, 0.0318, 0.0480, 0.0893, 0.0764, 0.0513],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,135][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([1.4755e-03, 1.6102e-01, 7.5392e-02, 7.3266e-02, 7.7273e-02, 5.3582e-04,
        2.4210e-04, 5.4459e-05, 3.9587e-03, 2.6359e-03, 3.9201e-03, 1.7437e-03,
        7.7842e-04, 3.6428e-02, 1.1486e-01, 4.7892e-02, 2.5179e-01, 1.4674e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,141][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([0.0173, 0.0478, 0.0813, 0.0936, 0.0775, 0.0559, 0.0643, 0.0572, 0.0686,
        0.0581, 0.0642, 0.0389, 0.0433, 0.0428, 0.0553, 0.0470, 0.0477, 0.0394],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,142][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([0.0003, 0.0265, 0.1192, 0.0406, 0.0540, 0.0312, 0.0768, 0.0685, 0.0549,
        0.1056, 0.0697, 0.1254, 0.0383, 0.0207, 0.0105, 0.0186, 0.0681, 0.0712],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,143][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([6.1684e-03, 2.4720e-01, 3.9693e-02, 1.6953e-01, 3.7826e-02, 2.5902e-03,
        9.8932e-04, 2.0586e-04, 1.4066e-02, 8.1184e-03, 1.0218e-02, 8.7217e-03,
        1.2470e-03, 4.5958e-02, 5.3072e-02, 4.0549e-02, 2.0688e-01, 1.0696e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,144][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([0.0229, 0.0270, 0.0222, 0.0449, 0.0313, 0.0530, 0.0610, 0.0179, 0.0999,
        0.0161, 0.1142, 0.0812, 0.0200, 0.0847, 0.0223, 0.0956, 0.1599, 0.0258],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,147][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([0.0181, 0.0014, 0.0161, 0.0092, 0.0166, 0.0117, 0.0116, 0.0204, 0.0294,
        0.0505, 0.0607, 0.0478, 0.0599, 0.0622, 0.1629, 0.1369, 0.0940, 0.1906],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,153][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1366, 0.0208, 0.0525, 0.0620, 0.0431, 0.0596, 0.0494, 0.0275, 0.0295,
        0.0295, 0.0617, 0.0465, 0.0815, 0.0938, 0.0329, 0.0661, 0.0527, 0.0167,
        0.0376], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,157][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0584, 0.0590, 0.0785, 0.0599, 0.0679, 0.0542, 0.0494, 0.0538, 0.0461,
        0.0518, 0.0451, 0.0490, 0.0460, 0.0379, 0.0532, 0.0481, 0.0442, 0.0495,
        0.0481], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,158][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.7989e-10, 9.9596e-01, 7.3449e-07, 4.0277e-03, 2.3330e-08, 6.3429e-08,
        1.9734e-06, 1.0208e-07, 6.0609e-06, 1.1039e-09, 1.4480e-07, 1.3198e-07,
        9.8832e-09, 3.4260e-06, 2.3366e-11, 8.8746e-10, 1.1646e-08, 3.9770e-11,
        3.1262e-08], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,159][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0143, 0.0797, 0.0166, 0.0133, 0.3094, 0.0402, 0.0382, 0.1295, 0.0162,
        0.0435, 0.0062, 0.0286, 0.1325, 0.0207, 0.0074, 0.0164, 0.0184, 0.0684,
        0.0005], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,160][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0880, 0.0478, 0.0486, 0.0500, 0.0510, 0.0591, 0.0562, 0.0554, 0.0510,
        0.0489, 0.0472, 0.0497, 0.0507, 0.0532, 0.0454, 0.0488, 0.0524, 0.0473,
        0.0496], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,165][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0106, 0.0201, 0.0663, 0.0033, 0.0420, 0.0129, 0.0052, 0.0272, 0.0122,
        0.2521, 0.0051, 0.0047, 0.1455, 0.0217, 0.0926, 0.0093, 0.0055, 0.2570,
        0.0066], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,169][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([2.8797e-04, 5.6031e-02, 3.5318e-02, 3.0451e-02, 2.4004e-02, 2.2124e-04,
        1.1173e-04, 1.2508e-05, 6.5059e-04, 1.1730e-03, 7.9320e-04, 1.1234e-03,
        3.7824e-04, 7.9900e-03, 5.5457e-02, 2.4308e-02, 2.2603e-01, 1.7762e-01,
        3.5803e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,173][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0131, 0.0450, 0.0803, 0.0892, 0.0771, 0.0551, 0.0618, 0.0543, 0.0658,
        0.0567, 0.0600, 0.0369, 0.0416, 0.0405, 0.0527, 0.0427, 0.0437, 0.0379,
        0.0457], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,174][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([8.4912e-05, 1.4747e-02, 1.1034e-01, 2.7528e-02, 3.5792e-02, 3.3351e-02,
        6.8734e-02, 5.2508e-02, 3.8587e-02, 9.5925e-02, 5.1633e-02, 1.1823e-01,
        4.9739e-02, 3.2621e-02, 1.9522e-02, 2.8447e-02, 9.1097e-02, 9.9745e-02,
        3.1367e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,175][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.3100e-03, 2.0048e-01, 9.0219e-03, 7.1212e-02, 1.0647e-02, 9.6905e-04,
        3.6514e-04, 5.5020e-05, 4.6124e-03, 3.4564e-03, 1.7634e-03, 4.1606e-03,
        2.2163e-04, 1.7460e-02, 2.0159e-02, 7.3333e-02, 1.5135e-01, 1.0023e-01,
        3.2920e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,176][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0518, 0.0453, 0.0212, 0.0540, 0.0310, 0.0370, 0.0377, 0.0179, 0.0672,
        0.0151, 0.1040, 0.0626, 0.0203, 0.0745, 0.0161, 0.0814, 0.1031, 0.0233,
        0.1365], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,179][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0152, 0.0018, 0.0151, 0.0095, 0.0147, 0.0126, 0.0121, 0.0199, 0.0269,
        0.0440, 0.0493, 0.0424, 0.0523, 0.0528, 0.1195, 0.1146, 0.0799, 0.1819,
        0.1357], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,222][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:30,226][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,229][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,231][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,231][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,232][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,233][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,233][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,235][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,237][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,239][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,240][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,243][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,246][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5919, 0.4081], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,249][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.4507, 0.5493], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,249][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([5.2826e-06, 9.9999e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,250][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3160, 0.6840], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,251][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3769, 0.6231], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,252][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2323, 0.7677], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,255][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.4173, 0.5827], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,261][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0014, 0.9986], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,265][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0241, 0.9759], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,265][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.3350, 0.6650], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,266][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2515, 0.7485], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,267][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3194, 0.6806], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,268][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.4610, 0.2957, 0.2433], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,273][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.2742, 0.3401, 0.3857], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,276][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([1.1679e-05, 4.4964e-06, 9.9998e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,281][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.1672, 0.4677, 0.3651], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,281][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.2264, 0.3954, 0.3782], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,282][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.0933, 0.4766, 0.4302], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,283][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.0160, 0.8173, 0.1667], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,283][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([2.3281e-04, 8.7462e-01, 1.2514e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,287][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.0012, 0.9754, 0.0235], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,292][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.0336, 0.8849, 0.0816], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,296][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.1119, 0.5286, 0.3595], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,297][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.0364, 0.7973, 0.1663], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,298][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3529, 0.2378, 0.1684, 0.2409], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,299][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2024, 0.2469, 0.2817, 0.2690], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,300][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([5.8395e-11, 5.3865e-06, 9.9992e-01, 7.9395e-05], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,305][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1321, 0.3159, 0.2748, 0.2772], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,310][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1629, 0.2621, 0.2645, 0.3105], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,312][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0664, 0.2299, 0.3329, 0.3708], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,313][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0075, 0.6791, 0.2637, 0.0497], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,314][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([6.6273e-06, 3.9216e-01, 3.9077e-01, 2.1706e-01], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,315][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([8.6624e-05, 8.7562e-01, 1.3106e-02, 1.1118e-01], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,316][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0071, 0.8913, 0.0398, 0.0618], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,322][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0267, 0.4643, 0.3856, 0.1233], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,328][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0062, 0.7156, 0.1348, 0.1433], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,329][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.3174, 0.2027, 0.1348, 0.1885, 0.1566], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,330][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([0.1587, 0.1920, 0.2175, 0.2090, 0.2228], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,330][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([4.3825e-08, 1.9264e-06, 9.7990e-01, 5.0065e-04, 1.9600e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,332][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([0.0957, 0.2517, 0.2327, 0.2255, 0.1943], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,337][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([0.1322, 0.2069, 0.2251, 0.2482, 0.1876], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,342][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.0431, 0.1677, 0.1915, 0.2914, 0.3064], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,344][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.0036, 0.6242, 0.1527, 0.1658, 0.0537], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,345][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([1.1686e-05, 4.2848e-01, 2.7754e-01, 2.8118e-01, 1.2784e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,346][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([1.2809e-04, 5.6491e-01, 1.9802e-02, 4.1136e-01, 3.7963e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,347][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.0040, 0.7371, 0.0377, 0.1982, 0.0230], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,350][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.0290, 0.3247, 0.3230, 0.1195, 0.2038], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,355][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.0057, 0.6371, 0.1314, 0.1891, 0.0366], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,360][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.2409, 0.1598, 0.1043, 0.1598, 0.1055, 0.2297], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:30,361][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.1316, 0.1594, 0.1808, 0.1745, 0.1851, 0.1686], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:30,362][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([1.3549e-13, 5.7943e-07, 9.6094e-01, 3.3149e-04, 3.8733e-02, 2.1972e-07],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:30,363][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0823, 0.2033, 0.1776, 0.1943, 0.1684, 0.1741], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:30,366][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1024, 0.1616, 0.1679, 0.1920, 0.1744, 0.2019], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:30,372][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0271, 0.1069, 0.1538, 0.1899, 0.2756, 0.2467], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:30,376][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([2.8197e-05, 3.3961e-01, 2.3684e-01, 1.7241e-01, 2.4914e-01, 1.9664e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:30,377][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([3.7400e-08, 2.7261e-01, 2.8569e-01, 3.7843e-01, 6.2796e-02, 4.6655e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:30,377][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([7.5692e-07, 6.5528e-01, 6.9085e-03, 3.2557e-01, 1.1998e-02, 2.3933e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:30,378][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([1.9657e-04, 8.7170e-01, 1.7675e-02, 9.9237e-02, 8.8998e-03, 2.2921e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:30,379][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0115, 0.3177, 0.2422, 0.0427, 0.0774, 0.3085], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:30,380][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([1.7918e-04, 5.7458e-01, 1.2347e-01, 2.4138e-01, 5.7487e-02, 2.9032e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:30,385][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2068, 0.1321, 0.0953, 0.1321, 0.0898, 0.1628, 0.1810],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:30,390][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1103, 0.1357, 0.1549, 0.1492, 0.1592, 0.1443, 0.1464],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:30,393][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([8.8487e-15, 8.8210e-07, 9.4857e-01, 4.1208e-04, 5.1018e-02, 1.1427e-06,
        9.1006e-08], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:30,393][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0740, 0.1787, 0.1437, 0.1534, 0.1535, 0.1672, 0.1294],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:30,394][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0854, 0.1341, 0.1391, 0.1645, 0.1463, 0.1806, 0.1500],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:30,395][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0266, 0.0941, 0.1419, 0.1402, 0.2171, 0.2127, 0.1674],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:30,396][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.2347e-05, 4.6134e-01, 1.5656e-01, 2.4875e-01, 1.2978e-01, 2.9066e-03,
        6.4618e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:30,399][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([5.4910e-11, 1.3712e-01, 2.4304e-01, 5.6888e-01, 5.0534e-02, 3.7692e-04,
        5.3698e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:30,403][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.7147e-07, 5.7666e-01, 1.0697e-02, 3.9763e-01, 1.4546e-02, 4.2542e-04,
        4.4987e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:30,405][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([7.5604e-05, 5.5866e-01, 4.7771e-02, 3.3384e-01, 4.9015e-02, 8.5068e-03,
        2.1333e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:30,409][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0027, 0.2349, 0.3119, 0.0964, 0.1601, 0.1363, 0.0578],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:30,410][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([3.5504e-05, 4.9912e-01, 1.4129e-01, 2.8876e-01, 6.6141e-02, 3.8754e-03,
        7.7432e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:30,410][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.1837, 0.1192, 0.0775, 0.1148, 0.0708, 0.1523, 0.1491, 0.1325],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:30,411][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0964, 0.1195, 0.1357, 0.1305, 0.1394, 0.1269, 0.1277, 0.1239],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:30,412][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([6.3939e-13, 3.4994e-06, 9.5259e-01, 3.4598e-03, 4.3942e-02, 1.6281e-06,
        1.7215e-06, 9.9002e-08], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:30,417][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0646, 0.1541, 0.1240, 0.1406, 0.1407, 0.1337, 0.1395, 0.1029],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:30,423][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0705, 0.1199, 0.1198, 0.1486, 0.1281, 0.1604, 0.1348, 0.1180],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:30,427][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0162, 0.0678, 0.1144, 0.1375, 0.1555, 0.1976, 0.1660, 0.1450],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:30,428][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([8.6561e-06, 4.2940e-01, 1.2718e-01, 3.0262e-01, 1.3677e-01, 2.3908e-03,
        1.5775e-03, 4.0226e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:30,428][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([3.8939e-09, 1.6270e-01, 2.0556e-01, 5.9936e-01, 3.1282e-02, 8.6695e-04,
        2.2785e-04, 6.9864e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:30,429][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([1.2486e-07, 3.7193e-01, 1.0405e-02, 5.8285e-01, 3.3875e-02, 7.9092e-04,
        1.4466e-04, 5.7792e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:30,430][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([7.5396e-05, 5.9859e-01, 4.8946e-02, 3.1300e-01, 2.8407e-02, 7.5302e-03,
        3.2912e-03, 1.5908e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:30,435][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0013, 0.4464, 0.1617, 0.0819, 0.1741, 0.0904, 0.0344, 0.0098],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:30,439][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([6.1844e-05, 4.4945e-01, 7.3165e-02, 3.9169e-01, 7.8952e-02, 3.0391e-03,
        3.2396e-03, 3.9780e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:30,443][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.1695, 0.1119, 0.0763, 0.1085, 0.0708, 0.1321, 0.1310, 0.0994, 0.1005],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:30,444][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0861, 0.1064, 0.1215, 0.1158, 0.1240, 0.1135, 0.1141, 0.1111, 0.1076],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:30,445][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([6.7130e-14, 1.1265e-06, 9.6084e-01, 3.8608e-04, 3.8764e-02, 6.2839e-07,
        4.3780e-07, 4.4827e-07, 7.1972e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:30,445][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0480, 0.1277, 0.1153, 0.1168, 0.1097, 0.1236, 0.1104, 0.1251, 0.1233],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:30,449][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0671, 0.1105, 0.1088, 0.1303, 0.1118, 0.1409, 0.1155, 0.0982, 0.1170],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:30,455][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0155, 0.0614, 0.1128, 0.1058, 0.1929, 0.1469, 0.1335, 0.1436, 0.0877],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:30,457][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([6.2310e-05, 5.5145e-01, 1.0233e-01, 2.1969e-01, 1.0747e-01, 2.8002e-03,
        1.5715e-03, 1.1157e-04, 1.4507e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:30,459][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([3.8966e-08, 2.3124e-01, 2.4171e-01, 4.8035e-01, 4.4723e-02, 8.7948e-04,
        2.3529e-04, 1.4578e-05, 8.5428e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:30,460][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([1.0524e-06, 7.2709e-01, 9.3392e-03, 2.4909e-01, 8.4447e-03, 3.4587e-04,
        4.6862e-05, 1.5516e-06, 5.6476e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:30,460][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([2.3977e-04, 6.7554e-01, 4.2938e-02, 2.3535e-01, 2.1447e-02, 3.4216e-03,
        1.6774e-03, 2.1709e-04, 1.9167e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:30,461][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0021, 0.3553, 0.1701, 0.0593, 0.2161, 0.1278, 0.0386, 0.0021, 0.0286],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:30,463][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([1.1014e-04, 4.4980e-01, 1.8761e-01, 2.6237e-01, 8.1388e-02, 3.4345e-03,
        1.3536e-03, 7.5009e-04, 1.3178e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:30,467][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.1747, 0.1108, 0.0638, 0.1010, 0.0578, 0.1296, 0.1319, 0.0974, 0.0916,
        0.0414], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:30,473][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0757, 0.0965, 0.1109, 0.1059, 0.1138, 0.1029, 0.1035, 0.1014, 0.0978,
        0.0916], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:30,475][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([6.2624e-11, 4.8497e-06, 9.3903e-01, 6.0333e-04, 6.0203e-02, 2.1935e-06,
        1.2197e-06, 1.3999e-06, 1.2520e-04, 2.6166e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:30,476][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0478, 0.1197, 0.0924, 0.1152, 0.1160, 0.1192, 0.1021, 0.0977, 0.1238,
        0.0661], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:30,477][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0584, 0.0964, 0.0987, 0.1182, 0.0971, 0.1375, 0.1082, 0.0963, 0.1044,
        0.0847], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:30,480][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0166, 0.0693, 0.0995, 0.1103, 0.1457, 0.1756, 0.1180, 0.1138, 0.0817,
        0.0694], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:30,484][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([8.5497e-05, 4.7740e-01, 1.2642e-01, 2.2638e-01, 1.4025e-01, 3.7712e-03,
        9.0729e-04, 1.8191e-04, 2.1509e-02, 3.0871e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:30,488][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([1.1121e-06, 2.9233e-01, 1.7484e-01, 4.8783e-01, 3.9840e-02, 1.9635e-03,
        4.0805e-04, 3.5173e-05, 2.2334e-03, 5.1615e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:30,490][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([2.3450e-06, 6.0430e-01, 1.4000e-02, 3.3178e-01, 3.3205e-02, 4.3043e-04,
        3.2327e-05, 8.4028e-06, 1.6121e-02, 1.2408e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:30,491][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([4.6414e-04, 6.1055e-01, 3.3390e-02, 2.1469e-01, 2.5435e-02, 3.2109e-02,
        3.2661e-03, 4.0695e-04, 7.2816e-02, 6.8688e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:30,492][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0028, 0.3908, 0.1509, 0.0678, 0.1731, 0.0847, 0.0304, 0.0063, 0.0350,
        0.0582], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:30,493][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([4.4250e-04, 5.1130e-01, 9.7981e-02, 2.6811e-01, 6.7068e-02, 2.0929e-03,
        3.1419e-03, 9.4474e-04, 4.2588e-02, 6.3241e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:30,496][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.1523, 0.1028, 0.0586, 0.1006, 0.0589, 0.1177, 0.1174, 0.0885, 0.0905,
        0.0366, 0.0761], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:30,501][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0691, 0.0878, 0.1019, 0.0975, 0.1042, 0.0941, 0.0952, 0.0930, 0.0896,
        0.0842, 0.0833], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:30,504][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([9.5088e-14, 5.5740e-06, 9.2905e-01, 4.5539e-04, 7.0144e-02, 4.6705e-06,
        1.6870e-06, 1.5412e-06, 1.6742e-04, 1.6972e-04, 4.4639e-08],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:30,506][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0400, 0.1100, 0.0913, 0.1010, 0.0919, 0.1079, 0.0912, 0.0852, 0.1173,
        0.0761, 0.0881], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:30,507][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0554, 0.0868, 0.0938, 0.1067, 0.0925, 0.1190, 0.0979, 0.0866, 0.0955,
        0.0802, 0.0857], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:30,508][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0182, 0.0521, 0.1037, 0.0887, 0.1476, 0.1450, 0.1145, 0.1093, 0.0733,
        0.0911, 0.0565], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:30,510][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([1.3173e-04, 4.3101e-01, 2.0189e-01, 1.6620e-01, 1.6384e-01, 3.1561e-03,
        1.6034e-03, 1.9404e-04, 1.6223e-02, 8.5131e-03, 7.2281e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:30,514][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([1.1748e-07, 2.0535e-01, 2.9900e-01, 4.3386e-01, 5.7533e-02, 9.3662e-04,
        1.8357e-04, 2.5990e-05, 1.0709e-03, 7.8768e-04, 1.2523e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:30,517][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([1.4667e-06, 7.0784e-01, 8.0996e-03, 2.5862e-01, 9.7751e-03, 4.4115e-04,
        4.9141e-05, 1.2761e-05, 1.3069e-02, 4.6189e-04, 1.6349e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:30,521][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([7.5616e-04, 5.5018e-01, 3.3032e-02, 2.2924e-01, 7.8800e-02, 4.6180e-03,
        3.6009e-03, 1.9497e-04, 5.4674e-02, 2.9240e-02, 1.5666e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:30,522][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0025, 0.2985, 0.1749, 0.0819, 0.1449, 0.1185, 0.0512, 0.0029, 0.0442,
        0.0446, 0.0360], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:30,523][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([1.6947e-04, 5.4197e-01, 6.6269e-02, 2.7095e-01, 2.8908e-02, 2.7149e-03,
        1.6255e-03, 1.1805e-03, 5.3122e-02, 1.7195e-02, 1.5903e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:30,524][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1395, 0.0882, 0.0591, 0.0884, 0.0561, 0.1065, 0.1099, 0.0844, 0.0793,
        0.0372, 0.0536, 0.0979], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:30,527][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0654, 0.0807, 0.0931, 0.0896, 0.0954, 0.0863, 0.0877, 0.0850, 0.0823,
        0.0774, 0.0774, 0.0797], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:30,531][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([1.8951e-14, 3.9800e-06, 9.2321e-01, 4.2628e-04, 7.5995e-02, 2.2728e-06,
        8.2603e-07, 2.0710e-06, 2.2255e-04, 1.3193e-04, 2.7252e-07, 6.0961e-08],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:30,537][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0385, 0.0997, 0.0850, 0.0879, 0.0877, 0.0958, 0.0763, 0.0811, 0.1010,
        0.0674, 0.0869, 0.0927], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:30,538][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0509, 0.0815, 0.0827, 0.0996, 0.0856, 0.1064, 0.0903, 0.0764, 0.0876,
        0.0702, 0.0774, 0.0914], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:30,539][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0143, 0.0511, 0.0899, 0.0815, 0.1279, 0.1210, 0.0975, 0.1046, 0.0759,
        0.0727, 0.0569, 0.1066], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:30,540][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([7.7354e-05, 4.1324e-01, 2.3020e-01, 1.5361e-01, 1.6265e-01, 2.1395e-03,
        9.8805e-04, 1.0614e-04, 1.3655e-02, 8.4027e-03, 1.0139e-02, 4.7894e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:30,543][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([1.0604e-09, 2.2640e-01, 2.8673e-01, 4.3688e-01, 4.6763e-02, 2.3096e-04,
        3.1654e-05, 3.0075e-06, 2.3318e-04, 2.5223e-04, 5.1819e-04, 1.9494e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:30,546][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([2.2908e-06, 5.7155e-01, 1.4299e-02, 3.5805e-01, 2.1096e-02, 4.3500e-04,
        4.3928e-05, 1.1390e-05, 2.3532e-02, 9.4631e-04, 9.2975e-03, 7.4295e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:30,550][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([3.7999e-04, 5.1430e-01, 5.2194e-02, 2.3063e-01, 7.0955e-02, 5.6815e-03,
        1.4986e-03, 4.4090e-04, 4.1866e-02, 3.2169e-02, 4.0288e-02, 9.5978e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:30,552][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0018, 0.2477, 0.2684, 0.0591, 0.1272, 0.1928, 0.0393, 0.0010, 0.0133,
        0.0106, 0.0153, 0.0235], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:30,553][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([1.8422e-04, 5.3313e-01, 9.6907e-02, 2.0160e-01, 7.9781e-02, 2.6464e-03,
        1.4309e-03, 6.3492e-04, 2.9856e-02, 1.9689e-02, 2.6397e-02, 7.7419e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:30,554][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.1359, 0.0849, 0.0526, 0.0809, 0.0515, 0.1091, 0.1033, 0.0816, 0.0716,
        0.0319, 0.0493, 0.0844, 0.0630], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:30,555][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0599, 0.0743, 0.0856, 0.0824, 0.0874, 0.0797, 0.0807, 0.0784, 0.0764,
        0.0723, 0.0714, 0.0735, 0.0780], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:30,556][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([9.4913e-13, 4.9846e-06, 9.7586e-01, 6.2109e-04, 2.3287e-02, 8.3440e-07,
        5.5900e-07, 2.8197e-07, 1.2051e-04, 1.0675e-04, 6.8580e-07, 5.3652e-07,
        2.0189e-07], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:30,562][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.0343, 0.0888, 0.0724, 0.0849, 0.0794, 0.0867, 0.0828, 0.0673, 0.1024,
        0.0532, 0.0850, 0.0920, 0.0709], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:30,568][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0428, 0.0734, 0.0761, 0.0926, 0.0792, 0.1061, 0.0831, 0.0757, 0.0791,
        0.0721, 0.0726, 0.0838, 0.0633], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:30,569][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.0084, 0.0491, 0.0718, 0.0909, 0.1070, 0.1551, 0.1097, 0.0821, 0.0659,
        0.0513, 0.0533, 0.1184, 0.0369], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:30,570][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([1.7854e-05, 3.8462e-01, 1.0552e-01, 2.9584e-01, 1.3849e-01, 2.9598e-03,
        1.1012e-03, 1.8432e-04, 3.5662e-02, 8.0288e-03, 1.7228e-02, 9.1149e-03,
        1.2282e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:30,571][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([3.0398e-07, 2.9896e-01, 2.7859e-01, 3.6344e-01, 3.2783e-02, 8.7429e-04,
        1.9566e-04, 2.7100e-05, 1.6727e-03, 6.9382e-04, 3.1731e-03, 1.9299e-02,
        2.8309e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:30,574][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([5.4364e-07, 4.7485e-01, 1.4447e-02, 4.3724e-01, 1.9887e-02, 5.5268e-04,
        6.6640e-05, 1.3240e-05, 3.9712e-02, 7.6972e-04, 1.1083e-02, 1.3009e-03,
        8.2221e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:30,577][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([4.9072e-04, 4.9103e-01, 5.1853e-02, 2.1333e-01, 3.5191e-02, 9.9045e-03,
        3.2561e-03, 5.2672e-04, 9.5546e-02, 1.9348e-02, 6.0416e-02, 1.8576e-02,
        5.2859e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:30,583][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.0014, 0.2729, 0.2585, 0.0828, 0.1015, 0.1470, 0.0234, 0.0036, 0.0235,
        0.0267, 0.0211, 0.0299, 0.0076], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:30,584][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([1.3192e-04, 5.5755e-01, 7.4209e-02, 2.0875e-01, 2.5286e-02, 4.1728e-03,
        1.5034e-03, 7.6381e-04, 5.6748e-02, 1.0408e-02, 4.3247e-02, 1.6273e-02,
        9.5253e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:30,585][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.1103, 0.0757, 0.0567, 0.0741, 0.0498, 0.0958, 0.0909, 0.0713, 0.0660,
        0.0366, 0.0481, 0.0781, 0.0527, 0.0940], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,586][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0579, 0.0691, 0.0791, 0.0762, 0.0805, 0.0735, 0.0748, 0.0726, 0.0710,
        0.0676, 0.0672, 0.0683, 0.0713, 0.0709], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,587][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([4.6094e-13, 6.2066e-06, 9.5445e-01, 6.0923e-04, 4.4569e-02, 2.9014e-06,
        1.4038e-06, 2.0529e-06, 1.5706e-04, 2.0227e-04, 3.4654e-07, 5.6965e-07,
        1.6692e-06, 2.1486e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,593][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0303, 0.0812, 0.0697, 0.0733, 0.0700, 0.0797, 0.0722, 0.0677, 0.0846,
        0.0583, 0.0662, 0.0830, 0.0802, 0.0834], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,599][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0425, 0.0692, 0.0723, 0.0855, 0.0738, 0.0920, 0.0770, 0.0648, 0.0747,
        0.0609, 0.0659, 0.0773, 0.0604, 0.0838], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,600][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0116, 0.0411, 0.0678, 0.0695, 0.1019, 0.1226, 0.1004, 0.0911, 0.0628,
        0.0699, 0.0469, 0.1042, 0.0492, 0.0610], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,601][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([1.4097e-04, 2.8275e-01, 2.2644e-01, 2.0149e-01, 2.2851e-01, 2.2800e-03,
        1.2481e-03, 1.2237e-04, 9.4908e-03, 1.2337e-02, 8.5789e-03, 1.0731e-02,
        2.5511e-03, 1.3326e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,602][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([1.5583e-08, 1.4994e-01, 4.8797e-01, 2.4916e-01, 5.1729e-02, 1.3344e-04,
        8.7573e-06, 2.1457e-06, 1.4697e-04, 2.4168e-04, 3.9595e-04, 1.9256e-03,
        1.7167e-04, 5.8178e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,605][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([7.5862e-06, 5.9445e-01, 8.4132e-03, 3.1546e-01, 1.3092e-02, 4.6308e-04,
        8.6306e-05, 2.3340e-05, 1.9666e-02, 6.3527e-04, 7.7918e-03, 2.2395e-03,
        2.2481e-04, 3.7455e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,608][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([4.3719e-04, 5.2515e-01, 5.6660e-02, 2.7173e-01, 3.5418e-02, 7.4947e-03,
        2.5165e-03, 4.8600e-04, 2.3564e-02, 1.9944e-02, 1.9271e-02, 1.5044e-02,
        1.7207e-03, 2.0562e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,614][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0048, 0.3925, 0.1771, 0.0688, 0.0980, 0.1184, 0.0275, 0.0019, 0.0189,
        0.0195, 0.0149, 0.0273, 0.0060, 0.0245], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,615][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([2.8034e-04, 2.9331e-01, 1.4421e-01, 3.2757e-01, 6.4505e-02, 2.3344e-03,
        2.0362e-03, 7.8542e-04, 2.9609e-02, 2.3352e-02, 3.3578e-02, 2.9078e-02,
        3.7166e-03, 4.5633e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:30,616][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.1184, 0.0750, 0.0630, 0.0677, 0.0465, 0.0940, 0.0812, 0.0652, 0.0629,
        0.0298, 0.0400, 0.0683, 0.0489, 0.0929, 0.0460], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,617][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0519, 0.0648, 0.0744, 0.0710, 0.0762, 0.0693, 0.0695, 0.0679, 0.0658,
        0.0622, 0.0614, 0.0643, 0.0681, 0.0675, 0.0656], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,618][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([8.8794e-09, 1.7565e-06, 9.4086e-01, 1.4224e-03, 3.4062e-02, 3.5857e-06,
        1.2627e-06, 1.2162e-06, 5.3825e-05, 2.1781e-04, 6.9023e-07, 5.1250e-07,
        1.8578e-06, 1.5015e-05, 2.3353e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,624][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.0240, 0.0739, 0.0584, 0.0695, 0.0639, 0.0724, 0.0660, 0.0626, 0.0856,
        0.0473, 0.0755, 0.0780, 0.0716, 0.0934, 0.0578], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,630][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.0390, 0.0689, 0.0647, 0.0798, 0.0722, 0.0915, 0.0685, 0.0595, 0.0735,
        0.0570, 0.0631, 0.0708, 0.0546, 0.0818, 0.0552], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,631][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.0104, 0.0519, 0.0525, 0.0639, 0.0834, 0.1498, 0.0766, 0.0749, 0.0679,
        0.0575, 0.0485, 0.1026, 0.0493, 0.0691, 0.0417], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,632][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([1.3984e-03, 4.2343e-01, 1.0185e-01, 1.4047e-01, 1.0087e-01, 1.1072e-03,
        6.8613e-04, 1.1733e-04, 1.0044e-02, 4.4084e-03, 9.1005e-03, 5.0475e-03,
        1.3701e-03, 5.1190e-02, 1.4891e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,633][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([9.4554e-06, 2.8365e-01, 1.0007e-01, 2.4113e-01, 3.2178e-02, 1.0057e-03,
        7.7456e-05, 3.3732e-05, 1.1117e-03, 1.0418e-03, 2.4407e-03, 4.5330e-03,
        7.6645e-04, 2.9657e-01, 3.5382e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,637][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([8.2459e-05, 4.9480e-01, 9.3897e-03, 3.6159e-01, 2.1864e-02, 4.2505e-04,
        7.0837e-05, 2.5569e-05, 1.4783e-02, 1.2604e-03, 5.9926e-03, 1.6639e-03,
        6.9318e-04, 6.8477e-02, 1.8876e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,641][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([4.8190e-03, 5.4732e-01, 5.7903e-02, 1.5588e-01, 4.1943e-02, 3.6784e-03,
        2.0114e-03, 1.6652e-04, 1.9243e-02, 7.2599e-03, 5.5877e-03, 1.4682e-02,
        1.5562e-03, 4.2688e-02, 9.5263e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,645][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0094, 0.2960, 0.1477, 0.0657, 0.1197, 0.0720, 0.0256, 0.0076, 0.0358,
        0.0540, 0.0293, 0.0216, 0.0108, 0.0375, 0.0673], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,646][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.0034, 0.4300, 0.0716, 0.1795, 0.0633, 0.0023, 0.0016, 0.0006, 0.0160,
        0.0123, 0.0158, 0.0157, 0.0036, 0.0870, 0.0972], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:30,647][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.1152, 0.0727, 0.0467, 0.0707, 0.0415, 0.0921, 0.0858, 0.0644, 0.0629,
        0.0286, 0.0416, 0.0669, 0.0424, 0.0889, 0.0353, 0.0441],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,648][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0488, 0.0605, 0.0697, 0.0667, 0.0712, 0.0647, 0.0655, 0.0636, 0.0620,
        0.0589, 0.0577, 0.0598, 0.0634, 0.0631, 0.0620, 0.0624],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,649][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([8.4581e-14, 2.1996e-06, 9.2489e-01, 3.7905e-04, 3.4584e-02, 2.3183e-07,
        5.0645e-07, 4.2548e-07, 3.8683e-05, 6.4165e-05, 1.3644e-07, 1.9489e-07,
        1.5325e-07, 2.4962e-06, 4.0041e-02, 2.7970e-07], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,655][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0267, 0.0738, 0.0591, 0.0703, 0.0578, 0.0651, 0.0593, 0.0542, 0.0856,
        0.0479, 0.0721, 0.0715, 0.0630, 0.0853, 0.0574, 0.0510],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,661][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0389, 0.0611, 0.0620, 0.0742, 0.0645, 0.0800, 0.0676, 0.0608, 0.0654,
        0.0557, 0.0580, 0.0699, 0.0564, 0.0733, 0.0552, 0.0572],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,661][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0096, 0.0420, 0.0650, 0.0655, 0.0778, 0.1040, 0.0694, 0.0634, 0.0604,
        0.0483, 0.0500, 0.0880, 0.0503, 0.0687, 0.0459, 0.0917],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,662][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([1.8958e-04, 2.3689e-01, 1.1576e-01, 1.4013e-01, 1.7401e-01, 7.8740e-04,
        7.2287e-04, 5.7458e-05, 4.6182e-03, 5.2057e-03, 4.7334e-03, 3.8081e-03,
        2.1780e-03, 3.4320e-02, 2.4438e-01, 3.2211e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,664][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([9.1711e-07, 2.2570e-01, 2.4000e-01, 2.0527e-01, 2.6340e-02, 2.2399e-04,
        4.3969e-05, 1.0633e-05, 4.2210e-04, 4.7309e-04, 7.7576e-04, 2.9719e-03,
        4.3652e-04, 2.4433e-01, 4.1999e-02, 1.1003e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,668][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([8.6321e-06, 6.1227e-01, 5.3821e-03, 2.9506e-01, 1.0614e-02, 1.5591e-04,
        2.4365e-05, 2.8056e-06, 7.8235e-03, 1.0053e-03, 1.7401e-03, 7.4735e-04,
        1.4298e-04, 4.2412e-02, 1.0903e-02, 1.1713e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,672][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([1.7315e-03, 6.7337e-01, 1.4419e-02, 1.5382e-01, 1.0910e-02, 5.5766e-03,
        1.2457e-03, 1.9362e-04, 1.8984e-02, 1.1019e-02, 1.4122e-02, 8.5084e-03,
        5.0653e-04, 4.9159e-02, 2.2289e-02, 1.4140e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,676][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0032, 0.3444, 0.1454, 0.0590, 0.0662, 0.1385, 0.0315, 0.0032, 0.0231,
        0.0336, 0.0224, 0.0382, 0.0060, 0.0248, 0.0260, 0.0345],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,677][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([1.1403e-03, 5.4851e-01, 3.6752e-02, 1.9167e-01, 2.5012e-02, 7.8902e-04,
        9.0129e-04, 4.2662e-04, 1.9886e-02, 5.7441e-03, 1.7482e-02, 7.6304e-03,
        1.2005e-03, 6.1756e-02, 3.9718e-02, 4.1376e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:30,677][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1001, 0.0632, 0.0450, 0.0633, 0.0430, 0.0794, 0.0851, 0.0600, 0.0579,
        0.0292, 0.0396, 0.0641, 0.0432, 0.0796, 0.0341, 0.0349, 0.0784],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,678][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0468, 0.0569, 0.0657, 0.0631, 0.0671, 0.0609, 0.0620, 0.0598, 0.0585,
        0.0552, 0.0549, 0.0564, 0.0596, 0.0594, 0.0582, 0.0589, 0.0566],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,680][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([5.5457e-14, 8.4887e-07, 9.1667e-01, 4.6199e-04, 3.9799e-02, 1.1948e-06,
        1.4268e-07, 6.4534e-07, 5.7694e-05, 5.3838e-05, 1.3981e-07, 1.6521e-07,
        9.2641e-07, 4.3670e-06, 4.2940e-02, 4.7421e-06, 7.6294e-07],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,685][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0269, 0.0699, 0.0548, 0.0600, 0.0584, 0.0657, 0.0512, 0.0599, 0.0688,
        0.0454, 0.0610, 0.0658, 0.0719, 0.0762, 0.0534, 0.0600, 0.0507],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,691][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0357, 0.0565, 0.0575, 0.0701, 0.0616, 0.0756, 0.0641, 0.0561, 0.0608,
        0.0511, 0.0557, 0.0651, 0.0516, 0.0702, 0.0513, 0.0569, 0.0601],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,692][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0112, 0.0381, 0.0532, 0.0544, 0.0818, 0.0883, 0.0684, 0.0791, 0.0547,
        0.0527, 0.0447, 0.0869, 0.0467, 0.0611, 0.0402, 0.0819, 0.0567],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,693][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([3.4575e-04, 2.3731e-01, 1.0531e-01, 8.9160e-02, 7.4240e-02, 6.0571e-04,
        1.3314e-04, 3.4429e-05, 4.4383e-03, 2.9001e-03, 2.5197e-03, 1.4948e-03,
        1.0186e-03, 2.6252e-02, 1.9387e-01, 5.6766e-02, 2.0360e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,695][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([1.3417e-08, 1.4934e-01, 3.0816e-01, 2.2916e-01, 2.9221e-02, 9.7038e-05,
        3.0769e-06, 1.1004e-06, 9.0199e-05, 1.7247e-04, 2.3047e-04, 8.7674e-04,
        1.3536e-04, 1.1626e-01, 3.6916e-02, 1.4321e-02, 1.1502e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,699][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([2.7046e-05, 5.2847e-01, 1.0023e-02, 2.4160e-01, 1.0997e-02, 1.3685e-04,
        9.0693e-06, 6.7609e-06, 6.8036e-03, 5.4921e-04, 2.9746e-03, 2.6955e-04,
        1.2627e-04, 3.6389e-02, 2.5444e-02, 6.2454e-02, 7.3726e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,702][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.1182e-03, 2.5098e-01, 2.3834e-02, 1.4285e-01, 1.9322e-02, 3.2144e-03,
        5.0893e-04, 1.8449e-04, 1.4794e-02, 1.0664e-02, 2.0729e-02, 5.8623e-03,
        1.7769e-03, 2.5511e-02, 3.7761e-02, 2.7685e-01, 1.6404e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,706][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0039, 0.2509, 0.2436, 0.0647, 0.0998, 0.0895, 0.0259, 0.0007, 0.0133,
        0.0095, 0.0185, 0.0154, 0.0056, 0.0205, 0.0215, 0.0249, 0.0917],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,707][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([9.3147e-04, 3.5632e-01, 8.4247e-02, 1.2920e-01, 3.5517e-02, 7.6628e-04,
        1.7586e-04, 3.1013e-04, 9.4454e-03, 8.2400e-03, 8.8443e-03, 7.3711e-03,
        7.9607e-04, 4.5095e-02, 1.0663e-01, 1.0600e-01, 1.0011e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:30,708][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([0.1087, 0.0649, 0.0431, 0.0586, 0.0391, 0.0781, 0.0712, 0.0588, 0.0553,
        0.0231, 0.0353, 0.0625, 0.0398, 0.0814, 0.0317, 0.0283, 0.0661, 0.0541],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,709][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([0.0452, 0.0542, 0.0615, 0.0595, 0.0633, 0.0575, 0.0584, 0.0562, 0.0549,
        0.0513, 0.0513, 0.0533, 0.0561, 0.0567, 0.0548, 0.0553, 0.0534, 0.0573],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,711][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([2.5983e-09, 1.6309e-06, 9.2110e-01, 4.9938e-03, 4.3147e-02, 2.4956e-06,
        3.1078e-06, 2.6116e-06, 2.5535e-04, 2.1168e-04, 7.4975e-06, 2.3387e-06,
        4.1328e-06, 5.4799e-05, 2.8804e-02, 9.3061e-06, 4.3258e-05, 1.3604e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,716][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([0.0188, 0.0583, 0.0563, 0.0554, 0.0562, 0.0600, 0.0545, 0.0498, 0.0744,
        0.0453, 0.0570, 0.0646, 0.0652, 0.0730, 0.0566, 0.0605, 0.0542, 0.0400],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,722][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([0.0309, 0.0538, 0.0586, 0.0683, 0.0599, 0.0742, 0.0606, 0.0560, 0.0579,
        0.0526, 0.0503, 0.0626, 0.0498, 0.0679, 0.0508, 0.0490, 0.0556, 0.0412],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,723][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([0.0065, 0.0299, 0.0405, 0.0574, 0.0552, 0.1131, 0.0788, 0.0733, 0.0444,
        0.0473, 0.0389, 0.0886, 0.0292, 0.0572, 0.0303, 0.1127, 0.0611, 0.0356],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,724][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([1.4755e-03, 1.6102e-01, 7.5392e-02, 7.3266e-02, 7.7273e-02, 5.3582e-04,
        2.4210e-04, 5.4459e-05, 3.9587e-03, 2.6359e-03, 3.9201e-03, 1.7437e-03,
        7.7842e-04, 3.6428e-02, 1.1486e-01, 4.7892e-02, 2.5179e-01, 1.4674e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,726][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([1.4637e-06, 1.2940e-01, 7.7512e-02, 1.7808e-01, 1.0836e-02, 6.5003e-04,
        7.0011e-05, 1.1733e-05, 7.2050e-04, 3.0009e-04, 1.3181e-03, 4.8850e-03,
        3.1523e-04, 3.1390e-01, 2.5372e-02, 1.6498e-02, 2.3972e-01, 4.1951e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,729][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([1.3448e-04, 4.1438e-01, 5.9771e-03, 2.1146e-01, 9.8750e-03, 1.6771e-04,
        2.7500e-05, 1.2834e-05, 5.5353e-03, 1.0256e-03, 4.8497e-03, 6.3620e-04,
        2.5371e-04, 3.2608e-02, 1.0811e-02, 1.1259e-01, 1.6878e-01, 2.0880e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,733][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([6.1684e-03, 2.4720e-01, 3.9693e-02, 1.6953e-01, 3.7826e-02, 2.5902e-03,
        9.8932e-04, 2.0586e-04, 1.4066e-02, 8.1184e-03, 1.0218e-02, 8.7217e-03,
        1.2470e-03, 4.5958e-02, 5.3072e-02, 4.0549e-02, 2.0688e-01, 1.0696e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,737][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([0.0046, 0.2899, 0.2316, 0.0458, 0.0851, 0.1051, 0.0139, 0.0018, 0.0135,
        0.0167, 0.0122, 0.0126, 0.0037, 0.0155, 0.0404, 0.0301, 0.0458, 0.0315],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,738][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([0.0034, 0.2062, 0.0794, 0.1132, 0.0458, 0.0005, 0.0004, 0.0004, 0.0094,
        0.0159, 0.0162, 0.0090, 0.0018, 0.0405, 0.1007, 0.1076, 0.1999, 0.0497],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:30,739][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0884, 0.0586, 0.0407, 0.0565, 0.0385, 0.0729, 0.0681, 0.0522, 0.0515,
        0.0258, 0.0371, 0.0588, 0.0395, 0.0728, 0.0314, 0.0334, 0.0636, 0.0432,
        0.0669], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,740][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0423, 0.0510, 0.0590, 0.0566, 0.0601, 0.0545, 0.0556, 0.0537, 0.0524,
        0.0494, 0.0492, 0.0504, 0.0531, 0.0530, 0.0522, 0.0527, 0.0506, 0.0538,
        0.0505], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,743][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.6277e-13, 1.2482e-06, 8.9438e-01, 7.6551e-04, 6.0522e-02, 2.3849e-06,
        1.4434e-06, 2.0312e-06, 9.7236e-05, 8.3648e-05, 1.6314e-07, 5.3254e-07,
        9.1587e-07, 1.0441e-05, 4.2554e-02, 1.7862e-05, 7.6478e-06, 1.5572e-03,
        8.0116e-07], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,748][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0229, 0.0593, 0.0486, 0.0525, 0.0479, 0.0622, 0.0527, 0.0488, 0.0653,
        0.0455, 0.0510, 0.0627, 0.0626, 0.0720, 0.0469, 0.0557, 0.0514, 0.0442,
        0.0479], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,752][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0327, 0.0515, 0.0515, 0.0635, 0.0563, 0.0711, 0.0578, 0.0505, 0.0553,
        0.0465, 0.0502, 0.0585, 0.0469, 0.0635, 0.0459, 0.0514, 0.0531, 0.0424,
        0.0516], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,753][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0093, 0.0331, 0.0471, 0.0501, 0.0750, 0.0880, 0.0699, 0.0710, 0.0469,
        0.0521, 0.0331, 0.0803, 0.0353, 0.0533, 0.0343, 0.0901, 0.0552, 0.0531,
        0.0229], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,754][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.8797e-04, 5.6031e-02, 3.5318e-02, 3.0451e-02, 2.4004e-02, 2.2124e-04,
        1.1173e-04, 1.2508e-05, 6.5059e-04, 1.1730e-03, 7.9320e-04, 1.1234e-03,
        3.7824e-04, 7.9900e-03, 5.5457e-02, 2.4308e-02, 2.2603e-01, 1.7762e-01,
        3.5803e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,756][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([2.9567e-07, 1.1852e-01, 2.6894e-01, 1.1154e-01, 2.3463e-02, 5.7441e-05,
        4.4853e-06, 1.8058e-06, 7.6019e-05, 1.6565e-04, 2.0476e-04, 8.1357e-04,
        1.4976e-04, 4.2906e-02, 3.2370e-02, 1.0448e-02, 9.8516e-02, 1.8493e-03,
        2.8997e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,759][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.5654e-05, 1.5562e-01, 2.3188e-03, 5.6033e-02, 1.4097e-03, 4.2113e-05,
        3.3964e-06, 9.3215e-07, 8.5765e-04, 8.2811e-05, 3.1649e-04, 2.0700e-04,
        1.7733e-05, 1.2854e-02, 5.1001e-03, 1.5910e-02, 4.6053e-02, 3.6298e-02,
        6.6685e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,763][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.3100e-03, 2.0048e-01, 9.0219e-03, 7.1212e-02, 1.0647e-02, 9.6905e-04,
        3.6514e-04, 5.5020e-05, 4.6124e-03, 3.4564e-03, 1.7634e-03, 4.1606e-03,
        2.2163e-04, 1.7460e-02, 2.0159e-02, 7.3333e-02, 1.5135e-01, 1.0023e-01,
        3.2920e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,767][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0024, 0.2693, 0.1685, 0.0606, 0.0882, 0.0769, 0.0285, 0.0013, 0.0183,
        0.0124, 0.0220, 0.0143, 0.0043, 0.0231, 0.0190, 0.0229, 0.0916, 0.0155,
        0.0609], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,768][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([5.8153e-04, 1.3251e-01, 2.1788e-02, 5.2422e-02, 9.7061e-03, 2.0054e-04,
        1.4129e-04, 1.1254e-04, 3.2008e-03, 5.9649e-03, 4.3439e-03, 3.8648e-03,
        3.5255e-04, 2.1043e-02, 3.5981e-02, 5.9200e-02, 1.0997e-01, 9.8407e-02,
        4.4021e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:30,772][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:30,775][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[9210],
        [1182],
        [1694],
        [4072],
        [ 125],
        [4604],
        [1647],
        [4278],
        [6689],
        [6826],
        [2430],
        [ 842],
        [5172],
        [2464],
        [2732],
        [3291],
        [2003],
        [ 507],
        [1567]], device='cuda:0')
[2024-07-24 10:27:30,777][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[10277],
        [ 2180],
        [ 2888],
        [ 6572],
        [  304],
        [ 8035],
        [ 3688],
        [ 3999],
        [16018],
        [14099],
        [ 4319],
        [ 2790],
        [ 8183],
        [ 5426],
        [10431],
        [ 4796],
        [ 2983],
        [ 1514],
        [ 5655]], device='cuda:0')
[2024-07-24 10:27:30,780][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[108],
        [ 81],
        [ 83],
        [ 58],
        [ 49],
        [ 59],
        [ 54],
        [ 58],
        [ 54],
        [ 74],
        [ 72],
        [155],
        [ 62],
        [ 52],
        [ 48],
        [ 51],
        [ 61],
        [ 76],
        [ 64]], device='cuda:0')
[2024-07-24 10:27:30,782][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[21167],
        [25427],
        [23760],
        [23960],
        [23103],
        [23843],
        [24990],
        [25648],
        [25149],
        [24953],
        [24598],
        [24679],
        [25019],
        [25219],
        [24718],
        [23892],
        [24392],
        [24860],
        [24524]], device='cuda:0')
[2024-07-24 10:27:30,785][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 3092],
        [30129],
        [33231],
        [33225],
        [33200],
        [33153],
        [33229],
        [33186],
        [33232],
        [33201],
        [33224],
        [33225],
        [33210],
        [33230],
        [33177],
        [33186],
        [33221],
        [33117],
        [33224]], device='cuda:0')
[2024-07-24 10:27:30,787][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 85],
        [ 46],
        [131],
        [107],
        [ 22],
        [  8],
        [ 11],
        [ 11],
        [ 16],
        [  7],
        [ 13],
        [ 10],
        [ 11],
        [  8],
        [ 13],
        [ 14],
        [  9],
        [ 13],
        [ 10]], device='cuda:0')
[2024-07-24 10:27:30,788][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[14136],
        [14020],
        [14045],
        [14704],
        [14487],
        [15062],
        [15611],
        [15856],
        [15780],
        [15652],
        [15942],
        [16090],
        [16021],
        [15918],
        [15765],
        [15668],
        [15959],
        [15989],
        [16131]], device='cuda:0')
[2024-07-24 10:27:30,790][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[18939],
        [17781],
        [ 7866],
        [16226],
        [ 4483],
        [ 5061],
        [ 9222],
        [10892],
        [ 4824],
        [ 7531],
        [23443],
        [18856],
        [11690],
        [26558],
        [ 9357],
        [20058],
        [21689],
        [17300],
        [29278]], device='cuda:0')
[2024-07-24 10:27:30,793][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[19001],
        [15302],
        [15258],
        [15808],
        [16250],
        [21755],
        [17992],
        [18119],
        [17081],
        [18080],
        [19360],
        [19654],
        [18582],
        [22162],
        [16926],
        [18354],
        [16540],
        [18476],
        [17730]], device='cuda:0')
[2024-07-24 10:27:30,795][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[27899],
        [37937],
        [39099],
        [36995],
        [37562],
        [37529],
        [37360],
        [37201],
        [37298],
        [36969],
        [36713],
        [36573],
        [36950],
        [37195],
        [37311],
        [37235],
        [37254],
        [37619],
        [37602]], device='cuda:0')
[2024-07-24 10:27:30,798][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 3375],
        [35267],
        [40229],
        [39327],
        [36877],
        [35590],
        [35067],
        [34708],
        [34494],
        [34776],
        [35740],
        [33889],
        [33618],
        [34317],
        [34972],
        [35261],
        [36658],
        [35482],
        [36363]], device='cuda:0')
[2024-07-24 10:27:30,800][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[13060],
        [27001],
        [26429],
        [29226],
        [30791],
        [30710],
        [32261],
        [31906],
        [31394],
        [33678],
        [32843],
        [32578],
        [33770],
        [32524],
        [27845],
        [33188],
        [43245],
        [33802],
        [35435]], device='cuda:0')
[2024-07-24 10:27:30,803][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[34552],
        [42708],
        [43595],
        [43363],
        [44014],
        [42741],
        [42587],
        [42668],
        [43023],
        [42265],
        [42900],
        [42522],
        [42168],
        [42563],
        [41967],
        [42040],
        [42028],
        [41562],
        [41888]], device='cuda:0')
[2024-07-24 10:27:30,805][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[31910],
        [28814],
        [25467],
        [24504],
        [27455],
        [25922],
        [24206],
        [22707],
        [22896],
        [24254],
        [23098],
        [23199],
        [22299],
        [21676],
        [24470],
        [22210],
        [21438],
        [21347],
        [21631]], device='cuda:0')
[2024-07-24 10:27:30,807][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[11399],
        [17798],
        [15039],
        [34843],
        [18302],
        [38219],
        [29532],
        [36283],
        [21873],
        [30416],
        [26581],
        [16945],
        [36615],
        [24526],
        [14175],
        [25043],
        [23602],
        [21063],
        [12974]], device='cuda:0')
[2024-07-24 10:27:30,809][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[38565],
        [38911],
        [38327],
        [38753],
        [39263],
        [39405],
        [40178],
        [40007],
        [40031],
        [39951],
        [40229],
        [40101],
        [40164],
        [40109],
        [39982],
        [39928],
        [40191],
        [40130],
        [40174]], device='cuda:0')
[2024-07-24 10:27:30,811][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[17774],
        [18473],
        [19416],
        [19705],
        [19229],
        [18789],
        [18557],
        [18413],
        [18473],
        [18872],
        [19011],
        [18992],
        [18803],
        [18710],
        [18822],
        [18828],
        [18756],
        [18649],
        [18538]], device='cuda:0')
[2024-07-24 10:27:30,814][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[12699],
        [ 4161],
        [ 7950],
        [ 7951],
        [ 7910],
        [ 7869],
        [ 7830],
        [ 7852],
        [ 7870],
        [ 7807],
        [ 7780],
        [ 7770],
        [ 7898],
        [ 7850],
        [ 7870],
        [ 7867],
        [ 7856],
        [ 7854],
        [ 7818]], device='cuda:0')
[2024-07-24 10:27:30,817][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[43824],
        [32264],
        [28608],
        [25975],
        [30347],
        [29544],
        [28385],
        [30664],
        [31096],
        [30740],
        [31202],
        [30988],
        [31237],
        [30651],
        [30253],
        [30101],
        [30122],
        [29757],
        [29846]], device='cuda:0')
[2024-07-24 10:27:30,819][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[5516],
        [6115],
        [7272],
        [5711],
        [6153],
        [6808],
        [6322],
        [6616],
        [6015],
        [6524],
        [6433],
        [6240],
        [6648],
        [6392],
        [6476],
        [6598],
        [6447],
        [6592],
        [6261]], device='cuda:0')
[2024-07-24 10:27:30,822][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[5032],
        [4739],
        [2391],
        [3690],
        [3865],
        [3783],
        [3715],
        [3369],
        [3385],
        [3371],
        [3334],
        [3595],
        [3710],
        [3458],
        [3395],
        [3250],
        [3278],
        [3230],
        [3085]], device='cuda:0')
[2024-07-24 10:27:30,824][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[28095],
        [17788],
        [13854],
        [12771],
        [12517],
        [12059],
        [11747],
        [11555],
        [12280],
        [11938],
        [11879],
        [11781],
        [11293],
        [11391],
        [10555],
        [ 9385],
        [ 8274],
        [ 8665],
        [12692]], device='cuda:0')
[2024-07-24 10:27:30,826][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[36672],
        [  483],
        [  582],
        [ 1133],
        [  917],
        [ 1088],
        [ 1329],
        [ 1289],
        [ 1118],
        [  918],
        [ 1208],
        [ 1174],
        [ 1059],
        [ 1573],
        [  632],
        [  913],
        [ 1325],
        [ 1016],
        [ 1271]], device='cuda:0')
[2024-07-24 10:27:30,827][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[21197],
        [17886],
        [16927],
        [15391],
        [12149],
        [12356],
        [12044],
        [11311],
        [13071],
        [11676],
        [12860],
        [11870],
        [11875],
        [12347],
        [11877],
        [12152],
        [11626],
        [11316],
        [10474]], device='cuda:0')
[2024-07-24 10:27:30,830][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[10041],
        [ 4126],
        [ 4067],
        [ 3436],
        [ 2542],
        [ 3123],
        [ 1865],
        [ 1958],
        [ 2247],
        [ 2249],
        [ 2267],
        [ 2321],
        [ 2172],
        [ 2122],
        [ 3182],
        [ 2734],
        [ 5151],
        [ 3953],
        [ 2487]], device='cuda:0')
[2024-07-24 10:27:30,833][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[39615],
        [26102],
        [16553],
        [16069],
        [13328],
        [17510],
        [15934],
        [17696],
        [17093],
        [16750],
        [17521],
        [17230],
        [17023],
        [18982],
        [16233],
        [19903],
        [18483],
        [17501],
        [19429]], device='cuda:0')
[2024-07-24 10:27:30,835][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 8580],
        [ 6092],
        [ 6767],
        [ 6506],
        [ 6707],
        [ 6796],
        [ 7010],
        [ 6813],
        [ 7406],
        [ 6739],
        [ 6427],
        [ 6883],
        [ 6405],
        [ 7539],
        [ 7263],
        [ 6307],
        [ 8491],
        [10665],
        [11002]], device='cuda:0')
[2024-07-24 10:27:30,838][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[18223],
        [33960],
        [35391],
        [36172],
        [37382],
        [36637],
        [37548],
        [37157],
        [36956],
        [37467],
        [37220],
        [37054],
        [37412],
        [36566],
        [37320],
        [37490],
        [35840],
        [35894],
        [36061]], device='cuda:0')
[2024-07-24 10:27:30,840][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 8552],
        [32777],
        [36843],
        [29841],
        [33313],
        [27417],
        [28706],
        [28337],
        [30381],
        [28197],
        [28303],
        [28958],
        [26590],
        [28532],
        [29169],
        [30054],
        [27476],
        [26016],
        [29990]], device='cuda:0')
[2024-07-24 10:27:30,842][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566]], device='cuda:0')
[2024-07-24 10:27:30,888][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:30,891][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,893][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,894][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,895][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,895][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,896][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,897][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,898][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,899][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,899][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,900][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,901][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:30,901][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1298, 0.8702], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,902][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0388, 0.9612], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,903][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.5447, 0.4553], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,907][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2411, 0.7589], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,910][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2964, 0.7036], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,914][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0782, 0.9218], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,915][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9493, 0.0507], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,915][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2111, 0.7889], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,916][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4498, 0.5502], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,917][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.5433, 0.4567], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,919][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.8931, 0.1069], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,921][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([2.5030e-04, 9.9975e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:30,925][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.0622, 0.4933, 0.4445], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,929][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0258, 0.6160, 0.3582], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,932][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.2462, 0.3799, 0.3739], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,933][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0859, 0.4079, 0.5061], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,933][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.1781, 0.4434, 0.3785], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,934][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0345, 0.5676, 0.3979], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,935][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.8431, 0.1008, 0.0561], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,937][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.1090, 0.4502, 0.4408], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,940][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.3117, 0.3807, 0.3076], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,944][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.2738, 0.4908, 0.2354], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,948][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.4230, 0.0421, 0.5349], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,950][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([6.2621e-16, 1.0000e+00, 2.1856e-13], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:30,951][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0520, 0.3439, 0.3126, 0.2915], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,951][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0118, 0.3775, 0.2865, 0.3241], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,952][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2028, 0.2389, 0.3260, 0.2323], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,953][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0777, 0.2812, 0.3760, 0.2651], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,955][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1289, 0.3356, 0.2744, 0.2612], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,957][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0159, 0.3716, 0.2389, 0.3736], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,961][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.8235, 0.0750, 0.0507, 0.0508], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,966][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1666, 0.3541, 0.3126, 0.1668], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,968][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2394, 0.2922, 0.2285, 0.2399], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,969][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2626, 0.2991, 0.2171, 0.2212], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,970][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.7238, 0.1079, 0.0585, 0.1099], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,970][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([1.3738e-16, 1.0000e+00, 6.9743e-12, 1.0478e-08], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:30,971][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.0392, 0.2699, 0.2409, 0.2254, 0.2245], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,973][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([0.0111, 0.3297, 0.2258, 0.2919, 0.1416], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,977][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.1400, 0.2102, 0.2366, 0.1726, 0.2406], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,980][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.0665, 0.2180, 0.2680, 0.2159, 0.2315], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,984][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.1064, 0.2415, 0.2063, 0.2007, 0.2450], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,986][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([0.0133, 0.3010, 0.2006, 0.3177, 0.1675], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,987][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.7715, 0.0874, 0.0472, 0.0601, 0.0337], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,988][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.0879, 0.3103, 0.3323, 0.1153, 0.1542], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,989][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.1932, 0.2308, 0.1871, 0.1917, 0.1972], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,990][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.1735, 0.2813, 0.1717, 0.2127, 0.1608], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,993][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.4896, 0.1515, 0.0692, 0.0434, 0.2463], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,995][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([4.3904e-19, 1.0000e+00, 2.5774e-13, 9.3893e-07, 3.8150e-17],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:30,999][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0288, 0.2244, 0.2104, 0.1878, 0.1911, 0.1576], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,003][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0114, 0.2704, 0.1862, 0.2547, 0.1334, 0.1439], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,004][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.1221, 0.1972, 0.1899, 0.1581, 0.2066, 0.1260], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,005][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0764, 0.1828, 0.2321, 0.1774, 0.1974, 0.1339], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,006][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1023, 0.1963, 0.1575, 0.1570, 0.1818, 0.2050], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,007][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0154, 0.2400, 0.1756, 0.2752, 0.1485, 0.1453], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,009][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.5783, 0.1391, 0.0761, 0.0864, 0.0598, 0.0604], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,012][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0258, 0.4062, 0.2403, 0.0708, 0.0781, 0.1788], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,016][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1502, 0.1828, 0.1493, 0.1498, 0.1578, 0.2101], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,020][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.1800, 0.2038, 0.1448, 0.1543, 0.1927, 0.1244], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,022][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.2837, 0.1768, 0.0517, 0.0356, 0.2375, 0.2148], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,023][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ had] are: tensor([9.4967e-22, 9.9978e-01, 3.6693e-09, 2.2278e-04, 1.3180e-09, 1.1259e-16],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,024][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0261, 0.1910, 0.1744, 0.1600, 0.1620, 0.1377, 0.1487],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,025][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0080, 0.2234, 0.1732, 0.2039, 0.1382, 0.1337, 0.1196],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,026][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0853, 0.1601, 0.1909, 0.1512, 0.2029, 0.1117, 0.0979],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,028][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0576, 0.1607, 0.1997, 0.1582, 0.1691, 0.1279, 0.1268],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,031][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0766, 0.1645, 0.1374, 0.1334, 0.1566, 0.1673, 0.1642],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,034][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0064, 0.2079, 0.1540, 0.2269, 0.1258, 0.1303, 0.1487],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,038][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.6714, 0.0707, 0.0469, 0.0507, 0.0391, 0.0427, 0.0785],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,041][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1097, 0.2317, 0.1783, 0.0881, 0.1024, 0.1745, 0.1155],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,041][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1268, 0.1561, 0.1263, 0.1306, 0.1368, 0.1861, 0.1373],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,042][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1875, 0.1787, 0.1401, 0.1371, 0.1655, 0.1170, 0.0741],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,043][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2217, 0.1437, 0.1985, 0.0489, 0.2339, 0.1065, 0.0468],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,044][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.5149e-27, 9.9998e-01, 6.5300e-14, 1.7982e-05, 8.3140e-15, 3.2039e-20,
        1.7988e-24], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,047][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0195, 0.1665, 0.1547, 0.1393, 0.1440, 0.1197, 0.1313, 0.1251],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,051][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0059, 0.2020, 0.1476, 0.1996, 0.1078, 0.1106, 0.1236, 0.1028],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,055][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.1360, 0.1190, 0.1655, 0.1123, 0.1930, 0.0975, 0.0916, 0.0850],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,059][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0543, 0.1459, 0.1777, 0.1418, 0.1578, 0.1195, 0.1180, 0.0850],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,059][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0683, 0.1424, 0.1134, 0.1130, 0.1346, 0.1463, 0.1386, 0.1434],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,060][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0068, 0.1907, 0.1258, 0.2028, 0.1091, 0.1096, 0.1344, 0.1206],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,061][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.5084, 0.0926, 0.0544, 0.0665, 0.0534, 0.0525, 0.1053, 0.0668],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,063][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0550, 0.2621, 0.1979, 0.0665, 0.0892, 0.1520, 0.0733, 0.1041],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,065][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.1121, 0.1362, 0.1097, 0.1122, 0.1190, 0.1611, 0.1183, 0.1312],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,070][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.1417, 0.1679, 0.1423, 0.1459, 0.1386, 0.0911, 0.1129, 0.0597],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,073][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.4631, 0.0392, 0.0540, 0.0292, 0.0880, 0.0489, 0.0581, 0.2195],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,075][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([1.1978e-25, 9.9895e-01, 1.6802e-10, 1.0516e-03, 2.0179e-10, 8.0255e-18,
        4.1789e-17, 3.8080e-24], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,077][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0221, 0.1462, 0.1345, 0.1233, 0.1239, 0.1060, 0.1147, 0.1098, 0.1194],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,078][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0060, 0.1710, 0.1412, 0.1583, 0.1076, 0.1025, 0.1069, 0.1101, 0.0964],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,079][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0790, 0.1231, 0.1612, 0.1242, 0.1694, 0.0948, 0.0803, 0.1012, 0.0668],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,080][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0314, 0.1281, 0.1622, 0.1253, 0.1455, 0.1032, 0.1085, 0.0898, 0.1061],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,082][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0471, 0.1336, 0.1019, 0.0963, 0.1235, 0.1365, 0.1309, 0.1320, 0.0982],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,084][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0067, 0.1695, 0.1110, 0.1816, 0.0943, 0.0963, 0.1241, 0.1145, 0.1020],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,088][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.5321, 0.0764, 0.0543, 0.0531, 0.0445, 0.0533, 0.0809, 0.0624, 0.0430],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,093][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.1212, 0.1797, 0.1537, 0.0714, 0.0819, 0.1600, 0.0747, 0.0954, 0.0619],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,095][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0973, 0.1241, 0.0974, 0.1008, 0.1084, 0.1449, 0.1081, 0.1175, 0.1016],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,096][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.1259, 0.1495, 0.1192, 0.1186, 0.1410, 0.0982, 0.0774, 0.0897, 0.0805],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,097][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.4151, 0.0697, 0.0530, 0.0269, 0.2084, 0.0318, 0.0175, 0.0858, 0.0917],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,097][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ of] are: tensor([1.5148e-20, 1.0000e+00, 2.0330e-11, 7.7973e-07, 6.3006e-14, 2.4865e-17,
        1.1148e-22, 1.2386e-23, 1.9812e-16], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,099][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0176, 0.1303, 0.1203, 0.1099, 0.1113, 0.0947, 0.1021, 0.0985, 0.1063,
        0.1091], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,102][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0099, 0.1650, 0.1212, 0.1454, 0.0843, 0.0918, 0.1035, 0.1060, 0.1037,
        0.0692], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,106][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0687, 0.1205, 0.1389, 0.1110, 0.1461, 0.0858, 0.0756, 0.0964, 0.0672,
        0.0897], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,111][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0338, 0.1187, 0.1431, 0.1161, 0.1297, 0.0907, 0.1005, 0.0719, 0.1046,
        0.0909], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,113][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0400, 0.1251, 0.0925, 0.0895, 0.1099, 0.1252, 0.1184, 0.1223, 0.0859,
        0.0912], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,114][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0052, 0.1494, 0.1169, 0.1628, 0.0933, 0.1006, 0.1060, 0.0995, 0.0984,
        0.0681], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,115][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.3959, 0.1247, 0.0510, 0.0627, 0.0464, 0.0630, 0.1018, 0.0764, 0.0422,
        0.0360], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,115][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0855, 0.1831, 0.1798, 0.0590, 0.0821, 0.1378, 0.0692, 0.1003, 0.0550,
        0.0482], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,117][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0921, 0.1116, 0.0874, 0.0900, 0.0936, 0.1295, 0.0956, 0.1066, 0.0911,
        0.1025], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,120][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.1439, 0.1485, 0.1065, 0.1211, 0.1104, 0.0767, 0.0993, 0.0598, 0.0752,
        0.0587], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,124][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.2650, 0.0491, 0.2010, 0.0595, 0.0532, 0.0264, 0.0337, 0.0677, 0.1935,
        0.0510], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,126][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([6.6855e-25, 9.9987e-01, 7.5297e-13, 1.3027e-04, 2.5180e-13, 1.3651e-18,
        3.7021e-21, 1.2374e-25, 1.4096e-13, 1.0017e-21], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,131][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0171, 0.1178, 0.1082, 0.0996, 0.1002, 0.0848, 0.0931, 0.0906, 0.0964,
        0.1018, 0.0906], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,131][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0064, 0.1476, 0.1076, 0.1335, 0.0865, 0.0919, 0.0887, 0.0920, 0.0920,
        0.0890, 0.0649], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,132][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0771, 0.1079, 0.1413, 0.1000, 0.1417, 0.0776, 0.0700, 0.0843, 0.0549,
        0.0824, 0.0629], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,133][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0363, 0.1021, 0.1372, 0.1020, 0.1176, 0.0826, 0.0846, 0.0704, 0.0874,
        0.1074, 0.0724], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,134][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0366, 0.1215, 0.0898, 0.0836, 0.1030, 0.1198, 0.1114, 0.1150, 0.0746,
        0.0774, 0.0671], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,136][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0049, 0.1493, 0.0904, 0.1661, 0.0755, 0.0862, 0.1054, 0.0969, 0.0960,
        0.0703, 0.0590], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,140][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.4310, 0.0804, 0.0481, 0.0504, 0.0411, 0.0527, 0.0787, 0.0675, 0.0448,
        0.0418, 0.0637], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,143][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0830, 0.1754, 0.1351, 0.0625, 0.0677, 0.1477, 0.0720, 0.0951, 0.0563,
        0.0413, 0.0639], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,147][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0813, 0.1045, 0.0776, 0.0829, 0.0872, 0.1228, 0.0905, 0.0985, 0.0856,
        0.0984, 0.0706], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,149][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0845, 0.1293, 0.0822, 0.0961, 0.1211, 0.0879, 0.0700, 0.0720, 0.0820,
        0.1199, 0.0548], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,150][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.2220, 0.1172, 0.0578, 0.0252, 0.2823, 0.0112, 0.0172, 0.0506, 0.1075,
        0.0257, 0.0834], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,151][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ at] are: tensor([1.7026e-23, 1.0000e+00, 5.7594e-12, 2.9160e-06, 4.5392e-14, 6.7520e-19,
        3.6160e-23, 1.3780e-25, 6.3453e-16, 3.0552e-20, 2.8862e-19],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,152][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0158, 0.1086, 0.1000, 0.0912, 0.0918, 0.0780, 0.0845, 0.0824, 0.0877,
        0.0920, 0.0835, 0.0845], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,154][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0044, 0.1378, 0.1022, 0.1238, 0.0823, 0.0851, 0.0746, 0.0764, 0.0839,
        0.0811, 0.0625, 0.0858], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,156][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0588, 0.1006, 0.1291, 0.0973, 0.1379, 0.0751, 0.0671, 0.0859, 0.0560,
        0.0802, 0.0655, 0.0467], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,160][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0283, 0.0962, 0.1244, 0.0959, 0.1055, 0.0769, 0.0797, 0.0639, 0.0851,
        0.0919, 0.0736, 0.0786], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,165][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0395, 0.1040, 0.0781, 0.0750, 0.0931, 0.1067, 0.1000, 0.1050, 0.0744,
        0.0754, 0.0649, 0.0840], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,167][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0028, 0.1297, 0.0934, 0.1423, 0.0775, 0.0767, 0.0912, 0.0893, 0.0853,
        0.0662, 0.0622, 0.0834], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,168][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.4745, 0.0612, 0.0395, 0.0399, 0.0352, 0.0419, 0.0664, 0.0550, 0.0367,
        0.0386, 0.0575, 0.0536], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,168][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0933, 0.1583, 0.1311, 0.0522, 0.0686, 0.1471, 0.0680, 0.0904, 0.0465,
        0.0367, 0.0535, 0.0544], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,169][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0748, 0.0945, 0.0748, 0.0773, 0.0816, 0.1116, 0.0814, 0.0908, 0.0789,
        0.0943, 0.0659, 0.0740], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,171][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1005, 0.1275, 0.0884, 0.1020, 0.1106, 0.0769, 0.0579, 0.0621, 0.0910,
        0.0651, 0.0690, 0.0489], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,174][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.3113, 0.0435, 0.0579, 0.0269, 0.0771, 0.1280, 0.0280, 0.1143, 0.1029,
        0.0221, 0.0586, 0.0293], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,176][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.3949e-26, 9.9998e-01, 8.3410e-15, 1.7592e-05, 8.0089e-16, 3.7568e-20,
        2.5158e-24, 8.1509e-28, 2.5584e-15, 2.9445e-22, 2.2581e-18, 2.6137e-24],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,180][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0135, 0.1009, 0.0937, 0.0841, 0.0866, 0.0710, 0.0791, 0.0771, 0.0820,
        0.0861, 0.0779, 0.0787, 0.0694], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,184][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0037, 0.1218, 0.0902, 0.1223, 0.0716, 0.0734, 0.0828, 0.0777, 0.0827,
        0.0664, 0.0630, 0.0918, 0.0526], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,185][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0544, 0.0962, 0.1108, 0.0836, 0.1149, 0.0706, 0.0664, 0.0869, 0.0595,
        0.0773, 0.0664, 0.0514, 0.0616], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,186][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0290, 0.0867, 0.1106, 0.0854, 0.0965, 0.0700, 0.0764, 0.0575, 0.0781,
        0.0838, 0.0699, 0.0767, 0.0793], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,187][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0409, 0.0892, 0.0738, 0.0707, 0.0824, 0.0890, 0.0859, 0.0889, 0.0754,
        0.0762, 0.0671, 0.0769, 0.0837], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,189][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0019, 0.1244, 0.0865, 0.1383, 0.0682, 0.0776, 0.0864, 0.0781, 0.0823,
        0.0592, 0.0608, 0.0772, 0.0592], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,192][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.2671, 0.0902, 0.0411, 0.0558, 0.0430, 0.0604, 0.0913, 0.0679, 0.0439,
        0.0370, 0.0602, 0.0708, 0.0713], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,196][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0628, 0.1653, 0.1487, 0.0473, 0.0672, 0.1323, 0.0581, 0.0860, 0.0433,
        0.0360, 0.0499, 0.0471, 0.0560], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,200][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.0719, 0.0878, 0.0734, 0.0706, 0.0766, 0.1029, 0.0745, 0.0827, 0.0702,
        0.0854, 0.0609, 0.0667, 0.0763], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,202][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0702, 0.1152, 0.1159, 0.1182, 0.0852, 0.0635, 0.0794, 0.0498, 0.0858,
        0.0559, 0.0709, 0.0494, 0.0406], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,203][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.1247, 0.0297, 0.0399, 0.0133, 0.0298, 0.0058, 0.0198, 0.0460, 0.0406,
        0.0642, 0.0096, 0.0100, 0.5666], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,204][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ store] are: tensor([1.5175e-27, 9.9971e-01, 4.2932e-13, 2.8569e-04, 4.8930e-14, 7.7587e-20,
        1.6664e-20, 3.9093e-26, 8.5199e-14, 1.0254e-19, 1.5366e-17, 9.7206e-20,
        6.1125e-26], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,205][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0143, 0.0930, 0.0856, 0.0792, 0.0791, 0.0660, 0.0739, 0.0714, 0.0760,
        0.0800, 0.0721, 0.0741, 0.0660, 0.0693], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,207][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0033, 0.1166, 0.0926, 0.1019, 0.0679, 0.0707, 0.0713, 0.0702, 0.0698,
        0.0712, 0.0541, 0.0829, 0.0594, 0.0680], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,210][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0531, 0.0836, 0.1270, 0.0821, 0.1241, 0.0664, 0.0580, 0.0802, 0.0509,
        0.0714, 0.0580, 0.0406, 0.0595, 0.0452], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,214][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0215, 0.0806, 0.1060, 0.0798, 0.0911, 0.0654, 0.0714, 0.0548, 0.0723,
        0.0777, 0.0605, 0.0719, 0.0779, 0.0693], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,218][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0319, 0.0793, 0.0681, 0.0661, 0.0773, 0.0837, 0.0804, 0.0856, 0.0705,
        0.0725, 0.0628, 0.0723, 0.0770, 0.0726], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,220][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0026, 0.1133, 0.0753, 0.1224, 0.0653, 0.0669, 0.0821, 0.0775, 0.0735,
        0.0572, 0.0536, 0.0742, 0.0609, 0.0754], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,221][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.2934, 0.0712, 0.0413, 0.0489, 0.0383, 0.0440, 0.0767, 0.0597, 0.0405,
        0.0322, 0.0555, 0.0633, 0.0694, 0.0658], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,222][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0767, 0.1687, 0.1341, 0.0492, 0.0561, 0.1084, 0.0591, 0.0775, 0.0421,
        0.0326, 0.0486, 0.0444, 0.0495, 0.0531], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,223][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0645, 0.0797, 0.0645, 0.0666, 0.0700, 0.0947, 0.0699, 0.0768, 0.0670,
        0.0785, 0.0561, 0.0641, 0.0731, 0.0745], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,225][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0973, 0.1143, 0.0822, 0.0837, 0.0832, 0.0669, 0.0698, 0.0567, 0.0659,
        0.0542, 0.0449, 0.0500, 0.0654, 0.0654], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,229][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.2869, 0.0455, 0.0365, 0.0168, 0.1921, 0.0172, 0.0166, 0.0347, 0.1030,
        0.0264, 0.0436, 0.0143, 0.0738, 0.0925], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,231][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [.] are: tensor([7.2123e-21, 9.9998e-01, 2.5163e-11, 2.1967e-05, 1.1029e-12, 1.4206e-17,
        1.1744e-21, 3.6852e-24, 7.6662e-15, 8.1453e-19, 3.8486e-17, 4.3720e-21,
        9.0416e-23, 1.1961e-13], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,234][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.0115, 0.0896, 0.0824, 0.0731, 0.0740, 0.0624, 0.0671, 0.0663, 0.0700,
        0.0739, 0.0660, 0.0669, 0.0606, 0.0636, 0.0727], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,238][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0045, 0.1130, 0.0709, 0.1081, 0.0551, 0.0725, 0.0707, 0.0732, 0.0698,
        0.0538, 0.0546, 0.0780, 0.0550, 0.0713, 0.0496], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,239][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.0586, 0.0973, 0.1024, 0.0754, 0.1070, 0.0600, 0.0535, 0.0710, 0.0479,
        0.0600, 0.0512, 0.0376, 0.0488, 0.0447, 0.0847], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,240][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0143, 0.0761, 0.0933, 0.0752, 0.0837, 0.0592, 0.0687, 0.0504, 0.0679,
        0.0675, 0.0606, 0.0638, 0.0690, 0.0647, 0.0855], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,241][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.0301, 0.0802, 0.0723, 0.0662, 0.0770, 0.0825, 0.0813, 0.0790, 0.0619,
        0.0586, 0.0509, 0.0617, 0.0697, 0.0678, 0.0607], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,243][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0027, 0.1037, 0.0672, 0.1121, 0.0569, 0.0685, 0.0792, 0.0773, 0.0720,
        0.0522, 0.0547, 0.0690, 0.0582, 0.0791, 0.0471], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,246][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.1977, 0.0978, 0.0363, 0.0554, 0.0425, 0.0563, 0.0911, 0.0659, 0.0368,
        0.0360, 0.0487, 0.0695, 0.0715, 0.0773, 0.0173], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,250][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.0690, 0.1354, 0.1453, 0.0410, 0.0629, 0.1040, 0.0535, 0.0775, 0.0415,
        0.0332, 0.0474, 0.0436, 0.0525, 0.0495, 0.0437], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,254][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.0608, 0.0761, 0.0616, 0.0612, 0.0668, 0.0927, 0.0656, 0.0710, 0.0616,
        0.0739, 0.0521, 0.0594, 0.0695, 0.0703, 0.0573], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,256][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0629, 0.1311, 0.0573, 0.0955, 0.0824, 0.0710, 0.0723, 0.0446, 0.0696,
        0.0437, 0.0504, 0.0518, 0.0526, 0.0750, 0.0399], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,257][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.1519, 0.0125, 0.1963, 0.0090, 0.0284, 0.0356, 0.0253, 0.0099, 0.0285,
        0.0236, 0.0274, 0.0238, 0.2069, 0.0453, 0.1756], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,258][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([5.2286e-20, 9.9997e-01, 1.7470e-13, 3.0574e-05, 5.1531e-14, 4.5301e-17,
        6.1763e-21, 7.3361e-24, 1.2384e-13, 1.3111e-19, 5.4742e-17, 4.7917e-20,
        1.1406e-23, 2.4787e-12, 2.5814e-18], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,259][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0102, 0.0842, 0.0792, 0.0689, 0.0703, 0.0574, 0.0640, 0.0624, 0.0659,
        0.0688, 0.0619, 0.0639, 0.0569, 0.0597, 0.0694, 0.0570],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,261][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0040, 0.1056, 0.0697, 0.1005, 0.0538, 0.0608, 0.0667, 0.0742, 0.0684,
        0.0571, 0.0539, 0.0766, 0.0466, 0.0702, 0.0539, 0.0381],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,265][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0580, 0.0893, 0.0981, 0.0712, 0.1028, 0.0593, 0.0539, 0.0644, 0.0441,
        0.0618, 0.0478, 0.0381, 0.0495, 0.0422, 0.0774, 0.0423],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,268][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0170, 0.0723, 0.0937, 0.0687, 0.0838, 0.0548, 0.0580, 0.0457, 0.0627,
        0.0610, 0.0576, 0.0616, 0.0667, 0.0631, 0.0888, 0.0446],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,272][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0252, 0.0781, 0.0669, 0.0610, 0.0735, 0.0820, 0.0790, 0.0777, 0.0590,
        0.0551, 0.0465, 0.0600, 0.0686, 0.0660, 0.0537, 0.0477],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,274][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0028, 0.0975, 0.0697, 0.1118, 0.0603, 0.0613, 0.0736, 0.0668, 0.0726,
        0.0496, 0.0485, 0.0676, 0.0519, 0.0742, 0.0512, 0.0406],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,275][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1576, 0.1009, 0.0414, 0.0562, 0.0429, 0.0553, 0.0903, 0.0646, 0.0409,
        0.0331, 0.0518, 0.0684, 0.0596, 0.0668, 0.0191, 0.0510],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,276][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0306, 0.2119, 0.1485, 0.0424, 0.0491, 0.1239, 0.0481, 0.0631, 0.0324,
        0.0227, 0.0381, 0.0344, 0.0370, 0.0408, 0.0250, 0.0519],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,277][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0583, 0.0701, 0.0561, 0.0574, 0.0604, 0.0856, 0.0635, 0.0699, 0.0591,
        0.0703, 0.0503, 0.0556, 0.0657, 0.0648, 0.0521, 0.0608],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,279][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0653, 0.0996, 0.0743, 0.0799, 0.0714, 0.0558, 0.0516, 0.0461, 0.0585,
        0.0571, 0.0517, 0.0551, 0.0605, 0.0787, 0.0582, 0.0364],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,283][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.2273, 0.0290, 0.0215, 0.0180, 0.0824, 0.1059, 0.0181, 0.1082, 0.0544,
        0.0115, 0.0354, 0.0212, 0.0567, 0.0803, 0.0237, 0.1063],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,285][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([1.1034e-21, 9.9968e-01, 9.4998e-11, 3.1569e-04, 4.5489e-11, 6.0951e-17,
        1.8591e-18, 7.6197e-22, 6.7809e-13, 9.9693e-17, 2.3864e-15, 9.2659e-18,
        2.0829e-20, 2.2876e-11, 4.4355e-15, 1.2590e-17], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,288][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0110, 0.0754, 0.0698, 0.0651, 0.0648, 0.0551, 0.0607, 0.0583, 0.0639,
        0.0658, 0.0598, 0.0604, 0.0536, 0.0563, 0.0638, 0.0541, 0.0622],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,292][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0033, 0.0990, 0.0755, 0.0904, 0.0606, 0.0590, 0.0532, 0.0591, 0.0621,
        0.0577, 0.0477, 0.0659, 0.0528, 0.0634, 0.0574, 0.0443, 0.0488],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,293][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0452, 0.0795, 0.0933, 0.0698, 0.1028, 0.0551, 0.0475, 0.0624, 0.0429,
        0.0584, 0.0468, 0.0343, 0.0459, 0.0391, 0.0802, 0.0464, 0.0506],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,294][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0214, 0.0673, 0.0862, 0.0669, 0.0724, 0.0528, 0.0526, 0.0435, 0.0591,
        0.0644, 0.0541, 0.0558, 0.0646, 0.0595, 0.0836, 0.0462, 0.0497],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,295][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0298, 0.0708, 0.0579, 0.0547, 0.0679, 0.0717, 0.0712, 0.0699, 0.0572,
        0.0550, 0.0474, 0.0583, 0.0661, 0.0610, 0.0491, 0.0445, 0.0676],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,297][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0022, 0.0933, 0.0685, 0.1013, 0.0554, 0.0575, 0.0643, 0.0629, 0.0663,
        0.0468, 0.0451, 0.0630, 0.0490, 0.0686, 0.0507, 0.0429, 0.0624],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,301][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2194, 0.0700, 0.0355, 0.0427, 0.0349, 0.0433, 0.0667, 0.0568, 0.0361,
        0.0310, 0.0481, 0.0564, 0.0636, 0.0615, 0.0190, 0.0577, 0.0573],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,304][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0826, 0.1496, 0.1216, 0.0423, 0.0528, 0.0941, 0.0522, 0.0613, 0.0355,
        0.0271, 0.0406, 0.0371, 0.0410, 0.0418, 0.0308, 0.0536, 0.0361],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,308][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0536, 0.0679, 0.0538, 0.0557, 0.0582, 0.0814, 0.0581, 0.0652, 0.0560,
        0.0672, 0.0478, 0.0532, 0.0613, 0.0614, 0.0497, 0.0572, 0.0522],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,310][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0762, 0.0863, 0.0739, 0.0696, 0.0836, 0.0561, 0.0361, 0.0428, 0.0587,
        0.0500, 0.0458, 0.0352, 0.0758, 0.0706, 0.0595, 0.0464, 0.0333],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,311][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0818, 0.0490, 0.0775, 0.0183, 0.0868, 0.0364, 0.0187, 0.0555, 0.0652,
        0.0179, 0.0628, 0.0209, 0.1863, 0.0803, 0.0839, 0.0353, 0.0235],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,312][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.5005e-24, 9.9999e-01, 1.0347e-13, 6.6680e-06, 9.3930e-15, 9.2694e-20,
        2.6753e-24, 7.5179e-27, 7.5847e-16, 2.9593e-21, 7.0808e-19, 2.6855e-23,
        2.2327e-25, 6.7539e-14, 1.8046e-19, 4.0196e-20, 5.7013e-20],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,313][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.0091, 0.0731, 0.0673, 0.0601, 0.0613, 0.0516, 0.0551, 0.0542, 0.0580,
        0.0611, 0.0546, 0.0549, 0.0502, 0.0521, 0.0599, 0.0516, 0.0558, 0.0700],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,315][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([0.0029, 0.0992, 0.0692, 0.0875, 0.0532, 0.0561, 0.0594, 0.0584, 0.0583,
        0.0445, 0.0436, 0.0685, 0.0461, 0.0578, 0.0486, 0.0392, 0.0536, 0.0539],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,319][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([0.0400, 0.0820, 0.0813, 0.0659, 0.0929, 0.0502, 0.0467, 0.0669, 0.0407,
        0.0572, 0.0448, 0.0339, 0.0406, 0.0383, 0.0730, 0.0427, 0.0491, 0.0540],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,322][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([0.0156, 0.0647, 0.0768, 0.0626, 0.0688, 0.0509, 0.0574, 0.0410, 0.0575,
        0.0562, 0.0491, 0.0552, 0.0592, 0.0552, 0.0700, 0.0453, 0.0533, 0.0610],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,326][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([0.0313, 0.0625, 0.0528, 0.0516, 0.0627, 0.0669, 0.0658, 0.0650, 0.0535,
        0.0508, 0.0434, 0.0528, 0.0613, 0.0576, 0.0468, 0.0423, 0.0614, 0.0716],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,328][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([0.0018, 0.0912, 0.0655, 0.0968, 0.0515, 0.0553, 0.0631, 0.0583, 0.0596,
        0.0444, 0.0425, 0.0557, 0.0469, 0.0638, 0.0434, 0.0387, 0.0615, 0.0600],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,329][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([0.3897, 0.0623, 0.0260, 0.0308, 0.0240, 0.0334, 0.0519, 0.0426, 0.0225,
        0.0201, 0.0315, 0.0378, 0.0461, 0.0504, 0.0095, 0.0406, 0.0416, 0.0394],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,330][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([0.0669, 0.1267, 0.1355, 0.0391, 0.0564, 0.0819, 0.0460, 0.0630, 0.0340,
        0.0277, 0.0392, 0.0377, 0.0428, 0.0425, 0.0351, 0.0584, 0.0352, 0.0321],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,331][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([0.0495, 0.0631, 0.0535, 0.0533, 0.0557, 0.0757, 0.0552, 0.0605, 0.0527,
        0.0612, 0.0439, 0.0506, 0.0569, 0.0592, 0.0493, 0.0533, 0.0498, 0.0568],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,333][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([0.0534, 0.0983, 0.0719, 0.0872, 0.0665, 0.0520, 0.0657, 0.0386, 0.0577,
        0.0392, 0.0403, 0.0460, 0.0529, 0.0528, 0.0452, 0.0371, 0.0528, 0.0424],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,336][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([0.1004, 0.0327, 0.0343, 0.0293, 0.1450, 0.0289, 0.0120, 0.0183, 0.0572,
        0.0130, 0.0460, 0.0192, 0.0490, 0.0546, 0.0393, 0.0058, 0.0135, 0.3014],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,339][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([1.0209e-23, 9.9999e-01, 5.3024e-13, 1.4908e-05, 3.2193e-14, 1.0679e-19,
        2.6833e-22, 2.5401e-27, 2.5210e-15, 2.6781e-21, 6.2481e-19, 1.6667e-21,
        5.2125e-26, 9.3792e-15, 2.2182e-18, 2.8990e-20, 7.2568e-18, 1.0775e-21],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,342][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0114, 0.0654, 0.0614, 0.0555, 0.0561, 0.0468, 0.0522, 0.0513, 0.0531,
        0.0568, 0.0494, 0.0516, 0.0466, 0.0485, 0.0541, 0.0460, 0.0533, 0.0665,
        0.0740], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,346][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0031, 0.0834, 0.0645, 0.0783, 0.0529, 0.0486, 0.0525, 0.0535, 0.0555,
        0.0557, 0.0450, 0.0607, 0.0459, 0.0571, 0.0491, 0.0361, 0.0480, 0.0554,
        0.0545], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,347][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0377, 0.0814, 0.0805, 0.0633, 0.0860, 0.0464, 0.0438, 0.0639, 0.0405,
        0.0509, 0.0422, 0.0315, 0.0381, 0.0374, 0.0721, 0.0419, 0.0464, 0.0496,
        0.0464], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,348][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0161, 0.0593, 0.0748, 0.0584, 0.0669, 0.0480, 0.0521, 0.0383, 0.0535,
        0.0573, 0.0447, 0.0522, 0.0572, 0.0510, 0.0708, 0.0418, 0.0489, 0.0635,
        0.0453], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,349][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0250, 0.0611, 0.0499, 0.0480, 0.0607, 0.0663, 0.0655, 0.0639, 0.0479,
        0.0457, 0.0389, 0.0495, 0.0592, 0.0553, 0.0410, 0.0382, 0.0589, 0.0692,
        0.0557], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,351][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0022, 0.0808, 0.0555, 0.0936, 0.0473, 0.0505, 0.0614, 0.0557, 0.0573,
        0.0428, 0.0407, 0.0560, 0.0441, 0.0586, 0.0422, 0.0378, 0.0619, 0.0593,
        0.0522], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,354][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3000, 0.0438, 0.0273, 0.0269, 0.0248, 0.0320, 0.0476, 0.0420, 0.0267,
        0.0258, 0.0371, 0.0396, 0.0579, 0.0503, 0.0142, 0.0544, 0.0492, 0.0556,
        0.0449], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,358][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1146, 0.1153, 0.1016, 0.0370, 0.0472, 0.0846, 0.0457, 0.0574, 0.0339,
        0.0267, 0.0387, 0.0350, 0.0400, 0.0400, 0.0299, 0.0546, 0.0353, 0.0295,
        0.0331], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,362][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0483, 0.0618, 0.0482, 0.0509, 0.0533, 0.0732, 0.0527, 0.0575, 0.0507,
        0.0595, 0.0426, 0.0477, 0.0548, 0.0564, 0.0446, 0.0503, 0.0468, 0.0569,
        0.0438], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,364][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0644, 0.0792, 0.0610, 0.0617, 0.0722, 0.0401, 0.0501, 0.0343, 0.0572,
        0.0431, 0.0389, 0.0362, 0.0578, 0.0649, 0.0464, 0.0438, 0.0464, 0.0613,
        0.0408], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,365][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.2080, 0.0447, 0.0178, 0.0371, 0.0585, 0.0294, 0.0356, 0.0580, 0.0950,
        0.0188, 0.0614, 0.0255, 0.0367, 0.0720, 0.0193, 0.0184, 0.0352, 0.0516,
        0.0769], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,366][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([3.9730e-18, 1.0000e+00, 4.1614e-11, 1.8560e-07, 6.4809e-14, 2.0680e-17,
        3.4526e-23, 3.4751e-24, 4.2228e-17, 9.0382e-20, 1.2449e-19, 6.5905e-23,
        1.0780e-23, 8.4247e-14, 2.3767e-17, 1.5500e-17, 1.5654e-18, 1.1926e-18,
        1.0405e-14], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,413][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:31,414][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:31,414][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:31,415][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:31,416][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:31,417][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:31,417][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:31,418][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:31,419][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:31,419][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:31,420][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:31,421][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:31,421][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:31,422][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.7125, 0.2875], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:31,423][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.3181, 0.6819], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:31,424][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2506, 0.7494], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:31,426][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0214, 0.9786], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:31,430][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0822, 0.9178], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:31,433][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0038, 0.9962], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:31,437][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.8992, 0.1008], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:31,438][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([3.1991e-04, 9.9968e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:31,439][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0859, 0.9141], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:31,440][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.4750, 0.5250], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:31,440][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([9.9988e-01, 1.1548e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:31,441][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([2.5030e-04, 9.9975e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:31,444][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.0129, 0.9798, 0.0073], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:31,448][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.1545, 0.3547, 0.4908], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:31,451][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.1340, 0.4705, 0.3954], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:31,455][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.0052, 0.9621, 0.0327], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:31,457][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.0474, 0.4592, 0.4935], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:31,458][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([5.3058e-04, 9.9071e-01, 8.7557e-03], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:31,459][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.0694, 0.9201, 0.0105], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:31,460][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([5.9804e-05, 9.6092e-01, 3.9024e-02], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:31,460][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.0436, 0.4375, 0.5189], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:31,462][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.0994, 0.8513, 0.0494], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:31,465][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.9969, 0.0015, 0.0016], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:31,467][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([6.2621e-16, 1.0000e+00, 2.1856e-13], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:31,471][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2456, 0.5640, 0.1374, 0.0529], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:31,475][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1146, 0.2418, 0.3456, 0.2980], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:31,476][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1026, 0.3158, 0.2522, 0.3293], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:31,476][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([4.3831e-04, 9.4113e-01, 1.5084e-02, 4.3350e-02], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:31,477][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0327, 0.3192, 0.3093, 0.3388], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:31,478][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([7.1019e-05, 9.8398e-01, 1.9527e-03, 1.4001e-02], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:31,480][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3199, 0.3608, 0.2612, 0.0580], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:31,482][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([9.7793e-06, 5.6746e-01, 5.2613e-03, 4.2727e-01], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:31,486][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0232, 0.3027, 0.3626, 0.3115], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:31,489][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0265, 0.9195, 0.0203, 0.0336], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:31,491][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([9.9855e-01, 6.8224e-04, 2.1512e-04, 5.5346e-04], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:31,493][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([1.3738e-16, 1.0000e+00, 6.9743e-12, 1.0478e-08], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:31,494][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.0274, 0.7430, 0.0562, 0.1461, 0.0273], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:31,494][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([0.0790, 0.1823, 0.2615, 0.2281, 0.2491], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:31,495][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([0.0739, 0.2336, 0.1962, 0.2454, 0.2509], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:31,496][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([6.6309e-04, 9.0030e-01, 2.7466e-02, 6.7727e-02, 3.8456e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:31,498][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([0.0297, 0.2399, 0.2516, 0.2445, 0.2343], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:31,500][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([1.0214e-04, 9.2338e-01, 3.6780e-03, 7.0062e-02, 2.7763e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:31,504][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.0877, 0.6744, 0.0544, 0.1719, 0.0116], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:31,506][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([1.4514e-05, 5.7632e-01, 1.5199e-02, 3.9478e-01, 1.3690e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:31,509][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.0281, 0.2282, 0.2673, 0.2291, 0.2473], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:31,511][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.0272, 0.8446, 0.0295, 0.0738, 0.0250], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:31,512][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.9906, 0.0039, 0.0011, 0.0012, 0.0032], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:31,512][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([4.3904e-19, 1.0000e+00, 2.5774e-13, 9.3893e-07, 3.8150e-17],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:31,513][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0139, 0.6534, 0.0753, 0.1708, 0.0796, 0.0070], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,515][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0653, 0.1432, 0.2063, 0.1782, 0.1977, 0.2093], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,519][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0696, 0.1819, 0.1521, 0.1980, 0.2052, 0.1932], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,521][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([9.4927e-06, 7.9011e-01, 3.2216e-02, 1.6469e-01, 1.2752e-02, 2.1963e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,524][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0331, 0.1946, 0.1905, 0.1880, 0.1765, 0.2173], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,527][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([1.2230e-05, 8.1386e-01, 1.0365e-02, 1.5911e-01, 1.6341e-02, 3.1150e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,529][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.1535, 0.2690, 0.3066, 0.1127, 0.1455, 0.0126], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,529][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([2.5497e-06, 5.6561e-01, 7.4883e-03, 4.1457e-01, 1.0664e-02, 1.6690e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,530][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0175, 0.1864, 0.2256, 0.1888, 0.2032, 0.1786], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,531][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0020, 0.7037, 0.0571, 0.1568, 0.0739, 0.0066], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,533][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.7995, 0.0366, 0.0152, 0.0245, 0.0242, 0.0999], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,535][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([9.4967e-22, 9.9978e-01, 3.6693e-09, 2.2278e-04, 1.3180e-09, 1.1259e-16],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:31,539][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0417, 0.4914, 0.1287, 0.0742, 0.1671, 0.0814, 0.0154],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,542][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0521, 0.1206, 0.1734, 0.1501, 0.1661, 0.1778, 0.1598],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,546][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0507, 0.1540, 0.1290, 0.1658, 0.1756, 0.1681, 0.1569],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,547][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([3.1639e-06, 7.5668e-01, 1.4852e-02, 2.2426e-01, 4.0444e-03, 9.8406e-05,
        5.8306e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,548][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0148, 0.1585, 0.1626, 0.1682, 0.1463, 0.1675, 0.1822],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,549][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([3.8736e-07, 8.9396e-01, 4.0869e-03, 9.7268e-02, 4.6332e-03, 2.1513e-05,
        3.1579e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,551][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1326, 0.2943, 0.1471, 0.1696, 0.1488, 0.0833, 0.0242],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,553][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([6.7819e-07, 5.9948e-01, 3.6534e-03, 3.9001e-01, 4.3943e-03, 6.9985e-04,
        1.7608e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,557][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0125, 0.1556, 0.1918, 0.1616, 0.1755, 0.1521, 0.1509],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,559][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([6.3266e-04, 8.0779e-01, 2.5233e-02, 1.1490e-01, 4.7225e-02, 2.6961e-03,
        1.5201e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,562][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.9667, 0.0046, 0.0019, 0.0018, 0.0027, 0.0186, 0.0037],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,564][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.5149e-27, 9.9998e-01, 6.5300e-14, 1.7982e-05, 8.3140e-15, 3.2039e-20,
        1.7988e-24], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:31,565][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0221, 0.5182, 0.0554, 0.0983, 0.2093, 0.0734, 0.0205, 0.0029],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,566][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0435, 0.1050, 0.1494, 0.1327, 0.1431, 0.1541, 0.1421, 0.1302],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,567][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0329, 0.1316, 0.1100, 0.1446, 0.1507, 0.1448, 0.1344, 0.1510],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,568][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([1.5832e-07, 6.5377e-01, 1.2114e-02, 3.2707e-01, 6.9504e-03, 3.3798e-05,
        5.3233e-05, 4.1763e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,571][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0125, 0.1359, 0.1383, 0.1410, 0.1219, 0.1424, 0.1382, 0.1698],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,573][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([5.6101e-07, 6.4161e-01, 5.9533e-03, 3.4010e-01, 1.1789e-02, 9.7330e-05,
        4.3841e-04, 1.4166e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,578][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0991, 0.3217, 0.0557, 0.1073, 0.1813, 0.1475, 0.0460, 0.0415],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,580][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([3.8849e-07, 5.6478e-01, 5.4779e-03, 4.1908e-01, 6.5382e-03, 6.9375e-04,
        3.3442e-03, 8.7343e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,582][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0096, 0.1338, 0.1621, 0.1371, 0.1487, 0.1324, 0.1301, 0.1462],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,583][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([3.5085e-04, 6.3848e-01, 4.2107e-02, 2.4560e-01, 6.1343e-02, 4.6192e-03,
        6.6505e-03, 8.4714e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,584][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.8559, 0.0169, 0.0085, 0.0106, 0.0097, 0.0442, 0.0170, 0.0372],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,585][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([1.1978e-25, 9.9895e-01, 1.6802e-10, 1.0516e-03, 2.0179e-10, 8.0255e-18,
        4.1789e-17, 3.8080e-24], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:31,587][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0562, 0.2703, 0.2636, 0.0474, 0.2449, 0.0503, 0.0425, 0.0090, 0.0158],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,590][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0376, 0.0907, 0.1306, 0.1129, 0.1269, 0.1366, 0.1217, 0.1129, 0.1300],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,593][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0384, 0.1176, 0.0981, 0.1274, 0.1337, 0.1252, 0.1181, 0.1282, 0.1134],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,596][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([2.7164e-05, 8.8231e-01, 1.6244e-02, 9.7271e-02, 3.0583e-03, 2.3535e-04,
        1.0008e-04, 2.1915e-05, 7.2638e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,600][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0104, 0.1191, 0.1186, 0.1289, 0.1104, 0.1221, 0.1342, 0.1428, 0.1136],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,600][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([2.4455e-06, 9.2878e-01, 1.3158e-03, 6.7802e-02, 1.5987e-03, 3.3913e-05,
        3.8979e-05, 3.9380e-06, 4.2018e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,601][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.1165, 0.2735, 0.1212, 0.1369, 0.1334, 0.0952, 0.0558, 0.0510, 0.0165],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,602][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([2.8593e-06, 5.9629e-01, 3.9433e-03, 3.6737e-01, 4.0194e-03, 1.7318e-03,
        1.7544e-03, 6.8044e-05, 2.4824e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,604][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0078, 0.1191, 0.1437, 0.1226, 0.1350, 0.1196, 0.1192, 0.1304, 0.1026],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,606][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([1.5089e-03, 8.8238e-01, 1.5390e-02, 7.0996e-02, 1.6477e-02, 2.9960e-03,
        1.3658e-03, 3.7710e-04, 8.5082e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,609][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([9.4834e-01, 2.6562e-03, 8.5112e-04, 1.5554e-03, 1.4192e-03, 1.6040e-02,
        2.8834e-03, 9.1274e-03, 1.7127e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,611][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([1.5148e-20, 1.0000e+00, 2.0330e-11, 7.7973e-07, 6.3006e-14, 2.4865e-17,
        1.1148e-22, 1.2386e-23, 1.9812e-16], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:31,615][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0089, 0.2394, 0.0388, 0.0855, 0.3211, 0.0647, 0.0519, 0.0074, 0.1816,
        0.0007], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,618][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0317, 0.0796, 0.1170, 0.1012, 0.1099, 0.1170, 0.1071, 0.0999, 0.1183,
        0.1183], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,618][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0305, 0.1057, 0.0889, 0.1144, 0.1199, 0.1168, 0.1063, 0.1191, 0.1017,
        0.0967], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,619][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([1.1941e-05, 8.4357e-01, 2.9504e-02, 1.2013e-01, 5.6707e-03, 2.0373e-04,
        9.1010e-05, 1.5095e-05, 7.1323e-04, 9.1796e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,620][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0073, 0.1073, 0.1115, 0.1133, 0.0993, 0.1190, 0.1100, 0.1301, 0.0965,
        0.1056], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,621][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([1.6971e-06, 8.2805e-01, 2.6775e-03, 1.6209e-01, 4.6978e-03, 4.8844e-05,
        8.3166e-05, 5.8160e-06, 2.3087e-03, 3.3256e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,624][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0388, 0.3205, 0.0464, 0.1097, 0.0866, 0.1397, 0.0272, 0.0652, 0.1598,
        0.0061], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,627][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([1.1924e-06, 6.0118e-01, 5.7393e-03, 3.5564e-01, 5.7612e-03, 1.0128e-03,
        2.0174e-03, 7.5237e-05, 2.6699e-02, 1.8775e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,631][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0048, 0.1083, 0.1329, 0.1133, 0.1210, 0.1059, 0.1075, 0.1202, 0.0964,
        0.0897], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,633][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([1.2780e-03, 8.0157e-01, 2.6570e-02, 1.1728e-01, 2.6411e-02, 4.1868e-03,
        2.1983e-03, 5.8287e-04, 1.8224e-02, 1.6952e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,635][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.9273, 0.0043, 0.0026, 0.0024, 0.0029, 0.0172, 0.0054, 0.0169, 0.0161,
        0.0049], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,636][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([6.6855e-25, 9.9987e-01, 7.5297e-13, 1.3027e-04, 2.5180e-13, 1.3651e-18,
        3.7021e-21, 1.2374e-25, 1.4096e-13, 1.0017e-21], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:31,637][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0250, 0.3411, 0.0140, 0.0525, 0.0791, 0.0806, 0.1535, 0.0488, 0.1335,
        0.0619, 0.0101], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,638][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0296, 0.0720, 0.1010, 0.0883, 0.0982, 0.1071, 0.0959, 0.0888, 0.1031,
        0.1058, 0.1101], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,640][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0332, 0.0963, 0.0785, 0.1051, 0.1107, 0.1054, 0.0946, 0.1075, 0.0933,
        0.0880, 0.0874], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,642][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([2.4965e-06, 8.5167e-01, 1.5108e-02, 1.2856e-01, 3.6502e-03, 8.1269e-05,
        6.3333e-05, 9.8097e-06, 6.9114e-04, 8.2812e-05, 7.9292e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,646][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0073, 0.1016, 0.0995, 0.1066, 0.0865, 0.1063, 0.1073, 0.1233, 0.0822,
        0.0876, 0.0918], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,648][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([7.8436e-07, 9.1160e-01, 1.5343e-03, 8.2861e-02, 2.7877e-03, 2.9418e-05,
        5.8585e-05, 4.1070e-06, 1.0198e-03, 4.0998e-05, 5.9957e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,652][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0972, 0.1738, 0.0884, 0.0835, 0.1396, 0.1348, 0.0682, 0.0603, 0.0715,
        0.0786, 0.0040], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,654][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([1.0738e-06, 6.5345e-01, 3.4287e-03, 3.0921e-01, 3.6287e-03, 9.8662e-04,
        1.2946e-03, 4.7217e-05, 2.0866e-02, 9.3498e-04, 6.1527e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,654][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0043, 0.0968, 0.1207, 0.1023, 0.1131, 0.0975, 0.0992, 0.1095, 0.0871,
        0.0839, 0.0857], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,655][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([5.0652e-04, 8.0848e-01, 2.0776e-02, 1.1824e-01, 2.8111e-02, 2.4410e-03,
        1.7828e-03, 2.6564e-04, 1.5766e-02, 2.2100e-03, 1.4234e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,656][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.9454, 0.0027, 0.0012, 0.0014, 0.0019, 0.0149, 0.0031, 0.0102, 0.0108,
        0.0025, 0.0059], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,658][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([1.7026e-23, 1.0000e+00, 5.7594e-12, 2.9160e-06, 4.5392e-14, 6.7520e-19,
        3.6160e-23, 1.3780e-25, 6.3453e-16, 3.0552e-20, 2.8862e-19],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:31,661][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0344, 0.1787, 0.1422, 0.0581, 0.1950, 0.0720, 0.0112, 0.0321, 0.1376,
        0.0343, 0.0939, 0.0105], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,665][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0255, 0.0649, 0.0932, 0.0804, 0.0893, 0.0961, 0.0866, 0.0808, 0.0942,
        0.0978, 0.1011, 0.0902], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,669][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0278, 0.0864, 0.0720, 0.0946, 0.1007, 0.0944, 0.0888, 0.0977, 0.0835,
        0.0787, 0.0789, 0.0965], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,671][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([4.9105e-06, 8.0557e-01, 1.1547e-02, 1.7907e-01, 2.6205e-03, 7.8081e-05,
        5.7950e-05, 1.0286e-05, 7.7843e-04, 7.5351e-05, 1.1261e-04, 7.6024e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,672][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0073, 0.0881, 0.0928, 0.0927, 0.0832, 0.0924, 0.0927, 0.1106, 0.0806,
        0.0832, 0.0775, 0.0989], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,673][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([2.8605e-07, 9.1570e-01, 1.0439e-03, 8.0374e-02, 2.0329e-03, 1.2191e-05,
        3.1350e-05, 1.3752e-06, 6.4043e-04, 2.8227e-05, 7.8104e-05, 5.5744e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,674][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1016, 0.1777, 0.1130, 0.1172, 0.1308, 0.0647, 0.0618, 0.0973, 0.0421,
        0.0560, 0.0130, 0.0248], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,675][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([6.1349e-07, 6.5285e-01, 3.1412e-03, 3.1071e-01, 3.8139e-03, 7.0530e-04,
        1.4870e-03, 3.8184e-05, 1.8305e-02, 8.3045e-04, 5.7273e-03, 2.3907e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,678][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0055, 0.0909, 0.1116, 0.0944, 0.1022, 0.0901, 0.0895, 0.0994, 0.0797,
        0.0768, 0.0791, 0.0809], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,680][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([4.2849e-04, 8.1601e-01, 1.5188e-02, 1.1318e-01, 3.0291e-02, 2.0157e-03,
        1.2728e-03, 2.1276e-04, 1.6474e-02, 1.6387e-03, 1.9062e-03, 1.3811e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,684][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.9412, 0.0029, 0.0010, 0.0016, 0.0017, 0.0159, 0.0031, 0.0099, 0.0134,
        0.0018, 0.0055, 0.0020], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,687][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([1.3949e-26, 9.9998e-01, 8.3410e-15, 1.7592e-05, 8.0089e-16, 3.7568e-20,
        2.5158e-24, 8.1509e-28, 2.5584e-15, 2.9445e-22, 2.2581e-18, 2.6137e-24],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:31,689][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.0125, 0.3625, 0.0271, 0.1216, 0.0482, 0.0087, 0.0385, 0.0092, 0.2133,
        0.0016, 0.1353, 0.0189, 0.0028], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,690][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0251, 0.0595, 0.0833, 0.0758, 0.0793, 0.0866, 0.0806, 0.0729, 0.0888,
        0.0859, 0.0941, 0.0860, 0.0820], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,691][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.0214, 0.0803, 0.0686, 0.0873, 0.0942, 0.0881, 0.0798, 0.0887, 0.0774,
        0.0729, 0.0749, 0.0906, 0.0760], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,692][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([9.4405e-07, 7.2864e-01, 1.8769e-02, 2.4548e-01, 5.3534e-03, 6.5684e-05,
        9.2420e-05, 1.0639e-05, 1.0442e-03, 1.3725e-04, 2.0280e-04, 1.8675e-04,
        1.1980e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,695][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0087, 0.0855, 0.0837, 0.0875, 0.0720, 0.0848, 0.0818, 0.1014, 0.0728,
        0.0741, 0.0734, 0.0874, 0.0869], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,697][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([3.3387e-07, 7.8135e-01, 2.3131e-03, 2.0591e-01, 5.5359e-03, 4.6335e-05,
        1.4359e-04, 4.5849e-06, 3.8804e-03, 8.6313e-05, 3.4255e-04, 3.8740e-04,
        6.9055e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,702][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.0320, 0.2871, 0.0295, 0.0941, 0.2068, 0.0847, 0.0365, 0.0217, 0.0922,
        0.0472, 0.0201, 0.0426, 0.0054], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,705][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([7.3404e-07, 5.7370e-01, 6.3490e-03, 3.6769e-01, 7.7436e-03, 8.6725e-04,
        2.2017e-03, 7.3286e-05, 2.7292e-02, 2.0005e-03, 7.8218e-03, 3.9204e-03,
        3.3991e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,706][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.0093, 0.0831, 0.0984, 0.0827, 0.0898, 0.0809, 0.0793, 0.0882, 0.0716,
        0.0700, 0.0729, 0.0746, 0.0993], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,707][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([3.3813e-04, 6.7076e-01, 2.3325e-02, 2.1689e-01, 4.3696e-02, 2.3747e-03,
        4.1235e-03, 4.5895e-04, 2.5234e-02, 2.8970e-03, 5.1289e-03, 4.5394e-03,
        2.3465e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,708][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.8556, 0.0049, 0.0041, 0.0041, 0.0052, 0.0277, 0.0064, 0.0200, 0.0186,
        0.0070, 0.0118, 0.0052, 0.0295], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,709][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([1.5175e-27, 9.9971e-01, 4.2932e-13, 2.8569e-04, 4.8930e-14, 7.7587e-20,
        1.6664e-20, 3.9093e-26, 8.5199e-14, 1.0254e-19, 1.5366e-17, 9.7206e-20,
        6.1125e-26], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:31,711][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0428, 0.1071, 0.1505, 0.0289, 0.3539, 0.0155, 0.0596, 0.0212, 0.0435,
        0.0353, 0.0232, 0.0320, 0.0703, 0.0163], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,714][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0244, 0.0549, 0.0767, 0.0695, 0.0736, 0.0817, 0.0762, 0.0681, 0.0810,
        0.0794, 0.0855, 0.0792, 0.0764, 0.0735], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,718][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0252, 0.0749, 0.0620, 0.0793, 0.0831, 0.0809, 0.0754, 0.0810, 0.0716,
        0.0678, 0.0695, 0.0811, 0.0681, 0.0801], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,720][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([1.8317e-05, 8.0115e-01, 2.7988e-02, 1.6034e-01, 7.3118e-03, 2.1595e-04,
        1.5161e-04, 2.5302e-05, 1.4588e-03, 2.0085e-04, 1.9008e-04, 2.7494e-04,
        4.8017e-05, 6.2608e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,724][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0090, 0.0759, 0.0767, 0.0803, 0.0713, 0.0802, 0.0779, 0.0913, 0.0688,
        0.0710, 0.0659, 0.0812, 0.0743, 0.0762], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,725][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([2.1357e-06, 8.3252e-01, 1.9861e-03, 1.5891e-01, 3.9073e-03, 5.1004e-05,
        9.4434e-05, 4.5532e-06, 1.8013e-03, 4.4214e-05, 2.0305e-04, 2.3853e-04,
        4.4507e-06, 2.3839e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,726][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.1165, 0.1290, 0.1120, 0.0418, 0.0876, 0.0870, 0.0484, 0.0559, 0.0404,
        0.0389, 0.0096, 0.0431, 0.1751, 0.0146], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,727][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([7.6250e-07, 5.2691e-01, 2.6618e-03, 4.1788e-01, 2.9692e-03, 7.5424e-04,
        1.2480e-03, 4.2931e-05, 2.4671e-02, 1.2153e-03, 6.6264e-03, 2.6428e-03,
        1.7069e-04, 1.2204e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,729][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0071, 0.0760, 0.0889, 0.0766, 0.0839, 0.0745, 0.0738, 0.0810, 0.0662,
        0.0649, 0.0678, 0.0691, 0.0915, 0.0788], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,731][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([6.8793e-04, 7.8134e-01, 1.5484e-02, 1.4372e-01, 2.6387e-02, 2.7665e-03,
        2.1008e-03, 3.3084e-04, 1.7320e-02, 2.2719e-03, 2.0468e-03, 2.2371e-03,
        1.2944e-04, 3.1748e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,735][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.9289, 0.0021, 0.0012, 0.0011, 0.0023, 0.0174, 0.0033, 0.0097, 0.0120,
        0.0025, 0.0052, 0.0021, 0.0051, 0.0071], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,738][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([7.2123e-21, 9.9998e-01, 2.5163e-11, 2.1967e-05, 1.1029e-12, 1.4206e-17,
        1.1744e-21, 3.6852e-24, 7.6662e-15, 8.1453e-19, 3.8486e-17, 4.3720e-21,
        9.0416e-23, 1.1961e-13], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:31,741][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.0032, 0.2823, 0.0045, 0.1347, 0.0343, 0.0102, 0.0526, 0.0111, 0.2676,
        0.0014, 0.1609, 0.0137, 0.0040, 0.0184, 0.0012], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,743][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0192, 0.0511, 0.0725, 0.0633, 0.0707, 0.0761, 0.0700, 0.0645, 0.0752,
        0.0762, 0.0804, 0.0727, 0.0734, 0.0698, 0.0647], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,744][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.0197, 0.0694, 0.0591, 0.0754, 0.0796, 0.0730, 0.0693, 0.0759, 0.0683,
        0.0654, 0.0652, 0.0781, 0.0678, 0.0784, 0.0553], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,744][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([3.9525e-04, 8.2955e-01, 3.6866e-02, 1.1766e-01, 6.7699e-03, 6.3933e-04,
        3.6287e-04, 5.0760e-05, 1.8904e-03, 3.5486e-04, 3.6417e-04, 4.9048e-04,
        8.6303e-05, 2.0180e-03, 2.5016e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,745][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.0064, 0.0715, 0.0766, 0.0727, 0.0696, 0.0797, 0.0707, 0.0786, 0.0638,
        0.0670, 0.0586, 0.0753, 0.0694, 0.0696, 0.0705], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,747][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([2.2408e-05, 8.6597e-01, 3.7745e-03, 1.2166e-01, 3.8625e-03, 1.3107e-04,
        1.4931e-04, 1.4644e-05, 2.1160e-03, 8.5137e-05, 2.9165e-04, 3.1424e-04,
        1.1855e-05, 1.2408e-03, 3.4990e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,750][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.0114, 0.2797, 0.0040, 0.0797, 0.0708, 0.1365, 0.0215, 0.0611, 0.0572,
        0.0190, 0.0105, 0.0771, 0.1103, 0.0592, 0.0019], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,752][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([5.7924e-06, 6.2166e-01, 1.6260e-02, 2.6297e-01, 1.4195e-02, 1.6697e-03,
        3.5531e-03, 1.5660e-04, 4.3695e-02, 2.4610e-03, 1.0697e-02, 6.6029e-03,
        6.2919e-04, 1.2231e-02, 3.2124e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,756][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.0046, 0.0717, 0.0869, 0.0735, 0.0790, 0.0688, 0.0694, 0.0751, 0.0599,
        0.0571, 0.0590, 0.0617, 0.0833, 0.0725, 0.0775], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,759][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([4.1720e-03, 7.6319e-01, 2.3906e-02, 1.2359e-01, 4.0099e-02, 5.8352e-03,
        2.8345e-03, 9.8044e-04, 1.4541e-02, 3.0865e-03, 2.7164e-03, 2.6119e-03,
        3.6504e-04, 7.2304e-03, 4.8431e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,761][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.8706, 0.0048, 0.0052, 0.0030, 0.0046, 0.0228, 0.0090, 0.0174, 0.0148,
        0.0057, 0.0094, 0.0058, 0.0103, 0.0097, 0.0067], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,761][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([5.2286e-20, 9.9997e-01, 1.7470e-13, 3.0574e-05, 5.1531e-14, 4.5301e-17,
        6.1763e-21, 7.3361e-24, 1.2384e-13, 1.3111e-19, 5.4742e-17, 4.7917e-20,
        1.1406e-23, 2.4787e-12, 2.5814e-18], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:31,762][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0033, 0.3140, 0.0463, 0.0955, 0.0200, 0.0210, 0.0632, 0.0091, 0.2041,
        0.0031, 0.1091, 0.0330, 0.0120, 0.0479, 0.0164, 0.0020],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,763][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0185, 0.0480, 0.0681, 0.0601, 0.0657, 0.0704, 0.0642, 0.0580, 0.0708,
        0.0695, 0.0758, 0.0680, 0.0669, 0.0667, 0.0599, 0.0696],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,766][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0195, 0.0656, 0.0563, 0.0695, 0.0740, 0.0688, 0.0663, 0.0708, 0.0643,
        0.0631, 0.0597, 0.0743, 0.0608, 0.0732, 0.0526, 0.0611],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,767][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([2.8427e-06, 7.1815e-01, 1.9257e-02, 2.4684e-01, 1.0309e-02, 1.2387e-04,
        1.4334e-04, 3.8798e-05, 1.7518e-03, 3.0257e-04, 3.7846e-04, 3.3380e-04,
        6.3622e-05, 1.1148e-03, 1.0020e-03, 1.8129e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,771][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0058, 0.0660, 0.0678, 0.0703, 0.0594, 0.0761, 0.0725, 0.0792, 0.0559,
        0.0577, 0.0556, 0.0729, 0.0654, 0.0637, 0.0617, 0.0698],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,774][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([4.1475e-06, 7.3935e-01, 5.4666e-03, 2.3114e-01, 1.1685e-02, 1.7066e-04,
        5.1580e-04, 3.6731e-05, 6.0963e-03, 5.1337e-04, 8.0044e-04, 1.1166e-03,
        5.6835e-05, 2.1588e-03, 6.9331e-04, 2.0346e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,777][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0476, 0.1510, 0.0756, 0.0649, 0.1143, 0.0648, 0.0326, 0.0750, 0.0780,
        0.0725, 0.0107, 0.0408, 0.0852, 0.0398, 0.0436, 0.0036],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,779][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([6.9055e-07, 5.1225e-01, 3.6449e-03, 4.0751e-01, 5.8780e-03, 8.8824e-04,
        3.3212e-03, 8.1111e-05, 3.4528e-02, 2.0439e-03, 8.9229e-03, 5.7836e-03,
        3.8898e-04, 1.3435e-02, 9.3374e-04, 3.8968e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,780][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0041, 0.0644, 0.0789, 0.0667, 0.0714, 0.0622, 0.0626, 0.0691, 0.0567,
        0.0546, 0.0568, 0.0575, 0.0774, 0.0670, 0.0728, 0.0778],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,781][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0010, 0.6511, 0.0293, 0.1779, 0.0590, 0.0044, 0.0048, 0.0011, 0.0296,
        0.0043, 0.0061, 0.0058, 0.0007, 0.0122, 0.0074, 0.0055],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,782][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.5674, 0.0166, 0.0116, 0.0126, 0.0145, 0.0656, 0.0213, 0.0353, 0.0554,
        0.0158, 0.0407, 0.0153, 0.0249, 0.0353, 0.0178, 0.0499],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,783][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([1.1034e-21, 9.9968e-01, 9.4998e-11, 3.1569e-04, 4.5489e-11, 6.0951e-17,
        1.8591e-18, 7.6197e-22, 6.7809e-13, 9.9693e-17, 2.3864e-15, 9.2659e-18,
        2.0829e-20, 2.2876e-11, 4.4355e-15, 1.2590e-17], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:31,786][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0293, 0.2507, 0.0841, 0.0530, 0.0926, 0.0391, 0.0085, 0.0192, 0.0999,
        0.0119, 0.0665, 0.0145, 0.0776, 0.0570, 0.0372, 0.0501, 0.0088],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,790][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0199, 0.0456, 0.0633, 0.0565, 0.0612, 0.0668, 0.0608, 0.0549, 0.0650,
        0.0655, 0.0696, 0.0629, 0.0626, 0.0600, 0.0552, 0.0624, 0.0677],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,794][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0197, 0.0616, 0.0519, 0.0663, 0.0706, 0.0673, 0.0627, 0.0685, 0.0595,
        0.0565, 0.0555, 0.0689, 0.0565, 0.0676, 0.0481, 0.0592, 0.0596],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,797][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([6.3738e-06, 7.9703e-01, 1.2919e-02, 1.8339e-01, 4.1783e-03, 7.4807e-05,
        3.0855e-05, 5.2088e-06, 6.1028e-04, 5.4918e-05, 1.0385e-04, 7.6576e-05,
        1.2989e-05, 5.2997e-04, 3.6155e-04, 1.2165e-04, 4.9263e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,798][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0064, 0.0615, 0.0621, 0.0650, 0.0573, 0.0662, 0.0690, 0.0740, 0.0549,
        0.0594, 0.0552, 0.0667, 0.0640, 0.0598, 0.0563, 0.0530, 0.0691],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,798][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.0618e-06, 9.0159e-01, 3.3778e-03, 8.8707e-02, 4.1433e-03, 2.3461e-05,
        2.9874e-05, 3.3204e-06, 8.6927e-04, 4.1959e-05, 1.0417e-04, 1.5391e-04,
        5.3176e-06, 3.8029e-04, 2.0668e-04, 3.8923e-05, 3.2162e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,799][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0491, 0.1601, 0.0796, 0.0904, 0.0786, 0.0448, 0.0125, 0.0730, 0.0481,
        0.0290, 0.0185, 0.0726, 0.1103, 0.0600, 0.0441, 0.0209, 0.0083],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,801][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([4.1797e-07, 6.3794e-01, 2.9121e-03, 3.1447e-01, 3.8913e-03, 4.5089e-04,
        1.2880e-03, 2.9384e-05, 1.8707e-02, 8.9237e-04, 5.2738e-03, 2.6446e-03,
        1.3931e-04, 7.5221e-03, 5.5160e-04, 2.0729e-04, 3.0834e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,804][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0051, 0.0596, 0.0733, 0.0619, 0.0667, 0.0588, 0.0586, 0.0645, 0.0529,
        0.0503, 0.0519, 0.0535, 0.0720, 0.0619, 0.0676, 0.0692, 0.0723],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,806][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([8.6202e-04, 7.8222e-01, 1.8461e-02, 1.1756e-01, 3.5583e-02, 2.2068e-03,
        1.2756e-03, 3.0393e-04, 1.5126e-02, 2.0830e-03, 2.1007e-03, 1.5521e-03,
        2.0050e-04, 4.7419e-03, 3.5358e-03, 4.1018e-03, 8.0852e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,810][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.8122, 0.0093, 0.0045, 0.0044, 0.0047, 0.0273, 0.0077, 0.0163, 0.0259,
        0.0052, 0.0139, 0.0051, 0.0157, 0.0156, 0.0064, 0.0168, 0.0088],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,813][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.5005e-24, 9.9999e-01, 1.0347e-13, 6.6680e-06, 9.3930e-15, 9.2694e-20,
        2.6753e-24, 7.5179e-27, 7.5847e-16, 2.9593e-21, 7.0808e-19, 2.6855e-23,
        2.2327e-25, 6.7539e-14, 1.8046e-19, 4.0196e-20, 5.7013e-20],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:31,814][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([0.0039, 0.4831, 0.0061, 0.1001, 0.0212, 0.0156, 0.0237, 0.0041, 0.1622,
        0.0012, 0.1337, 0.0056, 0.0042, 0.0168, 0.0009, 0.0026, 0.0127, 0.0022],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,815][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([0.0190, 0.0427, 0.0584, 0.0528, 0.0562, 0.0614, 0.0566, 0.0510, 0.0617,
        0.0604, 0.0661, 0.0601, 0.0579, 0.0572, 0.0523, 0.0617, 0.0643, 0.0602],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,816][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([0.0158, 0.0582, 0.0488, 0.0627, 0.0663, 0.0638, 0.0582, 0.0638, 0.0559,
        0.0543, 0.0543, 0.0648, 0.0545, 0.0655, 0.0452, 0.0565, 0.0549, 0.0565],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,817][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([3.2128e-05, 7.7988e-01, 1.4571e-02, 1.9536e-01, 5.7304e-03, 1.4395e-04,
        9.4760e-05, 1.0847e-05, 8.0988e-04, 7.8930e-05, 1.8113e-04, 1.7694e-04,
        1.5167e-05, 6.4935e-04, 5.7925e-04, 2.0025e-04, 1.2410e-03, 2.4958e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,819][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([0.0051, 0.0585, 0.0588, 0.0620, 0.0543, 0.0661, 0.0605, 0.0687, 0.0527,
        0.0549, 0.0479, 0.0624, 0.0598, 0.0600, 0.0536, 0.0494, 0.0605, 0.0649],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,821][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([6.2361e-06, 8.2473e-01, 4.1627e-03, 1.6089e-01, 5.7058e-03, 4.5119e-05,
        6.7544e-05, 5.6455e-06, 1.4364e-03, 8.2511e-05, 2.0408e-04, 2.0938e-04,
        7.9133e-06, 8.0185e-04, 2.9433e-04, 9.5910e-05, 9.2724e-04, 3.2118e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,826][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([0.0109, 0.2753, 0.0353, 0.0952, 0.1220, 0.0505, 0.0194, 0.0671, 0.0421,
        0.0390, 0.0160, 0.0375, 0.0569, 0.0839, 0.0137, 0.0175, 0.0124, 0.0054],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,828][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([1.6756e-06, 5.4066e-01, 9.7556e-03, 3.8394e-01, 9.8521e-03, 7.3976e-04,
        1.7316e-03, 7.2670e-05, 2.4198e-02, 1.6833e-03, 6.2832e-03, 3.0145e-03,
        2.3768e-04, 7.7352e-03, 1.6330e-03, 4.9619e-04, 4.7122e-03, 3.2580e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,832][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([0.0057, 0.0568, 0.0690, 0.0574, 0.0624, 0.0554, 0.0539, 0.0603, 0.0490,
        0.0467, 0.0485, 0.0503, 0.0681, 0.0578, 0.0621, 0.0642, 0.0668, 0.0657],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,833][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([2.4372e-03, 7.1451e-01, 2.9746e-02, 1.3564e-01, 5.4653e-02, 3.4420e-03,
        1.7696e-03, 4.7484e-04, 1.5482e-02, 2.3591e-03, 2.5496e-03, 1.9683e-03,
        2.5101e-04, 5.0114e-03, 5.7721e-03, 5.3512e-03, 1.3358e-02, 5.2249e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,834][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([0.7601, 0.0127, 0.0055, 0.0077, 0.0155, 0.0327, 0.0096, 0.0201, 0.0339,
        0.0047, 0.0205, 0.0066, 0.0085, 0.0183, 0.0068, 0.0181, 0.0102, 0.0087],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,835][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([1.0209e-23, 9.9999e-01, 5.3024e-13, 1.4908e-05, 3.2193e-14, 1.0679e-19,
        2.6833e-22, 2.5401e-27, 2.5210e-15, 2.6781e-21, 6.2481e-19, 1.6667e-21,
        5.2125e-26, 9.3792e-15, 2.2182e-18, 2.8990e-20, 7.2568e-18, 1.0775e-21],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:31,838][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0427, 0.1082, 0.0428, 0.0315, 0.0938, 0.0405, 0.0724, 0.0464, 0.0472,
        0.0448, 0.0181, 0.0512, 0.1241, 0.0291, 0.0149, 0.0790, 0.0542, 0.0553,
        0.0039], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,843][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0196, 0.0410, 0.0536, 0.0497, 0.0529, 0.0598, 0.0552, 0.0493, 0.0573,
        0.0555, 0.0603, 0.0565, 0.0541, 0.0531, 0.0470, 0.0543, 0.0613, 0.0576,
        0.0619], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,847][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0170, 0.0556, 0.0459, 0.0598, 0.0616, 0.0593, 0.0553, 0.0605, 0.0538,
        0.0500, 0.0510, 0.0612, 0.0510, 0.0606, 0.0427, 0.0537, 0.0531, 0.0550,
        0.0529], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,849][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.6247e-04, 8.8342e-01, 2.0508e-02, 8.0074e-02, 4.4138e-03, 5.5754e-04,
        2.0287e-04, 2.4903e-05, 1.3461e-03, 2.4413e-04, 2.2688e-04, 3.4318e-04,
        4.4233e-05, 1.2761e-03, 1.2498e-03, 5.8187e-04, 2.5671e-03, 1.2804e-03,
        1.3772e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,850][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0059, 0.0554, 0.0565, 0.0597, 0.0519, 0.0568, 0.0587, 0.0644, 0.0491,
        0.0510, 0.0483, 0.0599, 0.0550, 0.0558, 0.0505, 0.0479, 0.0585, 0.0567,
        0.0580], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,851][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([8.9739e-06, 9.0821e-01, 2.1197e-03, 8.1657e-02, 2.9409e-03, 4.7037e-05,
        5.7285e-05, 6.1679e-06, 9.6656e-04, 5.0333e-05, 9.8936e-05, 1.5578e-04,
        3.6871e-06, 4.6021e-04, 1.5418e-04, 8.1684e-05, 6.8377e-04, 2.3560e-04,
        2.0633e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,853][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0396, 0.1546, 0.0550, 0.0921, 0.0703, 0.0796, 0.0255, 0.0327, 0.0516,
        0.0387, 0.0196, 0.0431, 0.2025, 0.0170, 0.0211, 0.0157, 0.0165, 0.0189,
        0.0058], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,855][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([2.2369e-06, 6.8218e-01, 4.0576e-03, 2.3836e-01, 4.0983e-03, 8.5694e-04,
        1.0816e-03, 3.9664e-05, 1.7505e-02, 8.7965e-04, 5.1787e-03, 1.9081e-03,
        1.5474e-04, 6.5189e-03, 7.1588e-04, 4.1510e-04, 3.2279e-03, 1.6231e-03,
        3.1194e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,860][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0048, 0.0524, 0.0651, 0.0544, 0.0592, 0.0516, 0.0515, 0.0564, 0.0460,
        0.0447, 0.0471, 0.0478, 0.0630, 0.0546, 0.0593, 0.0608, 0.0624, 0.0616,
        0.0571], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,863][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([3.3423e-03, 7.5717e-01, 2.2483e-02, 9.5036e-02, 4.0006e-02, 3.0137e-03,
        1.5056e-03, 4.4434e-04, 1.3831e-02, 2.2346e-03, 1.6784e-03, 1.4575e-03,
        1.6317e-04, 4.6570e-03, 4.5551e-03, 4.8726e-03, 1.0696e-02, 4.1398e-03,
        2.8710e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,867][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.8584, 0.0034, 0.0020, 0.0022, 0.0026, 0.0207, 0.0060, 0.0163, 0.0189,
        0.0035, 0.0086, 0.0037, 0.0063, 0.0107, 0.0032, 0.0131, 0.0066, 0.0020,
        0.0118], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,867][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([3.9730e-18, 1.0000e+00, 4.1614e-11, 1.8560e-07, 6.4809e-14, 2.0680e-17,
        3.4526e-23, 3.4751e-24, 4.2228e-17, 9.0382e-20, 1.2449e-19, 6.5905e-23,
        1.0780e-23, 8.4247e-14, 2.3767e-17, 1.5500e-17, 1.5654e-18, 1.1926e-18,
        1.0405e-14], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:31,871][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:31,874][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[8551],
        [ 473],
        [1890],
        [1930],
        [ 414],
        [1673],
        [ 148],
        [2491],
        [ 730],
        [1328],
        [ 428],
        [ 137],
        [ 470],
        [ 390],
        [ 478],
        [1453],
        [ 237],
        [  63],
        [ 109]], device='cuda:0')
[2024-07-24 10:27:31,877][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[9398],
        [1199],
        [1963],
        [2857],
        [1152],
        [2291],
        [ 670],
        [3058],
        [2719],
        [2862],
        [1124],
        [ 310],
        [2002],
        [1036],
        [1479],
        [2077],
        [ 968],
        [  35],
        [ 337]], device='cuda:0')
[2024-07-24 10:27:31,879][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 6116],
        [ 8793],
        [ 9059],
        [ 9812],
        [10470],
        [10650],
        [10662],
        [10717],
        [10893],
        [10607],
        [10649],
        [10614],
        [10507],
        [10434],
        [10312],
        [10227],
        [10073],
        [ 9863],
        [ 9903]], device='cuda:0')
[2024-07-24 10:27:31,882][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[36231],
        [19605],
        [14549],
        [14514],
        [14582],
        [15111],
        [14696],
        [15671],
        [15818],
        [16423],
        [16797],
        [16288],
        [16493],
        [16260],
        [15998],
        [15906],
        [15717],
        [15915],
        [16131]], device='cuda:0')
[2024-07-24 10:27:31,885][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[28880],
        [35620],
        [32588],
        [26663],
        [26373],
        [25739],
        [24126],
        [23507],
        [22692],
        [21750],
        [21260],
        [20649],
        [20197],
        [19953],
        [20716],
        [20160],
        [19572],
        [19380],
        [20086]], device='cuda:0')
[2024-07-24 10:27:31,888][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[23414],
        [23749],
        [23747],
        [22964],
        [21437],
        [22658],
        [23631],
        [24368],
        [24372],
        [23674],
        [24056],
        [24248],
        [24286],
        [24516],
        [24811],
        [25013],
        [25079],
        [24887],
        [25120]], device='cuda:0')
[2024-07-24 10:27:31,889][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 423],
        [ 425],
        [ 603],
        [ 777],
        [ 861],
        [ 818],
        [1040],
        [1116],
        [1302],
        [1501],
        [1506],
        [1471],
        [1543],
        [1504],
        [1535],
        [1504],
        [1521],
        [1501],
        [1494]], device='cuda:0')
[2024-07-24 10:27:31,891][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[21494],
        [31126],
        [25836],
        [29778],
        [25535],
        [25656],
        [28787],
        [28486],
        [29181],
        [28066],
        [29386],
        [29123],
        [28809],
        [29229],
        [28692],
        [28483],
        [29485],
        [29582],
        [30386]], device='cuda:0')
[2024-07-24 10:27:31,893][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[6275],
        [5686],
        [4508],
        [3991],
        [3514],
        [2345],
        [2734],
        [2016],
        [2119],
        [1825],
        [1902],
        [1963],
        [1650],
        [1643],
        [1536],
        [1488],
        [1518],
        [1793],
        [1724]], device='cuda:0')
[2024-07-24 10:27:31,895][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 2045],
        [18517],
        [16313],
        [12553],
        [14279],
        [18634],
        [11241],
        [14486],
        [ 9848],
        [11952],
        [12345],
        [11553],
        [14011],
        [13739],
        [13479],
        [16480],
        [12769],
        [13411],
        [10728]], device='cuda:0')
[2024-07-24 10:27:31,898][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[15728],
        [16880],
        [14722],
        [14524],
        [13402],
        [13391],
        [13285],
        [13506],
        [13573],
        [13587],
        [13491],
        [13579],
        [13286],
        [13007],
        [12677],
        [12592],
        [12628],
        [12655],
        [12704]], device='cuda:0')
[2024-07-24 10:27:31,900][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[37197],
        [39506],
        [41895],
        [44761],
        [43872],
        [38584],
        [38085],
        [39112],
        [36724],
        [37982],
        [34575],
        [33794],
        [34665],
        [33765],
        [33611],
        [33479],
        [33103],
        [32881],
        [31468]], device='cuda:0')
[2024-07-24 10:27:31,903][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[16048],
        [ 6217],
        [32232],
        [ 5246],
        [19847],
        [ 7444],
        [18855],
        [38239],
        [19912],
        [ 8550],
        [12260],
        [ 8473],
        [ 1478],
        [ 5363],
        [11840],
        [ 4631],
        [ 3580],
        [ 8300],
        [ 2165]], device='cuda:0')
[2024-07-24 10:27:31,906][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 7516],
        [15297],
        [15298],
        [15298],
        [15298],
        [15298],
        [15298],
        [15295],
        [15298],
        [15299],
        [15298],
        [15298],
        [15297],
        [15298],
        [15298],
        [15297],
        [15298],
        [15298],
        [15298]], device='cuda:0')
[2024-07-24 10:27:31,908][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 1940],
        [ 2469],
        [18533],
        [22939],
        [14192],
        [14720],
        [14068],
        [10807],
        [10175],
        [22677],
        [20926],
        [29912],
        [18229],
        [16065],
        [18925],
        [25987],
        [19918],
        [34012],
        [23259]], device='cuda:0')
[2024-07-24 10:27:31,910][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[20126],
        [16668],
        [ 7140],
        [ 8616],
        [ 6418],
        [ 6547],
        [10138],
        [10134],
        [10428],
        [13989],
        [10296],
        [13180],
        [ 9507],
        [ 9722],
        [ 9941],
        [ 8616],
        [11285],
        [ 8890],
        [11721]], device='cuda:0')
[2024-07-24 10:27:31,911][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[41210],
        [41019],
        [40922],
        [40299],
        [40497],
        [40380],
        [40544],
        [40804],
        [40840],
        [40927],
        [40765],
        [40681],
        [40768],
        [40674],
        [40675],
        [40489],
        [40538],
        [40566],
        [40614]], device='cuda:0')
[2024-07-24 10:27:31,913][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 9363],
        [10493],
        [12835],
        [12840],
        [12676],
        [12059],
        [12082],
        [11867],
        [11968],
        [12015],
        [12110],
        [12134],
        [12177],
        [12263],
        [12537],
        [12452],
        [12511],
        [12545],
        [12502]], device='cuda:0')
[2024-07-24 10:27:31,916][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[8983],
        [5532],
        [5514],
        [5630],
        [5687],
        [5983],
        [6191],
        [6521],
        [5784],
        [5857],
        [5884],
        [6053],
        [6268],
        [5988],
        [5873],
        [6287],
        [6065],
        [6102],
        [5738]], device='cuda:0')
[2024-07-24 10:27:31,918][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[15598],
        [18035],
        [19732],
        [18173],
        [19642],
        [18675],
        [16900],
        [16914],
        [16911],
        [16947],
        [16490],
        [16140],
        [15922],
        [16097],
        [17047],
        [15521],
        [15188],
        [15787],
        [15677]], device='cuda:0')
[2024-07-24 10:27:31,921][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 7169],
        [15033],
        [14755],
        [14860],
        [14250],
        [12530],
        [13879],
        [ 9702],
        [14353],
        [12915],
        [14148],
        [14219],
        [12168],
        [12993],
        [13461],
        [11448],
        [13976],
        [12826],
        [14068]], device='cuda:0')
[2024-07-24 10:27:31,924][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 8599],
        [ 7968],
        [15082],
        [10207],
        [14431],
        [ 9099],
        [11805],
        [12231],
        [11953],
        [14655],
        [12543],
        [11690],
        [13128],
        [ 9363],
        [12485],
        [11213],
        [10659],
        [12230],
        [ 9710]], device='cuda:0')
[2024-07-24 10:27:31,927][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[31901],
        [24799],
        [25003],
        [23656],
        [23817],
        [23725],
        [23755],
        [23701],
        [23825],
        [23883],
        [23980],
        [23997],
        [23910],
        [23730],
        [24272],
        [23812],
        [23981],
        [23896],
        [24299]], device='cuda:0')
[2024-07-24 10:27:31,929][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[11657],
        [12016],
        [13537],
        [12575],
        [12324],
        [12870],
        [13337],
        [14549],
        [14244],
        [14509],
        [14648],
        [14862],
        [16112],
        [16614],
        [16491],
        [16406],
        [16683],
        [16912],
        [16880]], device='cuda:0')
[2024-07-24 10:27:31,931][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[27426],
        [ 7104],
        [ 5875],
        [ 5774],
        [ 5924],
        [ 6115],
        [ 5926],
        [ 6630],
        [ 5768],
        [ 5937],
        [ 5932],
        [ 5881],
        [ 6354],
        [ 6047],
        [ 5962],
        [ 6129],
        [ 5859],
        [ 5875],
        [ 5672]], device='cuda:0')
[2024-07-24 10:27:31,932][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[3913],
        [3912],
        [3887],
        [3904],
        [3954],
        [3944],
        [3925],
        [4250],
        [3969],
        [4107],
        [4032],
        [3991],
        [5210],
        [4212],
        [4668],
        [5128],
        [4976],
        [5155],
        [4669]], device='cuda:0')
[2024-07-24 10:27:31,934][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[42392],
        [19901],
        [19891],
        [19891],
        [19891],
        [19889],
        [19891],
        [19880],
        [19891],
        [19890],
        [19891],
        [19891],
        [19888],
        [19891],
        [19891],
        [19888],
        [19891],
        [19891],
        [19891]], device='cuda:0')
[2024-07-24 10:27:31,936][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[35783],
        [38536],
        [39483],
        [40089],
        [39798],
        [40659],
        [39628],
        [39497],
        [39339],
        [38471],
        [39326],
        [38945],
        [38503],
        [39734],
        [38581],
        [39055],
        [38518],
        [38553],
        [38897]], device='cuda:0')
[2024-07-24 10:27:31,939][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[48311],
        [44936],
        [23851],
        [20036],
        [23543],
        [25857],
        [21581],
        [32368],
        [23834],
        [20553],
        [17355],
        [10944],
        [24881],
        [20627],
        [19406],
        [15260],
        [22533],
        [17198],
        [13678]], device='cuda:0')
[2024-07-24 10:27:31,942][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240]], device='cuda:0')
[2024-07-24 10:27:32,001][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:32,005][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,006][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,006][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,007][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,008][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,008][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,009][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,010][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,010][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,011][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,012][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,012][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,013][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0523, 0.9477], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,014][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.3459, 0.6541], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,015][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1166, 0.8834], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,018][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9931, 0.0069], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,022][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.7180, 0.2820], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,024][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9937, 0.0063], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,025][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9645, 0.0355], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,025][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5773, 0.4227], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,026][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0017, 0.9983], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,027][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9454, 0.0546], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,028][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([9.9989e-01, 1.1370e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,031][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4850, 0.5150], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,035][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.0342, 0.4203, 0.5456], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,038][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.5765, 0.2309, 0.1926], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,042][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.0065, 0.9342, 0.0593], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,043][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0386, 0.9495, 0.0118], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,043][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.1611, 0.3196, 0.5192], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,044][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.9826, 0.0074, 0.0100], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,045][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.4757, 0.4585, 0.0658], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,047][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.4032, 0.3448, 0.2520], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,049][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.0326, 0.8114, 0.1560], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,053][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.8976, 0.0469, 0.0555], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,056][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([9.9899e-01, 3.5370e-04, 6.5448e-04], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,060][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.8216, 0.1505, 0.0279], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,060][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0160, 0.1743, 0.5872, 0.2224], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,061][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1281, 0.3466, 0.5088, 0.0165], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,062][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0019, 0.8920, 0.0734, 0.0327], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,063][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5159, 0.4558, 0.0230, 0.0054], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,065][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1928, 0.1876, 0.3986, 0.2210], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,067][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.8653, 0.0507, 0.0784, 0.0056], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,071][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.9040, 0.0344, 0.0508, 0.0109], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,075][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2905, 0.2718, 0.1981, 0.2396], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,078][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([1.1016e-04, 7.5062e-01, 2.4666e-01, 2.6102e-03], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,079][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.7622, 0.0430, 0.1090, 0.0859], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,079][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([9.9885e-01, 5.0752e-04, 3.3026e-04, 3.1100e-04], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,080][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2327, 0.4053, 0.0260, 0.3360], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,081][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.0233, 0.1569, 0.2490, 0.3680, 0.2029], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,083][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([0.7297, 0.1167, 0.1181, 0.0097, 0.0258], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,085][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.0021, 0.8887, 0.0515, 0.0388, 0.0189], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,089][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.0155, 0.9556, 0.0097, 0.0171, 0.0021], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,093][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.0970, 0.1878, 0.2958, 0.2602, 0.1593], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,096][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([9.6635e-01, 1.0846e-02, 1.9401e-02, 6.9384e-04, 2.7100e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,097][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.5239, 0.2501, 0.0671, 0.1113, 0.0476], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,097][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.2450, 0.2078, 0.1682, 0.1944, 0.1846], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,098][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.0014, 0.9104, 0.0761, 0.0021, 0.0099], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,099][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.4784, 0.0907, 0.2989, 0.1263, 0.0057], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,100][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([9.9717e-01, 4.2058e-04, 5.5792e-04, 4.6898e-04, 1.3851e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,103][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([0.4141, 0.2666, 0.0348, 0.1996, 0.0849], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,107][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0094, 0.0837, 0.2548, 0.2040, 0.1381, 0.3099], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,110][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0084, 0.4585, 0.1757, 0.1617, 0.1584, 0.0373], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,112][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ had] are: tensor([2.2106e-04, 7.1691e-01, 8.5509e-02, 1.2879e-01, 6.6798e-02, 1.7731e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,114][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.2102, 0.6626, 0.0536, 0.0212, 0.0243, 0.0281], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,115][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1079, 0.1343, 0.3022, 0.2296, 0.1908, 0.0351], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,116][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.3346, 0.1500, 0.2006, 0.0922, 0.1621, 0.0605], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,117][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.7242, 0.0960, 0.0455, 0.0449, 0.0428, 0.0465], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,119][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1521, 0.2002, 0.1568, 0.1807, 0.1773, 0.1328], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,121][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ had] are: tensor([1.3027e-05, 2.4606e-01, 5.3920e-01, 1.6611e-02, 1.9791e-01, 2.1498e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,125][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.2523, 0.1035, 0.2220, 0.0961, 0.2018, 0.1245], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,128][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.6316, 0.0413, 0.0297, 0.0316, 0.0362, 0.2296], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,132][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1022, 0.2620, 0.0411, 0.3189, 0.0666, 0.2092], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,133][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0069, 0.1044, 0.1316, 0.1762, 0.0738, 0.4399, 0.0672],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,134][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0746, 0.1185, 0.3435, 0.0277, 0.2124, 0.1092, 0.1141],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,134][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([3.4582e-05, 8.5112e-01, 3.8704e-02, 7.9470e-02, 3.0001e-02, 2.8076e-04,
        3.9037e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,136][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.3441, 0.4007, 0.0477, 0.0455, 0.0518, 0.0886, 0.0216],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,139][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1208, 0.1229, 0.2714, 0.2153, 0.1895, 0.0510, 0.0291],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,143][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.9053, 0.0174, 0.0348, 0.0038, 0.0157, 0.0140, 0.0089],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,147][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.6264, 0.0676, 0.0772, 0.0299, 0.0902, 0.0719, 0.0369],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,150][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1412, 0.1820, 0.1370, 0.1655, 0.1536, 0.1175, 0.1031],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,151][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([8.8978e-07, 5.1351e-01, 4.1425e-01, 6.2804e-03, 6.5348e-02, 5.3293e-05,
        5.5587e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,152][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.3590, 0.0855, 0.0839, 0.0928, 0.0943, 0.1206, 0.1639],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,152][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.8853, 0.0027, 0.0022, 0.0016, 0.0053, 0.0975, 0.0054],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,154][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1795, 0.2106, 0.0257, 0.1818, 0.0601, 0.1310, 0.2113],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,157][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0029, 0.0601, 0.1043, 0.1114, 0.1002, 0.4916, 0.0711, 0.0583],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,161][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0057, 0.2997, 0.0938, 0.1947, 0.0873, 0.0306, 0.2620, 0.0263],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,164][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([9.5496e-05, 6.5027e-01, 6.8942e-02, 1.6417e-01, 1.0395e-01, 1.6714e-03,
        1.0580e-02, 3.2516e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,168][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0197, 0.7760, 0.0376, 0.0668, 0.0354, 0.0177, 0.0302, 0.0166],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,168][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.1164, 0.1055, 0.2360, 0.2373, 0.1917, 0.0500, 0.0414, 0.0216],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,169][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.5877, 0.0399, 0.0951, 0.0165, 0.0884, 0.0419, 0.0643, 0.0662],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,170][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.3975, 0.1441, 0.0426, 0.0886, 0.0443, 0.1207, 0.1306, 0.0317],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,172][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.1107, 0.1598, 0.1335, 0.1499, 0.1490, 0.1109, 0.1004, 0.0859],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,174][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([6.1330e-05, 2.7092e-01, 4.5551e-01, 5.6040e-02, 2.0229e-01, 1.4637e-03,
        1.3403e-02, 3.2016e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,178][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.2021, 0.1039, 0.0842, 0.0916, 0.1593, 0.1735, 0.1238, 0.0617],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,182][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.4586, 0.0525, 0.0409, 0.0381, 0.0499, 0.1636, 0.0559, 0.1406],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,186][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0656, 0.2433, 0.0379, 0.2268, 0.0749, 0.1084, 0.1994, 0.0437],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,186][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0039, 0.0477, 0.0833, 0.0968, 0.0658, 0.3537, 0.0910, 0.0932, 0.1646],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,187][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0553, 0.0516, 0.3112, 0.0060, 0.2495, 0.0585, 0.1262, 0.0996, 0.0421],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,188][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ of] are: tensor([1.4983e-04, 8.4982e-01, 3.3528e-02, 7.6037e-02, 3.5593e-02, 7.6246e-04,
        9.3457e-04, 7.4125e-05, 3.1054e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,190][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.1537, 0.5497, 0.0770, 0.0495, 0.0495, 0.0270, 0.0344, 0.0225, 0.0367],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,193][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1006, 0.1214, 0.2523, 0.1716, 0.1456, 0.0502, 0.0407, 0.0280, 0.0896],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,197][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.6828, 0.0339, 0.0727, 0.0123, 0.0566, 0.0403, 0.0312, 0.0598, 0.0103],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,201][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.5473, 0.0635, 0.0591, 0.0237, 0.0594, 0.0564, 0.0729, 0.0892, 0.0286],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,204][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.1329, 0.1461, 0.1111, 0.1324, 0.1230, 0.0968, 0.0845, 0.0765, 0.0965],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,204][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ of] are: tensor([8.9462e-07, 5.4179e-01, 3.5702e-01, 7.5526e-03, 9.0195e-02, 6.9390e-05,
        1.9897e-03, 1.1045e-05, 1.3685e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,205][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.3664, 0.0259, 0.0866, 0.0366, 0.0504, 0.0790, 0.0973, 0.1979, 0.0599],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,206][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ of] are: tensor([8.4602e-01, 2.4295e-03, 7.0348e-04, 8.2209e-04, 1.8470e-03, 6.9427e-02,
        2.8733e-03, 6.4159e-02, 1.1716e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,208][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.1951, 0.2106, 0.0124, 0.1574, 0.0304, 0.0894, 0.0949, 0.0191, 0.1907],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,211][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0010, 0.0547, 0.0844, 0.0878, 0.0881, 0.3097, 0.0563, 0.0649, 0.1957,
        0.0575], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,215][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0829, 0.0851, 0.2186, 0.0132, 0.1215, 0.0776, 0.0982, 0.0903, 0.0550,
        0.1576], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,218][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([1.9523e-05, 8.7701e-01, 1.7385e-02, 7.9448e-02, 2.1676e-02, 1.9515e-04,
        6.1859e-04, 2.1499e-05, 3.5276e-03, 9.7170e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,222][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.2032, 0.4907, 0.0366, 0.0318, 0.0259, 0.0394, 0.0448, 0.0596, 0.0605,
        0.0074], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,223][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0934, 0.1269, 0.1603, 0.1865, 0.1470, 0.0442, 0.0522, 0.0327, 0.0948,
        0.0621], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,223][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.6513, 0.0466, 0.0739, 0.0095, 0.0779, 0.0364, 0.0318, 0.0406, 0.0138,
        0.0182], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,224][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.2165, 0.1408, 0.0252, 0.0789, 0.0421, 0.1273, 0.1566, 0.0458, 0.1468,
        0.0201], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,226][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.1166, 0.1369, 0.0993, 0.1225, 0.1162, 0.0895, 0.0782, 0.0690, 0.0911,
        0.0806], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,228][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([1.1819e-06, 6.1555e-01, 3.2195e-01, 3.9177e-03, 5.7871e-02, 4.0166e-05,
        3.4119e-04, 4.6410e-06, 2.4423e-04, 8.4391e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,233][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.2909, 0.0524, 0.1629, 0.0419, 0.0311, 0.1463, 0.0584, 0.1693, 0.0432,
        0.0036], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,236][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.7462, 0.0087, 0.0020, 0.0033, 0.0050, 0.1156, 0.0071, 0.0731, 0.0289,
        0.0102], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,240][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0271, 0.2729, 0.0271, 0.2195, 0.0657, 0.0387, 0.1010, 0.0199, 0.1960,
        0.0323], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,241][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0016, 0.0257, 0.0524, 0.0518, 0.0461, 0.3939, 0.0594, 0.0466, 0.1736,
        0.0910, 0.0579], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,241][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0344, 0.0215, 0.1477, 0.0038, 0.0939, 0.0432, 0.0697, 0.0576, 0.0425,
        0.4713, 0.0144], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,242][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ at] are: tensor([2.0607e-05, 8.7741e-01, 2.7297e-02, 6.2711e-02, 2.8090e-02, 1.7873e-04,
        4.5376e-04, 1.8656e-05, 3.4667e-03, 1.7283e-04, 1.8253e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,244][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.1317, 0.5050, 0.0539, 0.0553, 0.0508, 0.0469, 0.0373, 0.0349, 0.0434,
        0.0335, 0.0072], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,247][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0848, 0.1002, 0.1887, 0.1451, 0.1276, 0.0468, 0.0413, 0.0294, 0.0869,
        0.0984, 0.0508], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,251][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.7202, 0.0293, 0.0558, 0.0079, 0.0339, 0.0287, 0.0210, 0.0576, 0.0088,
        0.0255, 0.0113], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,256][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.4034, 0.0922, 0.0678, 0.0379, 0.0498, 0.0813, 0.0830, 0.0792, 0.0399,
        0.0553, 0.0103], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,258][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.1037, 0.1254, 0.0957, 0.1156, 0.1067, 0.0809, 0.0731, 0.0621, 0.0842,
        0.0750, 0.0777], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,259][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ at] are: tensor([2.5369e-06, 6.6910e-01, 2.5856e-01, 5.9774e-03, 6.3263e-02, 1.4055e-04,
        1.1665e-03, 1.8968e-05, 1.0005e-03, 6.2323e-04, 1.5194e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,259][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.2383, 0.0288, 0.1176, 0.0296, 0.1101, 0.0644, 0.0995, 0.1611, 0.0522,
        0.0663, 0.0320], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,260][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ at] are: tensor([8.5310e-01, 2.6095e-03, 7.2432e-04, 8.2430e-04, 1.6382e-03, 6.7165e-02,
        2.6025e-03, 5.4147e-02, 9.9337e-03, 4.5040e-03, 2.7481e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,262][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.1464, 0.1899, 0.0139, 0.1179, 0.0322, 0.0697, 0.1030, 0.0158, 0.1591,
        0.0103, 0.1419], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,265][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0029, 0.0452, 0.0576, 0.0648, 0.0486, 0.2184, 0.0458, 0.0430, 0.2404,
        0.0689, 0.1220, 0.0425], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,269][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1251, 0.0352, 0.1675, 0.0045, 0.1701, 0.0659, 0.0396, 0.1272, 0.0277,
        0.1893, 0.0146, 0.0334], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,272][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ the] are: tensor([1.1588e-05, 8.8904e-01, 1.6955e-02, 6.9275e-02, 2.0754e-02, 1.3091e-04,
        3.4420e-04, 1.2673e-05, 3.0414e-03, 1.3017e-04, 2.1284e-04, 9.3427e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,276][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0950, 0.6195, 0.0420, 0.0452, 0.0502, 0.0352, 0.0155, 0.0200, 0.0341,
        0.0260, 0.0130, 0.0042], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,277][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0786, 0.0966, 0.1783, 0.1362, 0.1164, 0.0403, 0.0286, 0.0257, 0.0903,
        0.0896, 0.0598, 0.0596], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,277][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.8617, 0.0123, 0.0282, 0.0032, 0.0246, 0.0141, 0.0073, 0.0237, 0.0048,
        0.0104, 0.0067, 0.0030], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,278][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.4459, 0.0615, 0.0652, 0.0250, 0.0791, 0.0541, 0.0358, 0.0605, 0.0495,
        0.0477, 0.0230, 0.0527], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,280][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0962, 0.1206, 0.0879, 0.1083, 0.1004, 0.0766, 0.0686, 0.0593, 0.0795,
        0.0698, 0.0735, 0.0593], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,282][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ the] are: tensor([2.7225e-06, 4.2949e-01, 4.1753e-01, 5.7818e-03, 1.4471e-01, 8.2006e-05,
        7.5398e-04, 1.6547e-05, 8.8284e-04, 3.9640e-04, 1.6415e-04, 1.8728e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,287][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.2549, 0.0411, 0.0607, 0.0439, 0.0671, 0.0766, 0.1293, 0.1328, 0.0577,
        0.0354, 0.0377, 0.0629], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,289][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ the] are: tensor([8.5874e-01, 1.9142e-03, 6.0280e-04, 6.7062e-04, 1.4102e-03, 6.8785e-02,
        2.1855e-03, 5.2751e-02, 7.7559e-03, 2.9654e-03, 1.5882e-03, 6.3362e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,293][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0714, 0.1884, 0.0140, 0.1465, 0.0393, 0.0583, 0.1210, 0.0167, 0.1455,
        0.0140, 0.0653, 0.1196], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,294][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0022, 0.0333, 0.0560, 0.0583, 0.0521, 0.2120, 0.0648, 0.0557, 0.1993,
        0.0559, 0.0945, 0.0525, 0.0635], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,295][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0203, 0.0591, 0.1019, 0.0187, 0.0418, 0.0536, 0.0880, 0.0303, 0.0811,
        0.1929, 0.0549, 0.2129, 0.0446], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,296][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ store] are: tensor([1.0249e-05, 8.1881e-01, 2.1742e-02, 1.2020e-01, 3.0794e-02, 1.7676e-04,
        9.7871e-04, 2.0301e-05, 5.7498e-03, 3.6287e-04, 5.7611e-04, 5.5587e-04,
        2.0305e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,298][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0151, 0.7447, 0.0305, 0.1043, 0.0185, 0.0068, 0.0131, 0.0041, 0.0331,
        0.0077, 0.0129, 0.0033, 0.0057], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,300][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0524, 0.0892, 0.1460, 0.1790, 0.1321, 0.0307, 0.0487, 0.0203, 0.0861,
        0.0559, 0.0603, 0.0716, 0.0276], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,305][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.8136, 0.0110, 0.0343, 0.0028, 0.0229, 0.0225, 0.0107, 0.0260, 0.0080,
        0.0202, 0.0082, 0.0111, 0.0087], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,309][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.3000, 0.0858, 0.0288, 0.0398, 0.0384, 0.0784, 0.0714, 0.0498, 0.0788,
        0.0328, 0.0297, 0.1335, 0.0328], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,311][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0811, 0.1070, 0.0842, 0.1018, 0.0992, 0.0722, 0.0648, 0.0552, 0.0746,
        0.0692, 0.0711, 0.0579, 0.0617], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,312][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ store] are: tensor([3.3873e-07, 5.2831e-01, 3.1429e-01, 8.2595e-03, 1.4665e-01, 5.5668e-05,
        1.0979e-03, 2.8726e-06, 6.3963e-04, 3.2473e-04, 8.0670e-05, 2.7555e-04,
        1.2442e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,313][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.1867, 0.0228, 0.1311, 0.0290, 0.1495, 0.1109, 0.0849, 0.0691, 0.0374,
        0.0810, 0.0299, 0.0633, 0.0045], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,314][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.7401, 0.0045, 0.0022, 0.0023, 0.0058, 0.0848, 0.0064, 0.0870, 0.0262,
        0.0061, 0.0095, 0.0035, 0.0215], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,316][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0245, 0.1607, 0.0204, 0.1498, 0.0686, 0.0320, 0.0862, 0.0160, 0.1508,
        0.0264, 0.1307, 0.0931, 0.0409], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,319][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0020, 0.0181, 0.0501, 0.0278, 0.0741, 0.1705, 0.0549, 0.0603, 0.1151,
        0.0902, 0.0761, 0.0450, 0.0981, 0.1177], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,323][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0196, 0.0517, 0.1096, 0.0043, 0.0837, 0.0391, 0.0547, 0.0385, 0.0252,
        0.3397, 0.0205, 0.0907, 0.1070, 0.0159], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,325][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [.] are: tensor([3.5120e-05, 8.8068e-01, 2.3798e-02, 5.9477e-02, 3.0173e-02, 2.2643e-04,
        6.1585e-04, 3.0618e-05, 3.8899e-03, 2.2957e-04, 2.8244e-04, 3.0877e-04,
        1.9922e-05, 2.3297e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,328][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [.] are: tensor([4.8510e-02, 6.7784e-01, 2.0832e-02, 2.2176e-02, 4.8956e-02, 2.6176e-02,
        6.3022e-02, 1.8077e-02, 1.4614e-02, 2.2913e-02, 6.3327e-03, 4.8596e-03,
        2.5058e-02, 6.3202e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,330][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0605, 0.0771, 0.1816, 0.1198, 0.0918, 0.0315, 0.0367, 0.0214, 0.0723,
        0.0825, 0.0464, 0.0755, 0.0448, 0.0582], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,330][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.7893, 0.0134, 0.0330, 0.0052, 0.0277, 0.0196, 0.0127, 0.0384, 0.0057,
        0.0122, 0.0080, 0.0078, 0.0143, 0.0126], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,331][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.4606, 0.0285, 0.0488, 0.0121, 0.0620, 0.0536, 0.0554, 0.0628, 0.0222,
        0.0425, 0.0090, 0.0813, 0.0526, 0.0086], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,332][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0850, 0.1053, 0.0760, 0.0959, 0.0873, 0.0682, 0.0605, 0.0516, 0.0707,
        0.0616, 0.0656, 0.0536, 0.0563, 0.0624], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,334][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [.] are: tensor([2.4016e-06, 6.2042e-01, 2.7739e-01, 6.9699e-03, 9.2369e-02, 8.7572e-05,
        9.8237e-04, 1.5026e-05, 7.1460e-04, 4.0236e-04, 9.3558e-05, 2.6445e-04,
        4.7534e-05, 2.4029e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,336][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.2210, 0.0368, 0.0492, 0.0421, 0.0691, 0.0857, 0.0613, 0.1276, 0.0660,
        0.0376, 0.0469, 0.0575, 0.0678, 0.0314], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,339][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [.] are: tensor([8.6562e-01, 1.5438e-03, 5.0208e-04, 5.3065e-04, 1.1118e-03, 5.5825e-02,
        2.2624e-03, 5.0822e-02, 7.9679e-03, 2.7066e-03, 2.0829e-03, 7.1761e-04,
        2.8774e-03, 5.4323e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,343][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0868, 0.1488, 0.0131, 0.1273, 0.0292, 0.0498, 0.0597, 0.0178, 0.1026,
        0.0106, 0.0619, 0.0478, 0.0208, 0.2237], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,347][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.0009, 0.0221, 0.0342, 0.0578, 0.0462, 0.1236, 0.0748, 0.0449, 0.1551,
        0.0457, 0.0730, 0.0513, 0.0600, 0.1538, 0.0564], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,348][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0586, 0.0667, 0.0700, 0.0220, 0.0809, 0.0623, 0.0602, 0.0708, 0.0358,
        0.1685, 0.0304, 0.0678, 0.0929, 0.0506, 0.0625], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,349][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([2.0156e-04, 8.5916e-01, 2.7022e-02, 7.5251e-02, 2.5581e-02, 7.5640e-04,
        1.2320e-03, 1.1890e-04, 6.8760e-03, 5.5940e-04, 7.2383e-04, 4.8504e-04,
        8.1569e-05, 8.1009e-04, 1.1426e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,350][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0071, 0.7908, 0.0147, 0.0618, 0.0244, 0.0109, 0.0113, 0.0031, 0.0274,
        0.0034, 0.0069, 0.0033, 0.0124, 0.0202, 0.0023], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,352][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.0330, 0.0749, 0.1166, 0.1208, 0.1025, 0.0269, 0.0357, 0.0234, 0.0689,
        0.0561, 0.0451, 0.0574, 0.0391, 0.0729, 0.1265], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,355][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.8108, 0.0226, 0.0295, 0.0039, 0.0293, 0.0175, 0.0077, 0.0208, 0.0027,
        0.0119, 0.0041, 0.0045, 0.0149, 0.0088, 0.0110], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,355][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.0800, 0.0938, 0.0194, 0.0642, 0.0442, 0.0791, 0.1173, 0.0350, 0.1205,
        0.0223, 0.0325, 0.1884, 0.0364, 0.0507, 0.0162], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,360][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.0949, 0.0927, 0.0731, 0.0854, 0.0814, 0.0626, 0.0558, 0.0505, 0.0645,
        0.0579, 0.0598, 0.0488, 0.0536, 0.0570, 0.0620], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,362][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([5.0868e-05, 8.2403e-01, 1.0490e-01, 6.0627e-03, 6.3780e-02, 1.9296e-04,
        3.4968e-04, 4.6346e-05, 1.7173e-04, 1.1625e-04, 2.4479e-05, 6.8122e-05,
        9.0992e-06, 6.1395e-05, 1.4119e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,365][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.2738, 0.0206, 0.0252, 0.0274, 0.1059, 0.0895, 0.0393, 0.0575, 0.0373,
        0.1000, 0.0245, 0.0502, 0.0965, 0.0217, 0.0305], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,367][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([8.4853e-01, 1.4576e-03, 1.5341e-03, 8.0684e-04, 1.3664e-03, 6.2675e-02,
        2.4671e-03, 6.3195e-02, 5.5542e-03, 2.1721e-03, 1.5299e-03, 7.8709e-04,
        1.7285e-03, 3.4260e-03, 2.7696e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,368][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.1227, 0.0794, 0.0125, 0.0803, 0.0321, 0.0597, 0.0887, 0.0230, 0.1370,
        0.0105, 0.1198, 0.0754, 0.0131, 0.1310, 0.0148], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,369][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0008, 0.0256, 0.0564, 0.0513, 0.0463, 0.0689, 0.0526, 0.0335, 0.1418,
        0.0590, 0.0758, 0.0464, 0.0666, 0.1480, 0.0885, 0.0383],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,371][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0027, 0.1676, 0.0600, 0.0699, 0.0553, 0.0131, 0.0919, 0.0104, 0.0849,
        0.0874, 0.0660, 0.1216, 0.0496, 0.0611, 0.0490, 0.0095],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,373][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([1.7754e-04, 6.2797e-01, 6.3494e-02, 1.5661e-01, 8.9660e-02, 1.6528e-03,
        7.8233e-03, 4.1834e-04, 2.3944e-02, 3.9763e-03, 5.3884e-03, 5.0366e-03,
        9.0373e-04, 5.4925e-03, 6.5273e-03, 9.3200e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,377][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0697, 0.4049, 0.0450, 0.0395, 0.0368, 0.0288, 0.0538, 0.0491, 0.0485,
        0.0282, 0.0179, 0.0580, 0.0355, 0.0528, 0.0236, 0.0079],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,381][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0530, 0.0588, 0.1109, 0.1113, 0.0913, 0.0176, 0.0286, 0.0167, 0.0787,
        0.0514, 0.0467, 0.0670, 0.0345, 0.0623, 0.1377, 0.0333],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,385][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.4047, 0.0451, 0.0752, 0.0153, 0.0744, 0.0320, 0.0280, 0.0520, 0.0183,
        0.0322, 0.0245, 0.0249, 0.0484, 0.0374, 0.0434, 0.0442],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,385][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.3534, 0.0842, 0.0229, 0.0401, 0.0306, 0.0411, 0.0563, 0.0199, 0.0752,
        0.0188, 0.0160, 0.1235, 0.0235, 0.0468, 0.0195, 0.0281],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,386][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0658, 0.0899, 0.0705, 0.0813, 0.0807, 0.0597, 0.0543, 0.0474, 0.0625,
        0.0575, 0.0585, 0.0487, 0.0519, 0.0560, 0.0609, 0.0544],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,387][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([7.6925e-05, 3.6055e-01, 3.1953e-01, 3.5625e-02, 2.5398e-01, 7.2642e-04,
        7.1848e-03, 2.6017e-04, 5.4792e-03, 3.0100e-03, 1.7543e-03, 2.9834e-03,
        7.3372e-04, 3.2806e-03, 4.4546e-03, 3.7435e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,389][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0944, 0.0431, 0.1032, 0.0213, 0.1398, 0.0431, 0.0526, 0.0496, 0.0389,
        0.0337, 0.0501, 0.0500, 0.0937, 0.0403, 0.1196, 0.0266],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,392][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.2753, 0.0310, 0.0161, 0.0183, 0.0246, 0.1074, 0.0307, 0.0906, 0.0691,
        0.0330, 0.0357, 0.0214, 0.0426, 0.0502, 0.0306, 0.1235],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,396][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0272, 0.1051, 0.0157, 0.1133, 0.0272, 0.0483, 0.0892, 0.0192, 0.1179,
        0.0175, 0.0838, 0.0735, 0.0338, 0.1619, 0.0135, 0.0528],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,400][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0017, 0.0335, 0.0371, 0.0557, 0.0225, 0.1312, 0.0180, 0.0274, 0.1637,
        0.0415, 0.1073, 0.0336, 0.0559, 0.1596, 0.0564, 0.0364, 0.0185],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,403][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0086, 0.0725, 0.0967, 0.0289, 0.0818, 0.0262, 0.0510, 0.0313, 0.0487,
        0.1649, 0.0312, 0.0940, 0.0702, 0.0504, 0.0889, 0.0282, 0.0265],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,404][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([9.1977e-05, 7.9779e-01, 3.5855e-02, 1.0232e-01, 4.4287e-02, 6.7346e-04,
        1.6187e-03, 1.2464e-04, 9.3724e-03, 9.5603e-04, 1.2368e-03, 9.6673e-04,
        1.5802e-04, 1.5991e-03, 1.5712e-03, 3.5068e-04, 1.0207e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,405][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0630, 0.4850, 0.0336, 0.0722, 0.0367, 0.0444, 0.0126, 0.0251, 0.0580,
        0.0253, 0.0147, 0.0119, 0.0544, 0.0252, 0.0095, 0.0156, 0.0128],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,406][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0606, 0.0495, 0.1234, 0.0967, 0.0839, 0.0183, 0.0121, 0.0137, 0.0618,
        0.0582, 0.0345, 0.0513, 0.0397, 0.0657, 0.1658, 0.0476, 0.0173],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,409][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.5971, 0.0289, 0.0482, 0.0070, 0.0267, 0.0186, 0.0118, 0.0531, 0.0068,
        0.0184, 0.0097, 0.0092, 0.0184, 0.0238, 0.0310, 0.0768, 0.0147],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,413][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3121, 0.0474, 0.0514, 0.0199, 0.0637, 0.0560, 0.0252, 0.0533, 0.0500,
        0.0436, 0.0158, 0.0544, 0.0515, 0.0323, 0.0452, 0.0585, 0.0198],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,418][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0606, 0.0895, 0.0697, 0.0799, 0.0774, 0.0570, 0.0515, 0.0427, 0.0590,
        0.0539, 0.0557, 0.0458, 0.0481, 0.0529, 0.0583, 0.0504, 0.0478],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,420][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([6.7736e-06, 5.5864e-01, 3.1479e-01, 1.4812e-02, 1.0426e-01, 1.5222e-04,
        1.0780e-03, 4.3936e-05, 1.4353e-03, 1.2190e-03, 2.4891e-04, 7.8733e-04,
        9.0734e-05, 1.2542e-03, 7.0114e-04, 7.4323e-05, 4.0689e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,421][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1289, 0.0392, 0.0389, 0.0397, 0.0487, 0.0539, 0.0664, 0.0976, 0.0442,
        0.0302, 0.0439, 0.0595, 0.0465, 0.0500, 0.0431, 0.0968, 0.0724],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,422][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.4688, 0.0139, 0.0064, 0.0059, 0.0106, 0.1073, 0.0135, 0.0780, 0.0314,
        0.0157, 0.0125, 0.0064, 0.0161, 0.0230, 0.0111, 0.1208, 0.0585],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,423][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0524, 0.0939, 0.0157, 0.0894, 0.0302, 0.0485, 0.0906, 0.0152, 0.0937,
        0.0116, 0.0573, 0.0590, 0.0234, 0.1339, 0.0130, 0.0442, 0.1279],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,425][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.0013, 0.0220, 0.0335, 0.0426, 0.0338, 0.1151, 0.0459, 0.0449, 0.1352,
        0.0336, 0.0663, 0.0428, 0.0676, 0.1268, 0.0579, 0.0349, 0.0569, 0.0388],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,428][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([0.1885, 0.0379, 0.0458, 0.0043, 0.0705, 0.0407, 0.0170, 0.0892, 0.0138,
        0.0944, 0.0177, 0.0165, 0.1532, 0.0141, 0.0399, 0.0792, 0.0277, 0.0497],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,431][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([3.2466e-05, 9.1517e-01, 1.0411e-02, 5.1154e-02, 1.8476e-02, 1.7320e-04,
        3.5989e-04, 1.9560e-05, 2.4894e-03, 1.8154e-04, 2.3568e-04, 1.7295e-04,
        1.4472e-05, 2.8208e-04, 2.7383e-04, 8.5738e-05, 3.3750e-04, 1.2636e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,433][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([1.2538e-03, 8.9390e-01, 1.1248e-02, 3.1040e-02, 7.4086e-03, 2.9641e-03,
        7.5057e-03, 1.2180e-03, 1.4426e-02, 2.2908e-03, 3.0489e-03, 4.2131e-03,
        2.8474e-03, 1.0492e-02, 1.4940e-03, 5.9784e-04, 3.6181e-03, 4.3502e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,436][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([0.0314, 0.0606, 0.1095, 0.1080, 0.1056, 0.0225, 0.0322, 0.0145, 0.0781,
        0.0394, 0.0392, 0.0587, 0.0243, 0.0694, 0.1123, 0.0334, 0.0360, 0.0249],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,438][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([8.9006e-01, 1.4521e-02, 1.5818e-02, 8.2846e-04, 1.4099e-02, 4.9397e-03,
        2.0796e-03, 7.6105e-03, 1.0741e-03, 5.4537e-03, 1.8715e-03, 1.1391e-03,
        1.0051e-02, 2.7114e-03, 6.9000e-03, 1.4756e-02, 1.8834e-03, 4.2015e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,439][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([0.1333, 0.0733, 0.0343, 0.0380, 0.0405, 0.0839, 0.0625, 0.0361, 0.0997,
        0.0290, 0.0297, 0.0919, 0.0331, 0.0390, 0.0313, 0.0810, 0.0492, 0.0142],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,440][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([0.0670, 0.0827, 0.0671, 0.0746, 0.0777, 0.0540, 0.0478, 0.0411, 0.0534,
        0.0518, 0.0511, 0.0420, 0.0465, 0.0487, 0.0564, 0.0478, 0.0447, 0.0456],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,441][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([1.5648e-05, 8.0021e-01, 1.3175e-01, 1.6675e-03, 6.4992e-02, 6.4397e-05,
        2.3388e-04, 2.1267e-05, 1.5146e-04, 1.7579e-04, 3.9811e-05, 9.1381e-05,
        1.9257e-05, 8.9474e-05, 2.6409e-04, 3.1898e-05, 8.8299e-05, 9.4841e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,443][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([0.1947, 0.0411, 0.0442, 0.0510, 0.0292, 0.0448, 0.0487, 0.0628, 0.0410,
        0.0516, 0.0651, 0.0388, 0.0707, 0.0619, 0.0426, 0.0475, 0.0601, 0.0041],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,446][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([0.5227, 0.0090, 0.0054, 0.0073, 0.0085, 0.1095, 0.0123, 0.0781, 0.0346,
        0.0078, 0.0064, 0.0052, 0.0061, 0.0256, 0.0100, 0.0972, 0.0515, 0.0027],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,450][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([0.0129, 0.0948, 0.0167, 0.1164, 0.0447, 0.0221, 0.0656, 0.0110, 0.1304,
        0.0158, 0.0750, 0.0697, 0.0176, 0.1831, 0.0136, 0.0262, 0.0729, 0.0116],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,454][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0017, 0.0173, 0.0343, 0.0251, 0.0321, 0.1423, 0.0423, 0.0357, 0.0749,
        0.0713, 0.0442, 0.0511, 0.0628, 0.1210, 0.0588, 0.0469, 0.0592, 0.0419,
        0.0369], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,456][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0317, 0.0168, 0.1071, 0.0031, 0.0589, 0.0319, 0.0398, 0.0511, 0.0181,
        0.1853, 0.0078, 0.0637, 0.0578, 0.0142, 0.0965, 0.0323, 0.0209, 0.1565,
        0.0064], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,457][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.8970e-04, 8.3700e-01, 3.9438e-02, 6.9516e-02, 4.2760e-02, 7.7280e-04,
        8.9371e-04, 9.3221e-05, 4.2598e-03, 2.6898e-04, 4.0099e-04, 3.5823e-04,
        3.1153e-05, 3.7378e-04, 7.4065e-04, 3.9866e-04, 9.7236e-04, 3.6983e-04,
        1.1578e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,458][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0396, 0.7442, 0.0234, 0.0407, 0.0166, 0.0095, 0.0154, 0.0062, 0.0241,
        0.0072, 0.0114, 0.0031, 0.0189, 0.0111, 0.0051, 0.0043, 0.0135, 0.0018,
        0.0039], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,459][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0332, 0.0541, 0.1167, 0.0871, 0.0811, 0.0196, 0.0194, 0.0148, 0.0466,
        0.0601, 0.0275, 0.0496, 0.0487, 0.0625, 0.1370, 0.0563, 0.0295, 0.0391,
        0.0169], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,461][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.5274, 0.0260, 0.0474, 0.0087, 0.0292, 0.0271, 0.0220, 0.0537, 0.0076,
        0.0213, 0.0124, 0.0172, 0.0215, 0.0234, 0.0322, 0.0622, 0.0239, 0.0247,
        0.0123], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,465][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1932, 0.0405, 0.0473, 0.0156, 0.0538, 0.0634, 0.0585, 0.0734, 0.0271,
        0.0410, 0.0112, 0.1147, 0.0607, 0.0203, 0.0424, 0.0487, 0.0499, 0.0320,
        0.0064], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,468][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0640, 0.0808, 0.0596, 0.0718, 0.0680, 0.0516, 0.0469, 0.0393, 0.0534,
        0.0479, 0.0493, 0.0408, 0.0443, 0.0477, 0.0502, 0.0454, 0.0439, 0.0419,
        0.0529], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,470][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([4.5877e-06, 6.2966e-01, 2.9110e-01, 6.2956e-03, 6.6251e-02, 1.0302e-04,
        1.1232e-03, 3.0321e-05, 1.0506e-03, 7.9804e-04, 1.2479e-04, 5.2963e-04,
        6.3453e-05, 7.7670e-04, 5.2182e-04, 4.6722e-05, 3.1471e-04, 8.4955e-04,
        3.5212e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,474][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1760, 0.0227, 0.0468, 0.0247, 0.0432, 0.0491, 0.0708, 0.0998, 0.0362,
        0.0202, 0.0406, 0.0514, 0.0316, 0.0275, 0.0522, 0.0853, 0.0845, 0.0194,
        0.0181], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,475][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([7.8006e-01, 1.5712e-03, 4.5255e-04, 4.2341e-04, 1.0230e-03, 5.3142e-02,
        1.7746e-03, 4.7960e-02, 6.8681e-03, 3.0577e-03, 1.9216e-03, 5.5956e-04,
        1.9148e-03, 3.9451e-03, 1.1212e-03, 7.1912e-02, 1.8659e-02, 2.3236e-04,
        3.4021e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,476][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0519, 0.1091, 0.0084, 0.0928, 0.0212, 0.0364, 0.0618, 0.0108, 0.0931,
        0.0078, 0.0682, 0.0433, 0.0161, 0.1471, 0.0066, 0.0410, 0.0938, 0.0056,
        0.0851], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,536][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:32,536][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,537][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,538][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,538][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,539][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,540][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,541][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,541][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,542][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,543][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,543][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,544][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:32,545][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9919, 0.0081], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,545][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.3459, 0.6541], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,546][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1166, 0.8834], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,547][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2365, 0.7635], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,548][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([7.4995e-04, 9.9925e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,549][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9871, 0.0129], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,549][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0211, 0.9789], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,550][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1394, 0.8606], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,554][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1502, 0.8498], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,556][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([9.9969e-01, 3.1421e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,557][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([9.9989e-01, 1.1370e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,558][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9743, 0.0257], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:32,559][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.9848, 0.0024, 0.0127], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,559][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.5765, 0.2309, 0.1926], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,561][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.0065, 0.9342, 0.0593], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,565][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.0155, 0.8757, 0.1088], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,567][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([2.5008e-04, 9.9250e-01, 7.2509e-03], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,570][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.9785, 0.0093, 0.0121], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,573][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([9.6897e-04, 9.9724e-01, 1.7926e-03], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,574][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.0719, 0.8953, 0.0328], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,575][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.0875, 0.8258, 0.0868], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,576][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([9.9597e-01, 9.8965e-04, 3.0373e-03], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,576][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([9.9899e-01, 3.5370e-04, 6.5448e-04], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,577][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.9495, 0.0301, 0.0205], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:32,579][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([9.8060e-01, 2.6309e-03, 1.5860e-02, 9.1396e-04], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,581][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1281, 0.3466, 0.5088, 0.0165], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,585][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0019, 0.8920, 0.0734, 0.0327], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,588][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0024, 0.9257, 0.0436, 0.0282], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,590][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([1.3711e-05, 9.8654e-01, 2.0268e-03, 1.1424e-02], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,592][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.7139, 0.1019, 0.1371, 0.0471], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,593][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0034, 0.9065, 0.0010, 0.0891], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,594][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0043, 0.9303, 0.0082, 0.0571], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,595][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0065, 0.8948, 0.0865, 0.0123], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,596][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9940, 0.0014, 0.0036, 0.0011], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,598][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([9.9885e-01, 5.0752e-04, 3.3026e-04, 3.1100e-04], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,601][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.8196, 0.0637, 0.0110, 0.1057], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:32,603][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([9.8462e-01, 2.1212e-03, 7.0188e-03, 6.4673e-04, 5.5906e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,607][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([0.7297, 0.1167, 0.1181, 0.0097, 0.0258], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,610][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([0.0021, 0.8887, 0.0515, 0.0388, 0.0189], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,611][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([0.0055, 0.7689, 0.0925, 0.0663, 0.0668], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,612][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([2.8289e-05, 9.5552e-01, 4.2625e-03, 3.6663e-02, 3.5214e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,612][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.9469, 0.0135, 0.0305, 0.0029, 0.0062], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,613][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([4.7788e-04, 9.0253e-01, 1.3380e-03, 9.5518e-02, 1.3626e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,615][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.0224, 0.8001, 0.0361, 0.1232, 0.0182], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,617][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.0555, 0.8073, 0.0687, 0.0281, 0.0403], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,621][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.9835, 0.0035, 0.0089, 0.0016, 0.0025], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,624][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([9.9717e-01, 4.2058e-04, 5.5792e-04, 4.6898e-04, 1.3851e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,628][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.8516, 0.0428, 0.0172, 0.0465, 0.0418], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:32,628][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.3298, 0.1204, 0.1802, 0.0609, 0.1569, 0.1518], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,629][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0084, 0.4585, 0.1757, 0.1617, 0.1584, 0.0373], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,630][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([2.2106e-04, 7.1691e-01, 8.5509e-02, 1.2879e-01, 6.6798e-02, 1.7731e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,631][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0010, 0.5814, 0.1062, 0.1554, 0.1503, 0.0058], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,634][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([1.1939e-05, 8.6620e-01, 1.2303e-02, 1.0073e-01, 2.0474e-02, 2.8629e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,637][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0393, 0.2279, 0.1200, 0.4071, 0.1531, 0.0525], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,639][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([1.5104e-04, 8.0975e-01, 7.4690e-03, 1.7337e-01, 7.4185e-03, 1.8479e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,643][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0011, 0.6949, 0.0337, 0.2211, 0.0415, 0.0077], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,645][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0009, 0.7051, 0.0808, 0.1026, 0.1069, 0.0037], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,646][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.5626, 0.0681, 0.0833, 0.0450, 0.0921, 0.1489], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,647][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.6316, 0.0413, 0.0297, 0.0316, 0.0362, 0.2296], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,648][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.2042, 0.1609, 0.0583, 0.2195, 0.1018, 0.2553], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:32,649][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.8203, 0.0079, 0.0233, 0.0050, 0.0190, 0.1114, 0.0131],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,652][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0746, 0.1185, 0.3435, 0.0277, 0.2124, 0.1092, 0.1141],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,654][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([3.4582e-05, 8.5112e-01, 3.8704e-02, 7.9470e-02, 3.0001e-02, 2.8076e-04,
        3.9037e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,657][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.1163e-04, 8.2047e-01, 3.7909e-02, 8.2067e-02, 5.6840e-02, 1.0693e-03,
        1.5385e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,659][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.7538e-07, 9.5992e-01, 2.2451e-03, 3.4642e-02, 3.1553e-03, 1.2654e-05,
        2.2510e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,663][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.4567, 0.0587, 0.0936, 0.0755, 0.0972, 0.1336, 0.0848],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,664][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([4.6976e-05, 8.5275e-01, 5.5209e-04, 1.4519e-01, 3.1516e-04, 6.6989e-04,
        4.7517e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,664][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([1.6963e-04, 8.4263e-01, 7.6648e-03, 1.3765e-01, 7.6433e-03, 2.4851e-03,
        1.7508e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,665][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([4.6903e-04, 7.8562e-01, 6.5392e-02, 6.4204e-02, 7.9933e-02, 1.7372e-03,
        2.6429e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,667][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.8919, 0.0061, 0.0110, 0.0040, 0.0102, 0.0689, 0.0080],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,670][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.8853, 0.0027, 0.0022, 0.0016, 0.0053, 0.0975, 0.0054],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,674][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3525, 0.0877, 0.0240, 0.1095, 0.0898, 0.2184, 0.1182],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:32,677][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.1783, 0.1176, 0.1003, 0.0645, 0.0991, 0.1404, 0.1171, 0.1825],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,681][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0057, 0.2997, 0.0938, 0.1947, 0.0873, 0.0306, 0.2620, 0.0263],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,682][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([9.5496e-05, 6.5027e-01, 6.8942e-02, 1.6417e-01, 1.0395e-01, 1.6714e-03,
        1.0580e-02, 3.2516e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,682][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([4.5057e-04, 5.0727e-01, 8.3441e-02, 2.3492e-01, 1.4724e-01, 5.7213e-03,
        1.9488e-02, 1.4722e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,683][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([4.5098e-06, 7.7381e-01, 1.4160e-02, 1.8031e-01, 2.9123e-02, 3.0984e-04,
        2.2568e-03, 2.3255e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,685][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0438, 0.1557, 0.1108, 0.2278, 0.1390, 0.0601, 0.2044, 0.0584],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,687][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([8.0185e-05, 7.5616e-01, 6.7282e-03, 2.1668e-01, 9.3191e-03, 1.8730e-03,
        8.8982e-03, 2.5433e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,689][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([5.1040e-04, 6.2626e-01, 4.3393e-02, 2.4614e-01, 5.6302e-02, 7.2724e-03,
        1.9068e-02, 1.0559e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,692][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0007, 0.5431, 0.0876, 0.1919, 0.1375, 0.0059, 0.0316, 0.0017],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,696][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.3707, 0.0647, 0.0797, 0.0489, 0.0935, 0.1433, 0.0619, 0.1373],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,699][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.4586, 0.0525, 0.0409, 0.0381, 0.0499, 0.1636, 0.0559, 0.1406],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,699][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.1465, 0.1710, 0.0515, 0.1625, 0.1009, 0.1512, 0.1201, 0.0963],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:32,700][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.5310, 0.0222, 0.0394, 0.0062, 0.0260, 0.0958, 0.0252, 0.2216, 0.0326],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,701][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0553, 0.0516, 0.3112, 0.0060, 0.2495, 0.0585, 0.1262, 0.0996, 0.0421],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,702][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([1.4983e-04, 8.4982e-01, 3.3528e-02, 7.6037e-02, 3.5593e-02, 7.6246e-04,
        9.3457e-04, 7.4125e-05, 3.1054e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,704][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([2.6429e-04, 8.5233e-01, 3.3945e-02, 6.6264e-02, 3.8246e-02, 1.4420e-03,
        1.8080e-03, 3.2739e-04, 5.3691e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,707][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([7.7030e-07, 9.7469e-01, 1.7158e-03, 2.1698e-02, 1.5491e-03, 2.4518e-05,
        2.5166e-05, 3.8944e-07, 2.9545e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,710][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.2126, 0.0482, 0.1098, 0.0594, 0.1540, 0.0969, 0.1151, 0.1134, 0.0906],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,712][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([7.1021e-04, 8.7278e-01, 7.4611e-04, 1.1190e-01, 2.4584e-04, 3.2782e-03,
        1.2599e-03, 2.7086e-04, 8.8118e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,714][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([9.4749e-04, 7.9550e-01, 9.9106e-03, 1.5447e-01, 6.7525e-03, 5.7853e-03,
        2.9048e-03, 4.3322e-04, 2.3298e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,716][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([5.2910e-04, 7.4578e-01, 7.9855e-02, 3.5472e-02, 1.2353e-01, 1.4668e-03,
        5.0350e-03, 4.2051e-04, 7.9115e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,717][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.7434, 0.0117, 0.0112, 0.0056, 0.0122, 0.0798, 0.0123, 0.1024, 0.0214],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,718][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([8.4602e-01, 2.4295e-03, 7.0348e-04, 8.2209e-04, 1.8470e-03, 6.9427e-02,
        2.8733e-03, 6.4159e-02, 1.1716e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,719][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.3530, 0.0907, 0.0104, 0.1211, 0.0372, 0.1617, 0.0636, 0.0579, 0.1044],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:32,721][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.5974, 0.0056, 0.0360, 0.0018, 0.0233, 0.0850, 0.0107, 0.1687, 0.0191,
        0.0524], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,723][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0829, 0.0851, 0.2186, 0.0132, 0.1215, 0.0776, 0.0982, 0.0903, 0.0550,
        0.1576], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,726][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([1.9523e-05, 8.7701e-01, 1.7385e-02, 7.9448e-02, 2.1676e-02, 1.9515e-04,
        6.1859e-04, 2.1499e-05, 3.5276e-03, 9.7170e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,728][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([8.3951e-05, 8.0189e-01, 3.7291e-02, 9.9832e-02, 4.7501e-02, 8.6425e-04,
        1.9009e-03, 1.5971e-04, 9.1967e-03, 1.2845e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,730][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([2.1577e-07, 9.5258e-01, 1.7309e-03, 4.1865e-02, 3.0768e-03, 1.2842e-05,
        4.8074e-05, 3.5807e-07, 6.7689e-04, 1.2045e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,734][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.2836, 0.0567, 0.0902, 0.0322, 0.1809, 0.0795, 0.0664, 0.0921, 0.0832,
        0.0353], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,735][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([1.9843e-05, 7.6369e-01, 5.1010e-04, 2.1549e-01, 3.4583e-04, 6.5757e-04,
        1.5878e-03, 3.7911e-05, 1.7550e-02, 1.1195e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,736][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([4.0081e-04, 8.0076e-01, 5.4970e-03, 1.4458e-01, 8.7780e-03, 2.9718e-03,
        2.7708e-03, 2.0043e-04, 3.2509e-02, 1.5255e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,737][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([2.4800e-04, 8.1626e-01, 5.0747e-02, 4.0732e-02, 7.6365e-02, 1.0501e-03,
        3.4478e-03, 2.0583e-04, 9.9404e-03, 9.9973e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,739][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.6579, 0.0165, 0.0285, 0.0105, 0.0184, 0.0928, 0.0197, 0.1232, 0.0258,
        0.0066], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,742][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.7462, 0.0087, 0.0020, 0.0033, 0.0050, 0.1156, 0.0071, 0.0731, 0.0289,
        0.0102], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,746][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.2770, 0.1634, 0.0182, 0.1210, 0.0425, 0.1321, 0.0558, 0.0749, 0.0851,
        0.0301], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:32,750][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.5024, 0.0103, 0.0269, 0.0025, 0.0177, 0.0897, 0.0157, 0.2125, 0.0209,
        0.0866, 0.0148], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,752][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0344, 0.0215, 0.1477, 0.0038, 0.0939, 0.0432, 0.0697, 0.0576, 0.0425,
        0.4713, 0.0144], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,753][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([2.0607e-05, 8.7741e-01, 2.7297e-02, 6.2711e-02, 2.8090e-02, 1.7873e-04,
        4.5376e-04, 1.8656e-05, 3.4667e-03, 1.7283e-04, 1.8253e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,754][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([4.2291e-05, 8.6032e-01, 2.4913e-02, 7.3646e-02, 3.0386e-02, 5.6590e-04,
        1.3698e-03, 9.6170e-05, 6.8601e-03, 1.0680e-03, 7.2900e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,754][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([1.9155e-07, 9.7294e-01, 1.2605e-03, 2.3843e-02, 1.4909e-03, 1.1001e-05,
        2.5274e-05, 2.2149e-07, 3.9972e-04, 1.0348e-05, 2.0475e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,757][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.1605, 0.0457, 0.0653, 0.0434, 0.0817, 0.0719, 0.0866, 0.1116, 0.0883,
        0.2204, 0.0245], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,759][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([6.0095e-04, 8.1537e-01, 1.4053e-03, 1.6566e-01, 4.8890e-04, 3.0685e-03,
        1.7473e-03, 2.2983e-04, 1.0428e-02, 3.4099e-04, 6.6571e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,761][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([5.0030e-04, 7.8971e-01, 1.3551e-02, 1.5137e-01, 1.0346e-02, 3.2102e-03,
        3.0217e-03, 1.9195e-04, 2.3945e-02, 1.9408e-03, 2.2193e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,764][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([1.7543e-04, 8.2594e-01, 3.7683e-02, 4.7617e-02, 7.1188e-02, 8.4019e-04,
        3.8584e-03, 2.5242e-04, 8.5713e-03, 3.2633e-03, 6.1291e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,768][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.7100, 0.0116, 0.0141, 0.0070, 0.0148, 0.0745, 0.0136, 0.1116, 0.0209,
        0.0115, 0.0104], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,770][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([8.5310e-01, 2.6095e-03, 7.2432e-04, 8.2430e-04, 1.6382e-03, 6.7165e-02,
        2.6025e-03, 5.4147e-02, 9.9337e-03, 4.5040e-03, 2.7481e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,771][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.2582, 0.1434, 0.0166, 0.0907, 0.0535, 0.1298, 0.0656, 0.0546, 0.0786,
        0.0353, 0.0736], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:32,772][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.6588, 0.0045, 0.0157, 0.0015, 0.0101, 0.0681, 0.0061, 0.1736, 0.0126,
        0.0282, 0.0100, 0.0108], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,773][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1251, 0.0352, 0.1675, 0.0045, 0.1701, 0.0659, 0.0396, 0.1272, 0.0277,
        0.1893, 0.0146, 0.0334], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,774][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([1.1588e-05, 8.8904e-01, 1.6955e-02, 6.9275e-02, 2.0754e-02, 1.3091e-04,
        3.4420e-04, 1.2673e-05, 3.0414e-03, 1.3017e-04, 2.1284e-04, 9.3427e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,776][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([3.4077e-05, 8.6586e-01, 2.0305e-02, 7.3183e-02, 3.1244e-02, 4.6423e-04,
        1.0743e-03, 7.6090e-05, 5.6463e-03, 9.5535e-04, 6.9154e-04, 4.6954e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,779][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([7.5761e-08, 9.7354e-01, 8.5990e-04, 2.3584e-02, 1.5475e-03, 5.8891e-06,
        1.8028e-05, 1.1293e-07, 4.0235e-04, 8.1843e-06, 2.4573e-05, 6.1621e-06],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,783][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.3493, 0.0349, 0.0567, 0.0232, 0.1156, 0.0776, 0.0373, 0.1221, 0.0577,
        0.0936, 0.0195, 0.0124], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,786][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([4.1960e-05, 8.5654e-01, 4.1175e-04, 1.3155e-01, 1.6752e-04, 6.5477e-04,
        8.3880e-04, 4.0279e-05, 8.4592e-03, 1.4502e-04, 8.9566e-04, 2.5809e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,787][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([1.3862e-04, 8.6065e-01, 3.3081e-03, 1.0903e-01, 3.9576e-03, 1.5148e-03,
        1.5218e-03, 8.9629e-05, 1.6919e-02, 9.6205e-04, 1.5518e-03, 3.5447e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,788][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([2.4175e-04, 8.3363e-01, 3.9778e-02, 3.4119e-02, 7.9367e-02, 8.6184e-04,
        2.5487e-03, 2.3607e-04, 6.1965e-03, 1.7912e-03, 7.3771e-04, 4.9217e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,789][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.7519, 0.0079, 0.0109, 0.0041, 0.0123, 0.0663, 0.0101, 0.0985, 0.0149,
        0.0085, 0.0080, 0.0065], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,790][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([8.5874e-01, 1.9142e-03, 6.0280e-04, 6.7062e-04, 1.4102e-03, 6.8785e-02,
        2.1855e-03, 5.2751e-02, 7.7559e-03, 2.9654e-03, 1.5882e-03, 6.3362e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,792][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2615, 0.1217, 0.0173, 0.1012, 0.0736, 0.1266, 0.0741, 0.0587, 0.0674,
        0.0301, 0.0282, 0.0396], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:32,795][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.2879, 0.0258, 0.0552, 0.0079, 0.0363, 0.0901, 0.0378, 0.1335, 0.0515,
        0.1022, 0.0502, 0.0728, 0.0487], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,799][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0203, 0.0591, 0.1019, 0.0187, 0.0418, 0.0536, 0.0880, 0.0303, 0.0811,
        0.1929, 0.0549, 0.2129, 0.0446], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,801][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([1.0249e-05, 8.1881e-01, 2.1742e-02, 1.2020e-01, 3.0794e-02, 1.7676e-04,
        9.7871e-04, 2.0301e-05, 5.7498e-03, 3.6287e-04, 5.7611e-04, 5.5587e-04,
        2.0305e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,804][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([1.9431e-05, 7.1320e-01, 4.0283e-02, 1.6482e-01, 5.6935e-02, 5.4149e-04,
        3.2242e-03, 8.9561e-05, 1.4668e-02, 2.3708e-03, 1.8336e-03, 1.8615e-03,
        1.5144e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,806][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([3.7202e-08, 9.3185e-01, 9.0464e-04, 6.2840e-02, 1.9538e-03, 8.1552e-06,
        1.1077e-04, 1.7018e-07, 2.0682e-03, 3.5002e-05, 1.6425e-04, 6.6230e-05,
        7.2393e-07], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,806][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.1974, 0.0279, 0.0794, 0.0312, 0.0718, 0.0874, 0.0441, 0.0886, 0.1030,
        0.1473, 0.0319, 0.0706, 0.0192], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,807][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([1.2285e-05, 7.3031e-01, 7.4819e-04, 2.4421e-01, 4.3780e-04, 4.2623e-04,
        1.7709e-03, 2.6632e-05, 1.9315e-02, 3.2950e-04, 1.3474e-03, 1.0392e-03,
        2.7174e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,808][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([1.6002e-04, 7.1851e-01, 8.3017e-03, 2.0184e-01, 1.7071e-02, 1.9992e-03,
        4.1224e-03, 1.7348e-04, 3.5222e-02, 3.5488e-03, 6.5913e-03, 2.2473e-03,
        2.1049e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,810][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([1.8343e-04, 7.4888e-01, 4.7605e-02, 7.7970e-02, 7.9513e-02, 1.6041e-03,
        6.9841e-03, 2.9613e-04, 2.0751e-02, 7.0247e-03, 2.4621e-03, 6.2997e-03,
        4.2536e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,812][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.5495, 0.0231, 0.0311, 0.0155, 0.0341, 0.0965, 0.0256, 0.1219, 0.0257,
        0.0239, 0.0200, 0.0177, 0.0153], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,817][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.7401, 0.0045, 0.0022, 0.0023, 0.0058, 0.0848, 0.0064, 0.0870, 0.0262,
        0.0061, 0.0095, 0.0035, 0.0215], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,821][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.2489, 0.0975, 0.0260, 0.0808, 0.0755, 0.1074, 0.0518, 0.0773, 0.0700,
        0.0398, 0.0559, 0.0322, 0.0368], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:32,823][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.4726, 0.0112, 0.0204, 0.0031, 0.0200, 0.0793, 0.0150, 0.1969, 0.0244,
        0.0713, 0.0192, 0.0275, 0.0308, 0.0084], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,824][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0196, 0.0517, 0.1096, 0.0043, 0.0837, 0.0391, 0.0547, 0.0385, 0.0252,
        0.3397, 0.0205, 0.0907, 0.1070, 0.0159], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,825][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([3.5120e-05, 8.8068e-01, 2.3798e-02, 5.9477e-02, 3.0173e-02, 2.2643e-04,
        6.1585e-04, 3.0618e-05, 3.8899e-03, 2.2957e-04, 2.8244e-04, 3.0877e-04,
        1.9922e-05, 2.3297e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,826][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([9.8519e-05, 8.3938e-01, 2.6661e-02, 8.1340e-02, 3.8214e-02, 7.5404e-04,
        1.5591e-03, 1.5282e-04, 6.7974e-03, 1.5330e-03, 9.7218e-04, 8.3724e-04,
        1.3778e-04, 1.5601e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,827][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([5.3436e-07, 9.5341e-01, 1.1483e-03, 4.2524e-02, 1.9318e-03, 2.1384e-05,
        5.3975e-05, 4.6453e-07, 7.6426e-04, 2.0412e-05, 5.8429e-05, 2.9715e-05,
        4.7806e-07, 3.8562e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,830][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1866, 0.0352, 0.0622, 0.0443, 0.1047, 0.0702, 0.0487, 0.0962, 0.0670,
        0.1017, 0.0262, 0.0397, 0.0482, 0.0691], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,833][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([2.2985e-04, 7.7311e-01, 7.9624e-04, 2.0264e-01, 4.2614e-04, 1.6517e-03,
        1.9355e-03, 1.3834e-04, 1.1206e-02, 4.2287e-04, 1.3907e-03, 9.8566e-04,
        7.6790e-05, 4.9908e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,835][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([6.7792e-04, 7.9305e-01, 4.6092e-03, 1.5657e-01, 6.0585e-03, 3.4308e-03,
        2.1203e-03, 2.2147e-04, 2.6773e-02, 1.3625e-03, 2.7171e-03, 9.4173e-04,
        1.0563e-04, 1.3614e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,837][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([2.4064e-04, 8.6307e-01, 2.7792e-02, 3.9745e-02, 5.1891e-02, 8.4776e-04,
        3.3622e-03, 2.3876e-04, 6.5571e-03, 2.5418e-03, 8.0062e-04, 1.7437e-03,
        3.3726e-04, 8.3605e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,841][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.7165, 0.0083, 0.0102, 0.0050, 0.0134, 0.0627, 0.0094, 0.1009, 0.0184,
        0.0111, 0.0105, 0.0090, 0.0147, 0.0099], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,842][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([8.6562e-01, 1.5438e-03, 5.0208e-04, 5.3065e-04, 1.1118e-03, 5.5825e-02,
        2.2624e-03, 5.0822e-02, 7.9679e-03, 2.7066e-03, 2.0829e-03, 7.1761e-04,
        2.8774e-03, 5.4323e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,843][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.2638, 0.1151, 0.0176, 0.1099, 0.0451, 0.1116, 0.0439, 0.0703, 0.0533,
        0.0235, 0.0306, 0.0162, 0.0174, 0.0817], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:32,844][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.5865, 0.0054, 0.0252, 0.0021, 0.0207, 0.0753, 0.0082, 0.1435, 0.0101,
        0.0395, 0.0096, 0.0105, 0.0262, 0.0077, 0.0294], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,846][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0586, 0.0667, 0.0700, 0.0220, 0.0809, 0.0623, 0.0602, 0.0708, 0.0358,
        0.1685, 0.0304, 0.0678, 0.0929, 0.0506, 0.0625], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,848][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([2.0156e-04, 8.5916e-01, 2.7022e-02, 7.5251e-02, 2.5581e-02, 7.5640e-04,
        1.2320e-03, 1.1890e-04, 6.8760e-03, 5.5940e-04, 7.2383e-04, 4.8504e-04,
        8.1569e-05, 8.1009e-04, 1.1426e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,851][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([2.8342e-04, 7.6977e-01, 4.4398e-02, 9.2701e-02, 5.9860e-02, 1.7724e-03,
        3.6803e-03, 4.1183e-04, 1.2553e-02, 3.0046e-03, 1.9470e-03, 1.8771e-03,
        3.4360e-04, 4.7167e-03, 2.6761e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,853][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([4.9193e-06, 9.1947e-01, 3.4381e-03, 6.9212e-02, 4.6230e-03, 9.3560e-05,
        1.7301e-04, 4.3977e-06, 2.2002e-03, 9.4093e-05, 2.0340e-04, 9.2712e-05,
        5.8190e-06, 2.7382e-04, 1.1418e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,857][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.3919, 0.0342, 0.0315, 0.0173, 0.1094, 0.0789, 0.0260, 0.1050, 0.0179,
        0.0652, 0.0087, 0.0199, 0.0427, 0.0312, 0.0201], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,859][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([2.0054e-04, 8.0426e-01, 1.1476e-03, 1.4393e-01, 7.8545e-04, 1.4128e-03,
        2.5099e-03, 1.5465e-04, 2.8441e-02, 8.5376e-04, 2.2447e-03, 1.5527e-03,
        1.5604e-04, 1.1940e-02, 4.0344e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,860][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.0041, 0.7603, 0.0187, 0.1301, 0.0145, 0.0071, 0.0056, 0.0014, 0.0377,
        0.0038, 0.0052, 0.0018, 0.0009, 0.0050, 0.0038], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,861][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.0020, 0.7880, 0.0376, 0.0510, 0.0872, 0.0038, 0.0051, 0.0013, 0.0084,
        0.0038, 0.0014, 0.0025, 0.0009, 0.0028, 0.0041], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,862][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.6898, 0.0098, 0.0168, 0.0061, 0.0193, 0.0699, 0.0104, 0.0888, 0.0111,
        0.0142, 0.0083, 0.0077, 0.0193, 0.0087, 0.0198], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,864][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([8.4853e-01, 1.4576e-03, 1.5341e-03, 8.0684e-04, 1.3664e-03, 6.2675e-02,
        2.4671e-03, 6.3195e-02, 5.5542e-03, 2.1721e-03, 1.5299e-03, 7.8709e-04,
        1.7285e-03, 3.4260e-03, 2.7696e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,867][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.3266, 0.0567, 0.0211, 0.0555, 0.0488, 0.1360, 0.0571, 0.0673, 0.0549,
        0.0226, 0.0384, 0.0292, 0.0181, 0.0425, 0.0253], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:32,871][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0754, 0.0570, 0.0686, 0.0273, 0.0495, 0.0525, 0.0524, 0.0747, 0.0708,
        0.1040, 0.0558, 0.0705, 0.0555, 0.0498, 0.0721, 0.0642],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,875][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0027, 0.1676, 0.0600, 0.0699, 0.0553, 0.0131, 0.0919, 0.0104, 0.0849,
        0.0874, 0.0660, 0.1216, 0.0496, 0.0611, 0.0490, 0.0095],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,877][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([1.7754e-04, 6.2797e-01, 6.3494e-02, 1.5661e-01, 8.9660e-02, 1.6528e-03,
        7.8233e-03, 4.1834e-04, 2.3944e-02, 3.9763e-03, 5.3884e-03, 5.0366e-03,
        9.0373e-04, 5.4925e-03, 6.5273e-03, 9.3200e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,878][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0005, 0.5179, 0.0635, 0.1796, 0.1068, 0.0047, 0.0143, 0.0014, 0.0420,
        0.0131, 0.0112, 0.0126, 0.0028, 0.0154, 0.0116, 0.0026],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,879][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([1.0742e-05, 7.8474e-01, 1.0287e-02, 1.6230e-01, 1.9148e-02, 3.6145e-04,
        1.8550e-03, 3.2511e-05, 1.2888e-02, 1.0488e-03, 2.3658e-03, 1.3679e-03,
        1.1252e-04, 2.3536e-03, 1.0115e-03, 1.1319e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,880][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0246, 0.0842, 0.0541, 0.0913, 0.0876, 0.0309, 0.0672, 0.0296, 0.1004,
        0.0630, 0.0668, 0.0788, 0.0511, 0.0887, 0.0471, 0.0345],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,881][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([1.2101e-04, 6.6714e-01, 6.0074e-03, 2.1961e-01, 8.1495e-03, 2.1008e-03,
        8.9770e-03, 3.5431e-04, 4.0918e-02, 3.8361e-03, 1.0351e-02, 7.5593e-03,
        1.0123e-03, 2.1200e-02, 1.8586e-03, 8.0308e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,884][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0010, 0.5512, 0.0262, 0.1993, 0.0436, 0.0080, 0.0158, 0.0017, 0.0753,
        0.0150, 0.0203, 0.0111, 0.0025, 0.0160, 0.0089, 0.0042],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,889][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0006, 0.6042, 0.0557, 0.1056, 0.1064, 0.0034, 0.0164, 0.0013, 0.0373,
        0.0106, 0.0105, 0.0138, 0.0037, 0.0136, 0.0146, 0.0024],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,893][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1786, 0.0510, 0.0518, 0.0326, 0.0545, 0.0734, 0.0414, 0.0837, 0.0531,
        0.0401, 0.0460, 0.0392, 0.0579, 0.0441, 0.0553, 0.0973],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,895][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.2753, 0.0310, 0.0161, 0.0183, 0.0246, 0.1074, 0.0307, 0.0906, 0.0691,
        0.0330, 0.0357, 0.0214, 0.0426, 0.0502, 0.0306, 0.1235],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,896][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0739, 0.1121, 0.0314, 0.1057, 0.0523, 0.0763, 0.0739, 0.0457, 0.0703,
        0.0349, 0.0540, 0.0446, 0.0438, 0.0826, 0.0314, 0.0671],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:32,897][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1647, 0.0223, 0.0344, 0.0140, 0.0384, 0.0713, 0.0251, 0.1257, 0.0471,
        0.0842, 0.0348, 0.0439, 0.0383, 0.0397, 0.0455, 0.1047, 0.0659],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,898][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0086, 0.0725, 0.0967, 0.0289, 0.0818, 0.0262, 0.0510, 0.0313, 0.0487,
        0.1649, 0.0312, 0.0940, 0.0702, 0.0504, 0.0889, 0.0282, 0.0265],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,900][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([9.1977e-05, 7.9779e-01, 3.5855e-02, 1.0232e-01, 4.4287e-02, 6.7346e-04,
        1.6187e-03, 1.2464e-04, 9.3724e-03, 9.5603e-04, 1.2368e-03, 9.6673e-04,
        1.5802e-04, 1.5991e-03, 1.5712e-03, 3.5068e-04, 1.0207e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,902][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([2.3140e-04, 7.2753e-01, 4.1142e-02, 1.1839e-01, 6.2541e-02, 2.0403e-03,
        4.3775e-03, 4.6205e-04, 1.8431e-02, 4.4987e-03, 3.5604e-03, 3.1426e-03,
        6.9526e-04, 5.8525e-03, 3.5991e-03, 1.0454e-03, 2.4607e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,905][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([2.6076e-06, 8.9358e-01, 5.0989e-03, 8.7365e-02, 8.5905e-03, 1.0171e-04,
        2.5769e-04, 4.7888e-06, 3.3497e-03, 1.9560e-04, 4.3862e-04, 2.1292e-04,
        1.3141e-05, 4.6263e-04, 2.0184e-04, 2.4711e-05, 9.9048e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,909][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0463, 0.0670, 0.0478, 0.0711, 0.0632, 0.0403, 0.0461, 0.0463, 0.0739,
        0.0852, 0.0408, 0.0513, 0.0375, 0.0939, 0.0538, 0.0790, 0.0564],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,911][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.1378e-04, 7.7285e-01, 2.3133e-03, 1.7931e-01, 1.6929e-03, 1.4324e-03,
        2.1367e-03, 1.6809e-04, 2.1437e-02, 1.0478e-03, 3.5708e-03, 1.6381e-03,
        2.2648e-04, 9.7150e-03, 5.6233e-04, 5.2263e-04, 1.2622e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,913][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([5.2846e-04, 7.2126e-01, 1.4625e-02, 1.6496e-01, 1.6637e-02, 5.0010e-03,
        5.1550e-03, 4.5653e-04, 3.9013e-02, 4.5471e-03, 8.5645e-03, 2.9261e-03,
        8.3466e-04, 5.8919e-03, 3.3156e-03, 2.3178e-03, 3.9680e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,914][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([5.1435e-04, 7.2785e-01, 4.4362e-02, 8.4462e-02, 7.7001e-02, 2.3725e-03,
        5.1558e-03, 8.8806e-04, 1.9975e-02, 6.2245e-03, 3.3711e-03, 5.0371e-03,
        1.2943e-03, 7.5155e-03, 7.6316e-03, 1.9908e-03, 4.3540e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,915][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.3335, 0.0247, 0.0305, 0.0162, 0.0348, 0.0750, 0.0229, 0.0970, 0.0333,
        0.0272, 0.0242, 0.0216, 0.0341, 0.0244, 0.0346, 0.1171, 0.0490],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,916][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.4688, 0.0139, 0.0064, 0.0059, 0.0106, 0.1073, 0.0135, 0.0780, 0.0314,
        0.0157, 0.0125, 0.0064, 0.0161, 0.0230, 0.0111, 0.1208, 0.0585],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,918][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1255, 0.0791, 0.0273, 0.0739, 0.0602, 0.0846, 0.0672, 0.0451, 0.0535,
        0.0269, 0.0356, 0.0279, 0.0282, 0.0615, 0.0298, 0.0660, 0.1076],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:32,922][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([0.2799, 0.0300, 0.0444, 0.0057, 0.0362, 0.0612, 0.0141, 0.1556, 0.0251,
        0.0552, 0.0214, 0.0272, 0.0346, 0.0153, 0.0378, 0.0761, 0.0357, 0.0445],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,925][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([0.1885, 0.0379, 0.0458, 0.0043, 0.0705, 0.0407, 0.0170, 0.0892, 0.0138,
        0.0944, 0.0177, 0.0165, 0.1532, 0.0141, 0.0399, 0.0792, 0.0277, 0.0497],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,927][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([3.2466e-05, 9.1517e-01, 1.0411e-02, 5.1154e-02, 1.8476e-02, 1.7320e-04,
        3.5989e-04, 1.9560e-05, 2.4894e-03, 1.8154e-04, 2.3568e-04, 1.7295e-04,
        1.4472e-05, 2.8208e-04, 2.7383e-04, 8.5738e-05, 3.3750e-04, 1.2636e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,930][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([4.5584e-05, 7.2026e-01, 3.9115e-02, 1.4011e-01, 7.4267e-02, 6.0581e-04,
        2.4957e-03, 1.0094e-04, 1.0598e-02, 1.8162e-03, 1.1812e-03, 9.9130e-04,
        7.8705e-05, 3.4277e-03, 2.0191e-03, 2.9446e-04, 1.3773e-03, 1.2183e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,931][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([1.8410e-07, 9.5344e-01, 1.2804e-03, 4.1234e-02, 3.0213e-03, 9.3760e-06,
        3.5364e-05, 2.6751e-07, 7.6491e-04, 1.4876e-05, 4.8656e-05, 1.9356e-05,
        5.1414e-07, 6.5397e-05, 2.5428e-05, 1.7498e-06, 1.4400e-05, 1.9739e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,932][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([0.4383, 0.0527, 0.0188, 0.0052, 0.0881, 0.0357, 0.0112, 0.0688, 0.0085,
        0.0400, 0.0034, 0.0059, 0.0505, 0.0097, 0.0153, 0.1126, 0.0296, 0.0059],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,933][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([6.3285e-06, 8.7733e-01, 4.8781e-04, 1.0826e-01, 2.5592e-04, 1.6430e-04,
        1.3613e-03, 9.8756e-06, 7.4782e-03, 1.3719e-04, 5.8650e-04, 6.5426e-04,
        2.0129e-05, 2.6580e-03, 8.9759e-05, 4.8342e-05, 4.1134e-04, 3.8163e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,934][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([4.3451e-04, 8.5880e-01, 1.0627e-02, 8.7573e-02, 1.2468e-02, 2.3256e-03,
        1.9256e-03, 1.9886e-04, 1.2317e-02, 1.9134e-03, 2.3464e-03, 8.0050e-04,
        2.0940e-04, 2.6741e-03, 1.3743e-03, 1.1670e-03, 2.2811e-03, 5.6001e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,936][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([9.0479e-04, 8.5948e-01, 2.7008e-02, 2.3896e-02, 6.6227e-02, 1.1908e-03,
        2.0988e-03, 4.0893e-04, 3.6648e-03, 1.8738e-03, 1.0814e-03, 1.1529e-03,
        6.1173e-04, 1.3992e-03, 3.4101e-03, 1.3530e-03, 2.6078e-03, 1.6256e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,938][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([0.4300, 0.0170, 0.0263, 0.0106, 0.0342, 0.0695, 0.0201, 0.0794, 0.0223,
        0.0182, 0.0156, 0.0151, 0.0268, 0.0170, 0.0249, 0.1099, 0.0566, 0.0065],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,943][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([0.5227, 0.0090, 0.0054, 0.0073, 0.0085, 0.1095, 0.0123, 0.0781, 0.0346,
        0.0078, 0.0064, 0.0052, 0.0061, 0.0256, 0.0100, 0.0972, 0.0515, 0.0027],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,947][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([0.1602, 0.0796, 0.0259, 0.0871, 0.0672, 0.0914, 0.0439, 0.0590, 0.0667,
        0.0304, 0.0250, 0.0220, 0.0129, 0.0495, 0.0226, 0.0638, 0.0766, 0.0162],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:32,949][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3911, 0.0078, 0.0198, 0.0021, 0.0147, 0.0589, 0.0110, 0.1846, 0.0145,
        0.0413, 0.0074, 0.0167, 0.0241, 0.0114, 0.0257, 0.0866, 0.0413, 0.0343,
        0.0067], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,950][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0317, 0.0168, 0.1071, 0.0031, 0.0589, 0.0319, 0.0398, 0.0511, 0.0181,
        0.1853, 0.0078, 0.0637, 0.0578, 0.0142, 0.0965, 0.0323, 0.0209, 0.1565,
        0.0064], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,951][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.8970e-04, 8.3700e-01, 3.9438e-02, 6.9516e-02, 4.2760e-02, 7.7280e-04,
        8.9371e-04, 9.3221e-05, 4.2598e-03, 2.6898e-04, 4.0099e-04, 3.5823e-04,
        3.1153e-05, 3.7378e-04, 7.4065e-04, 3.9866e-04, 9.7236e-04, 3.6983e-04,
        1.1578e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,953][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.2509e-04, 8.7024e-01, 2.4865e-02, 5.5450e-02, 2.8777e-02, 8.3805e-04,
        1.5597e-03, 1.6724e-04, 5.0186e-03, 1.0831e-03, 7.8846e-04, 7.4201e-04,
        1.2025e-04, 2.0941e-03, 1.0389e-03, 3.9962e-04, 1.1268e-03, 1.0936e-03,
        4.4742e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,955][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([8.6473e-07, 9.7103e-01, 1.4723e-03, 2.4928e-02, 1.6068e-03, 2.4313e-05,
        4.0740e-05, 6.2791e-07, 5.3023e-04, 1.7699e-05, 4.0332e-05, 1.9228e-05,
        6.0616e-07, 3.9167e-05, 1.9830e-05, 4.7581e-06, 2.1086e-05, 1.5096e-05,
        1.8457e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,958][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1212, 0.0268, 0.0424, 0.0248, 0.0466, 0.0505, 0.0465, 0.0699, 0.0408,
        0.0764, 0.0163, 0.0396, 0.0328, 0.0520, 0.0528, 0.1180, 0.0632, 0.0578,
        0.0216], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,961][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.1053e-03, 8.1981e-01, 1.7662e-03, 1.2703e-01, 5.2875e-04, 4.0555e-03,
        2.1437e-03, 4.0098e-04, 9.7993e-03, 6.9783e-04, 1.4732e-03, 1.1489e-03,
        1.2342e-04, 9.0792e-03, 4.8266e-04, 1.6638e-03, 2.9873e-03, 3.2997e-04,
        1.5367e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,963][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([8.7421e-04, 8.1105e-01, 5.9237e-03, 1.1877e-01, 4.5595e-03, 3.6848e-03,
        2.1003e-03, 2.6690e-04, 2.7499e-02, 1.6292e-03, 2.3385e-03, 6.7402e-04,
        1.9789e-04, 1.6624e-03, 9.3838e-04, 1.3579e-03, 2.6076e-03, 3.9946e-04,
        1.3457e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,965][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([3.3830e-04, 8.3214e-01, 3.8529e-02, 3.7842e-02, 6.0201e-02, 9.8441e-04,
        3.1541e-03, 3.2822e-04, 7.0524e-03, 2.3803e-03, 6.3777e-04, 1.5918e-03,
        3.0547e-04, 2.2446e-03, 3.3523e-03, 8.6517e-04, 2.5054e-03, 3.3308e-03,
        2.2152e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,967][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.5371, 0.0094, 0.0123, 0.0052, 0.0147, 0.0638, 0.0117, 0.0895, 0.0183,
        0.0112, 0.0111, 0.0098, 0.0151, 0.0105, 0.0157, 0.1106, 0.0375, 0.0048,
        0.0118], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,968][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([7.8006e-01, 1.5712e-03, 4.5255e-04, 4.2341e-04, 1.0230e-03, 5.3142e-02,
        1.7746e-03, 4.7960e-02, 6.8681e-03, 3.0577e-03, 1.9216e-03, 5.5956e-04,
        1.9148e-03, 3.9451e-03, 1.1212e-03, 7.1912e-02, 1.8659e-02, 2.3236e-04,
        3.4021e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,969][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.2202, 0.0702, 0.0104, 0.0701, 0.0290, 0.0962, 0.0425, 0.0480, 0.0445,
        0.0160, 0.0330, 0.0131, 0.0125, 0.0506, 0.0118, 0.0783, 0.0951, 0.0068,
        0.0515], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:32,972][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:32,975][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[10583],
        [ 1746],
        [  674],
        [  686],
        [ 1554],
        [  455],
        [  156],
        [  606],
        [  315],
        [  153],
        [   51],
        [    7],
        [   71],
        [   49],
        [   64],
        [   19],
        [   13],
        [    5],
        [    6]], device='cuda:0')
[2024-07-24 10:27:32,977][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[12635],
        [ 1451],
        [  707],
        [  500],
        [ 1440],
        [  550],
        [  127],
        [  851],
        [  281],
        [  133],
        [   44],
        [    7],
        [   46],
        [   41],
        [   62],
        [   25],
        [   15],
        [    4],
        [    6]], device='cuda:0')
[2024-07-24 10:27:32,980][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[27851],
        [13239],
        [14266],
        [15678],
        [11739],
        [10949],
        [10987],
        [ 9671],
        [10343],
        [10710],
        [11009],
        [11216],
        [10654],
        [10829],
        [11597],
        [12257],
        [12729],
        [11720],
        [11563]], device='cuda:0')
[2024-07-24 10:27:32,983][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 3718],
        [14312],
        [13753],
        [24306],
        [12163],
        [31727],
        [39378],
        [31230],
        [42449],
        [35176],
        [32876],
        [38290],
        [32805],
        [34174],
        [34975],
        [33225],
        [36065],
        [32711],
        [29121]], device='cuda:0')
[2024-07-24 10:27:32,986][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 1364],
        [25875],
        [26798],
        [26775],
        [26811],
        [26800],
        [26813],
        [26754],
        [26800],
        [26779],
        [26802],
        [26788],
        [26720],
        [26798],
        [26700],
        [26160],
        [26644],
        [26801],
        [26754]], device='cuda:0')
[2024-07-24 10:27:32,988][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[10589],
        [10275],
        [12026],
        [ 9509],
        [11920],
        [ 9096],
        [ 5927],
        [ 9557],
        [ 7319],
        [ 8791],
        [ 7342],
        [ 8555],
        [ 9620],
        [ 8923],
        [10506],
        [ 7999],
        [ 7767],
        [11429],
        [ 9937]], device='cuda:0')
[2024-07-24 10:27:32,990][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[22979],
        [22300],
        [17715],
        [18204],
        [17976],
        [17487],
        [17900],
        [18150],
        [18237],
        [18767],
        [18070],
        [18033],
        [18580],
        [18796],
        [18372],
        [18171],
        [18042],
        [18730],
        [18362]], device='cuda:0')
[2024-07-24 10:27:32,991][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[26672],
        [26397],
        [25953],
        [20230],
        [25434],
        [11858],
        [23283],
        [12475],
        [13997],
        [13387],
        [13336],
        [20740],
        [17332],
        [16360],
        [17918],
        [ 6263],
        [ 7943],
        [21361],
        [ 6291]], device='cuda:0')
[2024-07-24 10:27:32,993][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[20849],
        [20165],
        [13792],
        [17300],
        [14779],
        [16210],
        [14913],
        [17228],
        [16488],
        [17860],
        [15444],
        [14900],
        [16502],
        [15516],
        [17029],
        [16383],
        [14404],
        [16258],
        [15230]], device='cuda:0')
[2024-07-24 10:27:32,996][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[13246],
        [ 8727],
        [ 8272],
        [ 8935],
        [10119],
        [ 9959],
        [ 9860],
        [ 9824],
        [ 9750],
        [ 9856],
        [ 9615],
        [ 9657],
        [ 9886],
        [10037],
        [10174],
        [10231],
        [10186],
        [10151],
        [10201]], device='cuda:0')
[2024-07-24 10:27:32,998][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[28500],
        [10799],
        [ 8794],
        [ 7724],
        [ 9793],
        [ 5388],
        [ 6171],
        [ 5992],
        [ 6730],
        [ 7006],
        [ 7656],
        [ 6245],
        [ 7182],
        [ 7470],
        [ 9495],
        [ 7228],
        [ 7085],
        [ 9173],
        [ 7286]], device='cuda:0')
[2024-07-24 10:27:33,001][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[11952],
        [12906],
        [12900],
        [12968],
        [15086],
        [15919],
        [11691],
        [12513],
        [ 8051],
        [10247],
        [ 9921],
        [ 7661],
        [10289],
        [ 7149],
        [ 9224],
        [ 8284],
        [ 7524],
        [ 7987],
        [ 7123]], device='cuda:0')
[2024-07-24 10:27:33,004][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 5362],
        [ 5361],
        [ 5364],
        [ 5368],
        [ 5475],
        [19318],
        [ 9379],
        [25100],
        [ 9920],
        [14684],
        [ 9695],
        [ 9450],
        [14140],
        [ 9135],
        [ 9490],
        [27014],
        [21871],
        [21419],
        [11106]], device='cuda:0')
[2024-07-24 10:27:33,006][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 7316],
        [13488],
        [ 9785],
        [14998],
        [11240],
        [12947],
        [11080],
        [11633],
        [10484],
        [11025],
        [10169],
        [10544],
        [10634],
        [12429],
        [10906],
        [12326],
        [11957],
        [11893],
        [12476]], device='cuda:0')
[2024-07-24 10:27:33,009][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 1334],
        [ 7439],
        [ 8280],
        [ 8409],
        [22671],
        [11461],
        [ 9659],
        [ 5952],
        [ 6218],
        [ 6708],
        [11225],
        [ 8114],
        [11541],
        [12745],
        [10007],
        [ 7500],
        [ 7959],
        [13646],
        [14836]], device='cuda:0')
[2024-07-24 10:27:33,011][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[19165],
        [19005],
        [19221],
        [19283],
        [19318],
        [23048],
        [20258],
        [20790],
        [18153],
        [18796],
        [18296],
        [18868],
        [15601],
        [16898],
        [17027],
        [14830],
        [13386],
        [14441],
        [14320]], device='cuda:0')
[2024-07-24 10:27:33,012][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[21064],
        [17013],
        [23016],
        [23651],
        [23978],
        [20573],
        [25425],
        [21442],
        [25768],
        [23256],
        [20919],
        [23323],
        [22712],
        [21316],
        [21674],
        [20961],
        [21761],
        [23393],
        [24175]], device='cuda:0')
[2024-07-24 10:27:33,014][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[21898],
        [ 5565],
        [ 5812],
        [ 5945],
        [ 5805],
        [ 6441],
        [ 5774],
        [ 6560],
        [ 5735],
        [ 5589],
        [ 5661],
        [ 5566],
        [ 5719],
        [ 5629],
        [ 5673],
        [ 6504],
        [ 5822],
        [ 5512],
        [ 5778]], device='cuda:0')
[2024-07-24 10:27:33,016][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[17997],
        [47464],
        [47465],
        [47569],
        [47178],
        [46514],
        [47329],
        [46336],
        [47433],
        [47334],
        [47464],
        [47469],
        [47183],
        [47429],
        [47289],
        [46789],
        [47248],
        [47148],
        [47500]], device='cuda:0')
[2024-07-24 10:27:33,019][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 3630],
        [18974],
        [19031],
        [18851],
        [18517],
        [17310],
        [18531],
        [15733],
        [18712],
        [18432],
        [18686],
        [18685],
        [18195],
        [18445],
        [18069],
        [16110],
        [17725],
        [18440],
        [18669]], device='cuda:0')
[2024-07-24 10:27:33,022][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[11881],
        [12280],
        [12118],
        [13005],
        [12154],
        [12180],
        [11505],
        [11564],
        [10811],
        [11104],
        [10002],
        [10512],
        [10503],
        [11475],
        [11419],
        [12032],
        [11567],
        [11618],
        [10217]], device='cuda:0')
[2024-07-24 10:27:33,025][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[48765],
        [ 3687],
        [ 3551],
        [ 4359],
        [ 4407],
        [ 5455],
        [ 4963],
        [ 6119],
        [ 4757],
        [ 6199],
        [ 5440],
        [ 4941],
        [ 6675],
        [ 6011],
        [ 5562],
        [ 7552],
        [ 5997],
        [ 4669],
        [ 5351]], device='cuda:0')
[2024-07-24 10:27:33,027][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[7496],
        [7574],
        [7508],
        [7021],
        [5867],
        [4718],
        [5959],
        [4282],
        [5470],
        [5551],
        [5447],
        [6164],
        [4783],
        [5420],
        [5356],
        [3835],
        [4951],
        [6312],
        [5743]], device='cuda:0')
[2024-07-24 10:27:33,030][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[19456],
        [12053],
        [12678],
        [12724],
        [13253],
        [15309],
        [14109],
        [18229],
        [14118],
        [13681],
        [13683],
        [13417],
        [14997],
        [13324],
        [14133],
        [17593],
        [15532],
        [13195],
        [13688]], device='cuda:0')
[2024-07-24 10:27:33,032][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[32922],
        [32915],
        [32876],
        [32836],
        [32780],
        [25509],
        [31219],
        [21201],
        [30134],
        [28794],
        [29740],
        [30210],
        [26417],
        [29723],
        [29632],
        [18230],
        [22856],
        [24853],
        [27207]], device='cuda:0')
[2024-07-24 10:27:33,033][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[16914],
        [16925],
        [17013],
        [17042],
        [17131],
        [31737],
        [22519],
        [34727],
        [24688],
        [30437],
        [24581],
        [24086],
        [29974],
        [24074],
        [24365],
        [34253],
        [33668],
        [33916],
        [26730]], device='cuda:0')
[2024-07-24 10:27:33,035][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[34842],
        [34120],
        [34672],
        [34820],
        [37071],
        [31194],
        [31039],
        [28390],
        [28066],
        [28591],
        [28020],
        [27711],
        [25752],
        [27020],
        [27086],
        [23836],
        [24566],
        [24916],
        [26010]], device='cuda:0')
[2024-07-24 10:27:33,037][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[27553],
        [29098],
        [28994],
        [28736],
        [29149],
        [28576],
        [28513],
        [29783],
        [29275],
        [28561],
        [29874],
        [29410],
        [30438],
        [29804],
        [30182],
        [31272],
        [30620],
        [30143],
        [30426]], device='cuda:0')
[2024-07-24 10:27:33,040][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[10862],
        [29826],
        [24225],
        [24411],
        [18220],
        [27745],
        [23407],
        [30586],
        [27275],
        [27074],
        [25766],
        [25633],
        [25253],
        [24985],
        [25533],
        [31113],
        [28344],
        [22839],
        [22446]], device='cuda:0')
[2024-07-24 10:27:33,043][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805]], device='cuda:0')
[2024-07-24 10:27:33,105][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:33,106][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,107][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,107][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,108][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,109][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,110][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,110][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,111][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,112][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,112][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,113][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,113][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,114][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9971, 0.0029], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,115][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0123, 0.9877], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,116][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4774, 0.5226], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,119][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4703, 0.5297], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,123][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.7288, 0.2712], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,126][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3521, 0.6479], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,128][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3378, 0.6622], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,129][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1959, 0.8041], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,129][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2211, 0.7789], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,130][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0219, 0.9781], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,131][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9981, 0.0019], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,133][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1268, 0.8732], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,135][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.9665, 0.0296, 0.0039], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,139][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0435, 0.5968, 0.3597], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,143][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.2702, 0.3540, 0.3758], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,146][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.6910, 0.2221, 0.0869], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,147][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.5083, 0.2078, 0.2839], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,147][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.1270, 0.6757, 0.1972], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,148][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.7245, 0.1771, 0.0984], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,149][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.1268, 0.7610, 0.1122], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,151][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.0500, 0.9192, 0.0308], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,153][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0120, 0.6937, 0.2943], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,156][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([9.9899e-01, 8.6928e-04, 1.3894e-04], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,160][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.0729, 0.4411, 0.4860], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,162][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.7250e-01, 1.2356e-02, 1.4661e-02, 4.8328e-04], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,164][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([8.0659e-05, 7.4498e-01, 2.3327e-01, 2.1673e-02], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,165][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2498, 0.2582, 0.2236, 0.2684], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,166][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2531, 0.3429, 0.1828, 0.2212], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,166][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4155, 0.1658, 0.2146, 0.2041], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,167][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1282, 0.4252, 0.1409, 0.3056], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,169][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2452, 0.3032, 0.1613, 0.2903], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,173][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0115, 0.9046, 0.0336, 0.0504], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,176][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0014, 0.9561, 0.0087, 0.0339], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,180][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0033, 0.4540, 0.1826, 0.3601], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,182][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([9.9865e-01, 1.0445e-03, 1.9633e-04, 1.1068e-04], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,183][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0386, 0.2913, 0.3330, 0.3371], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,184][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.9510, 0.0280, 0.0094, 0.0038, 0.0077], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,185][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([0.0022, 0.5207, 0.3893, 0.0461, 0.0416], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,185][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.0828, 0.2655, 0.2148, 0.2655, 0.1714], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,188][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.3986, 0.2281, 0.1014, 0.1709, 0.1009], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,191][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.3364, 0.1268, 0.1749, 0.1661, 0.1958], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,194][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([0.0979, 0.3094, 0.1026, 0.2800, 0.2101], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,198][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.4963, 0.2077, 0.0811, 0.1095, 0.1054], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,201][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.0366, 0.7100, 0.0889, 0.0957, 0.0688], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,201][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.0048, 0.8875, 0.0113, 0.0916, 0.0049], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,202][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.0083, 0.3733, 0.1745, 0.3037, 0.1401], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,203][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([9.9942e-01, 4.5215e-04, 6.1882e-05, 4.3928e-05, 2.5959e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,204][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([0.0330, 0.2266, 0.2551, 0.2599, 0.2253], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,207][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.8423, 0.0343, 0.0479, 0.0023, 0.0628, 0.0105], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,210][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ had] are: tensor([2.2440e-05, 5.9909e-01, 2.2703e-01, 5.6907e-02, 1.1633e-01, 6.2239e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,214][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0373, 0.2369, 0.1448, 0.3113, 0.1855, 0.0841], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,218][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0337, 0.3422, 0.1981, 0.2521, 0.1470, 0.0269], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,219][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2942, 0.1131, 0.1464, 0.1408, 0.1636, 0.1419], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,220][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0377, 0.2430, 0.0798, 0.2776, 0.2263, 0.1355], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,221][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1423, 0.1313, 0.0645, 0.0972, 0.0626, 0.5021], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,221][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0024, 0.6708, 0.0879, 0.1348, 0.0956, 0.0085], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,223][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ had] are: tensor([2.9743e-04, 7.6527e-01, 3.7890e-02, 1.4830e-01, 4.6688e-02, 1.5481e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,225][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ had] are: tensor([3.8422e-04, 4.2449e-01, 1.2395e-01, 3.1143e-01, 1.1855e-01, 2.1196e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,227][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ had] are: tensor([9.9691e-01, 1.8792e-03, 3.9592e-04, 2.2822e-04, 1.9626e-04, 3.9479e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,231][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0156, 0.1819, 0.2121, 0.2153, 0.1905, 0.1846], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,235][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.8763, 0.0286, 0.0329, 0.0032, 0.0407, 0.0159, 0.0025],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,237][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([9.0586e-06, 6.0049e-01, 2.9493e-01, 4.8483e-02, 5.4378e-02, 4.1574e-04,
        1.2989e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,237][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0870, 0.1435, 0.1604, 0.1682, 0.1425, 0.1025, 0.1960],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,238][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1425, 0.2534, 0.1363, 0.1866, 0.1312, 0.0511, 0.0988],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,239][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2603, 0.0966, 0.1257, 0.1211, 0.1427, 0.1232, 0.1304],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,241][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0515, 0.2256, 0.0799, 0.1894, 0.2371, 0.1123, 0.1042],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,244][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1722, 0.0990, 0.0568, 0.0811, 0.0413, 0.2176, 0.3320],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,248][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0036, 0.7943, 0.0368, 0.1073, 0.0394, 0.0086, 0.0100],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,250][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([9.1248e-05, 9.1594e-01, 5.5690e-03, 7.3102e-02, 4.6606e-03, 3.8751e-04,
        2.5440e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,254][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0036, 0.2906, 0.1315, 0.2482, 0.1211, 0.0455, 0.1594],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,255][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.9844e-01, 9.4191e-04, 1.8050e-04, 1.0460e-04, 8.0027e-05, 1.9104e-04,
        5.9305e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,256][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0151, 0.1504, 0.1758, 0.1775, 0.1583, 0.1533, 0.1696],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,257][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.5105, 0.1366, 0.0673, 0.0231, 0.1154, 0.0277, 0.0525, 0.0669],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,258][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([2.7068e-05, 4.7212e-01, 2.2251e-01, 1.1888e-01, 1.6368e-01, 1.1201e-03,
        2.1493e-02, 1.7324e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,260][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0276, 0.1387, 0.0944, 0.2300, 0.1578, 0.0866, 0.1779, 0.0870],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,263][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0047, 0.1975, 0.2084, 0.1722, 0.1560, 0.1707, 0.0852, 0.0054],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,266][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.2178, 0.0880, 0.1102, 0.1092, 0.1260, 0.1091, 0.1159, 0.1238],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,270][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0226, 0.2324, 0.0750, 0.2026, 0.2078, 0.1078, 0.1059, 0.0460],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,273][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.1005, 0.0633, 0.0276, 0.0480, 0.0268, 0.1440, 0.1101, 0.4797],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,273][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0017, 0.5835, 0.0773, 0.1766, 0.0982, 0.0085, 0.0505, 0.0037],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,274][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([1.2950e-04, 7.3865e-01, 3.3330e-02, 1.5466e-01, 5.5659e-02, 1.1755e-03,
        1.6079e-02, 3.1425e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,275][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([2.4107e-04, 3.5874e-01, 9.6869e-02, 2.5533e-01, 9.5228e-02, 1.6268e-02,
        1.7097e-01, 6.3485e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,276][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([9.8843e-01, 4.8378e-03, 1.0790e-03, 6.3171e-04, 5.5209e-04, 1.0152e-03,
        3.4825e-04, 3.1031e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,279][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0098, 0.1293, 0.1522, 0.1568, 0.1386, 0.1430, 0.1532, 0.1171],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,283][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.8530, 0.0152, 0.0214, 0.0019, 0.0232, 0.0130, 0.0098, 0.0611, 0.0014],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,286][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ of] are: tensor([4.4265e-05, 6.8781e-01, 2.0551e-01, 6.5376e-02, 3.0530e-02, 1.1303e-03,
        3.9879e-03, 9.5739e-05, 5.5228e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,289][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0791, 0.1452, 0.1258, 0.1504, 0.1118, 0.0876, 0.1506, 0.0818, 0.0677],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,291][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.1512, 0.2256, 0.1137, 0.1489, 0.1033, 0.0529, 0.0886, 0.0134, 0.1024],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,292][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1792, 0.0735, 0.0957, 0.0935, 0.1078, 0.0941, 0.0969, 0.1057, 0.1537],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,292][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0483, 0.1795, 0.0689, 0.1632, 0.1832, 0.0932, 0.0780, 0.0403, 0.1453],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,293][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0483, 0.0730, 0.0459, 0.0588, 0.0416, 0.1083, 0.1115, 0.1843, 0.3282],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,295][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0048, 0.8391, 0.0206, 0.0743, 0.0185, 0.0099, 0.0081, 0.0029, 0.0217],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,297][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ of] are: tensor([4.1252e-04, 9.2243e-01, 5.3687e-03, 6.5793e-02, 2.3946e-03, 1.0058e-03,
        4.6675e-04, 1.2510e-04, 2.0063e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,302][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0030, 0.2315, 0.1127, 0.1978, 0.1047, 0.0383, 0.1421, 0.0202, 0.1496],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,304][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ of] are: tensor([9.9748e-01, 9.6335e-04, 1.6088e-04, 1.2197e-04, 5.4125e-05, 2.2580e-04,
        7.7296e-05, 8.8045e-04, 3.2600e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,307][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0145, 0.1158, 0.1325, 0.1343, 0.1185, 0.1166, 0.1284, 0.1000, 0.1394],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,309][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.7618, 0.0279, 0.0127, 0.0073, 0.0232, 0.0177, 0.0241, 0.1101, 0.0142,
        0.0010], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,310][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([4.0662e-05, 6.2296e-01, 1.6454e-01, 1.4392e-01, 5.0455e-02, 1.7394e-03,
        5.0936e-03, 9.2970e-05, 1.0624e-02, 5.2677e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,311][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0578, 0.1235, 0.1332, 0.1501, 0.1167, 0.0718, 0.1158, 0.0534, 0.0717,
        0.1061], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,312][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0998, 0.2107, 0.1122, 0.1515, 0.1159, 0.0442, 0.0916, 0.0140, 0.1113,
        0.0489], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,314][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.1693, 0.0639, 0.0817, 0.0811, 0.0932, 0.0819, 0.0864, 0.0945, 0.1428,
        0.1051], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,316][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0330, 0.1732, 0.0501, 0.1575, 0.1549, 0.0818, 0.0926, 0.0524, 0.1595,
        0.0451], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,320][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.1004, 0.0748, 0.0342, 0.0438, 0.0277, 0.1273, 0.0884, 0.1940, 0.1097,
        0.1998], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,325][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0016, 0.8030, 0.0219, 0.1043, 0.0238, 0.0043, 0.0089, 0.0014, 0.0268,
        0.0039], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,327][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([2.5626e-05, 9.3705e-01, 1.9364e-03, 5.6185e-02, 2.5170e-03, 1.3491e-04,
        2.8944e-04, 1.3838e-05, 1.8074e-03, 4.1182e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,328][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0029, 0.2130, 0.1021, 0.1774, 0.0949, 0.0364, 0.1318, 0.0183, 0.1408,
        0.0825], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,329][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([9.9616e-01, 1.4176e-03, 2.6857e-04, 1.5765e-04, 1.1843e-04, 3.0700e-04,
        9.4789e-05, 1.1516e-03, 7.5041e-05, 2.4462e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,330][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0115, 0.1020, 0.1150, 0.1195, 0.1036, 0.1079, 0.1166, 0.0879, 0.1269,
        0.1090], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,332][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.8006, 0.0368, 0.0414, 0.0031, 0.0311, 0.0253, 0.0114, 0.0427, 0.0037,
        0.0028, 0.0011], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,334][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ at] are: tensor([2.5807e-05, 7.0484e-01, 1.3562e-01, 8.7197e-02, 5.7296e-02, 1.0346e-03,
        3.6186e-03, 7.4760e-05, 8.5650e-03, 1.3334e-03, 3.9624e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,338][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0330, 0.1165, 0.1191, 0.1385, 0.1057, 0.0859, 0.1316, 0.0482, 0.0642,
        0.0948, 0.0625], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,341][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0923, 0.1985, 0.1124, 0.1428, 0.1016, 0.0408, 0.0873, 0.0110, 0.1055,
        0.0472, 0.0606], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,345][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1465, 0.0576, 0.0752, 0.0741, 0.0851, 0.0750, 0.0783, 0.0862, 0.1288,
        0.0952, 0.0980], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,346][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0361, 0.1463, 0.0608, 0.1400, 0.1475, 0.0863, 0.0691, 0.0432, 0.1398,
        0.0480, 0.0830], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,347][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0123, 0.0488, 0.0314, 0.0404, 0.0276, 0.0636, 0.0555, 0.1307, 0.1257,
        0.1357, 0.3282], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,348][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0015, 0.8183, 0.0188, 0.1001, 0.0188, 0.0040, 0.0072, 0.0012, 0.0208,
        0.0037, 0.0055], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,349][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ at] are: tensor([7.0600e-05, 9.0951e-01, 3.9005e-03, 8.0878e-02, 2.6974e-03, 3.0081e-04,
        3.3977e-04, 3.8015e-05, 1.9977e-03, 1.0384e-04, 1.6051e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,352][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0026, 0.1908, 0.0902, 0.1619, 0.0834, 0.0325, 0.1145, 0.0170, 0.1243,
        0.0899, 0.0929], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,355][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ at] are: tensor([9.9685e-01, 1.1504e-03, 2.0139e-04, 1.4312e-04, 8.2277e-05, 2.4912e-04,
        8.4160e-05, 9.2246e-04, 5.0756e-05, 1.7470e-04, 9.0459e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,359][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0101, 0.0916, 0.1048, 0.1068, 0.0945, 0.0924, 0.1019, 0.0796, 0.1113,
        0.0999, 0.1071], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,363][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.6211, 0.0545, 0.0987, 0.0060, 0.0740, 0.0304, 0.0104, 0.0874, 0.0073,
        0.0047, 0.0026, 0.0029], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,364][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ the] are: tensor([6.2138e-06, 7.9531e-01, 1.1482e-01, 4.6249e-02, 3.7649e-02, 2.5946e-04,
        1.7417e-03, 1.8644e-05, 3.3062e-03, 4.5325e-04, 1.5173e-04, 3.6609e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,365][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0444, 0.1020, 0.1016, 0.1175, 0.1018, 0.0819, 0.1273, 0.0608, 0.0487,
        0.0887, 0.0484, 0.0768], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,366][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0847, 0.1957, 0.1014, 0.1359, 0.0942, 0.0434, 0.0777, 0.0125, 0.0934,
        0.0450, 0.0578, 0.0583], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,368][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1352, 0.0536, 0.0697, 0.0680, 0.0793, 0.0690, 0.0728, 0.0797, 0.1231,
        0.0901, 0.0927, 0.0668], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,371][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0332, 0.1535, 0.0492, 0.1305, 0.1382, 0.0708, 0.0710, 0.0336, 0.1299,
        0.0411, 0.0879, 0.0611], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,375][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0523, 0.0461, 0.0291, 0.0325, 0.0219, 0.0917, 0.0885, 0.1548, 0.1101,
        0.1026, 0.1190, 0.1515], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,379][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0018, 0.8120, 0.0224, 0.0888, 0.0240, 0.0045, 0.0071, 0.0013, 0.0222,
        0.0045, 0.0072, 0.0043], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,381][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ the] are: tensor([4.6579e-05, 9.2051e-01, 2.6205e-03, 7.1191e-02, 2.3789e-03, 2.2018e-04,
        2.3149e-04, 2.4723e-05, 2.4486e-03, 6.6809e-05, 2.0515e-04, 5.4384e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,382][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0023, 0.1788, 0.0795, 0.1478, 0.0810, 0.0282, 0.0985, 0.0146, 0.1081,
        0.0752, 0.0845, 0.1014], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,383][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ the] are: tensor([9.9677e-01, 1.1239e-03, 2.1555e-04, 1.3199e-04, 9.1486e-05, 2.4292e-04,
        8.0109e-05, 9.0642e-04, 5.9308e-05, 1.8406e-04, 1.0059e-04, 9.0308e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,384][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0075, 0.0816, 0.0952, 0.0957, 0.0860, 0.0837, 0.0917, 0.0727, 0.1009,
        0.0930, 0.0974, 0.0946], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,386][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.7410, 0.0590, 0.0356, 0.0084, 0.0542, 0.0248, 0.0122, 0.0438, 0.0112,
        0.0014, 0.0023, 0.0053, 0.0009], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,388][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ store] are: tensor([5.8182e-06, 4.7917e-01, 9.0282e-02, 3.2602e-01, 6.4830e-02, 1.0539e-03,
        8.5779e-03, 4.0436e-05, 2.4770e-02, 1.7318e-03, 1.8862e-03, 1.5676e-03,
        5.9226e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,392][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0301, 0.1116, 0.0942, 0.1316, 0.0831, 0.0741, 0.1078, 0.0388, 0.0570,
        0.0881, 0.0560, 0.0644, 0.0633], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,395][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0558, 0.1798, 0.1129, 0.1377, 0.0942, 0.0593, 0.0788, 0.0117, 0.0917,
        0.0426, 0.0555, 0.0596, 0.0203], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,399][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.1384, 0.0503, 0.0627, 0.0618, 0.0710, 0.0630, 0.0653, 0.0728, 0.1031,
        0.0775, 0.0795, 0.0584, 0.0963], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,400][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0234, 0.1348, 0.0497, 0.1169, 0.1493, 0.0854, 0.0645, 0.0411, 0.1318,
        0.0389, 0.0795, 0.0540, 0.0308], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,401][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0577, 0.0490, 0.0200, 0.0268, 0.0171, 0.0779, 0.0606, 0.1421, 0.0946,
        0.1032, 0.1467, 0.0731, 0.1313], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,402][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ store] are: tensor([6.2826e-04, 6.8708e-01, 2.7649e-02, 1.4172e-01, 4.4328e-02, 2.8646e-03,
        1.6836e-02, 9.7994e-04, 4.6111e-02, 7.5675e-03, 1.1215e-02, 1.1452e-02,
        1.5727e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,402][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ store] are: tensor([5.0915e-06, 8.9703e-01, 3.1891e-03, 8.9488e-02, 3.6830e-03, 6.8634e-05,
        8.2150e-04, 7.5623e-06, 4.7684e-03, 1.8294e-04, 3.8812e-04, 3.5770e-04,
        1.3310e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,405][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0010, 0.1692, 0.0741, 0.1496, 0.0661, 0.0204, 0.0986, 0.0093, 0.1088,
        0.0669, 0.0870, 0.1164, 0.0325], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,407][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ store] are: tensor([9.9024e-01, 2.8742e-03, 5.6250e-04, 3.4050e-04, 2.7082e-04, 5.9324e-04,
        2.2272e-04, 1.9603e-03, 1.7866e-04, 5.0036e-04, 2.9129e-04, 2.5220e-04,
        1.7108e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,411][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0078, 0.0752, 0.0858, 0.0885, 0.0775, 0.0802, 0.0863, 0.0658, 0.0943,
        0.0825, 0.0909, 0.0890, 0.0762], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,415][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.5652, 0.0619, 0.1128, 0.0024, 0.0548, 0.0704, 0.0248, 0.0764, 0.0047,
        0.0060, 0.0018, 0.0079, 0.0071, 0.0038], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,417][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [.] are: tensor([3.2702e-05, 7.4902e-01, 1.2233e-01, 7.1890e-02, 4.4222e-02, 6.8877e-04,
        3.3943e-03, 6.4731e-05, 6.5276e-03, 8.9893e-04, 3.7797e-04, 2.1314e-04,
        2.5677e-05, 3.1335e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,418][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0489, 0.0991, 0.1048, 0.1068, 0.0756, 0.0639, 0.0900, 0.0420, 0.0360,
        0.1008, 0.0491, 0.0469, 0.0596, 0.0765], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,419][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0634, 0.1878, 0.0912, 0.1282, 0.0874, 0.0389, 0.0778, 0.0085, 0.0935,
        0.0418, 0.0543, 0.0601, 0.0206, 0.0465], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,420][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.1251, 0.0468, 0.0562, 0.0557, 0.0645, 0.0566, 0.0594, 0.0641, 0.0924,
        0.0695, 0.0730, 0.0532, 0.0863, 0.0972], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,422][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0504, 0.1261, 0.0432, 0.1112, 0.1108, 0.0674, 0.0665, 0.0294, 0.0983,
        0.0355, 0.0680, 0.0484, 0.0246, 0.1201], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,426][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0305, 0.0330, 0.0243, 0.0218, 0.0210, 0.0662, 0.0426, 0.1180, 0.0881,
        0.1251, 0.1546, 0.0519, 0.1158, 0.1072], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,429][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0016, 0.7897, 0.0190, 0.1005, 0.0214, 0.0039, 0.0092, 0.0013, 0.0294,
        0.0044, 0.0078, 0.0062, 0.0009, 0.0048], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,432][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [.] are: tensor([8.7618e-05, 9.3563e-01, 3.0126e-03, 5.5522e-02, 2.2883e-03, 2.9097e-04,
        3.9715e-04, 4.4029e-05, 2.0786e-03, 1.2087e-04, 1.9743e-04, 1.3438e-04,
        2.0380e-05, 1.7889e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,436][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0015, 0.1645, 0.0698, 0.1315, 0.0674, 0.0233, 0.0929, 0.0116, 0.0958,
        0.0683, 0.0738, 0.0982, 0.0364, 0.0650], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,436][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [.] are: tensor([9.9437e-01, 1.7142e-03, 3.1504e-04, 1.9857e-04, 1.3373e-04, 3.2437e-04,
        1.1403e-04, 1.0723e-03, 7.0571e-05, 2.2600e-04, 1.2404e-04, 1.1884e-04,
        8.3483e-04, 3.8755e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,437][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0076, 0.0697, 0.0797, 0.0810, 0.0714, 0.0706, 0.0781, 0.0608, 0.0850,
        0.0757, 0.0815, 0.0799, 0.0697, 0.0892], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,438][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.6365, 0.0935, 0.0236, 0.0213, 0.0455, 0.0242, 0.0326, 0.0511, 0.0211,
        0.0015, 0.0031, 0.0154, 0.0026, 0.0248, 0.0032], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,440][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([4.2618e-04, 5.9724e-01, 2.2633e-01, 7.5237e-02, 7.2332e-02, 5.8036e-03,
        3.7940e-03, 5.1693e-04, 8.8766e-03, 1.9727e-03, 8.4416e-04, 5.5151e-04,
        1.1998e-04, 1.1037e-03, 4.8497e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,443][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.0197, 0.0893, 0.0780, 0.0900, 0.0949, 0.0478, 0.0724, 0.0349, 0.0664,
        0.0787, 0.0530, 0.0526, 0.0841, 0.0947, 0.0434], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,447][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.1305, 0.1699, 0.0828, 0.1166, 0.0767, 0.0352, 0.0703, 0.0078, 0.0794,
        0.0374, 0.0495, 0.0524, 0.0183, 0.0426, 0.0307], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,451][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.1064, 0.0430, 0.0525, 0.0530, 0.0599, 0.0528, 0.0546, 0.0593, 0.0825,
        0.0632, 0.0663, 0.0487, 0.0769, 0.0911, 0.0898], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,454][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0100, 0.0969, 0.0414, 0.1116, 0.1250, 0.0538, 0.0625, 0.0351, 0.1077,
        0.0399, 0.0624, 0.0582, 0.0378, 0.1413, 0.0165], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,454][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.0834, 0.0506, 0.0387, 0.0249, 0.0167, 0.0601, 0.0585, 0.0794, 0.1007,
        0.0937, 0.0859, 0.0908, 0.0697, 0.0675, 0.0794], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,455][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.0069, 0.6626, 0.0463, 0.1005, 0.0476, 0.0127, 0.0149, 0.0046, 0.0352,
        0.0094, 0.0156, 0.0123, 0.0036, 0.0172, 0.0105], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,456][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([5.6219e-04, 8.3922e-01, 5.8649e-03, 1.3187e-01, 7.0374e-03, 1.5650e-03,
        1.3009e-03, 2.4234e-04, 8.4048e-03, 5.3575e-04, 9.2142e-04, 5.4302e-04,
        1.1533e-04, 1.4791e-03, 3.3765e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,458][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0013, 0.1477, 0.0575, 0.1254, 0.0633, 0.0223, 0.0902, 0.0108, 0.0945,
        0.0634, 0.0781, 0.0989, 0.0351, 0.0731, 0.0386], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,460][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([9.9493e-01, 1.4970e-03, 2.4908e-04, 1.7124e-04, 9.4560e-05, 2.8386e-04,
        9.5966e-05, 9.8373e-04, 5.8198e-05, 1.7217e-04, 1.0180e-04, 1.0398e-04,
        7.9353e-04, 3.3202e-04, 1.3005e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,465][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.0063, 0.0635, 0.0727, 0.0749, 0.0658, 0.0689, 0.0736, 0.0580, 0.0791,
        0.0719, 0.0771, 0.0751, 0.0653, 0.0837, 0.0641], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,469][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.5347, 0.0623, 0.1022, 0.0077, 0.0630, 0.0186, 0.0236, 0.0717, 0.0247,
        0.0028, 0.0048, 0.0167, 0.0073, 0.0125, 0.0341, 0.0133],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,471][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([4.5082e-05, 5.3923e-01, 1.4843e-01, 1.2167e-01, 1.0534e-01, 1.1370e-03,
        1.8387e-02, 1.8846e-04, 1.9136e-02, 8.7623e-03, 6.0458e-03, 5.7342e-03,
        9.7399e-04, 9.8668e-03, 1.4620e-02, 4.2742e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,472][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0120, 0.0777, 0.0853, 0.1077, 0.0986, 0.0402, 0.0754, 0.0347, 0.0662,
        0.0796, 0.0489, 0.0535, 0.0555, 0.1045, 0.0415, 0.0186],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,473][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0080, 0.2249, 0.1180, 0.1659, 0.0982, 0.0420, 0.0684, 0.0018, 0.0812,
        0.0240, 0.0392, 0.0462, 0.0088, 0.0282, 0.0298, 0.0154],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,474][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1019, 0.0395, 0.0465, 0.0470, 0.0542, 0.0473, 0.0495, 0.0540, 0.0751,
        0.0577, 0.0592, 0.0450, 0.0694, 0.0774, 0.0798, 0.0965],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,476][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0172, 0.1217, 0.0303, 0.1150, 0.0994, 0.0528, 0.0588, 0.0306, 0.1158,
        0.0312, 0.0668, 0.0510, 0.0296, 0.1502, 0.0125, 0.0171],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,479][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0275, 0.0250, 0.0119, 0.0183, 0.0131, 0.0567, 0.0475, 0.0961, 0.0763,
        0.1003, 0.0872, 0.0654, 0.0736, 0.0694, 0.0252, 0.2065],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,483][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0015, 0.4785, 0.0512, 0.1410, 0.0663, 0.0061, 0.0343, 0.0028, 0.0656,
        0.0230, 0.0327, 0.0327, 0.0079, 0.0290, 0.0231, 0.0043],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,485][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([2.3367e-04, 7.3041e-01, 2.2574e-02, 1.4059e-01, 3.4280e-02, 1.4210e-03,
        9.9317e-03, 4.1400e-04, 2.7991e-02, 3.9791e-03, 7.3830e-03, 6.8428e-03,
        1.2214e-03, 8.5185e-03, 3.4339e-03, 7.7764e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,488][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([1.4929e-04, 1.8974e-01, 5.5447e-02, 1.3812e-01, 5.5769e-02, 9.0659e-03,
        9.0644e-02, 3.5998e-03, 9.3725e-02, 4.7930e-02, 7.9941e-02, 1.0438e-01,
        2.6182e-02, 6.9371e-02, 3.1808e-02, 4.1283e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,490][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([9.8432e-01, 3.8166e-03, 8.0164e-04, 4.8119e-04, 3.6530e-04, 7.4586e-04,
        2.9691e-04, 2.4069e-03, 2.0025e-04, 6.0176e-04, 3.3075e-04, 3.1016e-04,
        2.1172e-03, 9.3526e-04, 4.1937e-04, 1.8480e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,491][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0043, 0.0587, 0.0694, 0.0710, 0.0625, 0.0628, 0.0683, 0.0525, 0.0756,
        0.0680, 0.0727, 0.0706, 0.0618, 0.0808, 0.0607, 0.0603],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,491][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.6692, 0.0381, 0.0545, 0.0035, 0.0701, 0.0195, 0.0037, 0.0799, 0.0061,
        0.0021, 0.0019, 0.0020, 0.0061, 0.0073, 0.0146, 0.0176, 0.0037],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:33,493][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.7294e-06, 5.9814e-01, 1.7265e-01, 1.0737e-01, 8.7488e-02, 4.7172e-04,
        7.2240e-03, 5.0121e-05, 1.2348e-02, 3.2221e-03, 1.5953e-03, 1.2775e-03,
        1.8577e-04, 2.3565e-03, 5.0282e-03, 1.0565e-04, 4.8018e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:33,496][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0164, 0.0741, 0.0934, 0.0939, 0.0937, 0.0519, 0.0951, 0.0430, 0.0368,
        0.0685, 0.0397, 0.0677, 0.0558, 0.0735, 0.0376, 0.0217, 0.0373],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:33,500][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0444, 0.2404, 0.0924, 0.1381, 0.0782, 0.0218, 0.0604, 0.0026, 0.0779,
        0.0243, 0.0400, 0.0443, 0.0096, 0.0329, 0.0230, 0.0110, 0.0587],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:33,505][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0887, 0.0357, 0.0439, 0.0429, 0.0490, 0.0439, 0.0456, 0.0494, 0.0670,
        0.0525, 0.0543, 0.0400, 0.0629, 0.0717, 0.0733, 0.0872, 0.0919],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:33,507][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0144, 0.1130, 0.0392, 0.0938, 0.1409, 0.0527, 0.0548, 0.0242, 0.0938,
        0.0344, 0.0696, 0.0500, 0.0291, 0.1323, 0.0166, 0.0184, 0.0230],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:33,508][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0327, 0.0197, 0.0114, 0.0137, 0.0082, 0.0496, 0.0818, 0.0675, 0.0722,
        0.0453, 0.0715, 0.0753, 0.0498, 0.0669, 0.0252, 0.1050, 0.2043],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:33,509][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0017, 0.6165, 0.0367, 0.1259, 0.0427, 0.0061, 0.0192, 0.0023, 0.0507,
        0.0134, 0.0206, 0.0172, 0.0038, 0.0184, 0.0124, 0.0040, 0.0086],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:33,510][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([1.5224e-04, 8.5754e-01, 1.0652e-02, 9.6766e-02, 1.3115e-02, 7.2467e-04,
        2.0398e-03, 1.6170e-04, 1.0671e-02, 8.9062e-04, 1.8948e-03, 1.0459e-03,
        2.1869e-04, 2.2154e-03, 7.2796e-04, 3.4747e-04, 8.3520e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:33,512][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0004, 0.1740, 0.0590, 0.1333, 0.0586, 0.0136, 0.0846, 0.0061, 0.0868,
        0.0563, 0.0727, 0.0967, 0.0285, 0.0658, 0.0350, 0.0070, 0.0215],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:33,514][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.9548e-01, 1.1428e-03, 2.2916e-04, 1.2965e-04, 9.4884e-05, 2.0747e-04,
        7.1789e-05, 7.8821e-04, 4.6734e-05, 1.4874e-04, 7.6217e-05, 7.2879e-05,
        5.7102e-04, 2.3611e-04, 1.0170e-04, 4.7693e-04, 1.2526e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:33,518][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0039, 0.0553, 0.0660, 0.0663, 0.0592, 0.0582, 0.0635, 0.0499, 0.0702,
        0.0651, 0.0676, 0.0657, 0.0594, 0.0748, 0.0578, 0.0567, 0.0604],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:33,521][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.3252, 0.1005, 0.0478, 0.0139, 0.1041, 0.0380, 0.0898, 0.1134, 0.0332,
        0.0020, 0.0045, 0.0200, 0.0045, 0.0125, 0.0057, 0.0238, 0.0595, 0.0015],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:33,523][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([5.0029e-05, 6.3596e-01, 1.3446e-01, 1.4321e-01, 5.9917e-02, 1.4572e-03,
        4.0909e-03, 1.0420e-04, 1.1113e-02, 1.1005e-03, 9.4155e-04, 6.2757e-04,
        5.2649e-05, 1.3900e-03, 3.4185e-03, 3.4442e-04, 1.1166e-03, 6.5198e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:33,525][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([0.0171, 0.0858, 0.0737, 0.0968, 0.0567, 0.0509, 0.1068, 0.0294, 0.0378,
        0.0667, 0.0545, 0.0614, 0.0494, 0.0803, 0.0326, 0.0231, 0.0419, 0.0351],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:33,526][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([0.0664, 0.1497, 0.0815, 0.1088, 0.0755, 0.0365, 0.0614, 0.0093, 0.0747,
        0.0376, 0.0453, 0.0474, 0.0194, 0.0404, 0.0332, 0.0222, 0.0570, 0.0337],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:33,527][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([0.0783, 0.0327, 0.0408, 0.0400, 0.0454, 0.0400, 0.0417, 0.0452, 0.0625,
        0.0481, 0.0503, 0.0380, 0.0596, 0.0678, 0.0701, 0.0819, 0.0858, 0.0719],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:33,528][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([0.0142, 0.1143, 0.0321, 0.0968, 0.0992, 0.0616, 0.0641, 0.0306, 0.1101,
        0.0249, 0.0641, 0.0439, 0.0283, 0.1349, 0.0129, 0.0245, 0.0259, 0.0178],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:33,530][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([0.0433, 0.0380, 0.0124, 0.0246, 0.0168, 0.0540, 0.0413, 0.1076, 0.0524,
        0.0715, 0.0665, 0.0569, 0.0709, 0.0482, 0.0211, 0.1435, 0.0731, 0.0577],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:33,534][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([0.0012, 0.7748, 0.0189, 0.0953, 0.0255, 0.0034, 0.0078, 0.0010, 0.0261,
        0.0044, 0.0084, 0.0064, 0.0010, 0.0099, 0.0043, 0.0023, 0.0061, 0.0030],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:33,536][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([2.0817e-05, 9.4133e-01, 1.8384e-03, 4.9526e-02, 2.2531e-03, 1.3382e-04,
        3.9640e-04, 1.2691e-05, 3.4825e-03, 8.7348e-05, 1.5494e-04, 1.0783e-04,
        1.3207e-05, 3.3746e-04, 5.9052e-05, 4.9860e-05, 1.6940e-04, 2.5075e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:33,539][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([0.0020, 0.1394, 0.0562, 0.1082, 0.0651, 0.0226, 0.0809, 0.0122, 0.0838,
        0.0625, 0.0682, 0.0816, 0.0365, 0.0580, 0.0386, 0.0136, 0.0283, 0.0425],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:33,542][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([9.9337e-01, 1.4341e-03, 2.8066e-04, 1.7273e-04, 1.2109e-04, 3.0746e-04,
        1.0070e-04, 1.0924e-03, 7.6215e-05, 2.2736e-04, 1.2727e-04, 1.2082e-04,
        8.9532e-04, 3.7352e-04, 1.5864e-04, 7.2365e-04, 2.0456e-04, 2.1667e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:33,543][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([0.0057, 0.0540, 0.0612, 0.0631, 0.0545, 0.0580, 0.0620, 0.0472, 0.0672,
        0.0580, 0.0647, 0.0633, 0.0529, 0.0703, 0.0530, 0.0538, 0.0588, 0.0524],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:33,544][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4591, 0.0536, 0.0974, 0.0060, 0.0909, 0.0397, 0.0252, 0.0955, 0.0061,
        0.0033, 0.0014, 0.0073, 0.0121, 0.0129, 0.0214, 0.0296, 0.0300, 0.0069,
        0.0015], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:33,545][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.9433e-05, 7.8354e-01, 1.0536e-01, 5.3757e-02, 4.6434e-02, 5.1112e-04,
        2.1085e-03, 4.6997e-05, 4.5426e-03, 9.9081e-04, 2.3757e-04, 1.2873e-04,
        2.8146e-05, 2.5497e-04, 1.1237e-03, 1.0834e-04, 2.9220e-04, 2.6111e-04,
        2.5429e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:33,546][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0345, 0.0732, 0.0783, 0.0980, 0.0700, 0.0574, 0.0783, 0.0434, 0.0374,
        0.0663, 0.0460, 0.0445, 0.0472, 0.0672, 0.0319, 0.0258, 0.0335, 0.0336,
        0.0333], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:33,549][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0971, 0.1590, 0.0691, 0.0987, 0.0639, 0.0285, 0.0582, 0.0076, 0.0695,
        0.0328, 0.0435, 0.0456, 0.0166, 0.0369, 0.0273, 0.0170, 0.0449, 0.0288,
        0.0551], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:33,552][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0688, 0.0300, 0.0380, 0.0371, 0.0426, 0.0376, 0.0384, 0.0420, 0.0564,
        0.0442, 0.0462, 0.0339, 0.0534, 0.0620, 0.0632, 0.0741, 0.0763, 0.0660,
        0.0898], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:33,555][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0281, 0.1069, 0.0374, 0.0968, 0.1060, 0.0549, 0.0574, 0.0277, 0.0898,
        0.0337, 0.0593, 0.0426, 0.0272, 0.1065, 0.0165, 0.0233, 0.0259, 0.0207,
        0.0393], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:33,559][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0121, 0.0193, 0.0149, 0.0146, 0.0112, 0.0300, 0.0340, 0.0463, 0.0751,
        0.0569, 0.0944, 0.0519, 0.0579, 0.0723, 0.0346, 0.1001, 0.0880, 0.0440,
        0.1424], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:33,561][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0031, 0.7796, 0.0154, 0.0913, 0.0153, 0.0066, 0.0088, 0.0021, 0.0247,
        0.0038, 0.0076, 0.0051, 0.0008, 0.0051, 0.0028, 0.0040, 0.0070, 0.0027,
        0.0141], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:33,562][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([3.9755e-04, 9.1391e-01, 4.2006e-03, 7.2150e-02, 2.3716e-03, 9.1559e-04,
        4.9445e-04, 1.3935e-04, 2.7991e-03, 1.3759e-04, 2.5172e-04, 1.4855e-04,
        3.2234e-05, 2.7073e-04, 9.3710e-05, 3.6734e-04, 5.3884e-04, 6.3343e-05,
        7.1516e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:33,563][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0018, 0.1231, 0.0593, 0.1092, 0.0554, 0.0217, 0.0771, 0.0116, 0.0797,
        0.0577, 0.0616, 0.0824, 0.0307, 0.0569, 0.0384, 0.0121, 0.0263, 0.0422,
        0.0525], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:33,564][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.9588e-01, 8.4014e-04, 1.4601e-04, 1.0068e-04, 4.6387e-05, 1.8733e-04,
        6.4278e-05, 8.0602e-04, 2.9713e-05, 1.1755e-04, 5.8768e-05, 6.9217e-05,
        5.6473e-04, 2.2817e-04, 7.4459e-05, 4.8770e-04, 1.2454e-04, 1.4495e-04,
        3.1696e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:33,566][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0057, 0.0507, 0.0582, 0.0592, 0.0525, 0.0520, 0.0571, 0.0450, 0.0621,
        0.0560, 0.0598, 0.0584, 0.0518, 0.0658, 0.0507, 0.0499, 0.0541, 0.0507,
        0.0602], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:33,633][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:33,634][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,634][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,635][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,636][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,636][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,637][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,638][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,639][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,639][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,640][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,640][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,641][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:33,642][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5540, 0.4460], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,643][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0013, 0.9987], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,643][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.8812, 0.1188], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,645][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5345, 0.4655], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,645][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.9999e-01, 1.1904e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,646][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0326, 0.9674], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,647][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9976, 0.0024], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,647][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1959, 0.8041], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,650][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2211, 0.7789], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,654][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0035, 0.9965], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,657][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9899, 0.0101], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,661][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0129, 0.9871], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:33,662][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.0728, 0.8668, 0.0604], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,663][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0035, 0.9740, 0.0225], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,663][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.4852, 0.3678, 0.1470], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,665][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.4511, 0.4271, 0.1218], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,667][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([9.9946e-01, 9.0048e-05, 4.4634e-04], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,670][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.0110, 0.9031, 0.0860], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,674][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.9961, 0.0014, 0.0025], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,678][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.1268, 0.7610, 0.1122], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,679][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.0500, 0.9192, 0.0308], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,680][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.0092, 0.9123, 0.0785], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,681][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.8868, 0.0371, 0.0761], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,681][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.0024, 0.9794, 0.0183], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:33,683][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0104, 0.9069, 0.0584, 0.0243], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,685][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.2770e-05, 9.9350e-01, 1.9508e-03, 4.5367e-03], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,688][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3609, 0.3441, 0.1064, 0.1886], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,692][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0657, 0.7061, 0.0797, 0.1485], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,694][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.9911e-01, 1.6681e-04, 4.0038e-04, 3.2331e-04], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,697][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([7.3894e-04, 9.3703e-01, 3.2148e-02, 3.0079e-02], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,697][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9657, 0.0064, 0.0032, 0.0246], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,698][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0115, 0.9046, 0.0336, 0.0504], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,699][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0014, 0.9561, 0.0087, 0.0339], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,700][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([6.7273e-04, 8.1400e-01, 6.1762e-02, 1.2356e-01], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,702][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6892, 0.0890, 0.0843, 0.1375], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,704][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([7.2300e-05, 9.8794e-01, 3.5866e-03, 8.4033e-03], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:33,708][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.0169, 0.8204, 0.0540, 0.0686, 0.0401], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,710][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([3.1524e-04, 9.5601e-01, 1.0302e-02, 2.5288e-02, 8.0818e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,714][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([0.4538, 0.2229, 0.0852, 0.1420, 0.0961], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,715][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([0.1206, 0.4378, 0.0741, 0.2718, 0.0956], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,716][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([9.9852e-01, 1.4746e-04, 4.7541e-04, 3.7097e-04, 4.8658e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,716][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.0022, 0.8502, 0.0436, 0.0724, 0.0317], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,717][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.9735, 0.0038, 0.0041, 0.0134, 0.0052], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,719][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.0366, 0.7100, 0.0889, 0.0957, 0.0688], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,723][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.0048, 0.8875, 0.0113, 0.0916, 0.0049], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,726][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.0494, 0.6528, 0.1507, 0.1091, 0.0381], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,730][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.7002, 0.0367, 0.0784, 0.0970, 0.0877], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,732][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([3.1471e-04, 9.6009e-01, 6.8428e-03, 2.7810e-02, 4.9446e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:33,733][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0018, 0.6815, 0.0988, 0.1034, 0.1086, 0.0058], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,734][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([2.0289e-05, 9.3459e-01, 1.0183e-02, 3.3135e-02, 2.1874e-02, 1.9706e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,734][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0201, 0.4015, 0.1509, 0.1842, 0.2095, 0.0338], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,735][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0058, 0.5371, 0.0909, 0.2088, 0.1402, 0.0172], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,737][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.6148, 0.0384, 0.0376, 0.0457, 0.0403, 0.2232], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,739][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([3.3902e-04, 7.5810e-01, 6.8436e-02, 9.3300e-02, 7.7872e-02, 1.9546e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,743][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.2861, 0.1592, 0.0586, 0.1688, 0.0483, 0.2790], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,748][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0024, 0.6708, 0.0879, 0.1348, 0.0956, 0.0085], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,750][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([2.9743e-04, 7.6527e-01, 3.7890e-02, 1.4830e-01, 4.6688e-02, 1.5481e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,751][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([8.8223e-06, 7.3288e-01, 1.8397e-02, 2.2829e-01, 2.0235e-02, 1.8384e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,752][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0264, 0.3265, 0.1556, 0.2245, 0.2177, 0.0493], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,752][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([1.3779e-04, 8.1273e-01, 4.2756e-02, 7.0399e-02, 7.3009e-02, 9.6291e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:33,754][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0010, 0.8635, 0.0366, 0.0584, 0.0359, 0.0026, 0.0020],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,756][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([8.4355e-06, 9.7964e-01, 2.7315e-03, 1.3388e-02, 3.8096e-03, 5.8096e-05,
        3.6676e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,760][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1768, 0.3279, 0.0973, 0.1413, 0.1176, 0.0929, 0.0461],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,764][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0150, 0.6246, 0.0484, 0.1795, 0.0881, 0.0244, 0.0201],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,767][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.8985, 0.0012, 0.0016, 0.0020, 0.0019, 0.0932, 0.0016],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,768][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.0331e-04, 9.1612e-01, 1.9057e-02, 4.3728e-02, 1.8789e-02, 4.8653e-04,
        1.7156e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,769][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.7221, 0.0053, 0.0039, 0.0165, 0.0037, 0.2281, 0.0204],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,770][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0036, 0.7943, 0.0368, 0.1073, 0.0394, 0.0086, 0.0100],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,770][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([9.1248e-05, 9.1594e-01, 5.5690e-03, 7.3102e-02, 4.6606e-03, 3.8751e-04,
        2.5440e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,773][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0030, 0.4094, 0.0995, 0.1834, 0.1053, 0.0171, 0.1822],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,776][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.4014, 0.0328, 0.0502, 0.0879, 0.0745, 0.2346, 0.1186],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,778][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.0659e-05, 9.5349e-01, 4.7291e-03, 3.5211e-02, 6.1990e-03, 1.1906e-04,
        2.3718e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:33,782][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0007, 0.6516, 0.0685, 0.1349, 0.1150, 0.0041, 0.0237, 0.0015],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,784][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([2.4339e-05, 8.7146e-01, 1.4147e-02, 6.9330e-02, 3.4277e-02, 3.3759e-04,
        1.0331e-02, 9.3135e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,786][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0120, 0.3643, 0.1430, 0.1621, 0.1700, 0.0257, 0.1052, 0.0177],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,787][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0041, 0.4759, 0.0900, 0.1874, 0.1497, 0.0159, 0.0699, 0.0070],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,787][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.4096, 0.0326, 0.0380, 0.0415, 0.0475, 0.1827, 0.0501, 0.1980],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,788][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([2.2175e-04, 7.0591e-01, 6.0748e-02, 1.2746e-01, 7.9966e-02, 1.7975e-03,
        2.3312e-02, 5.8461e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,790][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.1634, 0.1787, 0.0579, 0.1436, 0.0486, 0.1730, 0.1052, 0.1296],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,792][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0017, 0.5835, 0.0773, 0.1766, 0.0982, 0.0085, 0.0505, 0.0037],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,793][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([1.2950e-04, 7.3865e-01, 3.3330e-02, 1.5466e-01, 5.5659e-02, 1.1755e-03,
        1.6079e-02, 3.1425e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,794][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([1.0609e-05, 6.7650e-01, 1.7591e-02, 1.9093e-01, 2.0126e-02, 1.9680e-04,
        9.4571e-02, 7.5243e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,798][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0199, 0.2609, 0.1322, 0.1688, 0.1723, 0.0398, 0.1703, 0.0358],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,801][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([7.4659e-05, 7.4394e-01, 4.6075e-02, 1.2181e-01, 7.6491e-02, 9.3784e-04,
        1.0458e-02, 2.0765e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:33,805][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0048, 0.8760, 0.0314, 0.0437, 0.0282, 0.0068, 0.0026, 0.0016, 0.0049],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,806][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([3.2635e-05, 9.8212e-01, 2.4729e-03, 1.1473e-02, 1.9952e-03, 1.2294e-04,
        6.4657e-04, 2.4726e-05, 1.1075e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,806][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.2082, 0.2478, 0.0895, 0.1153, 0.0984, 0.0928, 0.0425, 0.0772, 0.0284],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,807][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0170, 0.6614, 0.0385, 0.1260, 0.0579, 0.0271, 0.0189, 0.0076, 0.0455],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,808][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([7.5247e-01, 9.4190e-04, 6.0067e-04, 2.1724e-03, 9.7645e-04, 9.9763e-02,
        1.9124e-03, 1.3611e-01, 5.0571e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,809][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([2.3883e-04, 9.2573e-01, 1.6618e-02, 3.7211e-02, 1.2962e-02, 7.9646e-04,
        1.8417e-03, 1.4863e-04, 4.4555e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,812][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.6192, 0.0047, 0.0025, 0.0139, 0.0022, 0.1941, 0.0135, 0.1284, 0.0216],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,816][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0048, 0.8391, 0.0206, 0.0743, 0.0185, 0.0099, 0.0081, 0.0029, 0.0217],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,819][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([4.1252e-04, 9.2243e-01, 5.3687e-03, 6.5793e-02, 2.3946e-03, 1.0058e-03,
        4.6675e-04, 1.2510e-04, 2.0063e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,823][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0030, 0.2092, 0.1025, 0.0745, 0.1059, 0.0128, 0.1988, 0.0078, 0.2856],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,824][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.2027, 0.0205, 0.0374, 0.0611, 0.0585, 0.1503, 0.0830, 0.1526, 0.2338],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,824][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([4.0262e-05, 9.6152e-01, 3.7546e-03, 2.7924e-02, 4.2691e-03, 2.7204e-04,
        3.2332e-04, 2.2550e-05, 1.8755e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:33,825][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([3.8012e-04, 8.8739e-01, 2.0389e-02, 5.6310e-02, 2.4509e-02, 1.2024e-03,
        2.2174e-03, 2.4875e-04, 6.9359e-03, 4.2231e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,826][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([7.1917e-06, 9.7087e-01, 1.9067e-03, 2.1499e-02, 3.2632e-03, 5.9762e-05,
        6.5191e-04, 8.7592e-06, 1.6200e-03, 1.1603e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,829][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0980, 0.3138, 0.0914, 0.1531, 0.1039, 0.0685, 0.0439, 0.0551, 0.0330,
        0.0394], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,833][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0042, 0.6296, 0.0299, 0.1446, 0.0780, 0.0094, 0.0247, 0.0033, 0.0700,
        0.0061], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,838][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.6721, 0.0038, 0.0022, 0.0082, 0.0037, 0.1232, 0.0059, 0.1515, 0.0193,
        0.0101], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,840][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([8.0674e-05, 9.0287e-01, 1.7562e-02, 5.1726e-02, 1.8462e-02, 4.4438e-04,
        2.0817e-03, 8.6305e-05, 5.6755e-03, 1.0080e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,841][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.5243, 0.0164, 0.0059, 0.0233, 0.0060, 0.2048, 0.0221, 0.1459, 0.0352,
        0.0162], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,842][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0016, 0.8030, 0.0219, 0.1043, 0.0238, 0.0043, 0.0089, 0.0014, 0.0268,
        0.0039], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,842][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([2.5626e-05, 9.3705e-01, 1.9364e-03, 5.6185e-02, 2.5170e-03, 1.3491e-04,
        2.8944e-04, 1.3838e-05, 1.8074e-03, 4.1182e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,844][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0037, 0.2857, 0.0925, 0.0673, 0.0785, 0.0114, 0.1590, 0.0064, 0.2693,
        0.0262], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,847][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.1537, 0.0241, 0.0422, 0.0450, 0.0613, 0.1274, 0.0717, 0.1205, 0.1237,
        0.2305], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,850][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([5.7115e-06, 9.5809e-01, 2.8114e-03, 3.1715e-02, 3.6753e-03, 7.1947e-05,
        3.1052e-04, 6.5113e-06, 3.2132e-03, 1.0042e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:33,852][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([1.0402e-03, 9.0042e-01, 2.3312e-02, 4.0528e-02, 2.3768e-02, 2.2045e-03,
        2.0804e-03, 5.4262e-04, 4.9865e-03, 7.2434e-04, 3.9159e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,854][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([1.8161e-05, 9.7994e-01, 1.6696e-03, 1.3466e-02, 2.6764e-03, 8.4725e-05,
        5.0454e-04, 1.6519e-05, 1.2736e-03, 2.2266e-04, 1.2366e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,858][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1237, 0.2540, 0.1144, 0.1319, 0.1130, 0.0635, 0.0412, 0.0603, 0.0338,
        0.0437, 0.0206], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,859][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0105, 0.5812, 0.0442, 0.1474, 0.0738, 0.0169, 0.0262, 0.0059, 0.0748,
        0.0068, 0.0123], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,860][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.7706, 0.0015, 0.0012, 0.0025, 0.0015, 0.0874, 0.0019, 0.1187, 0.0070,
        0.0038, 0.0039], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,861][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([8.6101e-05, 9.2180e-01, 1.7156e-02, 4.1088e-02, 1.2274e-02, 4.2760e-04,
        1.6067e-03, 8.0893e-05, 3.8204e-03, 9.2454e-04, 7.3301e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,863][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.5682, 0.0106, 0.0044, 0.0199, 0.0032, 0.1922, 0.0173, 0.1332, 0.0224,
        0.0067, 0.0219], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,866][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0015, 0.8183, 0.0188, 0.1001, 0.0188, 0.0040, 0.0072, 0.0012, 0.0208,
        0.0037, 0.0055], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,869][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([7.0600e-05, 9.0951e-01, 3.9005e-03, 8.0878e-02, 2.6974e-03, 3.0081e-04,
        3.3977e-04, 3.8015e-05, 1.9977e-03, 1.0384e-04, 1.6051e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,872][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0017, 0.1933, 0.0533, 0.0621, 0.0496, 0.0103, 0.1334, 0.0054, 0.2809,
        0.1630, 0.0471], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,876][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.1134, 0.0214, 0.0262, 0.0529, 0.0349, 0.1011, 0.0829, 0.1037, 0.1688,
        0.1549, 0.1400], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,877][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([7.1663e-06, 9.6665e-01, 2.0635e-03, 2.6434e-02, 2.4179e-03, 8.9547e-05,
        3.1887e-04, 7.1987e-06, 1.7725e-03, 8.3824e-05, 1.5691e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:33,877][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([6.2753e-04, 8.8421e-01, 1.8047e-02, 5.9720e-02, 2.4010e-02, 1.8817e-03,
        2.2534e-03, 3.8351e-04, 7.1984e-03, 7.0868e-04, 5.9278e-04, 3.6216e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,878][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([6.2749e-06, 9.8892e-01, 9.7229e-04, 7.3376e-03, 1.6743e-03, 3.1950e-05,
        2.7909e-04, 5.7821e-06, 6.1692e-04, 8.7504e-05, 5.8969e-05, 1.2675e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,880][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0937, 0.3322, 0.0928, 0.1208, 0.1106, 0.0540, 0.0364, 0.0449, 0.0294,
        0.0340, 0.0175, 0.0338], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,883][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0054, 0.6880, 0.0270, 0.1289, 0.0527, 0.0102, 0.0161, 0.0034, 0.0475,
        0.0047, 0.0089, 0.0072], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,887][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.7591, 0.0015, 0.0011, 0.0025, 0.0013, 0.0984, 0.0018, 0.1210, 0.0050,
        0.0033, 0.0032, 0.0018], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,890][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([6.4303e-05, 9.2693e-01, 1.3079e-02, 3.8879e-02, 1.3777e-02, 3.3220e-04,
        1.4038e-03, 5.8798e-05, 3.5182e-03, 7.0994e-04, 6.3071e-04, 6.1577e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,894][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.5747, 0.0111, 0.0033, 0.0178, 0.0029, 0.1959, 0.0160, 0.1264, 0.0188,
        0.0069, 0.0112, 0.0151], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,895][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0018, 0.8120, 0.0224, 0.0888, 0.0240, 0.0045, 0.0071, 0.0013, 0.0222,
        0.0045, 0.0072, 0.0043], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,895][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([4.6579e-05, 9.2051e-01, 2.6205e-03, 7.1191e-02, 2.3789e-03, 2.2018e-04,
        2.3149e-04, 2.4723e-05, 2.4486e-03, 6.6809e-05, 2.0515e-04, 5.4384e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,896][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0031, 0.2486, 0.0549, 0.0699, 0.1127, 0.0116, 0.0922, 0.0067, 0.1958,
        0.1048, 0.0463, 0.0534], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,898][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1217, 0.0157, 0.0309, 0.0326, 0.0416, 0.1030, 0.0665, 0.1084, 0.1311,
        0.1606, 0.0881, 0.0998], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,900][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([3.3473e-06, 9.6398e-01, 1.9605e-03, 2.8662e-02, 3.1359e-03, 4.8018e-05,
        1.8900e-04, 3.4488e-06, 1.7330e-03, 6.7149e-05, 1.6018e-04, 6.0072e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:33,903][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([5.3145e-05, 8.7495e-01, 1.0414e-02, 8.1766e-02, 1.6354e-02, 4.2879e-04,
        2.9605e-03, 8.3683e-05, 9.6650e-03, 1.0567e-03, 1.0496e-03, 1.1096e-03,
        1.0955e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,905][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([2.2225e-06, 9.4260e-01, 1.4258e-03, 4.5330e-02, 4.6290e-03, 4.5659e-05,
        1.0212e-03, 5.7507e-06, 3.6868e-03, 4.1467e-04, 5.6692e-04, 2.4722e-04,
        2.3621e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,909][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.0212, 0.3513, 0.0847, 0.1495, 0.1186, 0.0241, 0.0428, 0.0199, 0.0448,
        0.0489, 0.0265, 0.0419, 0.0258], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,911][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.0023, 0.5758, 0.0399, 0.1650, 0.0704, 0.0083, 0.0279, 0.0026, 0.0645,
        0.0088, 0.0158, 0.0166, 0.0022], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,912][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.5952, 0.0051, 0.0045, 0.0080, 0.0068, 0.1288, 0.0075, 0.1701, 0.0155,
        0.0152, 0.0192, 0.0114, 0.0127], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,913][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([2.0293e-05, 8.8792e-01, 1.5019e-02, 6.4883e-02, 1.7520e-02, 2.1356e-04,
        2.6578e-03, 3.8708e-05, 7.2174e-03, 1.2999e-03, 1.5676e-03, 1.4908e-03,
        1.5244e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,914][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.4550, 0.0233, 0.0088, 0.0254, 0.0089, 0.1917, 0.0218, 0.1464, 0.0276,
        0.0150, 0.0251, 0.0217, 0.0291], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,915][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([6.2826e-04, 6.8708e-01, 2.7649e-02, 1.4172e-01, 4.4328e-02, 2.8646e-03,
        1.6836e-02, 9.7994e-04, 4.6111e-02, 7.5675e-03, 1.1215e-02, 1.1452e-02,
        1.5727e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,917][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([5.0915e-06, 8.9703e-01, 3.1891e-03, 8.9488e-02, 3.6830e-03, 6.8634e-05,
        8.2150e-04, 7.5623e-06, 4.7684e-03, 1.8294e-04, 3.8812e-04, 3.5770e-04,
        1.3310e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,920][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([2.6207e-04, 1.5170e-01, 4.5531e-02, 9.7816e-02, 2.5601e-02, 2.0897e-03,
        8.4731e-02, 8.7618e-04, 2.7865e-01, 4.2215e-02, 7.6441e-02, 1.9040e-01,
        3.6791e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,923][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.0372, 0.0462, 0.0583, 0.0431, 0.0550, 0.0485, 0.0940, 0.0565, 0.1149,
        0.1346, 0.0970, 0.1298, 0.0850], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,925][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([9.9444e-07, 9.4963e-01, 2.3036e-03, 3.9749e-02, 4.0781e-03, 2.4765e-05,
        4.2119e-04, 2.4868e-06, 3.0846e-03, 1.7274e-04, 3.3468e-04, 1.9484e-04,
        7.8868e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:33,928][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([1.4249e-03, 8.6538e-01, 2.0964e-02, 6.0475e-02, 3.1530e-02, 2.8942e-03,
        3.1513e-03, 7.5754e-04, 9.2378e-03, 1.1283e-03, 9.6102e-04, 7.4172e-04,
        1.9121e-04, 1.1582e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,929][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([8.8876e-06, 9.8435e-01, 1.0235e-03, 1.0478e-02, 1.9625e-03, 4.9437e-05,
        4.9675e-04, 9.4714e-06, 1.1663e-03, 1.7600e-04, 1.3108e-04, 5.2625e-05,
        1.0223e-05, 8.2668e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,930][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1072, 0.2859, 0.0871, 0.1032, 0.0915, 0.0518, 0.0311, 0.0527, 0.0317,
        0.0393, 0.0174, 0.0279, 0.0286, 0.0445], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,931][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0047, 0.6566, 0.0261, 0.1247, 0.0530, 0.0101, 0.0217, 0.0032, 0.0605,
        0.0058, 0.0108, 0.0120, 0.0014, 0.0095], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,932][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([7.6724e-01, 1.0212e-03, 6.5635e-04, 1.8768e-03, 1.3077e-03, 9.0311e-02,
        1.8816e-03, 1.1373e-01, 5.1440e-03, 2.9913e-03, 3.4934e-03, 2.2077e-03,
        3.0578e-03, 5.0764e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,933][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([9.5273e-05, 9.2287e-01, 1.4368e-02, 4.1190e-02, 1.2033e-02, 3.9316e-04,
        1.5818e-03, 8.3110e-05, 3.8534e-03, 9.4308e-04, 7.6991e-04, 8.4949e-04,
        1.0428e-04, 8.6698e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,936][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.4880, 0.0187, 0.0048, 0.0230, 0.0041, 0.1787, 0.0185, 0.1279, 0.0263,
        0.0097, 0.0177, 0.0145, 0.0165, 0.0514], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,941][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0016, 0.7897, 0.0190, 0.1005, 0.0214, 0.0039, 0.0092, 0.0013, 0.0294,
        0.0044, 0.0078, 0.0062, 0.0009, 0.0048], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,943][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([8.7618e-05, 9.3563e-01, 3.0126e-03, 5.5522e-02, 2.2883e-03, 2.9097e-04,
        3.9715e-04, 4.4029e-05, 2.0786e-03, 1.2087e-04, 1.9743e-04, 1.3438e-04,
        2.0380e-05, 1.7889e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,947][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0005, 0.3090, 0.0362, 0.0613, 0.0447, 0.0036, 0.1219, 0.0018, 0.1699,
        0.0818, 0.0347, 0.0925, 0.0140, 0.0281], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,948][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0740, 0.0160, 0.0175, 0.0290, 0.0412, 0.0715, 0.0719, 0.0772, 0.1048,
        0.1427, 0.0937, 0.1015, 0.1012, 0.0578], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,949][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([1.4292e-05, 9.4976e-01, 2.6684e-03, 3.8962e-02, 4.2981e-03, 1.2979e-04,
        4.6616e-04, 1.3480e-05, 2.7575e-03, 1.4585e-04, 3.4804e-04, 1.8134e-04,
        7.4072e-06, 2.4754e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:33,950][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([1.9489e-03, 8.2276e-01, 2.4696e-02, 7.1059e-02, 4.6106e-02, 3.9097e-03,
        3.9160e-03, 1.1180e-03, 1.3420e-02, 2.0002e-03, 1.7086e-03, 1.6555e-03,
        5.2751e-04, 3.3978e-03, 1.7777e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,951][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([1.1347e-04, 9.3858e-01, 7.1353e-03, 3.1079e-02, 1.2735e-02, 5.0677e-04,
        2.4402e-03, 1.1107e-04, 3.6802e-03, 1.0203e-03, 6.1999e-04, 4.5397e-04,
        1.1787e-04, 8.7610e-04, 5.3544e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,954][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.0683, 0.2459, 0.0789, 0.1281, 0.0937, 0.0497, 0.0434, 0.0430, 0.0370,
        0.0423, 0.0200, 0.0385, 0.0290, 0.0515, 0.0307], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,958][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.0157, 0.4717, 0.0499, 0.1448, 0.0766, 0.0296, 0.0371, 0.0101, 0.0682,
        0.0135, 0.0223, 0.0211, 0.0047, 0.0215, 0.0132], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,961][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([7.7861e-01, 4.3074e-04, 9.6740e-04, 9.1045e-04, 1.1039e-03, 8.6920e-02,
        1.1850e-03, 1.1729e-01, 1.3901e-03, 1.5402e-03, 1.6112e-03, 1.0152e-03,
        2.2666e-03, 1.9229e-03, 2.8381e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,963][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([4.3347e-04, 8.1668e-01, 3.6377e-02, 7.7928e-02, 4.0015e-02, 1.5629e-03,
        4.4252e-03, 3.6210e-04, 9.5573e-03, 2.7366e-03, 2.1235e-03, 2.2644e-03,
        4.4624e-04, 2.6648e-03, 2.4257e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,965][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.5277, 0.0069, 0.0068, 0.0155, 0.0056, 0.1843, 0.0168, 0.1325, 0.0148,
        0.0070, 0.0145, 0.0106, 0.0123, 0.0249, 0.0199], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,966][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.0069, 0.6626, 0.0463, 0.1005, 0.0476, 0.0127, 0.0149, 0.0046, 0.0352,
        0.0094, 0.0156, 0.0123, 0.0036, 0.0172, 0.0105], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,967][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([5.6219e-04, 8.3922e-01, 5.8649e-03, 1.3187e-01, 7.0374e-03, 1.5650e-03,
        1.3009e-03, 2.4234e-04, 8.4048e-03, 5.3575e-04, 9.2142e-04, 5.4302e-04,
        1.1533e-04, 1.4791e-03, 3.3765e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,969][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.0007, 0.2323, 0.0182, 0.0829, 0.0457, 0.0049, 0.1108, 0.0022, 0.1727,
        0.0522, 0.0601, 0.1194, 0.0105, 0.0775, 0.0099], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,971][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0962, 0.0139, 0.0364, 0.0265, 0.0419, 0.0782, 0.0567, 0.0880, 0.0721,
        0.0938, 0.0806, 0.0735, 0.1062, 0.0608, 0.0752], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,974][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([3.0168e-05, 9.2671e-01, 5.2359e-03, 5.1842e-02, 6.6734e-03, 2.5473e-04,
        8.2578e-04, 3.1280e-05, 5.7046e-03, 3.4572e-04, 6.8690e-04, 3.8650e-04,
        3.1529e-05, 9.4873e-04, 2.9030e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:33,978][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0012, 0.5900, 0.0511, 0.1230, 0.0895, 0.0049, 0.0190, 0.0020, 0.0404,
        0.0146, 0.0127, 0.0145, 0.0040, 0.0177, 0.0122, 0.0033],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,980][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([1.4491e-05, 8.9055e-01, 7.2476e-03, 5.2674e-02, 1.7776e-02, 1.9175e-04,
        6.8925e-03, 4.9880e-05, 9.3461e-03, 3.4645e-03, 3.4682e-03, 2.7942e-03,
        5.5346e-04, 3.4343e-03, 1.4352e-03, 1.0344e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,982][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0085, 0.2447, 0.0860, 0.1070, 0.0987, 0.0166, 0.0662, 0.0116, 0.0391,
        0.0454, 0.0353, 0.0628, 0.0379, 0.0720, 0.0527, 0.0155],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,983][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0036, 0.3767, 0.0561, 0.1465, 0.0943, 0.0115, 0.0492, 0.0053, 0.0752,
        0.0256, 0.0370, 0.0425, 0.0108, 0.0326, 0.0250, 0.0081],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,984][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.2333, 0.0259, 0.0183, 0.0290, 0.0215, 0.1170, 0.0311, 0.1169, 0.0484,
        0.0356, 0.0440, 0.0417, 0.0342, 0.0434, 0.0347, 0.1250],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,985][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([2.8295e-04, 6.5359e-01, 5.0377e-02, 1.1897e-01, 6.2110e-02, 1.7735e-03,
        1.7523e-02, 6.2418e-04, 3.0394e-02, 1.2465e-02, 1.1941e-02, 1.3278e-02,
        3.1309e-03, 1.2757e-02, 9.6523e-03, 1.1345e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,987][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0930, 0.0983, 0.0259, 0.0626, 0.0205, 0.0885, 0.0498, 0.0650, 0.0553,
        0.0327, 0.0493, 0.0564, 0.0388, 0.1057, 0.0544, 0.1036],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,990][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0015, 0.4785, 0.0512, 0.1410, 0.0663, 0.0061, 0.0343, 0.0028, 0.0656,
        0.0230, 0.0327, 0.0327, 0.0079, 0.0290, 0.0231, 0.0043],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,992][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([2.3367e-04, 7.3041e-01, 2.2574e-02, 1.4059e-01, 3.4280e-02, 1.4210e-03,
        9.9317e-03, 4.1400e-04, 2.7991e-02, 3.9791e-03, 7.3830e-03, 6.8428e-03,
        1.2214e-03, 8.5185e-03, 3.4339e-03, 7.7764e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,994][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([8.0652e-06, 4.0595e-01, 1.4660e-02, 1.4467e-01, 1.8323e-02, 1.5324e-04,
        6.2115e-02, 5.6419e-05, 1.3417e-01, 1.2072e-02, 6.3828e-02, 1.0107e-01,
        2.1737e-03, 3.6616e-02, 4.0577e-03, 7.5575e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:33,999][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0064, 0.1038, 0.0504, 0.0665, 0.0616, 0.0152, 0.0747, 0.0133, 0.1038,
        0.0941, 0.0826, 0.1100, 0.0511, 0.0875, 0.0617, 0.0173],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:34,001][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([1.1846e-04, 7.4571e-01, 2.9948e-02, 1.0575e-01, 5.2106e-02, 1.0226e-03,
        8.5289e-03, 2.5903e-04, 2.5439e-02, 4.7978e-03, 7.7247e-03, 6.1927e-03,
        8.9427e-04, 6.4540e-03, 4.5115e-03, 5.4375e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:34,002][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0011, 0.7472, 0.0357, 0.0947, 0.0563, 0.0037, 0.0072, 0.0011, 0.0232,
        0.0045, 0.0043, 0.0038, 0.0011, 0.0063, 0.0042, 0.0020, 0.0035],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,003][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.1224e-05, 9.3976e-01, 4.4016e-03, 3.4377e-02, 9.1991e-03, 1.2152e-04,
        2.2800e-03, 2.8734e-05, 5.1116e-03, 1.1843e-03, 1.0445e-03, 6.4518e-04,
        1.3306e-04, 9.2983e-04, 4.6057e-04, 5.6044e-05, 2.5239e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,004][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0234, 0.2711, 0.0825, 0.1087, 0.0919, 0.0262, 0.0476, 0.0198, 0.0330,
        0.0372, 0.0247, 0.0431, 0.0285, 0.0566, 0.0421, 0.0265, 0.0371],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,007][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0046, 0.5163, 0.0459, 0.1305, 0.0730, 0.0116, 0.0302, 0.0047, 0.0591,
        0.0128, 0.0224, 0.0236, 0.0047, 0.0216, 0.0134, 0.0083, 0.0174],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,011][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.3694, 0.0098, 0.0069, 0.0127, 0.0084, 0.1151, 0.0112, 0.1283, 0.0214,
        0.0163, 0.0179, 0.0131, 0.0144, 0.0197, 0.0169, 0.1387, 0.0796],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,014][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.8191e-04, 7.9728e-01, 3.2880e-02, 8.6099e-02, 3.4921e-02, 1.0228e-03,
        7.1622e-03, 2.8079e-04, 1.5317e-02, 4.6803e-03, 4.4381e-03, 4.5252e-03,
        7.8720e-04, 4.8436e-03, 3.5175e-03, 5.3862e-04, 1.5204e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,018][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1568, 0.0411, 0.0145, 0.0391, 0.0106, 0.1063, 0.0352, 0.0769, 0.0382,
        0.0200, 0.0332, 0.0334, 0.0270, 0.0711, 0.0365, 0.1261, 0.1337],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,019][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0017, 0.6165, 0.0367, 0.1259, 0.0427, 0.0061, 0.0192, 0.0023, 0.0507,
        0.0134, 0.0206, 0.0172, 0.0038, 0.0184, 0.0124, 0.0040, 0.0086],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,020][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.5224e-04, 8.5754e-01, 1.0652e-02, 9.6766e-02, 1.3115e-02, 7.2467e-04,
        2.0398e-03, 1.6170e-04, 1.0671e-02, 8.9062e-04, 1.8948e-03, 1.0459e-03,
        2.1869e-04, 2.2154e-03, 7.2796e-04, 3.4747e-04, 8.3520e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,021][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.2342e-05, 4.2900e-01, 1.6341e-02, 1.3061e-01, 2.1926e-02, 3.7653e-04,
        5.6831e-02, 1.5233e-04, 1.1732e-01, 2.8335e-02, 4.9100e-02, 9.9767e-02,
        3.0146e-03, 3.9660e-02, 5.8571e-03, 2.1893e-04, 1.4673e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,023][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0176, 0.0460, 0.0361, 0.0447, 0.0482, 0.0267, 0.0635, 0.0263, 0.1063,
        0.0942, 0.0894, 0.1001, 0.0637, 0.0804, 0.0640, 0.0380, 0.0549],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,025][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([4.1048e-05, 8.6235e-01, 1.2673e-02, 8.4833e-02, 1.9082e-02, 3.9936e-04,
        2.1322e-03, 6.3105e-05, 1.0452e-02, 1.1700e-03, 2.1091e-03, 1.2299e-03,
        1.3996e-04, 1.7134e-03, 9.3484e-04, 1.7979e-04, 5.0190e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,027][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([9.5926e-05, 9.2394e-01, 7.0730e-03, 4.3134e-02, 1.4118e-02, 4.7718e-04,
        1.4028e-03, 8.4592e-05, 5.7586e-03, 4.4017e-04, 4.8842e-04, 4.7638e-04,
        6.1595e-05, 8.9581e-04, 4.0748e-04, 2.1389e-04, 5.4393e-04, 3.9062e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,030][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([5.7607e-06, 9.8046e-01, 9.7212e-04, 1.4191e-02, 2.1770e-03, 3.3258e-05,
        3.5707e-04, 6.6233e-06, 1.0799e-03, 1.3821e-04, 1.3272e-04, 6.0744e-05,
        1.0567e-05, 1.4169e-04, 6.0115e-05, 1.5730e-05, 7.6306e-05, 8.4602e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,034][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([0.0369, 0.2048, 0.0804, 0.1618, 0.0876, 0.0384, 0.0393, 0.0246, 0.0376,
        0.0305, 0.0218, 0.0328, 0.0165, 0.0474, 0.0307, 0.0398, 0.0437, 0.0254],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,036][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([0.0044, 0.6037, 0.0302, 0.1381, 0.0582, 0.0107, 0.0191, 0.0034, 0.0544,
        0.0073, 0.0112, 0.0105, 0.0020, 0.0111, 0.0069, 0.0074, 0.0161, 0.0052],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,037][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([0.4920, 0.0102, 0.0057, 0.0068, 0.0089, 0.1066, 0.0050, 0.1355, 0.0086,
        0.0085, 0.0071, 0.0037, 0.0090, 0.0107, 0.0073, 0.1171, 0.0514, 0.0058],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,038][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([8.1377e-05, 8.9651e-01, 1.5155e-02, 5.2780e-02, 2.3349e-02, 3.6106e-04,
        1.5295e-03, 8.0819e-05, 4.2797e-03, 9.7718e-04, 8.3884e-04, 7.2945e-04,
        1.3089e-04, 1.0664e-03, 7.7623e-04, 1.7595e-04, 4.8363e-04, 6.9301e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,040][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([0.2961, 0.0150, 0.0058, 0.0191, 0.0053, 0.1362, 0.0218, 0.0936, 0.0216,
        0.0096, 0.0160, 0.0168, 0.0153, 0.0334, 0.0157, 0.1438, 0.1211, 0.0137],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,042][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([0.0012, 0.7748, 0.0189, 0.0953, 0.0255, 0.0034, 0.0078, 0.0010, 0.0261,
        0.0044, 0.0084, 0.0064, 0.0010, 0.0099, 0.0043, 0.0023, 0.0061, 0.0030],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,045][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([2.0817e-05, 9.4133e-01, 1.8384e-03, 4.9526e-02, 2.2531e-03, 1.3382e-04,
        3.9640e-04, 1.2691e-05, 3.4825e-03, 8.7348e-05, 1.5494e-04, 1.0783e-04,
        1.3207e-05, 3.3746e-04, 5.9052e-05, 4.9860e-05, 1.6940e-04, 2.5075e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,049][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([0.0033, 0.2795, 0.0229, 0.0518, 0.1003, 0.0066, 0.1081, 0.0052, 0.1486,
        0.0723, 0.0419, 0.0612, 0.0212, 0.0362, 0.0147, 0.0076, 0.0129, 0.0057],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,053][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([0.0260, 0.0268, 0.0219, 0.0367, 0.0323, 0.0360, 0.0770, 0.0372, 0.0848,
        0.0908, 0.0675, 0.0915, 0.0730, 0.0707, 0.0507, 0.0552, 0.0814, 0.0406],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,054][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([4.6454e-06, 9.5701e-01, 2.4757e-03, 3.2912e-02, 4.6364e-03, 4.7965e-05,
        2.3095e-04, 5.1861e-06, 1.7998e-03, 1.1310e-04, 1.5120e-04, 9.0951e-05,
        5.4325e-06, 2.8181e-04, 8.1571e-05, 1.9632e-05, 7.7901e-05, 5.8627e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,055][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.8447e-03, 8.9105e-01, 1.8807e-02, 3.6498e-02, 2.3981e-02, 4.4620e-03,
        2.8360e-03, 1.1603e-03, 6.6547e-03, 8.9757e-04, 6.5607e-04, 5.5649e-04,
        1.6832e-04, 1.0109e-03, 7.8707e-04, 2.2679e-03, 2.7367e-03, 5.5119e-04,
        2.0740e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,056][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.2525e-05, 9.8583e-01, 1.1648e-03, 8.6152e-03, 2.1106e-03, 8.0802e-05,
        4.0744e-04, 1.8574e-05, 9.1879e-04, 1.7080e-04, 9.8126e-05, 4.0558e-05,
        1.1187e-05, 9.2778e-05, 4.6172e-05, 3.4878e-05, 1.0903e-04, 4.8580e-05,
        1.8119e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,058][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0812, 0.2537, 0.0751, 0.0932, 0.0678, 0.0452, 0.0306, 0.0416, 0.0237,
        0.0313, 0.0153, 0.0259, 0.0164, 0.0362, 0.0254, 0.0462, 0.0451, 0.0218,
        0.0243], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,061][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0116, 0.6289, 0.0278, 0.1034, 0.0430, 0.0188, 0.0170, 0.0061, 0.0432,
        0.0054, 0.0104, 0.0089, 0.0016, 0.0094, 0.0056, 0.0129, 0.0218, 0.0035,
        0.0206], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,063][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([6.0791e-01, 5.7425e-04, 4.6023e-04, 1.3198e-03, 6.8782e-04, 8.4027e-02,
        1.9931e-03, 1.0870e-01, 4.0828e-03, 3.0040e-03, 3.9241e-03, 2.3123e-03,
        2.4106e-03, 3.3241e-03, 2.5160e-03, 1.1589e-01, 4.9946e-02, 1.9404e-03,
        4.9820e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,065][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.8613e-04, 8.9105e-01, 2.1352e-02, 5.0158e-02, 1.5977e-02, 9.2468e-04,
        2.6285e-03, 2.0069e-04, 5.1969e-03, 1.3088e-03, 1.1830e-03, 1.2728e-03,
        1.8411e-04, 1.5744e-03, 1.2086e-03, 4.3225e-04, 1.0182e-03, 1.0260e-03,
        3.0207e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,069][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.4202, 0.0040, 0.0024, 0.0079, 0.0017, 0.1137, 0.0079, 0.0860, 0.0105,
        0.0036, 0.0097, 0.0060, 0.0090, 0.0244, 0.0085, 0.1601, 0.0980, 0.0050,
        0.0212], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,072][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0031, 0.7796, 0.0154, 0.0913, 0.0153, 0.0066, 0.0088, 0.0021, 0.0247,
        0.0038, 0.0076, 0.0051, 0.0008, 0.0051, 0.0028, 0.0040, 0.0070, 0.0027,
        0.0141], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,073][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([3.9755e-04, 9.1391e-01, 4.2006e-03, 7.2150e-02, 2.3716e-03, 9.1559e-04,
        4.9445e-04, 1.3935e-04, 2.7991e-03, 1.3759e-04, 2.5172e-04, 1.4855e-04,
        3.2234e-05, 2.7073e-04, 9.3710e-05, 3.6734e-04, 5.3884e-04, 6.3343e-05,
        7.1516e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,074][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0024, 0.1097, 0.0469, 0.0621, 0.0449, 0.0103, 0.1071, 0.0064, 0.1778,
        0.0959, 0.0397, 0.1066, 0.0192, 0.0558, 0.0391, 0.0080, 0.0172, 0.0225,
        0.0284], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,076][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0567, 0.0080, 0.0215, 0.0189, 0.0267, 0.0608, 0.0438, 0.0573, 0.0755,
        0.0901, 0.0555, 0.0599, 0.0761, 0.0386, 0.0480, 0.0928, 0.0868, 0.0268,
        0.0563], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,078][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([3.4907e-05, 9.5136e-01, 3.2770e-03, 3.5981e-02, 3.5392e-03, 2.3215e-04,
        4.9565e-04, 2.4763e-05, 2.5882e-03, 1.2635e-04, 3.0781e-04, 1.4844e-04,
        9.1867e-06, 2.8199e-04, 8.6804e-05, 8.8828e-05, 2.4167e-04, 5.6299e-05,
        1.1183e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,081][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:34,084][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[5628],
        [1388],
        [2881],
        [2282],
        [8390],
        [1696],
        [ 686],
        [1400],
        [1992],
        [1979],
        [1461],
        [ 444],
        [ 631],
        [ 986],
        [1565],
        [ 868],
        [ 260],
        [ 431],
        [ 541]], device='cuda:0')
[2024-07-24 10:27:34,087][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 6901],
        [ 3179],
        [ 4971],
        [ 5085],
        [15477],
        [ 4429],
        [ 1995],
        [ 3088],
        [ 3655],
        [ 2939],
        [ 2279],
        [  812],
        [ 1587],
        [ 1738],
        [ 2354],
        [ 1728],
        [  555],
        [ 1023],
        [ 1037]], device='cuda:0')
[2024-07-24 10:27:34,089][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[36336],
        [36501],
        [37947],
        [37379],
        [38429],
        [40625],
        [40214],
        [43044],
        [41251],
        [43195],
        [41994],
        [42655],
        [42841],
        [42731],
        [44231],
        [43008],
        [43180],
        [43980],
        [43341]], device='cuda:0')
[2024-07-24 10:27:34,092][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[3614],
        [6555],
        [7247],
        [6734],
        [7166],
        [6732],
        [6829],
        [6205],
        [6352],
        [5757],
        [6103],
        [6354],
        [4668],
        [6161],
        [6307],
        [5496],
        [5936],
        [5653],
        [6264]], device='cuda:0')
[2024-07-24 10:27:34,094][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 6833],
        [31051],
        [26516],
        [27400],
        [27050],
        [27188],
        [25244],
        [25873],
        [26083],
        [25441],
        [25825],
        [25927],
        [26270],
        [26451],
        [26885],
        [26718],
        [26034],
        [26115],
        [25950]], device='cuda:0')
[2024-07-24 10:27:34,095][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[14466],
        [34175],
        [28652],
        [34190],
        [31187],
        [33658],
        [33101],
        [33893],
        [33768],
        [34405],
        [34925],
        [34786],
        [35131],
        [34935],
        [34461],
        [34749],
        [34251],
        [34588],
        [34181]], device='cuda:0')
[2024-07-24 10:27:34,097][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[1898],
        [1560],
        [1360],
        [1175],
        [1400],
        [1232],
        [1156],
        [1147],
        [1170],
        [1252],
        [1211],
        [1219],
        [1256],
        [1266],
        [1312],
        [1336],
        [1337],
        [1345],
        [1287]], device='cuda:0')
[2024-07-24 10:27:34,099][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[16808],
        [ 9867],
        [ 8809],
        [ 6959],
        [ 6651],
        [ 6215],
        [ 6368],
        [ 6472],
        [ 6345],
        [ 6241],
        [ 6122],
        [ 6177],
        [ 6185],
        [ 6060],
        [ 5948],
        [ 5941],
        [ 5926],
        [ 5848],
        [ 5804]], device='cuda:0')
[2024-07-24 10:27:34,102][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 5934],
        [ 6929],
        [ 7224],
        [ 9037],
        [11283],
        [ 9233],
        [ 8424],
        [ 8671],
        [ 7453],
        [ 7976],
        [ 8643],
        [ 7913],
        [ 7790],
        [ 7937],
        [ 7853],
        [ 8188],
        [ 7749],
        [ 8570],
        [ 8688]], device='cuda:0')
[2024-07-24 10:27:34,105][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[13446],
        [26816],
        [28348],
        [28014],
        [30752],
        [31814],
        [29654],
        [32924],
        [28667],
        [29137],
        [28946],
        [29025],
        [30359],
        [29113],
        [30428],
        [32193],
        [30633],
        [29211],
        [28902]], device='cuda:0')
[2024-07-24 10:27:34,108][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 9964],
        [38687],
        [39699],
        [39950],
        [39738],
        [39531],
        [39850],
        [39555],
        [39865],
        [39908],
        [39831],
        [39861],
        [39812],
        [39904],
        [39621],
        [39576],
        [39735],
        [39938],
        [39848]], device='cuda:0')
[2024-07-24 10:27:34,110][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[27453],
        [28124],
        [30510],
        [30708],
        [34993],
        [33833],
        [34621],
        [33579],
        [34243],
        [33291],
        [32746],
        [32617],
        [32343],
        [32419],
        [32479],
        [32216],
        [32291],
        [32146],
        [32020]], device='cuda:0')
[2024-07-24 10:27:34,113][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[18558],
        [18480],
        [18512],
        [18503],
        [18529],
        [18426],
        [18496],
        [18026],
        [18454],
        [18389],
        [18418],
        [18415],
        [18091],
        [18308],
        [18329],
        [17819],
        [18347],
        [18248],
        [18367]], device='cuda:0')
[2024-07-24 10:27:34,115][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[30069],
        [14911],
        [11243],
        [10335],
        [ 9757],
        [10160],
        [ 9948],
        [ 9935],
        [10277],
        [ 9937],
        [10049],
        [10321],
        [10267],
        [10513],
        [10314],
        [10535],
        [10636],
        [10637],
        [10704]], device='cuda:0')
[2024-07-24 10:27:34,116][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[7306],
        [5147],
        [7191],
        [5494],
        [6262],
        [5815],
        [3824],
        [7540],
        [3365],
        [8757],
        [5558],
        [3704],
        [3852],
        [3155],
        [5605],
        [5046],
        [3994],
        [3972],
        [3414]], device='cuda:0')
[2024-07-24 10:27:34,118][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[18132],
        [19878],
        [21116],
        [21179],
        [21564],
        [22330],
        [21398],
        [22627],
        [21302],
        [21259],
        [21160],
        [21292],
        [21427],
        [21370],
        [21579],
        [23452],
        [22047],
        [21107],
        [21213]], device='cuda:0')
[2024-07-24 10:27:34,120][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[27049],
        [28167],
        [27934],
        [28190],
        [28243],
        [28231],
        [28243],
        [28395],
        [28242],
        [28348],
        [28271],
        [28226],
        [28617],
        [28253],
        [28342],
        [28646],
        [28453],
        [28290],
        [28238]], device='cuda:0')
[2024-07-24 10:27:34,123][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 7324],
        [ 3717],
        [23936],
        [25477],
        [26561],
        [33701],
        [31116],
        [33177],
        [32392],
        [32943],
        [34872],
        [33153],
        [33522],
        [34065],
        [34076],
        [34203],
        [33790],
        [33263],
        [33762]], device='cuda:0')
[2024-07-24 10:27:34,126][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[13599],
        [35701],
        [37768],
        [39137],
        [42503],
        [42071],
        [40870],
        [43227],
        [40482],
        [41296],
        [41862],
        [40457],
        [42097],
        [40919],
        [43442],
        [45046],
        [42875],
        [41527],
        [41048]], device='cuda:0')
[2024-07-24 10:27:34,128][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[12630],
        [12631],
        [12666],
        [12723],
        [12744],
        [23485],
        [17402],
        [25014],
        [24190],
        [27221],
        [23891],
        [23914],
        [26950],
        [23739],
        [22840],
        [23775],
        [23340],
        [26450],
        [23657]], device='cuda:0')
[2024-07-24 10:27:34,131][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 3406],
        [15662],
        [15045],
        [15625],
        [15139],
        [14118],
        [15487],
        [14097],
        [15562],
        [15497],
        [15577],
        [15580],
        [15560],
        [15614],
        [14975],
        [14049],
        [15049],
        [15443],
        [15479]], device='cuda:0')
[2024-07-24 10:27:34,134][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[44114],
        [44216],
        [44099],
        [42519],
        [43136],
        [14532],
        [38212],
        [13296],
        [33841],
        [28063],
        [29850],
        [30837],
        [24542],
        [25596],
        [27615],
        [15194],
        [17928],
        [22720],
        [25027]], device='cuda:0')
[2024-07-24 10:27:34,135][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[28701],
        [17055],
        [17007],
        [16491],
        [18340],
        [18993],
        [17918],
        [20964],
        [17882],
        [18424],
        [18197],
        [18484],
        [21109],
        [19132],
        [22167],
        [27948],
        [23815],
        [19681],
        [19783]], device='cuda:0')
[2024-07-24 10:27:34,137][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[11309],
        [ 4090],
        [ 4135],
        [ 4019],
        [ 3754],
        [ 3321],
        [ 3833],
        [ 3260],
        [ 3867],
        [ 3903],
        [ 3804],
        [ 3850],
        [ 3756],
        [ 3900],
        [ 3542],
        [ 3257],
        [ 3626],
        [ 3934],
        [ 3838]], device='cuda:0')
[2024-07-24 10:27:34,139][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[34529],
        [20431],
        [20221],
        [21493],
        [20914],
        [22608],
        [21842],
        [22501],
        [21329],
        [21496],
        [23011],
        [22632],
        [24784],
        [23230],
        [24189],
        [24224],
        [23958],
        [23089],
        [24957]], device='cuda:0')
[2024-07-24 10:27:34,141][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[32048],
        [31262],
        [21395],
        [23810],
        [22688],
        [16540],
        [23506],
        [18131],
        [32625],
        [26061],
        [30409],
        [29367],
        [26974],
        [27410],
        [25557],
        [26234],
        [27260],
        [27221],
        [26846]], device='cuda:0')
[2024-07-24 10:27:34,144][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[12763],
        [39411],
        [39584],
        [39442],
        [39490],
        [39871],
        [39473],
        [40089],
        [39482],
        [39484],
        [39462],
        [39460],
        [39486],
        [39486],
        [39552],
        [40314],
        [39735],
        [39468],
        [39497]], device='cuda:0')
[2024-07-24 10:27:34,146][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[30195],
        [18342],
        [16060],
        [16389],
        [15169],
        [18276],
        [14727],
        [17220],
        [12208],
        [13259],
        [12098],
        [12740],
        [12397],
        [13011],
        [12536],
        [12985],
        [13272],
        [12863],
        [12656]], device='cuda:0')
[2024-07-24 10:27:34,149][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[41959],
        [40186],
        [35615],
        [32321],
        [32656],
        [35381],
        [36565],
        [33229],
        [38668],
        [32275],
        [34549],
        [38176],
        [37796],
        [39496],
        [35086],
        [36757],
        [38604],
        [38837],
        [39942]], device='cuda:0')
[2024-07-24 10:27:34,152][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250]], device='cuda:0')
[2024-07-24 10:27:34,220][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:34,221][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,222][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,222][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,223][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,224][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,225][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,226][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,226][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,227][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,227][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,228][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,229][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,230][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0134, 0.9866], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,230][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1608, 0.8392], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,231][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0072, 0.9928], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,233][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3891, 0.6109], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,236][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1821, 0.8179], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,240][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2676, 0.7324], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,244][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.8609, 0.1391], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,245][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0428, 0.9572], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,246][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2694, 0.7306], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,247][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0722, 0.9278], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,248][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1178, 0.8822], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,248][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1818, 0.8182], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,249][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([1.5740e-04, 9.9481e-01, 5.0285e-03], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,252][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.1280, 0.4381, 0.4340], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,256][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.0069, 0.5024, 0.4908], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,259][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0816, 0.7162, 0.2022], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,263][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.0431, 0.6354, 0.3214], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,264][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0963, 0.4808, 0.4229], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,265][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.4642, 0.2133, 0.3225], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,265][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.0360, 0.9114, 0.0526], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,266][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.0909, 0.5626, 0.3465], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,268][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0437, 0.4430, 0.5133], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,271][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.0743, 0.3208, 0.6049], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,275][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.2773, 0.4190, 0.3037], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,277][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([1.3400e-05, 9.9597e-01, 1.6703e-03, 2.3430e-03], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,281][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0554, 0.3138, 0.3080, 0.3228], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,282][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0027, 0.3408, 0.3398, 0.3168], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,282][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1307, 0.4615, 0.1452, 0.2626], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,283][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0445, 0.4422, 0.2630, 0.2502], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,284][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0939, 0.3144, 0.2967, 0.2949], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,286][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3906, 0.1773, 0.3507, 0.0814], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,289][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0023, 0.8910, 0.0401, 0.0666], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,293][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1120, 0.3605, 0.2419, 0.2855], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,297][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0267, 0.2950, 0.3452, 0.3332], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,299][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0131, 0.2090, 0.5747, 0.2032], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,300][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0692, 0.4158, 0.3006, 0.2144], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,301][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([9.6481e-06, 9.9130e-01, 1.3973e-03, 5.9453e-03, 1.3440e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,302][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([0.0565, 0.2398, 0.2289, 0.2473, 0.2275], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,302][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.0037, 0.2621, 0.2543, 0.2396, 0.2403], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,304][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.0665, 0.4132, 0.1006, 0.2617, 0.1580], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,308][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.0277, 0.3484, 0.1785, 0.2018, 0.2437], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,311][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([0.0503, 0.2539, 0.2211, 0.2387, 0.2360], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,315][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.2561, 0.1663, 0.2359, 0.0761, 0.2656], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,317][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.0314, 0.6951, 0.0933, 0.1017, 0.0785], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,318][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.0683, 0.2914, 0.1821, 0.2362, 0.2220], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,319][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.0226, 0.2152, 0.2444, 0.2422, 0.2756], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,320][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.0597, 0.2195, 0.4445, 0.1295, 0.1469], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,320][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([0.2192, 0.3643, 0.1417, 0.1208, 0.1540], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,322][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ had] are: tensor([9.3537e-06, 8.7791e-01, 2.2291e-02, 5.3580e-02, 4.6101e-02, 1.1108e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,324][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0070, 0.2155, 0.1990, 0.2560, 0.2102, 0.1122], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,329][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0006, 0.2361, 0.2280, 0.2124, 0.2144, 0.1086], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,333][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0328, 0.3368, 0.0700, 0.2403, 0.1044, 0.2158], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,335][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0100, 0.3280, 0.1601, 0.1803, 0.2327, 0.0888], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,336][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0439, 0.2060, 0.1857, 0.2015, 0.2068, 0.1561], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,337][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2573, 0.1368, 0.2765, 0.0663, 0.2299, 0.0333], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,338][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ had] are: tensor([3.3560e-04, 7.6792e-01, 7.8327e-02, 5.2131e-02, 1.0077e-01, 5.1654e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,339][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0372, 0.2697, 0.1665, 0.2176, 0.1991, 0.1099], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,340][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0058, 0.1981, 0.2448, 0.2304, 0.3017, 0.0193], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,342][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ had] are: tensor([1.9447e-04, 1.6964e-01, 4.7717e-01, 2.0276e-01, 1.5012e-01, 1.3151e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,347][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0008, 0.5073, 0.0882, 0.2719, 0.1286, 0.0033], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,349][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([1.9815e-07, 9.8982e-01, 8.1208e-04, 7.9815e-03, 1.3802e-03, 2.8145e-06,
        3.4205e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,353][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0273, 0.1688, 0.1641, 0.1812, 0.1681, 0.1167, 0.1738],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,354][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0024, 0.1849, 0.1793, 0.1716, 0.1733, 0.1063, 0.1821],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,355][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0695, 0.2725, 0.0928, 0.1996, 0.1084, 0.1494, 0.1077],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,355][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0119, 0.2636, 0.1412, 0.1719, 0.1869, 0.0871, 0.1375],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,356][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0430, 0.1722, 0.1600, 0.1693, 0.1756, 0.1367, 0.1431],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,358][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3468, 0.1336, 0.1890, 0.0561, 0.1913, 0.0315, 0.0516],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,361][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0084, 0.7046, 0.0904, 0.0649, 0.0927, 0.0099, 0.0291],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,365][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0503, 0.2211, 0.1423, 0.1821, 0.1626, 0.1082, 0.1334],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,369][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0147, 0.1724, 0.2004, 0.1959, 0.2415, 0.0314, 0.1437],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,372][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0181, 0.1157, 0.4136, 0.1246, 0.1529, 0.0221, 0.1529],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,372][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1613, 0.1294, 0.1184, 0.1135, 0.1187, 0.2058, 0.1529],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,373][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([1.7246e-06, 8.4277e-01, 1.5831e-02, 8.8389e-02, 4.9381e-02, 6.2460e-05,
        3.5529e-03, 8.6737e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,374][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0031, 0.1700, 0.1395, 0.2160, 0.1649, 0.0829, 0.1897, 0.0339],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,375][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([1.7403e-04, 1.9089e-01, 1.7446e-01, 1.6751e-01, 1.6935e-01, 7.4579e-02,
        1.8382e-01, 3.9215e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,377][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0104, 0.3011, 0.0827, 0.2058, 0.1113, 0.1462, 0.1081, 0.0344],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,380][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0022, 0.2370, 0.1297, 0.1459, 0.2136, 0.0895, 0.1539, 0.0283],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,383][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0216, 0.1718, 0.1456, 0.1597, 0.1618, 0.1194, 0.1306, 0.0895],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,388][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.1929, 0.1381, 0.1992, 0.0796, 0.1984, 0.0404, 0.0818, 0.0696],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,390][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([2.3194e-04, 7.6765e-01, 6.0109e-02, 5.6794e-02, 9.3496e-02, 4.5493e-04,
        2.0916e-02, 3.5087e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,391][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0152, 0.2460, 0.1293, 0.1957, 0.1647, 0.0894, 0.1233, 0.0364],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,391][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0032, 0.1738, 0.2043, 0.1994, 0.2494, 0.0201, 0.1339, 0.0159],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,392][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([6.5839e-05, 1.5033e-01, 3.1289e-01, 1.8946e-01, 1.3852e-01, 4.9755e-05,
        2.0867e-01, 1.1155e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,393][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0005, 0.4009, 0.0614, 0.1948, 0.1072, 0.0021, 0.2316, 0.0015],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,394][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ of] are: tensor([6.4353e-06, 9.9296e-01, 9.4644e-04, 4.7235e-03, 1.2747e-03, 2.4276e-05,
        6.3384e-06, 1.6308e-06, 5.8262e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,397][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0314, 0.1310, 0.1253, 0.1389, 0.1268, 0.1001, 0.1338, 0.0645, 0.1481],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,401][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0027, 0.1428, 0.1385, 0.1329, 0.1363, 0.0873, 0.1408, 0.0615, 0.1571],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,406][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0658, 0.2093, 0.0679, 0.1628, 0.0802, 0.1338, 0.1018, 0.0485, 0.1299],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,408][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0152, 0.2038, 0.1234, 0.1314, 0.1531, 0.0821, 0.1284, 0.0308, 0.1317],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,409][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0379, 0.1385, 0.1275, 0.1323, 0.1410, 0.1081, 0.1150, 0.0906, 0.1091],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,409][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.3377, 0.0967, 0.1599, 0.0486, 0.1632, 0.0318, 0.0508, 0.0684, 0.0430],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,410][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0062, 0.3875, 0.1143, 0.0688, 0.0939, 0.0158, 0.0537, 0.0104, 0.2494],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,412][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0487, 0.1751, 0.1152, 0.1446, 0.1299, 0.0846, 0.1138, 0.0450, 0.1430],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,415][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0160, 0.1397, 0.1552, 0.1539, 0.1810, 0.0312, 0.1171, 0.0269, 0.1791],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,419][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0266, 0.1044, 0.3879, 0.1010, 0.1435, 0.0224, 0.1391, 0.0226, 0.0525],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,423][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0791, 0.0509, 0.0865, 0.0524, 0.1114, 0.1078, 0.0884, 0.1316, 0.2919],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,426][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([4.3985e-08, 9.8827e-01, 6.1493e-04, 9.5342e-03, 1.3861e-03, 8.8473e-07,
        7.9537e-06, 5.3006e-08, 1.8350e-04, 2.8965e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,426][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0178, 0.1144, 0.1099, 0.1259, 0.1127, 0.0808, 0.1212, 0.0516, 0.1347,
        0.1310], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,427][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0023, 0.1240, 0.1262, 0.1162, 0.1201, 0.0760, 0.1224, 0.0523, 0.1385,
        0.1219], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,428][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0238, 0.1845, 0.0582, 0.1473, 0.1039, 0.1585, 0.0991, 0.0586, 0.1327,
        0.0334], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,430][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0147, 0.1553, 0.0970, 0.1208, 0.1447, 0.0699, 0.1259, 0.0380, 0.1414,
        0.0923], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,433][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0249, 0.1354, 0.1127, 0.1265, 0.1211, 0.1013, 0.1117, 0.0722, 0.1047,
        0.0894], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,437][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.2035, 0.1114, 0.1336, 0.0560, 0.1538, 0.0257, 0.0553, 0.0543, 0.0503,
        0.1561], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,440][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0036, 0.3838, 0.1248, 0.0442, 0.1186, 0.0054, 0.0172, 0.0045, 0.1487,
        0.1492], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,444][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0270, 0.1588, 0.0998, 0.1392, 0.1246, 0.0829, 0.1021, 0.0505, 0.1295,
        0.0857], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,445][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0127, 0.1192, 0.1285, 0.1294, 0.1455, 0.0297, 0.1005, 0.0237, 0.1533,
        0.1576], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,446][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0159, 0.1103, 0.3872, 0.0765, 0.1237, 0.0199, 0.1152, 0.0161, 0.0432,
        0.0920], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,446][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0289, 0.0999, 0.1552, 0.0458, 0.1072, 0.0534, 0.0819, 0.0461, 0.1428,
        0.2390], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,448][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ at] are: tensor([1.1800e-06, 9.8671e-01, 1.4671e-03, 8.2209e-03, 3.4824e-03, 8.9045e-06,
        1.1330e-05, 6.6990e-07, 8.5462e-05, 8.0914e-06, 5.0489e-06],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,450][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0175, 0.1043, 0.0961, 0.1077, 0.0991, 0.0735, 0.1034, 0.0500, 0.1193,
        0.1165, 0.1126], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,455][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0025, 0.1078, 0.1077, 0.1028, 0.1059, 0.0687, 0.1088, 0.0495, 0.1215,
        0.1103, 0.1145], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,458][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0458, 0.1848, 0.0646, 0.1357, 0.0845, 0.1343, 0.0795, 0.0508, 0.1099,
        0.0452, 0.0647], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,462][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0096, 0.1611, 0.0939, 0.1057, 0.1281, 0.0713, 0.1117, 0.0263, 0.1258,
        0.0834, 0.0831], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,463][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0240, 0.1166, 0.1066, 0.1106, 0.1175, 0.0908, 0.0959, 0.0757, 0.0913,
        0.0876, 0.0834], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,464][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.2293, 0.0958, 0.1453, 0.0467, 0.1470, 0.0252, 0.0459, 0.0519, 0.0370,
        0.1396, 0.0361], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,464][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0091, 0.2704, 0.0846, 0.0602, 0.1139, 0.0165, 0.0324, 0.0130, 0.1699,
        0.1857, 0.0442], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,466][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0327, 0.1470, 0.0965, 0.1139, 0.1104, 0.0745, 0.0900, 0.0337, 0.1190,
        0.0863, 0.0960], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,469][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0144, 0.1011, 0.1104, 0.1122, 0.1307, 0.0216, 0.0853, 0.0190, 0.1328,
        0.1518, 0.1208], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,473][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0170, 0.0838, 0.3346, 0.0703, 0.1115, 0.0211, 0.1011, 0.0185, 0.0418,
        0.1352, 0.0651], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,477][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0538, 0.0204, 0.0435, 0.0279, 0.0469, 0.0821, 0.0738, 0.0936, 0.2367,
        0.2934, 0.0279], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,480][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ the] are: tensor([8.6255e-08, 9.8921e-01, 3.9556e-04, 9.3481e-03, 9.2982e-04, 1.5213e-06,
        3.7354e-06, 7.6811e-08, 1.0339e-04, 3.2622e-06, 5.1079e-06, 6.7010e-07],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:34,481][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0150, 0.0928, 0.0902, 0.0966, 0.0894, 0.0654, 0.0940, 0.0446, 0.1042,
        0.1040, 0.1000, 0.1037], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:34,481][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0013, 0.0996, 0.0985, 0.0921, 0.0970, 0.0593, 0.0986, 0.0410, 0.1113,
        0.1003, 0.1037, 0.0972], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:34,482][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0362, 0.1680, 0.0633, 0.1331, 0.0751, 0.1022, 0.0728, 0.0380, 0.1249,
        0.0468, 0.0700, 0.0696], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:34,484][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0059, 0.1510, 0.0863, 0.1000, 0.1209, 0.0565, 0.0919, 0.0189, 0.1133,
        0.0822, 0.0886, 0.0844], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:34,487][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0238, 0.1054, 0.0966, 0.1003, 0.1041, 0.0830, 0.0866, 0.0710, 0.0824,
        0.0788, 0.0759, 0.0922], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:34,491][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1868, 0.0958, 0.1388, 0.0502, 0.1477, 0.0256, 0.0459, 0.0502, 0.0382,
        0.1366, 0.0380, 0.0462], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:34,495][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0036, 0.5525, 0.0627, 0.0379, 0.0540, 0.0053, 0.0191, 0.0046, 0.1091,
        0.1028, 0.0323, 0.0162], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:34,498][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0273, 0.1300, 0.0846, 0.1097, 0.0947, 0.0626, 0.0808, 0.0317, 0.1127,
        0.0795, 0.0939, 0.0925], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:34,499][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0088, 0.0898, 0.1010, 0.0993, 0.1190, 0.0175, 0.0745, 0.0156, 0.1195,
        0.1418, 0.1099, 0.1033], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:34,499][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0127, 0.0829, 0.2789, 0.0715, 0.1232, 0.0159, 0.0883, 0.0157, 0.0424,
        0.1069, 0.0607, 0.1009], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:34,500][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0832, 0.0617, 0.0719, 0.0262, 0.0939, 0.0826, 0.0372, 0.1283, 0.1518,
        0.1964, 0.0206, 0.0461], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:34,502][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ store] are: tensor([2.4661e-09, 9.8168e-01, 3.6738e-04, 1.6044e-02, 1.4610e-03, 2.2818e-07,
        2.1986e-05, 9.7707e-09, 3.9250e-04, 7.5150e-06, 1.3925e-05, 7.0360e-06,
        7.3548e-08], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:34,505][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0117, 0.0846, 0.0833, 0.0908, 0.0825, 0.0547, 0.0861, 0.0303, 0.0955,
        0.0974, 0.0956, 0.1001, 0.0875], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:34,509][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0009, 0.0909, 0.0906, 0.0856, 0.0872, 0.0554, 0.0905, 0.0358, 0.1042,
        0.0901, 0.0976, 0.0925, 0.0787], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:34,513][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0106, 0.1541, 0.0466, 0.1376, 0.0882, 0.1129, 0.0904, 0.0433, 0.1151,
        0.0283, 0.0649, 0.0821, 0.0260], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:34,516][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0070, 0.1409, 0.0692, 0.0984, 0.1152, 0.0514, 0.0917, 0.0200, 0.1152,
        0.0617, 0.0885, 0.0849, 0.0559], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:34,516][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0190, 0.1028, 0.0892, 0.0961, 0.0923, 0.0741, 0.0811, 0.0551, 0.0792,
        0.0681, 0.0726, 0.0886, 0.0815], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:34,517][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.1951, 0.0815, 0.1260, 0.0427, 0.1397, 0.0235, 0.0395, 0.0481, 0.0349,
        0.1279, 0.0334, 0.0442, 0.0636], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:34,518][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0006, 0.4968, 0.0766, 0.0438, 0.0850, 0.0014, 0.0183, 0.0011, 0.1172,
        0.0707, 0.0328, 0.0454, 0.0102], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:34,520][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.0182, 0.1220, 0.0708, 0.1050, 0.0908, 0.0614, 0.0736, 0.0330, 0.1004,
        0.0664, 0.0895, 0.0882, 0.0808], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:34,523][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0066, 0.0871, 0.0950, 0.0917, 0.1089, 0.0179, 0.0700, 0.0144, 0.1096,
        0.1204, 0.0981, 0.0951, 0.0850], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:34,527][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0138, 0.0631, 0.3258, 0.0618, 0.0879, 0.0102, 0.0756, 0.0085, 0.0368,
        0.0754, 0.0651, 0.1160, 0.0600], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:34,531][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0018, 0.0600, 0.0486, 0.0639, 0.0459, 0.0058, 0.0857, 0.0050, 0.2050,
        0.2039, 0.0804, 0.1831, 0.0109], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:34,533][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [.] are: tensor([1.8416e-06, 9.8318e-01, 1.6240e-03, 1.0721e-02, 4.2418e-03, 1.0745e-05,
        2.0483e-05, 9.8553e-07, 1.5022e-04, 1.3672e-05, 1.2761e-05, 4.0441e-06,
        3.6777e-07, 1.7827e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:34,534][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0158, 0.0740, 0.0704, 0.0775, 0.0717, 0.0590, 0.0758, 0.0387, 0.0859,
        0.0883, 0.0846, 0.0887, 0.0801, 0.0896], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:34,535][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0011, 0.0822, 0.0820, 0.0775, 0.0812, 0.0512, 0.0827, 0.0349, 0.0922,
        0.0836, 0.0871, 0.0828, 0.0738, 0.0877], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:34,536][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0716, 0.1798, 0.0480, 0.1016, 0.0616, 0.0772, 0.0716, 0.0303, 0.0904,
        0.0297, 0.0632, 0.0613, 0.0213, 0.0922], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:34,538][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0120, 0.1386, 0.0800, 0.0759, 0.0899, 0.0605, 0.0824, 0.0221, 0.0836,
        0.0688, 0.0667, 0.0789, 0.0498, 0.0908], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:34,540][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0222, 0.0896, 0.0798, 0.0831, 0.0855, 0.0704, 0.0745, 0.0584, 0.0689,
        0.0653, 0.0653, 0.0791, 0.0795, 0.0786], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:34,544][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.2189, 0.0788, 0.0985, 0.0416, 0.1135, 0.0263, 0.0377, 0.0511, 0.0326,
        0.1163, 0.0329, 0.0398, 0.0652, 0.0467], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:34,549][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0032, 0.3951, 0.0508, 0.0527, 0.0725, 0.0069, 0.0241, 0.0049, 0.1127,
        0.1269, 0.0398, 0.0272, 0.0261, 0.0571], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:34,551][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0263, 0.1071, 0.0687, 0.0867, 0.0785, 0.0558, 0.0717, 0.0288, 0.0909,
        0.0614, 0.0756, 0.0822, 0.0710, 0.0952], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:34,552][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0096, 0.0763, 0.0829, 0.0825, 0.0933, 0.0168, 0.0638, 0.0141, 0.0966,
        0.1041, 0.0891, 0.0855, 0.0751, 0.1104], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:34,553][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0114, 0.0753, 0.2710, 0.0519, 0.1057, 0.0133, 0.0630, 0.0105, 0.0300,
        0.0830, 0.0453, 0.0908, 0.0930, 0.0556], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:34,554][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0707, 0.0186, 0.0378, 0.0209, 0.0643, 0.0839, 0.0502, 0.1182, 0.0856,
        0.3138, 0.0144, 0.0485, 0.0522, 0.0210], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:34,555][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([2.4906e-06, 9.7144e-01, 1.9696e-03, 2.1398e-02, 4.3623e-03, 1.9269e-05,
        4.4150e-05, 1.6826e-06, 5.3415e-04, 3.0891e-05, 4.1819e-05, 1.7166e-05,
        1.1968e-06, 1.0311e-04, 3.5877e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:34,558][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0136, 0.0681, 0.0683, 0.0744, 0.0689, 0.0496, 0.0737, 0.0274, 0.0812,
        0.0823, 0.0799, 0.0852, 0.0731, 0.0823, 0.0720], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:34,562][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.0009, 0.0762, 0.0753, 0.0713, 0.0753, 0.0488, 0.0756, 0.0332, 0.0852,
        0.0770, 0.0814, 0.0758, 0.0695, 0.0813, 0.0731], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:34,567][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0081, 0.1309, 0.0397, 0.1229, 0.0718, 0.1077, 0.0788, 0.0362, 0.0911,
        0.0225, 0.0633, 0.0710, 0.0256, 0.1114, 0.0189], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:34,569][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.0062, 0.1121, 0.0628, 0.0836, 0.1031, 0.0398, 0.0838, 0.0206, 0.0969,
        0.0568, 0.0630, 0.0722, 0.0434, 0.1114, 0.0442], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:34,570][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0142, 0.0872, 0.0740, 0.0825, 0.0769, 0.0662, 0.0643, 0.0533, 0.0643,
        0.0623, 0.0607, 0.0722, 0.0738, 0.0776, 0.0705], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:34,570][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.1718, 0.0657, 0.1089, 0.0345, 0.1214, 0.0231, 0.0373, 0.0440, 0.0298,
        0.1269, 0.0312, 0.0404, 0.0727, 0.0427, 0.0498], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:34,571][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.0020, 0.5928, 0.0439, 0.0365, 0.0563, 0.0030, 0.0114, 0.0024, 0.0901,
        0.0570, 0.0199, 0.0136, 0.0111, 0.0365, 0.0236], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:34,573][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.0118, 0.0993, 0.0629, 0.0866, 0.0767, 0.0501, 0.0650, 0.0306, 0.0795,
        0.0588, 0.0716, 0.0741, 0.0687, 0.0953, 0.0690], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:34,576][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0073, 0.0688, 0.0778, 0.0758, 0.0844, 0.0185, 0.0595, 0.0142, 0.0867,
        0.0898, 0.0811, 0.0782, 0.0659, 0.1005, 0.0914], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:34,580][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.0117, 0.0707, 0.1522, 0.0556, 0.0734, 0.0189, 0.0644, 0.0152, 0.0307,
        0.0827, 0.0550, 0.0968, 0.1036, 0.0573, 0.1119], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:34,584][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.0426, 0.0489, 0.0619, 0.0372, 0.0821, 0.0857, 0.0645, 0.0705, 0.0903,
        0.1930, 0.0271, 0.0620, 0.0332, 0.0451, 0.0556], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:34,587][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([6.5943e-06, 8.1819e-01, 1.6006e-02, 9.2126e-02, 4.6789e-02, 1.1896e-04,
        2.8052e-03, 2.0957e-05, 1.1922e-02, 2.2076e-03, 3.0281e-03, 1.8920e-03,
        2.0527e-04, 3.0476e-03, 1.5755e-03, 6.0289e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:34,587][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0024, 0.0649, 0.0587, 0.0716, 0.0596, 0.0393, 0.0677, 0.0172, 0.0819,
        0.0901, 0.0830, 0.0906, 0.0746, 0.0952, 0.0691, 0.0339],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:34,588][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0001, 0.0735, 0.0744, 0.0674, 0.0724, 0.0363, 0.0741, 0.0205, 0.0898,
        0.0754, 0.0836, 0.0769, 0.0638, 0.0865, 0.0735, 0.0318],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:34,589][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0088, 0.1625, 0.0376, 0.1224, 0.0610, 0.0827, 0.0769, 0.0193, 0.1126,
        0.0193, 0.0532, 0.0679, 0.0174, 0.1165, 0.0186, 0.0233],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:34,591][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0020, 0.1178, 0.0596, 0.0840, 0.0959, 0.0339, 0.0739, 0.0124, 0.1086,
        0.0448, 0.0726, 0.0724, 0.0358, 0.1213, 0.0437, 0.0212],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:34,595][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0122, 0.0798, 0.0722, 0.0774, 0.0741, 0.0609, 0.0657, 0.0502, 0.0623,
        0.0572, 0.0559, 0.0720, 0.0715, 0.0721, 0.0690, 0.0475],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:34,598][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0865, 0.0807, 0.1144, 0.0443, 0.1099, 0.0215, 0.0456, 0.0358, 0.0386,
        0.1007, 0.0389, 0.0514, 0.0704, 0.0596, 0.0703, 0.0312],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:34,600][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([2.8201e-04, 5.7032e-01, 5.1529e-02, 5.1066e-02, 7.0322e-02, 6.1957e-04,
        2.1191e-02, 4.6198e-04, 6.6017e-02, 2.9576e-02, 3.1937e-02, 3.1942e-02,
        6.2113e-03, 4.5170e-02, 2.2547e-02, 8.1082e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:34,604][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0090, 0.1013, 0.0546, 0.0864, 0.0739, 0.0446, 0.0573, 0.0216, 0.0816,
        0.0534, 0.0676, 0.0713, 0.0665, 0.1046, 0.0676, 0.0388],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:34,605][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0022, 0.0662, 0.0750, 0.0723, 0.0870, 0.0079, 0.0484, 0.0058, 0.0905,
        0.1007, 0.0791, 0.0750, 0.0636, 0.1101, 0.1035, 0.0125],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:34,606][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([2.7470e-05, 6.7624e-02, 1.6798e-01, 1.0757e-01, 8.5174e-02, 3.6817e-05,
        9.1130e-02, 5.4528e-06, 5.5309e-02, 4.8922e-02, 8.2077e-02, 1.4926e-01,
        1.9714e-02, 4.7226e-02, 7.7927e-02, 1.6110e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:34,607][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0003, 0.1242, 0.0288, 0.0693, 0.0485, 0.0011, 0.0790, 0.0008, 0.1981,
        0.0661, 0.0926, 0.1362, 0.0101, 0.1106, 0.0333, 0.0010],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:34,608][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([1.7193e-06, 9.4910e-01, 3.7343e-03, 3.4813e-02, 9.4612e-03, 2.5807e-05,
        2.0828e-04, 2.8291e-06, 1.6264e-03, 1.9330e-04, 2.5400e-04, 9.1926e-05,
        8.8249e-06, 3.1260e-04, 1.1584e-04, 9.7190e-06, 4.5230e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,611][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0057, 0.0616, 0.0577, 0.0678, 0.0606, 0.0408, 0.0640, 0.0213, 0.0769,
        0.0791, 0.0749, 0.0795, 0.0683, 0.0835, 0.0661, 0.0349, 0.0572],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,616][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0003, 0.0701, 0.0686, 0.0654, 0.0683, 0.0390, 0.0702, 0.0249, 0.0813,
        0.0713, 0.0766, 0.0723, 0.0603, 0.0782, 0.0656, 0.0349, 0.0525],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,620][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0155, 0.1449, 0.0418, 0.1171, 0.0540, 0.0795, 0.0585, 0.0258, 0.1021,
        0.0279, 0.0553, 0.0601, 0.0212, 0.0970, 0.0207, 0.0270, 0.0515],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,622][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0020, 0.1280, 0.0617, 0.0804, 0.0929, 0.0359, 0.0637, 0.0109, 0.0880,
        0.0595, 0.0609, 0.0639, 0.0424, 0.0942, 0.0479, 0.0255, 0.0423],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,623][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0156, 0.0736, 0.0679, 0.0711, 0.0741, 0.0578, 0.0590, 0.0492, 0.0574,
        0.0564, 0.0539, 0.0640, 0.0695, 0.0668, 0.0644, 0.0455, 0.0537],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,624][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1690, 0.0746, 0.1077, 0.0316, 0.1106, 0.0194, 0.0331, 0.0388, 0.0278,
        0.1020, 0.0291, 0.0379, 0.0685, 0.0456, 0.0546, 0.0321, 0.0176],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,625][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0006, 0.4867, 0.0501, 0.0439, 0.0779, 0.0013, 0.0175, 0.0010, 0.1026,
        0.0477, 0.0372, 0.0298, 0.0099, 0.0618, 0.0278, 0.0017, 0.0027],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,627][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0171, 0.0972, 0.0575, 0.0772, 0.0665, 0.0423, 0.0537, 0.0196, 0.0800,
        0.0548, 0.0674, 0.0653, 0.0627, 0.0898, 0.0669, 0.0366, 0.0450],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,631][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0040, 0.0628, 0.0723, 0.0684, 0.0836, 0.0091, 0.0484, 0.0079, 0.0845,
        0.1003, 0.0758, 0.0711, 0.0665, 0.0999, 0.0958, 0.0137, 0.0358],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,634][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0003, 0.0419, 0.2255, 0.0666, 0.0735, 0.0010, 0.0604, 0.0004, 0.0279,
        0.0787, 0.0576, 0.1280, 0.0500, 0.0572, 0.1217, 0.0013, 0.0082],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,638][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0013, 0.0504, 0.0257, 0.0423, 0.0506, 0.0032, 0.0568, 0.0031, 0.2316,
        0.1188, 0.0713, 0.1488, 0.0126, 0.1297, 0.0397, 0.0041, 0.0101],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:34,640][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([1.6657e-08, 9.9551e-01, 2.1828e-04, 3.6368e-03, 5.6757e-04, 3.5060e-07,
        5.7350e-06, 1.8665e-08, 4.8386e-05, 2.8183e-06, 1.5670e-06, 1.1338e-06,
        2.8691e-08, 4.3959e-06, 1.2476e-06, 1.1562e-07, 1.0465e-06, 1.0706e-06],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,641][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([0.0060, 0.0597, 0.0609, 0.0668, 0.0620, 0.0393, 0.0620, 0.0201, 0.0708,
        0.0714, 0.0680, 0.0725, 0.0626, 0.0707, 0.0632, 0.0281, 0.0489, 0.0669],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,642][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([0.0007, 0.0696, 0.0668, 0.0628, 0.0654, 0.0370, 0.0661, 0.0232, 0.0759,
        0.0661, 0.0702, 0.0659, 0.0585, 0.0715, 0.0634, 0.0312, 0.0489, 0.0568],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,643][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([0.0056, 0.1289, 0.0365, 0.0994, 0.0642, 0.0979, 0.0661, 0.0348, 0.0938,
        0.0213, 0.0595, 0.0507, 0.0192, 0.0879, 0.0162, 0.0305, 0.0721, 0.0156],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,645][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([0.0058, 0.0951, 0.0516, 0.0707, 0.0876, 0.0480, 0.0739, 0.0215, 0.0938,
        0.0424, 0.0548, 0.0673, 0.0336, 0.1010, 0.0361, 0.0284, 0.0644, 0.0239],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,648][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([0.0133, 0.0750, 0.0636, 0.0686, 0.0654, 0.0569, 0.0582, 0.0419, 0.0549,
        0.0480, 0.0530, 0.0639, 0.0595, 0.0638, 0.0599, 0.0441, 0.0526, 0.0572],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,652][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([0.1602, 0.0703, 0.1086, 0.0344, 0.1132, 0.0196, 0.0336, 0.0375, 0.0285,
        0.0923, 0.0289, 0.0352, 0.0542, 0.0401, 0.0397, 0.0294, 0.0153, 0.0589],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,656][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([0.0009, 0.4809, 0.0290, 0.0442, 0.0694, 0.0022, 0.0106, 0.0016, 0.1109,
        0.0797, 0.0279, 0.0165, 0.0154, 0.0581, 0.0268, 0.0023, 0.0025, 0.0209],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,658][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([0.0118, 0.0817, 0.0514, 0.0733, 0.0666, 0.0435, 0.0541, 0.0314, 0.0684,
        0.0469, 0.0608, 0.0619, 0.0609, 0.0779, 0.0544, 0.0447, 0.0536, 0.0566],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,659][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([0.0071, 0.0622, 0.0671, 0.0653, 0.0730, 0.0155, 0.0513, 0.0116, 0.0748,
        0.0754, 0.0687, 0.0667, 0.0555, 0.0852, 0.0759, 0.0196, 0.0418, 0.0833],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,660][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([0.0167, 0.0798, 0.1390, 0.0448, 0.0880, 0.0068, 0.0647, 0.0087, 0.0243,
        0.0686, 0.0425, 0.0715, 0.0878, 0.0538, 0.1194, 0.0163, 0.0210, 0.0466],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,662][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([0.0094, 0.1524, 0.0364, 0.0650, 0.0796, 0.0222, 0.0699, 0.0173, 0.1520,
        0.1128, 0.0345, 0.0929, 0.0143, 0.0489, 0.0249, 0.0173, 0.0232, 0.0269],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:34,664][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([6.0203e-06, 9.9166e-01, 9.4194e-04, 5.6900e-03, 1.4241e-03, 2.2918e-05,
        1.4254e-05, 1.9678e-06, 8.0847e-05, 7.4974e-06, 6.8486e-06, 2.1665e-06,
        2.2891e-07, 1.8521e-05, 6.5434e-06, 7.6149e-06, 1.8459e-05, 6.8956e-06,
        8.4305e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,669][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0110, 0.0550, 0.0527, 0.0576, 0.0537, 0.0413, 0.0566, 0.0251, 0.0645,
        0.0638, 0.0635, 0.0664, 0.0589, 0.0659, 0.0566, 0.0353, 0.0517, 0.0609,
        0.0596], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,673][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0008, 0.0608, 0.0602, 0.0576, 0.0596, 0.0380, 0.0612, 0.0260, 0.0694,
        0.0612, 0.0643, 0.0619, 0.0546, 0.0663, 0.0590, 0.0358, 0.0485, 0.0532,
        0.0616], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,675][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0255, 0.1138, 0.0408, 0.0903, 0.0578, 0.0786, 0.0626, 0.0333, 0.0741,
        0.0267, 0.0507, 0.0571, 0.0255, 0.0779, 0.0239, 0.0407, 0.0643, 0.0192,
        0.0373], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,676][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0082, 0.0943, 0.0565, 0.0660, 0.0738, 0.0436, 0.0699, 0.0182, 0.0724,
        0.0513, 0.0526, 0.0595, 0.0365, 0.0767, 0.0403, 0.0311, 0.0583, 0.0355,
        0.0553], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,677][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0145, 0.0646, 0.0591, 0.0627, 0.0632, 0.0509, 0.0554, 0.0429, 0.0521,
        0.0488, 0.0483, 0.0594, 0.0602, 0.0592, 0.0564, 0.0410, 0.0505, 0.0571,
        0.0537], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,678][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2463, 0.0529, 0.0918, 0.0265, 0.0834, 0.0191, 0.0270, 0.0423, 0.0221,
        0.0853, 0.0234, 0.0293, 0.0538, 0.0325, 0.0373, 0.0323, 0.0147, 0.0616,
        0.0183], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,680][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0036, 0.2967, 0.0672, 0.0324, 0.0597, 0.0075, 0.0214, 0.0058, 0.1236,
        0.0928, 0.0371, 0.0323, 0.0197, 0.0632, 0.0526, 0.0077, 0.0077, 0.0338,
        0.0352], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,683][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0235, 0.0757, 0.0513, 0.0664, 0.0574, 0.0411, 0.0516, 0.0227, 0.0661,
        0.0453, 0.0578, 0.0589, 0.0562, 0.0712, 0.0573, 0.0399, 0.0466, 0.0529,
        0.0581], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,687][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0074, 0.0555, 0.0602, 0.0586, 0.0688, 0.0117, 0.0449, 0.0102, 0.0686,
        0.0775, 0.0623, 0.0604, 0.0559, 0.0787, 0.0730, 0.0155, 0.0349, 0.0825,
        0.0736], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,691][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0111, 0.0365, 0.1435, 0.0444, 0.0582, 0.0160, 0.0613, 0.0114, 0.0233,
        0.0622, 0.0423, 0.0878, 0.0867, 0.0562, 0.1182, 0.0312, 0.0373, 0.0501,
        0.0224], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,694][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0728, 0.0091, 0.0330, 0.0137, 0.0468, 0.0685, 0.0260, 0.1083, 0.0740,
        0.1506, 0.0088, 0.0348, 0.0259, 0.0221, 0.0582, 0.0953, 0.0693, 0.0576,
        0.0252], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:34,769][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:34,770][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,770][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,771][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,772][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,772][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,773][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,774][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,774][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,775][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,776][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,776][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,777][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:34,778][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0282, 0.9718], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,778][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9190, 0.0810], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,779][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([4.5141e-05, 9.9995e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,780][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0429, 0.9571], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,781][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0110, 0.9890], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,782][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9386, 0.0614], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,782][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.4933, 0.5067], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,783][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3812, 0.6188], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,787][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0399, 0.9601], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,790][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0099, 0.9901], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,794][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0121, 0.9879], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,795][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1818, 0.8182], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:34,796][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([4.3247e-05, 9.9834e-01, 1.6205e-03], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,796][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.8661, 0.0162, 0.1177], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,797][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([5.7590e-06, 9.2902e-01, 7.0979e-02], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,799][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.0041, 0.9659, 0.0299], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,801][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([6.1411e-05, 9.7285e-01, 2.7089e-02], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,805][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.7894, 0.1669, 0.0437], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,808][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.5085, 0.4000, 0.0915], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,812][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.2993, 0.5705, 0.1302], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,813][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.0014, 0.9706, 0.0280], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,813][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([2.4580e-04, 9.4009e-01, 5.9662e-02], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,814][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0237, 0.4798, 0.4965], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,816][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.2773, 0.4190, 0.3037], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:34,818][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([5.4811e-05, 9.9490e-01, 1.9986e-03, 3.0484e-03], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,822][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.4805, 0.1088, 0.3513, 0.0593], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,824][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.8162e-05, 4.8688e-01, 7.6932e-02, 4.3617e-01], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,827][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([6.8605e-04, 8.2245e-01, 2.0686e-02, 1.5618e-01], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,829][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([5.9952e-06, 9.4913e-01, 5.2102e-03, 4.5652e-02], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,830][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.7404, 0.1958, 0.0405, 0.0232], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,830][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2472, 0.2582, 0.1934, 0.3013], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,831][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2311, 0.5244, 0.1704, 0.0741], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,832][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([1.5573e-04, 9.3245e-01, 5.7475e-03, 6.1650e-02], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,833][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([2.5977e-05, 9.3651e-01, 5.1745e-02, 1.1719e-02], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,836][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0007, 0.2954, 0.5922, 0.1116], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,840][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0692, 0.4158, 0.3006, 0.2144], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:34,842][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([2.7683e-05, 9.8850e-01, 6.4939e-04, 7.5778e-03, 3.2420e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,845][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([0.5767, 0.0820, 0.1934, 0.0669, 0.0808], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,847][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([6.8407e-05, 6.6046e-01, 9.2650e-02, 2.0419e-01, 4.2628e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,848][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([0.0011, 0.7230, 0.0088, 0.2326, 0.0345], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,848][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([1.7291e-05, 9.1477e-01, 4.7418e-03, 6.9049e-02, 1.1422e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,849][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.4072, 0.2453, 0.0775, 0.0847, 0.1853], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,851][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.1715, 0.3368, 0.0941, 0.2072, 0.1905], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,854][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.1653, 0.3801, 0.2442, 0.0922, 0.1182], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,858][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.0008, 0.7598, 0.0069, 0.2140, 0.0186], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,860][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([8.2406e-05, 8.6432e-01, 1.8537e-02, 8.5508e-02, 3.1550e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,864][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.0402, 0.3599, 0.5322, 0.0389, 0.0287], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,865][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.2192, 0.3643, 0.1417, 0.1208, 0.1540], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:34,865][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([2.3412e-05, 6.1272e-01, 5.4124e-02, 1.0748e-01, 2.2540e-01, 2.4680e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,866][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0013, 0.4067, 0.1759, 0.2844, 0.1243, 0.0074], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,867][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([6.3941e-09, 8.8150e-01, 3.0391e-03, 1.0919e-01, 6.2711e-03, 2.1753e-07],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,868][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([1.0275e-04, 3.3968e-01, 7.9984e-02, 3.6065e-01, 2.1843e-01, 1.1455e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,869][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([1.0674e-05, 6.5413e-01, 2.4607e-02, 2.1197e-01, 1.0913e-01, 1.4693e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,873][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0483, 0.3065, 0.1661, 0.1955, 0.2218, 0.0618], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,876][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0185, 0.1907, 0.2269, 0.1756, 0.3560, 0.0324], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,878][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([2.5744e-04, 6.6974e-01, 1.4441e-01, 9.7319e-02, 8.7745e-02, 5.3062e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,880][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([2.2540e-05, 5.5230e-01, 3.5049e-02, 2.8713e-01, 1.2521e-01, 2.8720e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,882][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([1.3063e-05, 3.8575e-01, 1.8184e-01, 9.3255e-02, 3.3900e-01, 1.4369e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,883][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([1.4784e-06, 5.3528e-01, 7.5254e-02, 3.4064e-01, 4.8811e-02, 1.3975e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,884][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0008, 0.5073, 0.0882, 0.2719, 0.1286, 0.0033], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:34,885][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([7.6099e-06, 9.7234e-01, 1.3501e-03, 1.9985e-02, 6.2354e-03, 3.7921e-05,
        4.0976e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,887][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1776, 0.0233, 0.0651, 0.0249, 0.0244, 0.4684, 0.2163],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,888][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([5.0299e-05, 2.4854e-01, 3.4286e-02, 2.3147e-01, 7.5691e-02, 1.0013e-03,
        4.0896e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,891][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([2.2417e-04, 6.0959e-01, 1.5023e-02, 2.9430e-01, 6.7427e-02, 1.7945e-03,
        1.1641e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,893][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([2.4915e-06, 8.1224e-01, 6.5727e-03, 1.6706e-01, 1.0744e-02, 7.3921e-05,
        3.3141e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,897][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1500, 0.2404, 0.0299, 0.0866, 0.1587, 0.2622, 0.0722],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,900][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0694, 0.2074, 0.0743, 0.2354, 0.2352, 0.1134, 0.0649],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,900][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.3945, 0.1508, 0.1377, 0.0425, 0.0651, 0.1738, 0.0356],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,901][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.5900e-05, 6.5677e-01, 4.5229e-03, 3.1475e-01, 2.1493e-02, 3.3714e-04,
        2.1109e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,902][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([6.7871e-06, 7.7524e-01, 4.5129e-02, 9.1864e-02, 8.6035e-02, 8.3315e-05,
        1.6387e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,903][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0034, 0.0458, 0.4654, 0.0855, 0.1328, 0.0117, 0.2554],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,905][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1613, 0.1294, 0.1184, 0.1135, 0.1187, 0.2058, 0.1529],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:34,906][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([5.6556e-06, 4.3297e-01, 4.6761e-02, 2.1447e-01, 2.6496e-01, 1.6247e-04,
        4.0642e-02, 2.7632e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,910][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0010, 0.3175, 0.1156, 0.2056, 0.1136, 0.0048, 0.2396, 0.0022],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,913][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([6.9647e-09, 8.0345e-01, 1.9341e-03, 8.9449e-02, 5.3554e-03, 2.1165e-07,
        9.9810e-02, 5.3023e-08], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,915][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([5.7925e-05, 2.4318e-01, 8.2292e-02, 3.8823e-01, 1.9588e-01, 1.0157e-03,
        8.9106e-02, 2.3859e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,918][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([8.2158e-06, 4.7392e-01, 3.7646e-02, 2.9038e-01, 1.6086e-01, 1.6168e-04,
        3.6992e-02, 3.1094e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,918][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0120, 0.2265, 0.1134, 0.2718, 0.2052, 0.0325, 0.1187, 0.0198],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,919][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0100, 0.1568, 0.1810, 0.1659, 0.2885, 0.0234, 0.1582, 0.0162],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,920][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([1.3349e-04, 6.9181e-01, 7.8127e-02, 9.7917e-02, 6.4681e-02, 4.0055e-04,
        6.6674e-02, 2.5807e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,921][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([1.8385e-05, 3.3612e-01, 4.8583e-02, 3.6406e-01, 1.9578e-01, 3.9880e-04,
        5.4962e-02, 8.4389e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,924][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([9.0688e-06, 3.2919e-01, 1.4457e-01, 1.7107e-01, 3.2453e-01, 1.7916e-04,
        3.0419e-02, 4.1998e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,926][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([7.7193e-07, 3.2951e-01, 2.8446e-02, 1.4295e-01, 2.8106e-02, 6.6352e-06,
        4.7097e-01, 2.8900e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,930][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0005, 0.4009, 0.0614, 0.1948, 0.1072, 0.0021, 0.2316, 0.0015],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:34,932][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([1.6428e-03, 9.7972e-01, 1.5795e-03, 9.7945e-03, 4.2850e-03, 1.4437e-03,
        9.8740e-05, 2.3748e-04, 1.1967e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,935][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0250, 0.0060, 0.0173, 0.0162, 0.0093, 0.1552, 0.1746, 0.0603, 0.5361],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,936][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([5.3810e-05, 5.4480e-02, 2.6808e-02, 5.5577e-02, 5.0084e-02, 8.0360e-04,
        2.8260e-01, 5.1758e-04, 5.2908e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,937][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0024, 0.5630, 0.0097, 0.2444, 0.0353, 0.0071, 0.0118, 0.0011, 0.1253],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,937][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([1.5790e-05, 8.3490e-01, 1.7240e-03, 1.4866e-01, 4.3206e-03, 2.1001e-04,
        3.5533e-03, 1.3304e-05, 6.6025e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,939][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.1992, 0.0914, 0.0100, 0.0386, 0.0306, 0.2484, 0.0384, 0.0972, 0.2462],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,942][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0291, 0.0784, 0.0509, 0.1220, 0.1858, 0.0796, 0.0817, 0.0404, 0.3321],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,946][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.1667, 0.0917, 0.1856, 0.0496, 0.0611, 0.1893, 0.0790, 0.1304, 0.0465],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,948][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([4.1939e-04, 7.3948e-01, 3.0029e-03, 1.7664e-01, 7.6422e-03, 2.9180e-03,
        2.7244e-03, 3.2128e-04, 6.6849e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,950][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([1.0138e-04, 8.3970e-01, 2.1092e-02, 6.7782e-02, 4.5140e-02, 4.0508e-04,
        1.5101e-03, 6.5159e-05, 2.4206e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,953][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0066, 0.0157, 0.4954, 0.0335, 0.1044, 0.0136, 0.2576, 0.0293, 0.0440],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,954][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0791, 0.0509, 0.0865, 0.0524, 0.1114, 0.1078, 0.0884, 0.1316, 0.2919],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:34,955][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([8.2738e-07, 9.5408e-01, 8.5538e-04, 2.9234e-02, 6.5593e-03, 7.2563e-06,
        1.4521e-04, 7.1782e-07, 9.0498e-03, 7.0477e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,955][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0054, 0.0045, 0.0128, 0.0159, 0.0059, 0.0456, 0.1822, 0.0194, 0.5574,
        0.1509], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,957][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([2.0883e-06, 1.4040e-01, 1.2950e-01, 5.3316e-02, 3.9411e-02, 5.6507e-05,
        1.2966e-01, 2.2150e-05, 4.2304e-01, 8.4592e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,959][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([2.6253e-05, 4.9546e-01, 5.2876e-03, 3.3152e-01, 3.1399e-02, 3.7346e-04,
        8.6807e-03, 3.7896e-05, 1.2416e-01, 3.0518e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,962][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([2.4729e-07, 8.9678e-01, 8.1435e-04, 9.4362e-02, 2.5735e-03, 6.4077e-06,
        7.9479e-04, 3.6546e-07, 4.5938e-03, 7.8092e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,966][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0047, 0.0985, 0.0081, 0.0999, 0.0468, 0.0211, 0.0579, 0.0060, 0.6121,
        0.0450], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,970][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0134, 0.0759, 0.0278, 0.1550, 0.1810, 0.0329, 0.0589, 0.0219, 0.2045,
        0.2287], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,971][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0635, 0.1274, 0.3267, 0.0331, 0.1372, 0.0661, 0.0340, 0.0549, 0.0521,
        0.1050], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,972][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([2.3602e-06, 3.1078e-01, 6.1195e-04, 4.1286e-01, 4.1459e-03, 8.9475e-05,
        2.1749e-03, 6.5804e-06, 2.6870e-01, 6.3340e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,973][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([1.0616e-06, 6.7616e-01, 2.3132e-02, 1.1126e-01, 8.0443e-02, 2.0325e-05,
        1.8178e-03, 2.3075e-06, 1.0595e-01, 1.2052e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,974][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0012, 0.0581, 0.3774, 0.0223, 0.0685, 0.0028, 0.2514, 0.0051, 0.0838,
        0.1294], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,977][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0289, 0.0999, 0.1552, 0.0458, 0.1072, 0.0534, 0.0819, 0.0461, 0.1428,
        0.2390], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:34,980][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([2.6274e-04, 9.7135e-01, 2.2093e-03, 1.3180e-02, 1.1246e-02, 3.4554e-04,
        1.2558e-04, 6.7910e-05, 9.7505e-04, 1.5650e-04, 8.3994e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,984][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0299, 0.0072, 0.0097, 0.0053, 0.0049, 0.1247, 0.0637, 0.0737, 0.4477,
        0.1191, 0.1141], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,986][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([1.4018e-05, 1.4247e-02, 2.6030e-02, 4.1108e-02, 3.9606e-02, 2.9225e-04,
        1.4687e-01, 1.5353e-04, 3.2375e-01, 3.8057e-01, 2.7352e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,988][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([2.5916e-04, 4.5584e-01, 6.0076e-03, 3.0954e-01, 3.4334e-02, 1.4991e-03,
        1.0898e-02, 2.5054e-04, 1.6923e-01, 4.4203e-03, 7.7168e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,989][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([2.1421e-06, 8.6647e-01, 3.1451e-03, 1.0199e-01, 1.0446e-02, 4.4005e-05,
        3.3281e-03, 2.9149e-06, 1.2276e-02, 1.1517e-03, 1.1420e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,990][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0619, 0.2110, 0.0127, 0.0642, 0.0505, 0.0908, 0.0527, 0.0466, 0.2985,
        0.0906, 0.0204], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,991][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0166, 0.0534, 0.0265, 0.0964, 0.1149, 0.0467, 0.0730, 0.0240, 0.2149,
        0.2860, 0.0476], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,993][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.2038, 0.0521, 0.0809, 0.0360, 0.0794, 0.2181, 0.0404, 0.1803, 0.0402,
        0.0657, 0.0030], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,995][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([3.3799e-05, 5.8676e-01, 3.0631e-03, 2.6950e-01, 8.6796e-03, 4.9886e-04,
        2.6508e-03, 5.2369e-05, 1.2548e-01, 2.3356e-03, 9.4109e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:34,997][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([1.5013e-05, 7.4444e-01, 1.9741e-02, 1.0654e-01, 8.0334e-02, 1.2890e-04,
        2.1704e-03, 2.1885e-05, 4.0998e-02, 2.7417e-03, 2.8683e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:35,001][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0007, 0.0063, 0.1586, 0.0099, 0.0286, 0.0023, 0.0616, 0.0054, 0.0268,
        0.6604, 0.0393], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:35,006][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0538, 0.0204, 0.0435, 0.0279, 0.0469, 0.0821, 0.0738, 0.0936, 0.2367,
        0.2934, 0.0279], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:35,007][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([1.9527e-05, 9.4873e-01, 9.0931e-04, 3.9682e-02, 5.0652e-03, 7.7086e-05,
        9.5929e-05, 8.7231e-06, 4.8067e-03, 1.6905e-04, 3.9482e-04, 4.0813e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,007][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0278, 0.0096, 0.0278, 0.0085, 0.0071, 0.1284, 0.1170, 0.0751, 0.3505,
        0.1111, 0.0902, 0.0469], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,008][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([3.0825e-05, 7.0731e-02, 3.6369e-02, 3.1749e-02, 9.9843e-02, 4.5605e-04,
        1.0643e-01, 2.8692e-04, 2.9639e-01, 3.3376e-01, 1.2968e-02, 1.0980e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,009][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([2.2007e-04, 4.5760e-01, 6.6024e-03, 3.0434e-01, 3.1925e-02, 1.3285e-03,
        8.8730e-03, 1.8117e-04, 1.6797e-01, 2.7503e-03, 9.2267e-03, 8.9770e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,011][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([2.9666e-06, 7.9063e-01, 2.0472e-03, 1.7548e-01, 8.5221e-03, 6.8960e-05,
        4.2792e-03, 4.2412e-06, 1.5855e-02, 7.8159e-04, 1.7804e-03, 5.4813e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,014][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0828, 0.1804, 0.0229, 0.0525, 0.0681, 0.1489, 0.0379, 0.0504, 0.2696,
        0.0548, 0.0222, 0.0094], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,018][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0238, 0.0680, 0.0317, 0.0954, 0.1394, 0.0492, 0.0466, 0.0334, 0.1470,
        0.3012, 0.0401, 0.0242], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,022][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.2181, 0.1534, 0.1150, 0.0289, 0.0437, 0.1607, 0.0411, 0.1706, 0.0282,
        0.0362, 0.0027, 0.0013], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,024][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([2.9684e-05, 6.5050e-01, 2.6782e-03, 2.2963e-01, 1.1095e-02, 3.8579e-04,
        1.5613e-03, 4.8305e-05, 1.0168e-01, 1.4471e-03, 7.9328e-04, 1.4944e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,025][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([1.1026e-05, 7.8755e-01, 1.4864e-02, 9.2036e-02, 4.5117e-02, 7.0063e-05,
        1.8131e-03, 1.4181e-05, 5.2252e-02, 1.3329e-03, 3.8927e-03, 1.0480e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,026][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0014, 0.0185, 0.2335, 0.0183, 0.0920, 0.0041, 0.0800, 0.0087, 0.0644,
        0.3865, 0.0551, 0.0374], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,027][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0832, 0.0617, 0.0719, 0.0262, 0.0939, 0.0826, 0.0372, 0.1283, 0.1518,
        0.1964, 0.0206, 0.0461], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,028][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([8.5177e-08, 8.6794e-01, 9.0481e-04, 9.3267e-02, 1.2358e-02, 2.7769e-06,
        8.3800e-04, 2.0524e-07, 2.2260e-02, 4.2134e-04, 1.2435e-03, 7.6213e-04,
        1.8311e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,031][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0014, 0.0123, 0.0227, 0.0149, 0.0085, 0.0131, 0.0777, 0.0042, 0.2465,
        0.1676, 0.1993, 0.1540, 0.0776], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,033][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([3.3588e-08, 6.0994e-02, 5.6842e-03, 3.3254e-02, 5.0044e-03, 2.5169e-06,
        6.0962e-02, 4.1264e-07, 6.3246e-01, 4.3509e-02, 4.9209e-02, 1.0859e-01,
        3.2938e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,035][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([2.8712e-06, 3.4509e-01, 5.2817e-03, 3.7368e-01, 4.9373e-02, 8.2727e-05,
        1.2215e-02, 9.7195e-06, 1.7732e-01, 5.0472e-03, 1.1467e-02, 2.0267e-02,
        1.6909e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,038][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([6.9901e-08, 7.8719e-01, 1.3248e-03, 1.6721e-01, 1.5779e-02, 3.1018e-06,
        2.2767e-03, 1.8911e-07, 2.2701e-02, 7.1774e-04, 1.6247e-03, 1.1627e-03,
        7.9525e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,042][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.0061, 0.1184, 0.0372, 0.0750, 0.0874, 0.0157, 0.0679, 0.0078, 0.3091,
        0.1668, 0.0501, 0.0462, 0.0121], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,043][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.0088, 0.0624, 0.0484, 0.0618, 0.1589, 0.0229, 0.0499, 0.0147, 0.1533,
        0.2951, 0.0471, 0.0643, 0.0124], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,043][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0041, 0.3595, 0.1951, 0.0550, 0.0745, 0.0076, 0.0598, 0.0059, 0.0969,
        0.0895, 0.0125, 0.0317, 0.0077], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,044][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([9.6756e-07, 2.0576e-01, 2.4360e-03, 4.6278e-01, 1.4702e-02, 5.9966e-05,
        6.6725e-03, 5.4559e-06, 2.9602e-01, 4.1173e-03, 4.1505e-03, 3.2412e-03,
        5.0138e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,046][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([2.0947e-07, 5.0199e-01, 1.2508e-02, 2.1587e-01, 8.9699e-02, 8.1591e-06,
        4.6146e-03, 9.1775e-07, 1.5292e-01, 3.8433e-03, 9.8161e-03, 8.5742e-03,
        1.5894e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,048][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([3.2482e-05, 2.3759e-02, 1.5652e-01, 2.3455e-02, 8.5350e-03, 2.0136e-04,
        9.7041e-02, 1.8151e-04, 6.3297e-02, 1.3891e-01, 2.1079e-01, 2.7557e-01,
        1.7100e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,051][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.0018, 0.0600, 0.0486, 0.0639, 0.0459, 0.0058, 0.0857, 0.0050, 0.2050,
        0.2039, 0.0804, 0.1831, 0.0109], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,054][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([3.1538e-04, 9.5645e-01, 2.0173e-03, 2.1591e-02, 1.4899e-02, 3.5223e-04,
        3.0528e-04, 8.0480e-05, 2.3395e-03, 2.5253e-04, 3.4152e-04, 1.2484e-04,
        5.9105e-06, 9.2509e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,058][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0136, 0.0024, 0.0040, 0.0030, 0.0029, 0.0855, 0.0343, 0.0368, 0.2421,
        0.1226, 0.1152, 0.0719, 0.1666, 0.0991], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,060][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([1.3109e-05, 4.0660e-02, 2.3378e-02, 4.6374e-02, 8.2989e-02, 3.1561e-04,
        1.7638e-01, 1.3841e-04, 2.2412e-01, 3.2099e-01, 2.3712e-02, 4.6035e-02,
        9.7212e-03, 5.1715e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,061][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([2.4566e-04, 5.0480e-01, 3.9602e-03, 3.1038e-01, 2.2714e-02, 1.4467e-03,
        8.7887e-03, 2.0448e-04, 1.1489e-01, 2.8628e-03, 7.7178e-03, 1.3221e-02,
        1.3774e-04, 8.6229e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,062][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([3.3113e-06, 8.0985e-01, 1.7355e-03, 1.6637e-01, 5.3051e-03, 5.6451e-05,
        3.1177e-03, 3.6096e-06, 9.9942e-03, 8.1034e-04, 1.2900e-03, 8.4356e-04,
        1.0433e-05, 6.1255e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,063][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0537, 0.1200, 0.0094, 0.0498, 0.0440, 0.0972, 0.0622, 0.0376, 0.3369,
        0.0947, 0.0312, 0.0210, 0.0072, 0.0350], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,066][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0231, 0.0657, 0.0206, 0.0729, 0.1053, 0.0498, 0.0450, 0.0308, 0.1381,
        0.2990, 0.0444, 0.0353, 0.0171, 0.0529], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,070][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.2136, 0.1109, 0.0693, 0.0464, 0.0767, 0.1790, 0.0462, 0.1566, 0.0277,
        0.0520, 0.0039, 0.0032, 0.0124, 0.0020], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,072][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([1.2388e-04, 7.4345e-01, 2.5922e-03, 1.3981e-01, 1.3306e-02, 8.6002e-04,
        2.5859e-03, 1.3410e-04, 9.0778e-02, 3.1242e-03, 1.2889e-03, 5.1295e-04,
        3.6805e-05, 1.4024e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,075][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([3.6927e-05, 6.7452e-01, 3.1775e-02, 1.1548e-01, 6.2164e-02, 2.3880e-04,
        3.4359e-03, 4.4815e-05, 8.6275e-02, 4.6909e-03, 9.1643e-03, 4.9893e-03,
        3.7216e-04, 6.8084e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,077][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([2.8362e-04, 1.6917e-02, 1.8389e-01, 1.6564e-02, 9.2477e-02, 1.3225e-03,
        7.0147e-02, 2.1974e-03, 4.1761e-02, 4.0472e-01, 5.3848e-02, 7.7296e-02,
        3.2558e-02, 6.0269e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,078][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0707, 0.0186, 0.0378, 0.0209, 0.0643, 0.0839, 0.0502, 0.1182, 0.0856,
        0.3138, 0.0144, 0.0485, 0.0522, 0.0210], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,079][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([2.7963e-05, 9.1140e-01, 1.7250e-03, 4.8820e-02, 1.4854e-02, 1.3819e-04,
        4.5019e-04, 1.8172e-05, 1.0476e-02, 5.4520e-04, 1.0268e-03, 5.4054e-04,
        1.5711e-05, 9.7011e-03, 2.6138e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,080][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0651, 0.0050, 0.0290, 0.0092, 0.0137, 0.1720, 0.0711, 0.0907, 0.2163,
        0.0571, 0.0667, 0.0683, 0.0689, 0.0372, 0.0295], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,082][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([1.4938e-06, 1.9026e-01, 1.5175e-02, 4.8955e-02, 4.4712e-02, 4.6776e-05,
        1.0400e-01, 1.4538e-05, 3.4942e-01, 1.3304e-01, 4.7001e-02, 4.4052e-02,
        4.4385e-03, 1.1257e-02, 7.6309e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,084][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([2.3294e-04, 4.8171e-01, 4.5164e-03, 3.0566e-01, 4.7095e-02, 1.5790e-03,
        7.0708e-03, 2.0053e-04, 9.7570e-02, 2.6860e-03, 8.7660e-03, 1.4094e-02,
        2.7847e-04, 2.7345e-02, 1.1919e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,086][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([2.2038e-06, 7.3412e-01, 5.0528e-03, 2.0906e-01, 1.9962e-02, 4.8653e-05,
        3.9171e-03, 3.9403e-06, 2.2447e-02, 6.5744e-04, 1.8650e-03, 1.7463e-03,
        1.8593e-05, 9.6263e-04, 1.3412e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,089][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.0614, 0.1132, 0.0299, 0.0532, 0.0604, 0.1796, 0.0632, 0.0488, 0.2364,
        0.0632, 0.0222, 0.0162, 0.0089, 0.0208, 0.0229], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,093][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.0351, 0.0539, 0.0291, 0.0352, 0.1375, 0.0566, 0.0392, 0.0394, 0.0834,
        0.3407, 0.0301, 0.0343, 0.0243, 0.0289, 0.0323], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,096][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.1211, 0.3401, 0.1142, 0.0473, 0.0711, 0.0843, 0.0286, 0.0822, 0.0480,
        0.0395, 0.0035, 0.0030, 0.0095, 0.0031, 0.0043], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,097][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([3.6838e-05, 4.3940e-01, 3.3179e-03, 3.0647e-01, 2.3131e-02, 5.6021e-04,
        5.7502e-03, 9.1006e-05, 1.9890e-01, 4.4013e-03, 2.2279e-03, 2.1311e-03,
        1.3959e-04, 1.2779e-02, 6.5818e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,097][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([2.0482e-05, 5.2588e-01, 2.9108e-02, 9.2574e-02, 1.1618e-01, 1.9647e-04,
        4.9305e-03, 3.2718e-05, 1.7020e-01, 6.5577e-03, 1.6880e-02, 1.1683e-02,
        4.4198e-04, 1.8526e-02, 6.7898e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,099][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0006, 0.0285, 0.0488, 0.0159, 0.0322, 0.0022, 0.1038, 0.0032, 0.0793,
        0.2487, 0.1638, 0.2068, 0.0312, 0.0244, 0.0105], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,102][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.0426, 0.0489, 0.0619, 0.0372, 0.0821, 0.0857, 0.0645, 0.0705, 0.0903,
        0.1930, 0.0271, 0.0620, 0.0332, 0.0451, 0.0556], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,105][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([4.1414e-05, 3.3917e-01, 3.4755e-02, 1.6673e-01, 1.6604e-01, 4.9321e-04,
        2.5499e-02, 1.1616e-04, 9.0454e-02, 2.8366e-02, 4.0294e-02, 2.8992e-02,
        2.5149e-03, 6.1346e-02, 1.4846e-02, 3.4037e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,109][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0002, 0.1041, 0.0354, 0.0446, 0.0291, 0.0012, 0.0578, 0.0004, 0.1696,
        0.1155, 0.1373, 0.1390, 0.0244, 0.1000, 0.0406, 0.0007],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,111][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([3.6448e-09, 2.5444e-01, 1.3850e-03, 2.8831e-02, 3.0098e-03, 9.9863e-08,
        4.0286e-02, 2.4415e-08, 4.9527e-01, 6.9016e-03, 4.8718e-02, 9.2139e-02,
        3.8066e-05, 2.8190e-02, 7.9278e-04, 3.6295e-08], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,113][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([7.5693e-05, 1.6763e-01, 2.7575e-02, 2.4726e-01, 8.4718e-02, 8.5054e-04,
        4.5209e-02, 2.3029e-04, 1.8175e-01, 3.7253e-02, 4.9186e-02, 6.5513e-02,
        4.5188e-03, 6.7526e-02, 2.0156e-02, 5.4274e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,114][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([1.2835e-05, 4.4061e-01, 1.9625e-02, 2.1938e-01, 8.6337e-02, 1.7916e-04,
        2.3088e-02, 3.7473e-05, 9.6078e-02, 2.0328e-02, 3.0456e-02, 2.3256e-02,
        1.5559e-03, 3.2055e-02, 6.8823e-03, 1.1526e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,115][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0084, 0.0918, 0.0510, 0.0859, 0.0861, 0.0200, 0.0649, 0.0123, 0.1476,
        0.1149, 0.0692, 0.0518, 0.0302, 0.0685, 0.0815, 0.0158],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,116][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0036, 0.0618, 0.0567, 0.0566, 0.0866, 0.0090, 0.0666, 0.0060, 0.1168,
        0.1379, 0.0764, 0.1094, 0.0243, 0.1012, 0.0804, 0.0065],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,117][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([7.1758e-05, 4.3163e-01, 5.2904e-02, 7.3745e-02, 4.3428e-02, 2.7648e-04,
        5.6687e-02, 1.6511e-04, 1.1419e-01, 5.2815e-02, 4.5125e-02, 5.5585e-02,
        5.8386e-03, 4.5359e-02, 2.1953e-02, 2.3665e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,119][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([3.2041e-05, 2.2659e-01, 2.1420e-02, 2.7068e-01, 8.1315e-02, 4.3911e-04,
        3.2070e-02, 1.1595e-04, 2.0781e-01, 2.9836e-02, 3.8597e-02, 3.8795e-02,
        1.8290e-03, 3.6518e-02, 1.3693e-02, 2.5826e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,122][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([2.1732e-05, 2.6058e-01, 6.7681e-02, 1.3176e-01, 1.9476e-01, 2.5466e-04,
        2.1623e-02, 6.9690e-05, 1.2771e-01, 2.9105e-02, 3.8951e-02, 3.4141e-02,
        6.6959e-03, 4.9320e-02, 3.7121e-02, 2.0926e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,124][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([8.5982e-08, 4.9486e-02, 6.8406e-03, 3.5884e-02, 7.0138e-03, 1.1275e-06,
        9.4785e-02, 4.0959e-07, 2.0990e-01, 1.7322e-02, 2.0767e-01, 3.3143e-01,
        5.0486e-04, 3.6143e-02, 3.0112e-03, 7.6042e-07], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,127][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0003, 0.1242, 0.0288, 0.0693, 0.0485, 0.0011, 0.0790, 0.0008, 0.1981,
        0.0661, 0.0926, 0.1362, 0.0101, 0.1106, 0.0333, 0.0010],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,130][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([3.1894e-05, 7.7631e-01, 8.3498e-03, 1.0737e-01, 4.6142e-02, 2.3754e-04,
        2.8061e-03, 3.7086e-05, 2.6750e-02, 4.0797e-03, 7.0245e-03, 2.4498e-03,
        1.2428e-04, 1.6131e-02, 1.1748e-03, 1.3388e-04, 8.5107e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,132][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0004, 0.0251, 0.0130, 0.0137, 0.0121, 0.0024, 0.0407, 0.0010, 0.2628,
        0.1424, 0.1525, 0.1251, 0.0372, 0.1299, 0.0302, 0.0018, 0.0096],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,132][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([2.1111e-08, 1.5412e-01, 1.9972e-03, 3.6426e-02, 7.7633e-03, 7.8321e-07,
        6.5132e-02, 2.3021e-07, 5.1491e-01, 2.9513e-02, 4.8831e-02, 1.1918e-01,
        1.1311e-04, 2.1060e-02, 9.5202e-04, 2.9114e-07, 6.7742e-06],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,133][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([6.3733e-05, 2.6498e-01, 1.0578e-02, 3.2185e-01, 5.0872e-02, 7.3008e-04,
        2.0705e-02, 1.3145e-04, 2.0463e-01, 1.3663e-02, 2.7019e-02, 3.3831e-02,
        9.4319e-04, 4.1057e-02, 4.3768e-03, 3.6949e-04, 4.2082e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,135][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([4.9957e-06, 6.4002e-01, 9.1007e-03, 2.1884e-01, 3.2081e-02, 8.7372e-05,
        1.0015e-02, 1.1043e-05, 5.5694e-02, 6.6741e-03, 1.1082e-02, 7.0349e-03,
        1.9734e-04, 7.7732e-03, 8.8724e-04, 4.0929e-05, 4.5751e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,138][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0082, 0.1193, 0.0242, 0.0868, 0.0692, 0.0241, 0.0464, 0.0103, 0.2713,
        0.1020, 0.0522, 0.0369, 0.0131, 0.0551, 0.0320, 0.0172, 0.0316],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,142][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0053, 0.0644, 0.0444, 0.0555, 0.0959, 0.0135, 0.0555, 0.0078, 0.1365,
        0.1882, 0.0643, 0.0747, 0.0215, 0.0847, 0.0617, 0.0091, 0.0170],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,146][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0015, 0.3550, 0.0704, 0.0754, 0.0696, 0.0031, 0.0586, 0.0023, 0.1654,
        0.0737, 0.0314, 0.0311, 0.0094, 0.0319, 0.0139, 0.0029, 0.0045],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,149][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.8498e-05, 4.6314e-01, 6.8141e-03, 2.3414e-01, 3.7757e-02, 2.7201e-04,
        8.6121e-03, 4.5585e-05, 2.1163e-01, 8.2523e-03, 7.8706e-03, 6.4485e-03,
        2.4124e-04, 1.2023e-02, 1.8658e-03, 1.1353e-04, 7.5362e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,150][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.8251e-05, 4.2701e-01, 6.7819e-02, 1.2626e-01, 1.4164e-01, 1.7059e-04,
        9.0300e-03, 3.9175e-05, 1.3995e-01, 1.2776e-02, 2.2078e-02, 1.4244e-02,
        1.6039e-03, 2.2628e-02, 1.3466e-02, 1.4454e-04, 1.1192e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,150][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([2.8349e-07, 2.8381e-02, 1.0319e-02, 4.2774e-02, 8.1050e-03, 4.5029e-06,
        6.9524e-02, 2.6230e-06, 1.3484e-01, 6.7775e-02, 2.3982e-01, 3.7357e-01,
        9.8804e-04, 2.1027e-02, 2.7968e-03, 3.8702e-06, 5.9556e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,151][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0013, 0.0504, 0.0257, 0.0423, 0.0506, 0.0032, 0.0568, 0.0031, 0.2316,
        0.1188, 0.0713, 0.1488, 0.0126, 0.1297, 0.0397, 0.0041, 0.0101],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,153][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([1.0173e-06, 9.8250e-01, 3.6267e-04, 1.1414e-02, 2.5607e-03, 7.4382e-06,
        2.4370e-04, 7.6537e-07, 1.7696e-03, 1.4678e-04, 6.3279e-05, 7.2764e-05,
        7.4958e-07, 7.3316e-04, 1.0060e-05, 4.8637e-06, 8.6526e-05, 2.6996e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,156][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([0.0012, 0.0056, 0.0269, 0.0169, 0.0155, 0.0107, 0.0624, 0.0036, 0.3114,
        0.1203, 0.0743, 0.0791, 0.0520, 0.0347, 0.0246, 0.0045, 0.0192, 0.1372],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,158][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([1.9274e-06, 4.9033e-01, 1.6008e-02, 3.2865e-02, 2.9366e-02, 2.3872e-05,
        6.6311e-02, 1.1696e-05, 2.7190e-01, 5.2676e-02, 1.2849e-02, 1.6598e-02,
        1.6111e-03, 4.3659e-03, 4.2452e-03, 8.9131e-06, 7.7479e-05, 7.5219e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,160][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([6.4874e-05, 4.5991e-01, 3.9997e-03, 2.9939e-01, 4.2248e-02, 5.6366e-04,
        7.5193e-03, 7.3715e-05, 1.1963e-01, 3.0450e-03, 7.9092e-03, 1.4581e-02,
        1.9136e-04, 3.0511e-02, 1.2242e-03, 2.5967e-04, 3.9443e-03, 4.9377e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,163][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([7.4178e-07, 8.4715e-01, 2.8395e-03, 1.0698e-01, 8.5031e-03, 2.0607e-05,
        3.7536e-03, 1.5489e-06, 2.3944e-02, 2.1125e-03, 1.2384e-03, 1.0294e-03,
        1.5182e-05, 1.9568e-03, 1.1089e-04, 8.9474e-06, 2.0973e-04, 1.2394e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,167][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([0.0090, 0.1267, 0.0793, 0.0453, 0.1592, 0.0262, 0.0636, 0.0084, 0.1600,
        0.0983, 0.0208, 0.0168, 0.0121, 0.0413, 0.0401, 0.0213, 0.0405, 0.0311],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,168][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([0.0082, 0.0661, 0.0503, 0.0766, 0.2056, 0.0252, 0.0378, 0.0137, 0.0825,
        0.2230, 0.0335, 0.0269, 0.0175, 0.0404, 0.0256, 0.0141, 0.0195, 0.0334],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,169][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([0.0069, 0.5574, 0.0654, 0.0743, 0.1010, 0.0115, 0.0278, 0.0089, 0.0517,
        0.0463, 0.0050, 0.0034, 0.0094, 0.0051, 0.0037, 0.0089, 0.0071, 0.0061],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,170][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([1.2736e-05, 7.0235e-01, 2.5144e-03, 1.4337e-01, 1.0438e-02, 2.0907e-04,
        4.9895e-03, 2.4828e-05, 1.1578e-01, 3.5935e-03, 2.3250e-03, 1.8113e-03,
        1.1035e-04, 1.0083e-02, 5.6055e-04, 9.2760e-05, 1.4599e-03, 2.7097e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,172][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([5.5526e-06, 6.2054e-01, 2.1418e-02, 1.3503e-01, 7.9553e-02, 5.7018e-05,
        3.0731e-03, 8.1578e-06, 9.9238e-02, 3.4929e-03, 1.0723e-02, 5.4187e-03,
        1.1199e-04, 1.2814e-02, 3.5067e-03, 5.2956e-05, 7.1219e-04, 4.2451e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,176][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([0.0020, 0.0376, 0.0726, 0.0191, 0.1191, 0.0032, 0.1293, 0.0066, 0.0384,
        0.2611, 0.0780, 0.0831, 0.0606, 0.0325, 0.0238, 0.0067, 0.0116, 0.0145],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,180][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([0.0094, 0.1524, 0.0364, 0.0650, 0.0796, 0.0222, 0.0699, 0.0173, 0.1520,
        0.1128, 0.0345, 0.0929, 0.0143, 0.0489, 0.0249, 0.0173, 0.0232, 0.0269],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,182][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.8422e-03, 9.7300e-01, 1.1986e-03, 1.0700e-02, 3.0679e-03, 1.5413e-03,
        2.1226e-04, 3.1281e-04, 1.0551e-03, 1.3018e-04, 1.2858e-04, 4.8060e-05,
        3.2545e-06, 9.9401e-04, 2.9135e-05, 1.0572e-03, 1.9027e-03, 1.0216e-04,
        2.6714e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,184][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0144, 0.0013, 0.0035, 0.0011, 0.0018, 0.0522, 0.0211, 0.0252, 0.1839,
        0.0397, 0.0785, 0.0509, 0.0790, 0.0400, 0.0098, 0.0515, 0.1996, 0.0656,
        0.0808], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,185][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([4.2215e-05, 1.4798e-02, 1.3070e-02, 2.4780e-02, 3.5784e-02, 5.8148e-04,
        1.7162e-01, 3.2566e-04, 4.1462e-01, 1.9696e-01, 1.7093e-02, 5.8653e-02,
        8.6140e-03, 8.0926e-03, 2.1178e-02, 3.4919e-04, 1.7740e-03, 3.8603e-03,
        7.8083e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,186][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.1968e-03, 4.5016e-01, 2.4722e-03, 2.5457e-01, 2.5747e-02, 4.0495e-03,
        8.0438e-03, 7.0391e-04, 1.1235e-01, 3.5189e-03, 8.1122e-03, 1.2978e-02,
        1.7888e-04, 1.8856e-02, 5.2704e-04, 2.1326e-03, 1.5182e-02, 2.0998e-03,
        7.7118e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,187][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.8217e-05, 8.4972e-01, 2.3697e-03, 1.0705e-01, 7.0902e-03, 2.4686e-04,
        5.5014e-03, 1.5730e-05, 1.6115e-02, 1.2034e-03, 1.6153e-03, 1.1004e-03,
        1.5306e-05, 4.9965e-04, 5.5534e-05, 8.8426e-05, 7.7868e-04, 3.9764e-05,
        6.4746e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,189][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0515, 0.0683, 0.0099, 0.0277, 0.0315, 0.1045, 0.0577, 0.0320, 0.1711,
        0.0537, 0.0183, 0.0121, 0.0039, 0.0210, 0.0090, 0.0700, 0.1180, 0.0073,
        0.1324], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,192][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0149, 0.0354, 0.0191, 0.0541, 0.0613, 0.0410, 0.0422, 0.0232, 0.1191,
        0.3161, 0.0332, 0.0301, 0.0169, 0.0291, 0.0215, 0.0219, 0.0317, 0.0600,
        0.0290], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,196][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1648, 0.0859, 0.0981, 0.0325, 0.0464, 0.1482, 0.0446, 0.1287, 0.0389,
        0.0304, 0.0035, 0.0047, 0.0052, 0.0026, 0.0037, 0.1095, 0.0467, 0.0045,
        0.0009], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,198][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.1030e-04, 7.1672e-01, 1.6168e-03, 1.4756e-01, 6.7091e-03, 1.5688e-03,
        3.2170e-03, 2.6042e-04, 1.0455e-01, 2.4884e-03, 8.7851e-04, 5.1518e-04,
        4.4643e-05, 2.6593e-03, 1.1973e-04, 5.1515e-04, 1.8006e-03, 8.7124e-05,
        8.4786e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,200][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.7584e-04, 6.4310e-01, 2.7118e-02, 8.4145e-02, 6.0752e-02, 6.4722e-04,
        4.1366e-03, 1.5266e-04, 7.3897e-02, 4.0013e-03, 6.4933e-03, 4.4237e-03,
        3.1118e-04, 7.4093e-03, 2.3097e-03, 6.6450e-04, 3.3964e-03, 4.5105e-03,
        7.2356e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,202][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0039, 0.0033, 0.1484, 0.0295, 0.0288, 0.0118, 0.0962, 0.0230, 0.0302,
        0.2901, 0.0741, 0.0929, 0.0599, 0.0090, 0.0368, 0.0181, 0.0196, 0.0228,
        0.0016], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,203][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0728, 0.0091, 0.0330, 0.0137, 0.0468, 0.0685, 0.0260, 0.1083, 0.0740,
        0.1506, 0.0088, 0.0348, 0.0259, 0.0221, 0.0582, 0.0953, 0.0693, 0.0576,
        0.0252], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,207][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:35,209][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[5328],
        [1257],
        [1382],
        [ 700],
        [5698],
        [ 267],
        [ 179],
        [ 265],
        [ 654],
        [ 557],
        [ 189],
        [  69],
        [ 117],
        [ 184],
        [ 490],
        [  85],
        [  36],
        [ 106],
        [  97]], device='cuda:0')
[2024-07-24 10:27:35,212][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 7039],
        [ 3804],
        [ 6712],
        [ 4670],
        [16162],
        [ 2957],
        [ 1748],
        [ 2830],
        [ 4753],
        [ 4183],
        [ 2738],
        [  940],
        [ 1634],
        [ 2079],
        [ 4180],
        [ 1654],
        [  539],
        [ 1233],
        [ 1194]], device='cuda:0')
[2024-07-24 10:27:35,215][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[41802],
        [30606],
        [30557],
        [30524],
        [30545],
        [31560],
        [30533],
        [31424],
        [30545],
        [30528],
        [30594],
        [30518],
        [30510],
        [30609],
        [30572],
        [31295],
        [30626],
        [30528],
        [30547]], device='cuda:0')
[2024-07-24 10:27:35,217][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[16414],
        [18486],
        [20361],
        [20462],
        [25299],
        [26137],
        [26819],
        [26601],
        [26429],
        [26329],
        [26098],
        [26318],
        [24725],
        [24613],
        [24825],
        [24261],
        [24013],
        [24291],
        [23830]], device='cuda:0')
[2024-07-24 10:27:35,220][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[24780],
        [12865],
        [18962],
        [17279],
        [30534],
        [26979],
        [23727],
        [23739],
        [20628],
        [19836],
        [19589],
        [18398],
        [18373],
        [17869],
        [18671],
        [18218],
        [17545],
        [17539],
        [17228]], device='cuda:0')
[2024-07-24 10:27:35,223][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[341],
        [248],
        [156],
        [150],
        [185],
        [113],
        [ 99],
        [102],
        [103],
        [ 97],
        [101],
        [104],
        [107],
        [103],
        [103],
        [107],
        [ 94],
        [ 89],
        [ 78]], device='cuda:0')
[2024-07-24 10:27:35,224][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 5197],
        [ 9834],
        [11267],
        [11772],
        [11427],
        [11294],
        [11729],
        [11514],
        [11639],
        [12312],
        [12484],
        [12485],
        [11959],
        [11872],
        [12355],
        [12255],
        [12378],
        [12393],
        [12816]], device='cuda:0')
[2024-07-24 10:27:35,226][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[44656],
        [42135],
        [42841],
        [42397],
        [39160],
        [38253],
        [37113],
        [36558],
        [36214],
        [35401],
        [34608],
        [34375],
        [34972],
        [34871],
        [35133],
        [34636],
        [34134],
        [33658],
        [33212]], device='cuda:0')
[2024-07-24 10:27:35,227][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[24],
        [16],
        [16],
        [14],
        [16],
        [15],
        [15],
        [16],
        [16],
        [17],
        [16],
        [17],
        [17],
        [18],
        [18],
        [18],
        [18],
        [18],
        [17]], device='cuda:0')
[2024-07-24 10:27:35,230][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[40698],
        [12442],
        [13172],
        [13109],
        [15152],
        [14856],
        [14791],
        [14313],
        [12123],
        [12552],
        [10800],
        [11038],
        [11386],
        [10245],
        [11296],
        [11725],
        [11087],
        [10577],
        [ 9826]], device='cuda:0')
[2024-07-24 10:27:35,233][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[32614],
        [34879],
        [31358],
        [32741],
        [30828],
        [33222],
        [34394],
        [34598],
        [35533],
        [35873],
        [36103],
        [36226],
        [36368],
        [36436],
        [36055],
        [36461],
        [36423],
        [36807],
        [37119]], device='cuda:0')
[2024-07-24 10:27:35,236][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[12571],
        [ 5425],
        [ 5594],
        [ 4582],
        [ 4047],
        [ 4024],
        [ 4122],
        [ 4097],
        [ 3853],
        [ 4307],
        [ 4259],
        [ 4367],
        [ 4385],
        [ 4328],
        [ 4255],
        [ 4240],
        [ 4262],
        [ 4293],
        [ 4203]], device='cuda:0')
[2024-07-24 10:27:35,238][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 844],
        [ 259],
        [ 679],
        [ 506],
        [2467],
        [2297],
        [2809],
        [2198],
        [2586],
        [2133],
        [1856],
        [2178],
        [1875],
        [2247],
        [2264],
        [1829],
        [2128],
        [2725],
        [2222]], device='cuda:0')
[2024-07-24 10:27:35,241][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[35205],
        [42260],
        [48544],
        [46839],
        [47952],
        [44863],
        [47620],
        [45128],
        [43480],
        [46469],
        [40920],
        [44962],
        [42250],
        [43881],
        [45674],
        [42089],
        [41836],
        [43736],
        [44472]], device='cuda:0')
[2024-07-24 10:27:35,244][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 5721],
        [13435],
        [11982],
        [13851],
        [20194],
        [13044],
        [14146],
        [ 9627],
        [10121],
        [11829],
        [ 8247],
        [11770],
        [11832],
        [14817],
        [10487],
        [12145],
        [15381],
        [15213],
        [10623]], device='cuda:0')
[2024-07-24 10:27:35,245][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[20352],
        [38069],
        [38081],
        [38083],
        [38056],
        [34290],
        [38021],
        [32600],
        [38064],
        [38011],
        [38006],
        [37999],
        [37799],
        [37969],
        [37865],
        [33244],
        [37282],
        [38049],
        [38038]], device='cuda:0')
[2024-07-24 10:27:35,247][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[25736],
        [23560],
        [ 9678],
        [ 6194],
        [ 6119],
        [ 2884],
        [ 8163],
        [ 3698],
        [ 8795],
        [ 9020],
        [10845],
        [10957],
        [14067],
        [14097],
        [12104],
        [10409],
        [13264],
        [11928],
        [13800]], device='cuda:0')
[2024-07-24 10:27:35,248][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[18101],
        [25976],
        [28639],
        [20263],
        [25352],
        [24170],
        [26752],
        [25911],
        [25718],
        [26224],
        [20209],
        [19759],
        [20511],
        [20617],
        [22090],
        [21376],
        [21063],
        [24073],
        [22430]], device='cuda:0')
[2024-07-24 10:27:35,251][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[24000],
        [29206],
        [28640],
        [25876],
        [24281],
        [19778],
        [22465],
        [17864],
        [22461],
        [21282],
        [20926],
        [20985],
        [19427],
        [21316],
        [20764],
        [19705],
        [18858],
        [20456],
        [20596]], device='cuda:0')
[2024-07-24 10:27:35,254][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[33458],
        [47491],
        [47554],
        [47687],
        [47832],
        [48638],
        [48111],
        [48780],
        [48042],
        [47865],
        [48001],
        [48170],
        [48202],
        [48100],
        [48312],
        [48489],
        [48447],
        [48056],
        [48042]], device='cuda:0')
[2024-07-24 10:27:35,256][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[21829],
        [20126],
        [23563],
        [25400],
        [23177],
        [24761],
        [22101],
        [24717],
        [27456],
        [31830],
        [31235],
        [30394],
        [30443],
        [32118],
        [29735],
        [28725],
        [30809],
        [27675],
        [33336]], device='cuda:0')
[2024-07-24 10:27:35,259][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[47122],
        [38542],
        [37161],
        [26091],
        [20494],
        [12845],
        [20130],
        [17660],
        [27157],
        [24303],
        [26908],
        [25323],
        [26313],
        [28773],
        [26100],
        [33255],
        [31779],
        [24564],
        [29956]], device='cuda:0')
[2024-07-24 10:27:35,262][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[34321],
        [25726],
        [25708],
        [22996],
        [18219],
        [18565],
        [19826],
        [18458],
        [16495],
        [15203],
        [13606],
        [18087],
        [15233],
        [14578],
        [16721],
        [13043],
        [11957],
        [15621],
        [16616]], device='cuda:0')
[2024-07-24 10:27:35,264][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[45413],
        [27880],
        [27412],
        [27316],
        [27329],
        [27567],
        [27328],
        [28605],
        [28536],
        [31535],
        [29469],
        [29067],
        [32183],
        [29004],
        [30909],
        [33635],
        [31424],
        [29576],
        [29350]], device='cuda:0')
[2024-07-24 10:27:35,266][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[31078],
        [44105],
        [42848],
        [43032],
        [43223],
        [26521],
        [41479],
        [28743],
        [42977],
        [42015],
        [42193],
        [42992],
        [41532],
        [42032],
        [40742],
        [35537],
        [38378],
        [41672],
        [42009]], device='cuda:0')
[2024-07-24 10:27:35,267][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[46182],
        [31935],
        [27111],
        [29182],
        [29068],
        [33912],
        [36933],
        [33184],
        [35818],
        [35858],
        [39231],
        [39217],
        [32584],
        [39539],
        [36025],
        [35625],
        [35024],
        [39589],
        [36757]], device='cuda:0')
[2024-07-24 10:27:35,269][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[36111],
        [22821],
        [24287],
        [29208],
        [27993],
        [29718],
        [33550],
        [30393],
        [36109],
        [37305],
        [41032],
        [38632],
        [39381],
        [42064],
        [39678],
        [36945],
        [38617],
        [36811],
        [41273]], device='cuda:0')
[2024-07-24 10:27:35,272][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 2158],
        [ 4933],
        [ 8734],
        [12301],
        [14744],
        [20590],
        [13136],
        [18701],
        [ 9379],
        [ 8659],
        [ 7959],
        [ 7850],
        [ 8540],
        [ 6790],
        [ 8094],
        [10571],
        [ 8854],
        [ 8467],
        [ 6151]], device='cuda:0')
[2024-07-24 10:27:35,274][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[39138],
        [ 3713],
        [ 3983],
        [ 4729],
        [ 1313],
        [22659],
        [ 3356],
        [28643],
        [ 3219],
        [ 4902],
        [ 4562],
        [ 5387],
        [ 4445],
        [ 2405],
        [ 5317],
        [15223],
        [ 5531],
        [ 5171],
        [ 3444]], device='cuda:0')
[2024-07-24 10:27:35,277][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884]], device='cuda:0')
[2024-07-24 10:27:35,357][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:35,359][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,360][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,360][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,361][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,362][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,362][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,363][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,364][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,364][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,365][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,366][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,366][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,367][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6003, 0.3997], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,368][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1734, 0.8266], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,371][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.5028, 0.4972], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,375][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0167, 0.9833], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,378][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0246, 0.9754], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,380][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2535, 0.7465], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,380][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.8128, 0.1872], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,381][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0200, 0.9800], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,382][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0176, 0.9824], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,383][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.5225, 0.4775], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,385][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1084, 0.8916], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,388][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2157, 0.7843], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,391][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.6398, 0.3489, 0.0113], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,395][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0044, 0.8237, 0.1719], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,398][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.1803, 0.3031, 0.5166], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,398][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0123, 0.5499, 0.4379], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,399][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.0032, 0.9312, 0.0656], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,400][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0068, 0.9558, 0.0374], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,401][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.9765, 0.0111, 0.0124], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,402][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([7.7226e-04, 9.4011e-01, 5.9116e-02], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,405][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.0070, 0.4893, 0.5038], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,409][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.2644, 0.3320, 0.4036], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,413][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.0660, 0.7429, 0.1911], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,416][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.0150, 0.5717, 0.4133], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,416][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3399, 0.3004, 0.0095, 0.3501], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,417][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0157, 0.7450, 0.2156, 0.0237], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,418][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1192, 0.2383, 0.4223, 0.2202], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,419][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0056, 0.4528, 0.3536, 0.1879], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,421][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0041, 0.6199, 0.0488, 0.3272], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,423][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([4.3555e-04, 9.7793e-01, 1.6328e-02, 5.3047e-03], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,426][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.9258, 0.0157, 0.0478, 0.0107], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,429][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([7.7103e-04, 8.0300e-01, 8.2384e-02, 1.1384e-01], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,432][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0064, 0.3150, 0.3415, 0.3371], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,434][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3604, 0.2883, 0.2266, 0.1248], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,435][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0479, 0.2981, 0.0799, 0.5741], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,435][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0107, 0.3033, 0.3536, 0.3324], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,436][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.3540, 0.2885, 0.0104, 0.3012, 0.0459], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,438][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([0.0287, 0.5157, 0.2653, 0.0564, 0.1339], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,441][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.0883, 0.2053, 0.3696, 0.1825, 0.1542], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,444][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.0057, 0.3755, 0.3030, 0.1579, 0.1580], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,448][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.0031, 0.6015, 0.0237, 0.3143, 0.0574], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,450][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([5.0256e-04, 9.6071e-01, 1.5721e-02, 1.5304e-02, 7.7589e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,452][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.9224, 0.0220, 0.0360, 0.0166, 0.0030], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,453][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([2.1720e-04, 7.1987e-01, 5.5251e-02, 1.7773e-01, 4.6934e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,453][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.0033, 0.2403, 0.2675, 0.2464, 0.2426], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,454][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.2699, 0.2505, 0.1817, 0.1431, 0.1547], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,456][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.0260, 0.2295, 0.0365, 0.4995, 0.2084], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,459][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([0.0342, 0.3214, 0.0864, 0.3106, 0.2474], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,462][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.2678, 0.2960, 0.0064, 0.3602, 0.0333, 0.0363], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:35,465][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ had] are: tensor([4.2095e-05, 9.2617e-01, 3.0113e-02, 9.2107e-03, 3.4253e-02, 2.0856e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:35,468][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.1146, 0.1444, 0.3021, 0.1444, 0.1234, 0.1711], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:35,470][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ had] are: tensor([3.8002e-04, 4.6190e-01, 3.1838e-01, 1.1031e-01, 1.0897e-01, 6.2568e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:35,471][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ had] are: tensor([5.7692e-04, 4.6697e-01, 4.6485e-02, 3.8436e-01, 1.0156e-01, 4.6582e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:35,471][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ had] are: tensor([1.6744e-04, 7.4790e-01, 7.7178e-02, 7.6460e-02, 9.7216e-02, 1.0739e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:35,472][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.3826, 0.0742, 0.2535, 0.0592, 0.0254, 0.2052], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:35,473][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ had] are: tensor([1.1904e-05, 4.7895e-01, 1.9258e-01, 1.8852e-01, 1.3955e-01, 3.8405e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:35,475][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0015, 0.1937, 0.2345, 0.2219, 0.2106, 0.1379], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:35,478][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.1699, 0.2240, 0.2233, 0.1840, 0.1928, 0.0060], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:35,481][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0038, 0.1135, 0.1429, 0.3279, 0.3881, 0.0237], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:35,484][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ had] are: tensor([1.9507e-04, 6.4612e-02, 2.9235e-01, 2.7321e-01, 3.6808e-01, 1.5552e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:35,488][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0872, 0.0726, 0.0020, 0.0957, 0.0080, 0.0281, 0.7064],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:35,488][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0314, 0.4906, 0.2126, 0.0596, 0.1453, 0.0242, 0.0363],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:35,489][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0856, 0.1472, 0.2528, 0.1329, 0.1161, 0.1452, 0.1202],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:35,490][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0030, 0.3857, 0.2903, 0.1346, 0.1349, 0.0007, 0.0509],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:35,491][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([2.8056e-03, 5.2142e-01, 2.7813e-02, 3.4559e-01, 5.6073e-02, 2.1982e-04,
        4.6084e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:35,492][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([6.7777e-06, 9.6099e-01, 1.0397e-02, 1.8992e-02, 9.4954e-03, 4.7208e-05,
        6.8323e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:35,495][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.7734, 0.0184, 0.0401, 0.0232, 0.0039, 0.1324, 0.0086],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:35,497][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([5.8323e-05, 7.5069e-01, 5.7329e-02, 1.3136e-01, 3.5072e-02, 4.3860e-04,
        2.5052e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:35,501][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0021, 0.1715, 0.1868, 0.1902, 0.1761, 0.1256, 0.1476],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:35,504][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1654, 0.1806, 0.1628, 0.1619, 0.1190, 0.0153, 0.1949],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:35,506][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0147, 0.0719, 0.0206, 0.2649, 0.1336, 0.0987, 0.3957],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:35,507][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0105, 0.1241, 0.0654, 0.1914, 0.1359, 0.0136, 0.4591],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:35,508][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0204, 0.0302, 0.0015, 0.0441, 0.0056, 0.0051, 0.8764, 0.0167],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:35,508][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([1.1289e-05, 9.4246e-01, 1.5930e-02, 9.2936e-03, 2.2467e-02, 1.0005e-04,
        9.6857e-03, 5.7172e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:35,510][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0622, 0.1145, 0.2097, 0.0932, 0.0771, 0.1133, 0.0857, 0.2443],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:35,512][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([3.9021e-04, 4.6683e-01, 3.0192e-01, 1.1238e-01, 9.6509e-02, 4.7988e-05,
        2.1901e-02, 1.6949e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:35,514][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([3.2456e-04, 3.2732e-01, 7.4084e-02, 3.8227e-01, 1.4698e-01, 3.3909e-04,
        6.8562e-02, 1.2022e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:35,517][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([4.7956e-05, 6.8970e-01, 6.0514e-02, 1.2353e-01, 1.1572e-01, 7.4311e-04,
        9.5706e-03, 1.8330e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:35,520][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0893, 0.1155, 0.3303, 0.1145, 0.0680, 0.1233, 0.0869, 0.0721],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:35,522][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([9.1188e-06, 2.2790e-01, 1.7335e-01, 2.3419e-01, 1.3559e-01, 1.7529e-03,
        2.2710e-01, 1.0728e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:35,524][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0017, 0.1491, 0.1762, 0.1663, 0.1608, 0.1134, 0.1349, 0.0976],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:35,525][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0771, 0.1570, 0.2024, 0.1410, 0.1790, 0.0038, 0.2361, 0.0036],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:35,526][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0012, 0.0807, 0.1158, 0.2355, 0.2819, 0.0100, 0.2715, 0.0033],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:35,526][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([8.0209e-05, 3.8916e-02, 1.9359e-01, 1.7029e-01, 2.0761e-01, 1.0726e-03,
        3.8803e-01, 4.2133e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:35,528][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0365, 0.0594, 0.0032, 0.0853, 0.0091, 0.0300, 0.6143, 0.0399, 0.1223],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:35,531][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0605, 0.2825, 0.2585, 0.0430, 0.1310, 0.0385, 0.0490, 0.0699, 0.0671],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:35,535][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0363, 0.1084, 0.1979, 0.0950, 0.0782, 0.1056, 0.0896, 0.1923, 0.0966],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:35,538][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0099, 0.2736, 0.2118, 0.1223, 0.1201, 0.0019, 0.0579, 0.0013, 0.2013],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:35,540][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ of] are: tensor([9.5148e-03, 4.0609e-01, 2.0457e-02, 2.6011e-01, 4.4555e-02, 3.7374e-04,
        4.7066e-02, 3.7831e-04, 2.1146e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:35,542][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ of] are: tensor([3.1158e-05, 9.7479e-01, 7.0031e-03, 1.2652e-02, 4.8307e-03, 1.0543e-04,
        7.8704e-05, 1.4420e-05, 4.8932e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:35,543][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.3046, 0.0289, 0.1045, 0.0513, 0.0137, 0.2150, 0.0319, 0.2158, 0.0342],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:35,544][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ of] are: tensor([1.5284e-03, 5.5528e-01, 3.6827e-02, 6.8244e-02, 2.4368e-02, 2.4519e-03,
        1.4864e-02, 2.3600e-04, 2.9620e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:35,545][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0019, 0.1310, 0.1453, 0.1417, 0.1375, 0.0983, 0.1158, 0.0828, 0.1457],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:35,546][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.1537, 0.1115, 0.1548, 0.1023, 0.0839, 0.0085, 0.1511, 0.0079, 0.2264],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:35,549][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0180, 0.0286, 0.0060, 0.0710, 0.0455, 0.0699, 0.1111, 0.0200, 0.6300],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:35,550][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0302, 0.0919, 0.0640, 0.0602, 0.0595, 0.0149, 0.1776, 0.0180, 0.4837],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:35,554][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0239, 0.0691, 0.0027, 0.1008, 0.0133, 0.0244, 0.5294, 0.0275, 0.1497,
        0.0593], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:35,558][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0161, 0.3541, 0.2203, 0.0448, 0.1696, 0.0164, 0.0463, 0.0236, 0.0704,
        0.0383], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:35,562][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0434, 0.0995, 0.1581, 0.0865, 0.0703, 0.0868, 0.0726, 0.1424, 0.0937,
        0.1469], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:35,562][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0038, 0.2811, 0.1991, 0.1029, 0.1003, 0.0007, 0.0417, 0.0004, 0.1956,
        0.0743], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:35,563][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([2.3214e-03, 3.7467e-01, 1.1568e-02, 2.7135e-01, 3.0130e-02, 1.5716e-04,
        4.5388e-02, 1.1595e-04, 2.3780e-01, 2.6505e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:35,564][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([2.8285e-06, 9.6750e-01, 5.0540e-03, 2.0834e-02, 5.7279e-03, 2.4001e-05,
        8.5237e-05, 2.5378e-06, 7.4450e-04, 2.2371e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:35,565][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.5054, 0.0203, 0.0426, 0.0298, 0.0062, 0.1291, 0.0104, 0.2040, 0.0281,
        0.0240], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:35,566][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([4.7255e-05, 1.4390e-01, 3.7364e-02, 6.3112e-02, 2.7095e-02, 2.4240e-03,
        2.3964e-02, 9.1619e-05, 6.9122e-01, 1.0776e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:35,569][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0027, 0.1136, 0.1313, 0.1190, 0.1233, 0.0954, 0.1048, 0.0809, 0.1314,
        0.0977], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:35,573][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.1098, 0.0992, 0.0890, 0.0928, 0.0833, 0.0071, 0.1241, 0.0067, 0.2082,
        0.1798], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:35,578][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0010, 0.0177, 0.0050, 0.0799, 0.0479, 0.0128, 0.1214, 0.0026, 0.5960,
        0.1157], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:35,580][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0018, 0.0367, 0.0118, 0.0502, 0.0215, 0.0030, 0.1455, 0.0024, 0.6286,
        0.0986], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:35,581][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0175, 0.0530, 0.0017, 0.0835, 0.0069, 0.0246, 0.5562, 0.0237, 0.1062,
        0.0364, 0.0905], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:35,581][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0362, 0.3092, 0.1970, 0.0432, 0.1253, 0.0269, 0.0525, 0.0520, 0.0697,
        0.0606, 0.0274], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:35,582][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0339, 0.0818, 0.1521, 0.0741, 0.0638, 0.0796, 0.0629, 0.1408, 0.0788,
        0.1445, 0.0878], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:35,584][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0039, 0.2574, 0.1907, 0.0946, 0.0957, 0.0006, 0.0389, 0.0004, 0.1833,
        0.0690, 0.0656], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:35,586][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ at] are: tensor([3.4732e-03, 3.9907e-01, 8.8259e-03, 2.4053e-01, 2.7612e-02, 2.2316e-04,
        3.7024e-02, 2.0254e-04, 1.7162e-01, 2.5794e-02, 8.5626e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:35,589][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ at] are: tensor([2.2728e-06, 9.7771e-01, 4.1175e-03, 1.3395e-02, 4.1551e-03, 1.7176e-05,
        5.9600e-05, 2.1281e-06, 4.8394e-04, 2.3469e-05, 3.3570e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:35,593][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.3203, 0.0325, 0.1203, 0.0486, 0.0176, 0.1537, 0.0281, 0.1717, 0.0368,
        0.0474, 0.0229], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:35,595][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ at] are: tensor([4.8561e-04, 4.5053e-01, 3.2454e-02, 6.0888e-02, 1.9238e-02, 1.1708e-03,
        1.4340e-02, 1.1575e-04, 3.1284e-01, 2.4033e-02, 8.3902e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:35,598][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0019, 0.1043, 0.1186, 0.1128, 0.1136, 0.0808, 0.0935, 0.0716, 0.1186,
        0.0918, 0.0925], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:35,599][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1105, 0.0884, 0.1135, 0.0832, 0.0753, 0.0072, 0.0964, 0.0047, 0.1509,
        0.1108, 0.1590], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:35,599][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0044, 0.0159, 0.0028, 0.0540, 0.0289, 0.0238, 0.0896, 0.0069, 0.6018,
        0.0786, 0.0933], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:35,600][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0023, 0.0359, 0.0249, 0.0367, 0.0323, 0.0025, 0.1263, 0.0022, 0.5430,
        0.1198, 0.0741], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:35,602][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0234, 0.0479, 0.0013, 0.0603, 0.0059, 0.0142, 0.3961, 0.0192, 0.0829,
        0.0237, 0.0732, 0.2519], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,605][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0126, 0.4566, 0.1683, 0.0387, 0.1131, 0.0130, 0.0364, 0.0232, 0.0606,
        0.0385, 0.0236, 0.0154], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,609][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0317, 0.0705, 0.1299, 0.0646, 0.0583, 0.0716, 0.0585, 0.1308, 0.0738,
        0.1286, 0.0807, 0.1011], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,613][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0029, 0.2528, 0.1883, 0.0909, 0.0898, 0.0005, 0.0350, 0.0003, 0.1757,
        0.0653, 0.0595, 0.0390], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,616][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ the] are: tensor([1.8942e-03, 3.3552e-01, 7.9960e-03, 2.1234e-01, 2.6633e-02, 1.3017e-04,
        3.2423e-02, 1.0997e-04, 1.5846e-01, 2.2657e-02, 7.8454e-02, 1.2338e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,616][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ the] are: tensor([1.5391e-06, 9.7505e-01, 3.2557e-03, 1.6425e-02, 4.5164e-03, 1.4558e-05,
        5.7656e-05, 1.5181e-06, 5.9968e-04, 2.1597e-05, 4.0976e-05, 1.3247e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,617][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2943, 0.0355, 0.0801, 0.0482, 0.0138, 0.1595, 0.0311, 0.1634, 0.0572,
        0.0406, 0.0390, 0.0374], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,618][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ the] are: tensor([1.0347e-04, 3.2851e-01, 1.8777e-02, 5.8332e-02, 1.3631e-02, 3.7696e-04,
        1.0399e-02, 2.8641e-05, 4.2154e-01, 1.7613e-02, 9.0929e-02, 3.9754e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,620][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0014, 0.0970, 0.1066, 0.1053, 0.1003, 0.0726, 0.0826, 0.0636, 0.1088,
        0.0828, 0.0859, 0.0932], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,623][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1030, 0.0864, 0.0775, 0.0751, 0.0540, 0.0061, 0.0898, 0.0059, 0.1446,
        0.1007, 0.1320, 0.1248], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,627][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0023, 0.0114, 0.0034, 0.0488, 0.0274, 0.0145, 0.0794, 0.0039, 0.5550,
        0.0620, 0.0861, 0.1057], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,631][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0028, 0.0433, 0.0219, 0.0482, 0.0384, 0.0036, 0.1445, 0.0026, 0.4185,
        0.0829, 0.0858, 0.1075], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:35,634][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0119, 0.0518, 0.0014, 0.0621, 0.0112, 0.0064, 0.3987, 0.0087, 0.0825,
        0.0273, 0.0533, 0.2711, 0.0135], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,635][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0022, 0.4688, 0.1139, 0.0362, 0.0828, 0.0049, 0.0455, 0.0057, 0.0766,
        0.0427, 0.0407, 0.0611, 0.0191], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,635][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0284, 0.0656, 0.1101, 0.0592, 0.0510, 0.0609, 0.0522, 0.1101, 0.0666,
        0.1064, 0.0725, 0.0954, 0.1216], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,636][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ store] are: tensor([1.8145e-03, 2.9279e-01, 1.7868e-01, 8.4122e-02, 7.8159e-02, 2.2753e-04,
        2.8553e-02, 1.2270e-04, 1.8451e-01, 5.4786e-02, 5.2022e-02, 3.1472e-02,
        1.2741e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,638][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ store] are: tensor([3.5830e-04, 1.8927e-01, 5.7699e-03, 2.1845e-01, 1.6591e-02, 5.9151e-05,
        3.4552e-02, 3.5990e-05, 1.8936e-01, 2.7015e-02, 1.1258e-01, 2.0492e-01,
        1.0521e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,640][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ store] are: tensor([2.0548e-07, 9.5700e-01, 2.8016e-03, 3.2090e-02, 6.2720e-03, 6.5519e-06,
        1.6257e-04, 6.1843e-07, 1.4487e-03, 4.9998e-05, 1.0137e-04, 6.5345e-05,
        2.3933e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,643][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.6193, 0.0140, 0.0511, 0.0229, 0.0051, 0.0581, 0.0089, 0.1334, 0.0318,
        0.0227, 0.0150, 0.0117, 0.0061], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,645][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ store] are: tensor([3.3100e-06, 4.6746e-02, 1.6871e-02, 4.6790e-02, 8.5004e-03, 6.1999e-04,
        2.4466e-02, 1.5252e-05, 6.2526e-01, 3.7397e-03, 1.4631e-01, 8.0276e-02,
        4.0036e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,649][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.0015, 0.0856, 0.1001, 0.0926, 0.0906, 0.0704, 0.0786, 0.0590, 0.0976,
        0.0765, 0.0793, 0.0875, 0.0808], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,652][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.1093, 0.0683, 0.0830, 0.0802, 0.0476, 0.0014, 0.0777, 0.0023, 0.1555,
        0.1119, 0.1088, 0.1029, 0.0512], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,653][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ store] are: tensor([3.5150e-04, 1.2786e-02, 3.5063e-03, 6.7222e-02, 2.9294e-02, 5.5555e-03,
        1.1748e-01, 1.0685e-03, 3.8104e-01, 8.3759e-02, 1.0781e-01, 1.6675e-01,
        2.3377e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,653][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ store] are: tensor([1.7700e-04, 1.3359e-02, 5.5382e-03, 2.2939e-02, 1.5869e-02, 5.5178e-04,
        1.1079e-01, 3.7914e-04, 4.0705e-01, 8.7458e-02, 1.1005e-01, 2.2252e-01,
        3.3192e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:35,654][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0141, 0.0340, 0.0017, 0.0437, 0.0053, 0.0183, 0.3849, 0.0179, 0.0785,
        0.0257, 0.0521, 0.2683, 0.0149, 0.0405], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,656][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0163, 0.3796, 0.1341, 0.0334, 0.1297, 0.0176, 0.0468, 0.0260, 0.0671,
        0.0490, 0.0271, 0.0329, 0.0267, 0.0136], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,659][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0182, 0.0567, 0.0964, 0.0493, 0.0418, 0.0534, 0.0442, 0.0936, 0.0538,
        0.0964, 0.0611, 0.0768, 0.1118, 0.1463], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,663][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0033, 0.2446, 0.1718, 0.0838, 0.0790, 0.0005, 0.0322, 0.0003, 0.1678,
        0.0580, 0.0580, 0.0371, 0.0164, 0.0473], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,666][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [.] are: tensor([2.3154e-03, 3.0579e-01, 5.5093e-03, 1.9829e-01, 1.9359e-02, 1.2505e-04,
        3.0928e-02, 1.1454e-04, 1.5797e-01, 2.2539e-02, 7.6641e-02, 1.3323e-01,
        9.8652e-04, 4.6208e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,668][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [.] are: tensor([6.4932e-06, 9.7169e-01, 4.8656e-03, 1.7300e-02, 4.9866e-03, 3.2920e-05,
        8.6340e-05, 5.1613e-06, 8.2695e-04, 4.4709e-05, 6.6217e-05, 2.8839e-05,
        1.6218e-06, 5.5292e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,670][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.5203, 0.0150, 0.0359, 0.0167, 0.0057, 0.0900, 0.0210, 0.1707, 0.0226,
        0.0237, 0.0176, 0.0268, 0.0115, 0.0224], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,671][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [.] are: tensor([6.7984e-04, 2.8325e-01, 1.5701e-02, 5.3657e-02, 1.2585e-02, 1.1593e-03,
        1.4277e-02, 1.1389e-04, 2.9332e-01, 1.1970e-02, 8.5238e-02, 5.4704e-02,
        9.8178e-04, 1.7237e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,672][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0013, 0.0825, 0.0891, 0.0868, 0.0837, 0.0647, 0.0721, 0.0543, 0.0895,
        0.0694, 0.0716, 0.0786, 0.0724, 0.0839], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,673][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1213, 0.0755, 0.0685, 0.0626, 0.0398, 0.0037, 0.0874, 0.0025, 0.1112,
        0.0879, 0.0968, 0.1066, 0.0353, 0.1009], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,675][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0019, 0.0148, 0.0017, 0.0469, 0.0186, 0.0140, 0.0760, 0.0037, 0.4710,
        0.0596, 0.0755, 0.1024, 0.0085, 0.1052], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,677][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0043, 0.0455, 0.0258, 0.0330, 0.0348, 0.0036, 0.1009, 0.0030, 0.4317,
        0.0817, 0.0738, 0.1049, 0.0020, 0.0549], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:35,681][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.0251, 0.0625, 0.0022, 0.0621, 0.0119, 0.0160, 0.3077, 0.0192, 0.0867,
        0.0286, 0.0680, 0.2202, 0.0201, 0.0586, 0.0110], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,686][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0046, 0.4489, 0.1047, 0.0334, 0.0839, 0.0083, 0.0396, 0.0092, 0.0811,
        0.0369, 0.0367, 0.0351, 0.0218, 0.0244, 0.0313], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,688][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.0148, 0.0500, 0.0887, 0.0427, 0.0341, 0.0440, 0.0396, 0.0707, 0.0463,
        0.0811, 0.0482, 0.0677, 0.0934, 0.1259, 0.1529], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,689][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0040, 0.1936, 0.1509, 0.0780, 0.0787, 0.0008, 0.0351, 0.0005, 0.1480,
        0.0589, 0.0585, 0.0385, 0.0203, 0.0496, 0.0846], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,690][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([8.3624e-04, 2.2057e-01, 5.0065e-03, 1.5950e-01, 2.4190e-02, 9.1380e-05,
        2.7096e-02, 6.6707e-05, 1.6971e-01, 2.2807e-02, 9.1136e-02, 2.0282e-01,
        1.3122e-03, 6.5201e-02, 9.6566e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,691][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([1.7872e-05, 9.5827e-01, 6.7680e-03, 2.3229e-02, 8.8768e-03, 8.7805e-05,
        2.1991e-04, 1.3614e-05, 1.8482e-03, 8.9336e-05, 1.4318e-04, 1.0845e-04,
        7.2592e-06, 2.1387e-04, 1.0369e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,693][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.7931, 0.0136, 0.0147, 0.0094, 0.0012, 0.0267, 0.0055, 0.0718, 0.0112,
        0.0059, 0.0069, 0.0058, 0.0016, 0.0083, 0.0243], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,695][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([2.5404e-05, 1.1201e-01, 8.5032e-03, 3.7743e-02, 6.8283e-03, 7.4470e-04,
        1.4921e-02, 2.6811e-05, 3.7828e-01, 6.2529e-03, 9.0994e-02, 6.8936e-02,
        5.9640e-04, 2.7080e-01, 3.3390e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,699][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.0010, 0.0754, 0.0792, 0.0795, 0.0744, 0.0602, 0.0661, 0.0518, 0.0852,
        0.0646, 0.0667, 0.0731, 0.0676, 0.0825, 0.0728], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,703][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0518, 0.0555, 0.0953, 0.0544, 0.0518, 0.0034, 0.0569, 0.0037, 0.0917,
        0.1031, 0.0733, 0.0692, 0.0512, 0.0888, 0.1499], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,706][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.0026, 0.0184, 0.0034, 0.0498, 0.0258, 0.0174, 0.0872, 0.0042, 0.3976,
        0.0728, 0.0807, 0.1195, 0.0111, 0.0978, 0.0118], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,707][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.0006, 0.0367, 0.0157, 0.0585, 0.0250, 0.0017, 0.1216, 0.0009, 0.3258,
        0.0531, 0.1050, 0.1411, 0.0021, 0.0943, 0.0178], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:35,707][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0050, 0.0153, 0.0005, 0.0203, 0.0024, 0.0017, 0.4756, 0.0041, 0.0392,
        0.0131, 0.0286, 0.3643, 0.0035, 0.0180, 0.0047, 0.0037],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,708][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([1.6957e-05, 8.6045e-01, 1.6615e-02, 9.9553e-03, 2.3902e-02, 1.3056e-04,
        1.0776e-02, 7.8388e-05, 2.2365e-02, 6.2927e-03, 1.1915e-02, 1.4072e-02,
        2.2210e-03, 1.2110e-02, 9.0142e-03, 8.3922e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,710][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0149, 0.0368, 0.0730, 0.0322, 0.0256, 0.0379, 0.0311, 0.0832, 0.0374,
        0.0765, 0.0405, 0.0613, 0.0815, 0.1250, 0.1586, 0.0845],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,712][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([5.3650e-04, 2.9206e-01, 1.8002e-01, 6.7882e-02, 6.5890e-02, 6.0891e-05,
        1.8025e-02, 2.7109e-05, 1.7189e-01, 3.9499e-02, 3.7868e-02, 2.0870e-02,
        7.4540e-03, 3.0670e-02, 6.7027e-02, 2.1759e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,715][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([3.4750e-04, 1.7880e-01, 1.2399e-02, 2.1582e-01, 4.0740e-02, 1.2660e-04,
        2.8425e-02, 6.6962e-05, 1.5476e-01, 3.2445e-02, 8.7591e-02, 1.4619e-01,
        2.6270e-03, 7.8278e-02, 2.1257e-02, 1.3143e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,717][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([9.9344e-05, 7.1510e-01, 4.1739e-02, 9.9891e-02, 8.1111e-02, 8.6918e-04,
        6.7298e-03, 2.4412e-04, 2.5364e-02, 3.4540e-03, 6.9856e-03, 5.1384e-03,
        1.0142e-03, 6.5247e-03, 5.1439e-03, 5.9026e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,721][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0490, 0.0287, 0.1203, 0.0478, 0.0171, 0.0361, 0.0285, 0.0341, 0.0761,
        0.0679, 0.0338, 0.0276, 0.0205, 0.0729, 0.2789, 0.0609],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,724][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([2.8885e-05, 7.5454e-02, 2.4154e-02, 6.3779e-02, 1.9064e-02, 1.0970e-03,
        4.0764e-02, 8.0303e-05, 3.4261e-01, 1.0344e-02, 1.5062e-01, 8.5081e-02,
        1.7544e-03, 1.7341e-01, 9.7071e-03, 2.0562e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,724][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0008, 0.0701, 0.0808, 0.0777, 0.0748, 0.0562, 0.0640, 0.0452, 0.0824,
        0.0571, 0.0619, 0.0701, 0.0602, 0.0768, 0.0722, 0.0497],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,725][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0348, 0.0477, 0.0772, 0.0556, 0.0665, 0.0007, 0.0614, 0.0007, 0.1097,
        0.0981, 0.0899, 0.0911, 0.0258, 0.0713, 0.1694, 0.0003],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,726][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0005, 0.0211, 0.0199, 0.0684, 0.0615, 0.0036, 0.0768, 0.0012, 0.1822,
        0.0902, 0.1145, 0.1061, 0.0374, 0.1675, 0.0456, 0.0037],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,728][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([1.8664e-05, 7.0331e-03, 3.0696e-02, 3.3547e-02, 3.8885e-02, 1.9512e-04,
        9.8731e-02, 8.4494e-05, 1.8890e-01, 8.6141e-02, 1.0927e-01, 1.2016e-01,
        7.7871e-03, 1.3974e-01, 1.3865e-01, 1.6027e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:35,730][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([3.6286e-03, 1.6129e-02, 1.9469e-04, 2.2825e-02, 1.4692e-03, 1.4666e-03,
        3.0444e-01, 2.6808e-03, 3.7554e-02, 9.4419e-03, 2.2807e-02, 1.9387e-01,
        3.0355e-03, 1.7787e-02, 1.6992e-03, 3.0427e-03, 3.5793e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,732][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([2.5145e-04, 6.8208e-01, 4.5198e-02, 2.0686e-02, 5.8174e-02, 9.9512e-04,
        2.0803e-02, 8.9854e-04, 5.5819e-02, 1.8207e-02, 2.3488e-02, 2.5900e-02,
        6.5673e-03, 1.8077e-02, 1.9384e-02, 8.1703e-04, 2.6495e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,737][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0155, 0.0399, 0.0760, 0.0345, 0.0295, 0.0378, 0.0330, 0.0729, 0.0375,
        0.0757, 0.0431, 0.0595, 0.0819, 0.1130, 0.1379, 0.0676, 0.0448],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,739][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([9.2568e-04, 2.5374e-01, 1.7898e-01, 7.3767e-02, 6.9962e-02, 1.2557e-04,
        2.1237e-02, 6.0651e-05, 1.6444e-01, 4.4054e-02, 4.3542e-02, 2.5238e-02,
        9.8760e-03, 3.5168e-02, 7.6378e-02, 4.2588e-04, 2.0771e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,741][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([3.2477e-04, 2.9369e-01, 4.0696e-03, 2.6300e-01, 1.8116e-02, 3.0753e-05,
        1.9202e-02, 1.7894e-05, 1.4819e-01, 1.5073e-02, 6.5017e-02, 1.2284e-01,
        5.2016e-04, 4.5690e-02, 4.0395e-03, 2.3011e-05, 1.6618e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,742][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([3.4198e-05, 8.9210e-01, 1.7763e-02, 5.1135e-02, 2.6818e-02, 2.5100e-04,
        9.9647e-04, 5.1434e-05, 6.3900e-03, 5.5593e-04, 1.0352e-03, 5.3352e-04,
        8.0363e-05, 1.0782e-03, 6.5950e-04, 1.5289e-04, 3.6222e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,743][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2888, 0.0150, 0.0460, 0.0272, 0.0034, 0.0728, 0.0085, 0.0990, 0.0441,
        0.0212, 0.0239, 0.0130, 0.0079, 0.0441, 0.1439, 0.1182, 0.0228],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,744][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([2.1443e-05, 1.7048e-01, 1.4623e-02, 5.5136e-02, 8.9049e-03, 2.2014e-04,
        1.2521e-02, 1.3020e-05, 4.0314e-01, 8.3137e-03, 1.0070e-01, 4.6782e-02,
        6.2160e-04, 1.5777e-01, 3.5143e-03, 9.1449e-04, 1.6321e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,746][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0008, 0.0671, 0.0725, 0.0739, 0.0682, 0.0502, 0.0579, 0.0445, 0.0762,
        0.0581, 0.0613, 0.0664, 0.0601, 0.0713, 0.0665, 0.0484, 0.0567],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,748][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0490, 0.0431, 0.0587, 0.0589, 0.0427, 0.0009, 0.0680, 0.0012, 0.1408,
        0.0710, 0.1247, 0.0887, 0.0277, 0.0861, 0.1307, 0.0004, 0.0073],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,752][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0005, 0.0109, 0.0052, 0.0533, 0.0280, 0.0045, 0.0711, 0.0011, 0.3476,
        0.0644, 0.0869, 0.0984, 0.0166, 0.1357, 0.0185, 0.0043, 0.0529],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,755][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([7.3714e-05, 1.2345e-02, 2.2610e-02, 3.8424e-02, 3.2554e-02, 3.5276e-04,
        1.2851e-01, 1.8236e-04, 3.0273e-01, 9.5779e-02, 8.6439e-02, 1.1320e-01,
        3.5350e-03, 9.5733e-02, 6.0442e-02, 3.3624e-04, 6.7543e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:35,759][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.0097, 0.0458, 0.0016, 0.0455, 0.0088, 0.0078, 0.2374, 0.0085, 0.0687,
        0.0289, 0.0520, 0.1563, 0.0142, 0.0555, 0.0068, 0.0099, 0.2214, 0.0215],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,760][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([0.0058, 0.5173, 0.1004, 0.0237, 0.0798, 0.0072, 0.0277, 0.0092, 0.0615,
        0.0264, 0.0262, 0.0259, 0.0160, 0.0127, 0.0210, 0.0072, 0.0088, 0.0232],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,761][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([0.0140, 0.0395, 0.0713, 0.0343, 0.0309, 0.0371, 0.0346, 0.0611, 0.0372,
        0.0645, 0.0405, 0.0600, 0.0766, 0.1117, 0.1219, 0.0607, 0.0441, 0.0601],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,762][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([1.8710e-03, 2.2792e-01, 1.6529e-01, 7.6260e-02, 7.2238e-02, 2.4118e-04,
        2.6131e-02, 1.2849e-04, 1.5507e-01, 5.1949e-02, 4.7817e-02, 2.9054e-02,
        1.2719e-02, 3.9942e-02, 7.8009e-02, 7.9321e-04, 3.2921e-03, 1.1274e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,763][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([1.3345e-03, 2.6188e-01, 5.2108e-03, 1.9050e-01, 1.9209e-02, 9.7839e-05,
        3.2050e-02, 8.8933e-05, 1.6359e-01, 2.7006e-02, 7.5856e-02, 1.3543e-01,
        1.4225e-03, 7.3641e-02, 8.0182e-03, 1.1157e-04, 6.2653e-04, 3.9238e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,766][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([9.9023e-07, 9.7751e-01, 2.4974e-03, 1.4627e-02, 4.4289e-03, 1.0526e-05,
        6.4739e-05, 1.1062e-06, 6.1257e-04, 2.8360e-05, 4.5032e-05, 2.7557e-05,
        1.3241e-06, 6.5754e-05, 2.5262e-05, 5.9450e-06, 2.2940e-05, 2.3304e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,770][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([0.4242, 0.0094, 0.0204, 0.0127, 0.0020, 0.0750, 0.0069, 0.1814, 0.0155,
        0.0117, 0.0110, 0.0073, 0.0032, 0.0134, 0.0399, 0.1350, 0.0223, 0.0086],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,773][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([3.6939e-05, 8.5593e-02, 1.4887e-02, 4.1260e-02, 1.3738e-02, 1.3074e-03,
        2.4034e-02, 6.3359e-05, 3.1704e-01, 5.6014e-03, 8.9931e-02, 6.5054e-02,
        8.4570e-04, 2.4889e-01, 4.1064e-03, 4.0810e-03, 8.0627e-02, 2.9094e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,777][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([0.0009, 0.0615, 0.0715, 0.0647, 0.0699, 0.0480, 0.0564, 0.0446, 0.0675,
        0.0552, 0.0533, 0.0593, 0.0579, 0.0648, 0.0628, 0.0469, 0.0557, 0.0590],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,778][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([0.0598, 0.0662, 0.0661, 0.0566, 0.0420, 0.0011, 0.0841, 0.0012, 0.1115,
        0.0732, 0.1156, 0.0705, 0.0258, 0.0715, 0.0893, 0.0005, 0.0066, 0.0584],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,779][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([0.0006, 0.0107, 0.0022, 0.0604, 0.0179, 0.0067, 0.0892, 0.0014, 0.4034,
        0.0507, 0.0771, 0.0982, 0.0066, 0.0831, 0.0065, 0.0047, 0.0625, 0.0180],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,780][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([0.0012, 0.0271, 0.0098, 0.0685, 0.0181, 0.0031, 0.1185, 0.0019, 0.2893,
        0.0672, 0.0973, 0.1471, 0.0018, 0.0757, 0.0227, 0.0031, 0.0408, 0.0069],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:35,781][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0068, 0.0248, 0.0011, 0.0281, 0.0040, 0.0074, 0.2178, 0.0077, 0.0438,
        0.0151, 0.0351, 0.1547, 0.0090, 0.0310, 0.0062, 0.0099, 0.3179, 0.0140,
        0.0657], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,784][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0363, 0.1174, 0.1351, 0.0284, 0.1125, 0.0322, 0.0532, 0.0541, 0.0658,
        0.0552, 0.0303, 0.0432, 0.0382, 0.0185, 0.0399, 0.0357, 0.0305, 0.0542,
        0.0191], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,788][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0120, 0.0369, 0.0711, 0.0325, 0.0251, 0.0340, 0.0312, 0.0653, 0.0330,
        0.0721, 0.0403, 0.0576, 0.0786, 0.1016, 0.1228, 0.0573, 0.0404, 0.0566,
        0.0316], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,793][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0031, 0.2022, 0.1411, 0.0726, 0.0740, 0.0004, 0.0298, 0.0002, 0.1494,
        0.0540, 0.0537, 0.0330, 0.0161, 0.0431, 0.0801, 0.0012, 0.0046, 0.0130,
        0.0283], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,795][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([4.2498e-03, 2.6550e-01, 5.4372e-03, 1.7238e-01, 2.1027e-02, 1.9853e-04,
        3.4510e-02, 2.1648e-04, 1.5336e-01, 2.1822e-02, 7.4685e-02, 1.3616e-01,
        1.1563e-03, 4.7476e-02, 5.6857e-03, 1.8559e-04, 6.6512e-04, 3.2982e-03,
        5.1978e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,796][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.3765e-05, 9.7621e-01, 4.1759e-03, 1.3602e-02, 4.4944e-03, 5.8719e-05,
        9.6251e-05, 8.5322e-06, 7.5208e-04, 4.2856e-05, 5.6997e-05, 2.4316e-05,
        1.8796e-06, 7.4616e-05, 3.7441e-05, 3.3615e-05, 6.2897e-05, 3.3836e-05,
        2.2050e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,797][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2067, 0.0152, 0.0555, 0.0237, 0.0071, 0.0783, 0.0177, 0.1291, 0.0246,
        0.0226, 0.0171, 0.0209, 0.0145, 0.0208, 0.1137, 0.1377, 0.0486, 0.0295,
        0.0168], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,798][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.8624e-03, 1.8236e-01, 1.1290e-02, 3.1447e-02, 7.2097e-03, 2.8976e-03,
        9.3659e-03, 2.6467e-04, 1.4442e-01, 5.3866e-03, 4.2331e-02, 2.9699e-02,
        5.4524e-04, 1.1088e-01, 2.0145e-03, 1.3446e-02, 5.2387e-02, 2.3190e-03,
        3.4988e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,800][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0008, 0.0583, 0.0679, 0.0640, 0.0630, 0.0451, 0.0523, 0.0384, 0.0662,
        0.0511, 0.0530, 0.0588, 0.0541, 0.0619, 0.0618, 0.0427, 0.0505, 0.0539,
        0.0561], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,803][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0930, 0.0463, 0.0546, 0.0469, 0.0383, 0.0014, 0.0532, 0.0015, 0.1009,
        0.0903, 0.0968, 0.0736, 0.0260, 0.0677, 0.1146, 0.0008, 0.0078, 0.0569,
        0.0293], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,806][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0037, 0.0081, 0.0016, 0.0278, 0.0121, 0.0181, 0.0477, 0.0051, 0.3545,
        0.0403, 0.0549, 0.0693, 0.0081, 0.0654, 0.0049, 0.0173, 0.1157, 0.0082,
        0.1370], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,811][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0044, 0.0438, 0.0276, 0.0462, 0.0258, 0.0052, 0.1506, 0.0043, 0.2666,
        0.0696, 0.0664, 0.0835, 0.0025, 0.0449, 0.0204, 0.0049, 0.0357, 0.0098,
        0.0880], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:35,896][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:35,896][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,897][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,898][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,899][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,899][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,900][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,901][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,901][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,902][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,903][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,903][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,906][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:35,906][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3994, 0.6006], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,907][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0456, 0.9544], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,908][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6872, 0.3128], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,909][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2020, 0.7980], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,909][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3312, 0.6688], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,910][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3533, 0.6467], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,913][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0985, 0.9015], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,914][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1212, 0.8788], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,914][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9221, 0.0779], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,915][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.4877, 0.5123], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,917][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1084, 0.8916], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,920][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2157, 0.7843], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:35,924][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.4574, 0.5299, 0.0127], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,928][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0710, 0.4034, 0.5256], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,930][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.5390, 0.1891, 0.2720], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,931][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.4618, 0.3035, 0.2348], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,932][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.0905, 0.8940, 0.0156], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,932][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.0337, 0.8966, 0.0697], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,933][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.3594, 0.5154, 0.1252], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,935][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.0044, 0.9865, 0.0090], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,938][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.9919, 0.0050, 0.0031], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,942][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.6420, 0.3186, 0.0393], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,946][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0660, 0.7429, 0.1911], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,948][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.0150, 0.5717, 0.4133], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:35,949][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0246, 0.0883, 0.0026, 0.8845], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,950][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0722, 0.5675, 0.3001, 0.0603], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,951][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5703, 0.1496, 0.0869, 0.1932], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,951][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3273, 0.4870, 0.0569, 0.1289], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,953][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0676, 0.5837, 0.0215, 0.3272], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,957][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0619, 0.7903, 0.0832, 0.0646], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,960][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1155, 0.5658, 0.1563, 0.1625], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,964][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0450, 0.8829, 0.0131, 0.0590], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,966][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9271, 0.0405, 0.0231, 0.0093], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,967][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4972, 0.2208, 0.0295, 0.2524], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,968][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0479, 0.2981, 0.0799, 0.5741], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,969][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0107, 0.3033, 0.3536, 0.3324], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:35,971][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.0790, 0.1510, 0.0025, 0.7622, 0.0053], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,973][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([0.3341, 0.1959, 0.2289, 0.1037, 0.1374], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,977][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([0.1795, 0.2351, 0.1012, 0.2023, 0.2819], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,982][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([0.4603, 0.2727, 0.0453, 0.0669, 0.1548], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,984][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([0.0763, 0.6130, 0.0033, 0.2604, 0.0470], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,985][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.0409, 0.7158, 0.0252, 0.1473, 0.0708], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,985][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.3998, 0.3792, 0.0405, 0.1301, 0.0504], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,986][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.0269, 0.8505, 0.0038, 0.0657, 0.0532], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,987][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.9666, 0.0156, 0.0062, 0.0061, 0.0055], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,990][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.5152, 0.1836, 0.0146, 0.2087, 0.0779], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,994][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.0260, 0.2295, 0.0365, 0.4995, 0.2084], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:35,998][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.0342, 0.3214, 0.0864, 0.3106, 0.2474], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:36,002][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0081, 0.0759, 0.0042, 0.8250, 0.0063, 0.0805], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,002][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([8.2724e-06, 3.9176e-01, 2.5911e-01, 5.4518e-02, 2.9459e-01, 1.8292e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,003][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0297, 0.1247, 0.1622, 0.1937, 0.4109, 0.0788], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,004][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0104, 0.1974, 0.2339, 0.1176, 0.4262, 0.0146], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,005][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0008, 0.1776, 0.0456, 0.4579, 0.3147, 0.0033], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,006][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0036, 0.2285, 0.2444, 0.1238, 0.3807, 0.0190], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,009][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0109, 0.3342, 0.2111, 0.0804, 0.3549, 0.0086], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,013][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0006, 0.1726, 0.0917, 0.1664, 0.5636, 0.0050], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,018][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.1533, 0.1348, 0.1735, 0.1132, 0.2362, 0.1890], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,020][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0113, 0.1292, 0.1231, 0.4271, 0.2699, 0.0393], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,021][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0038, 0.1135, 0.1429, 0.3279, 0.3881, 0.0237], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,021][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([1.9507e-04, 6.4612e-02, 2.9235e-01, 2.7321e-01, 3.6808e-01, 1.5552e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,022][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([8.0475e-05, 3.0033e-04, 5.7068e-06, 4.6409e-03, 7.8379e-06, 1.1604e-03,
        9.9380e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,024][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.3333, 0.0747, 0.1623, 0.0547, 0.0716, 0.2853, 0.0181],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,027][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1477, 0.0764, 0.0334, 0.1869, 0.0788, 0.3469, 0.1300],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,031][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.5184, 0.0703, 0.0307, 0.0280, 0.0840, 0.2338, 0.0348],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,035][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0942, 0.4677, 0.0028, 0.3289, 0.0328, 0.0524, 0.0211],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,037][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0198, 0.5378, 0.0383, 0.1756, 0.0652, 0.0706, 0.0927],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,038][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1513, 0.1448, 0.0575, 0.2238, 0.0853, 0.2569, 0.0803],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,039][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0845, 0.6078, 0.0052, 0.1224, 0.0549, 0.1097, 0.0155],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,040][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.8380, 0.0145, 0.0034, 0.0031, 0.0032, 0.1360, 0.0019],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,041][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1420, 0.1324, 0.0166, 0.2779, 0.0748, 0.2458, 0.1105],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,044][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0147, 0.0719, 0.0206, 0.2649, 0.1336, 0.0987, 0.3957],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,048][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0105, 0.1241, 0.0654, 0.1914, 0.1359, 0.0136, 0.4591],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,051][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([8.0233e-05, 6.3281e-04, 5.3075e-05, 4.8224e-03, 9.3897e-05, 5.1922e-04,
        9.9332e-01, 4.8297e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,053][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([3.0876e-06, 3.6030e-01, 1.3237e-01, 7.9981e-02, 2.6106e-01, 1.0629e-05,
        1.6627e-01, 5.9630e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,055][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0163, 0.0906, 0.1492, 0.1473, 0.2793, 0.0429, 0.2454, 0.0290],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,056][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0026, 0.1230, 0.1681, 0.1457, 0.3642, 0.0068, 0.1849, 0.0047],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,057][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([1.6972e-04, 1.1920e-01, 6.0505e-02, 4.2598e-01, 2.8766e-01, 1.8500e-03,
        1.0415e-01, 4.8222e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,058][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0008, 0.1128, 0.2036, 0.1580, 0.3839, 0.0079, 0.1305, 0.0026],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,060][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0035, 0.2662, 0.1607, 0.1163, 0.3113, 0.0059, 0.1316, 0.0046],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,062][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([4.9699e-05, 9.1823e-02, 7.3175e-02, 2.1344e-01, 4.3047e-01, 1.1038e-03,
        1.8972e-01, 2.1661e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,066][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0201, 0.1284, 0.1604, 0.1762, 0.2733, 0.0585, 0.1492, 0.0338],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,070][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0028, 0.0769, 0.1160, 0.3216, 0.2009, 0.0164, 0.2597, 0.0058],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,072][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0012, 0.0807, 0.1158, 0.2355, 0.2819, 0.0100, 0.2715, 0.0033],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,073][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([8.0209e-05, 3.8916e-02, 1.9359e-01, 1.7029e-01, 2.0761e-01, 1.0726e-03,
        3.8803e-01, 4.2133e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,074][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([8.9434e-05, 3.3502e-04, 8.5174e-06, 4.9529e-03, 1.3146e-05, 1.3693e-03,
        9.7459e-01, 6.7747e-04, 1.7962e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,075][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.2783, 0.0243, 0.0755, 0.0142, 0.0197, 0.1558, 0.0096, 0.4105, 0.0121],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,077][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0642, 0.0859, 0.0283, 0.1611, 0.0553, 0.2043, 0.1329, 0.0918, 0.1762],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,079][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.5415, 0.0332, 0.0083, 0.0050, 0.0312, 0.1297, 0.0115, 0.2048, 0.0349],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,084][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.4270, 0.1852, 0.0009, 0.1045, 0.0099, 0.0795, 0.0138, 0.0790, 0.1002],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,088][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0586, 0.4237, 0.0132, 0.1074, 0.0181, 0.1054, 0.1136, 0.0422, 0.1179],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,090][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0915, 0.0735, 0.0229, 0.0911, 0.0529, 0.2055, 0.0817, 0.1433, 0.2376],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,091][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.4558, 0.2365, 0.0011, 0.0199, 0.0094, 0.1836, 0.0039, 0.0796, 0.0103],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,092][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.7091, 0.0136, 0.0032, 0.0019, 0.0018, 0.1090, 0.0023, 0.1536, 0.0055],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,093][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0715, 0.0662, 0.0097, 0.1836, 0.0391, 0.1655, 0.1056, 0.0538, 0.3049],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,095][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0180, 0.0286, 0.0060, 0.0710, 0.0455, 0.0699, 0.1111, 0.0200, 0.6300],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,098][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0302, 0.0919, 0.0640, 0.0602, 0.0595, 0.0149, 0.1776, 0.0180, 0.4837],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,101][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([5.9783e-05, 7.8117e-04, 2.2744e-05, 1.2044e-02, 6.0502e-05, 1.4708e-03,
        9.1800e-01, 5.6257e-04, 6.4975e-02, 2.0257e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,104][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.1168, 0.0729, 0.2425, 0.0527, 0.1209, 0.0924, 0.0334, 0.1827, 0.0499,
        0.0358], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,108][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0309, 0.0529, 0.0128, 0.1568, 0.0741, 0.1336, 0.1315, 0.0546, 0.1351,
        0.2177], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,109][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.1522, 0.0477, 0.0195, 0.0205, 0.1010, 0.1244, 0.0595, 0.1439, 0.1655,
        0.1659], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,110][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0138, 0.1943, 0.0006, 0.2801, 0.0110, 0.0144, 0.0392, 0.0064, 0.4354,
        0.0048], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,110][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0027, 0.3859, 0.0095, 0.1835, 0.0374, 0.0138, 0.1153, 0.0030, 0.2321,
        0.0167], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,112][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0209, 0.0299, 0.0365, 0.1763, 0.0646, 0.0761, 0.1233, 0.0509, 0.2732,
        0.1483], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,115][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0313, 0.6417, 0.0014, 0.0765, 0.0310, 0.0280, 0.0147, 0.0076, 0.1406,
        0.0272], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,119][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.5397, 0.0322, 0.0078, 0.0111, 0.0077, 0.1827, 0.0094, 0.1753, 0.0239,
        0.0103], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,124][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0145, 0.0566, 0.0057, 0.1690, 0.0393, 0.0686, 0.1758, 0.0191, 0.3504,
        0.1010], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,126][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0010, 0.0177, 0.0050, 0.0799, 0.0479, 0.0128, 0.1214, 0.0026, 0.5960,
        0.1157], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,127][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0018, 0.0367, 0.0118, 0.0502, 0.0215, 0.0030, 0.1455, 0.0024, 0.6286,
        0.0986], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,127][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([4.1397e-05, 5.3286e-04, 7.5299e-06, 8.5814e-03, 1.5067e-05, 1.1011e-03,
        9.5350e-01, 3.9368e-04, 3.2204e-02, 5.4481e-04, 3.0803e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,128][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.1970, 0.0236, 0.0560, 0.0225, 0.0272, 0.1641, 0.0179, 0.4321, 0.0194,
        0.0355, 0.0047], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,130][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0547, 0.0451, 0.0123, 0.1312, 0.0260, 0.2638, 0.1074, 0.0701, 0.1345,
        0.0923, 0.0627], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,134][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.4068, 0.0389, 0.0117, 0.0063, 0.0554, 0.1279, 0.0173, 0.1951, 0.0754,
        0.0465, 0.0188], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,136][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([4.7469e-02, 3.5104e-01, 2.6599e-04, 2.5777e-01, 9.6510e-03, 3.4577e-02,
        2.7790e-02, 2.2787e-02, 2.2427e-01, 5.6550e-03, 1.8730e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,139][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0056, 0.3549, 0.0062, 0.1663, 0.0202, 0.0184, 0.1311, 0.0065, 0.2179,
        0.0264, 0.0466], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,143][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0539, 0.0621, 0.0159, 0.1179, 0.0244, 0.1671, 0.0770, 0.1255, 0.1892,
        0.1064, 0.0609], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,144][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.2955, 0.4277, 0.0010, 0.0352, 0.0122, 0.1274, 0.0065, 0.0603, 0.0178,
        0.0144, 0.0019], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,145][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.6283, 0.0229, 0.0043, 0.0040, 0.0032, 0.1157, 0.0042, 0.1827, 0.0209,
        0.0097, 0.0041], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,146][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0127, 0.0447, 0.0063, 0.1843, 0.0239, 0.0625, 0.1239, 0.0151, 0.3548,
        0.0956, 0.0763], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,148][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0044, 0.0159, 0.0028, 0.0540, 0.0289, 0.0238, 0.0896, 0.0069, 0.6018,
        0.0786, 0.0933], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,151][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0023, 0.0359, 0.0249, 0.0367, 0.0323, 0.0025, 0.1263, 0.0022, 0.5430,
        0.1198, 0.0741], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,153][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([4.5752e-05, 3.9636e-04, 5.5135e-06, 4.7620e-03, 1.2119e-05, 7.7933e-04,
        6.4283e-01, 3.3274e-04, 1.9192e-02, 3.2917e-04, 2.2288e-03, 3.2909e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,157][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0865, 0.0760, 0.2091, 0.0502, 0.0753, 0.1062, 0.0375, 0.2251, 0.0500,
        0.0638, 0.0109, 0.0093], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,161][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0285, 0.0541, 0.0145, 0.1454, 0.0312, 0.1201, 0.1373, 0.0420, 0.1202,
        0.0945, 0.0836, 0.1286], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,162][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.3432, 0.0326, 0.0173, 0.0104, 0.0423, 0.1107, 0.0229, 0.1836, 0.0875,
        0.0813, 0.0250, 0.0432], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,163][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([2.2994e-02, 3.4591e-01, 2.1600e-04, 2.7171e-01, 1.0149e-02, 1.5435e-02,
        2.8972e-02, 9.5051e-03, 2.2519e-01, 4.0533e-03, 1.9179e-02, 4.6677e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,164][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0051, 0.2786, 0.0051, 0.1772, 0.0229, 0.0163, 0.1234, 0.0048, 0.2632,
        0.0224, 0.0561, 0.0249], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,166][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0444, 0.0922, 0.0505, 0.1246, 0.0447, 0.1163, 0.0847, 0.0849, 0.1567,
        0.1008, 0.0705, 0.0296], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,168][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0819, 0.5456, 0.0008, 0.1109, 0.0164, 0.0670, 0.0129, 0.0202, 0.0949,
        0.0359, 0.0067, 0.0069], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,172][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.5362, 0.0498, 0.0107, 0.0107, 0.0093, 0.1361, 0.0086, 0.1671, 0.0332,
        0.0180, 0.0087, 0.0116], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,177][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0214, 0.0556, 0.0091, 0.1994, 0.0327, 0.0686, 0.1026, 0.0193, 0.2931,
        0.0714, 0.0540, 0.0729], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,179][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0023, 0.0114, 0.0034, 0.0488, 0.0274, 0.0145, 0.0794, 0.0039, 0.5550,
        0.0620, 0.0861, 0.1057], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,180][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0028, 0.0433, 0.0219, 0.0482, 0.0384, 0.0036, 0.1445, 0.0026, 0.4185,
        0.0829, 0.0858, 0.1075], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,181][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([6.1894e-06, 2.7500e-04, 4.3728e-06, 3.7054e-03, 2.0213e-05, 2.0210e-04,
        6.1085e-01, 6.8483e-05, 1.0810e-02, 3.1531e-04, 9.4120e-04, 3.7270e-01,
        1.0050e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,182][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0048, 0.0487, 0.1220, 0.0622, 0.0619, 0.0074, 0.0708, 0.0117, 0.1619,
        0.1180, 0.0600, 0.2044, 0.0663], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,184][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.0093, 0.0390, 0.0085, 0.1255, 0.0711, 0.0664, 0.0895, 0.0214, 0.1179,
        0.1052, 0.0873, 0.0827, 0.1762], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,186][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.0444, 0.0365, 0.0064, 0.0126, 0.0410, 0.0371, 0.0321, 0.0523, 0.1238,
        0.1611, 0.0389, 0.1052, 0.3088], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,189][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([7.0923e-04, 6.2147e-02, 1.3725e-04, 2.6836e-01, 5.0552e-03, 2.7645e-03,
        4.7401e-02, 8.4847e-04, 3.9945e-01, 8.9623e-03, 4.6104e-02, 1.5740e-01,
        6.6774e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,191][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([1.8409e-04, 9.8409e-02, 3.1848e-03, 1.9925e-01, 3.2112e-02, 2.4950e-03,
        1.3719e-01, 5.2444e-04, 3.2488e-01, 4.0550e-02, 8.1016e-02, 7.4178e-02,
        6.0203e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,195][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.0059, 0.0433, 0.0320, 0.1214, 0.0634, 0.0185, 0.0820, 0.0146, 0.2258,
        0.1346, 0.0963, 0.1025, 0.0596], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,197][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0020, 0.2624, 0.0008, 0.1938, 0.0211, 0.0061, 0.0533, 0.0018, 0.2591,
        0.1217, 0.0209, 0.0546, 0.0024], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,198][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.3057, 0.0410, 0.0150, 0.0258, 0.0154, 0.1937, 0.0193, 0.1972, 0.0682,
        0.0483, 0.0174, 0.0288, 0.0242], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,199][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.0106, 0.0533, 0.0045, 0.2662, 0.0321, 0.0368, 0.0647, 0.0130, 0.2720,
        0.0552, 0.0657, 0.0732, 0.0528], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,200][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([3.5150e-04, 1.2786e-02, 3.5063e-03, 6.7222e-02, 2.9294e-02, 5.5555e-03,
        1.1748e-01, 1.0685e-03, 3.8104e-01, 8.3759e-02, 1.0781e-01, 1.6675e-01,
        2.3377e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,202][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([1.7700e-04, 1.3359e-02, 5.5382e-03, 2.2939e-02, 1.5869e-02, 5.5178e-04,
        1.1079e-01, 3.7914e-04, 4.0705e-01, 8.7458e-02, 1.1005e-01, 2.2252e-01,
        3.3192e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,203][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([5.3186e-05, 2.8475e-04, 9.1320e-06, 2.6299e-03, 1.5267e-05, 9.7709e-04,
        5.9913e-01, 3.9177e-04, 1.8400e-02, 4.1177e-04, 1.1869e-03, 3.7550e-01,
        1.1535e-04, 8.9571e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,208][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.2034, 0.0484, 0.0584, 0.0251, 0.0414, 0.1364, 0.0215, 0.3455, 0.0264,
        0.0374, 0.0060, 0.0148, 0.0334, 0.0019], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,212][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0244, 0.0280, 0.0083, 0.1063, 0.0157, 0.1254, 0.0887, 0.0415, 0.1211,
        0.1051, 0.0836, 0.0856, 0.0872, 0.0793], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,214][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.1582, 0.0318, 0.0121, 0.0076, 0.0328, 0.0659, 0.0297, 0.0956, 0.1265,
        0.0986, 0.0312, 0.0684, 0.1506, 0.0911], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,215][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([5.0706e-02, 3.5929e-01, 8.2514e-05, 1.9308e-01, 5.8016e-03, 2.2151e-02,
        2.7235e-02, 1.6655e-02, 2.2188e-01, 5.0311e-03, 1.7065e-02, 5.9147e-02,
        3.3022e-04, 2.1537e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,216][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0043, 0.2647, 0.0028, 0.1481, 0.0136, 0.0128, 0.1178, 0.0049, 0.2691,
        0.0321, 0.0610, 0.0384, 0.0022, 0.0284], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,217][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0247, 0.0447, 0.0112, 0.1038, 0.0282, 0.1243, 0.0767, 0.0655, 0.1879,
        0.1401, 0.0586, 0.0539, 0.0418, 0.0386], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,218][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([1.6494e-01, 5.1709e-01, 4.9282e-04, 8.8225e-02, 9.8873e-03, 7.4328e-02,
        1.7294e-02, 3.8834e-02, 4.5071e-02, 2.6120e-02, 3.8485e-03, 7.9807e-03,
        8.4120e-04, 5.0491e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,221][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.5266, 0.0354, 0.0090, 0.0080, 0.0068, 0.1313, 0.0088, 0.1707, 0.0458,
        0.0191, 0.0093, 0.0118, 0.0102, 0.0072], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,225][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0155, 0.0390, 0.0036, 0.1761, 0.0189, 0.0591, 0.0905, 0.0166, 0.2746,
        0.0628, 0.0565, 0.0621, 0.0316, 0.0930], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,230][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0019, 0.0148, 0.0017, 0.0469, 0.0186, 0.0140, 0.0760, 0.0037, 0.4710,
        0.0596, 0.0755, 0.1024, 0.0085, 0.1052], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,232][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0043, 0.0455, 0.0258, 0.0330, 0.0348, 0.0036, 0.1009, 0.0030, 0.4317,
        0.0817, 0.0738, 0.1049, 0.0020, 0.0549], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,233][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([1.0199e-04, 1.0923e-03, 1.5803e-05, 8.0763e-03, 5.2318e-05, 1.4994e-03,
        5.7089e-01, 6.3584e-04, 3.0351e-02, 8.4247e-04, 2.9854e-03, 3.8000e-01,
        4.4318e-04, 2.7105e-03, 3.0522e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,234][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0379, 0.0773, 0.1224, 0.0515, 0.0777, 0.0636, 0.0510, 0.0775, 0.1330,
        0.0935, 0.0329, 0.0509, 0.0857, 0.0141, 0.0309], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,236][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.0202, 0.0375, 0.0167, 0.0736, 0.0628, 0.0863, 0.0551, 0.0368, 0.0732,
        0.1884, 0.0295, 0.0361, 0.1563, 0.0626, 0.0649], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,239][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.0995, 0.0175, 0.0158, 0.0051, 0.0411, 0.0699, 0.0241, 0.0887, 0.0942,
        0.1428, 0.0364, 0.0665, 0.1804, 0.0808, 0.0373], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,241][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([1.2571e-02, 1.3498e-01, 1.1404e-04, 1.0116e-01, 1.4408e-02, 1.1707e-02,
        2.2427e-02, 7.3019e-03, 3.1625e-01, 8.9978e-03, 4.0202e-02, 2.3868e-01,
        1.9281e-03, 8.8333e-02, 9.3598e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,245][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.0012, 0.1328, 0.0024, 0.0938, 0.0273, 0.0085, 0.1201, 0.0022, 0.3284,
        0.0342, 0.0653, 0.0837, 0.0097, 0.0877, 0.0028], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,249][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.0534, 0.0866, 0.0365, 0.0952, 0.0442, 0.0984, 0.0617, 0.0952, 0.1759,
        0.0752, 0.0358, 0.0336, 0.0260, 0.0253, 0.0571], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,250][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.0161, 0.3747, 0.0005, 0.0872, 0.0380, 0.0263, 0.0244, 0.0088, 0.1339,
        0.1195, 0.0174, 0.0490, 0.0098, 0.0933, 0.0011], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,251][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.5334, 0.0177, 0.0080, 0.0053, 0.0049, 0.1753, 0.0056, 0.1901, 0.0125,
        0.0124, 0.0048, 0.0071, 0.0128, 0.0049, 0.0050], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,252][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.0567, 0.0630, 0.0103, 0.1399, 0.0564, 0.0996, 0.0551, 0.0363, 0.1747,
        0.0834, 0.0488, 0.0603, 0.0453, 0.0609, 0.0092], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,254][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0026, 0.0184, 0.0034, 0.0498, 0.0258, 0.0174, 0.0872, 0.0042, 0.3976,
        0.0728, 0.0807, 0.1195, 0.0111, 0.0978, 0.0118], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,257][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.0006, 0.0367, 0.0157, 0.0585, 0.0250, 0.0017, 0.1216, 0.0009, 0.3258,
        0.0531, 0.1050, 0.1411, 0.0021, 0.0943, 0.0178], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,259][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([1.8115e-05, 2.7272e-04, 1.5894e-05, 1.9059e-03, 3.4813e-05, 1.6841e-04,
        5.5827e-01, 1.2362e-04, 5.4428e-03, 4.9874e-04, 1.3509e-03, 4.3024e-01,
        1.0234e-04, 1.0461e-03, 4.2551e-04, 7.8800e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,261][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([1.2212e-06, 1.0989e-01, 5.5782e-02, 3.2807e-02, 9.1150e-02, 4.6168e-06,
        5.9450e-02, 2.5445e-06, 1.8498e-01, 4.0547e-02, 1.1562e-01, 1.2467e-01,
        5.6391e-03, 1.1716e-01, 6.2288e-02, 3.7924e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,265][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0044, 0.0236, 0.0409, 0.0527, 0.0734, 0.0166, 0.0793, 0.0079, 0.0852,
        0.0660, 0.0824, 0.0901, 0.0924, 0.1107, 0.1592, 0.0152],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,268][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0017, 0.0432, 0.0526, 0.0283, 0.1088, 0.0031, 0.0499, 0.0027, 0.0707,
        0.1750, 0.0705, 0.1135, 0.0917, 0.1238, 0.0604, 0.0041],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,269][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([1.5909e-04, 5.8518e-02, 6.3892e-03, 2.3607e-01, 6.8288e-02, 1.2144e-03,
        4.9618e-02, 3.7100e-04, 2.2646e-01, 3.4810e-02, 6.6345e-02, 1.2570e-01,
        9.1654e-03, 9.9531e-02, 1.6441e-02, 9.2129e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,269][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0010, 0.0823, 0.0379, 0.1005, 0.1129, 0.0067, 0.0891, 0.0025, 0.1571,
        0.0481, 0.0955, 0.0850, 0.0328, 0.0966, 0.0458, 0.0062],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,271][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0013, 0.0698, 0.0492, 0.0485, 0.0981, 0.0027, 0.0561, 0.0020, 0.1395,
        0.1056, 0.0821, 0.0722, 0.0352, 0.1096, 0.1251, 0.0028],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,274][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0002, 0.0700, 0.0126, 0.1266, 0.1149, 0.0018, 0.0883, 0.0005, 0.1738,
        0.1358, 0.0848, 0.0823, 0.0141, 0.0778, 0.0148, 0.0019],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,278][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0160, 0.0495, 0.0571, 0.0632, 0.0699, 0.0360, 0.0711, 0.0232, 0.0962,
        0.0966, 0.0596, 0.0795, 0.0516, 0.0838, 0.1013, 0.0454],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,283][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0014, 0.0292, 0.0303, 0.1281, 0.0535, 0.0069, 0.0895, 0.0024, 0.1691,
        0.0911, 0.0868, 0.0870, 0.0418, 0.1325, 0.0450, 0.0055],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,285][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0005, 0.0211, 0.0199, 0.0684, 0.0615, 0.0036, 0.0768, 0.0012, 0.1822,
        0.0902, 0.1145, 0.1061, 0.0374, 0.1675, 0.0456, 0.0037],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,286][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([1.8664e-05, 7.0331e-03, 3.0696e-02, 3.3547e-02, 3.8885e-02, 1.9512e-04,
        9.8731e-02, 8.4494e-05, 1.8890e-01, 8.6141e-02, 1.0927e-01, 1.2016e-01,
        7.7871e-03, 1.3974e-01, 1.3865e-01, 1.6027e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,287][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([5.6998e-06, 1.3783e-04, 2.4741e-06, 1.8538e-03, 7.0250e-06, 1.1725e-04,
        5.8377e-01, 5.7273e-05, 7.4653e-03, 2.2294e-04, 7.2111e-04, 3.7830e-01,
        4.5616e-05, 6.7034e-04, 8.9891e-05, 3.8564e-05, 2.6491e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,288][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([6.6495e-05, 9.2188e-02, 9.5324e-02, 4.7736e-02, 1.1048e-01, 1.9309e-04,
        5.2267e-02, 1.7958e-04, 2.5912e-01, 7.1595e-02, 7.0611e-02, 9.9093e-02,
        1.2604e-02, 4.0397e-02, 4.6593e-02, 1.9381e-04, 1.3570e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,290][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0062, 0.0211, 0.0138, 0.0734, 0.0295, 0.0304, 0.0805, 0.0101, 0.1068,
        0.0689, 0.0749, 0.0977, 0.0790, 0.1194, 0.0748, 0.0263, 0.0870],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,292][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0103, 0.0254, 0.0326, 0.0158, 0.0714, 0.0113, 0.0342, 0.0117, 0.0986,
        0.1585, 0.0422, 0.0875, 0.1420, 0.1382, 0.0414, 0.0205, 0.0583],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,296][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0010, 0.1454, 0.0007, 0.3838, 0.0247, 0.0035, 0.0321, 0.0011, 0.2349,
        0.0092, 0.0294, 0.0730, 0.0014, 0.0446, 0.0008, 0.0023, 0.0119],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,301][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0015, 0.1647, 0.0136, 0.1653, 0.0499, 0.0102, 0.1074, 0.0029, 0.2258,
        0.0338, 0.0696, 0.0418, 0.0088, 0.0573, 0.0060, 0.0070, 0.0345],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,303][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0035, 0.0442, 0.0334, 0.0695, 0.0536, 0.0113, 0.0570, 0.0073, 0.2045,
        0.1280, 0.0761, 0.0528, 0.0343, 0.0802, 0.1072, 0.0099, 0.0272],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,304][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0033, 0.2827, 0.0042, 0.2050, 0.0599, 0.0124, 0.0459, 0.0029, 0.1602,
        0.0688, 0.0264, 0.0259, 0.0036, 0.0265, 0.0011, 0.0124, 0.0587],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,305][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0780, 0.0498, 0.0247, 0.0302, 0.0234, 0.0729, 0.0336, 0.0582, 0.0712,
        0.0536, 0.0257, 0.0406, 0.0290, 0.0409, 0.0278, 0.1302, 0.2104],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,307][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0021, 0.0264, 0.0116, 0.1609, 0.0306, 0.0118, 0.0883, 0.0029, 0.2404,
        0.0725, 0.0665, 0.0666, 0.0321, 0.1169, 0.0162, 0.0092, 0.0450],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,310][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0005, 0.0109, 0.0052, 0.0533, 0.0280, 0.0045, 0.0711, 0.0011, 0.3476,
        0.0644, 0.0869, 0.0984, 0.0166, 0.1357, 0.0185, 0.0043, 0.0529],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,312][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([7.3714e-05, 1.2345e-02, 2.2610e-02, 3.8424e-02, 3.2554e-02, 3.5276e-04,
        1.2851e-01, 1.8236e-04, 3.0273e-01, 9.5779e-02, 8.6439e-02, 1.1320e-01,
        3.5350e-03, 9.5733e-02, 6.0442e-02, 3.3624e-04, 6.7543e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,314][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([2.6188e-05, 8.2237e-04, 1.1652e-05, 5.6210e-03, 4.3395e-05, 6.0657e-04,
        5.7868e-01, 2.1533e-04, 3.4310e-02, 1.2111e-03, 3.0107e-03, 3.2832e-01,
        3.1296e-04, 3.9542e-03, 1.7241e-04, 1.8795e-04, 4.1262e-02, 1.2322e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,318][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([0.0137, 0.1103, 0.1139, 0.0603, 0.0937, 0.0279, 0.0521, 0.0307, 0.1514,
        0.0639, 0.0340, 0.0494, 0.0586, 0.0115, 0.0136, 0.0264, 0.0286, 0.0599],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,320][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([0.0015, 0.0540, 0.0104, 0.1332, 0.0618, 0.0120, 0.1509, 0.0039, 0.1043,
        0.1114, 0.0490, 0.0671, 0.0434, 0.0989, 0.0294, 0.0066, 0.0340, 0.0281],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,321][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([0.0848, 0.0164, 0.0141, 0.0066, 0.0266, 0.0543, 0.0146, 0.0782, 0.0609,
        0.0701, 0.0196, 0.0388, 0.0814, 0.0583, 0.0212, 0.1120, 0.1263, 0.1157],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,322][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([4.0691e-02, 2.3183e-01, 1.1464e-04, 1.8352e-01, 7.2355e-03, 1.9100e-02,
        2.8167e-02, 1.5671e-02, 2.0992e-01, 7.5260e-03, 1.3978e-02, 4.5174e-02,
        1.0232e-03, 6.6578e-02, 3.2831e-04, 3.3802e-02, 9.1948e-02, 3.3979e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,323][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([0.0019, 0.1327, 0.0025, 0.0898, 0.0263, 0.0106, 0.1255, 0.0027, 0.2532,
        0.0532, 0.0620, 0.0715, 0.0062, 0.0675, 0.0020, 0.0101, 0.0732, 0.0090],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,325][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([0.0131, 0.0789, 0.0240, 0.1390, 0.0302, 0.0417, 0.0871, 0.0257, 0.2083,
        0.0664, 0.0439, 0.0349, 0.0223, 0.0363, 0.0320, 0.0326, 0.0609, 0.0229],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,327][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([1.0427e-02, 4.7529e-01, 6.1611e-04, 8.8471e-02, 1.8097e-02, 1.1211e-02,
        3.6392e-02, 5.0743e-03, 8.8852e-02, 5.9567e-02, 5.0885e-03, 1.2582e-02,
        1.7870e-03, 1.9636e-02, 1.3945e-04, 2.7836e-02, 1.3802e-01, 9.1756e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,331][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([0.2268, 0.0209, 0.0053, 0.0103, 0.0035, 0.1359, 0.0094, 0.0908, 0.0144,
        0.0088, 0.0054, 0.0101, 0.0078, 0.0071, 0.0030, 0.2128, 0.2018, 0.0261],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,334][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([0.0074, 0.0365, 0.0078, 0.1408, 0.0434, 0.0307, 0.0994, 0.0076, 0.1847,
        0.0588, 0.0460, 0.0688, 0.0483, 0.0786, 0.0085, 0.0255, 0.0877, 0.0194],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,338][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([0.0006, 0.0107, 0.0022, 0.0604, 0.0179, 0.0067, 0.0892, 0.0014, 0.4034,
        0.0507, 0.0771, 0.0982, 0.0066, 0.0831, 0.0065, 0.0047, 0.0625, 0.0180],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,339][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([0.0012, 0.0271, 0.0098, 0.0685, 0.0181, 0.0031, 0.1185, 0.0019, 0.2893,
        0.0672, 0.0973, 0.1471, 0.0018, 0.0757, 0.0227, 0.0031, 0.0408, 0.0069],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,340][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.7876e-05, 2.4983e-04, 3.8557e-06, 2.2764e-03, 9.8275e-06, 4.8189e-04,
        5.7525e-01, 1.6894e-04, 1.4224e-02, 3.5110e-04, 1.2192e-03, 3.3221e-01,
        1.2136e-04, 1.2631e-03, 1.1649e-04, 1.4678e-04, 5.0763e-02, 5.1528e-04,
        2.0618e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,342][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1608, 0.0108, 0.0357, 0.0099, 0.0186, 0.1264, 0.0115, 0.2884, 0.0168,
        0.0183, 0.0043, 0.0117, 0.0221, 0.0016, 0.0065, 0.1795, 0.0517, 0.0220,
        0.0034], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,345][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0072, 0.0244, 0.0083, 0.0836, 0.0221, 0.0535, 0.0647, 0.0139, 0.0827,
        0.0636, 0.0585, 0.0628, 0.0788, 0.0767, 0.0336, 0.0357, 0.0997, 0.0348,
        0.0955], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,349][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2794, 0.0096, 0.0052, 0.0014, 0.0144, 0.0645, 0.0052, 0.1158, 0.0254,
        0.0162, 0.0080, 0.0155, 0.0458, 0.0249, 0.0063, 0.1701, 0.1355, 0.0286,
        0.0283], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,352][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.4304e-01, 1.8262e-01, 7.2610e-05, 1.0433e-01, 6.2191e-03, 5.0620e-02,
        2.8294e-02, 4.6001e-02, 1.6254e-01, 2.8932e-03, 1.1993e-02, 4.4649e-02,
        3.1705e-04, 1.4227e-02, 7.8796e-05, 5.4449e-02, 8.9760e-02, 1.0980e-03,
        5.6803e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,356][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0145, 0.2110, 0.0023, 0.0959, 0.0094, 0.0409, 0.1328, 0.0150, 0.1717,
        0.0223, 0.0376, 0.0233, 0.0024, 0.0270, 0.0008, 0.0264, 0.0919, 0.0051,
        0.0698], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,357][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0228, 0.0261, 0.0084, 0.0521, 0.0170, 0.0777, 0.0495, 0.0546, 0.1415,
        0.1012, 0.0387, 0.0445, 0.0295, 0.0380, 0.0294, 0.0608, 0.0948, 0.0174,
        0.0960], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,358][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([3.5563e-01, 1.0018e-01, 1.6286e-04, 1.1539e-02, 1.8825e-03, 1.2719e-01,
        3.3870e-03, 6.8244e-02, 6.8345e-03, 3.8929e-03, 5.5752e-04, 1.1684e-03,
        2.5223e-04, 1.1106e-03, 1.2804e-05, 1.9514e-01, 1.1822e-01, 1.6972e-04,
        4.4205e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,359][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.3013, 0.0166, 0.0058, 0.0040, 0.0025, 0.0897, 0.0073, 0.0918, 0.0178,
        0.0104, 0.0059, 0.0080, 0.0072, 0.0065, 0.0030, 0.1976, 0.1682, 0.0133,
        0.0432], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,361][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0166, 0.0264, 0.0036, 0.0875, 0.0140, 0.0500, 0.0610, 0.0147, 0.1620,
        0.0591, 0.0334, 0.0516, 0.0333, 0.0691, 0.0036, 0.0480, 0.1147, 0.0067,
        0.1446], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,364][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0037, 0.0081, 0.0016, 0.0278, 0.0121, 0.0181, 0.0477, 0.0051, 0.3545,
        0.0403, 0.0549, 0.0693, 0.0081, 0.0654, 0.0049, 0.0173, 0.1157, 0.0082,
        0.1370], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,367][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0044, 0.0438, 0.0276, 0.0462, 0.0258, 0.0052, 0.1506, 0.0043, 0.2666,
        0.0696, 0.0664, 0.0835, 0.0025, 0.0449, 0.0204, 0.0049, 0.0357, 0.0098,
        0.0880], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,371][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:36,374][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[910],
        [ 29],
        [ 24],
        [ 24],
        [374],
        [ 74],
        [  6],
        [148],
        [ 14],
        [ 17],
        [  4],
        [  4],
        [  7],
        [  7],
        [ 19],
        [  6],
        [  2],
        [ 15],
        [  2]], device='cuda:0')
[2024-07-24 10:27:36,376][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[1444],
        [  65],
        [  93],
        [ 100],
        [1049],
        [ 603],
        [  45],
        [ 757],
        [ 107],
        [ 115],
        [  35],
        [  28],
        [  57],
        [  37],
        [ 116],
        [  69],
        [  18],
        [ 105],
        [  21]], device='cuda:0')
[2024-07-24 10:27:36,379][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 9674],
        [ 8819],
        [ 8748],
        [12107],
        [11062],
        [11775],
        [11685],
        [11855],
        [12212],
        [12305],
        [12836],
        [12059],
        [11710],
        [11870],
        [12042],
        [11429],
        [10979],
        [11446],
        [11151]], device='cuda:0')
[2024-07-24 10:27:36,380][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[20968],
        [23053],
        [26320],
        [27014],
        [34629],
        [24981],
        [33966],
        [24169],
        [34571],
        [34488],
        [31284],
        [29713],
        [25537],
        [29391],
        [25878],
        [23487],
        [24412],
        [26458],
        [28691]], device='cuda:0')
[2024-07-24 10:27:36,382][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[3887],
        [6269],
        [3255],
        [3882],
        [2370],
        [2640],
        [2917],
        [2252],
        [2275],
        [1990],
        [1900],
        [2066],
        [2304],
        [2772],
        [2576],
        [2635],
        [2703],
        [2746],
        [2683]], device='cuda:0')
[2024-07-24 10:27:36,384][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[23599],
        [ 9392],
        [ 5682],
        [ 5419],
        [ 4782],
        [ 5171],
        [ 4971],
        [ 5294],
        [ 4933],
        [ 4670],
        [ 4383],
        [ 4424],
        [ 4615],
        [ 4334],
        [ 4029],
        [ 4520],
        [ 4330],
        [ 4162],
        [ 4014]], device='cuda:0')
[2024-07-24 10:27:36,386][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[46494],
        [24396],
        [23087],
        [20726],
        [20675],
        [19461],
        [20668],
        [19154],
        [21996],
        [22235],
        [22959],
        [23276],
        [23734],
        [23525],
        [23932],
        [23064],
        [22867],
        [23567],
        [23946]], device='cuda:0')
[2024-07-24 10:27:36,389][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[21896],
        [13943],
        [14209],
        [13985],
        [13997],
        [15115],
        [13932],
        [14885],
        [13902],
        [13843],
        [13869],
        [13848],
        [13770],
        [13856],
        [13875],
        [14677],
        [13999],
        [13853],
        [13873]], device='cuda:0')
[2024-07-24 10:27:36,391][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[14336],
        [11359],
        [13797],
        [13346],
        [12990],
        [13172],
        [13417],
        [12601],
        [15557],
        [16785],
        [16224],
        [15476],
        [15852],
        [16600],
        [14843],
        [15632],
        [16256],
        [17533],
        [15966]], device='cuda:0')
[2024-07-24 10:27:36,394][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[31460],
        [29285],
        [28732],
        [28347],
        [28276],
        [26742],
        [28136],
        [24503],
        [23965],
        [18512],
        [22299],
        [20678],
        [17321],
        [20490],
        [18351],
        [18523],
        [19060],
        [18806],
        [19925]], device='cuda:0')
[2024-07-24 10:27:36,397][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[11331],
        [19055],
        [ 9699],
        [10935],
        [ 1992],
        [ 2149],
        [ 2740],
        [ 3256],
        [ 3647],
        [ 4419],
        [ 4714],
        [ 5076],
        [ 4928],
        [ 5058],
        [ 4793],
        [ 4531],
        [ 4714],
        [ 4668],
        [ 4888]], device='cuda:0')
[2024-07-24 10:27:36,399][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[9262],
        [2578],
        [2705],
        [2654],
        [3907],
        [4100],
        [3199],
        [3515],
        [3537],
        [4347],
        [3630],
        [3436],
        [3314],
        [3247],
        [3692],
        [3893],
        [3564],
        [3585],
        [3932]], device='cuda:0')
[2024-07-24 10:27:36,401][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[23732],
        [ 6387],
        [ 4236],
        [ 3357],
        [  873],
        [  233],
        [  271],
        [  183],
        [  295],
        [  284],
        [  309],
        [  324],
        [  335],
        [  375],
        [  351],
        [  381],
        [  386],
        [  374],
        [  429]], device='cuda:0')
[2024-07-24 10:27:36,403][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[34770],
        [37555],
        [38734],
        [45835],
        [50247],
        [50250],
        [50094],
        [50196],
        [50036],
        [49921],
        [50008],
        [49976],
        [49854],
        [49988],
        [49920],
        [49991],
        [49968],
        [49861],
        [49929]], device='cuda:0')
[2024-07-24 10:27:36,404][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[5885],
        [2719],
        [1479],
        [2622],
        [3542],
        [ 862],
        [2374],
        [1596],
        [1271],
        [1255],
        [1037],
        [2219],
        [ 941],
        [1091],
        [1904],
        [ 223],
        [2694],
        [2673],
        [1096]], device='cuda:0')
[2024-07-24 10:27:36,407][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[20289],
        [31464],
        [30279],
        [39336],
        [38987],
        [38842],
        [33747],
        [33744],
        [33440],
        [32658],
        [33207],
        [33297],
        [33333],
        [33199],
        [33026],
        [33287],
        [33298],
        [32969],
        [33204]], device='cuda:0')
[2024-07-24 10:27:36,410][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[16760],
        [13446],
        [15805],
        [17230],
        [22847],
        [19947],
        [24448],
        [25885],
        [24408],
        [26942],
        [27999],
        [29402],
        [42030],
        [30141],
        [37556],
        [44070],
        [42519],
        [39217],
        [31862]], device='cuda:0')
[2024-07-24 10:27:36,412][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[30173],
        [25483],
        [10197],
        [ 9845],
        [ 9069],
        [ 7936],
        [ 7477],
        [ 8326],
        [ 8479],
        [10480],
        [ 8966],
        [ 8977],
        [ 7275],
        [ 7583],
        [ 6944],
        [ 5891],
        [ 6061],
        [ 7741],
        [ 6117]], device='cuda:0')
[2024-07-24 10:27:36,415][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[43934],
        [35839],
        [39959],
        [35370],
        [35513],
        [31658],
        [34756],
        [31765],
        [39729],
        [29882],
        [35657],
        [32942],
        [15701],
        [20341],
        [19016],
        [20526],
        [19328],
        [24209],
        [28798]], device='cuda:0')
[2024-07-24 10:27:36,418][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[21760],
        [ 9338],
        [ 8828],
        [ 3213],
        [ 3877],
        [ 2144],
        [ 2828],
        [ 1782],
        [ 2376],
        [ 1229],
        [ 1860],
        [ 1660],
        [  942],
        [ 1800],
        [ 1252],
        [ 1147],
        [ 1117],
        [ 1276],
        [ 1208]], device='cuda:0')
[2024-07-24 10:27:36,420][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[38203],
        [26197],
        [25669],
        [26401],
        [27750],
        [25132],
        [29010],
        [27543],
        [27001],
        [26449],
        [26825],
        [26685],
        [27641],
        [26263],
        [25747],
        [26397],
        [26963],
        [26381],
        [25977]], device='cuda:0')
[2024-07-24 10:27:36,422][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[25557],
        [35280],
        [31077],
        [32780],
        [25802],
        [12628],
        [21266],
        [12802],
        [13029],
        [12450],
        [12956],
        [13232],
        [ 8837],
        [ 9808],
        [ 9570],
        [ 5448],
        [ 6001],
        [ 8896],
        [ 5676]], device='cuda:0')
[2024-07-24 10:27:36,423][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[21502],
        [31397],
        [30019],
        [29991],
        [30555],
        [30873],
        [32233],
        [31031],
        [28474],
        [31997],
        [32957],
        [32388],
        [30317],
        [32788],
        [30241],
        [28276],
        [30887],
        [33693],
        [27931]], device='cuda:0')
[2024-07-24 10:27:36,425][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[30922],
        [34379],
        [31867],
        [35664],
        [34503],
        [12381],
        [32030],
        [10037],
        [30522],
        [19025],
        [26163],
        [19373],
        [12345],
        [17983],
        [19417],
        [ 8962],
        [ 9837],
        [10201],
        [10652]], device='cuda:0')
[2024-07-24 10:27:36,428][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[18400],
        [ 2483],
        [ 3354],
        [ 9037],
        [10105],
        [13032],
        [14573],
        [13997],
        [14871],
        [14823],
        [15000],
        [14979],
        [15218],
        [15428],
        [15298],
        [15351],
        [15595],
        [16172],
        [17268]], device='cuda:0')
[2024-07-24 10:27:36,430][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 4463],
        [ 6358],
        [11004],
        [24126],
        [24901],
        [25236],
        [32787],
        [29233],
        [34041],
        [35150],
        [35410],
        [34118],
        [33923],
        [33088],
        [32828],
        [31179],
        [32551],
        [33275],
        [34056]], device='cuda:0')
[2024-07-24 10:27:36,433][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 5755],
        [11677],
        [26214],
        [29791],
        [26196],
        [28353],
        [36936],
        [34026],
        [23548],
        [21884],
        [23750],
        [26619],
        [26876],
        [23392],
        [24788],
        [22811],
        [24498],
        [26462],
        [26402]], device='cuda:0')
[2024-07-24 10:27:36,436][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[14870],
        [32941],
        [32720],
        [24631],
        [24814],
        [35965],
        [22093],
        [35533],
        [25901],
        [32274],
        [28354],
        [30620],
        [35254],
        [35138],
        [33656],
        [38038],
        [37293],
        [34601],
        [36900]], device='cuda:0')
[2024-07-24 10:27:36,439][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[40381],
        [30661],
        [28467],
        [28526],
        [19526],
        [35692],
        [35487],
        [40024],
        [40723],
        [33582],
        [33470],
        [30017],
        [32206],
        [35579],
        [20644],
        [41038],
        [20942],
        [19034],
        [39351]], device='cuda:0')
[2024-07-24 10:27:36,441][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507]], device='cuda:0')
[2024-07-24 10:27:36,535][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:36,536][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:36,538][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:36,541][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:36,541][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:36,542][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:36,543][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:36,543][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:36,544][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:36,545][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:36,546][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:36,546][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:36,547][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:36,548][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8266, 0.1734], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:36,548][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0275, 0.9725], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:36,549][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9842, 0.0158], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:36,550][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9084, 0.0916], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:36,553][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2433, 0.7567], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:36,555][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3082, 0.6918], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:36,555][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0061, 0.9939], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:36,556][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3584, 0.6416], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:36,557][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.6803, 0.3197], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:36,558][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0128, 0.9872], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:36,560][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1488, 0.8512], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:36,562][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0291, 0.9709], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:36,566][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.9235, 0.0113, 0.0652], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:36,570][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0087, 0.2623, 0.7290], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:36,573][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.9932, 0.0012, 0.0056], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:36,573][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.8190, 0.1767, 0.0042], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:36,574][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.2279, 0.1141, 0.6580], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:36,575][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.3473, 0.4643, 0.1884], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:36,576][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.0019, 0.2699, 0.7282], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:36,579][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.1470, 0.7967, 0.0563], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:36,583][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.7317, 0.2018, 0.0664], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:36,586][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0034, 0.2338, 0.7629], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:36,590][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.0898, 0.8609, 0.0494], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:36,591][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.0156, 0.6099, 0.3745], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:36,592][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.9514, 0.0083, 0.0279, 0.0125], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:36,592][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0031, 0.3553, 0.4333, 0.2083], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:36,593][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.9849, 0.0017, 0.0101, 0.0033], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:36,594][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([9.7277e-01, 2.3651e-02, 9.4774e-04, 2.6277e-03], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:36,597][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2048, 0.0840, 0.3598, 0.3513], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:36,601][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2745, 0.4065, 0.0881, 0.2309], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:36,604][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0007, 0.0806, 0.6593, 0.2593], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:36,608][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2964, 0.2497, 0.0568, 0.3971], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:36,609][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.6598, 0.2106, 0.0800, 0.0496], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:36,610][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0023, 0.2645, 0.4164, 0.3169], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:36,610][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2840, 0.5422, 0.0289, 0.1448], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:36,612][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0158, 0.4836, 0.3013, 0.1993], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:36,615][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.9774, 0.0045, 0.0105, 0.0040, 0.0036], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:36,619][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([0.0068, 0.0951, 0.2963, 0.1368, 0.4650], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:36,622][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.9878, 0.0015, 0.0072, 0.0020, 0.0015], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:36,624][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([9.1160e-01, 7.4708e-02, 7.2215e-04, 1.0088e-02, 2.8844e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:36,626][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.1554, 0.0746, 0.4543, 0.1514, 0.1642], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:36,627][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([0.2951, 0.2767, 0.0629, 0.1577, 0.2075], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:36,627][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.0019, 0.0784, 0.3021, 0.2551, 0.3625], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:36,628][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.2299, 0.2768, 0.0160, 0.4099, 0.0674], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:36,630][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.5166, 0.2050, 0.0484, 0.0610, 0.1690], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:36,633][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.0201, 0.1390, 0.3924, 0.1519, 0.2966], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:36,637][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.1651, 0.4533, 0.0067, 0.2121, 0.1628], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:36,640][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([0.0177, 0.3683, 0.1104, 0.2502, 0.2534], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:36,644][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.3207, 0.0282, 0.2346, 0.0619, 0.0688, 0.2858], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,644][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ had] are: tensor([5.6551e-06, 7.3733e-02, 1.4363e-01, 2.5229e-02, 7.5732e-01, 7.7708e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,645][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.5147, 0.0147, 0.0937, 0.0286, 0.0384, 0.3100], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,646][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.6966, 0.0704, 0.0094, 0.0226, 0.0186, 0.1825], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,648][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0020, 0.0379, 0.5215, 0.1202, 0.3107, 0.0077], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,650][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0400, 0.2700, 0.1105, 0.1486, 0.2814, 0.1495], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,653][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ had] are: tensor([2.0627e-06, 4.6769e-02, 4.3349e-01, 9.7950e-02, 4.2176e-01, 3.5925e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,657][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0212, 0.1384, 0.1196, 0.3454, 0.2917, 0.0838], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,660][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0539, 0.1724, 0.2351, 0.0780, 0.4434, 0.0172], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,662][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ had] are: tensor([2.5297e-06, 2.4382e-01, 3.5277e-01, 1.3122e-01, 2.7215e-01, 3.3051e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,662][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0054, 0.3441, 0.0385, 0.2559, 0.3247, 0.0313], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,663][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ had] are: tensor([3.0141e-05, 1.3672e-01, 1.7998e-01, 1.4981e-01, 5.3264e-01, 8.1596e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:36,664][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.6256, 0.0021, 0.0115, 0.0046, 0.0043, 0.3288, 0.0232],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,666][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0027, 0.0497, 0.1532, 0.1078, 0.3980, 0.0485, 0.2402],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,668][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([5.6931e-01, 5.0973e-04, 3.2302e-03, 1.3364e-03, 7.8993e-04, 4.1989e-01,
        4.9332e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,670][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([9.0313e-01, 7.3903e-03, 1.9074e-04, 1.2721e-03, 3.2864e-04, 8.7355e-02,
        3.3097e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,673][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2180, 0.0180, 0.1039, 0.0399, 0.0794, 0.4620, 0.0789],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,677][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1637, 0.0853, 0.0237, 0.0547, 0.0628, 0.4725, 0.1374],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,679][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([2.5005e-04, 1.5354e-02, 3.2669e-01, 7.4103e-02, 1.9788e-01, 3.7460e-03,
        3.8198e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,680][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2120, 0.0594, 0.0070, 0.1541, 0.0315, 0.3899, 0.1462],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,681][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.4714, 0.1216, 0.0971, 0.0336, 0.1779, 0.0750, 0.0234],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,682][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0037, 0.0568, 0.2973, 0.0967, 0.1270, 0.0249, 0.3935],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,684][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1747, 0.2087, 0.0065, 0.0991, 0.0638, 0.2678, 0.1793],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,686][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0421, 0.2115, 0.1163, 0.1405, 0.1374, 0.0914, 0.2608],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:36,690][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0325, 0.0423, 0.2647, 0.0999, 0.1533, 0.0654, 0.3038, 0.0381],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,692][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([1.3246e-05, 8.6905e-02, 1.1234e-01, 2.4698e-02, 5.6673e-01, 8.2262e-05,
        2.0921e-01, 1.6961e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,696][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0740, 0.0507, 0.1764, 0.1083, 0.1494, 0.1172, 0.2212, 0.1027],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,697][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.1655, 0.1590, 0.0270, 0.1368, 0.0820, 0.1449, 0.1145, 0.1703],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,698][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0006, 0.0460, 0.3108, 0.1167, 0.2724, 0.0025, 0.2499, 0.0011],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,699][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0135, 0.1914, 0.1191, 0.1412, 0.2360, 0.0580, 0.2253, 0.0156],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,700][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([1.0956e-06, 3.8595e-02, 2.4848e-01, 5.2068e-02, 2.4926e-01, 1.2182e-05,
        4.1158e-01, 2.2711e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,702][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0036, 0.0751, 0.0920, 0.2281, 0.2598, 0.0247, 0.3064, 0.0103],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,704][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0193, 0.1618, 0.2416, 0.0911, 0.3364, 0.0109, 0.1220, 0.0168],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,707][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([2.5317e-07, 1.0170e-01, 1.3771e-01, 4.1171e-02, 1.3477e-01, 3.2350e-06,
        5.8465e-01, 3.1795e-07], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,711][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0005, 0.1410, 0.0270, 0.2235, 0.2337, 0.0063, 0.3665, 0.0016],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,713][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([1.3055e-05, 6.5985e-02, 1.1851e-01, 8.6564e-02, 3.2116e-01, 3.2888e-04,
        4.0734e-01, 9.2680e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:36,715][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.3179, 0.0049, 0.0234, 0.0077, 0.0092, 0.2415, 0.0348, 0.2004, 0.1603],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,716][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0026, 0.0291, 0.0481, 0.0598, 0.1527, 0.0312, 0.1783, 0.0122, 0.4861],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,717][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.3680, 0.0013, 0.0042, 0.0022, 0.0014, 0.2616, 0.0068, 0.3424, 0.0121],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,718][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ of] are: tensor([8.5841e-01, 3.1884e-03, 7.1503e-05, 3.7640e-04, 6.4079e-05, 2.5515e-02,
        1.1333e-04, 1.1222e-01, 4.7272e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,720][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0669, 0.0113, 0.0676, 0.0370, 0.1047, 0.2635, 0.0920, 0.1646, 0.1923],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,723][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.1780, 0.0684, 0.0159, 0.0338, 0.0413, 0.4022, 0.0775, 0.1292, 0.0537],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,725][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ of] are: tensor([2.3368e-04, 8.1815e-03, 1.5302e-01, 3.0728e-02, 8.9714e-02, 1.8122e-03,
        1.6278e-01, 8.6839e-04, 5.5266e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,729][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.2892, 0.0409, 0.0031, 0.0733, 0.0161, 0.2628, 0.0919, 0.1280, 0.0947],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,733][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.3758, 0.0855, 0.0950, 0.0234, 0.1403, 0.0471, 0.0157, 0.1403, 0.0769],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,734][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0014, 0.0263, 0.1457, 0.0419, 0.0873, 0.0066, 0.2267, 0.0027, 0.4615],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,735][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.2832, 0.1024, 0.0017, 0.0342, 0.0125, 0.1990, 0.0881, 0.1704, 0.1085],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,736][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0435, 0.1241, 0.0397, 0.1103, 0.0815, 0.0703, 0.2313, 0.1218, 0.1774],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:36,738][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0784, 0.0060, 0.0320, 0.0196, 0.0151, 0.1632, 0.1058, 0.0882, 0.3043,
        0.1874], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,740][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([2.2370e-04, 1.4391e-02, 3.7631e-02, 5.9145e-02, 1.4161e-01, 6.5892e-03,
        1.1377e-01, 1.6697e-03, 3.6465e-01, 2.6032e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,744][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.2370, 0.0023, 0.0063, 0.0060, 0.0037, 0.3011, 0.0338, 0.3422, 0.0423,
        0.0252], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,747][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([7.6705e-01, 1.7406e-02, 1.6107e-04, 2.6001e-03, 4.8350e-04, 6.0626e-02,
        1.1886e-03, 1.4450e-01, 1.2052e-03, 4.7814e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,750][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0041, 0.0058, 0.0622, 0.0499, 0.1419, 0.0595, 0.1615, 0.0209, 0.2257,
        0.2686], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,752][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0305, 0.0416, 0.0286, 0.0441, 0.0591, 0.2082, 0.1278, 0.0608, 0.1268,
        0.2727], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,753][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([4.5916e-05, 5.6614e-03, 7.5275e-02, 3.1122e-02, 5.4123e-02, 7.5582e-04,
        1.2301e-01, 2.6574e-04, 6.0593e-01, 1.0381e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,754][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0363, 0.0283, 0.0035, 0.1807, 0.0384, 0.1553, 0.1896, 0.0421, 0.2363,
        0.0896], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,754][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.2569, 0.0806, 0.0397, 0.0319, 0.0966, 0.0445, 0.0212, 0.1276, 0.1796,
        0.1214], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,756][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0007, 0.0133, 0.0668, 0.0383, 0.0449, 0.0044, 0.1148, 0.0014, 0.3190,
        0.3964], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,759][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0330, 0.1466, 0.0016, 0.0633, 0.0248, 0.0751, 0.1820, 0.0327, 0.3529,
        0.0881], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,763][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0097, 0.0696, 0.0435, 0.1009, 0.0954, 0.0299, 0.2984, 0.0287, 0.2480,
        0.0760], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:36,768][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.1771, 0.0042, 0.0140, 0.0058, 0.0060, 0.1851, 0.0310, 0.1438, 0.2319,
        0.1492, 0.0520], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,770][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0006, 0.0138, 0.0217, 0.0301, 0.0712, 0.0122, 0.1341, 0.0038, 0.5001,
        0.1285, 0.0838], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,771][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.2959, 0.0014, 0.0046, 0.0021, 0.0014, 0.3017, 0.0101, 0.3389, 0.0257,
        0.0117, 0.0064], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,771][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ at] are: tensor([8.1369e-01, 8.8682e-03, 6.2014e-05, 1.1028e-03, 1.4445e-04, 3.7574e-02,
        3.7488e-04, 1.3453e-01, 3.4888e-04, 3.0557e-03, 2.3952e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,772][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0617, 0.0080, 0.0329, 0.0285, 0.0851, 0.2124, 0.0849, 0.1537, 0.1541,
        0.1260, 0.0528], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,774][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0861, 0.0611, 0.0142, 0.0412, 0.0379, 0.3104, 0.0926, 0.0926, 0.0804,
        0.1205, 0.0630], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,776][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ at] are: tensor([1.0833e-04, 4.4623e-03, 5.4820e-02, 1.8704e-02, 3.9457e-02, 1.3372e-03,
        1.0327e-01, 5.5723e-04, 6.2072e-01, 8.6890e-02, 6.9671e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,781][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0848, 0.0281, 0.0023, 0.0960, 0.0248, 0.1836, 0.1173, 0.0674, 0.2372,
        0.1073, 0.0512], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,784][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.3955, 0.0694, 0.0364, 0.0204, 0.0875, 0.0492, 0.0108, 0.1440, 0.0832,
        0.0642, 0.0394], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,788][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0010, 0.0146, 0.0524, 0.0214, 0.0302, 0.0058, 0.0874, 0.0019, 0.3199,
        0.2080, 0.2575], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,789][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0813, 0.1228, 0.0013, 0.0546, 0.0199, 0.0826, 0.1361, 0.0569, 0.2665,
        0.1136, 0.0645], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,790][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0080, 0.0503, 0.0352, 0.1459, 0.0660, 0.0468, 0.2857, 0.0428, 0.2007,
        0.0440, 0.0745], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:36,790][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1645, 0.0049, 0.0199, 0.0077, 0.0099, 0.1906, 0.0427, 0.1221, 0.2122,
        0.1364, 0.0518, 0.0374], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,792][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0012, 0.0222, 0.0460, 0.0383, 0.1071, 0.0163, 0.0963, 0.0055, 0.3253,
        0.1875, 0.0816, 0.0728], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,795][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1803, 0.0024, 0.0093, 0.0052, 0.0036, 0.3704, 0.0307, 0.2531, 0.0648,
        0.0293, 0.0167, 0.0342], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,797][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ the] are: tensor([8.0326e-01, 1.5863e-02, 1.1880e-04, 3.9272e-03, 3.6368e-04, 4.9342e-02,
        1.2206e-03, 1.1789e-01, 1.5320e-03, 5.0740e-03, 7.0057e-04, 7.0755e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,801][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0470, 0.0089, 0.0473, 0.0250, 0.0951, 0.1578, 0.0789, 0.1185, 0.1511,
        0.1278, 0.0882, 0.0545], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,806][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0539, 0.0472, 0.0155, 0.0404, 0.0459, 0.2175, 0.1040, 0.0568, 0.0996,
        0.1322, 0.0696, 0.1175], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,807][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ the] are: tensor([6.0267e-05, 5.8145e-03, 7.5863e-02, 2.2741e-02, 4.5580e-02, 1.0386e-03,
        1.0420e-01, 3.3094e-04, 5.2508e-01, 9.9890e-02, 6.4557e-02, 5.4845e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,808][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1040, 0.0283, 0.0023, 0.1197, 0.0184, 0.1493, 0.0994, 0.0680, 0.2060,
        0.1012, 0.0463, 0.0571], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,808][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.2452, 0.0996, 0.0625, 0.0282, 0.1113, 0.0387, 0.0187, 0.0945, 0.1214,
        0.0938, 0.0650, 0.0210], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,811][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0004, 0.0118, 0.0668, 0.0175, 0.0287, 0.0029, 0.0749, 0.0008, 0.2016,
        0.2068, 0.1866, 0.2012], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,813][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0545, 0.0894, 0.0006, 0.0648, 0.0161, 0.0595, 0.1301, 0.0409, 0.3288,
        0.0821, 0.0843, 0.0486], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,817][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0057, 0.0522, 0.0363, 0.1247, 0.0623, 0.0398, 0.2867, 0.0299, 0.1913,
        0.0444, 0.0702, 0.0563], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:36,822][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.1649, 0.0038, 0.0193, 0.0087, 0.0068, 0.1002, 0.0573, 0.0988, 0.1653,
        0.1134, 0.0501, 0.0530, 0.1584], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,824][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ store] are: tensor([2.5801e-05, 8.1311e-03, 3.4980e-02, 2.3558e-02, 1.3310e-01, 7.8962e-04,
        1.0022e-01, 1.3154e-04, 4.1464e-01, 1.3862e-01, 5.7222e-02, 6.7958e-02,
        2.0621e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,825][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.2883, 0.0033, 0.0107, 0.0071, 0.0051, 0.2179, 0.0204, 0.2907, 0.0353,
        0.0283, 0.0189, 0.0330, 0.0409], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,826][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ store] are: tensor([6.4259e-01, 3.0400e-02, 1.1439e-04, 8.7309e-03, 8.8310e-04, 4.9405e-02,
        5.0001e-03, 1.9657e-01, 6.9148e-03, 3.1911e-02, 5.2755e-03, 1.5370e-02,
        6.8337e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,827][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0037, 0.0071, 0.0870, 0.0330, 0.0794, 0.0252, 0.0919, 0.0126, 0.1688,
        0.1480, 0.0879, 0.1359, 0.1194], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,829][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0226, 0.0557, 0.0186, 0.0433, 0.0536, 0.1115, 0.1223, 0.0320, 0.0849,
        0.1327, 0.0732, 0.1466, 0.1031], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,831][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ store] are: tensor([1.8135e-05, 4.3340e-03, 4.3914e-02, 1.8814e-02, 3.6214e-02, 1.9762e-04,
        9.3820e-02, 6.8652e-05, 5.1730e-01, 8.1334e-02, 8.2513e-02, 1.1518e-01,
        6.2941e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,835][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0078, 0.0138, 0.0029, 0.0897, 0.0250, 0.0434, 0.1718, 0.0122, 0.2993,
        0.1188, 0.0710, 0.1209, 0.0234], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,839][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.0886, 0.0450, 0.0269, 0.0296, 0.0852, 0.0237, 0.0273, 0.0568, 0.1951,
        0.1062, 0.0637, 0.0283, 0.2236], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,842][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ store] are: tensor([4.4731e-05, 4.8970e-03, 2.7179e-02, 1.3844e-02, 1.8505e-02, 2.8684e-04,
        5.3702e-02, 8.3438e-05, 2.2543e-01, 1.6942e-01, 1.6571e-01, 3.0778e-01,
        1.3114e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,843][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ store] are: tensor([1.1553e-02, 5.0159e-02, 2.0264e-04, 4.0295e-02, 9.7724e-03, 1.8293e-02,
        1.1117e-01, 1.4353e-02, 3.0876e-01, 1.2327e-01, 1.2065e-01, 1.3372e-01,
        5.7807e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,843][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ store] are: tensor([2.2658e-04, 3.7617e-02, 2.0837e-02, 8.2532e-02, 5.9404e-02, 3.3914e-03,
        2.7119e-01, 1.8367e-03, 2.1509e-01, 7.8467e-02, 9.6450e-02, 8.9738e-02,
        4.3225e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:36,844][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.1317, 0.0040, 0.0142, 0.0044, 0.0073, 0.0936, 0.0383, 0.0844, 0.1836,
        0.1247, 0.0474, 0.0314, 0.1389, 0.0959], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,846][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0013, 0.0120, 0.0282, 0.0268, 0.0953, 0.0178, 0.1098, 0.0067, 0.3461,
        0.1507, 0.0573, 0.0495, 0.0509, 0.0476], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,849][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.2640, 0.0022, 0.0070, 0.0032, 0.0034, 0.2963, 0.0168, 0.2557, 0.0396,
        0.0185, 0.0128, 0.0230, 0.0459, 0.0115], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,851][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [.] are: tensor([8.0447e-01, 1.5849e-02, 5.1096e-05, 3.3652e-03, 1.8864e-04, 3.2121e-02,
        9.4286e-04, 1.2992e-01, 1.0193e-03, 7.8394e-03, 5.6309e-04, 1.3047e-03,
        7.3373e-04, 1.6367e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,855][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0200, 0.0067, 0.0373, 0.0223, 0.0809, 0.0976, 0.0723, 0.0535, 0.1530,
        0.0913, 0.0510, 0.0543, 0.1028, 0.1570], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,860][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0609, 0.0597, 0.0122, 0.0357, 0.0297, 0.2419, 0.0949, 0.0694, 0.0714,
        0.1243, 0.0488, 0.0821, 0.0640, 0.0049], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,861][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [.] are: tensor([1.0056e-04, 7.0519e-03, 7.9565e-02, 1.8915e-02, 6.8287e-02, 8.6395e-04,
        8.4099e-02, 3.5072e-04, 4.2862e-01, 1.1392e-01, 5.9122e-02, 7.6796e-02,
        1.5527e-02, 4.6789e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,861][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0209, 0.0188, 0.0025, 0.1136, 0.0263, 0.0787, 0.1556, 0.0198, 0.2740,
        0.0908, 0.0549, 0.0874, 0.0164, 0.0403], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,862][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.1559, 0.0444, 0.0473, 0.0145, 0.0967, 0.0270, 0.0137, 0.0650, 0.1024,
        0.0826, 0.0427, 0.0136, 0.2304, 0.0638], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,864][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0006, 0.0130, 0.0432, 0.0165, 0.0212, 0.0024, 0.0586, 0.0009, 0.1712,
        0.1481, 0.1566, 0.1937, 0.0337, 0.1403], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,867][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1253, 0.0894, 0.0003, 0.0346, 0.0085, 0.0737, 0.1163, 0.0706, 0.1923,
        0.0854, 0.0537, 0.0545, 0.0192, 0.0762], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,871][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0138, 0.0861, 0.0254, 0.0942, 0.0676, 0.0353, 0.2665, 0.0543, 0.1402,
        0.0559, 0.0464, 0.0439, 0.0304, 0.0400], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:36,876][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.0937, 0.0028, 0.0267, 0.0041, 0.0097, 0.1178, 0.0252, 0.0653, 0.1217,
        0.1576, 0.0263, 0.0231, 0.1194, 0.0503, 0.1564], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,878][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0006, 0.0108, 0.0222, 0.0395, 0.0828, 0.0136, 0.1015, 0.0036, 0.3767,
        0.1207, 0.0598, 0.0606, 0.0326, 0.0541, 0.0208], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,879][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.2576, 0.0023, 0.0141, 0.0036, 0.0036, 0.2270, 0.0190, 0.2890, 0.0403,
        0.0284, 0.0103, 0.0204, 0.0392, 0.0121, 0.0331], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,880][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([4.3300e-01, 2.6500e-02, 9.3382e-05, 7.7989e-03, 1.4246e-03, 7.9578e-02,
        5.6836e-03, 2.1915e-01, 1.1054e-02, 9.0686e-02, 6.8053e-03, 2.2581e-02,
        3.0557e-02, 6.3098e-02, 1.9847e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,880][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.0203, 0.0069, 0.0507, 0.0289, 0.0579, 0.0882, 0.0773, 0.0605, 0.1161,
        0.1588, 0.0351, 0.0376, 0.0604, 0.0848, 0.1165], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,882][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0466, 0.0443, 0.0152, 0.0353, 0.0520, 0.1952, 0.0863, 0.0689, 0.0778,
        0.1534, 0.0435, 0.0848, 0.0797, 0.0051, 0.0119], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,884][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([9.9547e-05, 6.9846e-03, 5.2357e-02, 1.9009e-02, 3.5615e-02, 1.2501e-03,
        6.4976e-02, 4.3070e-04, 4.1322e-01, 1.1501e-01, 6.6419e-02, 6.6597e-02,
        2.1482e-02, 5.7406e-02, 7.9145e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,885][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.0315, 0.0335, 0.0030, 0.1022, 0.0228, 0.0695, 0.1313, 0.0354, 0.2132,
        0.1014, 0.0606, 0.1000, 0.0168, 0.0714, 0.0073], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,889][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.0798, 0.0317, 0.0281, 0.0157, 0.0451, 0.0190, 0.0195, 0.0524, 0.1185,
        0.1145, 0.0410, 0.0322, 0.1890, 0.0911, 0.1226], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,893][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0002, 0.0087, 0.0354, 0.0119, 0.0172, 0.0013, 0.0407, 0.0004, 0.1098,
        0.1419, 0.1609, 0.1990, 0.0361, 0.1267, 0.1098], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,895][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([1.4162e-02, 2.0736e-02, 1.3091e-04, 2.0053e-02, 6.0972e-03, 3.5880e-02,
        6.4543e-02, 3.1549e-02, 1.7261e-01, 1.1330e-01, 6.3287e-02, 1.1274e-01,
        1.0856e-01, 2.3279e-01, 3.5708e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,897][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.0045, 0.0849, 0.0375, 0.0790, 0.0626, 0.0226, 0.2213, 0.0194, 0.1781,
        0.0662, 0.0517, 0.0478, 0.0434, 0.0505, 0.0303], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:36,898][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0184, 0.0073, 0.0587, 0.0104, 0.0304, 0.0187, 0.0493, 0.0135, 0.0988,
        0.1334, 0.0682, 0.0514, 0.1246, 0.0818, 0.2050, 0.0299],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,899][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([1.3501e-06, 1.4686e-02, 3.5896e-02, 9.9863e-03, 1.4874e-01, 2.1450e-05,
        1.0199e-01, 2.7779e-06, 3.0051e-01, 7.5626e-02, 1.0257e-01, 8.8603e-02,
        1.2755e-02, 8.7793e-02, 2.0800e-02, 1.1702e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,900][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0565, 0.0180, 0.0465, 0.0237, 0.0373, 0.0562, 0.0516, 0.0520, 0.0846,
        0.0676, 0.0723, 0.1006, 0.0672, 0.0706, 0.1271, 0.0684],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,902][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.1683, 0.0603, 0.0025, 0.0401, 0.0105, 0.0704, 0.0260, 0.1076, 0.0299,
        0.0719, 0.0221, 0.0409, 0.0212, 0.0648, 0.0123, 0.2514],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,906][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0002, 0.0102, 0.0913, 0.0200, 0.1207, 0.0008, 0.0666, 0.0004, 0.0718,
        0.0947, 0.0979, 0.1143, 0.0516, 0.1378, 0.1204, 0.0012],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,909][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0091, 0.1122, 0.0504, 0.0705, 0.1334, 0.0414, 0.1359, 0.0092, 0.0576,
        0.0884, 0.0751, 0.1058, 0.0697, 0.0059, 0.0139, 0.0217],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,911][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([1.2717e-07, 5.8013e-03, 4.3319e-02, 9.0013e-03, 4.1256e-02, 2.0187e-06,
        8.3090e-02, 3.0766e-07, 3.2537e-01, 6.1524e-02, 1.3303e-01, 1.1855e-01,
        1.8569e-03, 6.8829e-02, 1.0836e-01, 9.4969e-07], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,916][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0020, 0.0260, 0.0191, 0.0935, 0.0714, 0.0108, 0.1163, 0.0041, 0.1623,
        0.1362, 0.0838, 0.1027, 0.0396, 0.0885, 0.0356, 0.0081],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,916][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0085, 0.0327, 0.0760, 0.0208, 0.1004, 0.0040, 0.0303, 0.0065, 0.1200,
        0.0915, 0.0733, 0.0374, 0.0952, 0.0979, 0.1950, 0.0107],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,917][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([1.7678e-08, 4.5914e-03, 8.5270e-03, 2.4755e-03, 6.6979e-03, 2.2223e-07,
        3.7428e-02, 2.1835e-08, 2.5253e-01, 6.4188e-02, 1.5089e-01, 2.7853e-01,
        1.1285e-03, 1.1121e-01, 8.1802e-02, 3.7716e-08], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,918][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0004, 0.0383, 0.0015, 0.0588, 0.0273, 0.0025, 0.0969, 0.0009, 0.3195,
        0.0788, 0.1045, 0.0989, 0.0253, 0.1350, 0.0080, 0.0036],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,920][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([1.1988e-06, 7.6845e-03, 1.4505e-02, 2.2513e-02, 4.3425e-02, 7.1189e-05,
        1.6258e-01, 1.3760e-05, 2.5201e-01, 3.3442e-02, 1.1715e-01, 9.6322e-02,
        1.7442e-02, 1.8679e-01, 4.6010e-02, 4.3237e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:36,924][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0599, 0.0021, 0.0187, 0.0036, 0.0090, 0.0474, 0.0226, 0.0361, 0.0906,
        0.0869, 0.0328, 0.0223, 0.0924, 0.0404, 0.1130, 0.1219, 0.2003],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,926][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.0035e-05, 7.0958e-03, 2.9087e-02, 1.4779e-02, 9.5601e-02, 2.7543e-04,
        9.2307e-02, 4.3991e-05, 4.1780e-01, 1.0431e-01, 6.1763e-02, 6.0123e-02,
        2.3556e-02, 6.7907e-02, 2.3530e-02, 1.4970e-04, 1.6716e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,929][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1342, 0.0031, 0.0116, 0.0061, 0.0058, 0.1318, 0.0223, 0.1289, 0.0422,
        0.0232, 0.0218, 0.0338, 0.0289, 0.0181, 0.0358, 0.1845, 0.1680],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,932][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([4.1996e-01, 2.4532e-02, 2.4703e-04, 9.5005e-03, 8.2294e-04, 6.9649e-02,
        2.5821e-03, 1.5800e-01, 2.7154e-03, 1.4535e-02, 1.6209e-03, 2.4967e-03,
        2.1514e-03, 5.7284e-03, 3.1601e-04, 2.3421e-01, 5.0939e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,936][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0025, 0.0054, 0.0464, 0.0109, 0.0765, 0.0093, 0.0454, 0.0054, 0.0869,
        0.0646, 0.0730, 0.0803, 0.0938, 0.1551, 0.1242, 0.0211, 0.0992],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,937][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0242, 0.0703, 0.0190, 0.0517, 0.0546, 0.1097, 0.1169, 0.0269, 0.0674,
        0.1009, 0.0625, 0.0991, 0.0646, 0.0045, 0.0089, 0.0583, 0.0606],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,937][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([1.6543e-06, 2.9740e-03, 5.3164e-02, 9.5525e-03, 3.9468e-02, 2.2782e-05,
        5.8498e-02, 5.5516e-06, 4.1545e-01, 8.6501e-02, 9.0889e-02, 8.9250e-02,
        4.0150e-03, 4.6915e-02, 1.0282e-01, 1.6863e-05, 4.4951e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,938][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0177, 0.0262, 0.0059, 0.1089, 0.0374, 0.0568, 0.1058, 0.0204, 0.1866,
        0.1078, 0.0545, 0.0701, 0.0223, 0.0524, 0.0096, 0.0360, 0.0815],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,941][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0551, 0.0294, 0.0713, 0.0146, 0.0885, 0.0123, 0.0143, 0.0279, 0.0855,
        0.0843, 0.0419, 0.0181, 0.1603, 0.0683, 0.1527, 0.0445, 0.0309],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,943][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([6.2450e-07, 3.0466e-03, 1.2265e-02, 3.2431e-03, 7.4861e-03, 5.5124e-06,
        3.4355e-02, 9.4319e-07, 2.4052e-01, 1.0731e-01, 1.5471e-01, 2.5582e-01,
        4.1657e-03, 1.0554e-01, 7.1436e-02, 1.6088e-06, 8.2370e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,947][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0037, 0.0505, 0.0007, 0.0651, 0.0161, 0.0117, 0.1112, 0.0049, 0.3009,
        0.0728, 0.0672, 0.0558, 0.0168, 0.0939, 0.0019, 0.0147, 0.1121],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,949][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([5.8689e-05, 1.7511e-02, 2.5248e-02, 5.4722e-02, 4.9617e-02, 1.4195e-03,
        1.9680e-01, 5.4204e-04, 2.7280e-01, 4.1007e-02, 8.8021e-02, 7.6371e-02,
        2.3840e-02, 1.1211e-01, 3.3079e-02, 8.7846e-04, 5.9773e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:36,953][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.0424, 0.0019, 0.0225, 0.0029, 0.0076, 0.0487, 0.0262, 0.0276, 0.0920,
        0.0592, 0.0222, 0.0157, 0.0771, 0.0507, 0.1039, 0.1063, 0.1848, 0.1081],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,954][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([0.0006, 0.0073, 0.0193, 0.0277, 0.0791, 0.0126, 0.0947, 0.0030, 0.3231,
        0.1716, 0.0466, 0.0604, 0.0346, 0.0436, 0.0219, 0.0081, 0.0177, 0.0282],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,955][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([0.1576, 0.0033, 0.0177, 0.0061, 0.0047, 0.1429, 0.0165, 0.1458, 0.0301,
        0.0143, 0.0103, 0.0252, 0.0281, 0.0109, 0.0297, 0.1729, 0.1306, 0.0533],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,957][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([3.4884e-01, 2.1871e-02, 9.7883e-05, 3.5588e-03, 6.6525e-04, 4.5231e-02,
        4.0446e-03, 1.1110e-01, 6.7184e-03, 2.6906e-02, 1.8946e-03, 4.8583e-03,
        4.1985e-03, 1.1276e-02, 1.6805e-04, 3.0536e-01, 1.0059e-01, 2.6185e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,960][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([0.0073, 0.0044, 0.0433, 0.0195, 0.0511, 0.0411, 0.0479, 0.0241, 0.1213,
        0.0859, 0.0285, 0.0332, 0.0486, 0.0772, 0.1430, 0.0570, 0.0985, 0.0681],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,964][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([0.0219, 0.0285, 0.0147, 0.0426, 0.0349, 0.1298, 0.1336, 0.0311, 0.0759,
        0.1011, 0.0446, 0.0935, 0.0504, 0.0058, 0.0094, 0.0562, 0.0758, 0.0504],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,967][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([7.8611e-05, 3.7904e-03, 7.1236e-02, 2.4630e-02, 6.2986e-02, 9.7543e-04,
        9.0228e-02, 3.4008e-04, 3.3839e-01, 1.2139e-01, 5.0638e-02, 6.3190e-02,
        1.7748e-02, 4.3999e-02, 8.0322e-02, 7.2890e-04, 3.5349e-03, 2.5791e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,971][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([0.0097, 0.0188, 0.0043, 0.1016, 0.0330, 0.0391, 0.1520, 0.0108, 0.2188,
        0.1027, 0.0491, 0.0890, 0.0137, 0.0443, 0.0078, 0.0201, 0.0661, 0.0190],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,972][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([0.0121, 0.0303, 0.0345, 0.0254, 0.0580, 0.0059, 0.0255, 0.0107, 0.1584,
        0.0903, 0.0592, 0.0390, 0.1437, 0.1055, 0.1049, 0.0174, 0.0223, 0.0567],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,973][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([2.0957e-04, 7.9769e-03, 4.1299e-02, 1.1261e-02, 2.6842e-02, 8.1634e-04,
        3.3969e-02, 3.3974e-04, 8.1051e-02, 1.7998e-01, 1.4804e-01, 2.2960e-01,
        1.6401e-02, 1.0585e-01, 6.2761e-02, 5.5075e-04, 2.3126e-03, 5.0739e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,973][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([1.6460e-02, 1.5983e-02, 1.3142e-04, 1.2855e-02, 2.7860e-03, 2.7662e-02,
        5.5180e-02, 1.9459e-02, 1.0326e-01, 5.8204e-02, 2.5385e-02, 3.4466e-02,
        1.9849e-02, 7.1891e-02, 1.1381e-03, 8.9413e-02, 4.3414e-01, 1.1737e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,975][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([8.8492e-05, 1.3114e-02, 1.2811e-02, 5.7234e-02, 3.8491e-02, 3.1465e-03,
        2.7385e-01, 9.7549e-04, 2.9681e-01, 4.0059e-02, 7.4209e-02, 5.9719e-02,
        1.7517e-02, 7.1299e-02, 1.3947e-02, 1.4665e-03, 8.5827e-03, 1.6674e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:36,978][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0985, 0.0012, 0.0039, 0.0012, 0.0018, 0.0485, 0.0084, 0.0400, 0.0506,
        0.0306, 0.0164, 0.0109, 0.0451, 0.0250, 0.0276, 0.1676, 0.1853, 0.0456,
        0.1918], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,980][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([3.3969e-04, 8.1261e-03, 2.4307e-02, 2.9007e-02, 6.1598e-02, 8.0730e-03,
        9.6454e-02, 2.0355e-03, 3.5906e-01, 1.1397e-01, 4.8052e-02, 4.8320e-02,
        2.8372e-02, 5.0409e-02, 2.3433e-02, 4.7683e-03, 1.4110e-02, 2.2187e-02,
        5.7372e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,984][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2059, 0.0021, 0.0059, 0.0026, 0.0017, 0.1406, 0.0119, 0.1392, 0.0316,
        0.0068, 0.0096, 0.0187, 0.0171, 0.0077, 0.0115, 0.2095, 0.1209, 0.0233,
        0.0334], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,987][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([6.7643e-01, 8.5349e-03, 5.0341e-05, 1.1752e-03, 1.2545e-04, 3.5184e-02,
        4.8362e-04, 1.3089e-01, 3.5513e-04, 3.1235e-03, 1.9948e-04, 3.8060e-04,
        4.4664e-04, 7.8300e-04, 2.1779e-05, 1.2648e-01, 1.4059e-02, 3.5794e-04,
        9.2098e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,989][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0186, 0.0036, 0.0161, 0.0082, 0.0339, 0.0547, 0.0199, 0.0403, 0.0687,
        0.0323, 0.0215, 0.0282, 0.0461, 0.0755, 0.0615, 0.1227, 0.2035, 0.0706,
        0.0741], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,990][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0694, 0.0401, 0.0085, 0.0221, 0.0221, 0.2037, 0.0572, 0.0595, 0.0377,
        0.0767, 0.0264, 0.0486, 0.0509, 0.0031, 0.0047, 0.1384, 0.0818, 0.0234,
        0.0256], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,991][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([9.9624e-05, 4.2452e-03, 8.7300e-02, 1.6596e-02, 4.0844e-02, 9.6091e-04,
        6.0606e-02, 3.7773e-04, 3.3415e-01, 7.4682e-02, 5.0333e-02, 5.9767e-02,
        1.4280e-02, 3.3927e-02, 8.0659e-02, 9.3469e-04, 4.1143e-03, 3.1476e-02,
        1.0464e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,993][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0837, 0.0214, 0.0021, 0.0710, 0.0140, 0.1370, 0.0907, 0.0498, 0.1437,
        0.0541, 0.0297, 0.0461, 0.0125, 0.0285, 0.0030, 0.0708, 0.1017, 0.0100,
        0.0300], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,995][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0894, 0.0326, 0.0358, 0.0149, 0.0668, 0.0190, 0.0119, 0.0410, 0.0836,
        0.0496, 0.0246, 0.0120, 0.1634, 0.0492, 0.0526, 0.0579, 0.0305, 0.0344,
        0.1309], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:36,999][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0003, 0.0064, 0.0496, 0.0089, 0.0181, 0.0012, 0.0436, 0.0004, 0.1237,
        0.1091, 0.1270, 0.1768, 0.0192, 0.0935, 0.0875, 0.0005, 0.0028, 0.0624,
        0.0690], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:37,002][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([6.5587e-02, 4.1555e-02, 2.1310e-04, 2.1616e-02, 4.2553e-03, 5.8449e-02,
        5.9615e-02, 4.7781e-02, 9.7266e-02, 4.0380e-02, 2.3973e-02, 2.4863e-02,
        1.4392e-02, 4.3865e-02, 5.8649e-04, 9.3710e-02, 2.8339e-01, 6.7456e-03,
        7.1761e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:37,006][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0034, 0.0300, 0.0179, 0.0945, 0.0391, 0.0247, 0.2263, 0.0182, 0.1841,
        0.0363, 0.0551, 0.0560, 0.0262, 0.0638, 0.0182, 0.0193, 0.0322, 0.0130,
        0.0416], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:37,115][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:37,119][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,122][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,125][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,126][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,126][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,127][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,128][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,129][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,132][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,135][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,138][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,141][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,143][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.8266, 0.1734], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,144][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0275, 0.9725], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,145][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9842, 0.0158], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,145][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9084, 0.0916], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,147][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2433, 0.7567], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,150][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3082, 0.6918], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,154][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0061, 0.9939], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,158][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3584, 0.6416], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,161][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.6803, 0.3197], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,161][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0128, 0.9872], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,162][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1488, 0.8512], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,163][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0291, 0.9709], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,164][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.9235, 0.0113, 0.0652], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,165][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0087, 0.2623, 0.7290], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,168][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.9932, 0.0012, 0.0056], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,172][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.8190, 0.1767, 0.0042], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,177][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.2279, 0.1141, 0.6580], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,179][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.3473, 0.4643, 0.1884], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,179][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.0019, 0.2699, 0.7282], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,180][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.1470, 0.7967, 0.0563], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,181][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.7317, 0.2018, 0.0664], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,183][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.0034, 0.2338, 0.7629], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,187][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0898, 0.8609, 0.0494], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,190][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.0156, 0.6099, 0.3745], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,194][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9514, 0.0083, 0.0279, 0.0125], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,196][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0031, 0.3553, 0.4333, 0.2083], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,197][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.9849, 0.0017, 0.0101, 0.0033], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,198][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([9.7277e-01, 2.3651e-02, 9.4774e-04, 2.6277e-03], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,198][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2048, 0.0840, 0.3598, 0.3513], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,200][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2745, 0.4065, 0.0881, 0.2309], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,203][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0007, 0.0806, 0.6593, 0.2593], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,207][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2964, 0.2497, 0.0568, 0.3971], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,212][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.6598, 0.2106, 0.0800, 0.0496], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,214][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0023, 0.2645, 0.4164, 0.3169], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,214][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2840, 0.5422, 0.0289, 0.1448], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,215][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0158, 0.4836, 0.3013, 0.1993], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,216][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.9774, 0.0045, 0.0105, 0.0040, 0.0036], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,218][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([0.0068, 0.0951, 0.2963, 0.1368, 0.4650], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,221][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([0.9878, 0.0015, 0.0072, 0.0020, 0.0015], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,223][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([9.1160e-01, 7.4708e-02, 7.2215e-04, 1.0088e-02, 2.8844e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,227][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([0.1554, 0.0746, 0.4543, 0.1514, 0.1642], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,231][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.2951, 0.2767, 0.0629, 0.1577, 0.2075], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,232][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.0019, 0.0784, 0.3021, 0.2551, 0.3625], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,233][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.2299, 0.2768, 0.0160, 0.4099, 0.0674], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,234][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.5166, 0.2050, 0.0484, 0.0610, 0.1690], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,235][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.0201, 0.1390, 0.3924, 0.1519, 0.2966], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,237][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.1651, 0.4533, 0.0067, 0.2121, 0.1628], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,239][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.0177, 0.3683, 0.1104, 0.2502, 0.2534], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,243][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.3207, 0.0282, 0.2346, 0.0619, 0.0688, 0.2858], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,246][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([5.6551e-06, 7.3733e-02, 1.4363e-01, 2.5229e-02, 7.5732e-01, 7.7708e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,250][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.5147, 0.0147, 0.0937, 0.0286, 0.0384, 0.3100], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,251][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.6966, 0.0704, 0.0094, 0.0226, 0.0186, 0.1825], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,252][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0020, 0.0379, 0.5215, 0.1202, 0.3107, 0.0077], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,252][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0400, 0.2700, 0.1105, 0.1486, 0.2814, 0.1495], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,254][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([2.0627e-06, 4.6769e-02, 4.3349e-01, 9.7950e-02, 4.2176e-01, 3.5925e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,256][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0212, 0.1384, 0.1196, 0.3454, 0.2917, 0.0838], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,261][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0539, 0.1724, 0.2351, 0.0780, 0.4434, 0.0172], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,263][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([2.5297e-06, 2.4382e-01, 3.5277e-01, 1.3122e-01, 2.7215e-01, 3.3051e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,267][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0054, 0.3441, 0.0385, 0.2559, 0.3247, 0.0313], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,268][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([3.0141e-05, 1.3672e-01, 1.7998e-01, 1.4981e-01, 5.3264e-01, 8.1596e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,269][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.6256, 0.0021, 0.0115, 0.0046, 0.0043, 0.3288, 0.0232],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,270][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0027, 0.0497, 0.1532, 0.1078, 0.3980, 0.0485, 0.2402],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,271][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([5.6931e-01, 5.0973e-04, 3.2302e-03, 1.3364e-03, 7.8993e-04, 4.1989e-01,
        4.9332e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,272][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([9.0313e-01, 7.3903e-03, 1.9074e-04, 1.2721e-03, 3.2864e-04, 8.7355e-02,
        3.3097e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,275][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.2180, 0.0180, 0.1039, 0.0399, 0.0794, 0.4620, 0.0789],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,279][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1637, 0.0853, 0.0237, 0.0547, 0.0628, 0.4725, 0.1374],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,281][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([2.5005e-04, 1.5354e-02, 3.2669e-01, 7.4103e-02, 1.9788e-01, 3.7460e-03,
        3.8198e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,285][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2120, 0.0594, 0.0070, 0.1541, 0.0315, 0.3899, 0.1462],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,286][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.4714, 0.1216, 0.0971, 0.0336, 0.1779, 0.0750, 0.0234],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,287][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0037, 0.0568, 0.2973, 0.0967, 0.1270, 0.0249, 0.3935],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,288][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1747, 0.2087, 0.0065, 0.0991, 0.0638, 0.2678, 0.1793],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,289][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0421, 0.2115, 0.1163, 0.1405, 0.1374, 0.0914, 0.2608],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,291][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0325, 0.0423, 0.2647, 0.0999, 0.1533, 0.0654, 0.3038, 0.0381],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,293][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([1.3246e-05, 8.6905e-02, 1.1234e-01, 2.4698e-02, 5.6673e-01, 8.2262e-05,
        2.0921e-01, 1.6961e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,297][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0740, 0.0507, 0.1764, 0.1083, 0.1494, 0.1172, 0.2212, 0.1027],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,301][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.1655, 0.1590, 0.0270, 0.1368, 0.0820, 0.1449, 0.1145, 0.1703],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,304][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0006, 0.0460, 0.3108, 0.1167, 0.2724, 0.0025, 0.2499, 0.0011],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,304][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0135, 0.1914, 0.1191, 0.1412, 0.2360, 0.0580, 0.2253, 0.0156],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,305][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([1.0956e-06, 3.8595e-02, 2.4848e-01, 5.2068e-02, 2.4926e-01, 1.2182e-05,
        4.1158e-01, 2.2711e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,306][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0036, 0.0751, 0.0920, 0.2281, 0.2598, 0.0247, 0.3064, 0.0103],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,308][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0193, 0.1618, 0.2416, 0.0911, 0.3364, 0.0109, 0.1220, 0.0168],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,310][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([2.5317e-07, 1.0170e-01, 1.3771e-01, 4.1171e-02, 1.3477e-01, 3.2350e-06,
        5.8465e-01, 3.1795e-07], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,314][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0005, 0.1410, 0.0270, 0.2235, 0.2337, 0.0063, 0.3665, 0.0016],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,317][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([1.3055e-05, 6.5985e-02, 1.1851e-01, 8.6564e-02, 3.2116e-01, 3.2888e-04,
        4.0734e-01, 9.2680e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,320][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.3179, 0.0049, 0.0234, 0.0077, 0.0092, 0.2415, 0.0348, 0.2004, 0.1603],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:37,322][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0026, 0.0291, 0.0481, 0.0598, 0.1527, 0.0312, 0.1783, 0.0122, 0.4861],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:37,323][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.3680, 0.0013, 0.0042, 0.0022, 0.0014, 0.2616, 0.0068, 0.3424, 0.0121],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:37,323][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([8.5841e-01, 3.1884e-03, 7.1503e-05, 3.7640e-04, 6.4079e-05, 2.5515e-02,
        1.1333e-04, 1.1222e-01, 4.7272e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:37,324][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0669, 0.0113, 0.0676, 0.0370, 0.1047, 0.2635, 0.0920, 0.1646, 0.1923],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:37,326][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.1780, 0.0684, 0.0159, 0.0338, 0.0413, 0.4022, 0.0775, 0.1292, 0.0537],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:37,328][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([2.3368e-04, 8.1815e-03, 1.5302e-01, 3.0728e-02, 8.9714e-02, 1.8122e-03,
        1.6278e-01, 8.6839e-04, 5.5266e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:37,332][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.2892, 0.0409, 0.0031, 0.0733, 0.0161, 0.2628, 0.0919, 0.1280, 0.0947],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:37,335][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.3758, 0.0855, 0.0950, 0.0234, 0.1403, 0.0471, 0.0157, 0.1403, 0.0769],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:37,339][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0014, 0.0263, 0.1457, 0.0419, 0.0873, 0.0066, 0.2267, 0.0027, 0.4615],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:37,340][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.2832, 0.1024, 0.0017, 0.0342, 0.0125, 0.1990, 0.0881, 0.1704, 0.1085],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:37,341][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0435, 0.1241, 0.0397, 0.1103, 0.0815, 0.0703, 0.2313, 0.1218, 0.1774],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:37,342][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0784, 0.0060, 0.0320, 0.0196, 0.0151, 0.1632, 0.1058, 0.0882, 0.3043,
        0.1874], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:37,343][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([2.2370e-04, 1.4391e-02, 3.7631e-02, 5.9145e-02, 1.4161e-01, 6.5892e-03,
        1.1377e-01, 1.6697e-03, 3.6465e-01, 2.6032e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:37,346][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.2370, 0.0023, 0.0063, 0.0060, 0.0037, 0.3011, 0.0338, 0.3422, 0.0423,
        0.0252], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:37,349][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([7.6705e-01, 1.7406e-02, 1.6107e-04, 2.6001e-03, 4.8350e-04, 6.0626e-02,
        1.1886e-03, 1.4450e-01, 1.2052e-03, 4.7814e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:37,353][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0041, 0.0058, 0.0622, 0.0499, 0.1419, 0.0595, 0.1615, 0.0209, 0.2257,
        0.2686], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:37,357][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0305, 0.0416, 0.0286, 0.0441, 0.0591, 0.2082, 0.1278, 0.0608, 0.1268,
        0.2727], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:37,357][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([4.5916e-05, 5.6614e-03, 7.5275e-02, 3.1122e-02, 5.4123e-02, 7.5582e-04,
        1.2301e-01, 2.6574e-04, 6.0593e-01, 1.0381e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:37,358][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0363, 0.0283, 0.0035, 0.1807, 0.0384, 0.1553, 0.1896, 0.0421, 0.2363,
        0.0896], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:37,359][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.2569, 0.0806, 0.0397, 0.0319, 0.0966, 0.0445, 0.0212, 0.1276, 0.1796,
        0.1214], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:37,360][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0007, 0.0133, 0.0668, 0.0383, 0.0449, 0.0044, 0.1148, 0.0014, 0.3190,
        0.3964], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:37,362][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0330, 0.1466, 0.0016, 0.0633, 0.0248, 0.0751, 0.1820, 0.0327, 0.3529,
        0.0881], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:37,366][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0097, 0.0696, 0.0435, 0.1009, 0.0954, 0.0299, 0.2984, 0.0287, 0.2480,
        0.0760], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:37,369][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.1771, 0.0042, 0.0140, 0.0058, 0.0060, 0.1851, 0.0310, 0.1438, 0.2319,
        0.1492, 0.0520], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:37,373][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0006, 0.0138, 0.0217, 0.0301, 0.0712, 0.0122, 0.1341, 0.0038, 0.5001,
        0.1285, 0.0838], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:37,375][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.2959, 0.0014, 0.0046, 0.0021, 0.0014, 0.3017, 0.0101, 0.3389, 0.0257,
        0.0117, 0.0064], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:37,376][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([8.1369e-01, 8.8682e-03, 6.2014e-05, 1.1028e-03, 1.4445e-04, 3.7574e-02,
        3.7488e-04, 1.3453e-01, 3.4888e-04, 3.0557e-03, 2.3952e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:37,377][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0617, 0.0080, 0.0329, 0.0285, 0.0851, 0.2124, 0.0849, 0.1537, 0.1541,
        0.1260, 0.0528], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:37,378][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0861, 0.0611, 0.0142, 0.0412, 0.0379, 0.3104, 0.0926, 0.0926, 0.0804,
        0.1205, 0.0630], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:37,381][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([1.0833e-04, 4.4623e-03, 5.4820e-02, 1.8704e-02, 3.9457e-02, 1.3372e-03,
        1.0327e-01, 5.5723e-04, 6.2072e-01, 8.6890e-02, 6.9671e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:37,384][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0848, 0.0281, 0.0023, 0.0960, 0.0248, 0.1836, 0.1173, 0.0674, 0.2372,
        0.1073, 0.0512], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:37,388][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.3955, 0.0694, 0.0364, 0.0204, 0.0875, 0.0492, 0.0108, 0.1440, 0.0832,
        0.0642, 0.0394], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:37,392][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0010, 0.0146, 0.0524, 0.0214, 0.0302, 0.0058, 0.0874, 0.0019, 0.3199,
        0.2080, 0.2575], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:37,393][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0813, 0.1228, 0.0013, 0.0546, 0.0199, 0.0826, 0.1361, 0.0569, 0.2665,
        0.1136, 0.0645], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:37,394][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0080, 0.0503, 0.0352, 0.1459, 0.0660, 0.0468, 0.2857, 0.0428, 0.2007,
        0.0440, 0.0745], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:37,395][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1645, 0.0049, 0.0199, 0.0077, 0.0099, 0.1906, 0.0427, 0.1221, 0.2122,
        0.1364, 0.0518, 0.0374], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:37,397][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0012, 0.0222, 0.0460, 0.0383, 0.1071, 0.0163, 0.0963, 0.0055, 0.3253,
        0.1875, 0.0816, 0.0728], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:37,399][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1803, 0.0024, 0.0093, 0.0052, 0.0036, 0.3704, 0.0307, 0.2531, 0.0648,
        0.0293, 0.0167, 0.0342], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:37,402][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([8.0326e-01, 1.5863e-02, 1.1880e-04, 3.9272e-03, 3.6368e-04, 4.9342e-02,
        1.2206e-03, 1.1789e-01, 1.5320e-03, 5.0740e-03, 7.0057e-04, 7.0755e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:37,406][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0470, 0.0089, 0.0473, 0.0250, 0.0951, 0.1578, 0.0789, 0.1185, 0.1511,
        0.1278, 0.0882, 0.0545], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:37,410][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0539, 0.0472, 0.0155, 0.0404, 0.0459, 0.2175, 0.1040, 0.0568, 0.0996,
        0.1322, 0.0696, 0.1175], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:37,411][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([6.0267e-05, 5.8145e-03, 7.5863e-02, 2.2741e-02, 4.5580e-02, 1.0386e-03,
        1.0420e-01, 3.3094e-04, 5.2508e-01, 9.9890e-02, 6.4557e-02, 5.4845e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:37,411][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1040, 0.0283, 0.0023, 0.1197, 0.0184, 0.1493, 0.0994, 0.0680, 0.2060,
        0.1012, 0.0463, 0.0571], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:37,412][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.2452, 0.0996, 0.0625, 0.0282, 0.1113, 0.0387, 0.0187, 0.0945, 0.1214,
        0.0938, 0.0650, 0.0210], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:37,414][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0004, 0.0118, 0.0668, 0.0175, 0.0287, 0.0029, 0.0749, 0.0008, 0.2016,
        0.2068, 0.1866, 0.2012], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:37,417][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0545, 0.0894, 0.0006, 0.0648, 0.0161, 0.0595, 0.1301, 0.0409, 0.3288,
        0.0821, 0.0843, 0.0486], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:37,421][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0057, 0.0522, 0.0363, 0.1247, 0.0623, 0.0398, 0.2867, 0.0299, 0.1913,
        0.0444, 0.0702, 0.0563], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:37,425][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.1649, 0.0038, 0.0193, 0.0087, 0.0068, 0.1002, 0.0573, 0.0988, 0.1653,
        0.1134, 0.0501, 0.0530, 0.1584], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:37,428][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([2.5801e-05, 8.1311e-03, 3.4980e-02, 2.3558e-02, 1.3310e-01, 7.8962e-04,
        1.0022e-01, 1.3154e-04, 4.1464e-01, 1.3862e-01, 5.7222e-02, 6.7958e-02,
        2.0621e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:37,428][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.2883, 0.0033, 0.0107, 0.0071, 0.0051, 0.2179, 0.0204, 0.2907, 0.0353,
        0.0283, 0.0189, 0.0330, 0.0409], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:37,429][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([6.4259e-01, 3.0400e-02, 1.1439e-04, 8.7309e-03, 8.8310e-04, 4.9405e-02,
        5.0001e-03, 1.9657e-01, 6.9148e-03, 3.1911e-02, 5.2755e-03, 1.5370e-02,
        6.8337e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:37,430][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0037, 0.0071, 0.0870, 0.0330, 0.0794, 0.0252, 0.0919, 0.0126, 0.1688,
        0.1480, 0.0879, 0.1359, 0.1194], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:37,432][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.0226, 0.0557, 0.0186, 0.0433, 0.0536, 0.1115, 0.1223, 0.0320, 0.0849,
        0.1327, 0.0732, 0.1466, 0.1031], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:37,434][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([1.8135e-05, 4.3340e-03, 4.3914e-02, 1.8814e-02, 3.6214e-02, 1.9762e-04,
        9.3820e-02, 6.8652e-05, 5.1730e-01, 8.1334e-02, 8.2513e-02, 1.1518e-01,
        6.2941e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:37,438][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0078, 0.0138, 0.0029, 0.0897, 0.0250, 0.0434, 0.1718, 0.0122, 0.2993,
        0.1188, 0.0710, 0.1209, 0.0234], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:37,442][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.0886, 0.0450, 0.0269, 0.0296, 0.0852, 0.0237, 0.0273, 0.0568, 0.1951,
        0.1062, 0.0637, 0.0283, 0.2236], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:37,444][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([4.4731e-05, 4.8970e-03, 2.7179e-02, 1.3844e-02, 1.8505e-02, 2.8684e-04,
        5.3702e-02, 8.3438e-05, 2.2543e-01, 1.6942e-01, 1.6571e-01, 3.0778e-01,
        1.3114e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:37,446][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([1.1553e-02, 5.0159e-02, 2.0264e-04, 4.0295e-02, 9.7724e-03, 1.8293e-02,
        1.1117e-01, 1.4353e-02, 3.0876e-01, 1.2327e-01, 1.2065e-01, 1.3372e-01,
        5.7807e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:37,446][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([2.2658e-04, 3.7617e-02, 2.0837e-02, 8.2532e-02, 5.9404e-02, 3.3914e-03,
        2.7119e-01, 1.8367e-03, 2.1509e-01, 7.8467e-02, 9.6450e-02, 8.9738e-02,
        4.3225e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:37,447][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.1317, 0.0040, 0.0142, 0.0044, 0.0073, 0.0936, 0.0383, 0.0844, 0.1836,
        0.1247, 0.0474, 0.0314, 0.1389, 0.0959], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:37,449][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0013, 0.0120, 0.0282, 0.0268, 0.0953, 0.0178, 0.1098, 0.0067, 0.3461,
        0.1507, 0.0573, 0.0495, 0.0509, 0.0476], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:37,453][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.2640, 0.0022, 0.0070, 0.0032, 0.0034, 0.2963, 0.0168, 0.2557, 0.0396,
        0.0185, 0.0128, 0.0230, 0.0459, 0.0115], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:37,456][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([8.0447e-01, 1.5849e-02, 5.1096e-05, 3.3652e-03, 1.8864e-04, 3.2121e-02,
        9.4286e-04, 1.2992e-01, 1.0193e-03, 7.8394e-03, 5.6309e-04, 1.3047e-03,
        7.3373e-04, 1.6367e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:37,459][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0200, 0.0067, 0.0373, 0.0223, 0.0809, 0.0976, 0.0723, 0.0535, 0.1530,
        0.0913, 0.0510, 0.0543, 0.1028, 0.1570], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:37,463][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0609, 0.0597, 0.0122, 0.0357, 0.0297, 0.2419, 0.0949, 0.0694, 0.0714,
        0.1243, 0.0488, 0.0821, 0.0640, 0.0049], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:37,465][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([1.0056e-04, 7.0519e-03, 7.9565e-02, 1.8915e-02, 6.8287e-02, 8.6395e-04,
        8.4099e-02, 3.5072e-04, 4.2862e-01, 1.1392e-01, 5.9122e-02, 7.6796e-02,
        1.5527e-02, 4.6789e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:37,466][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0209, 0.0188, 0.0025, 0.1136, 0.0263, 0.0787, 0.1556, 0.0198, 0.2740,
        0.0908, 0.0549, 0.0874, 0.0164, 0.0403], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:37,467][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.1559, 0.0444, 0.0473, 0.0145, 0.0967, 0.0270, 0.0137, 0.0650, 0.1024,
        0.0826, 0.0427, 0.0136, 0.2304, 0.0638], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:37,468][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0006, 0.0130, 0.0432, 0.0165, 0.0212, 0.0024, 0.0586, 0.0009, 0.1712,
        0.1481, 0.1566, 0.1937, 0.0337, 0.1403], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:37,470][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1253, 0.0894, 0.0003, 0.0346, 0.0085, 0.0737, 0.1163, 0.0706, 0.1923,
        0.0854, 0.0537, 0.0545, 0.0192, 0.0762], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:37,474][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0138, 0.0861, 0.0254, 0.0942, 0.0676, 0.0353, 0.2665, 0.0543, 0.1402,
        0.0559, 0.0464, 0.0439, 0.0304, 0.0400], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:37,477][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.0937, 0.0028, 0.0267, 0.0041, 0.0097, 0.1178, 0.0252, 0.0653, 0.1217,
        0.1576, 0.0263, 0.0231, 0.1194, 0.0503, 0.1564], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:37,481][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0006, 0.0108, 0.0222, 0.0395, 0.0828, 0.0136, 0.1015, 0.0036, 0.3767,
        0.1207, 0.0598, 0.0606, 0.0326, 0.0541, 0.0208], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:37,483][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.2576, 0.0023, 0.0141, 0.0036, 0.0036, 0.2270, 0.0190, 0.2890, 0.0403,
        0.0284, 0.0103, 0.0204, 0.0392, 0.0121, 0.0331], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:37,484][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([4.3300e-01, 2.6500e-02, 9.3382e-05, 7.7989e-03, 1.4246e-03, 7.9578e-02,
        5.6836e-03, 2.1915e-01, 1.1054e-02, 9.0686e-02, 6.8053e-03, 2.2581e-02,
        3.0557e-02, 6.3098e-02, 1.9847e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:37,485][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.0203, 0.0069, 0.0507, 0.0289, 0.0579, 0.0882, 0.0773, 0.0605, 0.1161,
        0.1588, 0.0351, 0.0376, 0.0604, 0.0848, 0.1165], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:37,486][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.0466, 0.0443, 0.0152, 0.0353, 0.0520, 0.1952, 0.0863, 0.0689, 0.0778,
        0.1534, 0.0435, 0.0848, 0.0797, 0.0051, 0.0119], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:37,487][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([9.9547e-05, 6.9846e-03, 5.2357e-02, 1.9009e-02, 3.5615e-02, 1.2501e-03,
        6.4976e-02, 4.3070e-04, 4.1322e-01, 1.1501e-01, 6.6419e-02, 6.6597e-02,
        2.1482e-02, 5.7406e-02, 7.9145e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:37,490][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.0315, 0.0335, 0.0030, 0.1022, 0.0228, 0.0695, 0.1313, 0.0354, 0.2132,
        0.1014, 0.0606, 0.1000, 0.0168, 0.0714, 0.0073], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:37,494][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.0798, 0.0317, 0.0281, 0.0157, 0.0451, 0.0190, 0.0195, 0.0524, 0.1185,
        0.1145, 0.0410, 0.0322, 0.1890, 0.0911, 0.1226], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:37,499][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.0002, 0.0087, 0.0354, 0.0119, 0.0172, 0.0013, 0.0407, 0.0004, 0.1098,
        0.1419, 0.1609, 0.1990, 0.0361, 0.1267, 0.1098], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:37,501][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([1.4162e-02, 2.0736e-02, 1.3091e-04, 2.0053e-02, 6.0972e-03, 3.5880e-02,
        6.4543e-02, 3.1549e-02, 1.7261e-01, 1.1330e-01, 6.3287e-02, 1.1274e-01,
        1.0856e-01, 2.3279e-01, 3.5708e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:37,502][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.0045, 0.0849, 0.0375, 0.0790, 0.0626, 0.0226, 0.2213, 0.0194, 0.1781,
        0.0662, 0.0517, 0.0478, 0.0434, 0.0505, 0.0303], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:37,503][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0184, 0.0073, 0.0587, 0.0104, 0.0304, 0.0187, 0.0493, 0.0135, 0.0988,
        0.1334, 0.0682, 0.0514, 0.1246, 0.0818, 0.2050, 0.0299],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:37,503][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([1.3501e-06, 1.4686e-02, 3.5896e-02, 9.9863e-03, 1.4874e-01, 2.1450e-05,
        1.0199e-01, 2.7779e-06, 3.0051e-01, 7.5626e-02, 1.0257e-01, 8.8603e-02,
        1.2755e-02, 8.7793e-02, 2.0800e-02, 1.1702e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:37,505][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0565, 0.0180, 0.0465, 0.0237, 0.0373, 0.0562, 0.0516, 0.0520, 0.0846,
        0.0676, 0.0723, 0.1006, 0.0672, 0.0706, 0.1271, 0.0684],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:37,508][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1683, 0.0603, 0.0025, 0.0401, 0.0105, 0.0704, 0.0260, 0.1076, 0.0299,
        0.0719, 0.0221, 0.0409, 0.0212, 0.0648, 0.0123, 0.2514],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:37,512][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0002, 0.0102, 0.0913, 0.0200, 0.1207, 0.0008, 0.0666, 0.0004, 0.0718,
        0.0947, 0.0979, 0.1143, 0.0516, 0.1378, 0.1204, 0.0012],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:37,516][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0091, 0.1122, 0.0504, 0.0705, 0.1334, 0.0414, 0.1359, 0.0092, 0.0576,
        0.0884, 0.0751, 0.1058, 0.0697, 0.0059, 0.0139, 0.0217],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:37,519][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([1.2717e-07, 5.8013e-03, 4.3319e-02, 9.0013e-03, 4.1256e-02, 2.0187e-06,
        8.3090e-02, 3.0766e-07, 3.2537e-01, 6.1524e-02, 1.3303e-01, 1.1855e-01,
        1.8569e-03, 6.8829e-02, 1.0836e-01, 9.4969e-07], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:37,520][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0020, 0.0260, 0.0191, 0.0935, 0.0714, 0.0108, 0.1163, 0.0041, 0.1623,
        0.1362, 0.0838, 0.1027, 0.0396, 0.0885, 0.0356, 0.0081],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:37,521][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0085, 0.0327, 0.0760, 0.0208, 0.1004, 0.0040, 0.0303, 0.0065, 0.1200,
        0.0915, 0.0733, 0.0374, 0.0952, 0.0979, 0.1950, 0.0107],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:37,521][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([1.7678e-08, 4.5914e-03, 8.5270e-03, 2.4755e-03, 6.6979e-03, 2.2223e-07,
        3.7428e-02, 2.1835e-08, 2.5253e-01, 6.4188e-02, 1.5089e-01, 2.7853e-01,
        1.1285e-03, 1.1121e-01, 8.1802e-02, 3.7716e-08], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:37,524][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0004, 0.0383, 0.0015, 0.0588, 0.0273, 0.0025, 0.0969, 0.0009, 0.3195,
        0.0788, 0.1045, 0.0989, 0.0253, 0.1350, 0.0080, 0.0036],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:37,525][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([1.1988e-06, 7.6845e-03, 1.4505e-02, 2.2513e-02, 4.3425e-02, 7.1189e-05,
        1.6258e-01, 1.3760e-05, 2.5201e-01, 3.3442e-02, 1.1715e-01, 9.6322e-02,
        1.7442e-02, 1.8679e-01, 4.6010e-02, 4.3237e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:37,530][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0599, 0.0021, 0.0187, 0.0036, 0.0090, 0.0474, 0.0226, 0.0361, 0.0906,
        0.0869, 0.0328, 0.0223, 0.0924, 0.0404, 0.1130, 0.1219, 0.2003],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:37,532][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.0035e-05, 7.0958e-03, 2.9087e-02, 1.4779e-02, 9.5601e-02, 2.7543e-04,
        9.2307e-02, 4.3991e-05, 4.1780e-01, 1.0431e-01, 6.1763e-02, 6.0123e-02,
        2.3556e-02, 6.7907e-02, 2.3530e-02, 1.4970e-04, 1.6716e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:37,536][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1342, 0.0031, 0.0116, 0.0061, 0.0058, 0.1318, 0.0223, 0.1289, 0.0422,
        0.0232, 0.0218, 0.0338, 0.0289, 0.0181, 0.0358, 0.1845, 0.1680],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:37,537][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([4.1996e-01, 2.4532e-02, 2.4703e-04, 9.5005e-03, 8.2294e-04, 6.9649e-02,
        2.5821e-03, 1.5800e-01, 2.7154e-03, 1.4535e-02, 1.6209e-03, 2.4967e-03,
        2.1514e-03, 5.7284e-03, 3.1601e-04, 2.3421e-01, 5.0939e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:37,538][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0025, 0.0054, 0.0464, 0.0109, 0.0765, 0.0093, 0.0454, 0.0054, 0.0869,
        0.0646, 0.0730, 0.0803, 0.0938, 0.1551, 0.1242, 0.0211, 0.0992],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:37,539][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0242, 0.0703, 0.0190, 0.0517, 0.0546, 0.1097, 0.1169, 0.0269, 0.0674,
        0.1009, 0.0625, 0.0991, 0.0646, 0.0045, 0.0089, 0.0583, 0.0606],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:37,540][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.6543e-06, 2.9740e-03, 5.3164e-02, 9.5525e-03, 3.9468e-02, 2.2782e-05,
        5.8498e-02, 5.5516e-06, 4.1545e-01, 8.6501e-02, 9.0889e-02, 8.9250e-02,
        4.0150e-03, 4.6915e-02, 1.0282e-01, 1.6863e-05, 4.4951e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:37,543][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0177, 0.0262, 0.0059, 0.1089, 0.0374, 0.0568, 0.1058, 0.0204, 0.1866,
        0.1078, 0.0545, 0.0701, 0.0223, 0.0524, 0.0096, 0.0360, 0.0815],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:37,547][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0551, 0.0294, 0.0713, 0.0146, 0.0885, 0.0123, 0.0143, 0.0279, 0.0855,
        0.0843, 0.0419, 0.0181, 0.1603, 0.0683, 0.1527, 0.0445, 0.0309],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:37,549][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([6.2450e-07, 3.0466e-03, 1.2265e-02, 3.2431e-03, 7.4861e-03, 5.5124e-06,
        3.4355e-02, 9.4319e-07, 2.4052e-01, 1.0731e-01, 1.5471e-01, 2.5582e-01,
        4.1657e-03, 1.0554e-01, 7.1436e-02, 1.6088e-06, 8.2370e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:37,553][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0037, 0.0505, 0.0007, 0.0651, 0.0161, 0.0117, 0.1112, 0.0049, 0.3009,
        0.0728, 0.0672, 0.0558, 0.0168, 0.0939, 0.0019, 0.0147, 0.1121],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:37,555][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([5.8689e-05, 1.7511e-02, 2.5248e-02, 5.4722e-02, 4.9617e-02, 1.4195e-03,
        1.9680e-01, 5.4204e-04, 2.7280e-01, 4.1007e-02, 8.8021e-02, 7.6371e-02,
        2.3840e-02, 1.1211e-01, 3.3079e-02, 8.7846e-04, 5.9773e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:37,555][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([0.0424, 0.0019, 0.0225, 0.0029, 0.0076, 0.0487, 0.0262, 0.0276, 0.0920,
        0.0592, 0.0222, 0.0157, 0.0771, 0.0507, 0.1039, 0.1063, 0.1848, 0.1081],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:37,556][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([0.0006, 0.0073, 0.0193, 0.0277, 0.0791, 0.0126, 0.0947, 0.0030, 0.3231,
        0.1716, 0.0466, 0.0604, 0.0346, 0.0436, 0.0219, 0.0081, 0.0177, 0.0282],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:37,557][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([0.1576, 0.0033, 0.0177, 0.0061, 0.0047, 0.1429, 0.0165, 0.1458, 0.0301,
        0.0143, 0.0103, 0.0252, 0.0281, 0.0109, 0.0297, 0.1729, 0.1306, 0.0533],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:37,559][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([3.4884e-01, 2.1871e-02, 9.7883e-05, 3.5588e-03, 6.6525e-04, 4.5231e-02,
        4.0446e-03, 1.1110e-01, 6.7184e-03, 2.6906e-02, 1.8946e-03, 4.8583e-03,
        4.1985e-03, 1.1276e-02, 1.6805e-04, 3.0536e-01, 1.0059e-01, 2.6185e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:37,562][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([0.0073, 0.0044, 0.0433, 0.0195, 0.0511, 0.0411, 0.0479, 0.0241, 0.1213,
        0.0859, 0.0285, 0.0332, 0.0486, 0.0772, 0.1430, 0.0570, 0.0985, 0.0681],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:37,566][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([0.0219, 0.0285, 0.0147, 0.0426, 0.0349, 0.1298, 0.1336, 0.0311, 0.0759,
        0.1011, 0.0446, 0.0935, 0.0504, 0.0058, 0.0094, 0.0562, 0.0758, 0.0504],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:37,568][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([7.8611e-05, 3.7904e-03, 7.1236e-02, 2.4630e-02, 6.2986e-02, 9.7543e-04,
        9.0228e-02, 3.4008e-04, 3.3839e-01, 1.2139e-01, 5.0638e-02, 6.3190e-02,
        1.7748e-02, 4.3999e-02, 8.0322e-02, 7.2890e-04, 3.5349e-03, 2.5791e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:37,572][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([0.0097, 0.0188, 0.0043, 0.1016, 0.0330, 0.0391, 0.1520, 0.0108, 0.2188,
        0.1027, 0.0491, 0.0890, 0.0137, 0.0443, 0.0078, 0.0201, 0.0661, 0.0190],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:37,573][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([0.0121, 0.0303, 0.0345, 0.0254, 0.0580, 0.0059, 0.0255, 0.0107, 0.1584,
        0.0903, 0.0592, 0.0390, 0.1437, 0.1055, 0.1049, 0.0174, 0.0223, 0.0567],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:37,574][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([2.0957e-04, 7.9769e-03, 4.1299e-02, 1.1261e-02, 2.6842e-02, 8.1634e-04,
        3.3969e-02, 3.3974e-04, 8.1051e-02, 1.7998e-01, 1.4804e-01, 2.2960e-01,
        1.6401e-02, 1.0585e-01, 6.2761e-02, 5.5075e-04, 2.3126e-03, 5.0739e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:37,575][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([1.6460e-02, 1.5983e-02, 1.3142e-04, 1.2855e-02, 2.7860e-03, 2.7662e-02,
        5.5180e-02, 1.9459e-02, 1.0326e-01, 5.8204e-02, 2.5385e-02, 3.4466e-02,
        1.9849e-02, 7.1891e-02, 1.1381e-03, 8.9413e-02, 4.3414e-01, 1.1737e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:37,576][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([8.8492e-05, 1.3114e-02, 1.2811e-02, 5.7234e-02, 3.8491e-02, 3.1465e-03,
        2.7385e-01, 9.7549e-04, 2.9681e-01, 4.0059e-02, 7.4209e-02, 5.9719e-02,
        1.7517e-02, 7.1299e-02, 1.3947e-02, 1.4665e-03, 8.5827e-03, 1.6674e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:37,579][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0985, 0.0012, 0.0039, 0.0012, 0.0018, 0.0485, 0.0084, 0.0400, 0.0506,
        0.0306, 0.0164, 0.0109, 0.0451, 0.0250, 0.0276, 0.1676, 0.1853, 0.0456,
        0.1918], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:37,581][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([3.3969e-04, 8.1261e-03, 2.4307e-02, 2.9007e-02, 6.1598e-02, 8.0730e-03,
        9.6454e-02, 2.0355e-03, 3.5906e-01, 1.1397e-01, 4.8052e-02, 4.8320e-02,
        2.8372e-02, 5.0409e-02, 2.3433e-02, 4.7683e-03, 1.4110e-02, 2.2187e-02,
        5.7372e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:37,586][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2059, 0.0021, 0.0059, 0.0026, 0.0017, 0.1406, 0.0119, 0.1392, 0.0316,
        0.0068, 0.0096, 0.0187, 0.0171, 0.0077, 0.0115, 0.2095, 0.1209, 0.0233,
        0.0334], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:37,588][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([6.7643e-01, 8.5349e-03, 5.0341e-05, 1.1752e-03, 1.2545e-04, 3.5184e-02,
        4.8362e-04, 1.3089e-01, 3.5513e-04, 3.1235e-03, 1.9948e-04, 3.8060e-04,
        4.4664e-04, 7.8300e-04, 2.1779e-05, 1.2648e-01, 1.4059e-02, 3.5794e-04,
        9.2098e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:37,590][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0186, 0.0036, 0.0161, 0.0082, 0.0339, 0.0547, 0.0199, 0.0403, 0.0687,
        0.0323, 0.0215, 0.0282, 0.0461, 0.0755, 0.0615, 0.1227, 0.2035, 0.0706,
        0.0741], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:37,591][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0694, 0.0401, 0.0085, 0.0221, 0.0221, 0.2037, 0.0572, 0.0595, 0.0377,
        0.0767, 0.0264, 0.0486, 0.0509, 0.0031, 0.0047, 0.1384, 0.0818, 0.0234,
        0.0256], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:37,592][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.9624e-05, 4.2452e-03, 8.7300e-02, 1.6596e-02, 4.0844e-02, 9.6091e-04,
        6.0606e-02, 3.7773e-04, 3.3415e-01, 7.4682e-02, 5.0333e-02, 5.9767e-02,
        1.4280e-02, 3.3927e-02, 8.0659e-02, 9.3469e-04, 4.1143e-03, 3.1476e-02,
        1.0464e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:37,593][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0837, 0.0214, 0.0021, 0.0710, 0.0140, 0.1370, 0.0907, 0.0498, 0.1437,
        0.0541, 0.0297, 0.0461, 0.0125, 0.0285, 0.0030, 0.0708, 0.1017, 0.0100,
        0.0300], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:37,596][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0894, 0.0326, 0.0358, 0.0149, 0.0668, 0.0190, 0.0119, 0.0410, 0.0836,
        0.0496, 0.0246, 0.0120, 0.1634, 0.0492, 0.0526, 0.0579, 0.0305, 0.0344,
        0.1309], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:37,600][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0003, 0.0064, 0.0496, 0.0089, 0.0181, 0.0012, 0.0436, 0.0004, 0.1237,
        0.1091, 0.1270, 0.1768, 0.0192, 0.0935, 0.0875, 0.0005, 0.0028, 0.0624,
        0.0690], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:37,603][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([6.5587e-02, 4.1555e-02, 2.1310e-04, 2.1616e-02, 4.2553e-03, 5.8449e-02,
        5.9615e-02, 4.7781e-02, 9.7266e-02, 4.0380e-02, 2.3973e-02, 2.4863e-02,
        1.4392e-02, 4.3865e-02, 5.8649e-04, 9.3710e-02, 2.8339e-01, 6.7456e-03,
        7.1761e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:37,606][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0034, 0.0300, 0.0179, 0.0945, 0.0391, 0.0247, 0.2263, 0.0182, 0.1841,
        0.0363, 0.0551, 0.0560, 0.0262, 0.0638, 0.0182, 0.0193, 0.0322, 0.0130,
        0.0416], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:37,610][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:37,611][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[3277],
        [   2],
        [   9],
        [  10],
        [ 546],
        [  23],
        [   9],
        [   9],
        [   2],
        [   1],
        [   2],
        [   4],
        [   6],
        [   2],
        [   4],
        [   2],
        [   3],
        [   7],
        [   2]], device='cuda:0')
[2024-07-24 10:27:37,613][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[2686],
        [   2],
        [   6],
        [   3],
        [ 137],
        [   5],
        [   1],
        [   2],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1]], device='cuda:0')
[2024-07-24 10:27:37,616][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[10037],
        [ 1766],
        [ 3919],
        [ 4896],
        [ 7882],
        [ 3885],
        [ 2900],
        [ 5527],
        [ 3366],
        [ 4985],
        [ 4603],
        [ 4687],
        [ 4313],
        [ 4629],
        [ 4763],
        [ 5319],
        [ 5169],
        [ 5559],
        [ 5736]], device='cuda:0')
[2024-07-24 10:27:37,618][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 3719],
        [ 9825],
        [19473],
        [14402],
        [22740],
        [26746],
        [22291],
        [25083],
        [23364],
        [21816],
        [23416],
        [23044],
        [23809],
        [22596],
        [23142],
        [25029],
        [24263],
        [22794],
        [23372]], device='cuda:0')
[2024-07-24 10:27:37,621][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 4444],
        [ 4699],
        [ 4527],
        [ 4636],
        [ 4691],
        [30633],
        [30498],
        [36460],
        [27057],
        [31896],
        [29912],
        [35728],
        [31707],
        [32882],
        [33256],
        [39683],
        [32348],
        [32608],
        [30634]], device='cuda:0')
[2024-07-24 10:27:37,624][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[19963],
        [24890],
        [30110],
        [21502],
        [25319],
        [40012],
        [26869],
        [48547],
        [27755],
        [33685],
        [30632],
        [31945],
        [42245],
        [31912],
        [47531],
        [48539],
        [45890],
        [47088],
        [38640]], device='cuda:0')
[2024-07-24 10:27:37,627][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 8517],
        [18998],
        [ 9591],
        [24307],
        [17225],
        [17191],
        [41288],
        [30032],
        [44212],
        [43767],
        [44432],
        [43340],
        [40691],
        [41109],
        [39804],
        [35091],
        [35797],
        [38931],
        [38611]], device='cuda:0')
[2024-07-24 10:27:37,629][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[36020],
        [41254],
        [32947],
        [33668],
        [22746],
        [17881],
        [12946],
        [12411],
        [13663],
        [ 8495],
        [10266],
        [ 7507],
        [ 7067],
        [ 8786],
        [ 8131],
        [ 8092],
        [ 7677],
        [ 6857],
        [ 8686]], device='cuda:0')
[2024-07-24 10:27:37,631][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[23060],
        [39656],
        [29131],
        [28551],
        [49401],
        [49753],
        [43561],
        [46048],
        [34471],
        [28257],
        [25912],
        [26309],
        [24908],
        [27970],
        [24067],
        [24955],
        [24921],
        [27127],
        [24932]], device='cuda:0')
[2024-07-24 10:27:37,632][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 3805],
        [40653],
        [43075],
        [46677],
        [45099],
        [39942],
        [43336],
        [42027],
        [42844],
        [46168],
        [45881],
        [46348],
        [47050],
        [46779],
        [46844],
        [46559],
        [46738],
        [46924],
        [46245]], device='cuda:0')
[2024-07-24 10:27:37,634][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 7234],
        [32617],
        [43281],
        [47099],
        [50241],
        [50255],
        [50247],
        [50252],
        [50229],
        [50188],
        [50189],
        [50196],
        [50138],
        [50160],
        [50103],
        [50167],
        [50166],
        [50102],
        [50093]], device='cuda:0')
[2024-07-24 10:27:37,636][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[41925],
        [19494],
        [43015],
        [37308],
        [50215],
        [50184],
        [48807],
        [48593],
        [45270],
        [41977],
        [38839],
        [36939],
        [33319],
        [36469],
        [38363],
        [31728],
        [32450],
        [38369],
        [38146]], device='cuda:0')
[2024-07-24 10:27:37,639][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[46706],
        [28969],
        [28322],
        [32884],
        [35392],
        [36848],
        [43500],
        [40966],
        [46286],
        [42183],
        [42478],
        [42691],
        [42140],
        [43369],
        [42845],
        [42438],
        [43112],
        [45598],
        [45774]], device='cuda:0')
[2024-07-24 10:27:37,642][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[16858],
        [17787],
        [21540],
        [16485],
        [28931],
        [39265],
        [22915],
        [33496],
        [15117],
        [14242],
        [13157],
        [12860],
        [12021],
        [13638],
        [12971],
        [12725],
        [12371],
        [11599],
        [11375]], device='cuda:0')
[2024-07-24 10:27:37,645][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[26324],
        [ 8591],
        [ 4376],
        [ 9621],
        [10624],
        [16429],
        [ 8727],
        [22821],
        [10782],
        [ 5725],
        [ 9130],
        [ 3471],
        [14128],
        [ 8588],
        [ 3568],
        [ 9440],
        [ 8740],
        [ 6474],
        [ 8202]], device='cuda:0')
[2024-07-24 10:27:37,647][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[45232],
        [32140],
        [41662],
        [43294],
        [44637],
        [23269],
        [14075],
        [22349],
        [16083],
        [18761],
        [18583],
        [18407],
        [17949],
        [20036],
        [21908],
        [23248],
        [20751],
        [23949],
        [22850]], device='cuda:0')
[2024-07-24 10:27:37,650][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[34878],
        [30997],
        [36994],
        [36444],
        [37294],
        [41526],
        [40123],
        [41283],
        [37005],
        [38897],
        [36525],
        [38028],
        [37329],
        [37202],
        [36854],
        [36664],
        [36318],
        [37458],
        [36558]], device='cuda:0')
[2024-07-24 10:27:37,651][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[25003],
        [24490],
        [24105],
        [22930],
        [23445],
        [ 4377],
        [ 8057],
        [ 2531],
        [ 5368],
        [ 4933],
        [ 5228],
        [ 4910],
        [ 4498],
        [ 4887],
        [ 4346],
        [ 4351],
        [ 6199],
        [ 6270],
        [ 7619]], device='cuda:0')
[2024-07-24 10:27:37,653][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 5355],
        [ 5200],
        [ 6106],
        [ 5196],
        [ 5049],
        [ 4989],
        [ 3769],
        [28327],
        [ 2884],
        [ 2424],
        [ 2519],
        [ 2613],
        [ 2954],
        [ 2485],
        [ 7526],
        [17218],
        [ 3156],
        [ 4249],
        [ 1533]], device='cuda:0')
[2024-07-24 10:27:37,655][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 5647],
        [18922],
        [31580],
        [22808],
        [24668],
        [23771],
        [18477],
        [21486],
        [13485],
        [16110],
        [14447],
        [14146],
        [13902],
        [12230],
        [16434],
        [16438],
        [15391],
        [16263],
        [14623]], device='cuda:0')
[2024-07-24 10:27:37,657][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 5869],
        [12117],
        [16996],
        [17061],
        [16408],
        [15991],
        [ 9143],
        [18109],
        [ 7726],
        [10574],
        [ 8557],
        [10583],
        [12563],
        [ 9834],
        [10594],
        [14096],
        [11277],
        [11234],
        [ 7831]], device='cuda:0')
[2024-07-24 10:27:37,660][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 6092],
        [27619],
        [16111],
        [17821],
        [16361],
        [13255],
        [23444],
        [24291],
        [25022],
        [25424],
        [25992],
        [26682],
        [28145],
        [26479],
        [27296],
        [29434],
        [28158],
        [27215],
        [27817]], device='cuda:0')
[2024-07-24 10:27:37,663][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 1040],
        [29678],
        [32506],
        [25093],
        [24180],
        [25389],
        [26842],
        [26921],
        [26704],
        [26491],
        [27276],
        [27501],
        [27285],
        [27603],
        [28355],
        [28579],
        [28601],
        [28190],
        [29894]], device='cuda:0')
[2024-07-24 10:27:37,665][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[21781],
        [27550],
        [21578],
        [22518],
        [12152],
        [ 5139],
        [ 7412],
        [ 6243],
        [ 6018],
        [ 5708],
        [ 6550],
        [ 7153],
        [ 2996],
        [ 2488],
        [ 2609],
        [ 3146],
        [ 2442],
        [ 2923],
        [ 2187]], device='cuda:0')
[2024-07-24 10:27:37,668][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[11190],
        [30917],
        [29475],
        [32551],
        [33574],
        [33322],
        [27238],
        [25421],
        [28461],
        [27076],
        [29551],
        [29530],
        [30481],
        [30675],
        [29590],
        [29284],
        [29155],
        [29239],
        [28718]], device='cuda:0')
[2024-07-24 10:27:37,671][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 2103],
        [ 3422],
        [ 3868],
        [ 4313],
        [ 5898],
        [ 7472],
        [10383],
        [13467],
        [ 9150],
        [13800],
        [13626],
        [13909],
        [16218],
        [14810],
        [18264],
        [15711],
        [15632],
        [16807],
        [15110]], device='cuda:0')
[2024-07-24 10:27:37,672][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[14405],
        [24545],
        [13237],
        [14486],
        [16497],
        [15989],
        [19895],
        [20584],
        [20884],
        [21761],
        [22627],
        [22708],
        [22970],
        [22851],
        [22179],
        [23492],
        [22694],
        [23059],
        [22801]], device='cuda:0')
[2024-07-24 10:27:37,674][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[46274],
        [25719],
        [26725],
        [26298],
        [30016],
        [40493],
        [38301],
        [30800],
        [39888],
        [37601],
        [37897],
        [36754],
        [37255],
        [38347],
        [34190],
        [30252],
        [36237],
        [34473],
        [37699]], device='cuda:0')
[2024-07-24 10:27:37,676][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[22357],
        [39623],
        [25359],
        [40223],
        [22919],
        [23810],
        [36407],
        [23136],
        [36902],
        [36634],
        [36140],
        [42298],
        [38897],
        [39845],
        [39143],
        [38575],
        [39165],
        [37954],
        [36789]], device='cuda:0')
[2024-07-24 10:27:37,678][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930]], device='cuda:0')
[2024-07-24 10:27:37,797][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:37,799][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,800][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,800][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,801][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,803][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,805][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,808][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,811][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,814][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,816][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,817][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,818][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:37,818][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2385, 0.7615], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,819][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1092, 0.8908], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,821][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1072, 0.8928], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,825][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1350, 0.8650], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,828][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5486, 0.4514], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,832][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3184, 0.6816], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,834][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1236, 0.8764], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,835][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1864, 0.8136], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,835][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0610, 0.9390], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,836][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.6564, 0.3436], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,837][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.8157, 0.1843], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,839][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1452, 0.8548], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:37,841][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.0593, 0.0933, 0.8475], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,845][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0495, 0.1688, 0.7817], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,849][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.0408, 0.1101, 0.8492], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,852][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0417, 0.2705, 0.6878], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,853][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.3644, 0.2727, 0.3629], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,854][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.1834, 0.6218, 0.1948], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,854][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.0370, 0.1210, 0.8420], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,855][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.0998, 0.1703, 0.7299], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,857][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.0290, 0.2532, 0.7178], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,860][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.7795, 0.1203, 0.1002], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,864][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.7689, 0.0646, 0.1665], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,868][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.2186, 0.0811, 0.7004], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:37,870][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0212, 0.0612, 0.6570, 0.2606], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,870][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0179, 0.1239, 0.6649, 0.1933], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,871][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0210, 0.1166, 0.5974, 0.2650], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,872][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0218, 0.1956, 0.4987, 0.2838], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,874][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1633, 0.1310, 0.2333, 0.4724], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,876][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2705, 0.3818, 0.1080, 0.2397], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,880][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0129, 0.0931, 0.5822, 0.3117], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,884][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0597, 0.1827, 0.5189, 0.2386], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,887][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0101, 0.2569, 0.4652, 0.2678], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,888][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.6780, 0.1005, 0.0581, 0.1634], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,889][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.7724, 0.0577, 0.1483, 0.0216], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,890][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0333, 0.0558, 0.6377, 0.2731], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:37,891][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.0211, 0.0428, 0.4186, 0.1518, 0.3657], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,893][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([0.0142, 0.0495, 0.2127, 0.0569, 0.6668], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,896][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.0244, 0.0778, 0.2794, 0.1627, 0.4558], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,900][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.0099, 0.1277, 0.3089, 0.1584, 0.3951], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,904][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.0648, 0.1394, 0.1638, 0.5163, 0.1157], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,905][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([0.1522, 0.3429, 0.0575, 0.2706, 0.1769], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,906][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.0124, 0.0599, 0.3996, 0.1672, 0.3610], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,907][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.0293, 0.0949, 0.3349, 0.1183, 0.4226], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,908][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.0098, 0.1374, 0.2886, 0.1462, 0.4180], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,909][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.6108, 0.0937, 0.0253, 0.1401, 0.1301], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,912][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.7597, 0.0511, 0.1127, 0.0215, 0.0550], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,916][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([0.0512, 0.0476, 0.3547, 0.1615, 0.3850], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:37,919][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0036, 0.0116, 0.4753, 0.1100, 0.3883, 0.0112], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,922][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ had] are: tensor([1.5815e-04, 1.2809e-02, 9.8465e-02, 2.5137e-02, 8.6293e-01, 5.0351e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,923][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0010, 0.0331, 0.3402, 0.1422, 0.4650, 0.0185], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,924][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0069, 0.0657, 0.3092, 0.1411, 0.4481, 0.0291], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,925][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1351, 0.0531, 0.2881, 0.3024, 0.0698, 0.1515], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,926][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1413, 0.2625, 0.0970, 0.1590, 0.1986, 0.1415], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,928][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0032, 0.0394, 0.4058, 0.1825, 0.3507, 0.0184], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,930][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0139, 0.0442, 0.4233, 0.0589, 0.4222, 0.0374], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,934][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0021, 0.1093, 0.2046, 0.1397, 0.5280, 0.0163], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,938][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3594, 0.0923, 0.0637, 0.1734, 0.2400, 0.0713], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,941][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.5954, 0.0636, 0.1940, 0.0190, 0.0980, 0.0299], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,942][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0022, 0.0077, 0.3402, 0.0832, 0.2082, 0.3585], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:37,943][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0137, 0.0207, 0.2751, 0.1031, 0.2917, 0.0172, 0.2785],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,944][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0047, 0.0175, 0.1544, 0.0353, 0.5759, 0.0062, 0.2061],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,945][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0081, 0.0307, 0.2402, 0.1085, 0.3447, 0.0550, 0.2130],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,948][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0065, 0.0751, 0.2283, 0.1382, 0.3529, 0.0365, 0.1626],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,952][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0590, 0.0589, 0.1323, 0.2938, 0.0668, 0.1424, 0.2468],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,955][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2139, 0.2094, 0.0464, 0.1267, 0.1005, 0.1517, 0.1513],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,959][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0028, 0.0217, 0.2256, 0.1155, 0.2380, 0.0287, 0.3676],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,960][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0087, 0.0612, 0.3029, 0.0920, 0.3486, 0.0563, 0.1303],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,961][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0070, 0.0576, 0.1495, 0.0985, 0.2482, 0.0566, 0.3826],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,962][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.6832, 0.0447, 0.0203, 0.0681, 0.0533, 0.0796, 0.0507],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,963][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.6469, 0.0355, 0.1363, 0.0182, 0.0592, 0.0600, 0.0440],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,966][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0325, 0.0066, 0.0937, 0.0439, 0.0896, 0.6734, 0.0603],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:37,970][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0007, 0.0110, 0.3593, 0.0684, 0.2756, 0.0023, 0.2817, 0.0009],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,972][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([1.6722e-05, 1.2227e-02, 8.3411e-02, 1.7992e-02, 5.8677e-01, 5.3975e-05,
        2.9953e-01, 2.2580e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,975][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([3.3229e-04, 2.9434e-02, 2.0136e-01, 9.6311e-02, 3.2114e-01, 5.4523e-03,
        3.4556e-01, 4.0981e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,977][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0036, 0.0737, 0.2316, 0.1262, 0.3862, 0.0104, 0.1640, 0.0043],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,978][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0680, 0.0534, 0.2073, 0.2101, 0.0754, 0.0777, 0.1870, 0.1210],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,979][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0546, 0.2626, 0.0768, 0.1697, 0.1649, 0.0392, 0.2106, 0.0215],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,980][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([3.3859e-04, 2.9741e-02, 2.7432e-01, 9.9281e-02, 2.3431e-01, 2.0891e-03,
        3.5971e-01, 2.1071e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,981][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0105, 0.0525, 0.3710, 0.0494, 0.4324, 0.0151, 0.0576, 0.0115],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,984][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0009, 0.0643, 0.1209, 0.0939, 0.2970, 0.0050, 0.4174, 0.0007],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,987][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0299, 0.0892, 0.0378, 0.1926, 0.2060, 0.0148, 0.4151, 0.0147],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,991][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.1858, 0.1223, 0.2938, 0.0324, 0.1874, 0.0116, 0.1619, 0.0048],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,993][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([3.9435e-05, 1.6183e-02, 2.7297e-01, 9.1659e-02, 2.2874e-01, 7.5208e-03,
        3.8255e-01, 3.3845e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:37,997][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0113, 0.0137, 0.2130, 0.0521, 0.1833, 0.0068, 0.1609, 0.0083, 0.3507],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:37,998][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0063, 0.0222, 0.1358, 0.0335, 0.4411, 0.0031, 0.1866, 0.0013, 0.1703],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:37,999][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0069, 0.0181, 0.1084, 0.0610, 0.2199, 0.0406, 0.1461, 0.0163, 0.3827],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:37,999][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0111, 0.0704, 0.1495, 0.1255, 0.2490, 0.0338, 0.1708, 0.0243, 0.1657],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,000][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0521, 0.0391, 0.1010, 0.2210, 0.0477, 0.0692, 0.2235, 0.0884, 0.1580],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,002][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.2360, 0.1591, 0.0263, 0.0963, 0.0489, 0.1429, 0.1177, 0.0774, 0.0953],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,006][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0030, 0.0165, 0.1615, 0.0666, 0.1373, 0.0129, 0.2231, 0.0037, 0.3753],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,009][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0091, 0.0603, 0.1918, 0.0633, 0.2796, 0.0504, 0.1060, 0.0227, 0.2169],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,013][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0055, 0.0399, 0.0705, 0.0651, 0.1732, 0.0458, 0.2964, 0.0163, 0.2872],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,015][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.6820, 0.0200, 0.0052, 0.0306, 0.0136, 0.0528, 0.0233, 0.1458, 0.0267],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,016][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.7424, 0.0246, 0.0626, 0.0087, 0.0345, 0.0385, 0.0250, 0.0598, 0.0038],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,017][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0122, 0.0093, 0.0603, 0.0416, 0.0607, 0.3145, 0.0493, 0.3707, 0.0814],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,019][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0052, 0.0083, 0.0890, 0.0431, 0.1109, 0.0085, 0.1493, 0.0086, 0.3060,
        0.2712], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,021][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0015, 0.0165, 0.0975, 0.0362, 0.3318, 0.0026, 0.1761, 0.0007, 0.2011,
        0.1361], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,026][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0009, 0.0103, 0.0642, 0.0491, 0.1545, 0.0183, 0.1465, 0.0046, 0.3537,
        0.1981], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,030][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0014, 0.0408, 0.1278, 0.0884, 0.2018, 0.0186, 0.1511, 0.0073, 0.1687,
        0.1941], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,032][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0233, 0.0314, 0.0753, 0.2136, 0.0540, 0.0552, 0.2336, 0.0506, 0.1455,
        0.1174], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,033][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0620, 0.1651, 0.0255, 0.1019, 0.0632, 0.0891, 0.1982, 0.0308, 0.1565,
        0.1078], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,034][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0004, 0.0117, 0.0952, 0.0642, 0.1122, 0.0076, 0.2017, 0.0013, 0.3205,
        0.1852], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,035][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0019, 0.0324, 0.2097, 0.0581, 0.2990, 0.0293, 0.1077, 0.0090, 0.1488,
        0.1041], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,037][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0014, 0.0222, 0.0560, 0.0465, 0.1338, 0.0232, 0.2127, 0.0058, 0.2701,
        0.2283], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,039][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.2967, 0.0482, 0.0096, 0.0728, 0.0393, 0.0685, 0.0931, 0.1142, 0.1112,
        0.1463], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,043][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.3150, 0.0442, 0.1146, 0.0325, 0.0867, 0.0609, 0.0920, 0.0619, 0.0155,
        0.1766], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,048][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0017, 0.0114, 0.0803, 0.0548, 0.0947, 0.1673, 0.0966, 0.0740, 0.1163,
        0.3030], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,050][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0045, 0.0078, 0.0961, 0.0303, 0.0778, 0.0045, 0.1003, 0.0050, 0.2411,
        0.2261, 0.2065], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,051][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0018, 0.0135, 0.0866, 0.0250, 0.2682, 0.0024, 0.1539, 0.0007, 0.1918,
        0.1053, 0.1508], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,052][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0017, 0.0090, 0.0654, 0.0408, 0.1311, 0.0175, 0.0964, 0.0053, 0.2832,
        0.1435, 0.2061], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,054][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0034, 0.0388, 0.0847, 0.0855, 0.1584, 0.0256, 0.1591, 0.0141, 0.1966,
        0.1628, 0.0710], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,056][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0275, 0.0250, 0.0630, 0.1750, 0.0381, 0.0562, 0.1942, 0.0593, 0.1261,
        0.1015, 0.1341], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,060][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0758, 0.1310, 0.0185, 0.0839, 0.0532, 0.0624, 0.1687, 0.0259, 0.1644,
        0.1010, 0.1152], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,064][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0011, 0.0093, 0.0850, 0.0417, 0.0771, 0.0080, 0.1651, 0.0023, 0.3210,
        0.1565, 0.1329], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,067][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0035, 0.0341, 0.1719, 0.0481, 0.2568, 0.0256, 0.0807, 0.0097, 0.1521,
        0.0846, 0.1329], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,068][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0037, 0.0261, 0.0542, 0.0430, 0.1058, 0.0229, 0.1789, 0.0078, 0.2078,
        0.1532, 0.1966], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,069][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.2877, 0.0352, 0.0068, 0.0668, 0.0252, 0.0494, 0.0723, 0.0860, 0.1106,
        0.1594, 0.1006], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,070][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.6188, 0.0337, 0.0698, 0.0137, 0.0445, 0.0410, 0.0371, 0.0521, 0.0058,
        0.0744, 0.0090], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,072][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0047, 0.0077, 0.0521, 0.0391, 0.0687, 0.1739, 0.0535, 0.1454, 0.0851,
        0.2448, 0.1251], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,074][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0023, 0.0065, 0.0636, 0.0215, 0.0629, 0.0030, 0.0842, 0.0027, 0.1857,
        0.1982, 0.1624, 0.2070], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,078][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0016, 0.0128, 0.0807, 0.0225, 0.2407, 0.0022, 0.1309, 0.0006, 0.1279,
        0.0945, 0.1172, 0.1685], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,082][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0018, 0.0079, 0.0745, 0.0353, 0.1126, 0.0194, 0.0925, 0.0055, 0.2266,
        0.1168, 0.1618, 0.1452], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,085][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0022, 0.0343, 0.0999, 0.0761, 0.1544, 0.0202, 0.1346, 0.0095, 0.1472,
        0.1491, 0.0574, 0.1152], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,086][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0198, 0.0196, 0.0514, 0.1428, 0.0379, 0.0435, 0.1770, 0.0399, 0.1146,
        0.1027, 0.1269, 0.1239], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,087][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0829, 0.1101, 0.0121, 0.0764, 0.0392, 0.0592, 0.1299, 0.0236, 0.1303,
        0.0645, 0.0851, 0.1868], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,089][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0005, 0.0085, 0.0785, 0.0376, 0.0721, 0.0064, 0.1534, 0.0013, 0.2589,
        0.1394, 0.1062, 0.1374], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,092][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0020, 0.0271, 0.1399, 0.0356, 0.1920, 0.0181, 0.0773, 0.0053, 0.1327,
        0.0778, 0.1211, 0.1711], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,096][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0019, 0.0217, 0.0533, 0.0341, 0.0947, 0.0162, 0.1725, 0.0046, 0.1845,
        0.1549, 0.1551, 0.1064], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,100][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.3260, 0.0300, 0.0036, 0.0549, 0.0153, 0.0314, 0.0620, 0.0619, 0.1048,
        0.1136, 0.0975, 0.0991], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,102][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.4877, 0.0447, 0.1068, 0.0177, 0.0630, 0.0433, 0.0545, 0.0452, 0.0081,
        0.1073, 0.0124, 0.0094], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,103][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0021, 0.0070, 0.0528, 0.0341, 0.0611, 0.1531, 0.0513, 0.0945, 0.0860,
        0.2409, 0.1025, 0.1146], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,104][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0018, 0.0037, 0.0433, 0.0159, 0.0463, 0.0017, 0.0559, 0.0017, 0.1613,
        0.1695, 0.1335, 0.1870, 0.1784], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,105][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ store] are: tensor([6.0686e-04, 8.7238e-03, 6.1132e-02, 2.1813e-02, 2.2279e-01, 6.1492e-04,
        1.0427e-01, 1.2914e-04, 1.4782e-01, 7.8617e-02, 1.2515e-01, 1.6737e-01,
        6.0971e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,107][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0003, 0.0066, 0.0477, 0.0329, 0.0963, 0.0065, 0.0900, 0.0010, 0.2336,
        0.1084, 0.1590, 0.1391, 0.0785], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,109][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0009, 0.0291, 0.0966, 0.0569, 0.1510, 0.0084, 0.1014, 0.0030, 0.1545,
        0.1382, 0.0623, 0.1444, 0.0533], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,113][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0146, 0.0115, 0.0408, 0.1102, 0.0223, 0.0320, 0.1672, 0.0389, 0.1064,
        0.1005, 0.1126, 0.1231, 0.1198], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,117][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0349, 0.0520, 0.0047, 0.0440, 0.0186, 0.0235, 0.1023, 0.0153, 0.1265,
        0.0966, 0.0972, 0.2888, 0.0956], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,120][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0005, 0.0088, 0.0866, 0.0429, 0.0676, 0.0037, 0.1306, 0.0007, 0.2220,
        0.1138, 0.1179, 0.1591, 0.0458], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,121][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0018, 0.0192, 0.1329, 0.0303, 0.2219, 0.0115, 0.0660, 0.0042, 0.1112,
        0.0610, 0.0900, 0.1406, 0.1093], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,122][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.0010, 0.0140, 0.0443, 0.0323, 0.0762, 0.0116, 0.1350, 0.0023, 0.1952,
        0.1246, 0.1531, 0.1348, 0.0756], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,124][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0549, 0.0143, 0.0019, 0.0367, 0.0132, 0.0126, 0.0637, 0.0249, 0.1351,
        0.1812, 0.1497, 0.2098, 0.1021], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,127][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.4011, 0.0457, 0.1100, 0.0236, 0.0688, 0.0344, 0.0630, 0.0273, 0.0100,
        0.1246, 0.0143, 0.0113, 0.0659], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,130][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0007, 0.0069, 0.0518, 0.0351, 0.0605, 0.0411, 0.0744, 0.0145, 0.0851,
        0.2015, 0.1025, 0.1477, 0.1783], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,134][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0016, 0.0052, 0.0461, 0.0169, 0.0522, 0.0016, 0.0617, 0.0016, 0.1518,
        0.1287, 0.1151, 0.1588, 0.1290, 0.1298], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,137][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0015, 0.0123, 0.0641, 0.0187, 0.2070, 0.0011, 0.0996, 0.0004, 0.1072,
        0.0822, 0.0953, 0.1427, 0.0665, 0.1013], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,138][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0016, 0.0076, 0.0474, 0.0296, 0.0995, 0.0144, 0.0783, 0.0040, 0.1779,
        0.1003, 0.1300, 0.1152, 0.0838, 0.1105], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,139][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0025, 0.0312, 0.0623, 0.0576, 0.1274, 0.0161, 0.1080, 0.0096, 0.1390,
        0.1293, 0.0595, 0.1074, 0.0569, 0.0932], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,140][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0200, 0.0216, 0.0417, 0.1244, 0.0244, 0.0385, 0.1416, 0.0403, 0.0908,
        0.0817, 0.0985, 0.1026, 0.0697, 0.1044], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,142][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0694, 0.0793, 0.0062, 0.0522, 0.0211, 0.0415, 0.1096, 0.0200, 0.1075,
        0.0621, 0.0642, 0.1755, 0.0498, 0.1417], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,145][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0004, 0.0085, 0.0523, 0.0318, 0.0567, 0.0039, 0.1132, 0.0008, 0.2132,
        0.1026, 0.0942, 0.1357, 0.0349, 0.1518], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,149][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0025, 0.0283, 0.1155, 0.0302, 0.1812, 0.0153, 0.0564, 0.0057, 0.1022,
        0.0510, 0.0753, 0.1186, 0.0888, 0.1290], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,153][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0019, 0.0153, 0.0363, 0.0278, 0.0875, 0.0201, 0.1307, 0.0070, 0.1410,
        0.1276, 0.1254, 0.0969, 0.0722, 0.1102], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,155][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1541, 0.0247, 0.0026, 0.0488, 0.0141, 0.0277, 0.0667, 0.0410, 0.1333,
        0.1387, 0.0952, 0.1125, 0.0434, 0.0971], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,156][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.5838, 0.0355, 0.0568, 0.0133, 0.0425, 0.0369, 0.0369, 0.0437, 0.0056,
        0.0717, 0.0083, 0.0070, 0.0460, 0.0118], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,157][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0015, 0.0081, 0.0407, 0.0295, 0.0543, 0.0550, 0.0499, 0.0313, 0.0674,
        0.1935, 0.0849, 0.1029, 0.1622, 0.1189], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,159][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.0014, 0.0028, 0.0302, 0.0099, 0.0284, 0.0013, 0.0374, 0.0012, 0.0923,
        0.0996, 0.0728, 0.1103, 0.0953, 0.0682, 0.3489], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,162][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0012, 0.0125, 0.0475, 0.0168, 0.1634, 0.0012, 0.1039, 0.0003, 0.0963,
        0.0684, 0.0956, 0.1418, 0.0608, 0.0885, 0.1018], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,165][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.0007, 0.0074, 0.0464, 0.0275, 0.0854, 0.0098, 0.0655, 0.0023, 0.1663,
        0.0874, 0.0976, 0.0990, 0.0700, 0.0877, 0.1468], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,170][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0017, 0.0339, 0.0650, 0.0616, 0.1075, 0.0133, 0.0924, 0.0064, 0.1112,
        0.1164, 0.0457, 0.1068, 0.0538, 0.0826, 0.1017], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,172][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.0132, 0.0144, 0.0310, 0.0953, 0.0204, 0.0256, 0.1061, 0.0326, 0.0786,
        0.0721, 0.0801, 0.0839, 0.0839, 0.1054, 0.1575], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,173][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0228, 0.0437, 0.0030, 0.0328, 0.0167, 0.0152, 0.0633, 0.0145, 0.0789,
        0.0661, 0.0684, 0.2144, 0.0677, 0.2691, 0.0234], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,174][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.0005, 0.0093, 0.0659, 0.0273, 0.0521, 0.0034, 0.0944, 0.0007, 0.1482,
        0.1055, 0.0775, 0.1000, 0.0385, 0.0971, 0.1796], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,175][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.0028, 0.0280, 0.0976, 0.0333, 0.1614, 0.0170, 0.0609, 0.0066, 0.0915,
        0.0420, 0.0931, 0.1141, 0.0696, 0.1113, 0.0708], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,177][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.0025, 0.0208, 0.0450, 0.0320, 0.0865, 0.0172, 0.1094, 0.0068, 0.1189,
        0.1235, 0.1085, 0.0720, 0.0857, 0.0994, 0.0719], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,179][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.1067, 0.0084, 0.0010, 0.0246, 0.0109, 0.0219, 0.0370, 0.0760, 0.0717,
        0.1306, 0.0787, 0.1673, 0.0829, 0.1592, 0.0231], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,183][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.4060, 0.0376, 0.0596, 0.0177, 0.0551, 0.0548, 0.0552, 0.0514, 0.0099,
        0.1092, 0.0144, 0.0117, 0.0831, 0.0239, 0.0105], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,187][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.0031, 0.0076, 0.0329, 0.0230, 0.0455, 0.0463, 0.0331, 0.0329, 0.0486,
        0.2023, 0.0668, 0.0776, 0.1679, 0.1010, 0.1113], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,189][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([3.0057e-05, 3.8345e-04, 1.5762e-02, 2.8899e-03, 1.2281e-02, 1.4639e-04,
        1.7998e-02, 5.1560e-05, 6.7288e-02, 6.5356e-02, 4.9426e-02, 6.2377e-02,
        5.0724e-02, 5.7125e-02, 5.9781e-01, 3.4770e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,190][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([2.7452e-06, 2.3136e-03, 2.5908e-02, 5.1996e-03, 1.4004e-01, 1.8668e-05,
        8.3079e-02, 7.5148e-07, 1.5658e-01, 3.1630e-02, 1.4353e-01, 1.2782e-01,
        2.3610e-02, 1.0654e-01, 1.5372e-01, 1.0132e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,191][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([2.6851e-05, 3.3805e-03, 4.1284e-02, 1.5990e-02, 5.8402e-02, 9.4230e-04,
        7.1460e-02, 6.4494e-05, 2.0238e-01, 5.5305e-02, 1.3197e-01, 1.0379e-01,
        3.5579e-02, 1.0010e-01, 1.7901e-01, 3.2243e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,193][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0004, 0.0188, 0.0713, 0.0445, 0.1308, 0.0044, 0.0804, 0.0011, 0.1018,
        0.1036, 0.0540, 0.0966, 0.0529, 0.0797, 0.1538, 0.0059],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,196][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0162, 0.0099, 0.0548, 0.0821, 0.0169, 0.0254, 0.0868, 0.0401, 0.0400,
        0.0440, 0.0688, 0.0724, 0.0688, 0.0845, 0.2487, 0.0405],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,200][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0202, 0.0532, 0.0052, 0.0400, 0.0202, 0.0145, 0.0975, 0.0053, 0.1144,
        0.0753, 0.0808, 0.2074, 0.0614, 0.1684, 0.0171, 0.0190],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,202][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([1.0560e-04, 7.4683e-03, 5.6297e-02, 2.0185e-02, 3.5770e-02, 5.9311e-04,
        7.8857e-02, 7.0092e-05, 1.6257e-01, 8.9545e-02, 8.8182e-02, 1.0460e-01,
        2.2986e-02, 1.0688e-01, 2.2576e-01, 1.2304e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,206][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0026, 0.0248, 0.2428, 0.0251, 0.3117, 0.0090, 0.0346, 0.0040, 0.0473,
        0.0319, 0.0405, 0.0578, 0.0480, 0.0493, 0.0571, 0.0136],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,207][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([1.5174e-04, 1.1163e-02, 2.1084e-02, 2.1633e-02, 5.0017e-02, 1.4640e-03,
        1.2217e-01, 1.4603e-04, 1.9659e-01, 5.3602e-02, 1.7196e-01, 1.2409e-01,
        3.1557e-02, 1.3028e-01, 6.2928e-02, 1.1718e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,208][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0091, 0.0108, 0.0012, 0.0303, 0.0112, 0.0027, 0.0709, 0.0026, 0.1377,
        0.1717, 0.1228, 0.1589, 0.0581, 0.1774, 0.0115, 0.0229],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,209][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.1142, 0.0642, 0.1853, 0.0224, 0.1263, 0.0192, 0.1336, 0.0048, 0.0081,
        0.1698, 0.0169, 0.0118, 0.0616, 0.0223, 0.0080, 0.0316],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,211][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([2.7862e-05, 4.7141e-03, 6.9817e-02, 2.8148e-02, 6.8927e-02, 6.0961e-03,
        8.9137e-02, 4.8286e-04, 7.3508e-02, 9.9531e-02, 8.4317e-02, 1.5257e-01,
        8.1409e-02, 1.0033e-01, 1.3825e-01, 2.7329e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,212][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([2.8224e-04, 6.9499e-04, 2.1017e-02, 4.2592e-03, 1.7768e-02, 4.5108e-04,
        2.1638e-02, 3.4554e-04, 7.9265e-02, 7.8419e-02, 5.7881e-02, 7.5502e-02,
        7.5857e-02, 5.8026e-02, 4.9511e-01, 1.5129e-03, 1.1966e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,215][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([4.3498e-05, 2.8050e-03, 4.7321e-02, 8.0304e-03, 1.5705e-01, 1.7400e-04,
        7.5710e-02, 1.8259e-05, 1.2444e-01, 5.4879e-02, 1.0294e-01, 1.4105e-01,
        3.4873e-02, 8.3353e-02, 1.5969e-01, 1.6842e-04, 7.4437e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,218][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0002, 0.0037, 0.0450, 0.0193, 0.0727, 0.0042, 0.0568, 0.0006, 0.1918,
        0.0716, 0.1155, 0.0947, 0.0528, 0.0896, 0.1536, 0.0029, 0.0249],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,222][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0004, 0.0131, 0.0530, 0.0456, 0.0957, 0.0098, 0.0823, 0.0026, 0.1283,
        0.1180, 0.0473, 0.1014, 0.0485, 0.0698, 0.1237, 0.0119, 0.0486],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,224][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0089, 0.0058, 0.0211, 0.0645, 0.0097, 0.0295, 0.0724, 0.0331, 0.0446,
        0.0447, 0.0504, 0.0460, 0.0558, 0.0565, 0.1150, 0.0495, 0.2928],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,225][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0530, 0.0768, 0.0061, 0.0498, 0.0228, 0.0307, 0.0869, 0.0113, 0.0885,
        0.0508, 0.0578, 0.1494, 0.0414, 0.1292, 0.0094, 0.0198, 0.1164],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,226][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([1.5854e-04, 4.6730e-03, 5.5911e-02, 2.4268e-02, 4.0979e-02, 1.8364e-03,
        8.4903e-02, 2.5036e-04, 1.6803e-01, 9.2957e-02, 8.3972e-02, 9.8521e-02,
        2.5915e-02, 8.9495e-02, 2.0610e-01, 4.9615e-04, 2.1527e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,228][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0019, 0.0183, 0.1654, 0.0250, 0.1785, 0.0132, 0.0402, 0.0047, 0.0675,
        0.0408, 0.0569, 0.0889, 0.0689, 0.0775, 0.0898, 0.0205, 0.0419],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,231][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0004, 0.0094, 0.0263, 0.0261, 0.0528, 0.0076, 0.1284, 0.0011, 0.1665,
        0.0873, 0.1295, 0.1072, 0.0403, 0.0960, 0.0637, 0.0073, 0.0501],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,235][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1975, 0.0186, 0.0020, 0.0442, 0.0132, 0.0130, 0.0462, 0.0255, 0.0748,
        0.1066, 0.0663, 0.0668, 0.0364, 0.0701, 0.0051, 0.0695, 0.1443],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,239][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2403, 0.0356, 0.1387, 0.0155, 0.0750, 0.0295, 0.0608, 0.0144, 0.0067,
        0.1336, 0.0119, 0.0092, 0.0557, 0.0171, 0.0072, 0.0877, 0.0611],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,241][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0008, 0.0017, 0.0243, 0.0128, 0.0275, 0.0490, 0.0235, 0.0293, 0.0311,
        0.1135, 0.0442, 0.0468, 0.1379, 0.0569, 0.0948, 0.0872, 0.2187],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,242][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.0013, 0.0032, 0.0323, 0.0103, 0.0353, 0.0009, 0.0423, 0.0008, 0.0819,
        0.0907, 0.0663, 0.0943, 0.0738, 0.0704, 0.3229, 0.0017, 0.0122, 0.0593],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,243][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([0.0009, 0.0121, 0.0608, 0.0181, 0.1917, 0.0009, 0.0928, 0.0002, 0.0895,
        0.0716, 0.0851, 0.1186, 0.0513, 0.0762, 0.0729, 0.0009, 0.0099, 0.0465],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,244][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([0.0005, 0.0044, 0.0336, 0.0191, 0.0714, 0.0072, 0.0584, 0.0017, 0.1459,
        0.0858, 0.0847, 0.0897, 0.0582, 0.0808, 0.1281, 0.0058, 0.0320, 0.0927],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,247][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([0.0008, 0.0227, 0.0508, 0.0513, 0.0970, 0.0076, 0.0924, 0.0026, 0.1114,
        0.1061, 0.0430, 0.0927, 0.0376, 0.0787, 0.0894, 0.0070, 0.0347, 0.0744],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,250][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([0.0052, 0.0065, 0.0136, 0.0570, 0.0111, 0.0150, 0.0855, 0.0128, 0.0607,
        0.0588, 0.0685, 0.0639, 0.0523, 0.0812, 0.0958, 0.0279, 0.1992, 0.0851],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,254][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([0.0277, 0.0546, 0.0030, 0.0358, 0.0134, 0.0182, 0.0745, 0.0111, 0.0895,
        0.0561, 0.0629, 0.1539, 0.0360, 0.1654, 0.0112, 0.0230, 0.1346, 0.0291],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,258][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([0.0004, 0.0054, 0.0382, 0.0215, 0.0359, 0.0022, 0.0768, 0.0004, 0.1328,
        0.0776, 0.0668, 0.0952, 0.0229, 0.0847, 0.1106, 0.0007, 0.0235, 0.2044],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,259][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([0.0033, 0.0245, 0.0686, 0.0298, 0.1219, 0.0130, 0.0521, 0.0051, 0.0873,
        0.0442, 0.0901, 0.1151, 0.0658, 0.1142, 0.0512, 0.0157, 0.0360, 0.0620],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,260][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([0.0012, 0.0133, 0.0272, 0.0233, 0.0460, 0.0110, 0.1081, 0.0028, 0.1202,
        0.1043, 0.1026, 0.0755, 0.0550, 0.0912, 0.0580, 0.0144, 0.0493, 0.0967],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,261][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([0.0820, 0.0092, 0.0011, 0.0200, 0.0070, 0.0193, 0.0348, 0.0369, 0.0670,
        0.0869, 0.0522, 0.0794, 0.0307, 0.0804, 0.0088, 0.1244, 0.2260, 0.0339],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,263][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([0.2089, 0.0381, 0.0673, 0.0189, 0.0620, 0.0349, 0.0569, 0.0254, 0.0124,
        0.1166, 0.0161, 0.0123, 0.0761, 0.0277, 0.0101, 0.0964, 0.0755, 0.0445],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,265][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([0.0012, 0.0038, 0.0229, 0.0143, 0.0332, 0.0466, 0.0355, 0.0318, 0.0416,
        0.1358, 0.0378, 0.0479, 0.1342, 0.0726, 0.0726, 0.0520, 0.1440, 0.0724],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,269][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0009, 0.0018, 0.0283, 0.0064, 0.0214, 0.0008, 0.0250, 0.0007, 0.0824,
        0.0649, 0.0542, 0.0721, 0.0626, 0.0495, 0.3339, 0.0020, 0.0120, 0.0464,
        0.1348], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,274][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0007, 0.0076, 0.0567, 0.0142, 0.1436, 0.0009, 0.0702, 0.0002, 0.0917,
        0.0554, 0.0706, 0.1106, 0.0400, 0.0635, 0.0800, 0.0009, 0.0123, 0.0555,
        0.1255], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,276][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0006, 0.0033, 0.0267, 0.0150, 0.0474, 0.0078, 0.0374, 0.0020, 0.1225,
        0.0555, 0.0751, 0.0694, 0.0518, 0.0643, 0.1087, 0.0081, 0.0353, 0.0787,
        0.1905], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,277][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0015, 0.0200, 0.0512, 0.0492, 0.0786, 0.0122, 0.0710, 0.0052, 0.1014,
        0.0979, 0.0425, 0.0845, 0.0392, 0.0565, 0.0933, 0.0146, 0.0411, 0.0698,
        0.0704], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,278][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0098, 0.0102, 0.0226, 0.0586, 0.0119, 0.0187, 0.0739, 0.0157, 0.0519,
        0.0435, 0.0521, 0.0551, 0.0378, 0.0524, 0.0660, 0.0285, 0.1579, 0.0776,
        0.1558], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,280][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0471, 0.0604, 0.0048, 0.0399, 0.0156, 0.0376, 0.0675, 0.0169, 0.0784,
        0.0447, 0.0503, 0.1269, 0.0346, 0.1139, 0.0095, 0.0255, 0.1045, 0.0234,
        0.0985], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,283][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0004, 0.0042, 0.0411, 0.0158, 0.0327, 0.0022, 0.0538, 0.0004, 0.1211,
        0.0535, 0.0488, 0.0643, 0.0172, 0.0599, 0.1188, 0.0010, 0.0230, 0.1768,
        0.1650], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,287][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0017, 0.0196, 0.0767, 0.0207, 0.1064, 0.0118, 0.0372, 0.0035, 0.0886,
        0.0393, 0.0646, 0.0998, 0.0665, 0.0970, 0.0693, 0.0162, 0.0390, 0.0492,
        0.0929], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,291][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0009, 0.0106, 0.0228, 0.0229, 0.0512, 0.0107, 0.0956, 0.0025, 0.1233,
        0.0837, 0.0955, 0.0787, 0.0399, 0.0733, 0.0508, 0.0158, 0.0598, 0.0665,
        0.0955], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,293][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2915, 0.0148, 0.0016, 0.0300, 0.0089, 0.0306, 0.0295, 0.0657, 0.0515,
        0.0563, 0.0387, 0.0480, 0.0220, 0.0392, 0.0040, 0.0798, 0.1155, 0.0168,
        0.0558], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,294][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.2330, 0.0322, 0.1041, 0.0156, 0.0575, 0.0341, 0.0481, 0.0230, 0.0104,
        0.0853, 0.0121, 0.0101, 0.0539, 0.0169, 0.0088, 0.0967, 0.0678, 0.0373,
        0.0531], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,295][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0028, 0.0026, 0.0159, 0.0109, 0.0161, 0.0594, 0.0124, 0.0692, 0.0203,
        0.0665, 0.0329, 0.0314, 0.1043, 0.0456, 0.0498, 0.1441, 0.1560, 0.0386,
        0.1213], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,415][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:38,416][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:38,417][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:38,418][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:38,419][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:38,420][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:38,420][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:38,421][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:38,422][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:38,423][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:38,423][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:38,426][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:38,426][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:38,427][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2385, 0.7615], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:38,428][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1092, 0.8908], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:38,429][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1072, 0.8928], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:38,429][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1350, 0.8650], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:38,430][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5486, 0.4514], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:38,431][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3184, 0.6816], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:38,432][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1236, 0.8764], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:38,432][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1864, 0.8136], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:38,433][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0610, 0.9390], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:38,434][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.6564, 0.3436], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:38,435][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.8157, 0.1843], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:38,435][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1452, 0.8548], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:38,436][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.0593, 0.0933, 0.8475], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:38,439][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0495, 0.1688, 0.7817], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:38,443][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.0408, 0.1101, 0.8492], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:38,446][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.0417, 0.2705, 0.6878], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:38,448][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.3644, 0.2727, 0.3629], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:38,449][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.1834, 0.6218, 0.1948], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:38,450][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.0370, 0.1210, 0.8420], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:38,450][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.0998, 0.1703, 0.7299], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:38,452][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.0290, 0.2532, 0.7178], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:38,455][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.7795, 0.1203, 0.1002], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:38,458][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.7689, 0.0646, 0.1665], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:38,462][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.2186, 0.0811, 0.7004], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:38,466][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0212, 0.0612, 0.6570, 0.2606], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:38,466][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0179, 0.1239, 0.6649, 0.1933], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:38,467][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0210, 0.1166, 0.5974, 0.2650], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:38,468][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0218, 0.1956, 0.4987, 0.2838], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:38,470][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1633, 0.1310, 0.2333, 0.4724], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:38,472][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2705, 0.3818, 0.1080, 0.2397], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:38,476][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0129, 0.0931, 0.5822, 0.3117], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:38,479][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0597, 0.1827, 0.5189, 0.2386], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:38,483][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0101, 0.2569, 0.4652, 0.2678], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:38,484][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.6780, 0.1005, 0.0581, 0.1634], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:38,485][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.7724, 0.0577, 0.1483, 0.0216], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:38,485][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0333, 0.0558, 0.6377, 0.2731], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:38,487][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.0211, 0.0428, 0.4186, 0.1518, 0.3657], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:38,490][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([0.0142, 0.0495, 0.2127, 0.0569, 0.6668], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:38,494][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([0.0244, 0.0778, 0.2794, 0.1627, 0.4558], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:38,497][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([0.0099, 0.1277, 0.3089, 0.1584, 0.3951], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:38,501][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([0.0648, 0.1394, 0.1638, 0.5163, 0.1157], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:38,501][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.1522, 0.3429, 0.0575, 0.2706, 0.1769], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:38,502][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.0124, 0.0599, 0.3996, 0.1672, 0.3610], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:38,503][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.0293, 0.0949, 0.3349, 0.1183, 0.4226], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:38,505][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.0098, 0.1374, 0.2886, 0.1462, 0.4180], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:38,507][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.6108, 0.0937, 0.0253, 0.1401, 0.1301], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:38,511][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.7597, 0.0511, 0.1127, 0.0215, 0.0550], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:38,514][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.0512, 0.0476, 0.3547, 0.1615, 0.3850], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:38,518][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0036, 0.0116, 0.4753, 0.1100, 0.3883, 0.0112], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:38,519][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([1.5815e-04, 1.2809e-02, 9.8465e-02, 2.5137e-02, 8.6293e-01, 5.0351e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:38,520][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0010, 0.0331, 0.3402, 0.1422, 0.4650, 0.0185], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:38,521][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0069, 0.0657, 0.3092, 0.1411, 0.4481, 0.0291], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:38,523][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1351, 0.0531, 0.2881, 0.3024, 0.0698, 0.1515], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:38,526][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1413, 0.2625, 0.0970, 0.1590, 0.1986, 0.1415], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:38,530][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0032, 0.0394, 0.4058, 0.1825, 0.3507, 0.0184], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:38,534][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0139, 0.0442, 0.4233, 0.0589, 0.4222, 0.0374], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:38,538][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0021, 0.1093, 0.2046, 0.1397, 0.5280, 0.0163], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:38,539][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3594, 0.0923, 0.0637, 0.1734, 0.2400, 0.0713], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:38,540][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.5954, 0.0636, 0.1940, 0.0190, 0.0980, 0.0299], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:38,540][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0022, 0.0077, 0.3402, 0.0832, 0.2082, 0.3585], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:38,543][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0137, 0.0207, 0.2751, 0.1031, 0.2917, 0.0172, 0.2785],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:38,545][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0047, 0.0175, 0.1544, 0.0353, 0.5759, 0.0062, 0.2061],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:38,549][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0081, 0.0307, 0.2402, 0.1085, 0.3447, 0.0550, 0.2130],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:38,554][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0065, 0.0751, 0.2283, 0.1382, 0.3529, 0.0365, 0.1626],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:38,556][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0590, 0.0589, 0.1323, 0.2938, 0.0668, 0.1424, 0.2468],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:38,557][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2139, 0.2094, 0.0464, 0.1267, 0.1005, 0.1517, 0.1513],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:38,558][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0028, 0.0217, 0.2256, 0.1155, 0.2380, 0.0287, 0.3676],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:38,558][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0087, 0.0612, 0.3029, 0.0920, 0.3486, 0.0563, 0.1303],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:38,559][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0070, 0.0576, 0.1495, 0.0985, 0.2482, 0.0566, 0.3826],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:38,561][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.6832, 0.0447, 0.0203, 0.0681, 0.0533, 0.0796, 0.0507],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:38,565][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.6469, 0.0355, 0.1363, 0.0182, 0.0592, 0.0600, 0.0440],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:38,568][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0325, 0.0066, 0.0937, 0.0439, 0.0896, 0.6734, 0.0603],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:38,572][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0007, 0.0110, 0.3593, 0.0684, 0.2756, 0.0023, 0.2817, 0.0009],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:38,574][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([1.6722e-05, 1.2227e-02, 8.3411e-02, 1.7992e-02, 5.8677e-01, 5.3975e-05,
        2.9953e-01, 2.2580e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:38,575][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([3.3229e-04, 2.9434e-02, 2.0136e-01, 9.6311e-02, 3.2114e-01, 5.4523e-03,
        3.4556e-01, 4.0981e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:38,576][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0036, 0.0737, 0.2316, 0.1262, 0.3862, 0.0104, 0.1640, 0.0043],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:38,577][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0680, 0.0534, 0.2073, 0.2101, 0.0754, 0.0777, 0.1870, 0.1210],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:38,579][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0546, 0.2626, 0.0768, 0.1697, 0.1649, 0.0392, 0.2106, 0.0215],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:38,581][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([3.3859e-04, 2.9741e-02, 2.7432e-01, 9.9281e-02, 2.3431e-01, 2.0891e-03,
        3.5971e-01, 2.1071e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:38,585][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0105, 0.0525, 0.3710, 0.0494, 0.4324, 0.0151, 0.0576, 0.0115],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:38,588][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0009, 0.0643, 0.1209, 0.0939, 0.2970, 0.0050, 0.4174, 0.0007],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:38,592][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0299, 0.0892, 0.0378, 0.1926, 0.2060, 0.0148, 0.4151, 0.0147],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:38,593][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.1858, 0.1223, 0.2938, 0.0324, 0.1874, 0.0116, 0.1619, 0.0048],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:38,594][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([3.9435e-05, 1.6183e-02, 2.7297e-01, 9.1659e-02, 2.2874e-01, 7.5208e-03,
        3.8255e-01, 3.3845e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:38,595][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0113, 0.0137, 0.2130, 0.0521, 0.1833, 0.0068, 0.1609, 0.0083, 0.3507],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,597][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0063, 0.0222, 0.1358, 0.0335, 0.4411, 0.0031, 0.1866, 0.0013, 0.1703],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,600][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0069, 0.0181, 0.1084, 0.0610, 0.2199, 0.0406, 0.1461, 0.0163, 0.3827],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,604][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0111, 0.0704, 0.1495, 0.1255, 0.2490, 0.0338, 0.1708, 0.0243, 0.1657],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,608][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0521, 0.0391, 0.1010, 0.2210, 0.0477, 0.0692, 0.2235, 0.0884, 0.1580],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,610][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.2360, 0.1591, 0.0263, 0.0963, 0.0489, 0.1429, 0.1177, 0.0774, 0.0953],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,611][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0030, 0.0165, 0.1615, 0.0666, 0.1373, 0.0129, 0.2231, 0.0037, 0.3753],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,612][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0091, 0.0603, 0.1918, 0.0633, 0.2796, 0.0504, 0.1060, 0.0227, 0.2169],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,613][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0055, 0.0399, 0.0705, 0.0651, 0.1732, 0.0458, 0.2964, 0.0163, 0.2872],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,615][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.6820, 0.0200, 0.0052, 0.0306, 0.0136, 0.0528, 0.0233, 0.1458, 0.0267],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,618][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.7424, 0.0246, 0.0626, 0.0087, 0.0345, 0.0385, 0.0250, 0.0598, 0.0038],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,622][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0122, 0.0093, 0.0603, 0.0416, 0.0607, 0.3145, 0.0493, 0.3707, 0.0814],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:38,626][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0052, 0.0083, 0.0890, 0.0431, 0.1109, 0.0085, 0.1493, 0.0086, 0.3060,
        0.2712], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,628][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0015, 0.0165, 0.0975, 0.0362, 0.3318, 0.0026, 0.1761, 0.0007, 0.2011,
        0.1361], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,629][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0009, 0.0103, 0.0642, 0.0491, 0.1545, 0.0183, 0.1465, 0.0046, 0.3537,
        0.1981], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,630][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0014, 0.0408, 0.1278, 0.0884, 0.2018, 0.0186, 0.1511, 0.0073, 0.1687,
        0.1941], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,631][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0233, 0.0314, 0.0753, 0.2136, 0.0540, 0.0552, 0.2336, 0.0506, 0.1455,
        0.1174], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,633][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0620, 0.1651, 0.0255, 0.1019, 0.0632, 0.0891, 0.1982, 0.0308, 0.1565,
        0.1078], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,636][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0004, 0.0117, 0.0952, 0.0642, 0.1122, 0.0076, 0.2017, 0.0013, 0.3205,
        0.1852], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,640][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0019, 0.0324, 0.2097, 0.0581, 0.2990, 0.0293, 0.1077, 0.0090, 0.1488,
        0.1041], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,644][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0014, 0.0222, 0.0560, 0.0465, 0.1338, 0.0232, 0.2127, 0.0058, 0.2701,
        0.2283], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,646][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.2967, 0.0482, 0.0096, 0.0728, 0.0393, 0.0685, 0.0931, 0.1142, 0.1112,
        0.1463], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,647][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.3150, 0.0442, 0.1146, 0.0325, 0.0867, 0.0609, 0.0920, 0.0619, 0.0155,
        0.1766], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,648][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0017, 0.0114, 0.0803, 0.0548, 0.0947, 0.1673, 0.0966, 0.0740, 0.1163,
        0.3030], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:38,649][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0045, 0.0078, 0.0961, 0.0303, 0.0778, 0.0045, 0.1003, 0.0050, 0.2411,
        0.2261, 0.2065], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,651][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0018, 0.0135, 0.0866, 0.0250, 0.2682, 0.0024, 0.1539, 0.0007, 0.1918,
        0.1053, 0.1508], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,654][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0017, 0.0090, 0.0654, 0.0408, 0.1311, 0.0175, 0.0964, 0.0053, 0.2832,
        0.1435, 0.2061], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,658][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0034, 0.0388, 0.0847, 0.0855, 0.1584, 0.0256, 0.1591, 0.0141, 0.1966,
        0.1628, 0.0710], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,662][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0275, 0.0250, 0.0630, 0.1750, 0.0381, 0.0562, 0.1942, 0.0593, 0.1261,
        0.1015, 0.1341], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,664][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0758, 0.1310, 0.0185, 0.0839, 0.0532, 0.0624, 0.1687, 0.0259, 0.1644,
        0.1010, 0.1152], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,665][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0011, 0.0093, 0.0850, 0.0417, 0.0771, 0.0080, 0.1651, 0.0023, 0.3210,
        0.1565, 0.1329], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,666][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0035, 0.0341, 0.1719, 0.0481, 0.2568, 0.0256, 0.0807, 0.0097, 0.1521,
        0.0846, 0.1329], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,667][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0037, 0.0261, 0.0542, 0.0430, 0.1058, 0.0229, 0.1789, 0.0078, 0.2078,
        0.1532, 0.1966], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,669][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.2877, 0.0352, 0.0068, 0.0668, 0.0252, 0.0494, 0.0723, 0.0860, 0.1106,
        0.1594, 0.1006], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,671][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.6188, 0.0337, 0.0698, 0.0137, 0.0445, 0.0410, 0.0371, 0.0521, 0.0058,
        0.0744, 0.0090], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,676][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0047, 0.0077, 0.0521, 0.0391, 0.0687, 0.1739, 0.0535, 0.1454, 0.0851,
        0.2448, 0.1251], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:38,680][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0023, 0.0065, 0.0636, 0.0215, 0.0629, 0.0030, 0.0842, 0.0027, 0.1857,
        0.1982, 0.1624, 0.2070], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,682][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0016, 0.0128, 0.0807, 0.0225, 0.2407, 0.0022, 0.1309, 0.0006, 0.1279,
        0.0945, 0.1172, 0.1685], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,683][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0018, 0.0079, 0.0745, 0.0353, 0.1126, 0.0194, 0.0925, 0.0055, 0.2266,
        0.1168, 0.1618, 0.1452], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,684][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0022, 0.0343, 0.0999, 0.0761, 0.1544, 0.0202, 0.1346, 0.0095, 0.1472,
        0.1491, 0.0574, 0.1152], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,685][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0198, 0.0196, 0.0514, 0.1428, 0.0379, 0.0435, 0.1770, 0.0399, 0.1146,
        0.1027, 0.1269, 0.1239], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,687][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0829, 0.1101, 0.0121, 0.0764, 0.0392, 0.0592, 0.1299, 0.0236, 0.1303,
        0.0645, 0.0851, 0.1868], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,689][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0005, 0.0085, 0.0785, 0.0376, 0.0721, 0.0064, 0.1534, 0.0013, 0.2589,
        0.1394, 0.1062, 0.1374], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,694][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0020, 0.0271, 0.1399, 0.0356, 0.1920, 0.0181, 0.0773, 0.0053, 0.1327,
        0.0778, 0.1211, 0.1711], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,698][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0019, 0.0217, 0.0533, 0.0341, 0.0947, 0.0162, 0.1725, 0.0046, 0.1845,
        0.1549, 0.1551, 0.1064], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,700][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.3260, 0.0300, 0.0036, 0.0549, 0.0153, 0.0314, 0.0620, 0.0619, 0.1048,
        0.1136, 0.0975, 0.0991], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,701][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.4877, 0.0447, 0.1068, 0.0177, 0.0630, 0.0433, 0.0545, 0.0452, 0.0081,
        0.1073, 0.0124, 0.0094], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,702][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0021, 0.0070, 0.0528, 0.0341, 0.0611, 0.1531, 0.0513, 0.0945, 0.0860,
        0.2409, 0.1025, 0.1146], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:38,703][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.0018, 0.0037, 0.0433, 0.0159, 0.0463, 0.0017, 0.0559, 0.0017, 0.1613,
        0.1695, 0.1335, 0.1870, 0.1784], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,704][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([6.0686e-04, 8.7238e-03, 6.1132e-02, 2.1813e-02, 2.2279e-01, 6.1492e-04,
        1.0427e-01, 1.2914e-04, 1.4782e-01, 7.8617e-02, 1.2515e-01, 1.6737e-01,
        6.0971e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,707][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.0003, 0.0066, 0.0477, 0.0329, 0.0963, 0.0065, 0.0900, 0.0010, 0.2336,
        0.1084, 0.1590, 0.1391, 0.0785], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,711][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.0009, 0.0291, 0.0966, 0.0569, 0.1510, 0.0084, 0.1014, 0.0030, 0.1545,
        0.1382, 0.0623, 0.1444, 0.0533], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,716][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0146, 0.0115, 0.0408, 0.1102, 0.0223, 0.0320, 0.1672, 0.0389, 0.1064,
        0.1005, 0.1126, 0.1231, 0.1198], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,718][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.0349, 0.0520, 0.0047, 0.0440, 0.0186, 0.0235, 0.1023, 0.0153, 0.1265,
        0.0966, 0.0972, 0.2888, 0.0956], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,719][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.0005, 0.0088, 0.0866, 0.0429, 0.0676, 0.0037, 0.1306, 0.0007, 0.2220,
        0.1138, 0.1179, 0.1591, 0.0458], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,720][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0018, 0.0192, 0.1329, 0.0303, 0.2219, 0.0115, 0.0660, 0.0042, 0.1112,
        0.0610, 0.0900, 0.1406, 0.1093], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,722][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.0010, 0.0140, 0.0443, 0.0323, 0.0762, 0.0116, 0.1350, 0.0023, 0.1952,
        0.1246, 0.1531, 0.1348, 0.0756], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,725][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.0549, 0.0143, 0.0019, 0.0367, 0.0132, 0.0126, 0.0637, 0.0249, 0.1351,
        0.1812, 0.1497, 0.2098, 0.1021], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,729][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.4011, 0.0457, 0.1100, 0.0236, 0.0688, 0.0344, 0.0630, 0.0273, 0.0100,
        0.1246, 0.0143, 0.0113, 0.0659], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,733][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.0007, 0.0069, 0.0518, 0.0351, 0.0605, 0.0411, 0.0744, 0.0145, 0.0851,
        0.2015, 0.1025, 0.1477, 0.1783], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:38,735][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0016, 0.0052, 0.0461, 0.0169, 0.0522, 0.0016, 0.0617, 0.0016, 0.1518,
        0.1287, 0.1151, 0.1588, 0.1290, 0.1298], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,736][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0015, 0.0123, 0.0641, 0.0187, 0.2070, 0.0011, 0.0996, 0.0004, 0.1072,
        0.0822, 0.0953, 0.1427, 0.0665, 0.1013], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,737][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0016, 0.0076, 0.0474, 0.0296, 0.0995, 0.0144, 0.0783, 0.0040, 0.1779,
        0.1003, 0.1300, 0.1152, 0.0838, 0.1105], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,738][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0025, 0.0312, 0.0623, 0.0576, 0.1274, 0.0161, 0.1080, 0.0096, 0.1390,
        0.1293, 0.0595, 0.1074, 0.0569, 0.0932], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,740][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0200, 0.0216, 0.0417, 0.1244, 0.0244, 0.0385, 0.1416, 0.0403, 0.0908,
        0.0817, 0.0985, 0.1026, 0.0697, 0.1044], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,743][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0694, 0.0793, 0.0062, 0.0522, 0.0211, 0.0415, 0.1096, 0.0200, 0.1075,
        0.0621, 0.0642, 0.1755, 0.0498, 0.1417], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,747][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0004, 0.0085, 0.0523, 0.0318, 0.0567, 0.0039, 0.1132, 0.0008, 0.2132,
        0.1026, 0.0942, 0.1357, 0.0349, 0.1518], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,751][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0025, 0.0283, 0.1155, 0.0302, 0.1812, 0.0153, 0.0564, 0.0057, 0.1022,
        0.0510, 0.0753, 0.1186, 0.0888, 0.1290], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,753][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0019, 0.0153, 0.0363, 0.0278, 0.0875, 0.0201, 0.1307, 0.0070, 0.1410,
        0.1276, 0.1254, 0.0969, 0.0722, 0.1102], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,754][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.1541, 0.0247, 0.0026, 0.0488, 0.0141, 0.0277, 0.0667, 0.0410, 0.1333,
        0.1387, 0.0952, 0.1125, 0.0434, 0.0971], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,755][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.5838, 0.0355, 0.0568, 0.0133, 0.0425, 0.0369, 0.0369, 0.0437, 0.0056,
        0.0717, 0.0083, 0.0070, 0.0460, 0.0118], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,756][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0015, 0.0081, 0.0407, 0.0295, 0.0543, 0.0550, 0.0499, 0.0313, 0.0674,
        0.1935, 0.0849, 0.1029, 0.1622, 0.1189], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:38,758][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.0014, 0.0028, 0.0302, 0.0099, 0.0284, 0.0013, 0.0374, 0.0012, 0.0923,
        0.0996, 0.0728, 0.1103, 0.0953, 0.0682, 0.3489], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,761][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0012, 0.0125, 0.0475, 0.0168, 0.1634, 0.0012, 0.1039, 0.0003, 0.0963,
        0.0684, 0.0956, 0.1418, 0.0608, 0.0885, 0.1018], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,765][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.0007, 0.0074, 0.0464, 0.0275, 0.0854, 0.0098, 0.0655, 0.0023, 0.1663,
        0.0874, 0.0976, 0.0990, 0.0700, 0.0877, 0.1468], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,769][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.0017, 0.0339, 0.0650, 0.0616, 0.1075, 0.0133, 0.0924, 0.0064, 0.1112,
        0.1164, 0.0457, 0.1068, 0.0538, 0.0826, 0.1017], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,771][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.0132, 0.0144, 0.0310, 0.0953, 0.0204, 0.0256, 0.1061, 0.0326, 0.0786,
        0.0721, 0.0801, 0.0839, 0.0839, 0.1054, 0.1575], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,772][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.0228, 0.0437, 0.0030, 0.0328, 0.0167, 0.0152, 0.0633, 0.0145, 0.0789,
        0.0661, 0.0684, 0.2144, 0.0677, 0.2691, 0.0234], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,773][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.0005, 0.0093, 0.0659, 0.0273, 0.0521, 0.0034, 0.0944, 0.0007, 0.1482,
        0.1055, 0.0775, 0.1000, 0.0385, 0.0971, 0.1796], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,775][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.0028, 0.0280, 0.0976, 0.0333, 0.1614, 0.0170, 0.0609, 0.0066, 0.0915,
        0.0420, 0.0931, 0.1141, 0.0696, 0.1113, 0.0708], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,778][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.0025, 0.0208, 0.0450, 0.0320, 0.0865, 0.0172, 0.1094, 0.0068, 0.1189,
        0.1235, 0.1085, 0.0720, 0.0857, 0.0994, 0.0719], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,782][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.1067, 0.0084, 0.0010, 0.0246, 0.0109, 0.0219, 0.0370, 0.0760, 0.0717,
        0.1306, 0.0787, 0.1673, 0.0829, 0.1592, 0.0231], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,786][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.4060, 0.0376, 0.0596, 0.0177, 0.0551, 0.0548, 0.0552, 0.0514, 0.0099,
        0.1092, 0.0144, 0.0117, 0.0831, 0.0239, 0.0105], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,788][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.0031, 0.0076, 0.0329, 0.0230, 0.0455, 0.0463, 0.0331, 0.0329, 0.0486,
        0.2023, 0.0668, 0.0776, 0.1679, 0.1010, 0.1113], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:38,789][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([3.0057e-05, 3.8345e-04, 1.5762e-02, 2.8899e-03, 1.2281e-02, 1.4639e-04,
        1.7998e-02, 5.1560e-05, 6.7288e-02, 6.5356e-02, 4.9426e-02, 6.2377e-02,
        5.0724e-02, 5.7125e-02, 5.9781e-01, 3.4770e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,790][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([2.7452e-06, 2.3136e-03, 2.5908e-02, 5.1996e-03, 1.4004e-01, 1.8668e-05,
        8.3079e-02, 7.5148e-07, 1.5658e-01, 3.1630e-02, 1.4353e-01, 1.2782e-01,
        2.3610e-02, 1.0654e-01, 1.5372e-01, 1.0132e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,791][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([2.6851e-05, 3.3805e-03, 4.1284e-02, 1.5990e-02, 5.8402e-02, 9.4230e-04,
        7.1460e-02, 6.4494e-05, 2.0238e-01, 5.5305e-02, 1.3197e-01, 1.0379e-01,
        3.5579e-02, 1.0010e-01, 1.7901e-01, 3.2243e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,793][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0004, 0.0188, 0.0713, 0.0445, 0.1308, 0.0044, 0.0804, 0.0011, 0.1018,
        0.1036, 0.0540, 0.0966, 0.0529, 0.0797, 0.1538, 0.0059],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,797][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0162, 0.0099, 0.0548, 0.0821, 0.0169, 0.0254, 0.0868, 0.0401, 0.0400,
        0.0440, 0.0688, 0.0724, 0.0688, 0.0845, 0.2487, 0.0405],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,800][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0202, 0.0532, 0.0052, 0.0400, 0.0202, 0.0145, 0.0975, 0.0053, 0.1144,
        0.0753, 0.0808, 0.2074, 0.0614, 0.1684, 0.0171, 0.0190],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,802][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([1.0560e-04, 7.4683e-03, 5.6297e-02, 2.0185e-02, 3.5770e-02, 5.9311e-04,
        7.8857e-02, 7.0092e-05, 1.6257e-01, 8.9545e-02, 8.8182e-02, 1.0460e-01,
        2.2986e-02, 1.0688e-01, 2.2576e-01, 1.2304e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,806][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0026, 0.0248, 0.2428, 0.0251, 0.3117, 0.0090, 0.0346, 0.0040, 0.0473,
        0.0319, 0.0405, 0.0578, 0.0480, 0.0493, 0.0571, 0.0136],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,807][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([1.5174e-04, 1.1163e-02, 2.1084e-02, 2.1633e-02, 5.0017e-02, 1.4640e-03,
        1.2217e-01, 1.4603e-04, 1.9659e-01, 5.3602e-02, 1.7196e-01, 1.2409e-01,
        3.1557e-02, 1.3028e-01, 6.2928e-02, 1.1718e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,808][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0091, 0.0108, 0.0012, 0.0303, 0.0112, 0.0027, 0.0709, 0.0026, 0.1377,
        0.1717, 0.1228, 0.1589, 0.0581, 0.1774, 0.0115, 0.0229],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,809][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.1142, 0.0642, 0.1853, 0.0224, 0.1263, 0.0192, 0.1336, 0.0048, 0.0081,
        0.1698, 0.0169, 0.0118, 0.0616, 0.0223, 0.0080, 0.0316],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,810][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([2.7862e-05, 4.7141e-03, 6.9817e-02, 2.8148e-02, 6.8927e-02, 6.0961e-03,
        8.9137e-02, 4.8286e-04, 7.3508e-02, 9.9531e-02, 8.4317e-02, 1.5257e-01,
        8.1409e-02, 1.0033e-01, 1.3825e-01, 2.7329e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:38,813][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([2.8224e-04, 6.9499e-04, 2.1017e-02, 4.2592e-03, 1.7768e-02, 4.5108e-04,
        2.1638e-02, 3.4554e-04, 7.9265e-02, 7.8419e-02, 5.7881e-02, 7.5502e-02,
        7.5857e-02, 5.8026e-02, 4.9511e-01, 1.5129e-03, 1.1966e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,815][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([4.3498e-05, 2.8050e-03, 4.7321e-02, 8.0304e-03, 1.5705e-01, 1.7400e-04,
        7.5710e-02, 1.8259e-05, 1.2444e-01, 5.4879e-02, 1.0294e-01, 1.4105e-01,
        3.4873e-02, 8.3353e-02, 1.5969e-01, 1.6842e-04, 7.4437e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,819][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0002, 0.0037, 0.0450, 0.0193, 0.0727, 0.0042, 0.0568, 0.0006, 0.1918,
        0.0716, 0.1155, 0.0947, 0.0528, 0.0896, 0.1536, 0.0029, 0.0249],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,824][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0004, 0.0131, 0.0530, 0.0456, 0.0957, 0.0098, 0.0823, 0.0026, 0.1283,
        0.1180, 0.0473, 0.1014, 0.0485, 0.0698, 0.1237, 0.0119, 0.0486],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,825][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0089, 0.0058, 0.0211, 0.0645, 0.0097, 0.0295, 0.0724, 0.0331, 0.0446,
        0.0447, 0.0504, 0.0460, 0.0558, 0.0565, 0.1150, 0.0495, 0.2928],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,826][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0530, 0.0768, 0.0061, 0.0498, 0.0228, 0.0307, 0.0869, 0.0113, 0.0885,
        0.0508, 0.0578, 0.1494, 0.0414, 0.1292, 0.0094, 0.0198, 0.1164],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,827][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.5854e-04, 4.6730e-03, 5.5911e-02, 2.4268e-02, 4.0979e-02, 1.8364e-03,
        8.4903e-02, 2.5036e-04, 1.6803e-01, 9.2957e-02, 8.3972e-02, 9.8521e-02,
        2.5915e-02, 8.9495e-02, 2.0610e-01, 4.9615e-04, 2.1527e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,829][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0019, 0.0183, 0.1654, 0.0250, 0.1785, 0.0132, 0.0402, 0.0047, 0.0675,
        0.0408, 0.0569, 0.0889, 0.0689, 0.0775, 0.0898, 0.0205, 0.0419],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,832][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0004, 0.0094, 0.0263, 0.0261, 0.0528, 0.0076, 0.1284, 0.0011, 0.1665,
        0.0873, 0.1295, 0.1072, 0.0403, 0.0960, 0.0637, 0.0073, 0.0501],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,835][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1975, 0.0186, 0.0020, 0.0442, 0.0132, 0.0130, 0.0462, 0.0255, 0.0748,
        0.1066, 0.0663, 0.0668, 0.0364, 0.0701, 0.0051, 0.0695, 0.1443],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,839][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2403, 0.0356, 0.1387, 0.0155, 0.0750, 0.0295, 0.0608, 0.0144, 0.0067,
        0.1336, 0.0119, 0.0092, 0.0557, 0.0171, 0.0072, 0.0877, 0.0611],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,842][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0008, 0.0017, 0.0243, 0.0128, 0.0275, 0.0490, 0.0235, 0.0293, 0.0311,
        0.1135, 0.0442, 0.0468, 0.1379, 0.0569, 0.0948, 0.0872, 0.2187],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:38,843][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([0.0013, 0.0032, 0.0323, 0.0103, 0.0353, 0.0009, 0.0423, 0.0008, 0.0819,
        0.0907, 0.0663, 0.0943, 0.0738, 0.0704, 0.3229, 0.0017, 0.0122, 0.0593],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,844][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([0.0009, 0.0121, 0.0608, 0.0181, 0.1917, 0.0009, 0.0928, 0.0002, 0.0895,
        0.0716, 0.0851, 0.1186, 0.0513, 0.0762, 0.0729, 0.0009, 0.0099, 0.0465],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,845][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([0.0005, 0.0044, 0.0336, 0.0191, 0.0714, 0.0072, 0.0584, 0.0017, 0.1459,
        0.0858, 0.0847, 0.0897, 0.0582, 0.0808, 0.1281, 0.0058, 0.0320, 0.0927],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,847][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([0.0008, 0.0227, 0.0508, 0.0513, 0.0970, 0.0076, 0.0924, 0.0026, 0.1114,
        0.1061, 0.0430, 0.0927, 0.0376, 0.0787, 0.0894, 0.0070, 0.0347, 0.0744],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,850][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([0.0052, 0.0065, 0.0136, 0.0570, 0.0111, 0.0150, 0.0855, 0.0128, 0.0607,
        0.0588, 0.0685, 0.0639, 0.0523, 0.0812, 0.0958, 0.0279, 0.1992, 0.0851],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,853][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([0.0277, 0.0546, 0.0030, 0.0358, 0.0134, 0.0182, 0.0745, 0.0111, 0.0895,
        0.0561, 0.0629, 0.1539, 0.0360, 0.1654, 0.0112, 0.0230, 0.1346, 0.0291],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,857][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([0.0004, 0.0054, 0.0382, 0.0215, 0.0359, 0.0022, 0.0768, 0.0004, 0.1328,
        0.0776, 0.0668, 0.0952, 0.0229, 0.0847, 0.1106, 0.0007, 0.0235, 0.2044],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,860][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([0.0033, 0.0245, 0.0686, 0.0298, 0.1219, 0.0130, 0.0521, 0.0051, 0.0873,
        0.0442, 0.0901, 0.1151, 0.0658, 0.1142, 0.0512, 0.0157, 0.0360, 0.0620],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,860][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([0.0012, 0.0133, 0.0272, 0.0233, 0.0460, 0.0110, 0.1081, 0.0028, 0.1202,
        0.1043, 0.1026, 0.0755, 0.0550, 0.0912, 0.0580, 0.0144, 0.0493, 0.0967],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,861][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([0.0820, 0.0092, 0.0011, 0.0200, 0.0070, 0.0193, 0.0348, 0.0369, 0.0670,
        0.0869, 0.0522, 0.0794, 0.0307, 0.0804, 0.0088, 0.1244, 0.2260, 0.0339],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,862][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([0.2089, 0.0381, 0.0673, 0.0189, 0.0620, 0.0349, 0.0569, 0.0254, 0.0124,
        0.1166, 0.0161, 0.0123, 0.0761, 0.0277, 0.0101, 0.0964, 0.0755, 0.0445],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,864][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([0.0012, 0.0038, 0.0229, 0.0143, 0.0332, 0.0466, 0.0355, 0.0318, 0.0416,
        0.1358, 0.0378, 0.0479, 0.1342, 0.0726, 0.0726, 0.0520, 0.1440, 0.0724],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:38,868][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0009, 0.0018, 0.0283, 0.0064, 0.0214, 0.0008, 0.0250, 0.0007, 0.0824,
        0.0649, 0.0542, 0.0721, 0.0626, 0.0495, 0.3339, 0.0020, 0.0120, 0.0464,
        0.1348], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,871][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0007, 0.0076, 0.0567, 0.0142, 0.1436, 0.0009, 0.0702, 0.0002, 0.0917,
        0.0554, 0.0706, 0.1106, 0.0400, 0.0635, 0.0800, 0.0009, 0.0123, 0.0555,
        0.1255], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,875][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0006, 0.0033, 0.0267, 0.0150, 0.0474, 0.0078, 0.0374, 0.0020, 0.1225,
        0.0555, 0.0751, 0.0694, 0.0518, 0.0643, 0.1087, 0.0081, 0.0353, 0.0787,
        0.1905], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,877][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0015, 0.0200, 0.0512, 0.0492, 0.0786, 0.0122, 0.0710, 0.0052, 0.1014,
        0.0979, 0.0425, 0.0845, 0.0392, 0.0565, 0.0933, 0.0146, 0.0411, 0.0698,
        0.0704], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,878][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0098, 0.0102, 0.0226, 0.0586, 0.0119, 0.0187, 0.0739, 0.0157, 0.0519,
        0.0435, 0.0521, 0.0551, 0.0378, 0.0524, 0.0660, 0.0285, 0.1579, 0.0776,
        0.1558], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,879][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0471, 0.0604, 0.0048, 0.0399, 0.0156, 0.0376, 0.0675, 0.0169, 0.0784,
        0.0447, 0.0503, 0.1269, 0.0346, 0.1139, 0.0095, 0.0255, 0.1045, 0.0234,
        0.0985], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,881][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0004, 0.0042, 0.0411, 0.0158, 0.0327, 0.0022, 0.0538, 0.0004, 0.1211,
        0.0535, 0.0488, 0.0643, 0.0172, 0.0599, 0.1188, 0.0010, 0.0230, 0.1768,
        0.1650], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,884][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0017, 0.0196, 0.0767, 0.0207, 0.1064, 0.0118, 0.0372, 0.0035, 0.0886,
        0.0393, 0.0646, 0.0998, 0.0665, 0.0970, 0.0693, 0.0162, 0.0390, 0.0492,
        0.0929], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,888][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0009, 0.0106, 0.0228, 0.0229, 0.0512, 0.0107, 0.0956, 0.0025, 0.1233,
        0.0837, 0.0955, 0.0787, 0.0399, 0.0733, 0.0508, 0.0158, 0.0598, 0.0665,
        0.0955], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,892][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.2915, 0.0148, 0.0016, 0.0300, 0.0089, 0.0306, 0.0295, 0.0657, 0.0515,
        0.0563, 0.0387, 0.0480, 0.0220, 0.0392, 0.0040, 0.0798, 0.1155, 0.0168,
        0.0558], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,895][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2330, 0.0322, 0.1041, 0.0156, 0.0575, 0.0341, 0.0481, 0.0230, 0.0104,
        0.0853, 0.0121, 0.0101, 0.0539, 0.0169, 0.0088, 0.0967, 0.0678, 0.0373,
        0.0531], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,896][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0028, 0.0026, 0.0159, 0.0109, 0.0161, 0.0594, 0.0124, 0.0692, 0.0203,
        0.0665, 0.0329, 0.0314, 0.1043, 0.0456, 0.0498, 0.1441, 0.1560, 0.0386,
        0.1213], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:38,899][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:38,902][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[6548],
        [  10],
        [   1],
        [  29],
        [   1],
        [ 143],
        [ 231],
        [ 172],
        [   1],
        [  41],
        [   6],
        [  23],
        [   1],
        [   1],
        [   1],
        [ 143],
        [  73],
        [   2],
        [   1]], device='cuda:0')
[2024-07-24 10:27:38,905][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[5723],
        [   7],
        [   2],
        [  16],
        [   1],
        [  14],
        [  86],
        [  12],
        [   2],
        [  37],
        [   3],
        [  15],
        [   1],
        [   1],
        [   1],
        [  18],
        [  26],
        [   2],
        [   1]], device='cuda:0')
[2024-07-24 10:27:38,907][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[21161],
        [14445],
        [32323],
        [32500],
        [49855],
        [49888],
        [48856],
        [48644],
        [42711],
        [37288],
        [30303],
        [23218],
        [21825],
        [22729],
        [29700],
        [33874],
        [32101],
        [30300],
        [27102]], device='cuda:0')
[2024-07-24 10:27:38,910][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[33402],
        [27978],
        [10561],
        [10890],
        [19791],
        [22105],
        [16558],
        [16147],
        [14555],
        [13625],
        [12788],
        [12197],
        [12279],
        [12071],
        [10832],
        [10062],
        [10241],
        [11263],
        [10427]], device='cuda:0')
[2024-07-24 10:27:38,913][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[48210],
        [38201],
        [46636],
        [45131],
        [49518],
        [49572],
        [49036],
        [48777],
        [46054],
        [45263],
        [44989],
        [44100],
        [44288],
        [44897],
        [45141],
        [44103],
        [44638],
        [44037],
        [43458]], device='cuda:0')
[2024-07-24 10:27:38,915][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 9422],
        [40309],
        [43159],
        [43663],
        [47570],
        [47833],
        [47412],
        [47613],
        [47384],
        [47399],
        [47334],
        [47373],
        [47722],
        [47744],
        [47593],
        [47722],
        [47495],
        [47325],
        [47245]], device='cuda:0')
[2024-07-24 10:27:38,917][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[24047],
        [37297],
        [39258],
        [40819],
        [41830],
        [41406],
        [43701],
        [43057],
        [42699],
        [42774],
        [42327],
        [43514],
        [42541],
        [42926],
        [41335],
        [40154],
        [40682],
        [41520],
        [41288]], device='cuda:0')
[2024-07-24 10:27:38,918][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[32841],
        [41537],
        [42351],
        [43162],
        [43394],
        [42100],
        [41001],
        [42188],
        [40404],
        [40920],
        [40795],
        [40254],
        [39314],
        [39058],
        [38271],
        [38839],
        [38754],
        [38312],
        [38266]], device='cuda:0')
[2024-07-24 10:27:38,920][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[16601],
        [30564],
        [16339],
        [17061],
        [38206],
        [37470],
        [33675],
        [33032],
        [26011],
        [23339],
        [19610],
        [18172],
        [17866],
        [18107],
        [17850],
        [16617],
        [17021],
        [20211],
        [19232]], device='cuda:0')
[2024-07-24 10:27:38,923][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[31543],
        [31553],
        [27353],
        [27316],
        [  395],
        [  526],
        [ 1491],
        [  466],
        [ 4519],
        [ 3619],
        [ 4654],
        [ 9185],
        [ 4623],
        [ 6526],
        [ 7400],
        [ 1603],
        [ 6767],
        [11523],
        [13109]], device='cuda:0')
[2024-07-24 10:27:38,925][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[15434],
        [29240],
        [18114],
        [16968],
        [12814],
        [11811],
        [12201],
        [12158],
        [11437],
        [11648],
        [10116],
        [ 9888],
        [ 9639],
        [10042],
        [10141],
        [ 9293],
        [ 9619],
        [ 9780],
        [ 9797]], device='cuda:0')
[2024-07-24 10:27:38,928][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[34485],
        [45247],
        [41681],
        [43622],
        [43521],
        [44399],
        [43984],
        [44860],
        [43385],
        [44198],
        [43529],
        [43403],
        [43289],
        [43439],
        [43561],
        [43047],
        [43811],
        [44220],
        [44227]], device='cuda:0')
[2024-07-24 10:27:38,931][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[13662],
        [14309],
        [25899],
        [25039],
        [35691],
        [38995],
        [33479],
        [39347],
        [25673],
        [25486],
        [23578],
        [25341],
        [25326],
        [22223],
        [21731],
        [29143],
        [23700],
        [18769],
        [19494]], device='cuda:0')
[2024-07-24 10:27:38,933][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[19841],
        [29036],
        [31558],
        [32277],
        [36453],
        [37965],
        [39946],
        [39970],
        [39606],
        [41268],
        [42261],
        [43003],
        [43744],
        [43933],
        [44208],
        [45035],
        [44805],
        [44522],
        [45088]], device='cuda:0')
[2024-07-24 10:27:38,936][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[18694],
        [22020],
        [12611],
        [23562],
        [14359],
        [21122],
        [22386],
        [18186],
        [10476],
        [12221],
        [17041],
        [15598],
        [17277],
        [17125],
        [10664],
        [20986],
        [19707],
        [11415],
        [12457]], device='cuda:0')
[2024-07-24 10:27:38,938][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 7919],
        [24490],
        [10053],
        [ 9498],
        [14783],
        [14415],
        [13827],
        [13052],
        [13138],
        [12530],
        [13311],
        [13603],
        [12938],
        [13323],
        [12573],
        [12494],
        [12424],
        [12491],
        [12146]], device='cuda:0')
[2024-07-24 10:27:38,939][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[44120],
        [30984],
        [29697],
        [30274],
        [42674],
        [43664],
        [42578],
        [42813],
        [42033],
        [40665],
        [39875],
        [39799],
        [39712],
        [38988],
        [38873],
        [38690],
        [38991],
        [39018],
        [38770]], device='cuda:0')
[2024-07-24 10:27:38,941][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[30959],
        [14418],
        [13316],
        [11973],
        [13981],
        [13916],
        [12671],
        [12560],
        [17894],
        [19235],
        [16868],
        [17159],
        [17486],
        [16574],
        [16366],
        [16480],
        [16272],
        [16755],
        [18051]], device='cuda:0')
[2024-07-24 10:27:38,943][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[39000],
        [28672],
        [29976],
        [30410],
        [29017],
        [29448],
        [29621],
        [29363],
        [29650],
        [29476],
        [28909],
        [28898],
        [28303],
        [27787],
        [27896],
        [28134],
        [27885],
        [27286],
        [26947]], device='cuda:0')
[2024-07-24 10:27:38,946][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[19498],
        [23810],
        [20089],
        [32434],
        [32023],
        [27427],
        [32691],
        [29646],
        [32670],
        [32965],
        [32767],
        [32369],
        [33701],
        [34186],
        [34437],
        [34144],
        [33650],
        [33207],
        [32717]], device='cuda:0')
[2024-07-24 10:27:38,949][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[21506],
        [32591],
        [34826],
        [35201],
        [36305],
        [35859],
        [35437],
        [36808],
        [35129],
        [35556],
        [35465],
        [35093],
        [34584],
        [34919],
        [34865],
        [35069],
        [34730],
        [34837],
        [34948]], device='cuda:0')
[2024-07-24 10:27:38,951][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[13436],
        [ 9810],
        [ 9187],
        [10336],
        [10369],
        [10381],
        [13360],
        [13001],
        [16881],
        [17111],
        [18394],
        [18483],
        [18150],
        [18121],
        [15788],
        [15928],
        [15883],
        [12602],
        [11369]], device='cuda:0')
[2024-07-24 10:27:38,954][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[27895],
        [22071],
        [17556],
        [15501],
        [15853],
        [15419],
        [13451],
        [15150],
        [13064],
        [12031],
        [11639],
        [10609],
        [10216],
        [10651],
        [10828],
        [12337],
        [11047],
        [10674],
        [10599]], device='cuda:0')
[2024-07-24 10:27:38,957][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[34239],
        [36108],
        [31688],
        [31353],
        [33040],
        [33335],
        [31297],
        [32047],
        [30374],
        [32013],
        [32615],
        [32327],
        [32229],
        [32413],
        [32398],
        [31760],
        [31854],
        [32032],
        [31891]], device='cuda:0')
[2024-07-24 10:27:38,958][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[36581],
        [27264],
        [28488],
        [27168],
        [25399],
        [23864],
        [27969],
        [26363],
        [33492],
        [27275],
        [27859],
        [28745],
        [29609],
        [28480],
        [29508],
        [28886],
        [28602],
        [28708],
        [28121]], device='cuda:0')
[2024-07-24 10:27:38,960][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[30449],
        [26610],
        [25901],
        [26158],
        [25386],
        [23382],
        [23909],
        [19480],
        [26884],
        [20758],
        [23902],
        [22051],
        [21689],
        [23674],
        [22028],
        [19664],
        [20559],
        [21616],
        [21741]], device='cuda:0')
[2024-07-24 10:27:38,962][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[34495],
        [ 8719],
        [ 5886],
        [ 4932],
        [ 6753],
        [ 7630],
        [ 9317],
        [ 5939],
        [16326],
        [11076],
        [12220],
        [11296],
        [10652],
        [11201],
        [12214],
        [10591],
        [11679],
        [11024],
        [11358]], device='cuda:0')
[2024-07-24 10:27:38,964][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 3473],
        [16710],
        [23486],
        [23197],
        [17083],
        [17798],
        [15582],
        [19713],
        [10333],
        [14812],
        [13469],
        [14556],
        [15386],
        [14902],
        [15534],
        [16387],
        [15962],
        [17473],
        [17689]], device='cuda:0')
[2024-07-24 10:27:38,967][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[21110],
        [13366],
        [18239],
        [12494],
        [16515],
        [ 9592],
        [11659],
        [15317],
        [23931],
        [18961],
        [16265],
        [15953],
        [14737],
        [14142],
        [17846],
        [13047],
        [11261],
        [15456],
        [18220]], device='cuda:0')
[2024-07-24 10:27:38,969][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113]], device='cuda:0')
[2024-07-24 10:27:39,099][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:39,099][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,100][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,101][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,102][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,103][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,103][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,104][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,105][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,105][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,106][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,107][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,107][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,108][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3472, 0.6528], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,109][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.6667, 0.3333], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,110][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2186, 0.7814], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,110][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.8068, 0.1932], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,112][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0535, 0.9465], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,114][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1575, 0.8425], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,114][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2557, 0.7443], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,115][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1312, 0.8688], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,116][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3530, 0.6470], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,117][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.6815, 0.3185], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,117][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4810, 0.5190], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,118][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.7446, 0.2554], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,119][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.2126, 0.2985, 0.4889], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,120][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.5944, 0.0866, 0.3191], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,120][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.0029, 0.0169, 0.9801], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,125][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.2932, 0.0268, 0.6800], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,129][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.0012, 0.0732, 0.9256], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,131][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.0222, 0.0816, 0.8961], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,132][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.0098, 0.0537, 0.9365], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,133][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.0059, 0.0696, 0.9245], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,134][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.2306, 0.7213, 0.0481], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,135][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.1746, 0.0339, 0.7916], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,138][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.3998, 0.1562, 0.4441], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,142][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.8146, 0.0535, 0.1319], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,147][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2019, 0.2780, 0.4068, 0.1134], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,149][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.4406, 0.0786, 0.3252, 0.1556], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,150][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0041, 0.0187, 0.6914, 0.2858], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,150][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5916, 0.0222, 0.3134, 0.0729], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,151][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0012, 0.0320, 0.5192, 0.4477], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,153][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0043, 0.0202, 0.6320, 0.3435], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,156][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0154, 0.0592, 0.5646, 0.3609], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,160][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0046, 0.0667, 0.4302, 0.4985], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,163][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([4.8254e-04, 1.6204e-01, 8.2917e-01, 8.3110e-03], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,166][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1456, 0.0250, 0.7926, 0.0367], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,167][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.3337, 0.1389, 0.2391, 0.2884], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,168][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.5873, 0.0332, 0.0555, 0.3240], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,169][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.2702, 0.3139, 0.2777, 0.0965, 0.0417], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,169][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([0.1434, 0.0785, 0.2699, 0.1868, 0.3214], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,172][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.0019, 0.0105, 0.4059, 0.3342, 0.2475], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,175][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.2310, 0.0248, 0.3035, 0.0996, 0.3411], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,177][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([9.6472e-05, 1.3033e-02, 2.2027e-01, 2.2760e-01, 5.3900e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,181][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([0.0026, 0.0274, 0.2719, 0.3381, 0.3601], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,185][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.0094, 0.0708, 0.4870, 0.3555, 0.0772], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,185][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.0007, 0.0167, 0.2553, 0.2395, 0.4879], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,186][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.0021, 0.4634, 0.4585, 0.0359, 0.0400], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,187][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.1128, 0.0378, 0.6458, 0.1164, 0.0872], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,189][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.2468, 0.1117, 0.1854, 0.3102, 0.1459], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,191][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([0.0783, 0.0272, 0.0950, 0.6986, 0.1010], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,196][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0704, 0.1034, 0.5443, 0.1401, 0.0709, 0.0710], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,200][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.4768, 0.0365, 0.2020, 0.0565, 0.0505, 0.1777], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,202][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0449, 0.0658, 0.2665, 0.3680, 0.1282, 0.1267], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,203][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.4336, 0.0169, 0.1926, 0.0344, 0.0812, 0.2413], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,204][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0005, 0.0122, 0.1061, 0.2016, 0.2477, 0.4320], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,205][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0020, 0.0046, 0.5092, 0.2791, 0.1663, 0.0389], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,207][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0050, 0.0447, 0.1939, 0.3572, 0.0890, 0.3102], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,210][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0048, 0.0838, 0.1863, 0.3382, 0.1948, 0.1921], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,213][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ had] are: tensor([4.5272e-06, 1.8190e-02, 9.7358e-01, 1.0319e-03, 7.1861e-03, 1.0294e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,216][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0541, 0.0095, 0.7207, 0.0348, 0.1415, 0.0394], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,220][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0032, 0.0518, 0.1801, 0.1340, 0.4515, 0.1794], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,221][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ had] are: tensor([3.9681e-01, 3.4720e-03, 5.2058e-04, 3.9498e-03, 5.6702e-04, 5.9468e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,221][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1604, 0.1564, 0.4021, 0.0768, 0.0410, 0.1144, 0.0489],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,222][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0954, 0.0355, 0.2162, 0.1632, 0.2194, 0.1490, 0.1213],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,224][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0013, 0.0098, 0.4389, 0.3469, 0.1164, 0.0130, 0.0738],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,227][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2268, 0.0128, 0.2827, 0.0570, 0.1811, 0.1444, 0.0953],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,229][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([8.5958e-05, 5.2779e-03, 1.2493e-01, 1.0429e-01, 1.9552e-01, 4.7204e-02,
        5.2270e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,233][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0007, 0.0069, 0.2340, 0.2920, 0.1674, 0.0452, 0.2537],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,238][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0017, 0.0176, 0.2225, 0.2690, 0.0486, 0.1147, 0.3260],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,238][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0004, 0.0122, 0.1036, 0.2151, 0.2922, 0.0595, 0.3170],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,239][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([7.0812e-04, 2.2142e-01, 7.2777e-01, 1.2212e-02, 2.4081e-02, 2.8336e-04,
        1.3523e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,240][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0184, 0.0086, 0.7394, 0.0533, 0.0653, 0.0645, 0.0505],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,242][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0612, 0.0791, 0.1612, 0.2490, 0.2770, 0.1142, 0.0583],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,245][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0181, 0.0020, 0.0075, 0.0592, 0.0078, 0.6078, 0.2976],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,249][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0551, 0.0752, 0.4537, 0.0993, 0.0693, 0.0535, 0.0392, 0.1546],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,253][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0902, 0.0157, 0.0808, 0.0362, 0.0165, 0.1125, 0.1132, 0.5349],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,255][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0637, 0.1399, 0.0853, 0.2934, 0.0625, 0.1009, 0.1551, 0.0992],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,256][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.1992, 0.0129, 0.0975, 0.0328, 0.0589, 0.2172, 0.2609, 0.1205],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,257][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([1.9763e-04, 2.6500e-03, 1.0315e-02, 2.8985e-02, 3.1006e-02, 9.8172e-02,
        7.9741e-01, 3.1269e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,258][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0034, 0.0034, 0.4267, 0.2898, 0.0954, 0.0228, 0.1334, 0.0252],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,260][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0015, 0.0131, 0.0242, 0.0775, 0.0345, 0.0591, 0.5497, 0.2405],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,263][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0067, 0.0924, 0.0936, 0.2039, 0.0939, 0.1721, 0.1210, 0.2165],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,265][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([3.2576e-06, 1.5026e-02, 9.7594e-01, 1.2206e-03, 6.9994e-03, 9.0739e-06,
        7.9699e-04, 4.6534e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,269][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0032, 0.0023, 0.5575, 0.0442, 0.2238, 0.0143, 0.0699, 0.0846],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,271][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([1.3089e-04, 1.6273e-02, 9.2690e-02, 7.3990e-02, 4.5455e-01, 6.1624e-02,
        2.6255e-01, 3.8185e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,274][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([2.0086e-01, 3.5337e-03, 1.9495e-04, 2.5296e-03, 3.2317e-04, 1.9260e-01,
        1.1109e-02, 5.8885e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,274][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.1551, 0.0932, 0.2826, 0.0461, 0.0311, 0.1035, 0.0366, 0.2418, 0.0099],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,275][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.1045, 0.0249, 0.0613, 0.1061, 0.1132, 0.1886, 0.1023, 0.2206, 0.0784],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,276][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0007, 0.0053, 0.1944, 0.2047, 0.0881, 0.0074, 0.0754, 0.0024, 0.4216],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,278][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.3399, 0.0263, 0.1463, 0.0744, 0.1423, 0.0609, 0.0696, 0.0540, 0.0863],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,280][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ of] are: tensor([1.8914e-04, 3.6821e-03, 4.3600e-02, 4.2373e-02, 8.6822e-02, 1.8815e-02,
        1.7591e-01, 8.9017e-04, 6.2772e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,284][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0011, 0.0077, 0.0639, 0.1955, 0.0811, 0.0403, 0.2245, 0.0092, 0.3766],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,289][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0077, 0.0253, 0.0922, 0.1916, 0.0227, 0.0856, 0.1755, 0.0503, 0.3491],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,291][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ of] are: tensor([4.2675e-04, 4.4845e-03, 3.1628e-02, 1.0813e-01, 1.1106e-01, 4.1742e-02,
        2.2836e-01, 1.5195e-02, 4.5897e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,292][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.2003, 0.2538, 0.0334, 0.1156, 0.0555, 0.0534, 0.1388, 0.0724, 0.0769],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,293][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0403, 0.0102, 0.1707, 0.0426, 0.0211, 0.0419, 0.0522, 0.1173, 0.5037],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,294][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.4164, 0.0881, 0.0586, 0.1503, 0.0729, 0.0445, 0.0148, 0.1206, 0.0338],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,297][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0273, 0.0024, 0.0045, 0.0574, 0.0064, 0.3444, 0.2726, 0.2414, 0.0435],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,301][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0691, 0.0870, 0.3954, 0.0637, 0.0433, 0.0795, 0.0573, 0.1792, 0.0158,
        0.0099], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,304][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0337, 0.0247, 0.0499, 0.0989, 0.1394, 0.0881, 0.1286, 0.0909, 0.1167,
        0.2291], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,306][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([2.2206e-04, 3.2542e-03, 1.2829e-01, 1.6393e-01, 1.0229e-01, 7.1294e-03,
        8.7972e-02, 2.3440e-03, 3.1190e-01, 1.9267e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,308][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0762, 0.0058, 0.0647, 0.0270, 0.0798, 0.0150, 0.0255, 0.0113, 0.0290,
        0.6657], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,309][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([5.8601e-05, 2.2317e-03, 2.5272e-02, 3.8699e-02, 6.9920e-02, 1.8406e-02,
        2.3713e-01, 8.1443e-04, 4.1852e-01, 1.8894e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,310][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([1.9294e-04, 3.0630e-03, 3.5387e-02, 7.4379e-02, 7.9244e-02, 8.9964e-03,
        1.3737e-01, 1.6183e-03, 2.2052e-01, 4.3924e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,311][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0008, 0.0087, 0.0390, 0.1297, 0.0227, 0.0483, 0.1592, 0.0173, 0.2045,
        0.3697], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,312][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([5.0085e-05, 1.9162e-03, 2.5032e-02, 4.7576e-02, 1.3046e-01, 8.3144e-03,
        1.4584e-01, 1.8266e-03, 2.2083e-01, 4.1816e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,314][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0353, 0.3784, 0.1291, 0.0566, 0.0508, 0.0117, 0.0825, 0.0148, 0.1149,
        0.1258], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,317][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0051, 0.0027, 0.0849, 0.0174, 0.0163, 0.0131, 0.0210, 0.0204, 0.1462,
        0.6727], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,321][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0403, 0.0543, 0.0803, 0.1969, 0.2267, 0.0371, 0.0510, 0.0617, 0.0713,
        0.1803], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,325][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0014, 0.0014, 0.0053, 0.0531, 0.0129, 0.1593, 0.3339, 0.0505, 0.0567,
        0.3255], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,327][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.1181, 0.1066, 0.2976, 0.0684, 0.0489, 0.0802, 0.0644, 0.1761, 0.0198,
        0.0107, 0.0091], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,328][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0650, 0.0276, 0.0672, 0.0907, 0.1553, 0.0891, 0.0857, 0.0883, 0.1175,
        0.1669, 0.0469], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,329][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ at] are: tensor([3.5098e-04, 3.0404e-03, 1.4757e-01, 1.1034e-01, 6.3900e-02, 3.6512e-03,
        4.6959e-02, 1.4069e-03, 3.6577e-01, 1.7043e-01, 8.6584e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,329][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0829, 0.0070, 0.0317, 0.0224, 0.0404, 0.0090, 0.0210, 0.0087, 0.0378,
        0.5514, 0.1876], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,331][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ at] are: tensor([6.1971e-05, 1.3722e-03, 1.7977e-02, 1.9895e-02, 4.2652e-02, 1.0226e-02,
        1.1939e-01, 4.3272e-04, 3.9664e-01, 1.1963e-01, 2.7173e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,333][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ at] are: tensor([1.7565e-04, 2.1888e-03, 2.8542e-02, 4.2823e-02, 4.2384e-02, 5.2645e-03,
        7.1684e-02, 8.4993e-04, 1.5731e-01, 2.8054e-01, 3.6824e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,337][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0022, 0.0105, 0.0483, 0.0957, 0.0159, 0.0398, 0.0993, 0.0156, 0.2470,
        0.3172, 0.1086], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,339][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ at] are: tensor([7.2792e-05, 1.4842e-03, 1.5137e-02, 2.7504e-02, 6.9581e-02, 4.1478e-03,
        6.7483e-02, 1.2532e-03, 2.7594e-01, 3.1516e-01, 2.2223e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,343][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0408, 0.3912, 0.0655, 0.0824, 0.0413, 0.0154, 0.0971, 0.0163, 0.1157,
        0.0681, 0.0663], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,345][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0098, 0.0026, 0.0678, 0.0104, 0.0084, 0.0089, 0.0107, 0.0198, 0.1257,
        0.5386, 0.1973], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,345][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1104, 0.0679, 0.0624, 0.2215, 0.1202, 0.0439, 0.0361, 0.0686, 0.0847,
        0.1258, 0.0584], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,346][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0130, 0.0020, 0.0040, 0.0372, 0.0072, 0.1301, 0.2028, 0.0618, 0.0721,
        0.3147, 0.1551], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,347][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1241, 0.1107, 0.3272, 0.0534, 0.0411, 0.0782, 0.0556, 0.1708, 0.0153,
        0.0083, 0.0069, 0.0083], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,349][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0242, 0.0244, 0.0500, 0.0771, 0.1218, 0.0914, 0.0942, 0.0796, 0.1132,
        0.1810, 0.0474, 0.0957], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,351][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ the] are: tensor([1.6386e-04, 2.2344e-03, 9.6016e-02, 8.8734e-02, 4.1256e-02, 3.7308e-03,
        5.3952e-02, 1.2411e-03, 3.1102e-01, 1.6975e-01, 8.5935e-02, 1.4597e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,355][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0399, 0.0045, 0.0194, 0.0131, 0.0284, 0.0089, 0.0214, 0.0056, 0.0280,
        0.5215, 0.1892, 0.1202], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,358][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ the] are: tensor([2.6523e-05, 1.1501e-03, 1.6450e-02, 1.9888e-02, 3.6130e-02, 1.0024e-02,
        1.1398e-01, 3.5995e-04, 2.9967e-01, 8.2458e-02, 1.8980e-01, 2.3006e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,360][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ the] are: tensor([7.8206e-05, 1.2395e-03, 1.7579e-02, 3.0535e-02, 2.3742e-02, 4.3286e-03,
        6.0481e-02, 6.2847e-04, 9.2732e-02, 2.4143e-01, 2.3216e-01, 2.9507e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,363][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0014, 0.0071, 0.0290, 0.0645, 0.0111, 0.0368, 0.1107, 0.0125, 0.1913,
        0.2654, 0.0961, 0.1742], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,364][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ the] are: tensor([4.1711e-05, 1.3490e-03, 1.1685e-02, 2.4506e-02, 4.5250e-02, 6.0547e-03,
        7.7149e-02, 1.3372e-03, 1.7688e-01, 2.6013e-01, 1.9469e-01, 2.0093e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,365][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0049, 0.2784, 0.1356, 0.0359, 0.0280, 0.0024, 0.0435, 0.0021, 0.2282,
        0.1056, 0.0769, 0.0587], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,365][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0057, 0.0016, 0.0444, 0.0063, 0.0047, 0.0083, 0.0099, 0.0201, 0.0695,
        0.4517, 0.1290, 0.2489], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,367][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0810, 0.0659, 0.0426, 0.1658, 0.1444, 0.0373, 0.0413, 0.0628, 0.0942,
        0.1347, 0.0724, 0.0576], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,370][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0033, 0.0009, 0.0023, 0.0211, 0.0035, 0.1121, 0.1937, 0.0447, 0.0268,
        0.1927, 0.0652, 0.3337], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,374][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0665, 0.0869, 0.3789, 0.0650, 0.0644, 0.0571, 0.0605, 0.1355, 0.0240,
        0.0134, 0.0109, 0.0122, 0.0246], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,379][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0124, 0.0110, 0.0525, 0.0557, 0.0557, 0.0551, 0.0757, 0.0630, 0.0898,
        0.2406, 0.0395, 0.1002, 0.1488], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,381][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ store] are: tensor([2.0064e-04, 2.4792e-03, 5.0101e-02, 1.2657e-01, 5.0227e-02, 3.9448e-03,
        4.6125e-02, 1.6005e-03, 3.0112e-01, 1.7930e-01, 7.7506e-02, 1.2857e-01,
        3.2257e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,382][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0127, 0.0014, 0.0065, 0.0060, 0.0134, 0.0035, 0.0153, 0.0029, 0.0201,
        0.4947, 0.1791, 0.1360, 0.1084], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,383][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ store] are: tensor([3.0482e-05, 9.2381e-04, 9.2344e-03, 1.6398e-02, 2.4939e-02, 1.1854e-02,
        1.6390e-01, 5.7604e-04, 2.4621e-01, 1.1382e-01, 1.6498e-01, 2.2844e-01,
        1.8684e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,383][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ store] are: tensor([4.4178e-05, 4.7036e-04, 1.5366e-02, 3.1090e-02, 1.5438e-02, 1.9840e-03,
        3.3847e-02, 4.9062e-04, 7.5074e-02, 2.0122e-01, 1.9412e-01, 2.3897e-01,
        1.9189e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,385][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ store] are: tensor([2.8149e-04, 3.2810e-03, 1.2906e-02, 4.8783e-02, 8.7618e-03, 1.2904e-02,
        7.0634e-02, 6.7394e-03, 1.8930e-01, 2.9665e-01, 8.9933e-02, 2.0236e-01,
        5.7464e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,387][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ store] are: tensor([3.6114e-05, 1.4192e-03, 1.1552e-02, 3.7144e-02, 5.7718e-02, 3.7359e-03,
        6.8271e-02, 1.0920e-03, 1.1707e-01, 2.4103e-01, 1.8512e-01, 1.4515e-01,
        1.3066e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,390][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.0007, 0.1506, 0.2786, 0.0146, 0.0196, 0.0005, 0.0158, 0.0004, 0.2576,
        0.1369, 0.0771, 0.0369, 0.0107], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,394][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0005, 0.0003, 0.0272, 0.0083, 0.0055, 0.0029, 0.0091, 0.0057, 0.0572,
        0.2756, 0.1591, 0.2805, 0.1681], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,399][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0041, 0.0188, 0.0432, 0.1099, 0.1939, 0.0131, 0.0431, 0.0105, 0.0764,
        0.2163, 0.0723, 0.0690, 0.1294], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,400][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0044, 0.0009, 0.0013, 0.0216, 0.0033, 0.1827, 0.2095, 0.1003, 0.0174,
        0.1406, 0.0439, 0.2124, 0.0617], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,400][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.1150, 0.1002, 0.3731, 0.0541, 0.0490, 0.0613, 0.0447, 0.1339, 0.0149,
        0.0086, 0.0071, 0.0089, 0.0204, 0.0087], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,401][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0144, 0.0116, 0.0291, 0.0637, 0.0810, 0.0663, 0.0843, 0.0547, 0.1294,
        0.1622, 0.0396, 0.1058, 0.0732, 0.0847], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,403][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [.] are: tensor([7.3145e-05, 1.5288e-03, 4.5976e-02, 8.2608e-02, 3.4318e-02, 2.0276e-03,
        3.8066e-02, 5.1667e-04, 3.3690e-01, 1.0937e-01, 6.8482e-02, 1.1819e-01,
        1.8566e-02, 1.4337e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,406][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0170, 0.0035, 0.0122, 0.0129, 0.0237, 0.0052, 0.0180, 0.0033, 0.0342,
        0.4047, 0.2176, 0.1338, 0.0709, 0.0429], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,408][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [.] are: tensor([2.1531e-05, 9.2471e-04, 1.3988e-02, 1.5898e-02, 2.9651e-02, 6.0923e-03,
        8.7184e-02, 2.2168e-04, 2.7822e-01, 9.5088e-02, 1.7555e-01, 2.1031e-01,
        1.4287e-02, 7.2559e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,410][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [.] are: tensor([6.8627e-05, 1.1386e-03, 9.5771e-03, 2.4730e-02, 1.5942e-02, 2.2474e-03,
        3.3912e-02, 4.6755e-04, 7.2523e-02, 1.7558e-01, 1.9068e-01, 2.5275e-01,
        8.1934e-02, 1.3845e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,415][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0008, 0.0066, 0.0213, 0.0626, 0.0078, 0.0161, 0.0674, 0.0057, 0.1902,
        0.2384, 0.0798, 0.1524, 0.0355, 0.1154], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,417][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [.] are: tensor([1.7006e-05, 7.4284e-04, 7.1607e-03, 2.1131e-02, 4.0359e-02, 2.8523e-03,
        5.7783e-02, 5.6769e-04, 1.8013e-01, 1.9400e-01, 1.4406e-01, 1.3996e-01,
        8.6144e-02, 1.2510e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,418][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0192, 0.2563, 0.0720, 0.0567, 0.0393, 0.0093, 0.0626, 0.0091, 0.1539,
        0.0896, 0.0734, 0.0655, 0.0320, 0.0612], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,419][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0021, 0.0009, 0.0175, 0.0064, 0.0038, 0.0040, 0.0080, 0.0084, 0.0637,
        0.3024, 0.1053, 0.2160, 0.1288, 0.1327], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,419][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0590, 0.0539, 0.0485, 0.1495, 0.1321, 0.0180, 0.0346, 0.0302, 0.0979,
        0.1214, 0.0558, 0.0499, 0.0833, 0.0658], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,422][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0020, 0.0007, 0.0015, 0.0254, 0.0028, 0.0825, 0.1631, 0.0308, 0.0387,
        0.1289, 0.0609, 0.2739, 0.0411, 0.1477], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,425][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.1333, 0.1131, 0.2690, 0.0427, 0.0391, 0.0602, 0.0361, 0.2001, 0.0149,
        0.0074, 0.0082, 0.0113, 0.0271, 0.0115, 0.0259], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:39,429][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0500, 0.0279, 0.0319, 0.0484, 0.0911, 0.0819, 0.0656, 0.0820, 0.1074,
        0.1361, 0.0344, 0.0723, 0.0660, 0.0630, 0.0420], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:39,431][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([1.3144e-04, 1.6717e-03, 4.1932e-02, 7.3730e-02, 3.7535e-02, 3.5962e-03,
        4.6588e-02, 1.1658e-03, 2.5362e-01, 9.7629e-02, 5.7969e-02, 1.4150e-01,
        2.5579e-02, 1.0444e-01, 1.1292e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:39,435][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0214, 0.0016, 0.0106, 0.0060, 0.0234, 0.0016, 0.0057, 0.0018, 0.0191,
        0.3356, 0.1855, 0.1866, 0.0984, 0.0516, 0.0512], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:39,436][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([5.4193e-05, 1.9262e-03, 9.4405e-03, 2.0162e-02, 2.8931e-02, 6.2899e-03,
        9.1946e-02, 3.3435e-04, 2.6362e-01, 8.6462e-02, 1.6602e-01, 1.7670e-01,
        1.4938e-02, 6.3300e-02, 6.9875e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:39,436][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([2.1073e-04, 1.9883e-03, 7.1444e-03, 2.6057e-02, 1.8693e-02, 5.1693e-03,
        5.3736e-02, 1.1159e-03, 8.8014e-02, 1.3791e-01, 1.9109e-01, 2.5452e-01,
        6.2859e-02, 1.3354e-01, 1.7954e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:39,437][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.0014, 0.0090, 0.0297, 0.0722, 0.0135, 0.0291, 0.0816, 0.0095, 0.1568,
        0.1890, 0.0896, 0.1683, 0.0353, 0.0969, 0.0182], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:39,439][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([1.3335e-05, 5.1254e-04, 5.8109e-03, 1.6303e-02, 3.2345e-02, 2.8798e-03,
        7.2209e-02, 5.4418e-04, 1.3367e-01, 1.4669e-01, 1.3578e-01, 2.0141e-01,
        7.6986e-02, 1.3437e-01, 4.0460e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:39,442][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.0646, 0.2395, 0.0398, 0.0775, 0.0409, 0.0258, 0.1006, 0.0327, 0.0752,
        0.0620, 0.0474, 0.0622, 0.0599, 0.0435, 0.0285], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:39,446][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0023, 0.0013, 0.0134, 0.0057, 0.0040, 0.0063, 0.0094, 0.0083, 0.0819,
        0.2150, 0.0929, 0.2159, 0.1056, 0.1154, 0.1226], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:39,450][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.1207, 0.0522, 0.0531, 0.1337, 0.1078, 0.0252, 0.0246, 0.0463, 0.0673,
        0.0951, 0.0455, 0.0523, 0.0846, 0.0536, 0.0379], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:39,453][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([1.4824e-03, 2.9561e-04, 7.0152e-04, 7.9954e-03, 1.8523e-03, 1.8387e-02,
        4.7747e-02, 1.1436e-02, 2.7730e-02, 1.3693e-01, 9.2854e-02, 4.1580e-01,
        5.0029e-02, 1.6315e-01, 2.3602e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:39,454][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0320, 0.0541, 0.4289, 0.0898, 0.0815, 0.0316, 0.0454, 0.0755, 0.0244,
        0.0230, 0.0096, 0.0074, 0.0146, 0.0075, 0.0184, 0.0560],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:39,455][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0079, 0.0034, 0.0266, 0.0096, 0.0062, 0.0304, 0.0314, 0.0924, 0.0153,
        0.2045, 0.0167, 0.0298, 0.3201, 0.0505, 0.0367, 0.1185],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:39,455][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0035, 0.0204, 0.0331, 0.1239, 0.0212, 0.0260, 0.0684, 0.0128, 0.1125,
        0.1527, 0.0452, 0.0825, 0.0346, 0.1492, 0.0072, 0.1066],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:39,458][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0109, 0.0009, 0.0018, 0.0015, 0.0017, 0.0062, 0.0104, 0.0042, 0.0023,
        0.2338, 0.0357, 0.0302, 0.1487, 0.0316, 0.0084, 0.4717],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:39,460][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([3.6669e-05, 8.0770e-04, 4.0156e-03, 8.7752e-03, 1.0841e-02, 2.6204e-02,
        3.0858e-01, 3.5670e-03, 1.4420e-01, 6.4884e-02, 8.8963e-02, 2.0299e-01,
        1.1502e-02, 6.9267e-02, 4.5861e-02, 9.5024e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:39,462][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([6.0845e-05, 3.2774e-04, 6.2030e-02, 4.3381e-02, 1.1942e-02, 2.4887e-03,
        2.7844e-02, 1.5321e-03, 2.7789e-02, 1.6378e-01, 6.7297e-02, 4.2473e-02,
        3.9959e-01, 5.6432e-02, 7.7333e-02, 1.5702e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:39,464][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([8.7651e-05, 1.1988e-03, 3.5687e-03, 8.6122e-03, 3.3117e-03, 5.4828e-03,
        5.8630e-02, 1.3149e-02, 9.4055e-02, 1.8635e-01, 6.6771e-02, 2.0024e-01,
        7.6454e-02, 1.7025e-01, 1.0375e-02, 1.0146e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:39,468][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0002, 0.0116, 0.0196, 0.0750, 0.0405, 0.0316, 0.0943, 0.0190, 0.0244,
        0.1379, 0.1226, 0.0598, 0.1365, 0.0731, 0.0093, 0.1446],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:39,471][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([5.8537e-06, 1.3936e-02, 4.6878e-01, 1.2955e-03, 6.2945e-03, 1.4125e-05,
        1.0906e-03, 6.8405e-06, 2.7079e-01, 6.6056e-02, 4.4763e-02, 9.3982e-03,
        1.3697e-03, 2.3304e-02, 9.2865e-02, 2.7276e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:39,472][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0008, 0.0006, 0.1074, 0.0085, 0.0234, 0.0024, 0.0094, 0.0162, 0.0389,
        0.1785, 0.2004, 0.1247, 0.1287, 0.0528, 0.0902, 0.0172],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:39,473][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([8.1521e-05, 5.0041e-03, 2.0939e-02, 2.0692e-02, 1.1558e-01, 9.0211e-03,
        4.7265e-02, 3.8041e-03, 1.8183e-02, 2.7760e-01, 4.0839e-02, 3.8209e-02,
        2.6964e-01, 6.6245e-02, 1.4595e-02, 5.2294e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:39,473][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([2.3644e-02, 1.6760e-04, 1.1176e-05, 2.2697e-04, 2.4731e-05, 3.7414e-02,
        2.2259e-03, 8.5219e-02, 1.4639e-05, 3.9995e-04, 3.7440e-05, 1.2029e-04,
        1.7905e-03, 3.2347e-04, 2.1560e-05, 8.4836e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:39,476][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0523, 0.0880, 0.3437, 0.0655, 0.0551, 0.0493, 0.0452, 0.0810, 0.0179,
        0.0107, 0.0081, 0.0073, 0.0135, 0.0075, 0.0141, 0.1284, 0.0125],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:39,479][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0105, 0.0072, 0.0483, 0.0326, 0.0347, 0.0473, 0.0425, 0.0624, 0.0405,
        0.1696, 0.0230, 0.0377, 0.1427, 0.0425, 0.0362, 0.1214, 0.1010],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:39,483][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0005, 0.0055, 0.0588, 0.1142, 0.0293, 0.0058, 0.0484, 0.0017, 0.2103,
        0.1388, 0.0621, 0.1020, 0.0240, 0.1180, 0.0224, 0.0226, 0.0354],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:39,487][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0152, 0.0016, 0.0058, 0.0044, 0.0073, 0.0055, 0.0129, 0.0035, 0.0079,
        0.3469, 0.0857, 0.0595, 0.0894, 0.0291, 0.0150, 0.1068, 0.2036],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:39,489][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([2.3050e-05, 7.9922e-04, 1.0831e-02, 1.2029e-02, 1.8510e-02, 1.0811e-02,
        1.6336e-01, 5.9574e-04, 2.1369e-01, 7.0453e-02, 1.2403e-01, 1.9268e-01,
        9.4340e-03, 5.5468e-02, 7.6483e-02, 4.1097e-03, 3.6700e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:39,490][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([4.1522e-05, 3.0311e-04, 2.6142e-02, 3.8026e-02, 1.3726e-02, 2.9871e-03,
        3.6716e-02, 6.9306e-04, 4.6159e-02, 1.7172e-01, 1.1385e-01, 9.8337e-02,
        2.2259e-01, 8.9314e-02, 4.1240e-02, 1.6381e-02, 8.1776e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:39,491][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([7.0559e-05, 9.8221e-04, 8.2477e-03, 1.5062e-02, 4.2982e-03, 7.2586e-03,
        5.4301e-02, 4.0591e-03, 1.1696e-01, 2.0388e-01, 6.1663e-02, 1.4371e-01,
        3.6076e-02, 1.0232e-01, 1.1228e-02, 9.3083e-02, 1.3680e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:39,492][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([4.3269e-05, 1.5662e-03, 7.6931e-03, 2.7821e-02, 3.2855e-02, 1.1002e-02,
        6.6013e-02, 2.2228e-03, 6.4647e-02, 1.5939e-01, 1.2450e-01, 8.6079e-02,
        1.0977e-01, 7.1771e-02, 1.2339e-02, 4.7721e-02, 1.7457e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:39,493][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([1.6054e-04, 3.4724e-02, 2.9575e-01, 5.0222e-03, 1.4230e-02, 1.4438e-04,
        5.4387e-03, 9.2223e-05, 3.0676e-01, 9.9447e-02, 7.6034e-02, 2.4272e-02,
        4.7664e-03, 4.1324e-02, 9.0328e-02, 2.2854e-04, 1.2703e-03],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:39,496][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0003, 0.0003, 0.0404, 0.0049, 0.0067, 0.0020, 0.0071, 0.0054, 0.0455,
        0.2307, 0.1191, 0.1420, 0.1222, 0.0719, 0.1294, 0.0287, 0.0433],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:39,500][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0023, 0.0154, 0.0350, 0.0603, 0.1176, 0.0137, 0.0371, 0.0093, 0.0390,
        0.1894, 0.0376, 0.0369, 0.1746, 0.0524, 0.0226, 0.0821, 0.0747],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:39,503][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([3.9741e-03, 2.2222e-04, 1.6412e-04, 2.7186e-03, 3.4953e-04, 3.7422e-02,
        1.9447e-02, 2.4508e-02, 8.3051e-04, 9.2474e-03, 1.5133e-03, 6.1055e-03,
        8.8041e-03, 6.2902e-03, 7.2410e-04, 6.9442e-01, 1.8326e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:39,507][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.0715, 0.0826, 0.2099, 0.0453, 0.0351, 0.0520, 0.0438, 0.1094, 0.0172,
        0.0091, 0.0087, 0.0102, 0.0188, 0.0110, 0.0147, 0.2316, 0.0183, 0.0109],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:39,508][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([0.0145, 0.0079, 0.0201, 0.0306, 0.0459, 0.0463, 0.0555, 0.0467, 0.0646,
        0.1621, 0.0261, 0.0605, 0.0747, 0.0545, 0.0295, 0.0768, 0.0958, 0.0879],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:39,509][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([7.7066e-05, 1.5348e-03, 5.0259e-02, 6.2352e-02, 4.7899e-02, 2.7301e-03,
        4.5551e-02, 6.4458e-04, 2.5033e-01, 1.1138e-01, 5.9217e-02, 1.1853e-01,
        1.9063e-02, 1.1387e-01, 6.1477e-02, 6.0655e-03, 2.3235e-02, 2.5777e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:39,510][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([0.0101, 0.0019, 0.0071, 0.0056, 0.0140, 0.0020, 0.0089, 0.0015, 0.0200,
        0.2933, 0.1759, 0.1352, 0.0707, 0.0472, 0.0184, 0.0312, 0.0826, 0.0744],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:39,511][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([4.6312e-05, 1.5136e-03, 8.5954e-03, 1.4706e-02, 2.4104e-02, 8.9553e-03,
        1.1463e-01, 4.4558e-04, 2.2406e-01, 6.9100e-02, 1.1708e-01, 1.8758e-01,
        1.2914e-02, 5.9466e-02, 6.0040e-02, 3.7813e-03, 2.5482e-02, 6.7494e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:39,513][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([1.3470e-04, 1.0688e-03, 1.5936e-02, 2.7129e-02, 1.7944e-02, 3.3216e-03,
        4.9760e-02, 7.0989e-04, 5.8085e-02, 1.6717e-01, 1.3462e-01, 1.6265e-01,
        1.0558e-01, 1.0114e-01, 2.2589e-02, 1.5316e-02, 8.6338e-02, 3.0498e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:39,518][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([0.0004, 0.0059, 0.0177, 0.0426, 0.0097, 0.0126, 0.0715, 0.0046, 0.1403,
        0.1663, 0.0698, 0.1519, 0.0270, 0.0890, 0.0093, 0.0659, 0.1022, 0.0134],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:39,521][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([2.8128e-05, 6.6240e-04, 4.5753e-03, 1.7332e-02, 2.7026e-02, 4.1949e-03,
        5.6717e-02, 1.1397e-03, 1.0568e-01, 1.6616e-01, 1.1897e-01, 1.1586e-01,
        7.6768e-02, 1.0767e-01, 2.4896e-02, 2.2838e-02, 1.0965e-01, 3.9836e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:39,525][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([0.0018, 0.1742, 0.1483, 0.0259, 0.0341, 0.0022, 0.0287, 0.0017, 0.1989,
        0.1063, 0.0793, 0.0475, 0.0185, 0.0570, 0.0477, 0.0025, 0.0082, 0.0173],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:39,525][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([0.0017, 0.0007, 0.0114, 0.0033, 0.0033, 0.0035, 0.0069, 0.0069, 0.0512,
        0.2260, 0.1147, 0.1641, 0.0957, 0.0873, 0.0628, 0.0604, 0.0666, 0.0336],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:39,526][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([0.0266, 0.0366, 0.0265, 0.0703, 0.1176, 0.0143, 0.0345, 0.0178, 0.0780,
        0.1154, 0.0558, 0.0526, 0.0792, 0.0629, 0.0217, 0.1028, 0.0751, 0.0120],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:39,527][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([1.1590e-03, 1.9330e-04, 1.1185e-04, 2.4204e-03, 5.1329e-04, 2.1316e-02,
        2.8838e-02, 1.3254e-02, 4.6411e-03, 2.9974e-02, 9.7581e-03, 3.6941e-02,
        1.3853e-02, 2.7480e-02, 2.4732e-03, 4.3118e-01, 3.1378e-01, 6.2112e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:39,530][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0743, 0.0933, 0.2767, 0.0448, 0.0373, 0.0547, 0.0334, 0.0990, 0.0124,
        0.0057, 0.0056, 0.0058, 0.0115, 0.0062, 0.0090, 0.2086, 0.0118, 0.0047,
        0.0050], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:39,533][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0097, 0.0095, 0.0385, 0.0484, 0.0903, 0.0494, 0.0408, 0.0310, 0.0740,
        0.0793, 0.0186, 0.0430, 0.0390, 0.0337, 0.0291, 0.0710, 0.0888, 0.1018,
        0.1041], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:39,535][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([4.0875e-05, 1.0488e-03, 5.1276e-02, 5.1799e-02, 3.2557e-02, 1.2567e-03,
        2.6702e-02, 2.3783e-04, 2.8775e-01, 8.4043e-02, 5.0801e-02, 9.5260e-02,
        1.4323e-02, 8.5433e-02, 6.2742e-02, 3.5483e-03, 1.9668e-02, 2.7940e-02,
        1.0358e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:39,539][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0126, 0.0020, 0.0059, 0.0052, 0.0107, 0.0021, 0.0069, 0.0018, 0.0169,
        0.2149, 0.0831, 0.0649, 0.0347, 0.0217, 0.0132, 0.0171, 0.0513, 0.0312,
        0.4037], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:39,541][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.2930e-05, 7.9203e-04, 1.5377e-02, 1.2170e-02, 2.7226e-02, 3.9910e-03,
        6.2737e-02, 9.8902e-05, 2.5441e-01, 4.4977e-02, 1.0464e-01, 1.3104e-01,
        6.6711e-03, 3.7973e-02, 7.9589e-02, 1.4339e-03, 1.4509e-02, 6.0505e-02,
        1.4185e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:39,543][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([4.3922e-05, 4.9403e-04, 7.0601e-03, 2.1196e-02, 8.9486e-03, 2.3200e-03,
        2.6946e-02, 4.2294e-04, 6.2226e-02, 1.1041e-01, 1.0174e-01, 1.2551e-01,
        6.1638e-02, 9.0249e-02, 1.7118e-02, 1.2396e-02, 8.3470e-02, 2.4493e-02,
        2.4332e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:39,544][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0003, 0.0024, 0.0192, 0.0287, 0.0071, 0.0094, 0.0411, 0.0027, 0.1490,
        0.1325, 0.0468, 0.1084, 0.0193, 0.0617, 0.0123, 0.0568, 0.1374, 0.0188,
        0.1462], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:39,545][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.0251e-05, 2.3903e-04, 3.5082e-03, 1.1201e-02, 1.7790e-02, 3.4637e-03,
        3.5164e-02, 5.1233e-04, 1.2734e-01, 1.2359e-01, 8.0038e-02, 9.8400e-02,
        5.7950e-02, 6.1108e-02, 2.2037e-02, 1.5386e-02, 1.0277e-01, 3.0893e-02,
        2.0860e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:39,546][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0068, 0.1498, 0.1019, 0.0368, 0.0375, 0.0050, 0.0405, 0.0041, 0.1757,
        0.0845, 0.0795, 0.0577, 0.0215, 0.0556, 0.0498, 0.0054, 0.0152, 0.0215,
        0.0511], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:39,548][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0010, 0.0004, 0.0086, 0.0032, 0.0017, 0.0019, 0.0041, 0.0037, 0.0430,
        0.1455, 0.0532, 0.1043, 0.0643, 0.0624, 0.0803, 0.0566, 0.1071, 0.0383,
        0.2205], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:39,551][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0820, 0.0720, 0.0368, 0.1091, 0.0834, 0.0125, 0.0179, 0.0166, 0.0732,
        0.0780, 0.0393, 0.0299, 0.0606, 0.0407, 0.0160, 0.0823, 0.0565, 0.0072,
        0.0859], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:39,554][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.4805e-03, 2.0945e-04, 2.5386e-04, 4.2982e-03, 6.1812e-04, 2.5149e-02,
        3.1110e-02, 1.0696e-02, 8.3251e-03, 3.3818e-02, 1.2039e-02, 6.0070e-02,
        1.1261e-02, 2.6848e-02, 3.4866e-03, 3.4511e-01, 2.7186e-01, 6.2400e-02,
        9.0970e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:39,670][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:39,671][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,673][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,673][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,674][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,675][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,675][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,676][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,677][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,677][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,678][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,679][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,679][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:39,680][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3472, 0.6528], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,681][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.6667, 0.3333], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,682][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2186, 0.7814], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,682][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.8068, 0.1932], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,685][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0535, 0.9465], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,688][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1575, 0.8425], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,692][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2557, 0.7443], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,695][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1312, 0.8688], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,697][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2595, 0.7405], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,697][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.6815, 0.3185], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,698][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4810, 0.5190], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,699][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.7446, 0.2554], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:39,700][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.2126, 0.2985, 0.4889], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,702][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.5944, 0.0866, 0.3191], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,705][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.0029, 0.0169, 0.9801], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,708][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.2932, 0.0268, 0.6800], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,712][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.0012, 0.0732, 0.9256], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,715][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.0222, 0.0816, 0.8961], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,715][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.0098, 0.0537, 0.9365], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,716][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.0059, 0.0696, 0.9245], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,717][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.3522, 0.4805, 0.1673], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,717][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.1746, 0.0339, 0.7916], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,720][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.3998, 0.1562, 0.4441], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,723][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.8146, 0.0535, 0.1319], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:27:39,726][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2019, 0.2780, 0.4068, 0.1134], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,730][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.4406, 0.0786, 0.3252, 0.1556], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,733][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0041, 0.0187, 0.6914, 0.2858], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,733][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.5916, 0.0222, 0.3134, 0.0729], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,734][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0012, 0.0320, 0.5192, 0.4477], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,735][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0043, 0.0202, 0.6320, 0.3435], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,736][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0154, 0.0592, 0.5646, 0.3609], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,739][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0046, 0.0667, 0.4302, 0.4985], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,744][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0827, 0.3007, 0.0653, 0.5513], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,748][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1456, 0.0250, 0.7926, 0.0367], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,750][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.3337, 0.1389, 0.2391, 0.2884], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,751][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.5873, 0.0332, 0.0555, 0.3240], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:27:39,752][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.2702, 0.3139, 0.2777, 0.0965, 0.0417], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,753][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([0.1434, 0.0785, 0.2699, 0.1868, 0.3214], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,754][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([0.0019, 0.0105, 0.4059, 0.3342, 0.2475], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,757][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([0.2310, 0.0248, 0.3035, 0.0996, 0.3411], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,760][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([9.6472e-05, 1.3033e-02, 2.2027e-01, 2.2760e-01, 5.3900e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,764][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.0026, 0.0274, 0.2719, 0.3381, 0.3601], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,768][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.0094, 0.0708, 0.4870, 0.3555, 0.0772], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,769][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.0007, 0.0167, 0.2553, 0.2395, 0.4879], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,770][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.0276, 0.2049, 0.0275, 0.7278, 0.0122], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,770][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.1128, 0.0378, 0.6458, 0.1164, 0.0872], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,771][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.2468, 0.1117, 0.1854, 0.3102, 0.1459], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,773][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.0783, 0.0272, 0.0950, 0.6986, 0.1010], device='cuda:0') for source tokens [Then, Brittany and Travis]
[2024-07-24 10:27:39,776][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0704, 0.1034, 0.5443, 0.1401, 0.0709, 0.0710], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,780][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.4768, 0.0365, 0.2020, 0.0565, 0.0505, 0.1777], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,784][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0449, 0.0658, 0.2665, 0.3680, 0.1282, 0.1267], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,786][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.4336, 0.0169, 0.1926, 0.0344, 0.0812, 0.2413], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,787][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0005, 0.0122, 0.1061, 0.2016, 0.2477, 0.4320], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,788][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0020, 0.0046, 0.5092, 0.2791, 0.1663, 0.0389], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,789][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0050, 0.0447, 0.1939, 0.3572, 0.0890, 0.3102], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,789][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0048, 0.0838, 0.1863, 0.3382, 0.1948, 0.1921], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,791][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0034, 0.0491, 0.0705, 0.0892, 0.7849, 0.0029], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,794][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0541, 0.0095, 0.7207, 0.0348, 0.1415, 0.0394], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,798][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0032, 0.0518, 0.1801, 0.1340, 0.4515, 0.1794], device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,801][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([3.9681e-01, 3.4720e-03, 5.2058e-04, 3.9498e-03, 5.6702e-04, 5.9468e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had]
[2024-07-24 10:27:39,805][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1604, 0.1564, 0.4021, 0.0768, 0.0410, 0.1144, 0.0489],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,806][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0954, 0.0355, 0.2162, 0.1632, 0.2194, 0.1490, 0.1213],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,806][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0013, 0.0098, 0.4389, 0.3469, 0.1164, 0.0130, 0.0738],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,807][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2268, 0.0128, 0.2827, 0.0570, 0.1811, 0.1444, 0.0953],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,808][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([8.5958e-05, 5.2779e-03, 1.2493e-01, 1.0429e-01, 1.9552e-01, 4.7204e-02,
        5.2270e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,811][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0007, 0.0069, 0.2340, 0.2920, 0.1674, 0.0452, 0.2537],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,816][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0017, 0.0176, 0.2225, 0.2690, 0.0486, 0.1147, 0.3260],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,820][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0004, 0.0122, 0.1036, 0.2151, 0.2922, 0.0595, 0.3170],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,823][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0020, 0.0115, 0.0019, 0.0346, 0.0022, 0.9221, 0.0256],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,823][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0184, 0.0086, 0.7394, 0.0533, 0.0653, 0.0645, 0.0505],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,824][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0612, 0.0791, 0.1612, 0.2490, 0.2770, 0.1142, 0.0583],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,825][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0181, 0.0020, 0.0075, 0.0592, 0.0078, 0.6078, 0.2976],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a]
[2024-07-24 10:27:39,827][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0551, 0.0752, 0.4537, 0.0993, 0.0693, 0.0535, 0.0392, 0.1546],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,830][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0902, 0.0157, 0.0808, 0.0362, 0.0165, 0.1125, 0.1132, 0.5349],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,834][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0637, 0.1399, 0.0853, 0.2934, 0.0625, 0.1009, 0.1551, 0.0992],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,838][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.1992, 0.0129, 0.0975, 0.0328, 0.0589, 0.2172, 0.2609, 0.1205],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,840][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([1.9763e-04, 2.6500e-03, 1.0315e-02, 2.8985e-02, 3.1006e-02, 9.8172e-02,
        7.9741e-01, 3.1269e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,841][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0034, 0.0034, 0.4267, 0.2898, 0.0954, 0.0228, 0.1334, 0.0252],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,842][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0015, 0.0131, 0.0242, 0.0775, 0.0345, 0.0591, 0.5497, 0.2405],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,843][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0067, 0.0924, 0.0936, 0.2039, 0.0939, 0.1721, 0.1210, 0.2165],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,844][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([1.7145e-03, 7.8842e-03, 4.3387e-02, 1.4042e-02, 7.3447e-01, 5.9010e-05,
        1.9842e-01, 1.9522e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,847][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0032, 0.0023, 0.5575, 0.0442, 0.2238, 0.0143, 0.0699, 0.0846],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,849][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([1.3089e-04, 1.6273e-02, 9.2690e-02, 7.3990e-02, 4.5455e-01, 6.1624e-02,
        2.6255e-01, 3.8185e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,852][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([2.0086e-01, 3.5337e-03, 1.9495e-04, 2.5296e-03, 3.2317e-04, 1.9260e-01,
        1.1109e-02, 5.8885e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot]
[2024-07-24 10:27:39,856][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.1551, 0.0932, 0.2826, 0.0461, 0.0311, 0.1035, 0.0366, 0.2418, 0.0099],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,858][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.1045, 0.0249, 0.0613, 0.1061, 0.1132, 0.1886, 0.1023, 0.2206, 0.0784],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,859][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0007, 0.0053, 0.1944, 0.2047, 0.0881, 0.0074, 0.0754, 0.0024, 0.4216],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,860][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.3399, 0.0263, 0.1463, 0.0744, 0.1423, 0.0609, 0.0696, 0.0540, 0.0863],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,861][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([1.8914e-04, 3.6821e-03, 4.3600e-02, 4.2373e-02, 8.6822e-02, 1.8815e-02,
        1.7591e-01, 8.9017e-04, 6.2772e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,863][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0011, 0.0077, 0.0639, 0.1955, 0.0811, 0.0403, 0.2245, 0.0092, 0.3766],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,865][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0077, 0.0253, 0.0922, 0.1916, 0.0227, 0.0856, 0.1755, 0.0503, 0.3491],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,868][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([4.2675e-04, 4.4845e-03, 3.1628e-02, 1.0813e-01, 1.1106e-01, 4.1742e-02,
        2.2836e-01, 1.5195e-02, 4.5897e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,870][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([2.4457e-04, 2.3665e-04, 1.8590e-05, 1.4180e-03, 1.4274e-05, 5.1174e-01,
        8.5796e-04, 4.8546e-01, 7.6165e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,874][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0403, 0.0102, 0.1707, 0.0426, 0.0211, 0.0419, 0.0522, 0.1173, 0.5037],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,876][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.4164, 0.0881, 0.0586, 0.1503, 0.0729, 0.0445, 0.0148, 0.1206, 0.0338],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,877][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0273, 0.0024, 0.0045, 0.0574, 0.0064, 0.3444, 0.2726, 0.2414, 0.0435],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of]
[2024-07-24 10:27:39,878][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0691, 0.0870, 0.3954, 0.0637, 0.0433, 0.0795, 0.0573, 0.1792, 0.0158,
        0.0099], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,879][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0337, 0.0247, 0.0499, 0.0989, 0.1394, 0.0881, 0.1286, 0.0909, 0.1167,
        0.2291], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,880][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([2.2206e-04, 3.2542e-03, 1.2829e-01, 1.6393e-01, 1.0229e-01, 7.1294e-03,
        8.7972e-02, 2.3440e-03, 3.1190e-01, 1.9267e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,883][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0762, 0.0058, 0.0647, 0.0270, 0.0798, 0.0150, 0.0255, 0.0113, 0.0290,
        0.6657], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,885][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([5.8601e-05, 2.2317e-03, 2.5272e-02, 3.8699e-02, 6.9920e-02, 1.8406e-02,
        2.3713e-01, 8.1443e-04, 4.1852e-01, 1.8894e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,888][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([1.9294e-04, 3.0630e-03, 3.5387e-02, 7.4379e-02, 7.9244e-02, 8.9964e-03,
        1.3737e-01, 1.6183e-03, 2.2052e-01, 4.3924e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,892][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0008, 0.0087, 0.0390, 0.1297, 0.0227, 0.0483, 0.1592, 0.0173, 0.2045,
        0.3697], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,894][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([5.0085e-05, 1.9162e-03, 2.5032e-02, 4.7576e-02, 1.3046e-01, 8.3144e-03,
        1.4584e-01, 1.8266e-03, 2.2083e-01, 4.1816e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,895][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([4.8600e-04, 7.3088e-04, 9.8824e-05, 2.1060e-03, 5.9203e-05, 4.4655e-01,
        1.2812e-03, 5.4849e-01, 1.5258e-05, 1.7491e-04], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,896][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0051, 0.0027, 0.0849, 0.0174, 0.0163, 0.0131, 0.0210, 0.0204, 0.1462,
        0.6727], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,896][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0403, 0.0543, 0.0803, 0.1969, 0.2267, 0.0371, 0.0510, 0.0617, 0.0713,
        0.1803], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,899][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0014, 0.0014, 0.0053, 0.0531, 0.0129, 0.1593, 0.3339, 0.0505, 0.0567,
        0.3255], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun]
[2024-07-24 10:27:39,901][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.1181, 0.1066, 0.2976, 0.0684, 0.0489, 0.0802, 0.0644, 0.1761, 0.0198,
        0.0107, 0.0091], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,905][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0650, 0.0276, 0.0672, 0.0907, 0.1553, 0.0891, 0.0857, 0.0883, 0.1175,
        0.1669, 0.0469], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,908][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([3.5098e-04, 3.0404e-03, 1.4757e-01, 1.1034e-01, 6.3900e-02, 3.6512e-03,
        4.6959e-02, 1.4069e-03, 3.6577e-01, 1.7043e-01, 8.6584e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,912][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0829, 0.0070, 0.0317, 0.0224, 0.0404, 0.0090, 0.0210, 0.0087, 0.0378,
        0.5514, 0.1876], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,913][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([6.1971e-05, 1.3722e-03, 1.7977e-02, 1.9895e-02, 4.2652e-02, 1.0226e-02,
        1.1939e-01, 4.3272e-04, 3.9664e-01, 1.1963e-01, 2.7173e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,914][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([1.7565e-04, 2.1888e-03, 2.8542e-02, 4.2823e-02, 4.2384e-02, 5.2645e-03,
        7.1684e-02, 8.4993e-04, 1.5731e-01, 2.8054e-01, 3.6824e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,915][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0022, 0.0105, 0.0483, 0.0957, 0.0159, 0.0398, 0.0993, 0.0156, 0.2470,
        0.3172, 0.1086], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,916][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([7.2792e-05, 1.4842e-03, 1.5137e-02, 2.7504e-02, 6.9581e-02, 4.1478e-03,
        6.7483e-02, 1.2532e-03, 2.7594e-01, 3.1516e-01, 2.2223e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,918][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([5.5815e-05, 3.2903e-04, 1.6565e-05, 2.3407e-03, 1.3518e-05, 6.9965e-01,
        1.3010e-03, 2.9624e-01, 7.9816e-06, 4.4260e-05, 5.0619e-06],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,921][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0098, 0.0026, 0.0678, 0.0104, 0.0084, 0.0089, 0.0107, 0.0198, 0.1257,
        0.5386, 0.1973], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,925][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.1104, 0.0679, 0.0624, 0.2215, 0.1202, 0.0439, 0.0361, 0.0686, 0.0847,
        0.1258, 0.0584], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,930][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0130, 0.0020, 0.0040, 0.0372, 0.0072, 0.1301, 0.2028, 0.0618, 0.0721,
        0.3147, 0.1551], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at]
[2024-07-24 10:27:39,931][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1241, 0.1107, 0.3272, 0.0534, 0.0411, 0.0782, 0.0556, 0.1708, 0.0153,
        0.0083, 0.0069, 0.0083], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,932][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0242, 0.0244, 0.0500, 0.0771, 0.1218, 0.0914, 0.0942, 0.0796, 0.1132,
        0.1810, 0.0474, 0.0957], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,932][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([1.6386e-04, 2.2344e-03, 9.6016e-02, 8.8734e-02, 4.1256e-02, 3.7308e-03,
        5.3952e-02, 1.2411e-03, 3.1102e-01, 1.6975e-01, 8.5935e-02, 1.4597e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,934][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0399, 0.0045, 0.0194, 0.0131, 0.0284, 0.0089, 0.0214, 0.0056, 0.0280,
        0.5215, 0.1892, 0.1202], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,936][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([2.6523e-05, 1.1501e-03, 1.6450e-02, 1.9888e-02, 3.6130e-02, 1.0024e-02,
        1.1398e-01, 3.5995e-04, 2.9967e-01, 8.2458e-02, 1.8980e-01, 2.3006e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,939][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([7.8206e-05, 1.2395e-03, 1.7579e-02, 3.0535e-02, 2.3742e-02, 4.3286e-03,
        6.0481e-02, 6.2847e-04, 9.2732e-02, 2.4143e-01, 2.3216e-01, 2.9507e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,943][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0014, 0.0071, 0.0290, 0.0645, 0.0111, 0.0368, 0.1107, 0.0125, 0.1913,
        0.2654, 0.0961, 0.1742], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,945][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([4.1711e-05, 1.3490e-03, 1.1685e-02, 2.4506e-02, 4.5250e-02, 6.0547e-03,
        7.7149e-02, 1.3372e-03, 1.7688e-01, 2.6013e-01, 1.9469e-01, 2.0093e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,948][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([1.5834e-04, 4.0203e-04, 1.9689e-05, 2.6570e-03, 2.3854e-05, 6.5647e-01,
        1.5089e-03, 3.3862e-01, 1.3322e-05, 8.0111e-05, 9.4405e-06, 3.4877e-05],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,949][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0057, 0.0016, 0.0444, 0.0063, 0.0047, 0.0083, 0.0099, 0.0201, 0.0695,
        0.4517, 0.1290, 0.2489], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,949][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0810, 0.0659, 0.0426, 0.1658, 0.1444, 0.0373, 0.0413, 0.0628, 0.0942,
        0.1347, 0.0724, 0.0576], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,950][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0033, 0.0009, 0.0023, 0.0211, 0.0035, 0.1121, 0.1937, 0.0447, 0.0268,
        0.1927, 0.0652, 0.3337], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the]
[2024-07-24 10:27:39,952][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.0665, 0.0869, 0.3789, 0.0650, 0.0644, 0.0571, 0.0605, 0.1355, 0.0240,
        0.0134, 0.0109, 0.0122, 0.0246], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,955][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0124, 0.0110, 0.0525, 0.0557, 0.0557, 0.0551, 0.0757, 0.0630, 0.0898,
        0.2406, 0.0395, 0.1002, 0.1488], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,957][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([2.0064e-04, 2.4792e-03, 5.0101e-02, 1.2657e-01, 5.0227e-02, 3.9448e-03,
        4.6125e-02, 1.6005e-03, 3.0112e-01, 1.7930e-01, 7.7506e-02, 1.2857e-01,
        3.2257e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,961][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.0127, 0.0014, 0.0065, 0.0060, 0.0134, 0.0035, 0.0153, 0.0029, 0.0201,
        0.4947, 0.1791, 0.1360, 0.1084], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,964][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([3.0482e-05, 9.2381e-04, 9.2344e-03, 1.6398e-02, 2.4939e-02, 1.1854e-02,
        1.6390e-01, 5.7604e-04, 2.4621e-01, 1.1382e-01, 1.6498e-01, 2.2844e-01,
        1.8684e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,966][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([4.4178e-05, 4.7036e-04, 1.5366e-02, 3.1090e-02, 1.5438e-02, 1.9840e-03,
        3.3847e-02, 4.9062e-04, 7.5074e-02, 2.0122e-01, 1.9412e-01, 2.3897e-01,
        1.9189e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,967][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([2.8149e-04, 3.2810e-03, 1.2906e-02, 4.8783e-02, 8.7618e-03, 1.2904e-02,
        7.0634e-02, 6.7394e-03, 1.8930e-01, 2.9665e-01, 8.9933e-02, 2.0236e-01,
        5.7464e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,967][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([3.6114e-05, 1.4192e-03, 1.1552e-02, 3.7144e-02, 5.7718e-02, 3.7359e-03,
        6.8271e-02, 1.0920e-03, 1.1707e-01, 2.4103e-01, 1.8512e-01, 1.4515e-01,
        1.3066e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,968][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.0012, 0.0081, 0.0013, 0.0449, 0.0025, 0.5415, 0.0608, 0.2664, 0.0028,
        0.0197, 0.0027, 0.0119, 0.0362], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,970][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.0005, 0.0003, 0.0272, 0.0083, 0.0055, 0.0029, 0.0091, 0.0057, 0.0572,
        0.2756, 0.1591, 0.2805, 0.1681], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,973][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.0041, 0.0188, 0.0432, 0.1099, 0.1939, 0.0131, 0.0431, 0.0105, 0.0764,
        0.2163, 0.0723, 0.0690, 0.1294], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,977][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.0044, 0.0009, 0.0013, 0.0216, 0.0033, 0.1827, 0.2095, 0.1003, 0.0174,
        0.1406, 0.0439, 0.2124, 0.0617], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store]
[2024-07-24 10:27:39,981][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.1150, 0.1002, 0.3731, 0.0541, 0.0490, 0.0613, 0.0447, 0.1339, 0.0149,
        0.0086, 0.0071, 0.0089, 0.0204, 0.0087], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,984][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0144, 0.0116, 0.0291, 0.0637, 0.0810, 0.0663, 0.0843, 0.0547, 0.1294,
        0.1622, 0.0396, 0.1058, 0.0732, 0.0847], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,984][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([7.3145e-05, 1.5288e-03, 4.5976e-02, 8.2608e-02, 3.4318e-02, 2.0276e-03,
        3.8066e-02, 5.1667e-04, 3.3690e-01, 1.0937e-01, 6.8482e-02, 1.1819e-01,
        1.8566e-02, 1.4337e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,985][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0170, 0.0035, 0.0122, 0.0129, 0.0237, 0.0052, 0.0180, 0.0033, 0.0342,
        0.4047, 0.2176, 0.1338, 0.0709, 0.0429], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,986][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([2.1531e-05, 9.2471e-04, 1.3988e-02, 1.5898e-02, 2.9651e-02, 6.0923e-03,
        8.7184e-02, 2.2168e-04, 2.7822e-01, 9.5088e-02, 1.7555e-01, 2.1031e-01,
        1.4287e-02, 7.2559e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,988][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([6.8627e-05, 1.1386e-03, 9.5771e-03, 2.4730e-02, 1.5942e-02, 2.2474e-03,
        3.3912e-02, 4.6755e-04, 7.2523e-02, 1.7558e-01, 1.9068e-01, 2.5275e-01,
        8.1934e-02, 1.3845e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,991][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0008, 0.0066, 0.0213, 0.0626, 0.0078, 0.0161, 0.0674, 0.0057, 0.1902,
        0.2384, 0.0798, 0.1524, 0.0355, 0.1154], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,993][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([1.7006e-05, 7.4284e-04, 7.1607e-03, 2.1131e-02, 4.0359e-02, 2.8523e-03,
        5.7783e-02, 5.6769e-04, 1.8013e-01, 1.9400e-01, 1.4406e-01, 1.3996e-01,
        8.6144e-02, 1.2510e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,995][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([3.9572e-05, 1.2424e-04, 7.2477e-06, 1.1064e-03, 5.6239e-06, 5.9676e-01,
        5.0874e-04, 4.0118e-01, 3.3113e-06, 1.8190e-05, 1.8038e-06, 7.5373e-06,
        2.2177e-04, 2.0306e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:39,999][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0021, 0.0009, 0.0175, 0.0064, 0.0038, 0.0040, 0.0080, 0.0084, 0.0637,
        0.3024, 0.1053, 0.2160, 0.1288, 0.1327], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:40,001][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0590, 0.0539, 0.0485, 0.1495, 0.1321, 0.0180, 0.0346, 0.0302, 0.0979,
        0.1214, 0.0558, 0.0499, 0.0833, 0.0658], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:40,002][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0020, 0.0007, 0.0015, 0.0254, 0.0028, 0.0825, 0.1631, 0.0308, 0.0387,
        0.1289, 0.0609, 0.2739, 0.0411, 0.1477], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store.]
[2024-07-24 10:27:40,003][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.1333, 0.1131, 0.2690, 0.0427, 0.0391, 0.0602, 0.0361, 0.2001, 0.0149,
        0.0074, 0.0082, 0.0113, 0.0271, 0.0115, 0.0259], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:40,004][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0500, 0.0279, 0.0319, 0.0484, 0.0911, 0.0819, 0.0656, 0.0820, 0.1074,
        0.1361, 0.0344, 0.0723, 0.0660, 0.0630, 0.0420], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:40,006][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([1.3144e-04, 1.6717e-03, 4.1932e-02, 7.3730e-02, 3.7535e-02, 3.5962e-03,
        4.6588e-02, 1.1658e-03, 2.5362e-01, 9.7629e-02, 5.7969e-02, 1.4150e-01,
        2.5579e-02, 1.0444e-01, 1.1292e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:40,008][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.0214, 0.0016, 0.0106, 0.0060, 0.0234, 0.0016, 0.0057, 0.0018, 0.0191,
        0.3356, 0.1855, 0.1866, 0.0984, 0.0516, 0.0512], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:40,011][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([5.4193e-05, 1.9262e-03, 9.4405e-03, 2.0162e-02, 2.8931e-02, 6.2899e-03,
        9.1946e-02, 3.3435e-04, 2.6362e-01, 8.6462e-02, 1.6602e-01, 1.7670e-01,
        1.4938e-02, 6.3300e-02, 6.9875e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:40,013][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([2.1073e-04, 1.9883e-03, 7.1444e-03, 2.6057e-02, 1.8693e-02, 5.1693e-03,
        5.3736e-02, 1.1159e-03, 8.8014e-02, 1.3791e-01, 1.9109e-01, 2.5452e-01,
        6.2859e-02, 1.3354e-01, 1.7954e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:40,017][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.0014, 0.0090, 0.0297, 0.0722, 0.0135, 0.0291, 0.0816, 0.0095, 0.1568,
        0.1890, 0.0896, 0.1683, 0.0353, 0.0969, 0.0182], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:40,019][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([1.3335e-05, 5.1254e-04, 5.8109e-03, 1.6303e-02, 3.2345e-02, 2.8798e-03,
        7.2209e-02, 5.4418e-04, 1.3367e-01, 1.4669e-01, 1.3578e-01, 2.0141e-01,
        7.6986e-02, 1.3437e-01, 4.0460e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:40,020][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([1.1068e-03, 4.7160e-04, 2.6947e-05, 1.0680e-03, 1.3768e-05, 3.5256e-01,
        5.8848e-04, 6.4331e-01, 7.1693e-06, 5.1313e-05, 5.3258e-06, 2.7563e-05,
        7.0725e-04, 5.7267e-05, 6.1347e-06], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:40,021][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.0023, 0.0013, 0.0134, 0.0057, 0.0040, 0.0063, 0.0094, 0.0083, 0.0819,
        0.2150, 0.0929, 0.2159, 0.1056, 0.1154, 0.1226], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:40,022][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.1207, 0.0522, 0.0531, 0.1337, 0.1078, 0.0252, 0.0246, 0.0463, 0.0673,
        0.0951, 0.0455, 0.0523, 0.0846, 0.0536, 0.0379], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:40,023][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([1.4824e-03, 2.9561e-04, 7.0152e-04, 7.9954e-03, 1.8523e-03, 1.8387e-02,
        4.7747e-02, 1.1436e-02, 2.7730e-02, 1.3693e-01, 9.2854e-02, 4.1580e-01,
        5.0029e-02, 1.6315e-01, 2.3602e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany]
[2024-07-24 10:27:40,026][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0320, 0.0541, 0.4289, 0.0898, 0.0815, 0.0316, 0.0454, 0.0755, 0.0244,
        0.0230, 0.0096, 0.0074, 0.0146, 0.0075, 0.0184, 0.0560],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:40,030][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0079, 0.0034, 0.0266, 0.0096, 0.0062, 0.0304, 0.0314, 0.0924, 0.0153,
        0.2045, 0.0167, 0.0298, 0.3201, 0.0505, 0.0367, 0.1185],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:40,035][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0035, 0.0204, 0.0331, 0.1239, 0.0212, 0.0260, 0.0684, 0.0128, 0.1125,
        0.1527, 0.0452, 0.0825, 0.0346, 0.1492, 0.0072, 0.1066],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:40,037][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0109, 0.0009, 0.0018, 0.0015, 0.0017, 0.0062, 0.0104, 0.0042, 0.0023,
        0.2338, 0.0357, 0.0302, 0.1487, 0.0316, 0.0084, 0.4717],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:40,038][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([3.6669e-05, 8.0770e-04, 4.0156e-03, 8.7752e-03, 1.0841e-02, 2.6204e-02,
        3.0858e-01, 3.5670e-03, 1.4420e-01, 6.4884e-02, 8.8963e-02, 2.0299e-01,
        1.1502e-02, 6.9267e-02, 4.5861e-02, 9.5024e-03], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:40,039][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([6.0845e-05, 3.2774e-04, 6.2030e-02, 4.3381e-02, 1.1942e-02, 2.4887e-03,
        2.7844e-02, 1.5321e-03, 2.7789e-02, 1.6378e-01, 6.7297e-02, 4.2473e-02,
        3.9959e-01, 5.6432e-02, 7.7333e-02, 1.5702e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:40,040][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([8.7651e-05, 1.1988e-03, 3.5687e-03, 8.6122e-03, 3.3117e-03, 5.4828e-03,
        5.8630e-02, 1.3149e-02, 9.4055e-02, 1.8635e-01, 6.6771e-02, 2.0024e-01,
        7.6454e-02, 1.7025e-01, 1.0375e-02, 1.0146e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:40,042][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0002, 0.0116, 0.0196, 0.0750, 0.0405, 0.0316, 0.0943, 0.0190, 0.0244,
        0.1379, 0.1226, 0.0598, 0.1365, 0.0731, 0.0093, 0.1446],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:40,044][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([8.8301e-06, 1.9914e-04, 3.5686e-04, 8.0320e-04, 6.8550e-03, 5.9129e-06,
        9.2370e-03, 7.7177e-07, 4.1489e-02, 2.0766e-01, 6.1043e-02, 2.7956e-01,
        1.3575e-02, 3.3736e-01, 4.1783e-02, 6.8194e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:40,048][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0008, 0.0006, 0.1074, 0.0085, 0.0234, 0.0024, 0.0094, 0.0162, 0.0389,
        0.1785, 0.2004, 0.1247, 0.1287, 0.0528, 0.0902, 0.0172],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:40,051][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([8.1521e-05, 5.0041e-03, 2.0939e-02, 2.0692e-02, 1.1558e-01, 9.0211e-03,
        4.7265e-02, 3.8041e-03, 1.8183e-02, 2.7760e-01, 4.0839e-02, 3.8209e-02,
        2.6964e-01, 6.6245e-02, 1.4595e-02, 5.2294e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:40,053][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([2.3644e-02, 1.6760e-04, 1.1176e-05, 2.2697e-04, 2.4731e-05, 3.7414e-02,
        2.2259e-03, 8.5219e-02, 1.4639e-05, 3.9995e-04, 3.7440e-05, 1.2029e-04,
        1.7905e-03, 3.2347e-04, 2.1560e-05, 8.4836e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave]
[2024-07-24 10:27:40,055][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0523, 0.0880, 0.3437, 0.0655, 0.0551, 0.0493, 0.0452, 0.0810, 0.0179,
        0.0107, 0.0081, 0.0073, 0.0135, 0.0075, 0.0141, 0.1284, 0.0125],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:40,056][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0105, 0.0072, 0.0483, 0.0326, 0.0347, 0.0473, 0.0425, 0.0624, 0.0405,
        0.1696, 0.0230, 0.0377, 0.1427, 0.0425, 0.0362, 0.1214, 0.1010],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:40,057][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0005, 0.0055, 0.0588, 0.1142, 0.0293, 0.0058, 0.0484, 0.0017, 0.2103,
        0.1388, 0.0621, 0.1020, 0.0240, 0.1180, 0.0224, 0.0226, 0.0354],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:40,058][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0152, 0.0016, 0.0058, 0.0044, 0.0073, 0.0055, 0.0129, 0.0035, 0.0079,
        0.3469, 0.0857, 0.0595, 0.0894, 0.0291, 0.0150, 0.1068, 0.2036],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:40,059][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([2.3050e-05, 7.9922e-04, 1.0831e-02, 1.2029e-02, 1.8510e-02, 1.0811e-02,
        1.6336e-01, 5.9574e-04, 2.1369e-01, 7.0453e-02, 1.2403e-01, 1.9268e-01,
        9.4340e-03, 5.5468e-02, 7.6483e-02, 4.1097e-03, 3.6700e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:40,061][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([4.1522e-05, 3.0311e-04, 2.6142e-02, 3.8026e-02, 1.3726e-02, 2.9871e-03,
        3.6716e-02, 6.9306e-04, 4.6159e-02, 1.7172e-01, 1.1385e-01, 9.8337e-02,
        2.2259e-01, 8.9314e-02, 4.1240e-02, 1.6381e-02, 8.1776e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:40,064][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([7.0559e-05, 9.8221e-04, 8.2477e-03, 1.5062e-02, 4.2982e-03, 7.2586e-03,
        5.4301e-02, 4.0591e-03, 1.1696e-01, 2.0388e-01, 6.1663e-02, 1.4371e-01,
        3.6076e-02, 1.0232e-01, 1.1228e-02, 9.3083e-02, 1.3680e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:40,066][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([4.3269e-05, 1.5662e-03, 7.6931e-03, 2.7821e-02, 3.2855e-02, 1.1002e-02,
        6.6013e-02, 2.2228e-03, 6.4647e-02, 1.5939e-01, 1.2450e-01, 8.6079e-02,
        1.0977e-01, 7.1771e-02, 1.2339e-02, 4.7721e-02, 1.7457e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:40,070][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0012, 0.0117, 0.0035, 0.0634, 0.0102, 0.1611, 0.1289, 0.0353, 0.0123,
        0.0695, 0.0101, 0.0486, 0.0686, 0.0779, 0.0064, 0.0892, 0.2019],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:40,072][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0003, 0.0003, 0.0404, 0.0049, 0.0067, 0.0020, 0.0071, 0.0054, 0.0455,
        0.2307, 0.1191, 0.1420, 0.1222, 0.0719, 0.1294, 0.0287, 0.0433],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:40,073][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0023, 0.0154, 0.0350, 0.0603, 0.1176, 0.0137, 0.0371, 0.0093, 0.0390,
        0.1894, 0.0376, 0.0369, 0.1746, 0.0524, 0.0226, 0.0821, 0.0747],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:40,074][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([3.9741e-03, 2.2222e-04, 1.6412e-04, 2.7186e-03, 3.4953e-04, 3.7422e-02,
        1.9447e-02, 2.4508e-02, 8.3051e-04, 9.2474e-03, 1.5133e-03, 6.1055e-03,
        8.8041e-03, 6.2902e-03, 7.2410e-04, 6.9442e-01, 1.8326e-01],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a]
[2024-07-24 10:27:40,075][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([0.0715, 0.0826, 0.2099, 0.0453, 0.0351, 0.0520, 0.0438, 0.1094, 0.0172,
        0.0091, 0.0087, 0.0102, 0.0188, 0.0110, 0.0147, 0.2316, 0.0183, 0.0109],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:40,077][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([0.0145, 0.0079, 0.0201, 0.0306, 0.0459, 0.0463, 0.0555, 0.0467, 0.0646,
        0.1621, 0.0261, 0.0605, 0.0747, 0.0545, 0.0295, 0.0768, 0.0958, 0.0879],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:40,079][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([7.7066e-05, 1.5348e-03, 5.0259e-02, 6.2352e-02, 4.7899e-02, 2.7301e-03,
        4.5551e-02, 6.4458e-04, 2.5033e-01, 1.1138e-01, 5.9217e-02, 1.1853e-01,
        1.9063e-02, 1.1387e-01, 6.1477e-02, 6.0655e-03, 2.3235e-02, 2.5777e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:40,083][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([0.0101, 0.0019, 0.0071, 0.0056, 0.0140, 0.0020, 0.0089, 0.0015, 0.0200,
        0.2933, 0.1759, 0.1352, 0.0707, 0.0472, 0.0184, 0.0312, 0.0826, 0.0744],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:40,086][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([4.6312e-05, 1.5136e-03, 8.5954e-03, 1.4706e-02, 2.4104e-02, 8.9553e-03,
        1.1463e-01, 4.4558e-04, 2.2406e-01, 6.9100e-02, 1.1708e-01, 1.8758e-01,
        1.2914e-02, 5.9466e-02, 6.0040e-02, 3.7813e-03, 2.5482e-02, 6.7494e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:40,088][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([1.3470e-04, 1.0688e-03, 1.5936e-02, 2.7129e-02, 1.7944e-02, 3.3216e-03,
        4.9760e-02, 7.0989e-04, 5.8085e-02, 1.6717e-01, 1.3462e-01, 1.6265e-01,
        1.0558e-01, 1.0114e-01, 2.2589e-02, 1.5316e-02, 8.6338e-02, 3.0498e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:40,090][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([0.0004, 0.0059, 0.0177, 0.0426, 0.0097, 0.0126, 0.0715, 0.0046, 0.1403,
        0.1663, 0.0698, 0.1519, 0.0270, 0.0890, 0.0093, 0.0659, 0.1022, 0.0134],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:40,091][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([2.8128e-05, 6.6240e-04, 4.5753e-03, 1.7332e-02, 2.7026e-02, 4.1949e-03,
        5.6717e-02, 1.1397e-03, 1.0568e-01, 1.6616e-01, 1.1897e-01, 1.1586e-01,
        7.6768e-02, 1.0767e-01, 2.4896e-02, 2.2838e-02, 1.0965e-01, 3.9836e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:40,092][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([4.3560e-04, 4.7845e-04, 3.5027e-05, 2.0699e-03, 3.3955e-05, 5.1137e-01,
        2.5094e-03, 3.6623e-01, 3.7488e-05, 2.0285e-04, 2.2123e-05, 1.0545e-04,
        1.3047e-03, 2.0564e-04, 8.8402e-06, 1.0829e-01, 6.4571e-03, 1.9715e-04],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:40,093][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([0.0017, 0.0007, 0.0114, 0.0033, 0.0033, 0.0035, 0.0069, 0.0069, 0.0512,
        0.2260, 0.1147, 0.1641, 0.0957, 0.0873, 0.0628, 0.0604, 0.0666, 0.0336],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:40,095][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([0.0266, 0.0366, 0.0265, 0.0703, 0.1176, 0.0143, 0.0345, 0.0178, 0.0780,
        0.1154, 0.0558, 0.0526, 0.0792, 0.0629, 0.0217, 0.1028, 0.0751, 0.0120],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:40,097][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([1.1590e-03, 1.9330e-04, 1.1185e-04, 2.4204e-03, 5.1329e-04, 2.1316e-02,
        2.8838e-02, 1.3254e-02, 4.6411e-03, 2.9974e-02, 9.7581e-03, 3.6941e-02,
        1.3853e-02, 2.7480e-02, 2.4732e-03, 4.3118e-01, 3.1378e-01, 6.2112e-02],
       device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone]
[2024-07-24 10:27:40,101][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0743, 0.0933, 0.2767, 0.0448, 0.0373, 0.0547, 0.0334, 0.0990, 0.0124,
        0.0057, 0.0056, 0.0058, 0.0115, 0.0062, 0.0090, 0.2086, 0.0118, 0.0047,
        0.0050], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:40,106][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0097, 0.0095, 0.0385, 0.0484, 0.0903, 0.0494, 0.0408, 0.0310, 0.0740,
        0.0793, 0.0186, 0.0430, 0.0390, 0.0337, 0.0291, 0.0710, 0.0888, 0.1018,
        0.1041], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:40,108][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([4.0875e-05, 1.0488e-03, 5.1276e-02, 5.1799e-02, 3.2557e-02, 1.2567e-03,
        2.6702e-02, 2.3783e-04, 2.8775e-01, 8.4043e-02, 5.0801e-02, 9.5260e-02,
        1.4323e-02, 8.5433e-02, 6.2742e-02, 3.5483e-03, 1.9668e-02, 2.7940e-02,
        1.0358e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:40,109][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0126, 0.0020, 0.0059, 0.0052, 0.0107, 0.0021, 0.0069, 0.0018, 0.0169,
        0.2149, 0.0831, 0.0649, 0.0347, 0.0217, 0.0132, 0.0171, 0.0513, 0.0312,
        0.4037], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:40,110][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.2930e-05, 7.9203e-04, 1.5377e-02, 1.2170e-02, 2.7226e-02, 3.9910e-03,
        6.2737e-02, 9.8902e-05, 2.5441e-01, 4.4977e-02, 1.0464e-01, 1.3104e-01,
        6.6711e-03, 3.7973e-02, 7.9589e-02, 1.4339e-03, 1.4509e-02, 6.0505e-02,
        1.4185e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:40,111][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([4.3922e-05, 4.9403e-04, 7.0601e-03, 2.1196e-02, 8.9486e-03, 2.3200e-03,
        2.6946e-02, 4.2294e-04, 6.2226e-02, 1.1041e-01, 1.0174e-01, 1.2551e-01,
        6.1638e-02, 9.0249e-02, 1.7118e-02, 1.2396e-02, 8.3470e-02, 2.4493e-02,
        2.4332e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:40,113][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0003, 0.0024, 0.0192, 0.0287, 0.0071, 0.0094, 0.0411, 0.0027, 0.1490,
        0.1325, 0.0468, 0.1084, 0.0193, 0.0617, 0.0123, 0.0568, 0.1374, 0.0188,
        0.1462], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:40,114][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.0251e-05, 2.3903e-04, 3.5082e-03, 1.1201e-02, 1.7790e-02, 3.4637e-03,
        3.5164e-02, 5.1233e-04, 1.2734e-01, 1.2359e-01, 8.0038e-02, 9.8400e-02,
        5.7950e-02, 6.1108e-02, 2.2037e-02, 1.5386e-02, 1.0277e-01, 3.0893e-02,
        2.0860e-01], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:40,115][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([7.4943e-05, 3.3415e-04, 1.5259e-05, 2.5503e-03, 1.8451e-05, 6.6294e-01,
        1.3995e-03, 2.8668e-01, 1.0578e-05, 3.9826e-05, 4.1296e-06, 1.6690e-05,
        3.6047e-04, 4.4606e-05, 1.7924e-06, 4.3546e-02, 1.8535e-03, 4.4011e-05,
        6.7141e-05], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:40,119][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0010, 0.0004, 0.0086, 0.0032, 0.0017, 0.0019, 0.0041, 0.0037, 0.0430,
        0.1455, 0.0532, 0.1043, 0.0643, 0.0624, 0.0803, 0.0566, 0.1071, 0.0383,
        0.2205], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:40,123][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0820, 0.0720, 0.0368, 0.1091, 0.0834, 0.0125, 0.0179, 0.0166, 0.0732,
        0.0780, 0.0393, 0.0299, 0.0606, 0.0407, 0.0160, 0.0823, 0.0565, 0.0072,
        0.0859], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:40,125][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.4805e-03, 2.0945e-04, 2.5386e-04, 4.2982e-03, 6.1812e-04, 2.5149e-02,
        3.1110e-02, 1.0696e-02, 8.3251e-03, 3.3818e-02, 1.2039e-02, 6.0070e-02,
        1.1261e-02, 2.6848e-02, 3.4866e-03, 3.4511e-01, 2.7186e-01, 6.2400e-02,
        9.0970e-02], device='cuda:0') for source tokens [Then, Brittany and Travis had a lot of fun at the store. Brittany gave a bone to]
[2024-07-24 10:27:40,129][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:40,131][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[7344],
        [  62],
        [   5],
        [  11],
        [   1],
        [  11],
        [  64],
        [  23],
        [   4],
        [  18],
        [   4],
        [  53],
        [   1],
        [   1],
        [   1],
        [  22],
        [  38],
        [   3],
        [   1]], device='cuda:0')
[2024-07-24 10:27:40,132][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[7034],
        [  39],
        [   5],
        [  15],
        [   1],
        [   7],
        [  64],
        [  22],
        [   2],
        [   8],
        [   4],
        [  38],
        [   1],
        [   1],
        [   1],
        [  14],
        [  29],
        [   2],
        [   1]], device='cuda:0')
[2024-07-24 10:27:40,135][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[10192],
        [30400],
        [37643],
        [36782],
        [35278],
        [37997],
        [37388],
        [38320],
        [37656],
        [38227],
        [37424],
        [37696],
        [38003],
        [38021],
        [37838],
        [38277],
        [38140],
        [37902],
        [38117]], device='cuda:0')
[2024-07-24 10:27:40,138][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 3932],
        [14096],
        [27576],
        [28319],
        [32544],
        [25838],
        [30360],
        [29843],
        [29301],
        [33207],
        [33458],
        [34158],
        [36202],
        [36208],
        [35641],
        [38261],
        [37630],
        [37658],
        [37110]], device='cuda:0')
[2024-07-24 10:27:40,140][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 1989],
        [ 2902],
        [ 2683],
        [ 2490],
        [12355],
        [ 6167],
        [ 5454],
        [ 4035],
        [ 3462],
        [ 3617],
        [ 2624],
        [ 1737],
        [ 1908],
        [ 1767],
        [ 1902],
        [ 2097],
        [ 1878],
        [ 1998],
        [ 1793]], device='cuda:0')
[2024-07-24 10:27:40,143][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[45167],
        [47139],
        [49264],
        [49326],
        [48935],
        [48513],
        [48948],
        [48695],
        [49231],
        [49483],
        [49603],
        [49655],
        [49719],
        [49738],
        [49790],
        [50000],
        [49922],
        [49834],
        [49902]], device='cuda:0')
[2024-07-24 10:27:40,146][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 6362],
        [27280],
        [25087],
        [25621],
        [23318],
        [24382],
        [24935],
        [25631],
        [31360],
        [31554],
        [34536],
        [35827],
        [35506],
        [36052],
        [36330],
        [34196],
        [35762],
        [36163],
        [36619]], device='cuda:0')
[2024-07-24 10:27:40,149][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[35565],
        [45366],
        [41256],
        [42942],
        [42607],
        [42535],
        [42410],
        [42779],
        [43881],
        [44641],
        [44619],
        [44627],
        [44948],
        [44654],
        [44503],
        [44944],
        [44536],
        [44401],
        [43997]], device='cuda:0')
[2024-07-24 10:27:40,150][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[38116],
        [25526],
        [29727],
        [27735],
        [29051],
        [28330],
        [23703],
        [18688],
        [21712],
        [20182],
        [19641],
        [18439],
        [18483],
        [18395],
        [18836],
        [17496],
        [15979],
        [16683],
        [15310]], device='cuda:0')
[2024-07-24 10:27:40,152][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[49813],
        [31137],
        [27242],
        [28842],
        [28429],
        [29124],
        [28365],
        [29802],
        [25737],
        [23755],
        [22944],
        [23386],
        [23429],
        [23041],
        [23116],
        [26118],
        [24348],
        [23322],
        [23298]], device='cuda:0')
[2024-07-24 10:27:40,153][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[10710],
        [11097],
        [12080],
        [ 7222],
        [ 7618],
        [ 7121],
        [ 7278],
        [ 7119],
        [10620],
        [12467],
        [12572],
        [ 8720],
        [ 7417],
        [12927],
        [10688],
        [ 7125],
        [ 7230],
        [ 8881],
        [12498]], device='cuda:0')
[2024-07-24 10:27:40,156][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[39528],
        [27351],
        [31163],
        [30841],
        [31394],
        [33129],
        [31823],
        [33793],
        [17971],
        [15649],
        [13496],
        [12857],
        [12364],
        [13208],
        [14465],
        [15770],
        [15757],
        [15385],
        [18572]], device='cuda:0')
[2024-07-24 10:27:40,159][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[34153],
        [38825],
        [16244],
        [22991],
        [14593],
        [ 8270],
        [15278],
        [13193],
        [32209],
        [27697],
        [33828],
        [35129],
        [34873],
        [36073],
        [36149],
        [41507],
        [40492],
        [40046],
        [40268]], device='cuda:0')
[2024-07-24 10:27:40,162][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[33865],
        [31727],
        [24962],
        [24276],
        [24237],
        [18939],
        [19084],
        [27219],
        [22255],
        [22336],
        [23619],
        [23350],
        [23087],
        [24481],
        [25427],
        [26936],
        [26345],
        [26503],
        [26031]], device='cuda:0')
[2024-07-24 10:27:40,164][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[11905],
        [16534],
        [13118],
        [17864],
        [20345],
        [16855],
        [15843],
        [16835],
        [17690],
        [19177],
        [18578],
        [17416],
        [19104],
        [15280],
        [16751],
        [14375],
        [18220],
        [20025],
        [21058]], device='cuda:0')
[2024-07-24 10:27:40,167][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[21237],
        [24450],
        [18532],
        [19342],
        [20517],
        [18690],
        [20161],
        [19439],
        [20965],
        [20312],
        [21159],
        [20966],
        [21146],
        [20963],
        [22111],
        [21603],
        [23590],
        [26522],
        [25424]], device='cuda:0')
[2024-07-24 10:27:40,170][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[21860],
        [22816],
        [21351],
        [22317],
        [23396],
        [22875],
        [24115],
        [29906],
        [27404],
        [28461],
        [28140],
        [28446],
        [29398],
        [28906],
        [29061],
        [30487],
        [29518],
        [29578],
        [29715]], device='cuda:0')
[2024-07-24 10:27:40,172][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[40965],
        [25952],
        [33543],
        [30610],
        [28268],
        [28706],
        [29264],
        [29877],
        [29531],
        [28966],
        [28987],
        [29296],
        [29423],
        [29604],
        [30154],
        [30278],
        [29838],
        [30090],
        [30305]], device='cuda:0')
[2024-07-24 10:27:40,174][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 6216],
        [ 4979],
        [13333],
        [11721],
        [11598],
        [10993],
        [11591],
        [10784],
        [10883],
        [ 9564],
        [ 9656],
        [ 9938],
        [ 9838],
        [10101],
        [10367],
        [ 8364],
        [ 8591],
        [ 9817],
        [ 9251]], device='cuda:0')
[2024-07-24 10:27:40,175][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[19932],
        [30110],
        [28103],
        [28111],
        [33157],
        [31801],
        [25387],
        [24159],
        [27911],
        [28878],
        [28571],
        [27685],
        [27822],
        [28592],
        [28558],
        [26842],
        [27462],
        [28939],
        [29003]], device='cuda:0')
[2024-07-24 10:27:40,177][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 5251],
        [ 8363],
        [12882],
        [11277],
        [11228],
        [11448],
        [10507],
        [10863],
        [ 9395],
        [10993],
        [ 9450],
        [ 9434],
        [ 9052],
        [ 9108],
        [ 8975],
        [ 8950],
        [ 9283],
        [ 9372],
        [10365]], device='cuda:0')
[2024-07-24 10:27:40,180][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[10484],
        [ 9483],
        [ 5481],
        [ 6590],
        [ 6777],
        [ 8749],
        [ 7306],
        [ 8016],
        [ 8185],
        [ 6680],
        [ 6652],
        [ 6388],
        [ 6205],
        [ 6369],
        [ 6390],
        [ 5886],
        [ 5845],
        [ 6075],
        [ 5946]], device='cuda:0')
[2024-07-24 10:27:40,182][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[18810],
        [17482],
        [20302],
        [22254],
        [22740],
        [22016],
        [24185],
        [22376],
        [29479],
        [28344],
        [30936],
        [30002],
        [29109],
        [31121],
        [31051],
        [28988],
        [29446],
        [30447],
        [30621]], device='cuda:0')
[2024-07-24 10:27:40,185][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[20349],
        [14901],
        [16831],
        [ 6325],
        [ 2534],
        [17344],
        [19071],
        [17168],
        [19488],
        [19523],
        [19386],
        [19401],
        [19105],
        [19453],
        [19569],
        [18954],
        [16747],
        [19459],
        [19389]], device='cuda:0')
[2024-07-24 10:27:40,188][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[10169],
        [ 9120],
        [ 6774],
        [ 6706],
        [ 6145],
        [ 5833],
        [ 5976],
        [ 5255],
        [ 7366],
        [ 8832],
        [ 7937],
        [ 7045],
        [ 6503],
        [ 6602],
        [ 6185],
        [ 6028],
        [ 6095],
        [ 6049],
        [ 5917]], device='cuda:0')
[2024-07-24 10:27:40,190][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 9336],
        [11960],
        [12880],
        [14426],
        [15470],
        [16896],
        [16371],
        [17218],
        [14254],
        [16398],
        [16067],
        [16412],
        [16193],
        [15958],
        [15550],
        [14631],
        [15403],
        [16163],
        [15903]], device='cuda:0')
[2024-07-24 10:27:40,193][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[7081],
        [3530],
        [4943],
        [5159],
        [5083],
        [2950],
        [3158],
        [2887],
        [3125],
        [4053],
        [4314],
        [4628],
        [4136],
        [4284],
        [4832],
        [5652],
        [5382],
        [4927],
        [4717]], device='cuda:0')
[2024-07-24 10:27:40,195][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[28410],
        [31555],
        [25845],
        [25211],
        [25307],
        [24885],
        [25158],
        [25492],
        [23460],
        [23256],
        [23747],
        [24252],
        [25043],
        [24484],
        [24255],
        [25782],
        [25012],
        [23877],
        [24272]], device='cuda:0')
[2024-07-24 10:27:40,196][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[34030],
        [30889],
        [33640],
        [34878],
        [33349],
        [30533],
        [30850],
        [31311],
        [28876],
        [28452],
        [28152],
        [28609],
        [28071],
        [30644],
        [28694],
        [32784],
        [30088],
        [27613],
        [26371]], device='cuda:0')
[2024-07-24 10:27:40,198][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058]], device='cuda:0')
